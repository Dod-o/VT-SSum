{
    "id": "vcjl6jrghflmvsweq7crauiuajbztlrj",
    "title": "Learning to Link with Wikipedia",
    "info": {
        "author": [
            "David Milne, Computer Science Department, University of Waikato"
        ],
        "published": "Nov. 19, 2008",
        "recorded": "October 2008",
        "category": [
            "Top->Computer Science->Web Mining->Link Analysis"
        ]
    },
    "url": "http://videolectures.net/cikm08_milne_ltlww/",
    "segmentation": [
        [
            "OK, my name is David Nolan and clearly it's anticipated that I'm going to be nervous here.",
            "OK, I'm here to talk about learning to link with Wikipedia.",
            "I've been running some experiments recently of just taking a document and automatically augmenting it with links to the relevant Wikipedia topics.",
            "I'm not going to give an outline of my talk.",
            "Is this exactly what you expect?",
            "I'll do some hand WAVY motivation stuff, then talk about the details of the algorithm and how it works and evaluation and talk about some applications.",
            "Also, barring any disasters or demo the system life."
        ],
        [
            "OK, motivation to motivate this talk.",
            "I want to go back and relive the heady day when I first discovered that I was coming to see RKM that my paper was accepted.",
            "To be honest, my first thought was not about all the networking opportunities or the different papers I'd be seeing.",
            "My first thought was, hey, I get to come to Napa, it's a place I've never seen before and I get to do it on the taxpayers dollar.",
            "So my first thing I did.",
            "Was I went off to Wikipedia and looked up about it, then some reading.",
            "And the great thing about Wikipedia.",
            "Is that it's all interlinked, so.",
            "Anytime I encounter something that I don't understand that needs a bit more explanation, I can just click on it and read a bit more.",
            "Anytime I want to find out or investigate something like I want to see the wide area that Knapper is and I can just click on it and read more.",
            "So obviously never being there for it does not take very long to start reading.",
            "About one so you know an hour later, lots and lots of clicking I.",
            "At least feel prepared to come to this conference.",
            "At least know a little bit about wine.",
            "So these links they're providing explanation, investigation, and opportunities for serendipitous encounters.",
            "When I first started, I did not know that I needed to read about wine before I came to this conference.",
            "Wouldn't it be great if we could add those same links and those same opportunities to all day?"
        ],
        [
            "Payments.",
            "This talk, for example, would be great if you could just hit pause on me and click on these things to learn more about machine learning or Wikipedia, or the place where I'm from.",
            "Unfortunately not famous enough to have a Wikipedia article about me, so there's no length."
        ],
        [
            "This is not a new idea.",
            "In fact, just last year at CIK and when it was in Portugal there was a paper presented which did exactly this, and there's a system called worker fire up on the web that you can use.",
            "There's also an entire track at the NX conference which investigates this idea."
        ],
        [
            "Suffice to say, I'm doing something a little bit different from these guys.",
            "And the difference is actually encoded in a little bit of deliberate ambiguity in the title of the talk, so we're all trying to link with Wikipedia.",
            "We're all trying to connect documents to Wikipedia.",
            "The thing I'm doing differently as I'm learning with Wikipedia, I'm using Wikipedia to provide millions of examples of how to link documents through Wikipedia, because every single Wikipedia article is an example of a document that's been manually linked to Wikipedia.",
            "So there's two steps involved in this algorithm.",
            "We need to do link disambiguation because terms can be ambiguous and we need to decide which exact article to link to.",
            "And there's also link selection.",
            "We need to decide is this term or phrase worth linking to or not both of these problems.",
            "We can create a machine learning solution for this, learning from Wikipedia."
        ],
        [
            "The articles themselves.",
            "So I will provide some details about the disambiguation step here.",
            "As we all know, human language is ambiguous, so Napa, for example, we could be talking about the city.",
            "Or a River nearby or the surrounding countryside.",
            "Or actually the top earning Google is something completely different.",
            "And this ambiguity is actually reflected in Wikipedia's link structure.",
            "So anytime a human author wants to add a link from the word Napa and Wikipedia thereafter, manually say this is a wiki syntax where they where they create the link after manually, say what is the exact destination of the link.",
            "So I have to manually to simulate it.",
            "That means we have millions of examples of how to disambiguate terms.",
            "Every single link is hundreds of millions of links as a positive example, 'cause we can see.",
            "Here's the term, and this is the actual concept failing to, and it's potentially 510 hundred negative examples of the things that they could have linked to, but they didn't."
        ],
        [
            "And.",
            "So a machine learning approach makes sense here.",
            "That again, is nothing different from what was done previously except.",
            "Normally this isn't a very expensive thing because your features are normally all the surrounding words and their parts of speech, whereas my approach works with only two features.",
            "Basically 2 main features.",
            "The first is commonness, which is just the prior probability of a sense being the correct one, completely independent of context, so here.",
            "Is a recent."
        ],
        [
            "Search from the news.",
            "Of course, it's about the current economic crisis.",
            "What else can I talk about?",
            "Um?",
            "Technically, in Wikipedia, global economy is ambiguous.",
            "When people start a link from the anchor global economy, they've made different choices about where it goes.",
            "Sometimes they go to the global economy, the obvious one, but sometimes they actually link to the phenomenon.",
            "The growing trend of.",
            "Countries and governments and trade organisations to cooperate globally.",
            "But we can easily identify the more obvious, sensible connection from the other one just by looking at how often.",
            "The term global economy is used to link to each of these destinations, and most of the time it goes to global economy.",
            "So that's one."
        ],
        [
            "Teacher.",
            "Obviously it's not a good idea to rely on that exclusively.",
            "Here's a different example.",
            "Turn banks.",
            "This is actually more genuinely ambiguous, so we could be talking about the financial position as institution as we are here, but it could also be talking about the Bank of the River, the side of a River.",
            "Or we could be talking about an underwater Hill like a sandbank that ships run aground on.",
            "Or we could be talking about banking a plan.",
            "Turning it.",
            "So if we always chose the most obvious since we'd be making a mistake here, we were talking about the banks of the River.",
            "To identify these cases, what we do is we take all of the unambiguous terms and phrases from the surrounding text, and we use those to disambiguate the the ambiguous ones.",
            "So what we do is we just calculate semantic weirdness between banks.",
            "All the different senses of banks and these two unambiguous terms which are both rivers, and we would see would get a very high relatedness score for the edge of the River or stream, and that's the sense we want.",
            "There's a problem here.",
            "We need to be able to calculate the relatedness of two Wikipedia concepts.",
            "So we've got our different sense concepts, candidate sensors, and we've also got a different.",
            "Context concepts and we need to get a measure of how they relate to each other.",
            "To do this, I'm building on some previous work which I recently presented at a workshop at AAAI."
        ],
        [
            "Where we use Wikipedia's links to calculate relatedness.",
            "The way it works is here we have the Wikipedia article on globalization and we have it.",
            "We can see the links to some related concepts such as trade, foreign, direct investment, human migration.",
            "So we just gather all of those links for that concept.",
            "If we do the same for bank, we would see there's some overlap World Bank mixed economy which relates to both concepts that would see that there's also links to relate that connects only to one concept or the other, so the ones in common indicate that the concepts related to ones that are distinct for one or the other.",
            "They indicate that they are not related.",
            "We can do exactly the same for the links coming into the articles, and there's a formula in the paper which turns us into a number of actually how much globalization relates to bank.",
            "And we just average that across all of our.",
            "Contact sensors actually it's weighted average because some context terms are better than others.",
            "The details are in the paper."
        ],
        [
            "OK, so we've got 2 features for whether a candidate sense is a good one or not.",
            "Morgan is those behind the balance them somehow.",
            "Which one is more important than the other?",
            "And to do that it makes sense to think of how good the context is.",
            "If we have lots of it and sort of forms a central thread, the document is about clearly about financial stuff.",
            "Or it's clearly about rivers, then relatedness is very important.",
            "We want to pretty much ignore prior probability.",
            "But if we have the opposite situation, we are.",
            "Al context is all mixed up all over the place.",
            "We don't really get a clear idea of what this document is about.",
            "Then we should pick the most common sense, 'cause by definition that will be correct in most cases.",
            "To drink that wine at the moment.",
            "OK, so to allow our machine learning classifier to identify these cases and to adjust the balance from document to document, we add a third feature into the mix which is just quality of context, which is the sum of the weights of the context terms.",
            "I realize I have not explained how the context terms are weighted, but it's in the paper."
        ],
        [
            "OK, it's very easy to explain how to evaluate this system.",
            "It's being trained up on Wikipedia links, so let's just keep some separate for training and another bunch separate for evaluation.",
            "So that's what we did.",
            "We trained on the links of about 500 articles.",
            "Developed in tweets.",
            "Change the classification algorithm that sort of thing on 100 articles and tested on 100 completely separate independent articles.",
            "And the results are very high.",
            "Definitely competitive with the state of the art.",
            "And the other thing about this approach is is very cheap.",
            "As I said, there's no passing.",
            "There's no parts of speech involved, so we're dealing with raw text and in grams, and we're only dealing with the link structure Wikipedia.",
            "We got all the information that we need to do this.",
            "It can all fit in memory.",
            "So for example, on these 100 articles, which involved that 11,000 links, so many, many, many Link candidates, candidates, sensors.",
            "It did it in about 3 or 4 minutes.",
            "And this is just on a very average run of the mill machine.",
            "The next problem is link selection.",
            "OK, we can resolve ambiguous links.",
            "And how about?",
            "How do we decide whether we should link a term in the first place?",
            "And again, every single, as I said before, every single Wikipedia article is an example of how to do this."
        ],
        [
            "So let's take a look at the article in Napa, CA that I showed earlier.",
            "Um?",
            "OK, so Wikipedia is are making pretty subtle to decisions about what we should add in link to and what we shouldn't.",
            "Can I get a minute?",
            "So they're making decisions like OK want to link to County seat because people are foreigners and don't know what this actually means.",
            "I need to click on this to understand what the concept was.",
            "Well they had a link to Napa County because chances are if you're looking at the city you want to also see the wider context of where it is but they don't like to things like census 'cause it's only peripherally relevant to the story and they don't link to things like city or population.",
            "'cause chances are you know what that is already.",
            "So can we learn from Wikipedia articles and make those same sort of decisions which pretty sophisticated automatically?",
            "Again, machine learning parts and the way it works is.",
            "We start by trying to collect everything we disambiguate.",
            "We detect and disambiguate every engram which could possibly.",
            "And any chance be a candidate link?",
            "And then.",
            "In training we were doing this on Wikipedia articles and are good examples are the ones that were manually linked to and the bad examples are the ones that weren't.",
            "And then, because these are not just.",
            "In grams, the disambiguated concepts we can get features like not just where these engrams are found, but also how they relate to other concepts that are mentioned in the document or how general specific they are and use those to distinguish between good concepts and bad concepts."
        ],
        [
            "OK, to gather all the candidate concepts.",
            "Fortunately, Wikipedia provides a huge vocabulary.",
            "Of how to do this.",
            "Basically every turn that is possibly been linked, we could use that as a candidate.",
            "The problem is if anything the vocabulary is too comprehensive, so we could link to all of the stop words in this document.",
            "Even there is a Wikipedia article about the number 6 or the concept of a of an article or even the concept of half of something.",
            "So this is not sensible to try and.",
            "To even consider these in the algorithm.",
            "So what we can do is look at how often these things are used as links.",
            "So most of the time.",
            "Almost all of the time in Wikipedia, when the word that is mentioned it's not used as a link, whereas when the words global economy I mentioned to Wikipedia 15% of the time they used as a link, so we can distinguish between the chaff.",
            "And the actual concepts and we can do this without any form of part of speech analysis.",
            "Actually, this is how the previous system that I described the Wikify system works exclusively, which based on this feature.",
            "We just use it as a first pass to get rid of it with a very low threshold just to get rid of the stuff that has no chance of being linked."
        ],
        [
            "So we do that and we have different things that we need to consider, like central banks and banks.",
            "Overlap is perfectly fine at this stage.",
            "It's not a problem and we send that to disambiguate are so that we can actually have a one to one map from each of these engrams to the actual.",
            "Concepts and Wikipedia.",
            "And then the next step is we need to learn what are the good things we would want to link to, such as central banks and what are the best things we wouldn't want to such as energy, effort.",
            "What is relevant and what is not.",
            "Anne."
        ],
        [
            "And the features that are involved in that state are linked probability.",
            "The way we initially driving the candidate sensors, 'cause we know that works based on the previous work.",
            "Let's not throw the baby out for dishwater.",
            "But also relatedness.",
            "So remember when we're disambiguating.",
            "How terms we had to calculate how well it related to the central thread of the document, and also because it's so cheap to calculate relatedness, we also calculate it to all of the candidate concepts in the document and the intuition here is that you're more likely to be interested in documents which relate to the central thread, so we've got a document that talks about economy.",
            "Let's link to those sort of concepts instead of one that maybe mentions a location where people are talking about it.",
            "Another one is disambiguation confidence.",
            "So our disambiguation classifier doesn't just return a yes or no answer.",
            "Is this a good sense of a concept of a term, or not?",
            "It returns a confidence in the answer, so we can emphasize the ones we're most confident about and hopefully reduce the amount of disambiguation errors.",
            "Is also generality.",
            "The intuition here is that you're not likely to want links to very general topics such as science, because you know what it is already, but you would want a link to a specific concept, such as atmospheric thermodynamics or something.",
            "Then we can tell that simply by doing a crawl through Wikipedia's category structure, just a search.",
            "And we do that beforehand.",
            "And the next features are all based on where these engrams are found in the documents.",
            "Such as.",
            "It's well known that important topics tend to be found at the start of the document and the introduction.",
            "And also if a topic is mentioned all the way throughout the document, then it's more likely to be important as well."
        ],
        [
            "Um?",
            "OK, evaluation again, it's really easy to explain.",
            "We just keep 100 random articles separate from all of the data that I talked about earlier, and this time it was around 10,000 links.",
            "And we achieve a recall of about 74% and a precision of 74%.",
            "So what that means is.",
            "We took a Wikipedia article completely removed all the links, tried to put them in automatically and on the.",
            "You know 1/4 of them.",
            "Word of the new links were not found in the old links, and I need a quarter of the old links were not found in the new links.",
            "We also tried it out with in the wild with fication in the world with 15 news documents and we use Mechanical Turk to get people to look.",
            "Yet this very closely.",
            "I'm sorry.",
            "And they spent about two weeks with the men hours investigating whether these links are good enough and they got exactly the same results.",
            "Pretty much so.",
            "We're very confident this is how good algorithm is.",
            "And if that's the case, then it's a very big improvement over previous work.",
            "It's 50% improvement to both recall and precision over previous work."
        ],
        [
            "OK, so it's a wrap up.",
            "What can we do?",
            "We can add explanatory links to any document.",
            "We could easily augment news stories, blogs, educational materials.",
            "We could also assist the creation of new Wikipedia articles.",
            "You can imagine you type up a new Wikipedia article and there will be a button or just his wikify this, but that's really just scratching the surface.",
            "What we're really doing is we're cross referencing documents with the largest knowledge base in the world, and there's lots of applications for this.",
            "I'm sure you're dreaming up them now, so here's.",
            "Some concepts that were extracted from the paper and you can see it's doing things like it's resolving.",
            "Let's reduce them from the words to the concepts that are storing things like resolving ambiguity so we know exactly what type of ontology we're talking about.",
            "It's encoding policy me so it wouldn't matter if the document talked about data mining or knowledge discovery or KDD.",
            "It would always go to the same concept.",
            "It's not just a bag, it's of words.",
            "It's a graph 'cause we know how these concepts relate to each other.",
            "If we wanted to be trivial to tap into all the different efforts that are going on of turning Wikipedia into an ontology so we can do reasoning, we could tell you know that Hamilton is a city in New Zealand and it's the home of the University of Waikato.",
            "So basically anything that uses a bag of words model could use this stuff to tap into Wikipedia and use graphs of concepts instead.",
            "So my future work is I'll be using this for information retrieval, but also some of my colleagues will be using it for topic indexing.",
            "I didn't find the topic, so the document is about or document clustering, grouping related concepts.",
            "Um or document summarization identifying.",
            "The shortest sentence is and the most useful chunks of information from a document.",
            "Then hopefully other people will pick up on this and use it for different applications as well."
        ],
        [
            "Of course, that's my end.",
            "Curtis, I realize I completely forgot to demo the system live.",
            "Can I just show you very, very quickly how it works?",
            "How?",
            "OK, so here's a news story from BBC that I just picked up not very long ago.",
            "You can see from the date that this is not haven't had a lot of preparation.",
            "And his little booklet that I'll give you the code for.",
            "Free videos.",
            "And here is it getting automatically augmented with Wikipedia topics.",
            "So the red links Wikipedia links.",
            "We've got things like Hungary.",
            "Budapest International Monetary Fund.",
            "Is making decisions about what really is central to the topic and what isn't such as Gucci is not linked 'cause it's not really important.",
            "And it's also doing disambiguations so.",
            "I am if it's linking to International Monetary Fund whereas there are lots of different destinations where it could possibly have linked to.",
            "And.",
            "Just to show you it is making different decisions about what to link depending on the context.",
            "Here's a very important blog about handbags.",
            "And.",
            "Here's a wikified version of it, and it is actually linking to Gucci.",
            "Hannah.",
            "This is a link where you can get the booklet OK.",
            "Very interesting work, any questions?",
            "So the question you mentioned surgery as being one of the key features, IVR, nice features and only exaggerated everything.",
            "Since we're moving this artificially problem early, super early and they came in sections at the moment making if many people need to this and then only they need to replace that.",
            "Many people have linked to so much easier to insert a link to globalization if the work is already present.",
            "Something else so that might skew your results.",
            "Sure this is.",
            "That's something that you would not expect.",
            "It wouldn't come up in the week Ification the Wikipedia based evaluation where we are comparing it to things that were actually linked.",
            "And we're not, but there's something that would come up in a human evaluation where people would think this should be linked.",
            "We had Mechanical Turk users pour over these documents and actually say should this be like there?",
            "Shouldn't it be?",
            "And we didn't find too many examples of that.",
            "I was getting the same results so but that is a good point maybe.",
            "Another application for this would be suggesting links that people thought they missed and documents and would be interesting to see.",
            "In this case, is it working well or not?",
            "Or is it just predicting the same stuff that was already there?",
            "Follow up question.",
            "Kind figuration the mechanical chemical code.",
            "Human results very similar.",
            "Feel my cleanse with the with the errors in the same also or like was there much agreement between the Wikipedia.",
            "Ground truth and the account owner correctly OK.",
            "So in this case we have no Wikipedia ground truth because they wouldn't Wikipedia articles they were looking at.",
            "But I don't have time to describe how the human evaluation works, but a limitation of it is that we started off by giving the people the wikified documents, and then they tell us.",
            "Precision is they tell us which links were wrong and recall is they tell us which links were missing, so that gets rid of a lot of the.",
            "The people weren't creating the ground truth directly.",
            "In your conversation over.",
            "Basically, compute the programmers probability of multiple terms.",
            "Instead of looking at the computer turns right and now is the carpet.",
            "I mean if you have the diving computer, all possible combination of returns to come up with the what is the best combination in combination with too expensive?",
            "Do you have any efficient to overcome?",
            "Boyd complication exporting.",
            "For that I mean you may be OK because Wikipedia currently have or we will continue that.",
            "William is also so that next month you want your competition accomplish your bounded by the number, but in general, but I think the overall population and the complexity is too high in activities that way, so I was wondering how we compete with their ridiculous I mean enjoying retiring.",
            "This is correct by computational reasoning.",
            "Do something operation it's.",
            "I'm not quite sure what you mean, so to calculate the relatedness of two Wikipedia concepts, it's very, very fast.",
            "It happens about 11,000 times a second.",
            "Call the corresponding probability for 2003 times combination at all kinds of.",
            "What is your learning algorithm to to get you out in the optimal solution to come up with the optimum?",
            "Complication alkama manner instead of tonight.",
            "Trying all possible combinations.",
            "At the moment it does try all possible combinations because it's cheap enough to do that.",
            "As I said, they can calculate the relatedness between two Wikipedia concepts 11,000 times every second.",
            "There's not quite bounded in our documents of how many concepts we can have, so it's not really that many.",
            "Yeah, it's another thing that we needed to optimize, we felt.",
            "OK, the last price trend.",
            "I think which is asking can you make it more stringent so that you don't have 100 in a very short article?",
            "I'm sorry I didn't didn't follow.",
            "So that it's not collecting so many.",
            "Well, the initial threshold of how the prior probability of the link we can adjust that, inflate that up and down to easily cut out the less and less and less likely candidates.",
            "And that is obviously a sacrificing recall for speed and precision, and so the paper has a graph that compares what happens when we do that.",
            "Only other ways to do it as well.",
            "I haven't really thought of it.",
            "OK, I think the work is very interesting, so your guys may still have some question you can discuss offline and like thanks to all the speakers."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, my name is David Nolan and clearly it's anticipated that I'm going to be nervous here.",
                    "label": 0
                },
                {
                    "sent": "OK, I'm here to talk about learning to link with Wikipedia.",
                    "label": 0
                },
                {
                    "sent": "I've been running some experiments recently of just taking a document and automatically augmenting it with links to the relevant Wikipedia topics.",
                    "label": 1
                },
                {
                    "sent": "I'm not going to give an outline of my talk.",
                    "label": 0
                },
                {
                    "sent": "Is this exactly what you expect?",
                    "label": 0
                },
                {
                    "sent": "I'll do some hand WAVY motivation stuff, then talk about the details of the algorithm and how it works and evaluation and talk about some applications.",
                    "label": 0
                },
                {
                    "sent": "Also, barring any disasters or demo the system life.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, motivation to motivate this talk.",
                    "label": 0
                },
                {
                    "sent": "I want to go back and relive the heady day when I first discovered that I was coming to see RKM that my paper was accepted.",
                    "label": 0
                },
                {
                    "sent": "To be honest, my first thought was not about all the networking opportunities or the different papers I'd be seeing.",
                    "label": 0
                },
                {
                    "sent": "My first thought was, hey, I get to come to Napa, it's a place I've never seen before and I get to do it on the taxpayers dollar.",
                    "label": 0
                },
                {
                    "sent": "So my first thing I did.",
                    "label": 0
                },
                {
                    "sent": "Was I went off to Wikipedia and looked up about it, then some reading.",
                    "label": 0
                },
                {
                    "sent": "And the great thing about Wikipedia.",
                    "label": 0
                },
                {
                    "sent": "Is that it's all interlinked, so.",
                    "label": 0
                },
                {
                    "sent": "Anytime I encounter something that I don't understand that needs a bit more explanation, I can just click on it and read a bit more.",
                    "label": 0
                },
                {
                    "sent": "Anytime I want to find out or investigate something like I want to see the wide area that Knapper is and I can just click on it and read more.",
                    "label": 0
                },
                {
                    "sent": "So obviously never being there for it does not take very long to start reading.",
                    "label": 0
                },
                {
                    "sent": "About one so you know an hour later, lots and lots of clicking I.",
                    "label": 0
                },
                {
                    "sent": "At least feel prepared to come to this conference.",
                    "label": 0
                },
                {
                    "sent": "At least know a little bit about wine.",
                    "label": 0
                },
                {
                    "sent": "So these links they're providing explanation, investigation, and opportunities for serendipitous encounters.",
                    "label": 0
                },
                {
                    "sent": "When I first started, I did not know that I needed to read about wine before I came to this conference.",
                    "label": 0
                },
                {
                    "sent": "Wouldn't it be great if we could add those same links and those same opportunities to all day?",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Payments.",
                    "label": 0
                },
                {
                    "sent": "This talk, for example, would be great if you could just hit pause on me and click on these things to learn more about machine learning or Wikipedia, or the place where I'm from.",
                    "label": 0
                },
                {
                    "sent": "Unfortunately not famous enough to have a Wikipedia article about me, so there's no length.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is not a new idea.",
                    "label": 0
                },
                {
                    "sent": "In fact, just last year at CIK and when it was in Portugal there was a paper presented which did exactly this, and there's a system called worker fire up on the web that you can use.",
                    "label": 0
                },
                {
                    "sent": "There's also an entire track at the NX conference which investigates this idea.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Suffice to say, I'm doing something a little bit different from these guys.",
                    "label": 0
                },
                {
                    "sent": "And the difference is actually encoded in a little bit of deliberate ambiguity in the title of the talk, so we're all trying to link with Wikipedia.",
                    "label": 1
                },
                {
                    "sent": "We're all trying to connect documents to Wikipedia.",
                    "label": 0
                },
                {
                    "sent": "The thing I'm doing differently as I'm learning with Wikipedia, I'm using Wikipedia to provide millions of examples of how to link documents through Wikipedia, because every single Wikipedia article is an example of a document that's been manually linked to Wikipedia.",
                    "label": 0
                },
                {
                    "sent": "So there's two steps involved in this algorithm.",
                    "label": 0
                },
                {
                    "sent": "We need to do link disambiguation because terms can be ambiguous and we need to decide which exact article to link to.",
                    "label": 0
                },
                {
                    "sent": "And there's also link selection.",
                    "label": 0
                },
                {
                    "sent": "We need to decide is this term or phrase worth linking to or not both of these problems.",
                    "label": 0
                },
                {
                    "sent": "We can create a machine learning solution for this, learning from Wikipedia.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The articles themselves.",
                    "label": 0
                },
                {
                    "sent": "So I will provide some details about the disambiguation step here.",
                    "label": 0
                },
                {
                    "sent": "As we all know, human language is ambiguous, so Napa, for example, we could be talking about the city.",
                    "label": 0
                },
                {
                    "sent": "Or a River nearby or the surrounding countryside.",
                    "label": 0
                },
                {
                    "sent": "Or actually the top earning Google is something completely different.",
                    "label": 0
                },
                {
                    "sent": "And this ambiguity is actually reflected in Wikipedia's link structure.",
                    "label": 0
                },
                {
                    "sent": "So anytime a human author wants to add a link from the word Napa and Wikipedia thereafter, manually say this is a wiki syntax where they where they create the link after manually, say what is the exact destination of the link.",
                    "label": 0
                },
                {
                    "sent": "So I have to manually to simulate it.",
                    "label": 0
                },
                {
                    "sent": "That means we have millions of examples of how to disambiguate terms.",
                    "label": 0
                },
                {
                    "sent": "Every single link is hundreds of millions of links as a positive example, 'cause we can see.",
                    "label": 0
                },
                {
                    "sent": "Here's the term, and this is the actual concept failing to, and it's potentially 510 hundred negative examples of the things that they could have linked to, but they didn't.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "So a machine learning approach makes sense here.",
                    "label": 0
                },
                {
                    "sent": "That again, is nothing different from what was done previously except.",
                    "label": 0
                },
                {
                    "sent": "Normally this isn't a very expensive thing because your features are normally all the surrounding words and their parts of speech, whereas my approach works with only two features.",
                    "label": 0
                },
                {
                    "sent": "Basically 2 main features.",
                    "label": 0
                },
                {
                    "sent": "The first is commonness, which is just the prior probability of a sense being the correct one, completely independent of context, so here.",
                    "label": 1
                },
                {
                    "sent": "Is a recent.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Search from the news.",
                    "label": 0
                },
                {
                    "sent": "Of course, it's about the current economic crisis.",
                    "label": 0
                },
                {
                    "sent": "What else can I talk about?",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Technically, in Wikipedia, global economy is ambiguous.",
                    "label": 1
                },
                {
                    "sent": "When people start a link from the anchor global economy, they've made different choices about where it goes.",
                    "label": 0
                },
                {
                    "sent": "Sometimes they go to the global economy, the obvious one, but sometimes they actually link to the phenomenon.",
                    "label": 1
                },
                {
                    "sent": "The growing trend of.",
                    "label": 0
                },
                {
                    "sent": "Countries and governments and trade organisations to cooperate globally.",
                    "label": 0
                },
                {
                    "sent": "But we can easily identify the more obvious, sensible connection from the other one just by looking at how often.",
                    "label": 0
                },
                {
                    "sent": "The term global economy is used to link to each of these destinations, and most of the time it goes to global economy.",
                    "label": 0
                },
                {
                    "sent": "So that's one.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Teacher.",
                    "label": 0
                },
                {
                    "sent": "Obviously it's not a good idea to rely on that exclusively.",
                    "label": 0
                },
                {
                    "sent": "Here's a different example.",
                    "label": 0
                },
                {
                    "sent": "Turn banks.",
                    "label": 0
                },
                {
                    "sent": "This is actually more genuinely ambiguous, so we could be talking about the financial position as institution as we are here, but it could also be talking about the Bank of the River, the side of a River.",
                    "label": 1
                },
                {
                    "sent": "Or we could be talking about an underwater Hill like a sandbank that ships run aground on.",
                    "label": 1
                },
                {
                    "sent": "Or we could be talking about banking a plan.",
                    "label": 0
                },
                {
                    "sent": "Turning it.",
                    "label": 1
                },
                {
                    "sent": "So if we always chose the most obvious since we'd be making a mistake here, we were talking about the banks of the River.",
                    "label": 0
                },
                {
                    "sent": "To identify these cases, what we do is we take all of the unambiguous terms and phrases from the surrounding text, and we use those to disambiguate the the ambiguous ones.",
                    "label": 0
                },
                {
                    "sent": "So what we do is we just calculate semantic weirdness between banks.",
                    "label": 0
                },
                {
                    "sent": "All the different senses of banks and these two unambiguous terms which are both rivers, and we would see would get a very high relatedness score for the edge of the River or stream, and that's the sense we want.",
                    "label": 1
                },
                {
                    "sent": "There's a problem here.",
                    "label": 0
                },
                {
                    "sent": "We need to be able to calculate the relatedness of two Wikipedia concepts.",
                    "label": 0
                },
                {
                    "sent": "So we've got our different sense concepts, candidate sensors, and we've also got a different.",
                    "label": 0
                },
                {
                    "sent": "Context concepts and we need to get a measure of how they relate to each other.",
                    "label": 0
                },
                {
                    "sent": "To do this, I'm building on some previous work which I recently presented at a workshop at AAAI.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Where we use Wikipedia's links to calculate relatedness.",
                    "label": 0
                },
                {
                    "sent": "The way it works is here we have the Wikipedia article on globalization and we have it.",
                    "label": 0
                },
                {
                    "sent": "We can see the links to some related concepts such as trade, foreign, direct investment, human migration.",
                    "label": 0
                },
                {
                    "sent": "So we just gather all of those links for that concept.",
                    "label": 0
                },
                {
                    "sent": "If we do the same for bank, we would see there's some overlap World Bank mixed economy which relates to both concepts that would see that there's also links to relate that connects only to one concept or the other, so the ones in common indicate that the concepts related to ones that are distinct for one or the other.",
                    "label": 0
                },
                {
                    "sent": "They indicate that they are not related.",
                    "label": 0
                },
                {
                    "sent": "We can do exactly the same for the links coming into the articles, and there's a formula in the paper which turns us into a number of actually how much globalization relates to bank.",
                    "label": 0
                },
                {
                    "sent": "And we just average that across all of our.",
                    "label": 0
                },
                {
                    "sent": "Contact sensors actually it's weighted average because some context terms are better than others.",
                    "label": 0
                },
                {
                    "sent": "The details are in the paper.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so we've got 2 features for whether a candidate sense is a good one or not.",
                    "label": 0
                },
                {
                    "sent": "Morgan is those behind the balance them somehow.",
                    "label": 0
                },
                {
                    "sent": "Which one is more important than the other?",
                    "label": 0
                },
                {
                    "sent": "And to do that it makes sense to think of how good the context is.",
                    "label": 0
                },
                {
                    "sent": "If we have lots of it and sort of forms a central thread, the document is about clearly about financial stuff.",
                    "label": 0
                },
                {
                    "sent": "Or it's clearly about rivers, then relatedness is very important.",
                    "label": 0
                },
                {
                    "sent": "We want to pretty much ignore prior probability.",
                    "label": 0
                },
                {
                    "sent": "But if we have the opposite situation, we are.",
                    "label": 0
                },
                {
                    "sent": "Al context is all mixed up all over the place.",
                    "label": 0
                },
                {
                    "sent": "We don't really get a clear idea of what this document is about.",
                    "label": 0
                },
                {
                    "sent": "Then we should pick the most common sense, 'cause by definition that will be correct in most cases.",
                    "label": 0
                },
                {
                    "sent": "To drink that wine at the moment.",
                    "label": 0
                },
                {
                    "sent": "OK, so to allow our machine learning classifier to identify these cases and to adjust the balance from document to document, we add a third feature into the mix which is just quality of context, which is the sum of the weights of the context terms.",
                    "label": 1
                },
                {
                    "sent": "I realize I have not explained how the context terms are weighted, but it's in the paper.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, it's very easy to explain how to evaluate this system.",
                    "label": 0
                },
                {
                    "sent": "It's being trained up on Wikipedia links, so let's just keep some separate for training and another bunch separate for evaluation.",
                    "label": 0
                },
                {
                    "sent": "So that's what we did.",
                    "label": 0
                },
                {
                    "sent": "We trained on the links of about 500 articles.",
                    "label": 1
                },
                {
                    "sent": "Developed in tweets.",
                    "label": 0
                },
                {
                    "sent": "Change the classification algorithm that sort of thing on 100 articles and tested on 100 completely separate independent articles.",
                    "label": 1
                },
                {
                    "sent": "And the results are very high.",
                    "label": 0
                },
                {
                    "sent": "Definitely competitive with the state of the art.",
                    "label": 0
                },
                {
                    "sent": "And the other thing about this approach is is very cheap.",
                    "label": 0
                },
                {
                    "sent": "As I said, there's no passing.",
                    "label": 0
                },
                {
                    "sent": "There's no parts of speech involved, so we're dealing with raw text and in grams, and we're only dealing with the link structure Wikipedia.",
                    "label": 0
                },
                {
                    "sent": "We got all the information that we need to do this.",
                    "label": 0
                },
                {
                    "sent": "It can all fit in memory.",
                    "label": 0
                },
                {
                    "sent": "So for example, on these 100 articles, which involved that 11,000 links, so many, many, many Link candidates, candidates, sensors.",
                    "label": 0
                },
                {
                    "sent": "It did it in about 3 or 4 minutes.",
                    "label": 0
                },
                {
                    "sent": "And this is just on a very average run of the mill machine.",
                    "label": 0
                },
                {
                    "sent": "The next problem is link selection.",
                    "label": 0
                },
                {
                    "sent": "OK, we can resolve ambiguous links.",
                    "label": 0
                },
                {
                    "sent": "And how about?",
                    "label": 0
                },
                {
                    "sent": "How do we decide whether we should link a term in the first place?",
                    "label": 0
                },
                {
                    "sent": "And again, every single, as I said before, every single Wikipedia article is an example of how to do this.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So let's take a look at the article in Napa, CA that I showed earlier.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "OK, so Wikipedia is are making pretty subtle to decisions about what we should add in link to and what we shouldn't.",
                    "label": 0
                },
                {
                    "sent": "Can I get a minute?",
                    "label": 0
                },
                {
                    "sent": "So they're making decisions like OK want to link to County seat because people are foreigners and don't know what this actually means.",
                    "label": 0
                },
                {
                    "sent": "I need to click on this to understand what the concept was.",
                    "label": 0
                },
                {
                    "sent": "Well they had a link to Napa County because chances are if you're looking at the city you want to also see the wider context of where it is but they don't like to things like census 'cause it's only peripherally relevant to the story and they don't link to things like city or population.",
                    "label": 0
                },
                {
                    "sent": "'cause chances are you know what that is already.",
                    "label": 0
                },
                {
                    "sent": "So can we learn from Wikipedia articles and make those same sort of decisions which pretty sophisticated automatically?",
                    "label": 0
                },
                {
                    "sent": "Again, machine learning parts and the way it works is.",
                    "label": 0
                },
                {
                    "sent": "We start by trying to collect everything we disambiguate.",
                    "label": 0
                },
                {
                    "sent": "We detect and disambiguate every engram which could possibly.",
                    "label": 1
                },
                {
                    "sent": "And any chance be a candidate link?",
                    "label": 0
                },
                {
                    "sent": "And then.",
                    "label": 0
                },
                {
                    "sent": "In training we were doing this on Wikipedia articles and are good examples are the ones that were manually linked to and the bad examples are the ones that weren't.",
                    "label": 0
                },
                {
                    "sent": "And then, because these are not just.",
                    "label": 1
                },
                {
                    "sent": "In grams, the disambiguated concepts we can get features like not just where these engrams are found, but also how they relate to other concepts that are mentioned in the document or how general specific they are and use those to distinguish between good concepts and bad concepts.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, to gather all the candidate concepts.",
                    "label": 0
                },
                {
                    "sent": "Fortunately, Wikipedia provides a huge vocabulary.",
                    "label": 1
                },
                {
                    "sent": "Of how to do this.",
                    "label": 0
                },
                {
                    "sent": "Basically every turn that is possibly been linked, we could use that as a candidate.",
                    "label": 0
                },
                {
                    "sent": "The problem is if anything the vocabulary is too comprehensive, so we could link to all of the stop words in this document.",
                    "label": 0
                },
                {
                    "sent": "Even there is a Wikipedia article about the number 6 or the concept of a of an article or even the concept of half of something.",
                    "label": 0
                },
                {
                    "sent": "So this is not sensible to try and.",
                    "label": 0
                },
                {
                    "sent": "To even consider these in the algorithm.",
                    "label": 0
                },
                {
                    "sent": "So what we can do is look at how often these things are used as links.",
                    "label": 0
                },
                {
                    "sent": "So most of the time.",
                    "label": 0
                },
                {
                    "sent": "Almost all of the time in Wikipedia, when the word that is mentioned it's not used as a link, whereas when the words global economy I mentioned to Wikipedia 15% of the time they used as a link, so we can distinguish between the chaff.",
                    "label": 0
                },
                {
                    "sent": "And the actual concepts and we can do this without any form of part of speech analysis.",
                    "label": 0
                },
                {
                    "sent": "Actually, this is how the previous system that I described the Wikify system works exclusively, which based on this feature.",
                    "label": 0
                },
                {
                    "sent": "We just use it as a first pass to get rid of it with a very low threshold just to get rid of the stuff that has no chance of being linked.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we do that and we have different things that we need to consider, like central banks and banks.",
                    "label": 0
                },
                {
                    "sent": "Overlap is perfectly fine at this stage.",
                    "label": 0
                },
                {
                    "sent": "It's not a problem and we send that to disambiguate are so that we can actually have a one to one map from each of these engrams to the actual.",
                    "label": 0
                },
                {
                    "sent": "Concepts and Wikipedia.",
                    "label": 0
                },
                {
                    "sent": "And then the next step is we need to learn what are the good things we would want to link to, such as central banks and what are the best things we wouldn't want to such as energy, effort.",
                    "label": 0
                },
                {
                    "sent": "What is relevant and what is not.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And the features that are involved in that state are linked probability.",
                    "label": 0
                },
                {
                    "sent": "The way we initially driving the candidate sensors, 'cause we know that works based on the previous work.",
                    "label": 0
                },
                {
                    "sent": "Let's not throw the baby out for dishwater.",
                    "label": 0
                },
                {
                    "sent": "But also relatedness.",
                    "label": 0
                },
                {
                    "sent": "So remember when we're disambiguating.",
                    "label": 0
                },
                {
                    "sent": "How terms we had to calculate how well it related to the central thread of the document, and also because it's so cheap to calculate relatedness, we also calculate it to all of the candidate concepts in the document and the intuition here is that you're more likely to be interested in documents which relate to the central thread, so we've got a document that talks about economy.",
                    "label": 0
                },
                {
                    "sent": "Let's link to those sort of concepts instead of one that maybe mentions a location where people are talking about it.",
                    "label": 0
                },
                {
                    "sent": "Another one is disambiguation confidence.",
                    "label": 1
                },
                {
                    "sent": "So our disambiguation classifier doesn't just return a yes or no answer.",
                    "label": 0
                },
                {
                    "sent": "Is this a good sense of a concept of a term, or not?",
                    "label": 0
                },
                {
                    "sent": "It returns a confidence in the answer, so we can emphasize the ones we're most confident about and hopefully reduce the amount of disambiguation errors.",
                    "label": 0
                },
                {
                    "sent": "Is also generality.",
                    "label": 0
                },
                {
                    "sent": "The intuition here is that you're not likely to want links to very general topics such as science, because you know what it is already, but you would want a link to a specific concept, such as atmospheric thermodynamics or something.",
                    "label": 0
                },
                {
                    "sent": "Then we can tell that simply by doing a crawl through Wikipedia's category structure, just a search.",
                    "label": 0
                },
                {
                    "sent": "And we do that beforehand.",
                    "label": 0
                },
                {
                    "sent": "And the next features are all based on where these engrams are found in the documents.",
                    "label": 0
                },
                {
                    "sent": "Such as.",
                    "label": 0
                },
                {
                    "sent": "It's well known that important topics tend to be found at the start of the document and the introduction.",
                    "label": 0
                },
                {
                    "sent": "And also if a topic is mentioned all the way throughout the document, then it's more likely to be important as well.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "OK, evaluation again, it's really easy to explain.",
                    "label": 0
                },
                {
                    "sent": "We just keep 100 random articles separate from all of the data that I talked about earlier, and this time it was around 10,000 links.",
                    "label": 0
                },
                {
                    "sent": "And we achieve a recall of about 74% and a precision of 74%.",
                    "label": 0
                },
                {
                    "sent": "So what that means is.",
                    "label": 0
                },
                {
                    "sent": "We took a Wikipedia article completely removed all the links, tried to put them in automatically and on the.",
                    "label": 0
                },
                {
                    "sent": "You know 1/4 of them.",
                    "label": 0
                },
                {
                    "sent": "Word of the new links were not found in the old links, and I need a quarter of the old links were not found in the new links.",
                    "label": 0
                },
                {
                    "sent": "We also tried it out with in the wild with fication in the world with 15 news documents and we use Mechanical Turk to get people to look.",
                    "label": 0
                },
                {
                    "sent": "Yet this very closely.",
                    "label": 0
                },
                {
                    "sent": "I'm sorry.",
                    "label": 0
                },
                {
                    "sent": "And they spent about two weeks with the men hours investigating whether these links are good enough and they got exactly the same results.",
                    "label": 0
                },
                {
                    "sent": "Pretty much so.",
                    "label": 0
                },
                {
                    "sent": "We're very confident this is how good algorithm is.",
                    "label": 0
                },
                {
                    "sent": "And if that's the case, then it's a very big improvement over previous work.",
                    "label": 0
                },
                {
                    "sent": "It's 50% improvement to both recall and precision over previous work.",
                    "label": 1
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so it's a wrap up.",
                    "label": 0
                },
                {
                    "sent": "What can we do?",
                    "label": 0
                },
                {
                    "sent": "We can add explanatory links to any document.",
                    "label": 1
                },
                {
                    "sent": "We could easily augment news stories, blogs, educational materials.",
                    "label": 0
                },
                {
                    "sent": "We could also assist the creation of new Wikipedia articles.",
                    "label": 0
                },
                {
                    "sent": "You can imagine you type up a new Wikipedia article and there will be a button or just his wikify this, but that's really just scratching the surface.",
                    "label": 0
                },
                {
                    "sent": "What we're really doing is we're cross referencing documents with the largest knowledge base in the world, and there's lots of applications for this.",
                    "label": 0
                },
                {
                    "sent": "I'm sure you're dreaming up them now, so here's.",
                    "label": 0
                },
                {
                    "sent": "Some concepts that were extracted from the paper and you can see it's doing things like it's resolving.",
                    "label": 0
                },
                {
                    "sent": "Let's reduce them from the words to the concepts that are storing things like resolving ambiguity so we know exactly what type of ontology we're talking about.",
                    "label": 0
                },
                {
                    "sent": "It's encoding policy me so it wouldn't matter if the document talked about data mining or knowledge discovery or KDD.",
                    "label": 0
                },
                {
                    "sent": "It would always go to the same concept.",
                    "label": 0
                },
                {
                    "sent": "It's not just a bag, it's of words.",
                    "label": 0
                },
                {
                    "sent": "It's a graph 'cause we know how these concepts relate to each other.",
                    "label": 0
                },
                {
                    "sent": "If we wanted to be trivial to tap into all the different efforts that are going on of turning Wikipedia into an ontology so we can do reasoning, we could tell you know that Hamilton is a city in New Zealand and it's the home of the University of Waikato.",
                    "label": 0
                },
                {
                    "sent": "So basically anything that uses a bag of words model could use this stuff to tap into Wikipedia and use graphs of concepts instead.",
                    "label": 0
                },
                {
                    "sent": "So my future work is I'll be using this for information retrieval, but also some of my colleagues will be using it for topic indexing.",
                    "label": 0
                },
                {
                    "sent": "I didn't find the topic, so the document is about or document clustering, grouping related concepts.",
                    "label": 0
                },
                {
                    "sent": "Um or document summarization identifying.",
                    "label": 0
                },
                {
                    "sent": "The shortest sentence is and the most useful chunks of information from a document.",
                    "label": 0
                },
                {
                    "sent": "Then hopefully other people will pick up on this and use it for different applications as well.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Of course, that's my end.",
                    "label": 0
                },
                {
                    "sent": "Curtis, I realize I completely forgot to demo the system live.",
                    "label": 0
                },
                {
                    "sent": "Can I just show you very, very quickly how it works?",
                    "label": 0
                },
                {
                    "sent": "How?",
                    "label": 0
                },
                {
                    "sent": "OK, so here's a news story from BBC that I just picked up not very long ago.",
                    "label": 0
                },
                {
                    "sent": "You can see from the date that this is not haven't had a lot of preparation.",
                    "label": 0
                },
                {
                    "sent": "And his little booklet that I'll give you the code for.",
                    "label": 0
                },
                {
                    "sent": "Free videos.",
                    "label": 0
                },
                {
                    "sent": "And here is it getting automatically augmented with Wikipedia topics.",
                    "label": 0
                },
                {
                    "sent": "So the red links Wikipedia links.",
                    "label": 0
                },
                {
                    "sent": "We've got things like Hungary.",
                    "label": 0
                },
                {
                    "sent": "Budapest International Monetary Fund.",
                    "label": 0
                },
                {
                    "sent": "Is making decisions about what really is central to the topic and what isn't such as Gucci is not linked 'cause it's not really important.",
                    "label": 0
                },
                {
                    "sent": "And it's also doing disambiguations so.",
                    "label": 0
                },
                {
                    "sent": "I am if it's linking to International Monetary Fund whereas there are lots of different destinations where it could possibly have linked to.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "Just to show you it is making different decisions about what to link depending on the context.",
                    "label": 0
                },
                {
                    "sent": "Here's a very important blog about handbags.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "Here's a wikified version of it, and it is actually linking to Gucci.",
                    "label": 0
                },
                {
                    "sent": "Hannah.",
                    "label": 0
                },
                {
                    "sent": "This is a link where you can get the booklet OK.",
                    "label": 0
                },
                {
                    "sent": "Very interesting work, any questions?",
                    "label": 0
                },
                {
                    "sent": "So the question you mentioned surgery as being one of the key features, IVR, nice features and only exaggerated everything.",
                    "label": 0
                },
                {
                    "sent": "Since we're moving this artificially problem early, super early and they came in sections at the moment making if many people need to this and then only they need to replace that.",
                    "label": 0
                },
                {
                    "sent": "Many people have linked to so much easier to insert a link to globalization if the work is already present.",
                    "label": 0
                },
                {
                    "sent": "Something else so that might skew your results.",
                    "label": 0
                },
                {
                    "sent": "Sure this is.",
                    "label": 0
                },
                {
                    "sent": "That's something that you would not expect.",
                    "label": 0
                },
                {
                    "sent": "It wouldn't come up in the week Ification the Wikipedia based evaluation where we are comparing it to things that were actually linked.",
                    "label": 0
                },
                {
                    "sent": "And we're not, but there's something that would come up in a human evaluation where people would think this should be linked.",
                    "label": 0
                },
                {
                    "sent": "We had Mechanical Turk users pour over these documents and actually say should this be like there?",
                    "label": 0
                },
                {
                    "sent": "Shouldn't it be?",
                    "label": 0
                },
                {
                    "sent": "And we didn't find too many examples of that.",
                    "label": 0
                },
                {
                    "sent": "I was getting the same results so but that is a good point maybe.",
                    "label": 0
                },
                {
                    "sent": "Another application for this would be suggesting links that people thought they missed and documents and would be interesting to see.",
                    "label": 0
                },
                {
                    "sent": "In this case, is it working well or not?",
                    "label": 0
                },
                {
                    "sent": "Or is it just predicting the same stuff that was already there?",
                    "label": 0
                },
                {
                    "sent": "Follow up question.",
                    "label": 0
                },
                {
                    "sent": "Kind figuration the mechanical chemical code.",
                    "label": 0
                },
                {
                    "sent": "Human results very similar.",
                    "label": 0
                },
                {
                    "sent": "Feel my cleanse with the with the errors in the same also or like was there much agreement between the Wikipedia.",
                    "label": 0
                },
                {
                    "sent": "Ground truth and the account owner correctly OK.",
                    "label": 0
                },
                {
                    "sent": "So in this case we have no Wikipedia ground truth because they wouldn't Wikipedia articles they were looking at.",
                    "label": 0
                },
                {
                    "sent": "But I don't have time to describe how the human evaluation works, but a limitation of it is that we started off by giving the people the wikified documents, and then they tell us.",
                    "label": 0
                },
                {
                    "sent": "Precision is they tell us which links were wrong and recall is they tell us which links were missing, so that gets rid of a lot of the.",
                    "label": 0
                },
                {
                    "sent": "The people weren't creating the ground truth directly.",
                    "label": 0
                },
                {
                    "sent": "In your conversation over.",
                    "label": 0
                },
                {
                    "sent": "Basically, compute the programmers probability of multiple terms.",
                    "label": 0
                },
                {
                    "sent": "Instead of looking at the computer turns right and now is the carpet.",
                    "label": 0
                },
                {
                    "sent": "I mean if you have the diving computer, all possible combination of returns to come up with the what is the best combination in combination with too expensive?",
                    "label": 0
                },
                {
                    "sent": "Do you have any efficient to overcome?",
                    "label": 0
                },
                {
                    "sent": "Boyd complication exporting.",
                    "label": 0
                },
                {
                    "sent": "For that I mean you may be OK because Wikipedia currently have or we will continue that.",
                    "label": 0
                },
                {
                    "sent": "William is also so that next month you want your competition accomplish your bounded by the number, but in general, but I think the overall population and the complexity is too high in activities that way, so I was wondering how we compete with their ridiculous I mean enjoying retiring.",
                    "label": 0
                },
                {
                    "sent": "This is correct by computational reasoning.",
                    "label": 0
                },
                {
                    "sent": "Do something operation it's.",
                    "label": 0
                },
                {
                    "sent": "I'm not quite sure what you mean, so to calculate the relatedness of two Wikipedia concepts, it's very, very fast.",
                    "label": 0
                },
                {
                    "sent": "It happens about 11,000 times a second.",
                    "label": 0
                },
                {
                    "sent": "Call the corresponding probability for 2003 times combination at all kinds of.",
                    "label": 0
                },
                {
                    "sent": "What is your learning algorithm to to get you out in the optimal solution to come up with the optimum?",
                    "label": 0
                },
                {
                    "sent": "Complication alkama manner instead of tonight.",
                    "label": 0
                },
                {
                    "sent": "Trying all possible combinations.",
                    "label": 0
                },
                {
                    "sent": "At the moment it does try all possible combinations because it's cheap enough to do that.",
                    "label": 0
                },
                {
                    "sent": "As I said, they can calculate the relatedness between two Wikipedia concepts 11,000 times every second.",
                    "label": 0
                },
                {
                    "sent": "There's not quite bounded in our documents of how many concepts we can have, so it's not really that many.",
                    "label": 0
                },
                {
                    "sent": "Yeah, it's another thing that we needed to optimize, we felt.",
                    "label": 0
                },
                {
                    "sent": "OK, the last price trend.",
                    "label": 0
                },
                {
                    "sent": "I think which is asking can you make it more stringent so that you don't have 100 in a very short article?",
                    "label": 0
                },
                {
                    "sent": "I'm sorry I didn't didn't follow.",
                    "label": 0
                },
                {
                    "sent": "So that it's not collecting so many.",
                    "label": 0
                },
                {
                    "sent": "Well, the initial threshold of how the prior probability of the link we can adjust that, inflate that up and down to easily cut out the less and less and less likely candidates.",
                    "label": 0
                },
                {
                    "sent": "And that is obviously a sacrificing recall for speed and precision, and so the paper has a graph that compares what happens when we do that.",
                    "label": 0
                },
                {
                    "sent": "Only other ways to do it as well.",
                    "label": 0
                },
                {
                    "sent": "I haven't really thought of it.",
                    "label": 0
                },
                {
                    "sent": "OK, I think the work is very interesting, so your guys may still have some question you can discuss offline and like thanks to all the speakers.",
                    "label": 0
                }
            ]
        }
    }
}