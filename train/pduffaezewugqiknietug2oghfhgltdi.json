{
    "id": "pduffaezewugqiknietug2oghfhgltdi",
    "title": "Sliding Shapes for 3D Object Detection in Depth Images",
    "info": {
        "author": [
            "Shuran Song, Department of Computer Science, Princeton University"
        ],
        "published": "Oct. 29, 2014",
        "recorded": "September 2014",
        "category": [
            "Top->Computer Science->Computer Vision"
        ]
    },
    "url": "http://videolectures.net/eccv2014_song_depth_images/",
    "segmentation": [
        [
            "Hello I'm Sean from Princeton University.",
            "It is a joint work with my PhD advisor, professors and himself and today I'm going to talk about sliding shapes, a 3D object detector in depth images."
        ],
        [
            "Object detection is one of the most fundamental problem in conservation.",
            "The task is like given events like this.",
            "For example, we want the computer to recognize objects and categories automatically.",
            "So in this."
        ],
        [
            "This is me and my little cat."
        ],
        [
            "And over the past decades, our committee has achieved great progress on object detection, especially the current state of the art, which use amazing deep learning, which is as considered as one of the top 10 greatest breakthrough in science.",
            "So just to see."
        ],
        [
            "How far we are from solving this problem?",
            "Let's do a little experiment which I called and why you algorithm on your data set.",
            "We will take the stage of the algorithm overfit from Professor Yukun and test it on the popular in value data set from Professor Rob Focus Group and see how well it performs of the shell."
        ],
        [
            "So here is the input image.",
            "You can see inside the bounding box is clearly a chair and if we feed this image Patch to the overfeed algorithm and here is the five most likely categories that algorithm predict.",
            "So you can see the algorithms many managed to find some shoes on the dining table."
        ],
        [
            "Let's try another one.",
            "This time this chair is recognized as a part as well.",
            "Well, it is not too bad.",
            "At least the dogs, and make it correct that both of them can rotate."
        ],
        [
            "So let's have another try.",
            "Well, this time this chair is recognized as a special type of dog.",
            "So please tell me what is really wrong here as well."
        ],
        [
            "No, most of these algorithms are trained on Imagenet.",
            "However, 40 years ago Imagenet author, Jedox, advisers, advisers, advisers adviser, has already told us that this type of techniques we are not going to work for three dimensional analysis for many reasons.",
            "For example, large variations will point difference illumination.",
            "Clutter like my roommates room an occlusion caused by this little cute dog and all these problems make object detection really, really difficult.",
            "And as we know all the steep learning godfather such as young as you are really super genius and Professor Hinton even figure out how the brain works for many, many times and even they cannot figure out how to solve this problem.",
            "How a poor PhD student like myself can do anything.",
            "So probably instead of thinking about only algorithm, we can sort of think about another type of input.",
            "So."
        ],
        [
            "The depth sensor can help.",
            "As we know, people care a lot more about playing games compared to going to the Moon or something.",
            "Cancer and driven by this market companies designs a lot of local city sensors such as Microsoft Kinect.",
            "And this type of city sensor."
        ],
        [
            "Enables a lot of breakthroughs in computation tasks.",
            "For example, the city reconstruction user confusion.",
            "Intrinsic image influence and the popular human pose estimation which enable you to cut food.",
            "Use your body.",
            "So today I'm."
        ],
        [
            "Going to introduce sliding shapes authority object detector in depth images.",
            "The input of our system will be a single connect depth map and the output will be a set of 3D bounding boxes with object labels.",
            "Bye."
        ],
        [
            "Using depth or detector cancer."
        ],
        [
            "Definitely outperforms the current state of sales.",
            "Are algorithms based on color image and achieve about 1.7 improvements on the average precision so."
        ],
        [
            "Now I'm going to talk about the algorithm 1st and then I will provide some analysis about why this album can work."
        ],
        [
            "So given an object category, for example, chair.",
            "In this case, we will first collect a set of 3D CAD models from the Internet.",
            "And for each of the."
        ],
        [
            "3D CAD model.",
            "We will render the depth map from different viewpoints.",
            "Just like this, we continue this until we cover all the typical viewpoints of an object.",
            "And for each."
        ],
        [
            "Render depth map.",
            "We will project through 3D print out and compute some features on the 3D.",
            "Print out and uses as the only positive example and come up with a negative datas from labeled Connect depth map.",
            "We will train a linear example SVM with highlights for mining.",
            "So now."
        ],
        [
            "I'm going to talk about how we actually compute features in 3D.",
            "If you still remember the two decades, like the hug, we cut the image into cells and we compute features for each cell and kind it to 1 feature vector which cause running to the S1 weight and similarly in 3D, we cut the 3D space into 3D cells and compute features for each 3D cell and concluded the feature to 1 feature vector and use the SVM to learn the weight.",
            "And."
        ],
        [
            "In order to capture the 3D shape information we designed for type of features like the point cloud, density, surface, normal surface shape, and truncating scientists and function, and we commend this full type of features as our final feature vector and use it to train our SVM."
        ],
        [
            "Another enticing or will slide a window in 3D to evaluate the score for each window, and use the example.",
            "Use the training examples VMS and we use the physical size of a typical chair to set the size of our sliding window so that we don't need to do the multiscale scanning like in two decades.",
            "So for each location, all the example as well will tell whether it is a chair or not.",
            "If all of them say no, then it's probably."
        ],
        [
            "The chair."
        ],
        [
            "And we continue to do."
        ],
        [
            "This until we cover all the 3D space."
        ],
        [
            "An if some of the examples we say yes, so it is probably a chair."
        ],
        [
            "And sometimes multiple detector get fair at the same location.",
            "Then we use non maximum suppression to get the final detection score."
        ],
        [
            "Here is the final detection result with the corresponding example we used."
        ],
        [
            "Here is another result.",
            "On the left is the color and depth image and on the right is sprinkled with the city models.",
            "We our system only use depth as input and color is only for visualization visualization and you can see that in this case we use a folding chair to detect a non folding chair with which demonstrates the ability to generalize of our model."
        ],
        [
            "Here is another example is a bedroom with a bed and chair detected?"
        ],
        [
            "Here is another one.",
            "You can see that the chair on the right it is correctly detected, but actually with the wrong orientation."
        ],
        [
            "We've added over albums on the popular online your data set of the following categories and chair, toilet, Bed, sofa and Table and across different categories or city detectors significantly outperforms DPM train on various datasets and our ceiling train on Pascal, you see.",
            "And just to go."
        ],
        [
            "Some intuition while we're better now as show a side by side comparison with our set depth space sliding shapes and the color based DPM you can see in this case both of us get it correct, but our detector can help us with the bounding box."
        ],
        [
            "And in this case the DPM failed to recognize the chair because it's too dark.",
            "However, by using depth we are not.",
            "We are not influenced by the lighting conditions."
        ],
        [
            "And is it in this example, the DPM has a false positive with the wrong size of bounding box.",
            "However, because we use the physical size of a chair to set the size of our sliding window, so we will not make this kind of mistake."
        ],
        [
            "And this example demonstrates that we have.",
            "We can have a better ability to handle the cushion DPM.",
            "You can see DPM fail to recognize this toilet because it's heavily acquitted."
        ],
        [
            "And sometimes the DPM will has the first positive because of the appearance similarity.",
            "So in this case if you look closer at this false positive, you can see it's really looks like a chair without back and seat.",
            "However, if we use the 3D shape information, we are not.",
            "We will not make this kind of mistake."
        ],
        [
            "And here I was going to show some failure case of our sliding shape you has because we only use steps information so sometimes or detector will get confused between the objects with a similar shape.",
            "So in this case a toilet is detected by combining a trash bin and the wall."
        ],
        [
            "And here is another example.",
            "You can see a sofa chair is detected because it has a similar shape with a bathtub."
        ],
        [
            "So now you know about the algorithms and I'm going to give you some more analyzes about why this algorithm can work.",
            "So."
        ],
        [
            "As I told before, all these problems make object detection really really difficult, and now I'm going to come back and see how our algorithm can handle all these problems 1 by 1.",
            "So."
        ],
        [
            "First, the large ship variations.",
            "For example, we have so many different type of chairs in the world and our solution is very simple.",
            "We just use different CG models to handle different type of chair."
        ],
        [
            "And the experiment result shows that with more and more model, edit or performance will keep increasing.",
            "And because we test our algorithms under your data set, which is quite small and also because of our algorithm can kind of generalize.",
            "So after some point the performance will get saturated."
        ],
        [
            "Another problem is the viewpoint difference.",
            "So you can see even with the same chair, it will look very different on different view angle.",
            "So in order to handle."
        ],
        [
            "We just simply render the different the depth."
        ],
        [
            "From the different view angle and we continue to do this until we cover all the typical viewpoints of an object."
        ],
        [
            "And again, the curve tell us that with more and more weapons rendered, the performance will keep increasing."
        ],
        [
            "Another difficulty for object detection is to obtain the invariants of illumination.",
            "As we know, even with the same texture and color of an object, it will look different in different lighting conditions.",
            "So and Furthermore, it is very difficult to obtain the photo.",
            "Realistic rendering of our city model, so also."
        ],
        [
            "That we only use steps without color because the depth is independent from the lighting condition.",
            "So we obtained the invariants by nature, and the similar idea is also used in the Connect Xbox to recommend to recognize the human body in the Connect app map."
        ],
        [
            "And the collector also makes object detection really difficult as we can see during the training we use a clean CG model.",
            "However, doing the testing the objects always surrounded by clutter, for example, a dining chair is always next for dining table.",
            "And in order to handle this problem, we."
        ],
        [
            "Construct a occupation mask which indicate which work cells are actually inside or under surface of the 3D mesh and after this."
        ],
        [
            "We will only use voxels that inside occupation mask to compute features and train the linear SVM.",
            "It is also the reason why we call algorithm sliding shapes because actually we are slide a shape in 3D instead of a simple rectangle window."
        ],
        [
            "And that the experiment result shows that with this occupation mask we are able to address all the clutter issue and enable to improve the performance around 7%."
        ],
        [
            "An occlusion is also a difficulty for object detection.",
            "For example, in this case, the toilet is heavily recruited by by the sink."
        ],
        [
            "And in 2D it is very difficult to handle occlusion because first we don't know which part is included.",
            "However, in 3D, by using the depth information we know that for example in this case is the right part is acquitted and also if we slide a window into the the color will be inside the bounding box which will mislead or confuse the detector.",
            "However, if we use a 3D sliding window, the acutal will be naturally separated from the object we want to detect.",
            "So in this case, the 3D sliding window give give us a lot of benefit."
        ],
        [
            "Last but not least, data is also very critical issue in this product."
        ],
        [
            "As we know, we can open a lot of benefit from by using Kinect depth map, but the depth data itself has many problems.",
            "So first of all, the data set is very small because we cannot really download steps map from the Internet like in like the image.",
            "So the typical RGB data set it has a much smaller size than the typical RGB image datasets such as Pascal and some database.",
            "Another difficulty is that the.",
            "So noise here is some example of depth from the entire data set is some tables and sofa.",
            "You can see that there is a lot of missing data and also the pattern of missing and the sensor noises keep changing from case to case.",
            "So how long?"
        ],
        [
            "Or by using CG city model rendering, we can obtain a large amount of training data with high quality depth map.",
            "But is this synthetic depth map better or worse than the real Connect depth map in order to answer this question, we do the following experiment.",
            "We take all the example SVM trained from the city models and we rank them by their individual AP from high to low."
        ],
        [
            "And we plot the AP curve by adding more and more examples and you can see in this example the performance will keep increasing and we do the same thing for the Kinect depth map.",
            "Here are some examples from the Kinect depth map.",
            "And we plot if you curve again and you can see that the AP the performance is at the beginning is improving.",
            "But after some point it start to decrease it, probably because by adding the examples with very bad deaths actually it hurts performance and it shows that by using the synthetic render depth map we can train a better model."
        ],
        [
            "And apart from the positive data, we can also use the CG rendering to get more negative data is for for training.",
            "For example what we do is that we download the whole room CG models and we delete the chairs if necessary and we render steps map from the typical view of camera viewpoints and camera height and to obtain more negative data for training.",
            "And and the experiment results demonstrate that by combining this larger that has a negative data set, we can obtain a better performance."
        ],
        [
            "So finally, here is a conclusion.",
            "Today I'm introducing another."
        ],
        [
            "Usage of connect apart from cutting foods, which is 3D."
        ],
        [
            "Detection, we propose setting shapes which we invade where we explore the depth information in our data driven fashion to address the major difficulties for object detection.",
            "And although we cannot help you to get a better performance to cut food, but we managed to improve the performance for object detection by a large margin of the state of the art and all the source code and data available online.",
            "Thank you very much.",
            "We have time for a couple questions.",
            "Hello, you said that you collect various viewpoints for an object.",
            "How do you decide when there's enough viewpoints?",
            "Um?",
            "Actually, you can continue to do this, but how we decide is enough is we can see the performance if if the performance will not increase, gets kind of saturated then we will stop to adding more and more examples.",
            "So basically with more viewpoints rendered, the performance will keep increasing, but because of the testing data is.",
            "Add small so it will get saturated after some point.",
            "Question over there.",
            "Frank so so I'm not an expert, but there was a very similar paper at CPR by Aubrey.",
            "So can you say something about the difference between your work and Aubrey at L?",
            "Which one is that thing through detail?",
            "Yes, that's right, OK.",
            "Difference is that they are used the color rendered.",
            "They are not rendered steps, they their training data are still RGB, and they're trying to detect objects still into the image, so I think that's the major difference.",
            "And also the user power base model and we are user rigid template matching.",
            "So since you have a tooth true 3D data from which you can actually compute invariant features, why do you need viewpoint rendered features?",
            "If you have invariant features, very good question, actually is because of the testing data.",
            "Our connects map and also is a single view depth map.",
            "So in order to match the different cross domain of from the complete CG model to a a single view depth map.",
            "So we do the rendering.",
            "Because if you try to match a complete model with like incomplete depth map is kind of difficult.",
            "We don't know like what's supposed to match, so that's the way that we crossed.",
            "We trying to cross the gap of the different domain.",
            "Is that answer your question?",
            "Hey, one last question.",
            "OK, I do have one question.",
            "You mentioned.",
            "The performance will increase with the number of viewpoint with number of models.",
            "I wonder what's the processing time.",
            "I mean when you try to detect object you do a sliding window approach.",
            "I imagine that would be very consuming."
        ],
        [
            "Yeah, actually."
        ],
        [
            "Here is a time complexity and the time you can see you mentioned.",
            "You ask about the testing time actually is around 2 seconds for one example and one image, and actually for the chair we have like 800 examples.",
            "So you can calculate the time is about like one day or several hours for one image to detect a chair, so it's actually not fast at all.",
            "But it about the good part is that the algorithm is naturally parallel paralyzable so that we can run it in different machines.",
            "OK, thank you.",
            "Let's thank speaker more until next."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Hello I'm Sean from Princeton University.",
                    "label": 0
                },
                {
                    "sent": "It is a joint work with my PhD advisor, professors and himself and today I'm going to talk about sliding shapes, a 3D object detector in depth images.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Object detection is one of the most fundamental problem in conservation.",
                    "label": 0
                },
                {
                    "sent": "The task is like given events like this.",
                    "label": 0
                },
                {
                    "sent": "For example, we want the computer to recognize objects and categories automatically.",
                    "label": 0
                },
                {
                    "sent": "So in this.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is me and my little cat.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And over the past decades, our committee has achieved great progress on object detection, especially the current state of the art, which use amazing deep learning, which is as considered as one of the top 10 greatest breakthrough in science.",
                    "label": 0
                },
                {
                    "sent": "So just to see.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "How far we are from solving this problem?",
                    "label": 0
                },
                {
                    "sent": "Let's do a little experiment which I called and why you algorithm on your data set.",
                    "label": 1
                },
                {
                    "sent": "We will take the stage of the algorithm overfit from Professor Yukun and test it on the popular in value data set from Professor Rob Focus Group and see how well it performs of the shell.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So here is the input image.",
                    "label": 0
                },
                {
                    "sent": "You can see inside the bounding box is clearly a chair and if we feed this image Patch to the overfeed algorithm and here is the five most likely categories that algorithm predict.",
                    "label": 1
                },
                {
                    "sent": "So you can see the algorithms many managed to find some shoes on the dining table.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Let's try another one.",
                    "label": 0
                },
                {
                    "sent": "This time this chair is recognized as a part as well.",
                    "label": 0
                },
                {
                    "sent": "Well, it is not too bad.",
                    "label": 0
                },
                {
                    "sent": "At least the dogs, and make it correct that both of them can rotate.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So let's have another try.",
                    "label": 0
                },
                {
                    "sent": "Well, this time this chair is recognized as a special type of dog.",
                    "label": 0
                },
                {
                    "sent": "So please tell me what is really wrong here as well.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "No, most of these algorithms are trained on Imagenet.",
                    "label": 0
                },
                {
                    "sent": "However, 40 years ago Imagenet author, Jedox, advisers, advisers, advisers adviser, has already told us that this type of techniques we are not going to work for three dimensional analysis for many reasons.",
                    "label": 1
                },
                {
                    "sent": "For example, large variations will point difference illumination.",
                    "label": 0
                },
                {
                    "sent": "Clutter like my roommates room an occlusion caused by this little cute dog and all these problems make object detection really, really difficult.",
                    "label": 0
                },
                {
                    "sent": "And as we know all the steep learning godfather such as young as you are really super genius and Professor Hinton even figure out how the brain works for many, many times and even they cannot figure out how to solve this problem.",
                    "label": 0
                },
                {
                    "sent": "How a poor PhD student like myself can do anything.",
                    "label": 0
                },
                {
                    "sent": "So probably instead of thinking about only algorithm, we can sort of think about another type of input.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The depth sensor can help.",
                    "label": 1
                },
                {
                    "sent": "As we know, people care a lot more about playing games compared to going to the Moon or something.",
                    "label": 1
                },
                {
                    "sent": "Cancer and driven by this market companies designs a lot of local city sensors such as Microsoft Kinect.",
                    "label": 0
                },
                {
                    "sent": "And this type of city sensor.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Enables a lot of breakthroughs in computation tasks.",
                    "label": 0
                },
                {
                    "sent": "For example, the city reconstruction user confusion.",
                    "label": 0
                },
                {
                    "sent": "Intrinsic image influence and the popular human pose estimation which enable you to cut food.",
                    "label": 1
                },
                {
                    "sent": "Use your body.",
                    "label": 0
                },
                {
                    "sent": "So today I'm.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Going to introduce sliding shapes authority object detector in depth images.",
                    "label": 0
                },
                {
                    "sent": "The input of our system will be a single connect depth map and the output will be a set of 3D bounding boxes with object labels.",
                    "label": 1
                },
                {
                    "sent": "Bye.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Using depth or detector cancer.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Definitely outperforms the current state of sales.",
                    "label": 0
                },
                {
                    "sent": "Are algorithms based on color image and achieve about 1.7 improvements on the average precision so.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now I'm going to talk about the algorithm 1st and then I will provide some analysis about why this album can work.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So given an object category, for example, chair.",
                    "label": 0
                },
                {
                    "sent": "In this case, we will first collect a set of 3D CAD models from the Internet.",
                    "label": 0
                },
                {
                    "sent": "And for each of the.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "3D CAD model.",
                    "label": 0
                },
                {
                    "sent": "We will render the depth map from different viewpoints.",
                    "label": 0
                },
                {
                    "sent": "Just like this, we continue this until we cover all the typical viewpoints of an object.",
                    "label": 0
                },
                {
                    "sent": "And for each.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Render depth map.",
                    "label": 0
                },
                {
                    "sent": "We will project through 3D print out and compute some features on the 3D.",
                    "label": 0
                },
                {
                    "sent": "Print out and uses as the only positive example and come up with a negative datas from labeled Connect depth map.",
                    "label": 0
                },
                {
                    "sent": "We will train a linear example SVM with highlights for mining.",
                    "label": 0
                },
                {
                    "sent": "So now.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I'm going to talk about how we actually compute features in 3D.",
                    "label": 0
                },
                {
                    "sent": "If you still remember the two decades, like the hug, we cut the image into cells and we compute features for each cell and kind it to 1 feature vector which cause running to the S1 weight and similarly in 3D, we cut the 3D space into 3D cells and compute features for each 3D cell and concluded the feature to 1 feature vector and use the SVM to learn the weight.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In order to capture the 3D shape information we designed for type of features like the point cloud, density, surface, normal surface shape, and truncating scientists and function, and we commend this full type of features as our final feature vector and use it to train our SVM.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Another enticing or will slide a window in 3D to evaluate the score for each window, and use the example.",
                    "label": 0
                },
                {
                    "sent": "Use the training examples VMS and we use the physical size of a typical chair to set the size of our sliding window so that we don't need to do the multiscale scanning like in two decades.",
                    "label": 0
                },
                {
                    "sent": "So for each location, all the example as well will tell whether it is a chair or not.",
                    "label": 0
                },
                {
                    "sent": "If all of them say no, then it's probably.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The chair.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we continue to do.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This until we cover all the 3D space.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "An if some of the examples we say yes, so it is probably a chair.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And sometimes multiple detector get fair at the same location.",
                    "label": 0
                },
                {
                    "sent": "Then we use non maximum suppression to get the final detection score.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here is the final detection result with the corresponding example we used.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here is another result.",
                    "label": 0
                },
                {
                    "sent": "On the left is the color and depth image and on the right is sprinkled with the city models.",
                    "label": 0
                },
                {
                    "sent": "We our system only use depth as input and color is only for visualization visualization and you can see that in this case we use a folding chair to detect a non folding chair with which demonstrates the ability to generalize of our model.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here is another example is a bedroom with a bed and chair detected?",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here is another one.",
                    "label": 0
                },
                {
                    "sent": "You can see that the chair on the right it is correctly detected, but actually with the wrong orientation.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We've added over albums on the popular online your data set of the following categories and chair, toilet, Bed, sofa and Table and across different categories or city detectors significantly outperforms DPM train on various datasets and our ceiling train on Pascal, you see.",
                    "label": 0
                },
                {
                    "sent": "And just to go.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Some intuition while we're better now as show a side by side comparison with our set depth space sliding shapes and the color based DPM you can see in this case both of us get it correct, but our detector can help us with the bounding box.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And in this case the DPM failed to recognize the chair because it's too dark.",
                    "label": 0
                },
                {
                    "sent": "However, by using depth we are not.",
                    "label": 0
                },
                {
                    "sent": "We are not influenced by the lighting conditions.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And is it in this example, the DPM has a false positive with the wrong size of bounding box.",
                    "label": 0
                },
                {
                    "sent": "However, because we use the physical size of a chair to set the size of our sliding window, so we will not make this kind of mistake.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And this example demonstrates that we have.",
                    "label": 0
                },
                {
                    "sent": "We can have a better ability to handle the cushion DPM.",
                    "label": 0
                },
                {
                    "sent": "You can see DPM fail to recognize this toilet because it's heavily acquitted.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And sometimes the DPM will has the first positive because of the appearance similarity.",
                    "label": 0
                },
                {
                    "sent": "So in this case if you look closer at this false positive, you can see it's really looks like a chair without back and seat.",
                    "label": 0
                },
                {
                    "sent": "However, if we use the 3D shape information, we are not.",
                    "label": 0
                },
                {
                    "sent": "We will not make this kind of mistake.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And here I was going to show some failure case of our sliding shape you has because we only use steps information so sometimes or detector will get confused between the objects with a similar shape.",
                    "label": 0
                },
                {
                    "sent": "So in this case a toilet is detected by combining a trash bin and the wall.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And here is another example.",
                    "label": 0
                },
                {
                    "sent": "You can see a sofa chair is detected because it has a similar shape with a bathtub.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So now you know about the algorithms and I'm going to give you some more analyzes about why this algorithm can work.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "As I told before, all these problems make object detection really really difficult, and now I'm going to come back and see how our algorithm can handle all these problems 1 by 1.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "First, the large ship variations.",
                    "label": 0
                },
                {
                    "sent": "For example, we have so many different type of chairs in the world and our solution is very simple.",
                    "label": 0
                },
                {
                    "sent": "We just use different CG models to handle different type of chair.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And the experiment result shows that with more and more model, edit or performance will keep increasing.",
                    "label": 0
                },
                {
                    "sent": "And because we test our algorithms under your data set, which is quite small and also because of our algorithm can kind of generalize.",
                    "label": 0
                },
                {
                    "sent": "So after some point the performance will get saturated.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Another problem is the viewpoint difference.",
                    "label": 0
                },
                {
                    "sent": "So you can see even with the same chair, it will look very different on different view angle.",
                    "label": 0
                },
                {
                    "sent": "So in order to handle.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We just simply render the different the depth.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "From the different view angle and we continue to do this until we cover all the typical viewpoints of an object.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And again, the curve tell us that with more and more weapons rendered, the performance will keep increasing.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Another difficulty for object detection is to obtain the invariants of illumination.",
                    "label": 0
                },
                {
                    "sent": "As we know, even with the same texture and color of an object, it will look different in different lighting conditions.",
                    "label": 0
                },
                {
                    "sent": "So and Furthermore, it is very difficult to obtain the photo.",
                    "label": 0
                },
                {
                    "sent": "Realistic rendering of our city model, so also.",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That we only use steps without color because the depth is independent from the lighting condition.",
                    "label": 0
                },
                {
                    "sent": "So we obtained the invariants by nature, and the similar idea is also used in the Connect Xbox to recommend to recognize the human body in the Connect app map.",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And the collector also makes object detection really difficult as we can see during the training we use a clean CG model.",
                    "label": 0
                },
                {
                    "sent": "However, doing the testing the objects always surrounded by clutter, for example, a dining chair is always next for dining table.",
                    "label": 0
                },
                {
                    "sent": "And in order to handle this problem, we.",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Construct a occupation mask which indicate which work cells are actually inside or under surface of the 3D mesh and after this.",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We will only use voxels that inside occupation mask to compute features and train the linear SVM.",
                    "label": 0
                },
                {
                    "sent": "It is also the reason why we call algorithm sliding shapes because actually we are slide a shape in 3D instead of a simple rectangle window.",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And that the experiment result shows that with this occupation mask we are able to address all the clutter issue and enable to improve the performance around 7%.",
                    "label": 0
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "An occlusion is also a difficulty for object detection.",
                    "label": 0
                },
                {
                    "sent": "For example, in this case, the toilet is heavily recruited by by the sink.",
                    "label": 0
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And in 2D it is very difficult to handle occlusion because first we don't know which part is included.",
                    "label": 0
                },
                {
                    "sent": "However, in 3D, by using the depth information we know that for example in this case is the right part is acquitted and also if we slide a window into the the color will be inside the bounding box which will mislead or confuse the detector.",
                    "label": 0
                },
                {
                    "sent": "However, if we use a 3D sliding window, the acutal will be naturally separated from the object we want to detect.",
                    "label": 0
                },
                {
                    "sent": "So in this case, the 3D sliding window give give us a lot of benefit.",
                    "label": 0
                }
            ]
        },
        "clip_55": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Last but not least, data is also very critical issue in this product.",
                    "label": 0
                }
            ]
        },
        "clip_56": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "As we know, we can open a lot of benefit from by using Kinect depth map, but the depth data itself has many problems.",
                    "label": 0
                },
                {
                    "sent": "So first of all, the data set is very small because we cannot really download steps map from the Internet like in like the image.",
                    "label": 0
                },
                {
                    "sent": "So the typical RGB data set it has a much smaller size than the typical RGB image datasets such as Pascal and some database.",
                    "label": 0
                },
                {
                    "sent": "Another difficulty is that the.",
                    "label": 0
                },
                {
                    "sent": "So noise here is some example of depth from the entire data set is some tables and sofa.",
                    "label": 0
                },
                {
                    "sent": "You can see that there is a lot of missing data and also the pattern of missing and the sensor noises keep changing from case to case.",
                    "label": 0
                },
                {
                    "sent": "So how long?",
                    "label": 0
                }
            ]
        },
        "clip_57": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Or by using CG city model rendering, we can obtain a large amount of training data with high quality depth map.",
                    "label": 1
                },
                {
                    "sent": "But is this synthetic depth map better or worse than the real Connect depth map in order to answer this question, we do the following experiment.",
                    "label": 1
                },
                {
                    "sent": "We take all the example SVM trained from the city models and we rank them by their individual AP from high to low.",
                    "label": 0
                }
            ]
        },
        "clip_58": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we plot the AP curve by adding more and more examples and you can see in this example the performance will keep increasing and we do the same thing for the Kinect depth map.",
                    "label": 0
                },
                {
                    "sent": "Here are some examples from the Kinect depth map.",
                    "label": 0
                },
                {
                    "sent": "And we plot if you curve again and you can see that the AP the performance is at the beginning is improving.",
                    "label": 0
                },
                {
                    "sent": "But after some point it start to decrease it, probably because by adding the examples with very bad deaths actually it hurts performance and it shows that by using the synthetic render depth map we can train a better model.",
                    "label": 0
                }
            ]
        },
        "clip_59": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And apart from the positive data, we can also use the CG rendering to get more negative data is for for training.",
                    "label": 0
                },
                {
                    "sent": "For example what we do is that we download the whole room CG models and we delete the chairs if necessary and we render steps map from the typical view of camera viewpoints and camera height and to obtain more negative data for training.",
                    "label": 0
                },
                {
                    "sent": "And and the experiment results demonstrate that by combining this larger that has a negative data set, we can obtain a better performance.",
                    "label": 0
                }
            ]
        },
        "clip_60": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So finally, here is a conclusion.",
                    "label": 0
                },
                {
                    "sent": "Today I'm introducing another.",
                    "label": 0
                }
            ]
        },
        "clip_61": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Usage of connect apart from cutting foods, which is 3D.",
                    "label": 0
                }
            ]
        },
        "clip_62": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Detection, we propose setting shapes which we invade where we explore the depth information in our data driven fashion to address the major difficulties for object detection.",
                    "label": 0
                },
                {
                    "sent": "And although we cannot help you to get a better performance to cut food, but we managed to improve the performance for object detection by a large margin of the state of the art and all the source code and data available online.",
                    "label": 0
                },
                {
                    "sent": "Thank you very much.",
                    "label": 0
                },
                {
                    "sent": "We have time for a couple questions.",
                    "label": 0
                },
                {
                    "sent": "Hello, you said that you collect various viewpoints for an object.",
                    "label": 0
                },
                {
                    "sent": "How do you decide when there's enough viewpoints?",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Actually, you can continue to do this, but how we decide is enough is we can see the performance if if the performance will not increase, gets kind of saturated then we will stop to adding more and more examples.",
                    "label": 0
                },
                {
                    "sent": "So basically with more viewpoints rendered, the performance will keep increasing, but because of the testing data is.",
                    "label": 0
                },
                {
                    "sent": "Add small so it will get saturated after some point.",
                    "label": 0
                },
                {
                    "sent": "Question over there.",
                    "label": 0
                },
                {
                    "sent": "Frank so so I'm not an expert, but there was a very similar paper at CPR by Aubrey.",
                    "label": 0
                },
                {
                    "sent": "So can you say something about the difference between your work and Aubrey at L?",
                    "label": 0
                },
                {
                    "sent": "Which one is that thing through detail?",
                    "label": 0
                },
                {
                    "sent": "Yes, that's right, OK.",
                    "label": 0
                },
                {
                    "sent": "Difference is that they are used the color rendered.",
                    "label": 0
                },
                {
                    "sent": "They are not rendered steps, they their training data are still RGB, and they're trying to detect objects still into the image, so I think that's the major difference.",
                    "label": 0
                },
                {
                    "sent": "And also the user power base model and we are user rigid template matching.",
                    "label": 0
                },
                {
                    "sent": "So since you have a tooth true 3D data from which you can actually compute invariant features, why do you need viewpoint rendered features?",
                    "label": 0
                },
                {
                    "sent": "If you have invariant features, very good question, actually is because of the testing data.",
                    "label": 0
                },
                {
                    "sent": "Our connects map and also is a single view depth map.",
                    "label": 0
                },
                {
                    "sent": "So in order to match the different cross domain of from the complete CG model to a a single view depth map.",
                    "label": 1
                },
                {
                    "sent": "So we do the rendering.",
                    "label": 0
                },
                {
                    "sent": "Because if you try to match a complete model with like incomplete depth map is kind of difficult.",
                    "label": 1
                },
                {
                    "sent": "We don't know like what's supposed to match, so that's the way that we crossed.",
                    "label": 0
                },
                {
                    "sent": "We trying to cross the gap of the different domain.",
                    "label": 0
                },
                {
                    "sent": "Is that answer your question?",
                    "label": 0
                },
                {
                    "sent": "Hey, one last question.",
                    "label": 0
                },
                {
                    "sent": "OK, I do have one question.",
                    "label": 0
                },
                {
                    "sent": "You mentioned.",
                    "label": 0
                },
                {
                    "sent": "The performance will increase with the number of viewpoint with number of models.",
                    "label": 0
                },
                {
                    "sent": "I wonder what's the processing time.",
                    "label": 0
                },
                {
                    "sent": "I mean when you try to detect object you do a sliding window approach.",
                    "label": 0
                },
                {
                    "sent": "I imagine that would be very consuming.",
                    "label": 0
                }
            ]
        },
        "clip_63": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Yeah, actually.",
                    "label": 0
                }
            ]
        },
        "clip_64": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here is a time complexity and the time you can see you mentioned.",
                    "label": 0
                },
                {
                    "sent": "You ask about the testing time actually is around 2 seconds for one example and one image, and actually for the chair we have like 800 examples.",
                    "label": 0
                },
                {
                    "sent": "So you can calculate the time is about like one day or several hours for one image to detect a chair, so it's actually not fast at all.",
                    "label": 0
                },
                {
                    "sent": "But it about the good part is that the algorithm is naturally parallel paralyzable so that we can run it in different machines.",
                    "label": 0
                },
                {
                    "sent": "OK, thank you.",
                    "label": 0
                },
                {
                    "sent": "Let's thank speaker more until next.",
                    "label": 0
                }
            ]
        }
    }
}