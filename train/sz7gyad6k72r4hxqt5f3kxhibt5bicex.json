{
    "id": "sz7gyad6k72r4hxqt5f3kxhibt5bicex",
    "title": "Empirical models of spiking in neural populations",
    "info": {
        "author": [
            "Lars Buesing, Gatsby Computational Neuroscience Unit, University College London"
        ],
        "published": "Jan. 25, 2012",
        "recorded": "December 2011",
        "category": [
            "Top->Biology->Neuroscience",
            "Top->Computer Science->Machine Learning"
        ]
    },
    "url": "http://videolectures.net/nips2011_buesing_neural/",
    "segmentation": [
        [
            "Unfortunately I couldn't make it to the conference, and so today it's my pleasure to talk about our joint work and let me start off by stating the pretty obvious fact that an important goal, the major goal of neuroscience researchers.",
            "Of course, to determine to characterize neural function."
        ],
        [
            "And historically, since the pioneering days, this has been this characterizing new function has been based on recording techniques that very often recorded from single electrodes from single neurons at a time.",
            "Basically, for example, using single electrode techniques as depicted here in this picture, and experimentalists then kind of systematically varied math mental conditions.",
            "For example, the orientation of a visual stimulus and measured the response of neurons.",
            "For example, in visual cortex.",
            "As a function of this stimulus, and they recorded many trials for a given stimulus and then averaged many of these responses, and as so, pretty much of what we know about the neural function in the brain today comes from experience like this and for example, the discovery of.",
            "Of orientation, tuning and some cells in the visual system.",
            "But this of course can't give you the whole picture, because presumably your information processing is a distributed process in which many neurons take part simultaneously and fortunate."
        ],
        [
            "We do to progress in experimental techniques.",
            "It's now possible to record simultaneously from many up to hundreds of neurons at the same time.",
            "For example, using techniques like multielectrode arrays instead of a single electrode as appear, and these recording devices give You Beautiful data for that are often depicted in terms of spike raster plots as shown here, where time is on the 1 axis and the neuron index is the other axis.",
            "And of course, you might analyze this kind of data.",
            "Pretty much in the same way it has been traditionally done of single neuron recordings.",
            "Basically, by just averaging over many trials, but presumably you would lose a lot of information, namely the information that's encoded in the statistical dependence between different neurons on on a single trial.",
            "And this kind of illustrate illustrates the need for appropriate statistical models in order to leverage this statistical dependence between neurons to further characterize neural function that's distributed in the system and."
        ],
        [
            "Here in this talk I want to investigate statistical models of multi cell recordings and I want to focus on two classes of models that have been that have a long history in neuroscience and have been very successfully applied to datasets and the first class is based on the framework of generalized linear models and their new model single neurons that have for example also take into account and reflective.",
            "And those neurons have our stimulus driven and.",
            "Which apparently is by spatial temporal receptive fields, for example.",
            "But most importantly the point I want to point out here is that statistical dependence between neurons is explicitly modeled via direct couplings between those neurons, and this is intuitively a very good model if you kind of exhaustively measure all the neurons in the system that you're looking at, then this seems to be very close to biological reality, and but, for example in cortex, when you record from cortex, it's impossible.",
            "Of course to measure all.",
            "The effects that are going on inside at a time and therefore it might be interesting to also look at other models whether they can capture these effects better, namely model class that I want to term latent dynamical systems where you account for all the effects that you don't directly observe by simply an aggregate statistical description by introducing latent variables that evolve overtime."
        ],
        [
            "And in this model, statistical dependencies between neurons are introduced not by direct couplings, but away.",
            "Assuming that these neurons are basically projections, are some kind of measurements of some underlying aggregate process that describes based in a certificate sense everything that you don't measure during the time during the."
        ],
        [
            "Apartments and both model cars have been very successfully applied to data and GM's.",
            "For example, have had tremendous success.",
            "For example, in modeling retinal data, and it could be shown that those allow a very good decoding or visual stimuli from retinal recording data.",
            "Much better than assumed that neurons are."
        ],
        [
            "Independent and on the other hand, the second model class instantiation's have been applied to a multielectrode recordings from motor cortex and facilitated single trial single train analysis there and."
        ],
        [
            "So also dynamical system models are nowadays important building blocks for a class of decoders for brain computer interfaces and the question we wanted to address in this study explicitly was what are.",
            "Which of these two model classes gives us a better description of the statistics of Multielectrode recordings from Cortex?",
            "We see very much focusing on the cortex and."
        ],
        [
            "So this compared to comparison between these two model classes that we performed was based on data that came from Krishna Shenoy Slab.",
            "It was obtained by Multi Electrode Array recording from motor and premotor areas from a monkey and the data that we analyzed consisted of 92 dimensions and this is 1 trial of the data.",
            "Just for illustration purposes and in total we analyzed 120 seconds of recordings that we've been to 10 millisecond buildings."
        ],
        [
            "And let me go into a bit more the details of the model, so we compare it.",
            "So the first one is of course it's a very standard GLM that has been described exhaustively in the literature, and we we kind of used one of those.",
            "And in this framework the instantaneous firing rate of a neuron is modeled as a function of some deterministic function that describes a kind of mean response overtime.",
            "But more importantly, it's influenced by the whole spike history of the network, basically.",
            "And this bike history of the network influence in neurons weighted by a kind of coupling matrix that paralyzes the strength of the couplings between these neurons."
        ],
        [
            "And then given this rate, the spikes of a neuron are in a time bin of 10 milliseconds, are modeled as Poss observations given this rate."
        ],
        [
            "And concretely, we parent tries the spike history by using five basis functions that were Model S taking exponentials with time constants of 80 or up to 150 mil."
        ],
        [
            "Seconds and in order to prevent overfitting of these models because the coupling matrix of course grows linearly in the number of neurons that you actually look at, we put in L1 prior or L1 regularization on this matrix, and these are all very well described techniques in the literature."
        ],
        [
            "Yeah, and the second model that we used.",
            "That late dynamical system model basically assumes that there is a latent variable X, which is usually modeled with a large lower dimensionality as the observation dimensionality and we we went for the simplest model that you can possibly come up with linear dynamics in time described by by just a matrix and plus Gaussian."
        ],
        [
            "Innovations with the time varying mean."
        ],
        [
            "And we compared to two different flavors of instantiations of these models that differ in their observation processes, and for the simplest model which we term Gaussian linear dynamical system dles neurons are modeled as Gaussian linear observations of this latent dynamical system.",
            "So it's some real valued random variable, and you can make that a bit more realistic by taking your towns.",
            "The discrete nature of spike counts and bins by.",
            "Assuming a person.",
            "Observation process on one dimensional projections of this dynamical system path to an exponential."
        ],
        [
            "And all the models model parameters that we looked at were estimated by maximum likelihood estimation over map estimation.",
            "If we had a regularizer, and for the person in dynamic system as inference as not energy tractable, we used a Laplace approximation for the pursuit on the PS."
        ],
        [
            "And we compared these different model given the data using a performance measure which I want to turn cross prediction performance measure as it measures are assesses the ability of the model to predict the whole spike train of a single held out neuron given the spike trains of all other neurons more concretely for a given test trial.",
            "For every neuron, we computed the prediction, which is basically just the conditional expectation of this dimension given the other dimensions for on your volumes, and then we computed the mean square error between the prediction of the trajectory and.",
            "Then we average overall neurons and all test trials, and so this is a kind of aggregate measure of how well how well the model describes kind of the joint statistics between neurons, and we do not directly report the mean square error of this.",
            "Prediction measure, but we report the improvement over a constant predictor, so higher is better in the following."
        ],
        [
            "It's.",
            "And this plot compares the performance of the GLM's versus the dynamical system models.",
            "More concretely, the personal assistant model, and here for different GLM instantiation for different coupling or spike history length.",
            "We show the performance of these models on the Y axis here as a function of the regularization parameter.",
            "Basically, this is the whole regularization path of these models in order to avoid comparing the overfitting models basically.",
            "And also plotted here is the performance of a person endemic system with five dimensional latent state and we see that the PLS significantly outperforms GLM's on this data set in terms of the cross prediction performance."
        ],
        [
            "And on the next slide, we also investigated.",
            "Given that we assume the dynamical system model, which are the better observation?",
            "Noise models that perform better in the cross prediction setting, and for that we plotted here the."
        ],
        [
            "Sorry."
        ],
        [
            "The cross prediction performance as a function of the latent dimensionality's of these dynamical systems, and here in red, is the Gaussian observation model versus the POS observation model.",
            "Here in Brown and you see that it's also significantly outperforms the Gaussian observation model.",
            "So you gain something by introducing this more realistic by computation, more demanding observation process for some survey, shun process, and what you can.",
            "Also, we also tried is augmenting the person in dynamic system with a single.",
            "Spike history filter basically which can account for a factory process an this is poverty in blue and you get a little bit of marginal or slight in performance increase from incorporating that effect.",
            "So now we kind of rank the models with respect to their cross prediction performance on this data set.",
            "But we also assess the ability of these models to reproduce unmatched statistics of the data that I usually looked at by experimentalists."
        ],
        [
            "So, and one of the statistics that we investigated in the data and what our models tell about about these statistics was the cross correlation between neurons as a function of the time lag between the neurons.",
            "And this blood shows it for the data.",
            "It's a bit hard to see, but the data is basically the solid line without any markers and for visualization purposes we we split the neural population into four different subclasses, and we averaged the cross correlations between neurons in one subclass.",
            "And so these four different curves correspond to different neurons subgroups, and you can see that the data basically cross correlation in the neurons from the empirical data.",
            "You see that there's a large pronounced peak at zero time.",
            "Lexa neurons tend to be mostly correlated, or when there's no latency between them and you have basically almost exponentially became cross correlation between neurons with broad flanks of roughly 100 millisecond time constants and also played here.",
            "Our predictions from the Lake dynamical system models with Gaussian observations that we process observations in there basically lie on top of the data which says that our models that have been fitted to the data and test data reproduce these statistics quite."
        ],
        [
            "Ridley and we also compare that to the prediction of GLM's and we see that, at least for this building of the data, which is a pretty cause, spinning of 10 milliseconds.",
            "We didn't find the DMS method.",
            "It is is very well, especially given our data preprocessing GLM's couldn't match the central peak at zero time lag which is possibly due to the lack of instantaneous couplings in the GLM model."
        ],
        [
            "And another statistics that we looked at was the frequency of population spike counts.",
            "Basically we define the population spike count as a number of spikes somewhere over the whole population in a single time bin, and this is a history histogram that basically shows the frequency of events as a function of the event size.",
            "So this is an aggregate measure of the whole population activity and the data here in blue and the person dynamic system.",
            "In Red match very well also for this statistics.",
            "Whereas other models that we compare to couldn't match the statistics very well.",
            "And OK, now I tried to convince you that person dynamical systems are kind of relatively accurate, model of multi cell recordings from cortex.",
            "But now we want to put that into a bit more."
        ],
        [
            "Absolute context by asking how much variance do the models?",
            "How how much variance is the person in linear dynamic systems?",
            "Explain on an absolute scale and here we plot the percentage of explained variance by our models in across prediction setting as a function of the bin size and we see that for small time bins that we usually use in all other experiments are models.",
            "Basically roughly explained 5 to 10%.",
            "Of the variance in the data, which doesn't seem to be very much, but if you assume that urine has some kind of private variability that is not shared across the population.",
            "For example, if you assume that a neuron given its rate samples person spikes given this rate, then you can't expect to explain all the variants of the data, and we can try to put that into the graph by having an approximation of how much variance you can hope to explain given in urine is."
        ],
        [
            "Also, and this is shown here in blue.",
            "And actually, we see that for small bin sizes are models explain more variance than can be expected from a concern assumption on the neurons themselves.",
            "So this kind of illustrates that.",
            "Also in absolute scale we do not have terribly bad job."
        ],
        [
            "These models.",
            "And on the last figure, we compared the amount of explained variance of the personal system model.",
            "The amount of variance that can be simply explained by assume that the neurons are independent and that have a time varying PSCH.",
            "And here we plot the fraction of the ratio of the explained variance of our model over the variance.",
            "That explains why appears the age predictor as a function of the bin size, and we see that as long as you choose the latent dimensionality of the porcelain enamel system to be high enough, basically larger than five, or something like that, then you can roughly explain twice as much variance in the data then by simply assuming that neurons are independent given the PCH."
        ],
        [
            "So let me briefly conclude my talk, so using Multielectrode recordings from Cortex based on those data I showed that dynamic assistant models outperform GLM's in this setup in terms of cross prediction measures and in terms of matching different statistics of the data, such as the cross coral."
        ],
        [
            "Social structure and we hypothesize that this might be due to the mismatch of GLM modelling assumptions in this type of data.",
            "Basically, GLM model GLM models assume that statistical dependence mostly comes from stimulus and direct coupling between the neurons.",
            "But this is kind of a might be a bit of a dubious assumption in Multielectrode recordings from Cortex, where you have to assume that you your recording device only has very sparse observations of the whole population.",
            "Even a very local population, and that most inputs to the neurons that you observe actually come from outside the population that you observe, and there's no in these naive GLM models that we investigate if there is no mechanism to account for that and where where there is in dynamical latent systems because you have a latent variable that can MoD."
        ],
        [
            "And yeah, so the take home message should be that for this type of data.",
            "For these type of recordings, later dynamical systems seem to be the more natural modeling choice.",
            "Thank you very much for your attention.",
            "So what actually should be as wide Jonathan?",
            "I guess because I mean there's been this work that he did with petrolatum about extending GLM models with latent with latent neurons, and I was wondering whether you wanted to comment on how you see that in you know in this space of possible approaches to modeling.",
            "So I think if you do that in a technical sound way, then it's definitely probably presumably the better model.",
            "If you account for overfitting and all these other effects by incorporating latent variables into GM's, I can't, because it's A kind of nested model class.",
            "Then it has to be better if you if you regularize the system in a in a proper way, and I think that's probably the way to go forward, but we just wanted to make the point here that if you if you kind of compare these two modeling assumptions, what is more important to take account for in cortex is it does the can you explain most variance by accounting for direct couplings or just just one very low dimensional latent variables?",
            "Something like 4:50 or 10 dimensions?",
            "So quick on.",
            "Have you actually looked at the kind of dynamical systems that you get after fitting what kind of dynamical behavior they so the time constants that the dynamics have roughly on the order of hundreds of milliseconds.",
            "So there there are some concerns that I described by the dynamic system matrix of just a few milliseconds, but there are also long, long time constant.",
            "Those tend to explain most of the variance of the data, so there seems to be some dynamics that you have to account for in order to obtain much variance that is on the order of.",
            "100 millisecond timescale, yeah?",
            "Thanks Lois, I was very nice talk.",
            "I want to ask one question which is.",
            "I wonder if your conclusion is maybe a bit too strong.",
            "You said cortex in general and so specifically this is motor cortex.",
            "I know Liam Pinsky's group is look at latent variable models for retina and have shown that their latent variable models are slightly worse than.",
            "Retina is not cortex montane sorry.",
            "Nobody, presumably in visual cortex, it might be that there is a high dimensional.",
            "Let me say this in retina you find mostly nearest neighbor connectivity, so the the correlations are driven by very local local interactions and Moreover when you fit a latent variable model you get a very high dimension.",
            "The latent dimensionality is the same as the number of neurons you find, so there really is.",
            "I don't know, at least in that case it looks like local connectivity is a better model slightly then this and so I'm wondering if you might if you would concede that it might be the case that in motor cortex we really do have.",
            "A low dimensional latent space and these latent variable models are better, but perhaps in sensory areas there's a high dimensional state space that could be better, better modeled in another way, though definitely looked at everything visual data.",
            "Yeah, I might have formulated by my consequences too strong.",
            "Yeah, that that's true that probably if you go to other areas in cortex for which which are closer to the sensory periphery, and which are more stimulus driven than and you sample more neurons than GL, EMS might definitely be competitive, and the better models, yeah.",
            "That's very true, but just as a footnote to that, in the retina, there recording densely from neighboring ganglion cells, and as you point out, those have direct connections, or there are very close connectivity.",
            "Right now, but if you're sampling in the cortex and what's the spacing between your electrodes is on the order of a column like it's a half a millimeter.",
            "In that case, you're sampling foods that have probably no direct connection whatsoever, and therefore you know you don't expect to find that kind of high dimensionality.",
            "Oh yeah, that's basically very much the conclusion that we came to.",
            "Yeah, that's true.",
            "OK, thank you very much large.",
            "We think our speaker."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Unfortunately I couldn't make it to the conference, and so today it's my pleasure to talk about our joint work and let me start off by stating the pretty obvious fact that an important goal, the major goal of neuroscience researchers.",
                    "label": 0
                },
                {
                    "sent": "Of course, to determine to characterize neural function.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And historically, since the pioneering days, this has been this characterizing new function has been based on recording techniques that very often recorded from single electrodes from single neurons at a time.",
                    "label": 0
                },
                {
                    "sent": "Basically, for example, using single electrode techniques as depicted here in this picture, and experimentalists then kind of systematically varied math mental conditions.",
                    "label": 0
                },
                {
                    "sent": "For example, the orientation of a visual stimulus and measured the response of neurons.",
                    "label": 0
                },
                {
                    "sent": "For example, in visual cortex.",
                    "label": 0
                },
                {
                    "sent": "As a function of this stimulus, and they recorded many trials for a given stimulus and then averaged many of these responses, and as so, pretty much of what we know about the neural function in the brain today comes from experience like this and for example, the discovery of.",
                    "label": 0
                },
                {
                    "sent": "Of orientation, tuning and some cells in the visual system.",
                    "label": 0
                },
                {
                    "sent": "But this of course can't give you the whole picture, because presumably your information processing is a distributed process in which many neurons take part simultaneously and fortunate.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We do to progress in experimental techniques.",
                    "label": 0
                },
                {
                    "sent": "It's now possible to record simultaneously from many up to hundreds of neurons at the same time.",
                    "label": 0
                },
                {
                    "sent": "For example, using techniques like multielectrode arrays instead of a single electrode as appear, and these recording devices give You Beautiful data for that are often depicted in terms of spike raster plots as shown here, where time is on the 1 axis and the neuron index is the other axis.",
                    "label": 0
                },
                {
                    "sent": "And of course, you might analyze this kind of data.",
                    "label": 0
                },
                {
                    "sent": "Pretty much in the same way it has been traditionally done of single neuron recordings.",
                    "label": 1
                },
                {
                    "sent": "Basically, by just averaging over many trials, but presumably you would lose a lot of information, namely the information that's encoded in the statistical dependence between different neurons on on a single trial.",
                    "label": 0
                },
                {
                    "sent": "And this kind of illustrate illustrates the need for appropriate statistical models in order to leverage this statistical dependence between neurons to further characterize neural function that's distributed in the system and.",
                    "label": 1
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Here in this talk I want to investigate statistical models of multi cell recordings and I want to focus on two classes of models that have been that have a long history in neuroscience and have been very successfully applied to datasets and the first class is based on the framework of generalized linear models and their new model single neurons that have for example also take into account and reflective.",
                    "label": 1
                },
                {
                    "sent": "And those neurons have our stimulus driven and.",
                    "label": 0
                },
                {
                    "sent": "Which apparently is by spatial temporal receptive fields, for example.",
                    "label": 0
                },
                {
                    "sent": "But most importantly the point I want to point out here is that statistical dependence between neurons is explicitly modeled via direct couplings between those neurons, and this is intuitively a very good model if you kind of exhaustively measure all the neurons in the system that you're looking at, then this seems to be very close to biological reality, and but, for example in cortex, when you record from cortex, it's impossible.",
                    "label": 0
                },
                {
                    "sent": "Of course to measure all.",
                    "label": 1
                },
                {
                    "sent": "The effects that are going on inside at a time and therefore it might be interesting to also look at other models whether they can capture these effects better, namely model class that I want to term latent dynamical systems where you account for all the effects that you don't directly observe by simply an aggregate statistical description by introducing latent variables that evolve overtime.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And in this model, statistical dependencies between neurons are introduced not by direct couplings, but away.",
                    "label": 0
                },
                {
                    "sent": "Assuming that these neurons are basically projections, are some kind of measurements of some underlying aggregate process that describes based in a certificate sense everything that you don't measure during the time during the.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Apartments and both model cars have been very successfully applied to data and GM's.",
                    "label": 0
                },
                {
                    "sent": "For example, have had tremendous success.",
                    "label": 0
                },
                {
                    "sent": "For example, in modeling retinal data, and it could be shown that those allow a very good decoding or visual stimuli from retinal recording data.",
                    "label": 1
                },
                {
                    "sent": "Much better than assumed that neurons are.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Independent and on the other hand, the second model class instantiation's have been applied to a multielectrode recordings from motor cortex and facilitated single trial single train analysis there and.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So also dynamical system models are nowadays important building blocks for a class of decoders for brain computer interfaces and the question we wanted to address in this study explicitly was what are.",
                    "label": 0
                },
                {
                    "sent": "Which of these two model classes gives us a better description of the statistics of Multielectrode recordings from Cortex?",
                    "label": 0
                },
                {
                    "sent": "We see very much focusing on the cortex and.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this compared to comparison between these two model classes that we performed was based on data that came from Krishna Shenoy Slab.",
                    "label": 0
                },
                {
                    "sent": "It was obtained by Multi Electrode Array recording from motor and premotor areas from a monkey and the data that we analyzed consisted of 92 dimensions and this is 1 trial of the data.",
                    "label": 0
                },
                {
                    "sent": "Just for illustration purposes and in total we analyzed 120 seconds of recordings that we've been to 10 millisecond buildings.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And let me go into a bit more the details of the model, so we compare it.",
                    "label": 0
                },
                {
                    "sent": "So the first one is of course it's a very standard GLM that has been described exhaustively in the literature, and we we kind of used one of those.",
                    "label": 0
                },
                {
                    "sent": "And in this framework the instantaneous firing rate of a neuron is modeled as a function of some deterministic function that describes a kind of mean response overtime.",
                    "label": 1
                },
                {
                    "sent": "But more importantly, it's influenced by the whole spike history of the network, basically.",
                    "label": 0
                },
                {
                    "sent": "And this bike history of the network influence in neurons weighted by a kind of coupling matrix that paralyzes the strength of the couplings between these neurons.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then given this rate, the spikes of a neuron are in a time bin of 10 milliseconds, are modeled as Poss observations given this rate.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And concretely, we parent tries the spike history by using five basis functions that were Model S taking exponentials with time constants of 80 or up to 150 mil.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Seconds and in order to prevent overfitting of these models because the coupling matrix of course grows linearly in the number of neurons that you actually look at, we put in L1 prior or L1 regularization on this matrix, and these are all very well described techniques in the literature.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Yeah, and the second model that we used.",
                    "label": 0
                },
                {
                    "sent": "That late dynamical system model basically assumes that there is a latent variable X, which is usually modeled with a large lower dimensionality as the observation dimensionality and we we went for the simplest model that you can possibly come up with linear dynamics in time described by by just a matrix and plus Gaussian.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Innovations with the time varying mean.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And we compared to two different flavors of instantiations of these models that differ in their observation processes, and for the simplest model which we term Gaussian linear dynamical system dles neurons are modeled as Gaussian linear observations of this latent dynamical system.",
                    "label": 1
                },
                {
                    "sent": "So it's some real valued random variable, and you can make that a bit more realistic by taking your towns.",
                    "label": 0
                },
                {
                    "sent": "The discrete nature of spike counts and bins by.",
                    "label": 0
                },
                {
                    "sent": "Assuming a person.",
                    "label": 0
                },
                {
                    "sent": "Observation process on one dimensional projections of this dynamical system path to an exponential.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And all the models model parameters that we looked at were estimated by maximum likelihood estimation over map estimation.",
                    "label": 0
                },
                {
                    "sent": "If we had a regularizer, and for the person in dynamic system as inference as not energy tractable, we used a Laplace approximation for the pursuit on the PS.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And we compared these different model given the data using a performance measure which I want to turn cross prediction performance measure as it measures are assesses the ability of the model to predict the whole spike train of a single held out neuron given the spike trains of all other neurons more concretely for a given test trial.",
                    "label": 0
                },
                {
                    "sent": "For every neuron, we computed the prediction, which is basically just the conditional expectation of this dimension given the other dimensions for on your volumes, and then we computed the mean square error between the prediction of the trajectory and.",
                    "label": 0
                },
                {
                    "sent": "Then we average overall neurons and all test trials, and so this is a kind of aggregate measure of how well how well the model describes kind of the joint statistics between neurons, and we do not directly report the mean square error of this.",
                    "label": 0
                },
                {
                    "sent": "Prediction measure, but we report the improvement over a constant predictor, so higher is better in the following.",
                    "label": 1
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "It's.",
                    "label": 0
                },
                {
                    "sent": "And this plot compares the performance of the GLM's versus the dynamical system models.",
                    "label": 0
                },
                {
                    "sent": "More concretely, the personal assistant model, and here for different GLM instantiation for different coupling or spike history length.",
                    "label": 0
                },
                {
                    "sent": "We show the performance of these models on the Y axis here as a function of the regularization parameter.",
                    "label": 1
                },
                {
                    "sent": "Basically, this is the whole regularization path of these models in order to avoid comparing the overfitting models basically.",
                    "label": 0
                },
                {
                    "sent": "And also plotted here is the performance of a person endemic system with five dimensional latent state and we see that the PLS significantly outperforms GLM's on this data set in terms of the cross prediction performance.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And on the next slide, we also investigated.",
                    "label": 0
                },
                {
                    "sent": "Given that we assume the dynamical system model, which are the better observation?",
                    "label": 0
                },
                {
                    "sent": "Noise models that perform better in the cross prediction setting, and for that we plotted here the.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Sorry.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The cross prediction performance as a function of the latent dimensionality's of these dynamical systems, and here in red, is the Gaussian observation model versus the POS observation model.",
                    "label": 0
                },
                {
                    "sent": "Here in Brown and you see that it's also significantly outperforms the Gaussian observation model.",
                    "label": 0
                },
                {
                    "sent": "So you gain something by introducing this more realistic by computation, more demanding observation process for some survey, shun process, and what you can.",
                    "label": 0
                },
                {
                    "sent": "Also, we also tried is augmenting the person in dynamic system with a single.",
                    "label": 0
                },
                {
                    "sent": "Spike history filter basically which can account for a factory process an this is poverty in blue and you get a little bit of marginal or slight in performance increase from incorporating that effect.",
                    "label": 0
                },
                {
                    "sent": "So now we kind of rank the models with respect to their cross prediction performance on this data set.",
                    "label": 0
                },
                {
                    "sent": "But we also assess the ability of these models to reproduce unmatched statistics of the data that I usually looked at by experimentalists.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So, and one of the statistics that we investigated in the data and what our models tell about about these statistics was the cross correlation between neurons as a function of the time lag between the neurons.",
                    "label": 1
                },
                {
                    "sent": "And this blood shows it for the data.",
                    "label": 0
                },
                {
                    "sent": "It's a bit hard to see, but the data is basically the solid line without any markers and for visualization purposes we we split the neural population into four different subclasses, and we averaged the cross correlations between neurons in one subclass.",
                    "label": 0
                },
                {
                    "sent": "And so these four different curves correspond to different neurons subgroups, and you can see that the data basically cross correlation in the neurons from the empirical data.",
                    "label": 1
                },
                {
                    "sent": "You see that there's a large pronounced peak at zero time.",
                    "label": 0
                },
                {
                    "sent": "Lexa neurons tend to be mostly correlated, or when there's no latency between them and you have basically almost exponentially became cross correlation between neurons with broad flanks of roughly 100 millisecond time constants and also played here.",
                    "label": 0
                },
                {
                    "sent": "Our predictions from the Lake dynamical system models with Gaussian observations that we process observations in there basically lie on top of the data which says that our models that have been fitted to the data and test data reproduce these statistics quite.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Ridley and we also compare that to the prediction of GLM's and we see that, at least for this building of the data, which is a pretty cause, spinning of 10 milliseconds.",
                    "label": 1
                },
                {
                    "sent": "We didn't find the DMS method.",
                    "label": 0
                },
                {
                    "sent": "It is is very well, especially given our data preprocessing GLM's couldn't match the central peak at zero time lag which is possibly due to the lack of instantaneous couplings in the GLM model.",
                    "label": 1
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And another statistics that we looked at was the frequency of population spike counts.",
                    "label": 1
                },
                {
                    "sent": "Basically we define the population spike count as a number of spikes somewhere over the whole population in a single time bin, and this is a history histogram that basically shows the frequency of events as a function of the event size.",
                    "label": 1
                },
                {
                    "sent": "So this is an aggregate measure of the whole population activity and the data here in blue and the person dynamic system.",
                    "label": 0
                },
                {
                    "sent": "In Red match very well also for this statistics.",
                    "label": 0
                },
                {
                    "sent": "Whereas other models that we compare to couldn't match the statistics very well.",
                    "label": 0
                },
                {
                    "sent": "And OK, now I tried to convince you that person dynamical systems are kind of relatively accurate, model of multi cell recordings from cortex.",
                    "label": 0
                },
                {
                    "sent": "But now we want to put that into a bit more.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Absolute context by asking how much variance do the models?",
                    "label": 1
                },
                {
                    "sent": "How how much variance is the person in linear dynamic systems?",
                    "label": 0
                },
                {
                    "sent": "Explain on an absolute scale and here we plot the percentage of explained variance by our models in across prediction setting as a function of the bin size and we see that for small time bins that we usually use in all other experiments are models.",
                    "label": 1
                },
                {
                    "sent": "Basically roughly explained 5 to 10%.",
                    "label": 0
                },
                {
                    "sent": "Of the variance in the data, which doesn't seem to be very much, but if you assume that urine has some kind of private variability that is not shared across the population.",
                    "label": 0
                },
                {
                    "sent": "For example, if you assume that a neuron given its rate samples person spikes given this rate, then you can't expect to explain all the variants of the data, and we can try to put that into the graph by having an approximation of how much variance you can hope to explain given in urine is.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Also, and this is shown here in blue.",
                    "label": 0
                },
                {
                    "sent": "And actually, we see that for small bin sizes are models explain more variance than can be expected from a concern assumption on the neurons themselves.",
                    "label": 1
                },
                {
                    "sent": "So this kind of illustrates that.",
                    "label": 0
                },
                {
                    "sent": "Also in absolute scale we do not have terribly bad job.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "These models.",
                    "label": 0
                },
                {
                    "sent": "And on the last figure, we compared the amount of explained variance of the personal system model.",
                    "label": 1
                },
                {
                    "sent": "The amount of variance that can be simply explained by assume that the neurons are independent and that have a time varying PSCH.",
                    "label": 0
                },
                {
                    "sent": "And here we plot the fraction of the ratio of the explained variance of our model over the variance.",
                    "label": 0
                },
                {
                    "sent": "That explains why appears the age predictor as a function of the bin size, and we see that as long as you choose the latent dimensionality of the porcelain enamel system to be high enough, basically larger than five, or something like that, then you can roughly explain twice as much variance in the data then by simply assuming that neurons are independent given the PCH.",
                    "label": 1
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So let me briefly conclude my talk, so using Multielectrode recordings from Cortex based on those data I showed that dynamic assistant models outperform GLM's in this setup in terms of cross prediction measures and in terms of matching different statistics of the data, such as the cross coral.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Social structure and we hypothesize that this might be due to the mismatch of GLM modelling assumptions in this type of data.",
                    "label": 1
                },
                {
                    "sent": "Basically, GLM model GLM models assume that statistical dependence mostly comes from stimulus and direct coupling between the neurons.",
                    "label": 0
                },
                {
                    "sent": "But this is kind of a might be a bit of a dubious assumption in Multielectrode recordings from Cortex, where you have to assume that you your recording device only has very sparse observations of the whole population.",
                    "label": 0
                },
                {
                    "sent": "Even a very local population, and that most inputs to the neurons that you observe actually come from outside the population that you observe, and there's no in these naive GLM models that we investigate if there is no mechanism to account for that and where where there is in dynamical latent systems because you have a latent variable that can MoD.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And yeah, so the take home message should be that for this type of data.",
                    "label": 1
                },
                {
                    "sent": "For these type of recordings, later dynamical systems seem to be the more natural modeling choice.",
                    "label": 0
                },
                {
                    "sent": "Thank you very much for your attention.",
                    "label": 0
                },
                {
                    "sent": "So what actually should be as wide Jonathan?",
                    "label": 0
                },
                {
                    "sent": "I guess because I mean there's been this work that he did with petrolatum about extending GLM models with latent with latent neurons, and I was wondering whether you wanted to comment on how you see that in you know in this space of possible approaches to modeling.",
                    "label": 0
                },
                {
                    "sent": "So I think if you do that in a technical sound way, then it's definitely probably presumably the better model.",
                    "label": 0
                },
                {
                    "sent": "If you account for overfitting and all these other effects by incorporating latent variables into GM's, I can't, because it's A kind of nested model class.",
                    "label": 0
                },
                {
                    "sent": "Then it has to be better if you if you regularize the system in a in a proper way, and I think that's probably the way to go forward, but we just wanted to make the point here that if you if you kind of compare these two modeling assumptions, what is more important to take account for in cortex is it does the can you explain most variance by accounting for direct couplings or just just one very low dimensional latent variables?",
                    "label": 0
                },
                {
                    "sent": "Something like 4:50 or 10 dimensions?",
                    "label": 0
                },
                {
                    "sent": "So quick on.",
                    "label": 0
                },
                {
                    "sent": "Have you actually looked at the kind of dynamical systems that you get after fitting what kind of dynamical behavior they so the time constants that the dynamics have roughly on the order of hundreds of milliseconds.",
                    "label": 0
                },
                {
                    "sent": "So there there are some concerns that I described by the dynamic system matrix of just a few milliseconds, but there are also long, long time constant.",
                    "label": 0
                },
                {
                    "sent": "Those tend to explain most of the variance of the data, so there seems to be some dynamics that you have to account for in order to obtain much variance that is on the order of.",
                    "label": 0
                },
                {
                    "sent": "100 millisecond timescale, yeah?",
                    "label": 0
                },
                {
                    "sent": "Thanks Lois, I was very nice talk.",
                    "label": 0
                },
                {
                    "sent": "I want to ask one question which is.",
                    "label": 0
                },
                {
                    "sent": "I wonder if your conclusion is maybe a bit too strong.",
                    "label": 0
                },
                {
                    "sent": "You said cortex in general and so specifically this is motor cortex.",
                    "label": 0
                },
                {
                    "sent": "I know Liam Pinsky's group is look at latent variable models for retina and have shown that their latent variable models are slightly worse than.",
                    "label": 0
                },
                {
                    "sent": "Retina is not cortex montane sorry.",
                    "label": 0
                },
                {
                    "sent": "Nobody, presumably in visual cortex, it might be that there is a high dimensional.",
                    "label": 0
                },
                {
                    "sent": "Let me say this in retina you find mostly nearest neighbor connectivity, so the the correlations are driven by very local local interactions and Moreover when you fit a latent variable model you get a very high dimension.",
                    "label": 0
                },
                {
                    "sent": "The latent dimensionality is the same as the number of neurons you find, so there really is.",
                    "label": 0
                },
                {
                    "sent": "I don't know, at least in that case it looks like local connectivity is a better model slightly then this and so I'm wondering if you might if you would concede that it might be the case that in motor cortex we really do have.",
                    "label": 0
                },
                {
                    "sent": "A low dimensional latent space and these latent variable models are better, but perhaps in sensory areas there's a high dimensional state space that could be better, better modeled in another way, though definitely looked at everything visual data.",
                    "label": 0
                },
                {
                    "sent": "Yeah, I might have formulated by my consequences too strong.",
                    "label": 0
                },
                {
                    "sent": "Yeah, that that's true that probably if you go to other areas in cortex for which which are closer to the sensory periphery, and which are more stimulus driven than and you sample more neurons than GL, EMS might definitely be competitive, and the better models, yeah.",
                    "label": 0
                },
                {
                    "sent": "That's very true, but just as a footnote to that, in the retina, there recording densely from neighboring ganglion cells, and as you point out, those have direct connections, or there are very close connectivity.",
                    "label": 0
                },
                {
                    "sent": "Right now, but if you're sampling in the cortex and what's the spacing between your electrodes is on the order of a column like it's a half a millimeter.",
                    "label": 0
                },
                {
                    "sent": "In that case, you're sampling foods that have probably no direct connection whatsoever, and therefore you know you don't expect to find that kind of high dimensionality.",
                    "label": 0
                },
                {
                    "sent": "Oh yeah, that's basically very much the conclusion that we came to.",
                    "label": 0
                },
                {
                    "sent": "Yeah, that's true.",
                    "label": 0
                },
                {
                    "sent": "OK, thank you very much large.",
                    "label": 0
                },
                {
                    "sent": "We think our speaker.",
                    "label": 0
                }
            ]
        }
    }
}