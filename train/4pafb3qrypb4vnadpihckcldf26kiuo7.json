{
    "id": "4pafb3qrypb4vnadpihckcldf26kiuo7",
    "title": "Constrained Semi-Supervised Learning using Attributes and Comparative Attributes",
    "info": {
        "author": [
            "Abhinav Shrivastava, Robotics Institute, School of Computer Science, Carnegie Mellon University"
        ],
        "chairman": [
            "Antonio Torralba, Center for Future Civic Media, Massachusetts Institute of Technology, MIT",
            "Stefan Carlsson, KTH - Royal Institute of Technology"
        ],
        "published": "Nov. 12, 2012",
        "recorded": "October 2012",
        "category": [
            "Top->Computer Science->Computer Vision",
            "Top->Computer Science->Machine Learning->Semi-supervised Learning"
        ]
    },
    "url": "http://videolectures.net/eccv2012_shrivastava_attributes/",
    "segmentation": [
        [
            "One of the biggest buzzwords these days in computer vision."
        ],
        [
            "Less big data.",
            "Now lots of data has definitely helped the field of computer vision over the past decade.",
            "It is still unclear how we should exploit such large amounts of data.",
            "There is an entire spectrum of approaches to use this data based on the amount of supervision they require.",
            "On one end of the spectrum are supervised approaches which use tools like label Me and Amazon Mechanical Turk to acquire labeling information.",
            "But it is not clear whether such approaches can scale up to the increasing amounts of data that we have.",
            "On the other end of the spectrum."
        ],
        [
            "Are completely unsupervised approaches which use clustering techniques to discover categories.",
            "But unsupervised clustering is an extremely difficult problem and is still an active area of research.",
            "In this work, we explored the intermediate range of the spectrum.",
            "The domain of semi supervised approaches."
        ],
        [
            "Semi supervised techniques use large amounts of unlabeled data with only small labeled information to build reliable models.",
            "The most simple way to do this."
        ],
        [
            "Is to use bootstrapping or self learning method?",
            "In bootstrapping, you start with small number of labeled examples.",
            "For example, those two seed images for amphitheater, train.",
            "Initial classifiers like SVM boosted decision trees.",
            "And use them to classify images in a large, unlabeled data set.",
            "The classifier picks the top images according to it.",
            "For example, these four images and add sent back to the label data set.",
            "And now we can retain our classifiers using these six images and apply them back to the unlabeled data set.",
            "And we keep doing this iteratively.",
            "Now, if you notice the classifier made a mistake by selecting this auditorium image.",
            "Often the class dies."
        ],
        [
            "Class for accumulates these errors over iterations and by the time we reach a later iteration, for example."
        ],
        [
            "5th in this case we have an auditorium plus amphitheater classifier.",
            "This is."
        ],
        [
            "Well known problem of semantic drift where this classifier started with an initial concept of amphitheater but eventually drifted away to the concept of amphitheater plus auditorium.",
            "Clearly we need some more constraints on this bootstrapping framework to select the right images.",
            "But the big question is how do we get these constraints?",
            "One of the most common way of getting constraints is by using similarity between images."
        ],
        [
            "One option is to build a glass between images based on their similarity and do label propagation where we ensure that similar images receive similar labels.",
            "However, in the visual world, it is very difficult to estimate a good similarity metric.",
            "So in this work we take an alternative approach.",
            "Instead of learning a similarity metric, we use constraints given by relationships between semantic classes to select the right images.",
            "So what we do is."
        ],
        [
            "We combine or couple the learning of multiple classifiers.",
            "For example, when we are trying to label amphitheater images, not only those two seat examples but also the auditorium images are going to be useful to select the correct images.",
            "The relationships that we have defined between these semantic classes help us share information."
        ],
        [
            "Which in turn helps enforce rich constraints on this bootstrapping framework.",
            "But how do we share this information?",
            "The most common way, and as pointed by Dave in the last talk as well, is by using attributes."
        ],
        [
            "For example, conference room and banquet Hall both share the property that they are indoors.",
            "They are man made and have tables and chairs."
        ],
        [
            "I'll answer theaters and auditoriums, have large city spaces.",
            "So now the image."
        ],
        [
            "From conference room.",
            "Banquet Hall, Auditorium are all indoors and hence can be used to turn indoor attribute classifier.",
            "Similarly, we can use combination of different classes to train different attribute classifiers.",
            "Which will eventually help us select better images for this bootstrapping."
        ],
        [
            "For example, for these candidate images of our class auditorium we can."
        ],
        [
            "For the constraints that they should be indoors and have seat rows, and we can prune out the incorrect examples.",
            "Now when we think about sharing, the first thing that comes to our mind is the similarity between classes.",
            "As I just discussed."
        ],
        [
            "But one of our key contribution in this work is that we extend the notion of sharing across categories and show that we can in fact use dis similarities between classes to share information and enforce constraints.",
            "So what do I?"
        ],
        [
            "I mean by this dissimilarity's.",
            "For example, we know that amphitheatres usually have larger circular structures as compared to auditoriums.",
            "So we can use this notion of what makes amphitheater different from auditorium to select better images for amphitheater.",
            "So, given these four can."
        ],
        [
            "Did images for Amphitheatre.",
            "We can compare them to all these auditorium images and select ones that satisfy this relationship."
        ],
        [
            "For example, these images have indeed more circular structure as compared to all these auditorium images.",
            "But"
        ],
        [
            "System is just not and hence can be pruned out.",
            "So you see how this sharing is happening.",
            "The auditorium images in this case are helping us select to find out the right images for amphitheaters.",
            "So how do we formulate this notion of dissimilarity?"
        ],
        [
            "So in this work we use the concept of comparative attribute classifiers which given to images can predict whether this relationship is satisfied or not."
        ],
        [
            "The way this works is we first extract features from these images, such as.",
            "Just larger will lie in our lab histograms we take the differential features and use boost."
        ],
        [
            "Decision tree classifier.",
            "To check whether this pairwise relationship of having larger circular structures satisfied or not.",
            "For these comparative attribute."
        ],
        [
            "We given the semantic classes we manually provide these pairwise relationships.",
            "For example, amphitheaters are usually more open than both bond and conference room, and both church and barn have taller structures as computer symmetry images.",
            "Since we have seen images for all these classes, we can easily get pair of images for training.",
            "These comparative attribute classifiers.",
            "So now we have introduced how we can share data using both similarities and dis similarities."
        ],
        [
            "Let me discuss how we can use these attributes and comparative attributes."
        ],
        [
            "To enforce additional constraints on this bootstrapping framework.",
            "Using a."
        ],
        [
            "The other approach.",
            "So, given a large unlabeled data set, we represent its images as nodes in a giant graph.",
            "Jenna few labeled seed examples for category.",
            "We train scene axem classifiers and attribute classifier on those and apply them on the unlabeled data set.",
            "Their scores represent the unity potentials for the notes in this graph.",
            "We also take the pairwise differential features between these images and train competitive attribute classifier on those.",
            "These pairwise classifier scores represent edge potentials in this graph.",
            "After pruning win approximate inference on this giant graph and select the most confident images to be added to back to the label set.",
            "And we repeat this procedure iteratively.",
            "Now let's look at what kind of images are selected by this framework.",
            "For these two centimeters for the Glass Conference room, these are the images selected by titration."
        ],
        [
            "A nitrogen 14.",
            "Now the classifier trained on just few images is very weak, so it tends to make mistake in the initial iteration, for example by adding that bedroom image.",
            "But even as the classifier gets better and better with attrition, it sometimes keeps making the similar mistake.",
            "The primary reason for this is that the classifier has no way to forget about or to correct the mistakes that made in the initial iterations.",
            "To deal with this, we add another step called introspection, where we use a classifier at later stages of dehydration, which are much better to clean up our initial labels.",
            "Now let's see how each of these constraints help.",
            "In the image selection process.",
            "For these two state images of amphitheater, these are the initi."
        ],
        [
            "Image is selected by bootstrapping.",
            "We can see that these three images are incorrect and we can use Amphitheatre attributes like Hasid rose and has no water to eliminate them and come up with this improved set.",
            "But still the third image is incorrect.",
            "Now we know that unfiltered images have larger circular structures as compared to images from auditoriums, bond symmetry, and so on.",
            "So we can use these comparative attributes along with images from all these other classes to remove that incorrect image and come up with this set.",
            "Now let's see how this constrain."
        ],
        [
            "Bootstrapping framework performs quantitatively."
        ],
        [
            "To begin with, we first started a set of control experiments to study how each constraint contributes to the framework.",
            "We started this 15 classes from Sunday to set with two seed images for categories.",
            "Attribute and compatible relationships are manually defined and we use pre trained classifier for these which are trained on separate 25 images each.",
            "The unlabeled data set is of 18,000 images from Sunday to set with around 9500 distractors.",
            "The."
        ],
        [
            "This is the mean average precision performance of the baseline bootstrapping approach across iterations."
        ],
        [
            "After using coupling of classifiers and using 19 boundary attribute constraints, this is the boost that we get.",
            "And after."
        ],
        [
            "Adding competitive attributes, this is the performance."
        ],
        [
            "This is the final improvement after using introspection for periodic cleaning of the label set."
        ],
        [
            "The top black line here represents the upper bound on our algorithm.",
            "That is, if all the unlabeled data set was labeled and used for training of these classifiers, that would be the performance."
        ],
        [
            "We also compare against state of the art reflection approach from focus at all called Eigen functions which is shown here in solid red."
        ],
        [
            "Qualitatively, for these two seed images from Banquet Hall, these are the images selected by our approach across iterations.",
            "An interesting thing to notice is that we only started with closely images of the table, but as iterations preceded we variable.",
            "Indeed, we were able to incorporate a larger diversity of images representing banquet Hall.",
            "Does increasing recall?",
            "Now you are going to use the exact same setup."
        ],
        [
            "15 scene classes and two city matches per category.",
            "But instead of using pre trained classifiers, we're going to train."
        ],
        [
            "Attribute and competitive attribute classifiers on these same seed images for classes, and we're going to return them with iterations."
        ],
        [
            "Now for these images of bedroom, these were the images selected by bootstrapping, which ended loading mostly incorrect images by attrition 60.",
            "In contrast, these are the images selected by our approach."
        ],
        [
            "Also, quantitatively on the test set we perform better than the baselines."
        ],
        [
            "Now is the final experiment we want to see if our approach scales well.",
            "So we use an interval data set of 1,000,000 images and around 25 images per category as seed.",
            "In this large scale setting we improved the same classifiers for 12 out of 15 categories."
        ],
        [
            "In conclusion, we demonstrated that how we can go beyond the standard notions of sharing using commonalities between classes and actually share information using these similarities.",
            "That is, by exploiting the notion of what makes classic different from Class B.",
            "We also showed a constraint bootstrapping framework that can help us avoid semantic drift.",
            "More specifically, we."
        ],
        [
            "So that how we can use different kinds of sharing to enforce rich constraints in a semi supervised learning framework.",
            "Thank you.",
            "Just the same question I asked Debbie.",
            "Did you find that there is a set of attributes that was more informative in order to make the propagation?",
            "Yes, so actually in some of the control experiments will reduce the number of attributes that we use and we didn't see we didn't see that the performance job drastically, but we didn't have an explicit analysis of how each of these attributes affect our performance.",
            "But that's definitely true that some attributes are definitely more important, and in fact more discriminative algebra, it's.",
            "When you evaluate the comparative attribute classifiers for pairs of images at the time, how do you handle the problem of quadratic scaling in your huge datasets?",
            "So a million times a million or something?",
            "Yes, so like I mentioned, we have an approximate.",
            "We have a we perform pruning before before having this inference technique.",
            "So what we do is we just use the unary potentials to select candidate images for each classes.",
            "For example, suppose we want to select five images that iteration we select 15 or 20 images and then we just evaluate those competitive attributes on those images.",
            "And we have more detail in paper about how we do that procedure.",
            "I have one question, so you use comparative attributes here.",
            "What happens if you turn these attributes into real valued attributes?",
            "So for example, if you have in your in your presentation you have open this.",
            "You say that this class is more open than that that class.",
            "Now if you define some kind of openness there and build a predictor that gives a real value openness.",
            "Then in that case, have you have you tried with this idea, and if so, how does it?",
            "Does it help at all?",
            "Or it's better to stick with comparative attributes so it's a good question?",
            "And this question goes back to the question that what's the difference of using competitive attributes as opposed to relative attributes?",
            "Now?",
            "According to me they both have similar spirits, so there should.",
            "Obviously there will obviously be a way to directly incorporate them into the system, but what we wanted was just to have.",
            "A pairwise relationship so that we can get those edge potentials for all versus all Singleton classes, but, but yes, that incorporating those should be easy, and I think they'll have similar effect as we showed for competitive attributes.",
            "That's a nice question, by the way.",
            "Similar to the question of Antonio, are there any attributes that actually if you use them, it will decrease the performance?",
            "If you understand your question correctly, you are asking are there any attributes that decrease the performance?",
            "We didn't see that happening because essentially these attributes help us get multiview constraints on the data, but that's definitely possible that there are some attributes that are so noisy that they degrade the performance, but we didn't see in the 19 attributes that we used and do you have consider any way to somehow selecting them or no?",
            "But no, we didn't have that, but that's an interesting future direction that, given all this list of hundreds of attributes which are the right attributes that you want to select two for these classes.",
            "But yeah, we didn't include it there, but that's a good feature direction to work on this.",
            "Thank you.",
            "OK."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "One of the biggest buzzwords these days in computer vision.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Less big data.",
                    "label": 0
                },
                {
                    "sent": "Now lots of data has definitely helped the field of computer vision over the past decade.",
                    "label": 0
                },
                {
                    "sent": "It is still unclear how we should exploit such large amounts of data.",
                    "label": 0
                },
                {
                    "sent": "There is an entire spectrum of approaches to use this data based on the amount of supervision they require.",
                    "label": 0
                },
                {
                    "sent": "On one end of the spectrum are supervised approaches which use tools like label Me and Amazon Mechanical Turk to acquire labeling information.",
                    "label": 0
                },
                {
                    "sent": "But it is not clear whether such approaches can scale up to the increasing amounts of data that we have.",
                    "label": 0
                },
                {
                    "sent": "On the other end of the spectrum.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Are completely unsupervised approaches which use clustering techniques to discover categories.",
                    "label": 0
                },
                {
                    "sent": "But unsupervised clustering is an extremely difficult problem and is still an active area of research.",
                    "label": 0
                },
                {
                    "sent": "In this work, we explored the intermediate range of the spectrum.",
                    "label": 0
                },
                {
                    "sent": "The domain of semi supervised approaches.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Semi supervised techniques use large amounts of unlabeled data with only small labeled information to build reliable models.",
                    "label": 0
                },
                {
                    "sent": "The most simple way to do this.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Is to use bootstrapping or self learning method?",
                    "label": 0
                },
                {
                    "sent": "In bootstrapping, you start with small number of labeled examples.",
                    "label": 0
                },
                {
                    "sent": "For example, those two seed images for amphitheater, train.",
                    "label": 0
                },
                {
                    "sent": "Initial classifiers like SVM boosted decision trees.",
                    "label": 0
                },
                {
                    "sent": "And use them to classify images in a large, unlabeled data set.",
                    "label": 1
                },
                {
                    "sent": "The classifier picks the top images according to it.",
                    "label": 0
                },
                {
                    "sent": "For example, these four images and add sent back to the label data set.",
                    "label": 0
                },
                {
                    "sent": "And now we can retain our classifiers using these six images and apply them back to the unlabeled data set.",
                    "label": 0
                },
                {
                    "sent": "And we keep doing this iteratively.",
                    "label": 0
                },
                {
                    "sent": "Now, if you notice the classifier made a mistake by selecting this auditorium image.",
                    "label": 0
                },
                {
                    "sent": "Often the class dies.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Class for accumulates these errors over iterations and by the time we reach a later iteration, for example.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "5th in this case we have an auditorium plus amphitheater classifier.",
                    "label": 0
                },
                {
                    "sent": "This is.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Well known problem of semantic drift where this classifier started with an initial concept of amphitheater but eventually drifted away to the concept of amphitheater plus auditorium.",
                    "label": 0
                },
                {
                    "sent": "Clearly we need some more constraints on this bootstrapping framework to select the right images.",
                    "label": 0
                },
                {
                    "sent": "But the big question is how do we get these constraints?",
                    "label": 0
                },
                {
                    "sent": "One of the most common way of getting constraints is by using similarity between images.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "One option is to build a glass between images based on their similarity and do label propagation where we ensure that similar images receive similar labels.",
                    "label": 0
                },
                {
                    "sent": "However, in the visual world, it is very difficult to estimate a good similarity metric.",
                    "label": 0
                },
                {
                    "sent": "So in this work we take an alternative approach.",
                    "label": 0
                },
                {
                    "sent": "Instead of learning a similarity metric, we use constraints given by relationships between semantic classes to select the right images.",
                    "label": 0
                },
                {
                    "sent": "So what we do is.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We combine or couple the learning of multiple classifiers.",
                    "label": 0
                },
                {
                    "sent": "For example, when we are trying to label amphitheater images, not only those two seat examples but also the auditorium images are going to be useful to select the correct images.",
                    "label": 0
                },
                {
                    "sent": "The relationships that we have defined between these semantic classes help us share information.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Which in turn helps enforce rich constraints on this bootstrapping framework.",
                    "label": 0
                },
                {
                    "sent": "But how do we share this information?",
                    "label": 0
                },
                {
                    "sent": "The most common way, and as pointed by Dave in the last talk as well, is by using attributes.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For example, conference room and banquet Hall both share the property that they are indoors.",
                    "label": 0
                },
                {
                    "sent": "They are man made and have tables and chairs.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I'll answer theaters and auditoriums, have large city spaces.",
                    "label": 0
                },
                {
                    "sent": "So now the image.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "From conference room.",
                    "label": 0
                },
                {
                    "sent": "Banquet Hall, Auditorium are all indoors and hence can be used to turn indoor attribute classifier.",
                    "label": 1
                },
                {
                    "sent": "Similarly, we can use combination of different classes to train different attribute classifiers.",
                    "label": 0
                },
                {
                    "sent": "Which will eventually help us select better images for this bootstrapping.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For example, for these candidate images of our class auditorium we can.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For the constraints that they should be indoors and have seat rows, and we can prune out the incorrect examples.",
                    "label": 0
                },
                {
                    "sent": "Now when we think about sharing, the first thing that comes to our mind is the similarity between classes.",
                    "label": 0
                },
                {
                    "sent": "As I just discussed.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But one of our key contribution in this work is that we extend the notion of sharing across categories and show that we can in fact use dis similarities between classes to share information and enforce constraints.",
                    "label": 0
                },
                {
                    "sent": "So what do I?",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I mean by this dissimilarity's.",
                    "label": 0
                },
                {
                    "sent": "For example, we know that amphitheatres usually have larger circular structures as compared to auditoriums.",
                    "label": 1
                },
                {
                    "sent": "So we can use this notion of what makes amphitheater different from auditorium to select better images for amphitheater.",
                    "label": 0
                },
                {
                    "sent": "So, given these four can.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Did images for Amphitheatre.",
                    "label": 0
                },
                {
                    "sent": "We can compare them to all these auditorium images and select ones that satisfy this relationship.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For example, these images have indeed more circular structure as compared to all these auditorium images.",
                    "label": 0
                },
                {
                    "sent": "But",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "System is just not and hence can be pruned out.",
                    "label": 0
                },
                {
                    "sent": "So you see how this sharing is happening.",
                    "label": 0
                },
                {
                    "sent": "The auditorium images in this case are helping us select to find out the right images for amphitheaters.",
                    "label": 0
                },
                {
                    "sent": "So how do we formulate this notion of dissimilarity?",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So in this work we use the concept of comparative attribute classifiers which given to images can predict whether this relationship is satisfied or not.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The way this works is we first extract features from these images, such as.",
                    "label": 0
                },
                {
                    "sent": "Just larger will lie in our lab histograms we take the differential features and use boost.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Decision tree classifier.",
                    "label": 0
                },
                {
                    "sent": "To check whether this pairwise relationship of having larger circular structures satisfied or not.",
                    "label": 1
                },
                {
                    "sent": "For these comparative attribute.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We given the semantic classes we manually provide these pairwise relationships.",
                    "label": 0
                },
                {
                    "sent": "For example, amphitheaters are usually more open than both bond and conference room, and both church and barn have taller structures as computer symmetry images.",
                    "label": 1
                },
                {
                    "sent": "Since we have seen images for all these classes, we can easily get pair of images for training.",
                    "label": 0
                },
                {
                    "sent": "These comparative attribute classifiers.",
                    "label": 0
                },
                {
                    "sent": "So now we have introduced how we can share data using both similarities and dis similarities.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Let me discuss how we can use these attributes and comparative attributes.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To enforce additional constraints on this bootstrapping framework.",
                    "label": 0
                },
                {
                    "sent": "Using a.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The other approach.",
                    "label": 0
                },
                {
                    "sent": "So, given a large unlabeled data set, we represent its images as nodes in a giant graph.",
                    "label": 0
                },
                {
                    "sent": "Jenna few labeled seed examples for category.",
                    "label": 0
                },
                {
                    "sent": "We train scene axem classifiers and attribute classifier on those and apply them on the unlabeled data set.",
                    "label": 0
                },
                {
                    "sent": "Their scores represent the unity potentials for the notes in this graph.",
                    "label": 0
                },
                {
                    "sent": "We also take the pairwise differential features between these images and train competitive attribute classifier on those.",
                    "label": 0
                },
                {
                    "sent": "These pairwise classifier scores represent edge potentials in this graph.",
                    "label": 0
                },
                {
                    "sent": "After pruning win approximate inference on this giant graph and select the most confident images to be added to back to the label set.",
                    "label": 0
                },
                {
                    "sent": "And we repeat this procedure iteratively.",
                    "label": 0
                },
                {
                    "sent": "Now let's look at what kind of images are selected by this framework.",
                    "label": 0
                },
                {
                    "sent": "For these two centimeters for the Glass Conference room, these are the images selected by titration.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "A nitrogen 14.",
                    "label": 0
                },
                {
                    "sent": "Now the classifier trained on just few images is very weak, so it tends to make mistake in the initial iteration, for example by adding that bedroom image.",
                    "label": 0
                },
                {
                    "sent": "But even as the classifier gets better and better with attrition, it sometimes keeps making the similar mistake.",
                    "label": 0
                },
                {
                    "sent": "The primary reason for this is that the classifier has no way to forget about or to correct the mistakes that made in the initial iterations.",
                    "label": 0
                },
                {
                    "sent": "To deal with this, we add another step called introspection, where we use a classifier at later stages of dehydration, which are much better to clean up our initial labels.",
                    "label": 0
                },
                {
                    "sent": "Now let's see how each of these constraints help.",
                    "label": 0
                },
                {
                    "sent": "In the image selection process.",
                    "label": 0
                },
                {
                    "sent": "For these two state images of amphitheater, these are the initi.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Image is selected by bootstrapping.",
                    "label": 0
                },
                {
                    "sent": "We can see that these three images are incorrect and we can use Amphitheatre attributes like Hasid rose and has no water to eliminate them and come up with this improved set.",
                    "label": 0
                },
                {
                    "sent": "But still the third image is incorrect.",
                    "label": 0
                },
                {
                    "sent": "Now we know that unfiltered images have larger circular structures as compared to images from auditoriums, bond symmetry, and so on.",
                    "label": 0
                },
                {
                    "sent": "So we can use these comparative attributes along with images from all these other classes to remove that incorrect image and come up with this set.",
                    "label": 0
                },
                {
                    "sent": "Now let's see how this constrain.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Bootstrapping framework performs quantitatively.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To begin with, we first started a set of control experiments to study how each constraint contributes to the framework.",
                    "label": 0
                },
                {
                    "sent": "We started this 15 classes from Sunday to set with two seed images for categories.",
                    "label": 0
                },
                {
                    "sent": "Attribute and compatible relationships are manually defined and we use pre trained classifier for these which are trained on separate 25 images each.",
                    "label": 0
                },
                {
                    "sent": "The unlabeled data set is of 18,000 images from Sunday to set with around 9500 distractors.",
                    "label": 0
                },
                {
                    "sent": "The.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is the mean average precision performance of the baseline bootstrapping approach across iterations.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "After using coupling of classifiers and using 19 boundary attribute constraints, this is the boost that we get.",
                    "label": 0
                },
                {
                    "sent": "And after.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Adding competitive attributes, this is the performance.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is the final improvement after using introspection for periodic cleaning of the label set.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The top black line here represents the upper bound on our algorithm.",
                    "label": 0
                },
                {
                    "sent": "That is, if all the unlabeled data set was labeled and used for training of these classifiers, that would be the performance.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We also compare against state of the art reflection approach from focus at all called Eigen functions which is shown here in solid red.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Qualitatively, for these two seed images from Banquet Hall, these are the images selected by our approach across iterations.",
                    "label": 1
                },
                {
                    "sent": "An interesting thing to notice is that we only started with closely images of the table, but as iterations preceded we variable.",
                    "label": 0
                },
                {
                    "sent": "Indeed, we were able to incorporate a larger diversity of images representing banquet Hall.",
                    "label": 0
                },
                {
                    "sent": "Does increasing recall?",
                    "label": 0
                },
                {
                    "sent": "Now you are going to use the exact same setup.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "15 scene classes and two city matches per category.",
                    "label": 0
                },
                {
                    "sent": "But instead of using pre trained classifiers, we're going to train.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Attribute and competitive attribute classifiers on these same seed images for classes, and we're going to return them with iterations.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now for these images of bedroom, these were the images selected by bootstrapping, which ended loading mostly incorrect images by attrition 60.",
                    "label": 0
                },
                {
                    "sent": "In contrast, these are the images selected by our approach.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Also, quantitatively on the test set we perform better than the baselines.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now is the final experiment we want to see if our approach scales well.",
                    "label": 0
                },
                {
                    "sent": "So we use an interval data set of 1,000,000 images and around 25 images per category as seed.",
                    "label": 0
                },
                {
                    "sent": "In this large scale setting we improved the same classifiers for 12 out of 15 categories.",
                    "label": 1
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In conclusion, we demonstrated that how we can go beyond the standard notions of sharing using commonalities between classes and actually share information using these similarities.",
                    "label": 0
                },
                {
                    "sent": "That is, by exploiting the notion of what makes classic different from Class B.",
                    "label": 0
                },
                {
                    "sent": "We also showed a constraint bootstrapping framework that can help us avoid semantic drift.",
                    "label": 0
                },
                {
                    "sent": "More specifically, we.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So that how we can use different kinds of sharing to enforce rich constraints in a semi supervised learning framework.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                },
                {
                    "sent": "Just the same question I asked Debbie.",
                    "label": 0
                },
                {
                    "sent": "Did you find that there is a set of attributes that was more informative in order to make the propagation?",
                    "label": 0
                },
                {
                    "sent": "Yes, so actually in some of the control experiments will reduce the number of attributes that we use and we didn't see we didn't see that the performance job drastically, but we didn't have an explicit analysis of how each of these attributes affect our performance.",
                    "label": 0
                },
                {
                    "sent": "But that's definitely true that some attributes are definitely more important, and in fact more discriminative algebra, it's.",
                    "label": 0
                },
                {
                    "sent": "When you evaluate the comparative attribute classifiers for pairs of images at the time, how do you handle the problem of quadratic scaling in your huge datasets?",
                    "label": 1
                },
                {
                    "sent": "So a million times a million or something?",
                    "label": 0
                },
                {
                    "sent": "Yes, so like I mentioned, we have an approximate.",
                    "label": 0
                },
                {
                    "sent": "We have a we perform pruning before before having this inference technique.",
                    "label": 0
                },
                {
                    "sent": "So what we do is we just use the unary potentials to select candidate images for each classes.",
                    "label": 0
                },
                {
                    "sent": "For example, suppose we want to select five images that iteration we select 15 or 20 images and then we just evaluate those competitive attributes on those images.",
                    "label": 0
                },
                {
                    "sent": "And we have more detail in paper about how we do that procedure.",
                    "label": 0
                },
                {
                    "sent": "I have one question, so you use comparative attributes here.",
                    "label": 0
                },
                {
                    "sent": "What happens if you turn these attributes into real valued attributes?",
                    "label": 0
                },
                {
                    "sent": "So for example, if you have in your in your presentation you have open this.",
                    "label": 0
                },
                {
                    "sent": "You say that this class is more open than that that class.",
                    "label": 0
                },
                {
                    "sent": "Now if you define some kind of openness there and build a predictor that gives a real value openness.",
                    "label": 0
                },
                {
                    "sent": "Then in that case, have you have you tried with this idea, and if so, how does it?",
                    "label": 0
                },
                {
                    "sent": "Does it help at all?",
                    "label": 0
                },
                {
                    "sent": "Or it's better to stick with comparative attributes so it's a good question?",
                    "label": 0
                },
                {
                    "sent": "And this question goes back to the question that what's the difference of using competitive attributes as opposed to relative attributes?",
                    "label": 0
                },
                {
                    "sent": "Now?",
                    "label": 0
                },
                {
                    "sent": "According to me they both have similar spirits, so there should.",
                    "label": 0
                },
                {
                    "sent": "Obviously there will obviously be a way to directly incorporate them into the system, but what we wanted was just to have.",
                    "label": 0
                },
                {
                    "sent": "A pairwise relationship so that we can get those edge potentials for all versus all Singleton classes, but, but yes, that incorporating those should be easy, and I think they'll have similar effect as we showed for competitive attributes.",
                    "label": 0
                },
                {
                    "sent": "That's a nice question, by the way.",
                    "label": 0
                },
                {
                    "sent": "Similar to the question of Antonio, are there any attributes that actually if you use them, it will decrease the performance?",
                    "label": 0
                },
                {
                    "sent": "If you understand your question correctly, you are asking are there any attributes that decrease the performance?",
                    "label": 0
                },
                {
                    "sent": "We didn't see that happening because essentially these attributes help us get multiview constraints on the data, but that's definitely possible that there are some attributes that are so noisy that they degrade the performance, but we didn't see in the 19 attributes that we used and do you have consider any way to somehow selecting them or no?",
                    "label": 0
                },
                {
                    "sent": "But no, we didn't have that, but that's an interesting future direction that, given all this list of hundreds of attributes which are the right attributes that you want to select two for these classes.",
                    "label": 0
                },
                {
                    "sent": "But yeah, we didn't include it there, but that's a good feature direction to work on this.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        }
    }
}