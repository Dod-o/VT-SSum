{
    "id": "nci472icmokezyct5zl5cfhinpdxmdo5",
    "title": "Introduction to Machine Learning",
    "info": {
        "author": [
            "John Quinn, Faculty of Computing and Informatics Technology, Makerere University"
        ],
        "published": "March 31, 2011",
        "recorded": "February 2011",
        "category": [
            "Top->Computer Science->Machine Learning"
        ]
    },
    "url": "http://videolectures.net/aibootcamp2011_quinn_iml/",
    "segmentation": [
        [
            "OK so I just introduced from here John Quinn who is giving the talk introduction to machine learning and do not only does this research in machine learning, but also is in University of compiler, so probably has more than most of us here a good idea of what sort of machine learning all sorts of research is interesting in ARM African setting.",
            "So it's really nice weather right?",
            "Thanks Colin for the introduction of great to be here.",
            "By the way, I first came to Ghana.",
            "Six years ago was my first trip to Sub Saharan Africa and I liked it so much I ended up coming back to live in Uganda.",
            "On the other side.",
            "So I've been at Macquarie for about 3 years now and one thing I found is there are abundant opportunities for machine learning and that's something I hope you tell you bit about.",
            "Alright."
        ],
        [
            "Even.",
            "So by the way, if you are puzzled, curious, scared, stick your hand up and we'll all, sort of.",
            "OK, so the thing we want to deal with here is machines being able to deal with very high level tasks.",
            "And where you have something specified in very abstract terms, or something very high level, then we need to be able to deal with uncertainty.",
            "This uncertainty might come from different.",
            "There might be different types of uncertainty.",
            "We might have a problem which is defined in completely, so we have examples of some of the types of inputs and outputs we might want.",
            "So this is this is the face of Jose.",
            "Find me another collection from this set of photographs which have Jose's face in there.",
            "But we only have a few examples.",
            "The problem is not completely specified.",
            "The input space is very large and we've got to try to work out what to do for unseen inputs.",
            "OK, we may also have uncertainty when the problem is just too big, so think of the traveling salesman person.",
            "If we have 100 cities that we need to route between and find the shortest, the shortest tour covering all the cities, the number of permutations is it's not only larger than the number of atoms in the universe, I just notice it's the squared.",
            "Take the number of atoms in universe.",
            "Square that number and you get the number of ways of ordering 100 cities, so there's obviously no possible way that any machine could work that out exactly.",
            "So we have to employ some approximation.",
            "There's some uncertainty in the in the situation there.",
            "We may also be trying to tackle a problem which is on her inherently uncertain.",
            "So if we look at whether it's a chaotic system, we're never going to have enough information to be able to find an exact prediction.",
            "So I guess the angle a lot of you're coming to this from is being used to writing software where there's some inputs, the sum outputs it's pretty well specified what to do.",
            "We get this input, we follow some logic and there's the output.",
            "There is the action we take.",
            "But here, that's not really going to be enough.",
            "We have this uncertainty with and.",
            "The solution is we have various techniques to show our machine examples of what we want to achieve and have it learn what to do, and so we'll look at how to how to get that working for you.",
            "A few problems.",
            "It's going to be a fairly practical session thinking lines about how to or kind of cookbook various recipes to get things working.",
            "It's going to be necessarily broad rather than deep.",
            "We are going to want to cover a few concepts and in order to do that within the time we have will not be able to go very far into the into each particular technique, but at least hopefully will get a flavor of how they how they work."
        ],
        [
            "Alright, let me show you some examples of uncertainty in practical applications, particularly ones which you may be interested in tackling here.",
            "Will think about how to deal with that uncertainty in general terms.",
            "Look at a few more examples of what kind of machine learning applications we might be interested in.",
            "Then after we've seen some applications, we've got an idea of the problems we might want to solve.",
            "Then we'll fire into how to go about solving them.",
            "Alright, here's a blood smear and I'm sure all of you have had the experience where you start to feel feverish.",
            "You have to go down to get get a malaria test.",
            "The guy picks your finger, smears it on a glass slide.",
            "They stay in it, put under a microscope.",
            "Now, when the lab technician is peering through the microscope, this is what is looking at and we have various broken down red blood cell material and the dark stain spots are.",
            "DNA.",
            "Matter, so we have nucleotides.",
            "We have this guy here which is Plasmodium.",
            "So this is the this is the parasite and here we've got in its engagement ring stage.",
            "There's a kind of ring with a form nucleus on there and when you speak to lab technicians about what they're looking for, they explain the pattern in those kind of terms.",
            "I'm looking for engagement rings or I'm looking for a comma or a pair of headphones where there's two nuclei and some connecting matter between them.",
            "Now, if you could take these images and automatically from this image be able to identify, here's where the parasite is.",
            "That would be an application of enormous value.",
            "We could start to automate the testing process, so even where experts are not available to.",
            "To look through the microscope, we might be able to make some headway on being able to do that automatically.",
            "So let's think about the uncertainty in here.",
            "When we have an image.",
            "Let's think about the space.",
            "The input space of possible images.",
            "OK, assuming every pixel in this image has three values, are red, green and blue, and each of those three values could be anyone of 255 different values, then we've got 255 * 255 * 255 combinations that one pixel could have taken, so we already have a huge number of.",
            "Values that that that one pixel could take on.",
            "Now if we look at the whole image, it's a gigantic number, you know.",
            "So the point here is that if we have examples of the behavior we like, that might still be covering a very small part of the input space.",
            "So the set of examples we have, even if we think we have several.",
            "If you look at the space that images can take, in general it's very small, so we can't.",
            "Obviously we can't just memorize images, we can't just take examples and think, OK, I've seen this image that's got a parasite in it.",
            "I've seen this one.",
            "It's not a parasite in it because we're never going to get the same image twice, so we need to be able to deal with that lack of specification of the problem."
        ],
        [
            "OK here is.",
            "The traffic in Kampala which I would say is marginally more chaotic than a krivan, at least at least here.",
            "Guys don't tend to drive on the pavement and you know.",
            "That kind of thing.",
            "I think it's a bit more organized if you have a CCTV video stream like this and you're getting a real time feed from cameras around the around the center of the city where you live.",
            "Imagine if you were able to derive some high level information from this video stream.",
            "If you could tell how fast the traffic is moving, is it moving normally?",
            "Is there some anomalous?",
            "Phenomenon in there, which maybe maybe an accident or maybe something unusual happening.",
            "That would be useful things to workout and you know, pretty you know, a pretty tough kind of inference problem.",
            "If you were able to work that out from the video data, then a whole new set of questions arises which also have some uncertainty.",
            "Could you predict the traffic characteristics?",
            "Tomorrow at a particular junction, how much traffic is going to be there, and I've been trying to do this for my three years in Kampala and complete.",
            "It always takes me by surprise where there's where there's going to be congestion.",
            "Sometimes the roads are fine when you're expecting it to be a nightmare.",
            "You know, I can't really figure it out, but if we had enough data then maybe we could do this automatically."
        ],
        [
            "Alright, here's an example which is not so specific to here, but one that will try out a bit later if we have speech to text, we may have an input recording some sounds, so a sound when you record it is just a sequence of numbers, just that it's several numbers.",
            "You know, maybe 44,000 times per second you you take a sample from this input signal, you get the sequence.",
            "You could represent that as a time versus frequency.",
            "Clocks here there's a spectrogram.",
            "Ann from these spectral spectral information here you could try to work out what's being said.",
            "This is a recording of my favorite poems for Ted Hughes.",
            "And that's an example which will look at it a bit, and obviously you know fairly complicated one, partly because of the size of the input space.",
            "Again, we've got so many so many numbers here, you know 500,000."
        ],
        [
            "Numbers in a sequence.",
            "OK, well think a bit about on in general terms how to deal with this uncertainty.",
            "It's going to be a bit a bit vague here.",
            "Give you some general notion of what we're doing, then we'll go back to looking at some more examples of the types of motivating applications we're interested in.",
            "So one thing is immediately clear if we didn't make any assumptions about our problems, we couldn't learn anything.",
            "If we lived in a white noise world where everything was completely random and we were continually surprised by our senses, we had no idea what to expect at anytime.",
            "We wouldn't be able to learn anything.",
            "It's only by making assumption or having some bias towards what you already expect to be happening in the world that you can begin to make headway on these problems.",
            "So humans have various kind of biases about the things they expect to expect to receive in their senses.",
            "The things biases about the types of ways they might represent the external world, and we're so good at seeing patterns that quite often we see them even when they're not really there.",
            "So usually there's two kinds of assumptions which are fundamental to pretty much all machine learning work, which allow us to make a start on solving these problems.",
            "The first one is smoothness, and this is.",
            "This is something you basically always assume that if you have some function, say images too.",
            "Label on disease.",
            "You would assume that if the input changes a little bit, then the output might change a little bit or not at all.",
            "So if you have some image you've received and you know the label, you know the output of this function.",
            "If you receive another image and it's almost the same but just a little bit different then then we assume the same kind of output.",
            "The next one is simplicity.",
            "And basically models which are which have fewer variables, fewer kind of knobs to twiddle.",
            "We prefer those over complicated ones."
        ],
        [
            "So we're biased towards seeing those kind of patterns and the things we're looking at.",
            "Right?",
            "Well just look at a few more kind of Canonical machine learning tasks.",
            "Just to give us a few examples to work with later on.",
            "And it's a pretty exciting time to be working in machine learning.",
            "Incidentally, we have.",
            "We've had these problems around for a long time, and I think fields at a stage now where these are being robust.",
            "Ified were being able not just to do face recognition, handwriting recognition, but we're being able to on this gigantic global scale.",
            "Speech recognition is pretty robust now when you when you try it out.",
            "So here's another example you might want to have images of handwritten digits.",
            "There's a great deal of variability in how someone might draw an image, and given a new image, let's try and work out which which digit the person intended.",
            "What do they have in mind when they were making those shapes on the page?",
            "So there's a gigantic Canonical database which a lot of people considered to be a good good testing ground for new algorithms.",
            "And if you think about having to go about this.",
            "Or even just a two class problem where you get some input and it's in a little square and you want to know whether it's a one or a 2.",
            "Maybe you'd start to think about crafting crafting rules.",
            "We're going to look at something where we basically take a great deal of data and try to have models which learned, learn the patterns within that data.",
            "Now you might be thinking alright.",
            "The difficulty here comes from the fact that a handwritten digit could be, you know, someone can make a make a make a scratch on the page any any kind of manner, and there's a lot of variability within that and maybe printed character recognition is much easier."
        ],
        [
            "Well, that could also be tricky here.",
            "We've got a number of characters which are all the letter A and when we look at these we can see immediately that they're all the letter A.",
            "But if you if you try to think about what's the essence of each of these, what's the invariants?",
            "Is there some regularity between each of these patterns that we could somehow encode?",
            "It's, you know, it seems trickier than that.",
            "It might at 1st, and there's this great paper by Doug Hofstadter, which is well worth a read this question.",
            "So you know, finding this invariants, the pattern or interest in might not be."
        ],
        [
            "As easy as we think.",
            "So the data could come in all sorts of forms.",
            "We could have video data, image data.",
            "It could be time series data, so here are some examples of measurements of vibrations in the ground at different times when they were here.",
            "3 earthquakes at the top and at the bottom here 3 mining detonations underground.",
            "And if you had some equipment which was measuring vibrations in the ground and you felt some disturbance in the earth.",
            "Probably quite interested in knowing whether that's an earthquake or an explosion could have big implications for you, so trying to distinguish between these two things, if you've got some examples, you have some new set of vibrations that's going to be a significant task, and it's not really immediately obvious how to do that from the from the data here.",
            "So one thing we might think about here is the data we're looking at, just doesn't.",
            "We look at it, and we can't see.",
            "What information it has about the about the problem we are interested in.",
            "So we're going to think about RE representing data in order."
        ],
        [
            "To be more effective.",
            "Doing this kind of distinction.",
            "Get back to Africa.",
            "Castle Castle for viral Disease is a big problem in Uganda and here is some healthy leaves and.",
            "Disease called classical music.",
            "And music's got this quite distinctive visual appearance, which means that you can actually do pretty well at distinguishing between healthy and disease leaves given given just the image and just a reasonably poor quality image from a camera phone.",
            "So if you have a large set of images like this, then another application we could be interested in is.",
            "A survey tool.",
            "Someone goes into the field.",
            "You've got some survey team.",
            "They're taking snaps with their camera phone, and if we can automatically diagnose whether their disease, which disease they have, are the crops under stress in some way.",
            "If we can get that information, then we can do surveys.",
            "Larger scale surveys.",
            "Without requiring a small number of highly trained experts, which is the bottleneck at the moment in such service?"
        ],
        [
            "So having established information like that, maybe from the kind of mobile phone based system, there could be other questions were interested in like this kind of geospatial analysis.",
            "If we've got some some density in space of disease, disease incidents across the country perhaps, and we have some inputs from our survey which maybe maybe this kind of automatic thing, or it may be traditional survey techniques and we see you know ones if we take that to denote a.",
            "A perfectly healthy plant and five to denote the worst level of disease possible where the plant actually dying.",
            "Back then, given our points, we might want to workout where what's the coverage of disease across the rest of the cross.",
            "The rest of the field, so you know at points AB&C, what do we predict is happening there?",
            "We weren't able to send a survey team there, but there's a tyrant at that place and we want to know if we need to make some intervention.",
            "That's a question we could be interested in."
        ],
        [
            "To.",
            "Alright, here's the last application face recognition of the Canonical machine learning task, particularly important if you're a kind of badass assassination robot from the future.",
            "I.",
            "What are the examples have in common is that we're learning some kind of function.",
            "We've got some inputs and outputs these examples.",
            "We want to learn what's the mapping between the two.",
            "We've got some kind of assumptions to help us limit hypothesis about what types of mappings there might be.",
            "But this type of problem is something known as supervised learning, so I think we'll we'll start to get into the details of that.",
            "So I'm going to.",
            "Talk for a bit about different techniques that we can use to do supervised learning.",
            "I'm going to introduce some notation to do that.",
            "Do we have any questions at this stage about the applications we've seen?",
            "The concepts we've had so far?",
            "Alright.",
            "OK Sir, we need some notation to get anywhere."
        ],
        [
            "I'm going to introduce Atlanta to sweeten the pill a bit less.",
            "Let's stick with the Terminator alright to do any kind of supervised learning task.",
            "We need a label training data.",
            "We need a number of.",
            "Of samples from our input space and we need to know the corresponding output of the function that we're trying to learn.",
            "So here's here's some input samples, and here's the probability of this being a particular class.",
            "So it doesn't always have to be probability, but we're going to look at it that way.",
            "And given our training data and our test data we've got.",
            "For example, two things that we might want to.",
            "We might want our learning machine to output.",
            "First, one might be the most likely class.",
            "What's the C which maximizes the probability of Pfc given X?",
            "We might also commonly be interested in out putting an action, so if we have some kind of loss matrix which tells you if you got it wrong, how bad would that be then?",
            "You can sum up over all those possible losses, weighted by the probability of how much you think each classes and that gives you the class.",
            "You should think it is if you're going to minimize your loss.",
            "So obviously if you're the Terminator, you don't really have that bigger loss about the old accidental termination, you just terminate everyone.",
            "But if you're diagnosing cancer or something like that, you might be much more concerned about false negatives than you are about false positives.",
            "We don't mind the occasional false alarm, but it's very important not to miss anybody, so the loss matrix might wait your inference so that you're kind of biased towards positive rather than negative.",
            "OK, so that's our notation.",
            "So now the big question is this P of C given X, how do we?",
            "How do we get into that?",
            "That's the quantity which we want to.",
            "We want to learn before we learn.",
            "How do we even write it down?",
            "How do we?",
            "How do we represent this?",
            "Well, let's take an example, a simple."
        ],
        [
            "A simple way to get a bit further into this.",
            "Now let's imagine we've got a 2 dimensional input space.",
            "We've got two axes values on both axes will expect to be positive reals, and imagine these are the Heights and weights of two different types of animals.",
            "We've gone into the field.",
            "We've captured a number of animals, recorded their Heights and weights, and we plotted them on a graph.",
            "It looks a bit like this.",
            "So these are your animals of type one.",
            "These are animals of type 2.",
            "So these are the positions.",
            "Here are the X is the weather there a red circle or blue diamond is the see that's the class.",
            "And given a new example, we have just the X.",
            "We want to know is see the red circle or the blue diamond type.",
            "So this this business of trying to take the probability of C given X where you might try to answer that by proposing a decision boundary.",
            "So let's say there's a linear boundary.",
            "The further we get on this side, the more likely The thing is to be in the blue diamond type of animal and the further The thing is on this side, the more likely it is to be a red circle.",
            "An if we get something which is exactly on the decision boundary, then we don't know."
        ],
        [
            "So let's see how we would.",
            "How we would formulate this a bit more explicitly?",
            "We can do if we've got something which is dealing with lines or planes or hyperplanes.",
            "Everything is linear, everything is just multiplication.",
            "Sums makes it makes it pretty easy.",
            "The kind of things we're doing yesterday.",
            "So if we had 1D imagine we were only measuring the weights of different animals and these are two classes, and in this example there conveniently well separated and we could draw a boundary.",
            "We could have some point, and if the.",
            "Value is greater than that point then.",
            "That is one class if it's less than that, it's another.",
            "So let's write that down as quantity X1, which is the variable that we observe.",
            "Times this thing W one that's like a weight and B is some offset and.",
            "If we find some W&B.",
            "Which effectively gives us some threshold on the input space.",
            "Where that zero?",
            "That's the decision boundary.",
            "We don't know which class it's in.",
            "If this quantity X * W + B is greater, then we say it's in one class, and if it's less than it's in another class.",
            "So in 2D pretty similar kind of thing, we're just we're just introducing another variable here and now we've got.",
            "Alayna csardas"
        ],
        [
            "Boundary.",
            "And so I think you can.",
            "Kind of see the pattern here, and I think this might be something you did you did yesterday.",
            "We can keep generalizing this and we find that the linear decision boundary is expressed by a weight vector times are input vector plus some scalar offset, so this is.",
            "So there's an interpretation for the W, which is W. Is this?",
            "It's a vector.",
            "And the way that vector points is, it's perpendicular to the decision boundary, so that's a vector pointing.",
            "This way, the decision boundary is going to be something.",
            "Something perpendicular to that.",
            "It's going to be orthogonal, and then the B is going to be something which moves that in One Direction or another from the origin.",
            "So this quantity gives you for some input space.",
            "If you find your WMB appropriately, you get zeros for the values of X which lie exactly on the boundary, they become increasingly positive on One Direction, increasingly negative on the other.",
            "OK, so we're.",
            "So now we have a way of formulating this.",
            "This type of boundary this this is not quite given the probability yet, but we've got some quantity at least which separates the input space in some way.",
            "So at this stage I want to take an example."
        ],
        [
            "And this is something.",
            "Came up with for two to illustrate this here.",
            "So last week I sat in my office and I recorded myself saying words yes and no several times and distinguishing being able to distinguish progressing no.",
            "I hope you agree.",
            "That's kind of a useful thing to be able to do.",
            "Imagine writing some software which expected a voice prompt and we needed some simple way of getting microphone input and being able to tell whether the person said yes or no.",
            "So here's our input space.",
            "And just like the earthquakes and explosions.",
            "Pretty difficult to see.",
            "Really what to do with this input space?",
            "It's pretty complicated.",
            "So you might be thinking at this stage.",
            "OK, this is an application which looks useful.",
            "The things we saw on the preceding slides about the linear decision boundary.",
            "Looks fine, but isn't that much too simple to really be able to deal with any any real world complex problem like this.",
            "So let's see how this problem can be solved with the concepts that we just saw in the previous slides."
        ],
        [
            "Alright, first of all, the data that we have in its raw form is no use to us.",
            "We need to have.",
            "Something more informative about the kinds of things we're looking at.",
            "So let's do some spectrogram transformation of this data.",
            "We want to look at here is time.",
            "Here is the duration of the sample, and here are frequency levels.",
            "This is actually plotted with lowest frequencies at the site.",
            "In higher frequencies at this side.",
            "So each of these each of these columns here is a little Fourier transform.",
            "And where at that instant there was some kind of low frequency component in my voice that shows up as a hot color here, and where that frequency component was lower than that shows a cool color.",
            "So we got three guesses, three nodes, and now we can you know, if you really squint at this for awhile and you try to work out what's going on, you can start to make some distinction between these two two types of classes.",
            "So you know, visually inspecting this, we could start to see some differences like there's you know the yes, have this kind of yellow cloud over here, whereas the nose don't really.",
            "There's kind of three stages to the yes, which actually is like the three different.",
            "I guess it's like the three different sort of shapes that my mouse took when I was saying the word, yes.",
            "I guess that's a yes something like that, whereas no is kind of 1 long.",
            "That vowel sound is more consistent.",
            "And this thing here it could be quite informative the the S of yes when I make that noise that's more like white noise, which we know is something that has frequent power across all frequencies.",
            "So during the well I'm uttering the end of the word yes, then we'd expect to see this high frequency component.",
            "No, doesn't have anything quite like that.",
            "Alright, so there's a.",
            "There's a start to being able to distinguish between these two things, so we could do some kind of what we're going to call feature engineering.",
            "And let's say the.",
            "The most interesting part here is these.",
            "These kind of bands here.",
            "If all my inputs are either going to be a sore nose, then one informative part of this data could be just this band here.",
            "So here we expect to see something of high power at some point, but not all the time, and."
        ],
        [
            "Are we expected to be low power throughout the veterans?",
            "So what we can do is take an average of that band across the length of the sample.",
            "And here I've done the.",
            "The yeses in red and the nose and blue and this is for those rows of the spectrogram.",
            "I've averaged that up over the over the frequencies were interested in.",
            "And part of that here, so they're all different lengths, but we can start to see some kind of distinction here the the this kind of bumping the yes frequencies where I get to saying the word S whereas the nose tend to be low power throughout.",
            "Now if I take 2 samples 22 features from this deals we make it even simpler.",
            "Let's say I just take the Max and the variance of each of these sequences here.",
            "And that gives me a 2 dimensional representation of each input data point.",
            "Then we get something like this.",
            "So plotting this here we can now see we've got it right down to this 2 dimensional description where we might be able to use some kind of linear classifier.",
            "Ha.",
            "OK, so now we're at a stage where we've we've made this.",
            "We've got this input space, which is pretty complicated.",
            "You know, several hundreds of thousands of numbers in one long sequence which progressively made it simpler and simpler.",
            "Just trying to keep the information we're interested in and throw away extra information that we don't need until we've taken maybe 500,000 numbers.",
            "Variable depending on the length of the sample, and we've condensed all that down into 2 numbers which are kind of features of this thing here.",
            "And these two numbers we think are quite informative about the problem that we have.",
            "Alright, the data and code for this are available on my website, by the way, we should find a link there on the software page with all the samples.",
            "If you want to hear me saying no, no, no over and over again like a maniac them.",
            "The opportunity is there alright, so let's take this as our R2D example, something a bit more interesting than classifying types of animals."
        ],
        [
            "And let's go back to.",
            "Linear classification let's try and actually actually do this.",
            "Alright Sir, we need to.",
            "We've got some idea that we have this 2 dimensional data which somehow can be split up by bioline.",
            "And we need to come up with some way of choosing a line.",
            "We need to somehow draw a line somewhere in this 2D space so that we split up our our data in a good way.",
            "Well, how could we do that?",
            "Let's take the simplest thing we could do.",
            "The thing with the least programming, which is let's choose a completely random line.",
            "When I say random, there's actually some details there, which I'm kind of going to cure for you.",
            "But let's take lines, all of which we before we've seen any data we think are equally likely.",
            "And then we'll see which ones match and will will keep the ones which match and look at them.",
            "So we've got two things to be able to work out there.",
            "One is how can we generate Lions and the other is how can we see if anyone line matches the data we have and neither of those are very challenging actually."
        ],
        [
            "So.",
            "If we.",
            "If you want to generate many lines, we can represent a line uniquely with a single point on on the on the 2D plane.",
            "If we have some.",
            "Origin we probably want to take the origin.",
            "Is that the mean of our data points?",
            "Something like that.",
            "If we generate any point somewhere.",
            "So we could have points at random if we take the vector from the origin to that point, and then we have that as a scaled version of RWR wait.",
            "Then this is something which is perpendicular to the to the.",
            "The.",
            "Decision boundary, so for all these random points we generate.",
            "We can draw a bunch of loans.",
            "And that's where these lines come from.",
            "Here in the example that you can try.",
            "And there's a few details I kind of alluded to that you you want to be a bit careful about how you draw these lines, and you can check this easily by just plotting many lines that are drawing and seeing that there are being generated in the right way.",
            "It's easy to, it's easy to generate lines in such a way that you are actually covering more of the input space with lines in some area in some regions than others.",
            "Let's assume that we've come up with some way of generating lines that we're happy with.",
            "It seems to be covering the space that we.",
            "The space of decision boundaries uniformly according to what we think is likely before we've seen any data."
        ],
        [
            "Alright, so we know how to generate lines.",
            "Now we need to distinguish between lines, which seem to be.",
            "Which seemed to be appropriate or consistent in some way with the data that we've that we've seen.",
            "So let's introduce a new concept of likelihood.",
            "Given that we've received some data, how likely is it that one particular line is the right line?",
            "So let's have a simple measure for this, so we've got something which will express as a probability.",
            "And we'll say, well, this is essentially saying is that for some line, if this line splits up the data perfectly, so all the yeses are on the positive side and all the nodes on the negative side, then that particular line has probability one.",
            "Anne."
        ],
        [
            "If it doesn't, then it has probability 0, so all that is essentially saying.",
            "Is.",
            "Let's generate a whole bunch of lines, so I think he regenerated maybe like 1000 lines and we'll look at the ones which have probability probability one, so the ones where all the all the red pluses on the positive side of the line and all the blue plus is on the negative side of line.",
            "Alright, so we've generated a whole bunch of lines which which fit.",
            "So now we've got some choices we could.",
            "We could stop there.",
            "We could take one of the lines at random and say, OK, all of these of these lines fit our training data in some ways.",
            "So we just we just choose one and that's going to be what will use to distinguish knew new test examples.",
            "Or we could look at all of these lines.",
            "Try to do something else with them."
        ],
        [
            "So let's do the latter.",
            "And I'm going to give you another.",
            "Another concept here, which is the use of.",
            "The use of Bayes rule to help with this kind of problem.",
            "So Bayes rule.",
            "Basic basic property of joint and conditional probabilities.",
            "When people talk about Bayesian methods, the.",
            "The insight that's using is that Bayes rule doesn't just have to be about things that statisticians usually call random variables.",
            "You could also be reasoning about the probability of different parameters, which is a fundamental change in statistical method from what was classically applied.",
            "It used to be that a parameter with some quantity that you couldn't reason about with probabilities, but why not?",
            "Let's give it a shot.",
            "So if you are interested in the probability.",
            "Of some parameters given some data.",
            "Then you can use Bayes rule you.",
            "You look at the likelihoods of different different data points, and you integrate this out over.",
            "You so you use Bayes rule to give you a posterior probability of your parameter space.",
            "Um?",
            "So having obtained this kind of quantity here, which will look at an example of just now, we can then use this to make predictions about new data points.",
            "So.",
            "If we have a distribution over what we think our parameters should be, we've got something which represents the space of all possible lines, and we have some measure of how likely each line is.",
            "Then we can actually use that distribution too.",
            "To give us what's called a posterior probability given and you test data point where we don't know the.",
            "The the output class.",
            "For example, we could say what's the probability of this test data?",
            "This X and this CR position, Anna label given all the data I've seen.",
            "And here's another application of Bayes rule where we basically integrate over the whole parameter space, so we're saying.",
            "We're taking all the lines that we that we know about.",
            "Potentially including every single line in the possible space of lines that there could be where.",
            "We're looking at how likely.",
            "That line is given the training data that we've already received were then looking at.",
            "How likely would that particular part of the test data be that class that we see in that X, the label and that position?",
            "How likely would both of those be given some particular line, and we integrate that over every possible line?",
            "So in our example, the parameters are what the lines are the W in the B and the data is the input position which was 2D in our.",
            "In our speech example and see which is either yes or no in that example.",
            "That's a bit confusing.",
            "Let's let's look at an example.",
            "OK, two questions.",
            "Let's thank you first.",
            "Density.",
            "Is that for the yes or no?",
            "We are.",
            "We're looking at the density of different parameters, so the data is something that's fixed.",
            "We've got some, we've got some data we've seen.",
            "We've seen that we know where the data points are, so we kind of know what that density is and we're interested in where's.",
            "Where's the good points in parameter space?",
            "That seems to represent that data, so it's not the density of the data exactly, but the density of good parameters.",
            "How likely are all the different possible length?",
            "Yet another question there.",
            "I wanted to know whether the objective over looking at base rule.",
            "In this specific case of our example is to help us determine which of the lines makes the best fits, or we're looking at whether the data is on the other side.",
            "Because this is a distribution of the lines or the distribution of the data, right?",
            "That's a great question, yeah?",
            "OK, so the distribution of the data again is something that we already know and what we're interested in is where, where should we put the best lines were interested in, you know?"
        ],
        [
            "Going back to.",
            "Going back to the the input data that we've got, let's remind ourselves of the task that's going on here.",
            "We want to know if we take a new recording of someone saying something which could either be a yes or no and it arrives at some point in this space.",
            "We want to know if that's a yes, or if it's a no.",
            "The way that we are choosing to distinguish between that is with a line.",
            "So the fundamental goal here is to work out where the lines are going, which places to put good lines.",
            "So that is why we're interested in the distribution of possible lines given the data.",
            "So, given that we've seen these things, what's the how likely do we think different different lines are?",
            "So we actually watching the behavior of the lines to see how best we get these exactly.",
            "Yeah, you got it spot on behavior.",
            "So we're trying to find that is yeah.",
            "Some detail follow noise, sure, yeah, So what do you want to detect to know that?",
            "OK, this is their land access at the bank?",
            "OK great great questions.",
            "The what we've already got away."
        ],
        [
            "Specifying the likelihoods so we can take a whole bunch of lines, and we can say.",
            "We can say here is a bunch of lines which had equally high likelihood.",
            "All of these have likelihood one, so so far we're saying all of these lines are equally equally likely and there's a whole other bunch of lines which we don't care about.",
            "We're not asshole interested in them because they have likelihood 0.",
            "OK, so we're trying to work out kind of which lines are better than other lines and at the moment we have a whole bunch of lines that we think are equally likely.",
            "We sampled each of those, so we're trying to get a bit further by looking at the combination of all of these lands.",
            "Were trying to see which kind of areas are covered up by by all of these.",
            "So for a particular point here.",
            "We are really interested in what should we think about the what should we infer about the class of a point which we receive here.",
            "Someone make some noise.",
            "They record it in the microphone.",
            "We calculate these features and it's projected here in this 2D space.",
            "Then what do we do with it here on some lines it's on the red side.",
            "On some other lines on the blue side.",
            "So what do we do?",
            "And So what Bayes rule is trying to do is to look at some combination over our whole input space and give us some probability, not just a zero or a one of this point.",
            "Here being a yes or a no or for any other point.",
            "Let's look at what the result is when we do."
        ],
        [
            "When we run through.",
            "This inference here.",
            "So for each data point, will try and we'll try and integrate this over all the possible lines and we'll see what the output is.",
            "And then maybe that will become more clear to you why we did it."
        ],
        [
            "OK, what I've done here.",
            "This data is.",
            "I've sampled 10,000 lines.",
            "And I've given each likelihood of 1 again if it splits up the two categories in the way we want and the likelihood of 0 if it doesn't.",
            "And I've drawn this contour plot.",
            "And this is drawn by looking at for each point what proportion of the Lions is it on the red side, and what proportion of the lines is it on the blue side.",
            "So it's very easy to calculate this.",
            "We have our.",
            "Of our.",
            "Space.",
            "X1 and X2 and if I have a line with likelihood of 1.",
            "Then on the posterior, I'll wait that I'm going to kind of shade in this color as.",
            "Neria saying that given this setting of the parameter here, any inputs I receive in this space will think that's a red plus that's going to be me saying yes, and here it's going to be in the blue space.",
            "It's me saying no.",
            "OK, that's what we can do for a single a single line.",
            "But now we're integrating over many lines, so let's take another one.",
            "Say that line.",
            "There also has likelihood of 1.",
            "If I then shade in the.",
            "The area there.",
            "So this is with two samples lines and we're saying both of them have equal likelihood.",
            "Now we've got kind of three different regions.",
            "We've got a region where any input here is definitely.",
            "We definitely infer that to be a blue plus we didn't for that to be somebody saying no in this region.",
            "Here, each of these.",
            "Each of these sections we have an intermediate probability.",
            "This is.",
            "This is data which one of one of the parameter sets would have predicted with a yes and one of them wouldn't have, and in this region here both of the lines that we've sampled so far would agree that it's a yes, so we've got definitely, you know, kind of in the middle.",
            "Definitely yes.",
            "So as we keep adding lines, say we've got to say we have another one like that.",
            "And this is the blue side.",
            "And this is the red side.",
            "Then we can keep.",
            "Adding on to the.",
            "Adding onto the probabilities again doing this integration.",
            "So that we end up with this posterior probability, and that's what we're plotting here from many, many lines.",
            "OK, so that's just doing.",
            "This integration here and we're doing this integration in.",
            "Using a method called Monte Carlo, which basically just means we take a load of random samples from our prior and we see what happens those samples and try to build a posterior which is made up of a bunch of those samples, and if we take enough samples from our prior then we hope to build up an accurate picture of our posterior.",
            "There's other ways of doing that integral as well.",
            "Alright, so a couple of things to notice about this.",
            "First of all, we have something so Bayes rule is given us a way of a very simple way of having a classifier, some random decision boundary, and.",
            "So linear decision boundary which splits things up into one or zero.",
            "It's a hard classifier.",
            "Everything is either definitely yes or definitely know by sampling many of them from our prior and looking at the.",
            "Looking at the posterior distribution, we get this kind of contour, so we say if we see a point here then maybe it's a probability of .2 that it's a yes.",
            "If we see something, here is the probability of .9 that is a yes.",
            "And this kind of follows the pattern that we've seen.",
            "So something to note, the posterior distribution under this Bayesian inference is of a different form to the hypothesis that we that it was made up of.",
            "So we're getting something extra kind of richer representation than our individual lines.",
            "By integrating them all up, we're getting something more significant.",
            "So we.",
            "We could have.",
            "People often look at something called the maximum a posteriori, which is something under Bayes rule which maximizes the maximizes the probability posterior parameter probability, but will not worry about that too much just now.",
            "This is ideally the thing to do if we if we can.",
            "Please mention.",
            "Oh great, OK. That's perfect, 'cause I wasn't going to say anything more about it.",
            "So still hear all about that tomorrow.",
            "Great, I think we're running for an hour.",
            "Let's have a quick break after some questions please.",
            "I want to know the.",
            "One thing, so it's like one thing is in using vision classification as.",
            "God bless you opposed to using regression because I see that you can use for patient.",
            "Also find a partner.",
            "Yeah, absolutely, and those two things are.",
            "So the I guess the comment is there we could look at the boundaries and see how far away the points are from the boundaries and try to find it that way and those two things are not mutually exclusive.",
            "You don't have to choose between regression or Bayesian methods.",
            "And actually what will look after the break is.",
            "Is doing regression in a Bayesian way?",
            "So you can actually you can actually do do both.",
            "So there's.",
            "Logistic regression, which is a way of choosing a line according to according to some different likelihood, and we can still still always do the Bayesian thing.",
            "Hope this is your your question.",
            "We will look at a bit more after the after the break.",
            "Anyone else here?",
            "Those are points where you have probability of test data against.",
            "The data that you have and the next."
        ],
        [
            "Right there and I just."
        ],
        [
            "Are you assuming that the data is almost the space distributed?",
            "OK, right right?",
            "So the probability of the data is some term which makes this a probability, so we know that if we.",
            "We know that if we.",
            "Look at every possible parameter setting.",
            "All of this has to sum up to one, so the integral over the parameters has to be one, and this term here is just the number of which makes it scale to that to that value.",
            "So it's just some some constant term that we put in there, and usually we just forget about it and say it's proportional, and then after we've actually done done a bunch of samples, then we just we just divide through to make it sum up to one.",
            "So it's just something to make it a bit easier.",
            "Alright anymore for anymore.",
            "Why did you generate just appoint?",
            "Couldn't have generated like the actual data you needed, because instead of going to find opponent and then finding perpendicular cleaned up there said oh I need W and peas.",
            "Well, it's the same thing, right?",
            "Like if we generate if we generate a point here, then that actually gives us a way of.",
            "Of generating our RW Zombies, it's uniquely specified by a single point, so we could as well generate the right.",
            "We could generate random values of W and random values of B.",
            "There's a bit of a danger there, and this is a danger which is partly in the details, which I kind of hid from you about generating these lines.",
            "We kind of want the lines to be within some space somewhere we want."
        ],
        [
            "Have generated some random lines here.",
            "And they're all kind of the lines.",
            "All kind of cross our space about where the data is.",
            "So if we generated random WMB with no constraints, we might have a whole bunch of lines somewhere over here somewhere down there somewhere right over at this side.",
            "And that wouldn't really be the kind of thing we're interested in.",
            "So the way we take this in Bayesian terms is our prior wants us to.",
            "We should have a prior which draws lines from the region where are.",
            "Data is we want to have lines kind of uniformly around here, and one way of ensuring that is to choose points which in some way or within the within the space where our data is.",
            "So if we can control where those points are and those points are the things we have an origin, which is the mean of our data, then we've always got lines which are kind of where we want them to be, and not not sort of miles off somewhere else.",
            "Yes, please.",
            "Find a means of the data or.",
            "OK for the question right I can see I'm not going to be able to hide these details from you anymore.",
            "You want to know how to choose the prior.",
            "Let me let me tell you that the way to choose the prior here.",
            "I could actually show you after the break what happens with different priors.",
            "OK, you could choose the points uniformly across this space, and if you do, it actually doesn't really work.",
            "You get lines where there's very few.",
            "There are very few lines going through the center and many around the edge.",
            "So the best way to choose these points is to start at the origin and uniformly sample some.",
            "Some radius out from the center and some some angle around, so your.",
            "Or uniformly choosing an angle from negative.",
            "Negative \u03c0 degrees, and you're choosing some radius uniformly, which is the distance away from the origin that you think the line should be.",
            "And if you do that then you'll get points which give you Lions which kind of look look right.",
            "So there's a couple of ways you could generate those those points, and not all of them are right, and the way to tell is to try it out and then see what you see what you get."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK so I just introduced from here John Quinn who is giving the talk introduction to machine learning and do not only does this research in machine learning, but also is in University of compiler, so probably has more than most of us here a good idea of what sort of machine learning all sorts of research is interesting in ARM African setting.",
                    "label": 1
                },
                {
                    "sent": "So it's really nice weather right?",
                    "label": 0
                },
                {
                    "sent": "Thanks Colin for the introduction of great to be here.",
                    "label": 0
                },
                {
                    "sent": "By the way, I first came to Ghana.",
                    "label": 0
                },
                {
                    "sent": "Six years ago was my first trip to Sub Saharan Africa and I liked it so much I ended up coming back to live in Uganda.",
                    "label": 0
                },
                {
                    "sent": "On the other side.",
                    "label": 0
                },
                {
                    "sent": "So I've been at Macquarie for about 3 years now and one thing I found is there are abundant opportunities for machine learning and that's something I hope you tell you bit about.",
                    "label": 0
                },
                {
                    "sent": "Alright.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Even.",
                    "label": 0
                },
                {
                    "sent": "So by the way, if you are puzzled, curious, scared, stick your hand up and we'll all, sort of.",
                    "label": 0
                },
                {
                    "sent": "OK, so the thing we want to deal with here is machines being able to deal with very high level tasks.",
                    "label": 0
                },
                {
                    "sent": "And where you have something specified in very abstract terms, or something very high level, then we need to be able to deal with uncertainty.",
                    "label": 1
                },
                {
                    "sent": "This uncertainty might come from different.",
                    "label": 0
                },
                {
                    "sent": "There might be different types of uncertainty.",
                    "label": 0
                },
                {
                    "sent": "We might have a problem which is defined in completely, so we have examples of some of the types of inputs and outputs we might want.",
                    "label": 0
                },
                {
                    "sent": "So this is this is the face of Jose.",
                    "label": 0
                },
                {
                    "sent": "Find me another collection from this set of photographs which have Jose's face in there.",
                    "label": 0
                },
                {
                    "sent": "But we only have a few examples.",
                    "label": 0
                },
                {
                    "sent": "The problem is not completely specified.",
                    "label": 1
                },
                {
                    "sent": "The input space is very large and we've got to try to work out what to do for unseen inputs.",
                    "label": 1
                },
                {
                    "sent": "OK, we may also have uncertainty when the problem is just too big, so think of the traveling salesman person.",
                    "label": 0
                },
                {
                    "sent": "If we have 100 cities that we need to route between and find the shortest, the shortest tour covering all the cities, the number of permutations is it's not only larger than the number of atoms in the universe, I just notice it's the squared.",
                    "label": 1
                },
                {
                    "sent": "Take the number of atoms in universe.",
                    "label": 0
                },
                {
                    "sent": "Square that number and you get the number of ways of ordering 100 cities, so there's obviously no possible way that any machine could work that out exactly.",
                    "label": 0
                },
                {
                    "sent": "So we have to employ some approximation.",
                    "label": 0
                },
                {
                    "sent": "There's some uncertainty in the in the situation there.",
                    "label": 1
                },
                {
                    "sent": "We may also be trying to tackle a problem which is on her inherently uncertain.",
                    "label": 0
                },
                {
                    "sent": "So if we look at whether it's a chaotic system, we're never going to have enough information to be able to find an exact prediction.",
                    "label": 0
                },
                {
                    "sent": "So I guess the angle a lot of you're coming to this from is being used to writing software where there's some inputs, the sum outputs it's pretty well specified what to do.",
                    "label": 0
                },
                {
                    "sent": "We get this input, we follow some logic and there's the output.",
                    "label": 0
                },
                {
                    "sent": "There is the action we take.",
                    "label": 0
                },
                {
                    "sent": "But here, that's not really going to be enough.",
                    "label": 0
                },
                {
                    "sent": "We have this uncertainty with and.",
                    "label": 0
                },
                {
                    "sent": "The solution is we have various techniques to show our machine examples of what we want to achieve and have it learn what to do, and so we'll look at how to how to get that working for you.",
                    "label": 0
                },
                {
                    "sent": "A few problems.",
                    "label": 0
                },
                {
                    "sent": "It's going to be a fairly practical session thinking lines about how to or kind of cookbook various recipes to get things working.",
                    "label": 0
                },
                {
                    "sent": "It's going to be necessarily broad rather than deep.",
                    "label": 0
                },
                {
                    "sent": "We are going to want to cover a few concepts and in order to do that within the time we have will not be able to go very far into the into each particular technique, but at least hopefully will get a flavor of how they how they work.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Alright, let me show you some examples of uncertainty in practical applications, particularly ones which you may be interested in tackling here.",
                    "label": 1
                },
                {
                    "sent": "Will think about how to deal with that uncertainty in general terms.",
                    "label": 0
                },
                {
                    "sent": "Look at a few more examples of what kind of machine learning applications we might be interested in.",
                    "label": 0
                },
                {
                    "sent": "Then after we've seen some applications, we've got an idea of the problems we might want to solve.",
                    "label": 1
                },
                {
                    "sent": "Then we'll fire into how to go about solving them.",
                    "label": 0
                },
                {
                    "sent": "Alright, here's a blood smear and I'm sure all of you have had the experience where you start to feel feverish.",
                    "label": 0
                },
                {
                    "sent": "You have to go down to get get a malaria test.",
                    "label": 0
                },
                {
                    "sent": "The guy picks your finger, smears it on a glass slide.",
                    "label": 0
                },
                {
                    "sent": "They stay in it, put under a microscope.",
                    "label": 0
                },
                {
                    "sent": "Now, when the lab technician is peering through the microscope, this is what is looking at and we have various broken down red blood cell material and the dark stain spots are.",
                    "label": 0
                },
                {
                    "sent": "DNA.",
                    "label": 0
                },
                {
                    "sent": "Matter, so we have nucleotides.",
                    "label": 0
                },
                {
                    "sent": "We have this guy here which is Plasmodium.",
                    "label": 0
                },
                {
                    "sent": "So this is the this is the parasite and here we've got in its engagement ring stage.",
                    "label": 0
                },
                {
                    "sent": "There's a kind of ring with a form nucleus on there and when you speak to lab technicians about what they're looking for, they explain the pattern in those kind of terms.",
                    "label": 0
                },
                {
                    "sent": "I'm looking for engagement rings or I'm looking for a comma or a pair of headphones where there's two nuclei and some connecting matter between them.",
                    "label": 0
                },
                {
                    "sent": "Now, if you could take these images and automatically from this image be able to identify, here's where the parasite is.",
                    "label": 0
                },
                {
                    "sent": "That would be an application of enormous value.",
                    "label": 0
                },
                {
                    "sent": "We could start to automate the testing process, so even where experts are not available to.",
                    "label": 0
                },
                {
                    "sent": "To look through the microscope, we might be able to make some headway on being able to do that automatically.",
                    "label": 0
                },
                {
                    "sent": "So let's think about the uncertainty in here.",
                    "label": 0
                },
                {
                    "sent": "When we have an image.",
                    "label": 0
                },
                {
                    "sent": "Let's think about the space.",
                    "label": 0
                },
                {
                    "sent": "The input space of possible images.",
                    "label": 0
                },
                {
                    "sent": "OK, assuming every pixel in this image has three values, are red, green and blue, and each of those three values could be anyone of 255 different values, then we've got 255 * 255 * 255 combinations that one pixel could have taken, so we already have a huge number of.",
                    "label": 0
                },
                {
                    "sent": "Values that that that one pixel could take on.",
                    "label": 0
                },
                {
                    "sent": "Now if we look at the whole image, it's a gigantic number, you know.",
                    "label": 0
                },
                {
                    "sent": "So the point here is that if we have examples of the behavior we like, that might still be covering a very small part of the input space.",
                    "label": 0
                },
                {
                    "sent": "So the set of examples we have, even if we think we have several.",
                    "label": 1
                },
                {
                    "sent": "If you look at the space that images can take, in general it's very small, so we can't.",
                    "label": 0
                },
                {
                    "sent": "Obviously we can't just memorize images, we can't just take examples and think, OK, I've seen this image that's got a parasite in it.",
                    "label": 0
                },
                {
                    "sent": "I've seen this one.",
                    "label": 0
                },
                {
                    "sent": "It's not a parasite in it because we're never going to get the same image twice, so we need to be able to deal with that lack of specification of the problem.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK here is.",
                    "label": 0
                },
                {
                    "sent": "The traffic in Kampala which I would say is marginally more chaotic than a krivan, at least at least here.",
                    "label": 0
                },
                {
                    "sent": "Guys don't tend to drive on the pavement and you know.",
                    "label": 0
                },
                {
                    "sent": "That kind of thing.",
                    "label": 0
                },
                {
                    "sent": "I think it's a bit more organized if you have a CCTV video stream like this and you're getting a real time feed from cameras around the around the center of the city where you live.",
                    "label": 1
                },
                {
                    "sent": "Imagine if you were able to derive some high level information from this video stream.",
                    "label": 0
                },
                {
                    "sent": "If you could tell how fast the traffic is moving, is it moving normally?",
                    "label": 0
                },
                {
                    "sent": "Is there some anomalous?",
                    "label": 0
                },
                {
                    "sent": "Phenomenon in there, which maybe maybe an accident or maybe something unusual happening.",
                    "label": 0
                },
                {
                    "sent": "That would be useful things to workout and you know, pretty you know, a pretty tough kind of inference problem.",
                    "label": 0
                },
                {
                    "sent": "If you were able to work that out from the video data, then a whole new set of questions arises which also have some uncertainty.",
                    "label": 0
                },
                {
                    "sent": "Could you predict the traffic characteristics?",
                    "label": 0
                },
                {
                    "sent": "Tomorrow at a particular junction, how much traffic is going to be there, and I've been trying to do this for my three years in Kampala and complete.",
                    "label": 0
                },
                {
                    "sent": "It always takes me by surprise where there's where there's going to be congestion.",
                    "label": 0
                },
                {
                    "sent": "Sometimes the roads are fine when you're expecting it to be a nightmare.",
                    "label": 0
                },
                {
                    "sent": "You know, I can't really figure it out, but if we had enough data then maybe we could do this automatically.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Alright, here's an example which is not so specific to here, but one that will try out a bit later if we have speech to text, we may have an input recording some sounds, so a sound when you record it is just a sequence of numbers, just that it's several numbers.",
                    "label": 0
                },
                {
                    "sent": "You know, maybe 44,000 times per second you you take a sample from this input signal, you get the sequence.",
                    "label": 1
                },
                {
                    "sent": "You could represent that as a time versus frequency.",
                    "label": 0
                },
                {
                    "sent": "Clocks here there's a spectrogram.",
                    "label": 0
                },
                {
                    "sent": "Ann from these spectral spectral information here you could try to work out what's being said.",
                    "label": 1
                },
                {
                    "sent": "This is a recording of my favorite poems for Ted Hughes.",
                    "label": 0
                },
                {
                    "sent": "And that's an example which will look at it a bit, and obviously you know fairly complicated one, partly because of the size of the input space.",
                    "label": 0
                },
                {
                    "sent": "Again, we've got so many so many numbers here, you know 500,000.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Numbers in a sequence.",
                    "label": 0
                },
                {
                    "sent": "OK, well think a bit about on in general terms how to deal with this uncertainty.",
                    "label": 0
                },
                {
                    "sent": "It's going to be a bit a bit vague here.",
                    "label": 0
                },
                {
                    "sent": "Give you some general notion of what we're doing, then we'll go back to looking at some more examples of the types of motivating applications we're interested in.",
                    "label": 0
                },
                {
                    "sent": "So one thing is immediately clear if we didn't make any assumptions about our problems, we couldn't learn anything.",
                    "label": 0
                },
                {
                    "sent": "If we lived in a white noise world where everything was completely random and we were continually surprised by our senses, we had no idea what to expect at anytime.",
                    "label": 0
                },
                {
                    "sent": "We wouldn't be able to learn anything.",
                    "label": 1
                },
                {
                    "sent": "It's only by making assumption or having some bias towards what you already expect to be happening in the world that you can begin to make headway on these problems.",
                    "label": 0
                },
                {
                    "sent": "So humans have various kind of biases about the things they expect to expect to receive in their senses.",
                    "label": 0
                },
                {
                    "sent": "The things biases about the types of ways they might represent the external world, and we're so good at seeing patterns that quite often we see them even when they're not really there.",
                    "label": 1
                },
                {
                    "sent": "So usually there's two kinds of assumptions which are fundamental to pretty much all machine learning work, which allow us to make a start on solving these problems.",
                    "label": 1
                },
                {
                    "sent": "The first one is smoothness, and this is.",
                    "label": 0
                },
                {
                    "sent": "This is something you basically always assume that if you have some function, say images too.",
                    "label": 0
                },
                {
                    "sent": "Label on disease.",
                    "label": 0
                },
                {
                    "sent": "You would assume that if the input changes a little bit, then the output might change a little bit or not at all.",
                    "label": 1
                },
                {
                    "sent": "So if you have some image you've received and you know the label, you know the output of this function.",
                    "label": 0
                },
                {
                    "sent": "If you receive another image and it's almost the same but just a little bit different then then we assume the same kind of output.",
                    "label": 1
                },
                {
                    "sent": "The next one is simplicity.",
                    "label": 0
                },
                {
                    "sent": "And basically models which are which have fewer variables, fewer kind of knobs to twiddle.",
                    "label": 0
                },
                {
                    "sent": "We prefer those over complicated ones.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we're biased towards seeing those kind of patterns and the things we're looking at.",
                    "label": 0
                },
                {
                    "sent": "Right?",
                    "label": 0
                },
                {
                    "sent": "Well just look at a few more kind of Canonical machine learning tasks.",
                    "label": 0
                },
                {
                    "sent": "Just to give us a few examples to work with later on.",
                    "label": 0
                },
                {
                    "sent": "And it's a pretty exciting time to be working in machine learning.",
                    "label": 1
                },
                {
                    "sent": "Incidentally, we have.",
                    "label": 0
                },
                {
                    "sent": "We've had these problems around for a long time, and I think fields at a stage now where these are being robust.",
                    "label": 0
                },
                {
                    "sent": "Ified were being able not just to do face recognition, handwriting recognition, but we're being able to on this gigantic global scale.",
                    "label": 0
                },
                {
                    "sent": "Speech recognition is pretty robust now when you when you try it out.",
                    "label": 0
                },
                {
                    "sent": "So here's another example you might want to have images of handwritten digits.",
                    "label": 1
                },
                {
                    "sent": "There's a great deal of variability in how someone might draw an image, and given a new image, let's try and work out which which digit the person intended.",
                    "label": 0
                },
                {
                    "sent": "What do they have in mind when they were making those shapes on the page?",
                    "label": 0
                },
                {
                    "sent": "So there's a gigantic Canonical database which a lot of people considered to be a good good testing ground for new algorithms.",
                    "label": 1
                },
                {
                    "sent": "And if you think about having to go about this.",
                    "label": 0
                },
                {
                    "sent": "Or even just a two class problem where you get some input and it's in a little square and you want to know whether it's a one or a 2.",
                    "label": 0
                },
                {
                    "sent": "Maybe you'd start to think about crafting crafting rules.",
                    "label": 0
                },
                {
                    "sent": "We're going to look at something where we basically take a great deal of data and try to have models which learned, learn the patterns within that data.",
                    "label": 0
                },
                {
                    "sent": "Now you might be thinking alright.",
                    "label": 0
                },
                {
                    "sent": "The difficulty here comes from the fact that a handwritten digit could be, you know, someone can make a make a make a scratch on the page any any kind of manner, and there's a lot of variability within that and maybe printed character recognition is much easier.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Well, that could also be tricky here.",
                    "label": 1
                },
                {
                    "sent": "We've got a number of characters which are all the letter A and when we look at these we can see immediately that they're all the letter A.",
                    "label": 0
                },
                {
                    "sent": "But if you if you try to think about what's the essence of each of these, what's the invariants?",
                    "label": 1
                },
                {
                    "sent": "Is there some regularity between each of these patterns that we could somehow encode?",
                    "label": 0
                },
                {
                    "sent": "It's, you know, it seems trickier than that.",
                    "label": 0
                },
                {
                    "sent": "It might at 1st, and there's this great paper by Doug Hofstadter, which is well worth a read this question.",
                    "label": 0
                },
                {
                    "sent": "So you know, finding this invariants, the pattern or interest in might not be.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "As easy as we think.",
                    "label": 0
                },
                {
                    "sent": "So the data could come in all sorts of forms.",
                    "label": 0
                },
                {
                    "sent": "We could have video data, image data.",
                    "label": 0
                },
                {
                    "sent": "It could be time series data, so here are some examples of measurements of vibrations in the ground at different times when they were here.",
                    "label": 1
                },
                {
                    "sent": "3 earthquakes at the top and at the bottom here 3 mining detonations underground.",
                    "label": 0
                },
                {
                    "sent": "And if you had some equipment which was measuring vibrations in the ground and you felt some disturbance in the earth.",
                    "label": 0
                },
                {
                    "sent": "Probably quite interested in knowing whether that's an earthquake or an explosion could have big implications for you, so trying to distinguish between these two things, if you've got some examples, you have some new set of vibrations that's going to be a significant task, and it's not really immediately obvious how to do that from the from the data here.",
                    "label": 0
                },
                {
                    "sent": "So one thing we might think about here is the data we're looking at, just doesn't.",
                    "label": 0
                },
                {
                    "sent": "We look at it, and we can't see.",
                    "label": 0
                },
                {
                    "sent": "What information it has about the about the problem we are interested in.",
                    "label": 0
                },
                {
                    "sent": "So we're going to think about RE representing data in order.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To be more effective.",
                    "label": 0
                },
                {
                    "sent": "Doing this kind of distinction.",
                    "label": 0
                },
                {
                    "sent": "Get back to Africa.",
                    "label": 0
                },
                {
                    "sent": "Castle Castle for viral Disease is a big problem in Uganda and here is some healthy leaves and.",
                    "label": 0
                },
                {
                    "sent": "Disease called classical music.",
                    "label": 0
                },
                {
                    "sent": "And music's got this quite distinctive visual appearance, which means that you can actually do pretty well at distinguishing between healthy and disease leaves given given just the image and just a reasonably poor quality image from a camera phone.",
                    "label": 0
                },
                {
                    "sent": "So if you have a large set of images like this, then another application we could be interested in is.",
                    "label": 0
                },
                {
                    "sent": "A survey tool.",
                    "label": 0
                },
                {
                    "sent": "Someone goes into the field.",
                    "label": 0
                },
                {
                    "sent": "You've got some survey team.",
                    "label": 0
                },
                {
                    "sent": "They're taking snaps with their camera phone, and if we can automatically diagnose whether their disease, which disease they have, are the crops under stress in some way.",
                    "label": 0
                },
                {
                    "sent": "If we can get that information, then we can do surveys.",
                    "label": 0
                },
                {
                    "sent": "Larger scale surveys.",
                    "label": 0
                },
                {
                    "sent": "Without requiring a small number of highly trained experts, which is the bottleneck at the moment in such service?",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So having established information like that, maybe from the kind of mobile phone based system, there could be other questions were interested in like this kind of geospatial analysis.",
                    "label": 0
                },
                {
                    "sent": "If we've got some some density in space of disease, disease incidents across the country perhaps, and we have some inputs from our survey which maybe maybe this kind of automatic thing, or it may be traditional survey techniques and we see you know ones if we take that to denote a.",
                    "label": 0
                },
                {
                    "sent": "A perfectly healthy plant and five to denote the worst level of disease possible where the plant actually dying.",
                    "label": 0
                },
                {
                    "sent": "Back then, given our points, we might want to workout where what's the coverage of disease across the rest of the cross.",
                    "label": 1
                },
                {
                    "sent": "The rest of the field, so you know at points AB&C, what do we predict is happening there?",
                    "label": 0
                },
                {
                    "sent": "We weren't able to send a survey team there, but there's a tyrant at that place and we want to know if we need to make some intervention.",
                    "label": 0
                },
                {
                    "sent": "That's a question we could be interested in.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "To.",
                    "label": 0
                },
                {
                    "sent": "Alright, here's the last application face recognition of the Canonical machine learning task, particularly important if you're a kind of badass assassination robot from the future.",
                    "label": 0
                },
                {
                    "sent": "I.",
                    "label": 0
                },
                {
                    "sent": "What are the examples have in common is that we're learning some kind of function.",
                    "label": 0
                },
                {
                    "sent": "We've got some inputs and outputs these examples.",
                    "label": 1
                },
                {
                    "sent": "We want to learn what's the mapping between the two.",
                    "label": 0
                },
                {
                    "sent": "We've got some kind of assumptions to help us limit hypothesis about what types of mappings there might be.",
                    "label": 0
                },
                {
                    "sent": "But this type of problem is something known as supervised learning, so I think we'll we'll start to get into the details of that.",
                    "label": 1
                },
                {
                    "sent": "So I'm going to.",
                    "label": 0
                },
                {
                    "sent": "Talk for a bit about different techniques that we can use to do supervised learning.",
                    "label": 0
                },
                {
                    "sent": "I'm going to introduce some notation to do that.",
                    "label": 0
                },
                {
                    "sent": "Do we have any questions at this stage about the applications we've seen?",
                    "label": 0
                },
                {
                    "sent": "The concepts we've had so far?",
                    "label": 0
                },
                {
                    "sent": "Alright.",
                    "label": 0
                },
                {
                    "sent": "OK Sir, we need some notation to get anywhere.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I'm going to introduce Atlanta to sweeten the pill a bit less.",
                    "label": 0
                },
                {
                    "sent": "Let's stick with the Terminator alright to do any kind of supervised learning task.",
                    "label": 1
                },
                {
                    "sent": "We need a label training data.",
                    "label": 0
                },
                {
                    "sent": "We need a number of.",
                    "label": 0
                },
                {
                    "sent": "Of samples from our input space and we need to know the corresponding output of the function that we're trying to learn.",
                    "label": 0
                },
                {
                    "sent": "So here's here's some input samples, and here's the probability of this being a particular class.",
                    "label": 0
                },
                {
                    "sent": "So it doesn't always have to be probability, but we're going to look at it that way.",
                    "label": 0
                },
                {
                    "sent": "And given our training data and our test data we've got.",
                    "label": 0
                },
                {
                    "sent": "For example, two things that we might want to.",
                    "label": 0
                },
                {
                    "sent": "We might want our learning machine to output.",
                    "label": 0
                },
                {
                    "sent": "First, one might be the most likely class.",
                    "label": 0
                },
                {
                    "sent": "What's the C which maximizes the probability of Pfc given X?",
                    "label": 0
                },
                {
                    "sent": "We might also commonly be interested in out putting an action, so if we have some kind of loss matrix which tells you if you got it wrong, how bad would that be then?",
                    "label": 0
                },
                {
                    "sent": "You can sum up over all those possible losses, weighted by the probability of how much you think each classes and that gives you the class.",
                    "label": 0
                },
                {
                    "sent": "You should think it is if you're going to minimize your loss.",
                    "label": 0
                },
                {
                    "sent": "So obviously if you're the Terminator, you don't really have that bigger loss about the old accidental termination, you just terminate everyone.",
                    "label": 0
                },
                {
                    "sent": "But if you're diagnosing cancer or something like that, you might be much more concerned about false negatives than you are about false positives.",
                    "label": 0
                },
                {
                    "sent": "We don't mind the occasional false alarm, but it's very important not to miss anybody, so the loss matrix might wait your inference so that you're kind of biased towards positive rather than negative.",
                    "label": 0
                },
                {
                    "sent": "OK, so that's our notation.",
                    "label": 0
                },
                {
                    "sent": "So now the big question is this P of C given X, how do we?",
                    "label": 0
                },
                {
                    "sent": "How do we get into that?",
                    "label": 0
                },
                {
                    "sent": "That's the quantity which we want to.",
                    "label": 0
                },
                {
                    "sent": "We want to learn before we learn.",
                    "label": 0
                },
                {
                    "sent": "How do we even write it down?",
                    "label": 0
                },
                {
                    "sent": "How do we?",
                    "label": 0
                },
                {
                    "sent": "How do we represent this?",
                    "label": 0
                },
                {
                    "sent": "Well, let's take an example, a simple.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "A simple way to get a bit further into this.",
                    "label": 0
                },
                {
                    "sent": "Now let's imagine we've got a 2 dimensional input space.",
                    "label": 0
                },
                {
                    "sent": "We've got two axes values on both axes will expect to be positive reals, and imagine these are the Heights and weights of two different types of animals.",
                    "label": 1
                },
                {
                    "sent": "We've gone into the field.",
                    "label": 0
                },
                {
                    "sent": "We've captured a number of animals, recorded their Heights and weights, and we plotted them on a graph.",
                    "label": 0
                },
                {
                    "sent": "It looks a bit like this.",
                    "label": 0
                },
                {
                    "sent": "So these are your animals of type one.",
                    "label": 0
                },
                {
                    "sent": "These are animals of type 2.",
                    "label": 0
                },
                {
                    "sent": "So these are the positions.",
                    "label": 0
                },
                {
                    "sent": "Here are the X is the weather there a red circle or blue diamond is the see that's the class.",
                    "label": 1
                },
                {
                    "sent": "And given a new example, we have just the X.",
                    "label": 1
                },
                {
                    "sent": "We want to know is see the red circle or the blue diamond type.",
                    "label": 1
                },
                {
                    "sent": "So this this business of trying to take the probability of C given X where you might try to answer that by proposing a decision boundary.",
                    "label": 0
                },
                {
                    "sent": "So let's say there's a linear boundary.",
                    "label": 1
                },
                {
                    "sent": "The further we get on this side, the more likely The thing is to be in the blue diamond type of animal and the further The thing is on this side, the more likely it is to be a red circle.",
                    "label": 0
                },
                {
                    "sent": "An if we get something which is exactly on the decision boundary, then we don't know.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So let's see how we would.",
                    "label": 0
                },
                {
                    "sent": "How we would formulate this a bit more explicitly?",
                    "label": 0
                },
                {
                    "sent": "We can do if we've got something which is dealing with lines or planes or hyperplanes.",
                    "label": 0
                },
                {
                    "sent": "Everything is linear, everything is just multiplication.",
                    "label": 0
                },
                {
                    "sent": "Sums makes it makes it pretty easy.",
                    "label": 0
                },
                {
                    "sent": "The kind of things we're doing yesterday.",
                    "label": 0
                },
                {
                    "sent": "So if we had 1D imagine we were only measuring the weights of different animals and these are two classes, and in this example there conveniently well separated and we could draw a boundary.",
                    "label": 0
                },
                {
                    "sent": "We could have some point, and if the.",
                    "label": 0
                },
                {
                    "sent": "Value is greater than that point then.",
                    "label": 0
                },
                {
                    "sent": "That is one class if it's less than that, it's another.",
                    "label": 0
                },
                {
                    "sent": "So let's write that down as quantity X1, which is the variable that we observe.",
                    "label": 0
                },
                {
                    "sent": "Times this thing W one that's like a weight and B is some offset and.",
                    "label": 0
                },
                {
                    "sent": "If we find some W&B.",
                    "label": 0
                },
                {
                    "sent": "Which effectively gives us some threshold on the input space.",
                    "label": 0
                },
                {
                    "sent": "Where that zero?",
                    "label": 0
                },
                {
                    "sent": "That's the decision boundary.",
                    "label": 0
                },
                {
                    "sent": "We don't know which class it's in.",
                    "label": 0
                },
                {
                    "sent": "If this quantity X * W + B is greater, then we say it's in one class, and if it's less than it's in another class.",
                    "label": 0
                },
                {
                    "sent": "So in 2D pretty similar kind of thing, we're just we're just introducing another variable here and now we've got.",
                    "label": 0
                },
                {
                    "sent": "Alayna csardas",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Boundary.",
                    "label": 0
                },
                {
                    "sent": "And so I think you can.",
                    "label": 0
                },
                {
                    "sent": "Kind of see the pattern here, and I think this might be something you did you did yesterday.",
                    "label": 0
                },
                {
                    "sent": "We can keep generalizing this and we find that the linear decision boundary is expressed by a weight vector times are input vector plus some scalar offset, so this is.",
                    "label": 0
                },
                {
                    "sent": "So there's an interpretation for the W, which is W. Is this?",
                    "label": 0
                },
                {
                    "sent": "It's a vector.",
                    "label": 0
                },
                {
                    "sent": "And the way that vector points is, it's perpendicular to the decision boundary, so that's a vector pointing.",
                    "label": 1
                },
                {
                    "sent": "This way, the decision boundary is going to be something.",
                    "label": 1
                },
                {
                    "sent": "Something perpendicular to that.",
                    "label": 0
                },
                {
                    "sent": "It's going to be orthogonal, and then the B is going to be something which moves that in One Direction or another from the origin.",
                    "label": 0
                },
                {
                    "sent": "So this quantity gives you for some input space.",
                    "label": 0
                },
                {
                    "sent": "If you find your WMB appropriately, you get zeros for the values of X which lie exactly on the boundary, they become increasingly positive on One Direction, increasingly negative on the other.",
                    "label": 0
                },
                {
                    "sent": "OK, so we're.",
                    "label": 0
                },
                {
                    "sent": "So now we have a way of formulating this.",
                    "label": 0
                },
                {
                    "sent": "This type of boundary this this is not quite given the probability yet, but we've got some quantity at least which separates the input space in some way.",
                    "label": 0
                },
                {
                    "sent": "So at this stage I want to take an example.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And this is something.",
                    "label": 0
                },
                {
                    "sent": "Came up with for two to illustrate this here.",
                    "label": 0
                },
                {
                    "sent": "So last week I sat in my office and I recorded myself saying words yes and no several times and distinguishing being able to distinguish progressing no.",
                    "label": 1
                },
                {
                    "sent": "I hope you agree.",
                    "label": 0
                },
                {
                    "sent": "That's kind of a useful thing to be able to do.",
                    "label": 0
                },
                {
                    "sent": "Imagine writing some software which expected a voice prompt and we needed some simple way of getting microphone input and being able to tell whether the person said yes or no.",
                    "label": 0
                },
                {
                    "sent": "So here's our input space.",
                    "label": 0
                },
                {
                    "sent": "And just like the earthquakes and explosions.",
                    "label": 0
                },
                {
                    "sent": "Pretty difficult to see.",
                    "label": 0
                },
                {
                    "sent": "Really what to do with this input space?",
                    "label": 0
                },
                {
                    "sent": "It's pretty complicated.",
                    "label": 0
                },
                {
                    "sent": "So you might be thinking at this stage.",
                    "label": 0
                },
                {
                    "sent": "OK, this is an application which looks useful.",
                    "label": 1
                },
                {
                    "sent": "The things we saw on the preceding slides about the linear decision boundary.",
                    "label": 0
                },
                {
                    "sent": "Looks fine, but isn't that much too simple to really be able to deal with any any real world complex problem like this.",
                    "label": 0
                },
                {
                    "sent": "So let's see how this problem can be solved with the concepts that we just saw in the previous slides.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Alright, first of all, the data that we have in its raw form is no use to us.",
                    "label": 0
                },
                {
                    "sent": "We need to have.",
                    "label": 0
                },
                {
                    "sent": "Something more informative about the kinds of things we're looking at.",
                    "label": 0
                },
                {
                    "sent": "So let's do some spectrogram transformation of this data.",
                    "label": 1
                },
                {
                    "sent": "We want to look at here is time.",
                    "label": 0
                },
                {
                    "sent": "Here is the duration of the sample, and here are frequency levels.",
                    "label": 0
                },
                {
                    "sent": "This is actually plotted with lowest frequencies at the site.",
                    "label": 1
                },
                {
                    "sent": "In higher frequencies at this side.",
                    "label": 0
                },
                {
                    "sent": "So each of these each of these columns here is a little Fourier transform.",
                    "label": 0
                },
                {
                    "sent": "And where at that instant there was some kind of low frequency component in my voice that shows up as a hot color here, and where that frequency component was lower than that shows a cool color.",
                    "label": 0
                },
                {
                    "sent": "So we got three guesses, three nodes, and now we can you know, if you really squint at this for awhile and you try to work out what's going on, you can start to make some distinction between these two two types of classes.",
                    "label": 1
                },
                {
                    "sent": "So you know, visually inspecting this, we could start to see some differences like there's you know the yes, have this kind of yellow cloud over here, whereas the nose don't really.",
                    "label": 0
                },
                {
                    "sent": "There's kind of three stages to the yes, which actually is like the three different.",
                    "label": 0
                },
                {
                    "sent": "I guess it's like the three different sort of shapes that my mouse took when I was saying the word, yes.",
                    "label": 0
                },
                {
                    "sent": "I guess that's a yes something like that, whereas no is kind of 1 long.",
                    "label": 0
                },
                {
                    "sent": "That vowel sound is more consistent.",
                    "label": 0
                },
                {
                    "sent": "And this thing here it could be quite informative the the S of yes when I make that noise that's more like white noise, which we know is something that has frequent power across all frequencies.",
                    "label": 0
                },
                {
                    "sent": "So during the well I'm uttering the end of the word yes, then we'd expect to see this high frequency component.",
                    "label": 0
                },
                {
                    "sent": "No, doesn't have anything quite like that.",
                    "label": 0
                },
                {
                    "sent": "Alright, so there's a.",
                    "label": 0
                },
                {
                    "sent": "There's a start to being able to distinguish between these two things, so we could do some kind of what we're going to call feature engineering.",
                    "label": 0
                },
                {
                    "sent": "And let's say the.",
                    "label": 0
                },
                {
                    "sent": "The most interesting part here is these.",
                    "label": 0
                },
                {
                    "sent": "These kind of bands here.",
                    "label": 0
                },
                {
                    "sent": "If all my inputs are either going to be a sore nose, then one informative part of this data could be just this band here.",
                    "label": 0
                },
                {
                    "sent": "So here we expect to see something of high power at some point, but not all the time, and.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Are we expected to be low power throughout the veterans?",
                    "label": 0
                },
                {
                    "sent": "So what we can do is take an average of that band across the length of the sample.",
                    "label": 1
                },
                {
                    "sent": "And here I've done the.",
                    "label": 0
                },
                {
                    "sent": "The yeses in red and the nose and blue and this is for those rows of the spectrogram.",
                    "label": 0
                },
                {
                    "sent": "I've averaged that up over the over the frequencies were interested in.",
                    "label": 0
                },
                {
                    "sent": "And part of that here, so they're all different lengths, but we can start to see some kind of distinction here the the this kind of bumping the yes frequencies where I get to saying the word S whereas the nose tend to be low power throughout.",
                    "label": 0
                },
                {
                    "sent": "Now if I take 2 samples 22 features from this deals we make it even simpler.",
                    "label": 0
                },
                {
                    "sent": "Let's say I just take the Max and the variance of each of these sequences here.",
                    "label": 0
                },
                {
                    "sent": "And that gives me a 2 dimensional representation of each input data point.",
                    "label": 1
                },
                {
                    "sent": "Then we get something like this.",
                    "label": 0
                },
                {
                    "sent": "So plotting this here we can now see we've got it right down to this 2 dimensional description where we might be able to use some kind of linear classifier.",
                    "label": 0
                },
                {
                    "sent": "Ha.",
                    "label": 0
                },
                {
                    "sent": "OK, so now we're at a stage where we've we've made this.",
                    "label": 0
                },
                {
                    "sent": "We've got this input space, which is pretty complicated.",
                    "label": 0
                },
                {
                    "sent": "You know, several hundreds of thousands of numbers in one long sequence which progressively made it simpler and simpler.",
                    "label": 1
                },
                {
                    "sent": "Just trying to keep the information we're interested in and throw away extra information that we don't need until we've taken maybe 500,000 numbers.",
                    "label": 0
                },
                {
                    "sent": "Variable depending on the length of the sample, and we've condensed all that down into 2 numbers which are kind of features of this thing here.",
                    "label": 0
                },
                {
                    "sent": "And these two numbers we think are quite informative about the problem that we have.",
                    "label": 0
                },
                {
                    "sent": "Alright, the data and code for this are available on my website, by the way, we should find a link there on the software page with all the samples.",
                    "label": 0
                },
                {
                    "sent": "If you want to hear me saying no, no, no over and over again like a maniac them.",
                    "label": 0
                },
                {
                    "sent": "The opportunity is there alright, so let's take this as our R2D example, something a bit more interesting than classifying types of animals.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And let's go back to.",
                    "label": 0
                },
                {
                    "sent": "Linear classification let's try and actually actually do this.",
                    "label": 0
                },
                {
                    "sent": "Alright Sir, we need to.",
                    "label": 0
                },
                {
                    "sent": "We've got some idea that we have this 2 dimensional data which somehow can be split up by bioline.",
                    "label": 0
                },
                {
                    "sent": "And we need to come up with some way of choosing a line.",
                    "label": 0
                },
                {
                    "sent": "We need to somehow draw a line somewhere in this 2D space so that we split up our our data in a good way.",
                    "label": 0
                },
                {
                    "sent": "Well, how could we do that?",
                    "label": 1
                },
                {
                    "sent": "Let's take the simplest thing we could do.",
                    "label": 1
                },
                {
                    "sent": "The thing with the least programming, which is let's choose a completely random line.",
                    "label": 0
                },
                {
                    "sent": "When I say random, there's actually some details there, which I'm kind of going to cure for you.",
                    "label": 0
                },
                {
                    "sent": "But let's take lines, all of which we before we've seen any data we think are equally likely.",
                    "label": 1
                },
                {
                    "sent": "And then we'll see which ones match and will will keep the ones which match and look at them.",
                    "label": 1
                },
                {
                    "sent": "So we've got two things to be able to work out there.",
                    "label": 0
                },
                {
                    "sent": "One is how can we generate Lions and the other is how can we see if anyone line matches the data we have and neither of those are very challenging actually.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "If we.",
                    "label": 0
                },
                {
                    "sent": "If you want to generate many lines, we can represent a line uniquely with a single point on on the on the 2D plane.",
                    "label": 1
                },
                {
                    "sent": "If we have some.",
                    "label": 0
                },
                {
                    "sent": "Origin we probably want to take the origin.",
                    "label": 0
                },
                {
                    "sent": "Is that the mean of our data points?",
                    "label": 0
                },
                {
                    "sent": "Something like that.",
                    "label": 0
                },
                {
                    "sent": "If we generate any point somewhere.",
                    "label": 1
                },
                {
                    "sent": "So we could have points at random if we take the vector from the origin to that point, and then we have that as a scaled version of RWR wait.",
                    "label": 0
                },
                {
                    "sent": "Then this is something which is perpendicular to the to the.",
                    "label": 1
                },
                {
                    "sent": "The.",
                    "label": 0
                },
                {
                    "sent": "Decision boundary, so for all these random points we generate.",
                    "label": 0
                },
                {
                    "sent": "We can draw a bunch of loans.",
                    "label": 0
                },
                {
                    "sent": "And that's where these lines come from.",
                    "label": 0
                },
                {
                    "sent": "Here in the example that you can try.",
                    "label": 0
                },
                {
                    "sent": "And there's a few details I kind of alluded to that you you want to be a bit careful about how you draw these lines, and you can check this easily by just plotting many lines that are drawing and seeing that there are being generated in the right way.",
                    "label": 0
                },
                {
                    "sent": "It's easy to, it's easy to generate lines in such a way that you are actually covering more of the input space with lines in some area in some regions than others.",
                    "label": 0
                },
                {
                    "sent": "Let's assume that we've come up with some way of generating lines that we're happy with.",
                    "label": 0
                },
                {
                    "sent": "It seems to be covering the space that we.",
                    "label": 0
                },
                {
                    "sent": "The space of decision boundaries uniformly according to what we think is likely before we've seen any data.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Alright, so we know how to generate lines.",
                    "label": 0
                },
                {
                    "sent": "Now we need to distinguish between lines, which seem to be.",
                    "label": 0
                },
                {
                    "sent": "Which seemed to be appropriate or consistent in some way with the data that we've that we've seen.",
                    "label": 0
                },
                {
                    "sent": "So let's introduce a new concept of likelihood.",
                    "label": 0
                },
                {
                    "sent": "Given that we've received some data, how likely is it that one particular line is the right line?",
                    "label": 0
                },
                {
                    "sent": "So let's have a simple measure for this, so we've got something which will express as a probability.",
                    "label": 1
                },
                {
                    "sent": "And we'll say, well, this is essentially saying is that for some line, if this line splits up the data perfectly, so all the yeses are on the positive side and all the nodes on the negative side, then that particular line has probability one.",
                    "label": 1
                },
                {
                    "sent": "Anne.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "If it doesn't, then it has probability 0, so all that is essentially saying.",
                    "label": 0
                },
                {
                    "sent": "Is.",
                    "label": 0
                },
                {
                    "sent": "Let's generate a whole bunch of lines, so I think he regenerated maybe like 1000 lines and we'll look at the ones which have probability probability one, so the ones where all the all the red pluses on the positive side of the line and all the blue plus is on the negative side of line.",
                    "label": 0
                },
                {
                    "sent": "Alright, so we've generated a whole bunch of lines which which fit.",
                    "label": 0
                },
                {
                    "sent": "So now we've got some choices we could.",
                    "label": 0
                },
                {
                    "sent": "We could stop there.",
                    "label": 0
                },
                {
                    "sent": "We could take one of the lines at random and say, OK, all of these of these lines fit our training data in some ways.",
                    "label": 0
                },
                {
                    "sent": "So we just we just choose one and that's going to be what will use to distinguish knew new test examples.",
                    "label": 0
                },
                {
                    "sent": "Or we could look at all of these lines.",
                    "label": 0
                },
                {
                    "sent": "Try to do something else with them.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So let's do the latter.",
                    "label": 0
                },
                {
                    "sent": "And I'm going to give you another.",
                    "label": 0
                },
                {
                    "sent": "Another concept here, which is the use of.",
                    "label": 0
                },
                {
                    "sent": "The use of Bayes rule to help with this kind of problem.",
                    "label": 0
                },
                {
                    "sent": "So Bayes rule.",
                    "label": 0
                },
                {
                    "sent": "Basic basic property of joint and conditional probabilities.",
                    "label": 0
                },
                {
                    "sent": "When people talk about Bayesian methods, the.",
                    "label": 0
                },
                {
                    "sent": "The insight that's using is that Bayes rule doesn't just have to be about things that statisticians usually call random variables.",
                    "label": 0
                },
                {
                    "sent": "You could also be reasoning about the probability of different parameters, which is a fundamental change in statistical method from what was classically applied.",
                    "label": 0
                },
                {
                    "sent": "It used to be that a parameter with some quantity that you couldn't reason about with probabilities, but why not?",
                    "label": 0
                },
                {
                    "sent": "Let's give it a shot.",
                    "label": 0
                },
                {
                    "sent": "So if you are interested in the probability.",
                    "label": 0
                },
                {
                    "sent": "Of some parameters given some data.",
                    "label": 0
                },
                {
                    "sent": "Then you can use Bayes rule you.",
                    "label": 1
                },
                {
                    "sent": "You look at the likelihoods of different different data points, and you integrate this out over.",
                    "label": 0
                },
                {
                    "sent": "You so you use Bayes rule to give you a posterior probability of your parameter space.",
                    "label": 1
                },
                {
                    "sent": "Um?",
                    "label": 1
                },
                {
                    "sent": "So having obtained this kind of quantity here, which will look at an example of just now, we can then use this to make predictions about new data points.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "If we have a distribution over what we think our parameters should be, we've got something which represents the space of all possible lines, and we have some measure of how likely each line is.",
                    "label": 0
                },
                {
                    "sent": "Then we can actually use that distribution too.",
                    "label": 0
                },
                {
                    "sent": "To give us what's called a posterior probability given and you test data point where we don't know the.",
                    "label": 0
                },
                {
                    "sent": "The the output class.",
                    "label": 0
                },
                {
                    "sent": "For example, we could say what's the probability of this test data?",
                    "label": 0
                },
                {
                    "sent": "This X and this CR position, Anna label given all the data I've seen.",
                    "label": 0
                },
                {
                    "sent": "And here's another application of Bayes rule where we basically integrate over the whole parameter space, so we're saying.",
                    "label": 0
                },
                {
                    "sent": "We're taking all the lines that we that we know about.",
                    "label": 0
                },
                {
                    "sent": "Potentially including every single line in the possible space of lines that there could be where.",
                    "label": 0
                },
                {
                    "sent": "We're looking at how likely.",
                    "label": 0
                },
                {
                    "sent": "That line is given the training data that we've already received were then looking at.",
                    "label": 0
                },
                {
                    "sent": "How likely would that particular part of the test data be that class that we see in that X, the label and that position?",
                    "label": 0
                },
                {
                    "sent": "How likely would both of those be given some particular line, and we integrate that over every possible line?",
                    "label": 0
                },
                {
                    "sent": "So in our example, the parameters are what the lines are the W in the B and the data is the input position which was 2D in our.",
                    "label": 0
                },
                {
                    "sent": "In our speech example and see which is either yes or no in that example.",
                    "label": 0
                },
                {
                    "sent": "That's a bit confusing.",
                    "label": 0
                },
                {
                    "sent": "Let's let's look at an example.",
                    "label": 0
                },
                {
                    "sent": "OK, two questions.",
                    "label": 0
                },
                {
                    "sent": "Let's thank you first.",
                    "label": 0
                },
                {
                    "sent": "Density.",
                    "label": 0
                },
                {
                    "sent": "Is that for the yes or no?",
                    "label": 0
                },
                {
                    "sent": "We are.",
                    "label": 0
                },
                {
                    "sent": "We're looking at the density of different parameters, so the data is something that's fixed.",
                    "label": 0
                },
                {
                    "sent": "We've got some, we've got some data we've seen.",
                    "label": 0
                },
                {
                    "sent": "We've seen that we know where the data points are, so we kind of know what that density is and we're interested in where's.",
                    "label": 0
                },
                {
                    "sent": "Where's the good points in parameter space?",
                    "label": 0
                },
                {
                    "sent": "That seems to represent that data, so it's not the density of the data exactly, but the density of good parameters.",
                    "label": 0
                },
                {
                    "sent": "How likely are all the different possible length?",
                    "label": 0
                },
                {
                    "sent": "Yet another question there.",
                    "label": 0
                },
                {
                    "sent": "I wanted to know whether the objective over looking at base rule.",
                    "label": 0
                },
                {
                    "sent": "In this specific case of our example is to help us determine which of the lines makes the best fits, or we're looking at whether the data is on the other side.",
                    "label": 0
                },
                {
                    "sent": "Because this is a distribution of the lines or the distribution of the data, right?",
                    "label": 0
                },
                {
                    "sent": "That's a great question, yeah?",
                    "label": 0
                },
                {
                    "sent": "OK, so the distribution of the data again is something that we already know and what we're interested in is where, where should we put the best lines were interested in, you know?",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Going back to.",
                    "label": 0
                },
                {
                    "sent": "Going back to the the input data that we've got, let's remind ourselves of the task that's going on here.",
                    "label": 0
                },
                {
                    "sent": "We want to know if we take a new recording of someone saying something which could either be a yes or no and it arrives at some point in this space.",
                    "label": 0
                },
                {
                    "sent": "We want to know if that's a yes, or if it's a no.",
                    "label": 0
                },
                {
                    "sent": "The way that we are choosing to distinguish between that is with a line.",
                    "label": 0
                },
                {
                    "sent": "So the fundamental goal here is to work out where the lines are going, which places to put good lines.",
                    "label": 0
                },
                {
                    "sent": "So that is why we're interested in the distribution of possible lines given the data.",
                    "label": 0
                },
                {
                    "sent": "So, given that we've seen these things, what's the how likely do we think different different lines are?",
                    "label": 0
                },
                {
                    "sent": "So we actually watching the behavior of the lines to see how best we get these exactly.",
                    "label": 0
                },
                {
                    "sent": "Yeah, you got it spot on behavior.",
                    "label": 0
                },
                {
                    "sent": "So we're trying to find that is yeah.",
                    "label": 0
                },
                {
                    "sent": "Some detail follow noise, sure, yeah, So what do you want to detect to know that?",
                    "label": 0
                },
                {
                    "sent": "OK, this is their land access at the bank?",
                    "label": 0
                },
                {
                    "sent": "OK great great questions.",
                    "label": 0
                },
                {
                    "sent": "The what we've already got away.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Specifying the likelihoods so we can take a whole bunch of lines, and we can say.",
                    "label": 0
                },
                {
                    "sent": "We can say here is a bunch of lines which had equally high likelihood.",
                    "label": 0
                },
                {
                    "sent": "All of these have likelihood one, so so far we're saying all of these lines are equally equally likely and there's a whole other bunch of lines which we don't care about.",
                    "label": 0
                },
                {
                    "sent": "We're not asshole interested in them because they have likelihood 0.",
                    "label": 1
                },
                {
                    "sent": "OK, so we're trying to work out kind of which lines are better than other lines and at the moment we have a whole bunch of lines that we think are equally likely.",
                    "label": 0
                },
                {
                    "sent": "We sampled each of those, so we're trying to get a bit further by looking at the combination of all of these lands.",
                    "label": 0
                },
                {
                    "sent": "Were trying to see which kind of areas are covered up by by all of these.",
                    "label": 0
                },
                {
                    "sent": "So for a particular point here.",
                    "label": 0
                },
                {
                    "sent": "We are really interested in what should we think about the what should we infer about the class of a point which we receive here.",
                    "label": 0
                },
                {
                    "sent": "Someone make some noise.",
                    "label": 0
                },
                {
                    "sent": "They record it in the microphone.",
                    "label": 0
                },
                {
                    "sent": "We calculate these features and it's projected here in this 2D space.",
                    "label": 0
                },
                {
                    "sent": "Then what do we do with it here on some lines it's on the red side.",
                    "label": 0
                },
                {
                    "sent": "On some other lines on the blue side.",
                    "label": 0
                },
                {
                    "sent": "So what do we do?",
                    "label": 0
                },
                {
                    "sent": "And So what Bayes rule is trying to do is to look at some combination over our whole input space and give us some probability, not just a zero or a one of this point.",
                    "label": 0
                },
                {
                    "sent": "Here being a yes or a no or for any other point.",
                    "label": 0
                },
                {
                    "sent": "Let's look at what the result is when we do.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "When we run through.",
                    "label": 0
                },
                {
                    "sent": "This inference here.",
                    "label": 0
                },
                {
                    "sent": "So for each data point, will try and we'll try and integrate this over all the possible lines and we'll see what the output is.",
                    "label": 0
                },
                {
                    "sent": "And then maybe that will become more clear to you why we did it.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, what I've done here.",
                    "label": 0
                },
                {
                    "sent": "This data is.",
                    "label": 0
                },
                {
                    "sent": "I've sampled 10,000 lines.",
                    "label": 0
                },
                {
                    "sent": "And I've given each likelihood of 1 again if it splits up the two categories in the way we want and the likelihood of 0 if it doesn't.",
                    "label": 0
                },
                {
                    "sent": "And I've drawn this contour plot.",
                    "label": 1
                },
                {
                    "sent": "And this is drawn by looking at for each point what proportion of the Lions is it on the red side, and what proportion of the lines is it on the blue side.",
                    "label": 0
                },
                {
                    "sent": "So it's very easy to calculate this.",
                    "label": 0
                },
                {
                    "sent": "We have our.",
                    "label": 0
                },
                {
                    "sent": "Of our.",
                    "label": 0
                },
                {
                    "sent": "Space.",
                    "label": 0
                },
                {
                    "sent": "X1 and X2 and if I have a line with likelihood of 1.",
                    "label": 0
                },
                {
                    "sent": "Then on the posterior, I'll wait that I'm going to kind of shade in this color as.",
                    "label": 0
                },
                {
                    "sent": "Neria saying that given this setting of the parameter here, any inputs I receive in this space will think that's a red plus that's going to be me saying yes, and here it's going to be in the blue space.",
                    "label": 0
                },
                {
                    "sent": "It's me saying no.",
                    "label": 1
                },
                {
                    "sent": "OK, that's what we can do for a single a single line.",
                    "label": 0
                },
                {
                    "sent": "But now we're integrating over many lines, so let's take another one.",
                    "label": 0
                },
                {
                    "sent": "Say that line.",
                    "label": 0
                },
                {
                    "sent": "There also has likelihood of 1.",
                    "label": 1
                },
                {
                    "sent": "If I then shade in the.",
                    "label": 0
                },
                {
                    "sent": "The area there.",
                    "label": 0
                },
                {
                    "sent": "So this is with two samples lines and we're saying both of them have equal likelihood.",
                    "label": 0
                },
                {
                    "sent": "Now we've got kind of three different regions.",
                    "label": 0
                },
                {
                    "sent": "We've got a region where any input here is definitely.",
                    "label": 0
                },
                {
                    "sent": "We definitely infer that to be a blue plus we didn't for that to be somebody saying no in this region.",
                    "label": 0
                },
                {
                    "sent": "Here, each of these.",
                    "label": 0
                },
                {
                    "sent": "Each of these sections we have an intermediate probability.",
                    "label": 0
                },
                {
                    "sent": "This is.",
                    "label": 0
                },
                {
                    "sent": "This is data which one of one of the parameter sets would have predicted with a yes and one of them wouldn't have, and in this region here both of the lines that we've sampled so far would agree that it's a yes, so we've got definitely, you know, kind of in the middle.",
                    "label": 0
                },
                {
                    "sent": "Definitely yes.",
                    "label": 0
                },
                {
                    "sent": "So as we keep adding lines, say we've got to say we have another one like that.",
                    "label": 0
                },
                {
                    "sent": "And this is the blue side.",
                    "label": 0
                },
                {
                    "sent": "And this is the red side.",
                    "label": 0
                },
                {
                    "sent": "Then we can keep.",
                    "label": 0
                },
                {
                    "sent": "Adding on to the.",
                    "label": 0
                },
                {
                    "sent": "Adding onto the probabilities again doing this integration.",
                    "label": 0
                },
                {
                    "sent": "So that we end up with this posterior probability, and that's what we're plotting here from many, many lines.",
                    "label": 0
                },
                {
                    "sent": "OK, so that's just doing.",
                    "label": 0
                },
                {
                    "sent": "This integration here and we're doing this integration in.",
                    "label": 0
                },
                {
                    "sent": "Using a method called Monte Carlo, which basically just means we take a load of random samples from our prior and we see what happens those samples and try to build a posterior which is made up of a bunch of those samples, and if we take enough samples from our prior then we hope to build up an accurate picture of our posterior.",
                    "label": 0
                },
                {
                    "sent": "There's other ways of doing that integral as well.",
                    "label": 0
                },
                {
                    "sent": "Alright, so a couple of things to notice about this.",
                    "label": 0
                },
                {
                    "sent": "First of all, we have something so Bayes rule is given us a way of a very simple way of having a classifier, some random decision boundary, and.",
                    "label": 0
                },
                {
                    "sent": "So linear decision boundary which splits things up into one or zero.",
                    "label": 0
                },
                {
                    "sent": "It's a hard classifier.",
                    "label": 0
                },
                {
                    "sent": "Everything is either definitely yes or definitely know by sampling many of them from our prior and looking at the.",
                    "label": 0
                },
                {
                    "sent": "Looking at the posterior distribution, we get this kind of contour, so we say if we see a point here then maybe it's a probability of .2 that it's a yes.",
                    "label": 1
                },
                {
                    "sent": "If we see something, here is the probability of .9 that is a yes.",
                    "label": 0
                },
                {
                    "sent": "And this kind of follows the pattern that we've seen.",
                    "label": 0
                },
                {
                    "sent": "So something to note, the posterior distribution under this Bayesian inference is of a different form to the hypothesis that we that it was made up of.",
                    "label": 0
                },
                {
                    "sent": "So we're getting something extra kind of richer representation than our individual lines.",
                    "label": 0
                },
                {
                    "sent": "By integrating them all up, we're getting something more significant.",
                    "label": 0
                },
                {
                    "sent": "So we.",
                    "label": 0
                },
                {
                    "sent": "We could have.",
                    "label": 0
                },
                {
                    "sent": "People often look at something called the maximum a posteriori, which is something under Bayes rule which maximizes the maximizes the probability posterior parameter probability, but will not worry about that too much just now.",
                    "label": 0
                },
                {
                    "sent": "This is ideally the thing to do if we if we can.",
                    "label": 0
                },
                {
                    "sent": "Please mention.",
                    "label": 0
                },
                {
                    "sent": "Oh great, OK. That's perfect, 'cause I wasn't going to say anything more about it.",
                    "label": 0
                },
                {
                    "sent": "So still hear all about that tomorrow.",
                    "label": 0
                },
                {
                    "sent": "Great, I think we're running for an hour.",
                    "label": 0
                },
                {
                    "sent": "Let's have a quick break after some questions please.",
                    "label": 0
                },
                {
                    "sent": "I want to know the.",
                    "label": 0
                },
                {
                    "sent": "One thing, so it's like one thing is in using vision classification as.",
                    "label": 0
                },
                {
                    "sent": "God bless you opposed to using regression because I see that you can use for patient.",
                    "label": 0
                },
                {
                    "sent": "Also find a partner.",
                    "label": 0
                },
                {
                    "sent": "Yeah, absolutely, and those two things are.",
                    "label": 0
                },
                {
                    "sent": "So the I guess the comment is there we could look at the boundaries and see how far away the points are from the boundaries and try to find it that way and those two things are not mutually exclusive.",
                    "label": 0
                },
                {
                    "sent": "You don't have to choose between regression or Bayesian methods.",
                    "label": 0
                },
                {
                    "sent": "And actually what will look after the break is.",
                    "label": 0
                },
                {
                    "sent": "Is doing regression in a Bayesian way?",
                    "label": 0
                },
                {
                    "sent": "So you can actually you can actually do do both.",
                    "label": 0
                },
                {
                    "sent": "So there's.",
                    "label": 0
                },
                {
                    "sent": "Logistic regression, which is a way of choosing a line according to according to some different likelihood, and we can still still always do the Bayesian thing.",
                    "label": 0
                },
                {
                    "sent": "Hope this is your your question.",
                    "label": 0
                },
                {
                    "sent": "We will look at a bit more after the after the break.",
                    "label": 0
                },
                {
                    "sent": "Anyone else here?",
                    "label": 0
                },
                {
                    "sent": "Those are points where you have probability of test data against.",
                    "label": 0
                },
                {
                    "sent": "The data that you have and the next.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Right there and I just.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Are you assuming that the data is almost the space distributed?",
                    "label": 0
                },
                {
                    "sent": "OK, right right?",
                    "label": 0
                },
                {
                    "sent": "So the probability of the data is some term which makes this a probability, so we know that if we.",
                    "label": 1
                },
                {
                    "sent": "We know that if we.",
                    "label": 1
                },
                {
                    "sent": "Look at every possible parameter setting.",
                    "label": 0
                },
                {
                    "sent": "All of this has to sum up to one, so the integral over the parameters has to be one, and this term here is just the number of which makes it scale to that to that value.",
                    "label": 0
                },
                {
                    "sent": "So it's just some some constant term that we put in there, and usually we just forget about it and say it's proportional, and then after we've actually done done a bunch of samples, then we just we just divide through to make it sum up to one.",
                    "label": 0
                },
                {
                    "sent": "So it's just something to make it a bit easier.",
                    "label": 0
                },
                {
                    "sent": "Alright anymore for anymore.",
                    "label": 0
                },
                {
                    "sent": "Why did you generate just appoint?",
                    "label": 0
                },
                {
                    "sent": "Couldn't have generated like the actual data you needed, because instead of going to find opponent and then finding perpendicular cleaned up there said oh I need W and peas.",
                    "label": 0
                },
                {
                    "sent": "Well, it's the same thing, right?",
                    "label": 0
                },
                {
                    "sent": "Like if we generate if we generate a point here, then that actually gives us a way of.",
                    "label": 1
                },
                {
                    "sent": "Of generating our RW Zombies, it's uniquely specified by a single point, so we could as well generate the right.",
                    "label": 0
                },
                {
                    "sent": "We could generate random values of W and random values of B.",
                    "label": 0
                },
                {
                    "sent": "There's a bit of a danger there, and this is a danger which is partly in the details, which I kind of hid from you about generating these lines.",
                    "label": 0
                },
                {
                    "sent": "We kind of want the lines to be within some space somewhere we want.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Have generated some random lines here.",
                    "label": 0
                },
                {
                    "sent": "And they're all kind of the lines.",
                    "label": 0
                },
                {
                    "sent": "All kind of cross our space about where the data is.",
                    "label": 0
                },
                {
                    "sent": "So if we generated random WMB with no constraints, we might have a whole bunch of lines somewhere over here somewhere down there somewhere right over at this side.",
                    "label": 0
                },
                {
                    "sent": "And that wouldn't really be the kind of thing we're interested in.",
                    "label": 0
                },
                {
                    "sent": "So the way we take this in Bayesian terms is our prior wants us to.",
                    "label": 0
                },
                {
                    "sent": "We should have a prior which draws lines from the region where are.",
                    "label": 0
                },
                {
                    "sent": "Data is we want to have lines kind of uniformly around here, and one way of ensuring that is to choose points which in some way or within the within the space where our data is.",
                    "label": 0
                },
                {
                    "sent": "So if we can control where those points are and those points are the things we have an origin, which is the mean of our data, then we've always got lines which are kind of where we want them to be, and not not sort of miles off somewhere else.",
                    "label": 0
                },
                {
                    "sent": "Yes, please.",
                    "label": 0
                },
                {
                    "sent": "Find a means of the data or.",
                    "label": 0
                },
                {
                    "sent": "OK for the question right I can see I'm not going to be able to hide these details from you anymore.",
                    "label": 0
                },
                {
                    "sent": "You want to know how to choose the prior.",
                    "label": 0
                },
                {
                    "sent": "Let me let me tell you that the way to choose the prior here.",
                    "label": 0
                },
                {
                    "sent": "I could actually show you after the break what happens with different priors.",
                    "label": 0
                },
                {
                    "sent": "OK, you could choose the points uniformly across this space, and if you do, it actually doesn't really work.",
                    "label": 0
                },
                {
                    "sent": "You get lines where there's very few.",
                    "label": 0
                },
                {
                    "sent": "There are very few lines going through the center and many around the edge.",
                    "label": 0
                },
                {
                    "sent": "So the best way to choose these points is to start at the origin and uniformly sample some.",
                    "label": 0
                },
                {
                    "sent": "Some radius out from the center and some some angle around, so your.",
                    "label": 0
                },
                {
                    "sent": "Or uniformly choosing an angle from negative.",
                    "label": 0
                },
                {
                    "sent": "Negative \u03c0 degrees, and you're choosing some radius uniformly, which is the distance away from the origin that you think the line should be.",
                    "label": 1
                },
                {
                    "sent": "And if you do that then you'll get points which give you Lions which kind of look look right.",
                    "label": 0
                },
                {
                    "sent": "So there's a couple of ways you could generate those those points, and not all of them are right, and the way to tell is to try it out and then see what you see what you get.",
                    "label": 0
                }
            ]
        }
    }
}