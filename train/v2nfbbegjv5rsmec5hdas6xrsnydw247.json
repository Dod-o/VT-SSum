{
    "id": "v2nfbbegjv5rsmec5hdas6xrsnydw247",
    "title": "Depth from Diffusion",
    "info": {
        "author": [
            "Changyin Zhou, Department of Computer Science, Columbia University"
        ],
        "published": "July 19, 2010",
        "recorded": "June 2010",
        "category": [
            "Top->Computer Science->Computer Vision->Shape from X"
        ]
    },
    "url": "http://videolectures.net/cvpr2010_zhou_dfd/",
    "segmentation": [
        [
            "So good afternoon everyone.",
            "I'm trying though from Columbia University this papered Epsom diffusion is caused by Oliver Coesite and Trina yeah and supported by Office of Naval Research.",
            "In this work, we propose to use optical device called diffuser, for high precision depth estimation.",
            "So first."
        ],
        [
            "Or what's optical diffuser in my hands now is a small piece of optical diffuser.",
            "And I highlighted the boundary of the diffuser so that you can see it, because if user has high transparency and has low reflectance.",
            "And here's a laser pointer like this one, and now should direct on the White paper.",
            "Then you'll see very bright and sharp dot.",
            "If I move the laser onto the diffuser and the light will become defocused or scattered, and you see Gaussian like pattern on the white paper.",
            "There are many different diffusers.",
            "For example, granted gas or lenticular array or holographic diffuse."
        ],
        [
            "And this is a holographic diffuser.",
            "If you look at the.",
            "Micrograph of this surface you can see many bumps.",
            "Each of them can be as small as a few microns.",
            "So diffusers very powerful device to control or modulators the lights.",
            "You can at once in optics and fabrication techniques, enable us to design and manufacture.",
            "This bumps had very high precision so that you can produce many different kind of diffusion patterns.",
            "For example, the Gaussian pattern.",
            "Like here you can get get also pillbox rings and even more."
        ],
        [
            "However, in computer vision, diffuser is still not a conventional device.",
            "Some photographers use diffuser to soften the flash or put the diffuser at the image plan to preview the image.",
            "Or they put in front lens to to make the image soft.",
            "So for example, this image has some nice hair affect this because the diffuser.",
            "And."
        ],
        [
            "This work we are going to use diffuser to encode depth information, so consider this setting as example.",
            "So we have a crinkled magazine.",
            "Here we have a point shoot camera here.",
            "And we put the diffuser right in front of the object and take an image.",
            "And this will be the image that you will see like image like this.",
            "The text you can see it's diffused abroad to different amounts and the amount of diffusion abroad varies with depth.",
            "That means the depth depth information is encoded in the diffusion.",
            "So this problem is.",
            "You may feel is very similar to the blur due to the lens defocus, and along this talk I will discuss the connection between the diffusion blur and defocus blur, and I'm going to show the bigger the advantage of using diffusion to encode apps."
        ],
        [
            "OK, you understand the diffusion.",
            "Let's look at the geometry first.",
            "This is the pinhole camera.",
            "So we know the four point object P only the light pass through the pinhole will reach the sensor.",
            "If you put the diffuser in front of the object."
        ],
        [
            "Some some light switch originally cannot reach the pinhole can be scattered into the pin code and here for simplicity.",
            "We assume the diffuser has appeal box.",
            "The future function to angle Theta, so that means the incoming light will be scattered uniformly into a column of angle Theta."
        ],
        [
            "So then for all the lines from object P, if they intersect with the diffuser in a certain region, then it can be scattered in the pinhole.",
            "And from the viewpoint of pinhole you will see a disk instead of points, and the disk maybe is a diameter of the disk."
        ],
        [
            "Suppose the distance from the pinhole to the diffuser.",
            "Is U and the distance from the object to the diffuser is Z and we can do some math and founder relation between UZ, an diffusion angle Theta and browser."
        ],
        [
            "Here AA is a field angle of the object.",
            "Notice that this equation looks very similar to the Gaussian Lenz law, so we call this diffusion law.",
            "From this diffusion law, we can easily derive the relation between the.",
            "Diffusion size on the sensor R and the depth Z.",
            "If we can compute the bra size of each of each pixel in the scene, we can get the depth."
        ],
        [
            "Map of this scene.",
            "So we can regard the diffuser as a proxy object, so the seeing is first mapped onto the diffuser, and for each pixel is blurred according to its distance to the diffuser.",
            "Then the diffuser as the proxy object produce image on the pinhole camera.",
            "OK.",
            "So the diffusion size varies with spatial varying, but if we look at a small Patch in the scene, we can assume all the pixels at the small Patch equally fields equally."
        ],
        [
            "Blood, then the captured image F can be formulated as a convolution of a clear image and the PSF diffusion PSF and the diffusion size is determined by the distance from object to the diffuser.",
            "Then too.",
            "OK, so so far we only consider."
        ],
        [
            "Single camera, what if a lens camera?",
            "Cause how is the diffusion will?",
            "How is diffusion interact with lens and lens defocus?"
        ],
        [
            "So let's look at the geometry of pinhole camera again.",
            "So remember, the diffuser is a proxy object, and seeing is first map onto diffuser, then produce image in the pinhole camera, and if we."
        ],
        [
            "Replace pinhole with the with the lens.",
            "So it should be a less yeah, OK?",
            "And if the lenses in focus you get exactly the same image as a pinhole camera.",
            "And if The thing is out of focus, then you will get.",
            "Actual."
        ],
        [
            "That means the final PSF will be the convolution of the defocus passive and diffusion PSF.",
            "Here LD is a diffusion PSF.",
            "If, uh, if the pin code was used.",
            "And Eliza defocus PSF.",
            "If the diffuser was removed, so it's quite simple formulation."
        ],
        [
            "Then, based on this diffusion model, we can do depth from diffusion.",
            "We capture 2 images or with diffuser and without diffuser.",
            "So F1F2 and we know that F1 equals two F2 control with D here.",
            "Note that L folks kernel is cancelled out.",
            "So from F1F2 we can easily compute the are.",
            "Actually this.",
            "This form is same as in depth from defocus, so that because of this similarity many depth of focus algorithm can be used applied here too for depth from diffusion.",
            "And if we have the bra size estimate from the image, we can compute the depth Z using our deficient law and the derived diffusion size equation.",
            "OK.",
            "So here you see absolutely focus and that absolute diffusion has very similar mathematical formulation.",
            "But they have very different."
        ],
        [
            "Physical causes behind the absolutely focus use, make use of focus property of lens.",
            "For the object out of the focal plane, it appears the broad in the sensor and the bra size is determined by distance from the object to the focal plane.",
            "That means the depth information is encoded in the block size.",
            "And people can people can use the focus as a cue to recover depth, and this idea has been proposed and studied as early as 1980s.",
            "And since there are a lot of work has been done in depth, only focus like in optimized camera setting or developing better algorithm to estimate, estimate Prosise from the image.",
            "Also, some analysis has been done in depth from defocus, especially, people have shown that the precision of depth depth from defocus is proportional to the actual size and inversely proportional to the object distance.",
            "And the proposed Epsom diffusion method relies on the diffuser which is placed on the object side.",
            "Therefore, the land size or length quality does not matter in this technique because the depth information is encoded in diffusion.",
            "Compared with depth of focus, the absolute diffusion has several significant."
        ],
        [
            "Images.",
            "Consider the following settings.",
            "We suppose we have a 22.5 by 15 millimeter sensor and 10 Micron pixel and 10 millimeter focal length lens.",
            "And we have object placed at 1 meter from the camera.",
            "And suppose we won't get a depth map at precision .1 millimeter.",
            "Stanford, Epsom diffusion.",
            "We just need a positive future 21 about 21 degree in front of object.",
            "And for depth."
        ],
        [
            "Focus you may need a large aperture to get the same precision on the 1 millimeter, so the app."
        ],
        [
            "Size will be huge, about 800 millimeters.",
            "This actually is a astronomy telescope lens."
        ],
        [
            "Consider another setting your moves objects far away from the camera to fire meters, and you won't achieve 1 millimeter precision for depth from diffusion, you just need a diffuser about 11 degree, and you get this precision.",
            "If you want to do."
        ],
        [
            "Absolutely focus.",
            "You may need a large aperture aperture camera."
        ],
        [
            "Amateur can be 2 meters, which is actually impossible.",
            "But here I want it to be perfected.",
            "Clear the depth from diffusion, get the increased precision at the cost you put in the diffuser at own object side.",
            "OK."
        ],
        [
            "To verify our model, we use a Canon camera and illuminated diffuser of 10 degree and point light source.",
            "To measure the ourselves that the folks at 70 Fusion pair self.",
            "So first we measure PSF at a small aperture 0 field field angle.",
            "This is a captured PSF with diffuser placed at a different location.",
            "And we plot the captured PSF and the model PSF on the light on in solid solid lines and dashed lines.",
            "We found this PSF matching each other quite well."
        ],
        [
            "We also test larger fields."
        ],
        [
            "Angle and the large aperture in all of these experiments, the captured PSF, and there's a.",
            "There's a model.",
            "PSF are quite consistent."
        ],
        [
            "OK, here are several experimental results using depth diffusion.",
            "This is file piled playing cards.",
            "Each of them is about .29 millimeter sick.",
            "We use a Canon 2020 camera and 50 millimeter lens and a 20 degree diffuser.",
            "We kept."
        ],
        [
            "The two images, 1 without diffuser and one with the diffuser."
        ],
        [
            "From these two images, we can compute the depth map.",
            "This map can have a precision of about 1 millimeter or even higher actually.",
            "You may wonder what if we use absolutely focus and actually that's very difficult.",
            "If you do that, you may get nothing 'cause the thickness of this thing is the total thickness actually is smaller than the depth of field of the lens, so you may not get anything."
        ],
        [
            "In the second experiment, we use a point shoot camera, Canon G5 and five degree diffuser to recover the depth map of this small sculpture."
        ],
        [
            "We capture 2 images without the diffuser and the wizard."
        ],
        [
            "From this to image you compute the depth map.",
            "You can see the three discrete structure of these tiny buildings in the Sky."
        ],
        [
            "Culture.",
            "In this experiment, we use a Canon 20D camera and 10 degree diffuser to recover the depth map of a large object whose size is about 650 millimeters by 450 millimeter size, which is much larger than the object of the diffuser.",
            "So we capture multiple image by swiping the diffuser over.",
            "The object will take 10 images and we recover 10 depth Maps.",
            "We register this depth Maps.",
            "And stitch them together."
        ],
        [
            "And we get this depth map for large objects.",
            "You can zoom in the depth map and see.",
            "The precision can be as high as one millimeter.",
            "Note that when we take this image, we don't need to move the camera, we just need to move the diffuser, so that's very easy for you to register and stage all the other images.",
            "And more details can be found in the paper."
        ],
        [
            "OK, as a summary, we introduced optical diffuser and formulated the image formation when the diffuser is placed between the camera and and this object.",
            "And based on this diffusion model, we proposed absolute diffusion.",
            "Which will require us to put the diffuser on the object side.",
            "Of course, this is not always possible in practice, but if you can do it, you can get high precision depth estimation even for distant objects, and this method have little requirement for lens, small lens or lens with operation should be fine for this method.",
            "And we demonstrated high precision depth estimation by using several experiments.",
            "OK."
        ],
        [
            "Thank you.",
            "So we have time for questions again, please come to the microphone, identify yourself and ask your question.",
            "Daniel Charleston for Middlebury.",
            "Just a quick question about the stitching.",
            "You're measuring the distance relative to the diffuser, correct?",
            "Yes, so that means you need to move the diffuser in the plane when you do the stitching.",
            "Actually, when you move the diffuser you don't have to stay on the one plane.",
            "When we take attack images, some overlapping.",
            "You can use an overlapping region to find the.",
            "Register the depth map and actually this kind of registration is quite straightforward, so you can do that if, say you change the angle, you can change angle.",
            "Actually make the plane that you have.",
            "Yeah, you don't have to stay perfect in the plane, you can move a little bit.",
            "It's not so sensitive.",
            "Go to Adobe Systems.",
            "I just wanted to ask you about the precision of the algorithm for detecting depth along edges, because I notice that in the cards example there seems to be maybe like 2 three pixels of difference on which one the edge detection.",
            "If you go.",
            "A little further back.",
            "Further back."
        ],
        [
            "Yet here, so along the edges of the cards, how precise do you think you can?",
            "Actually?",
            "This is a very naive algorithm.",
            "We just take two images and based on Patch based method to estimate the depth map with into any post processing.",
            "If we want deal with the boundary, I think we need you.",
            "Some bad algorithms.",
            "Actually, this algorithm has been well studied, studied in depth from defocus.",
            "OK, so you think that if we have multiple images it would be possible to improve this multiple image with the diffuser at different position?",
            "OK yeah maybe yeah thanks."
        ],
        [
            "Rely on the object.",
            "How much does your algorithm rely on the object?",
            "Having a lot of texture because I know if the color is uniform, you might not be able to tell how much the diffuser which method would require rich texture to work well if it was a texture is kind of weak then the depth map will be very sparse.",
            "I think this is a common issue also for depth from defocus and many other.",
            "Technique.",
            "Can you talk something about like applying this for video?",
            "Say if I want to get the depth map for video?",
            "I mean, yeah, it's a great question.",
            "So the problem actually is how can we recover tabs from a single image?",
            "Write something like that?",
            "Because if you take a video you need to because this method need positive user and remove this user.",
            "Of course you can come up with some techniques like you can design A diffuser for each different part.",
            "You have different diffusion angle.",
            "Then you can swipe the diffuser over the object and take a video and you may be able to recover the depth map for the video.",
            "How is the processing speed?",
            "Processing can you do this in real time?",
            "That's what depends on which kind of algorithm we're going to use.",
            "If you some simple like a four year transform based method, I think we can.",
            "OK, just where do you put the diffuser?",
            "Diffuser should be right in front of the object.",
            "The closer the better.",
            "If they closed the object you get high precision and high resolution depth map.",
            "If you move the diffuser away from objects and resolution of depth map will decrease.",
            "OK so you don't think you can just put it in front of the camera and then do that.",
            "Yeah no, I think it should be close to the object.",
            "OK, thanks.",
            "Let's thank the speaker one more time."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So good afternoon everyone.",
                    "label": 0
                },
                {
                    "sent": "I'm trying though from Columbia University this papered Epsom diffusion is caused by Oliver Coesite and Trina yeah and supported by Office of Naval Research.",
                    "label": 1
                },
                {
                    "sent": "In this work, we propose to use optical device called diffuser, for high precision depth estimation.",
                    "label": 0
                },
                {
                    "sent": "So first.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Or what's optical diffuser in my hands now is a small piece of optical diffuser.",
                    "label": 0
                },
                {
                    "sent": "And I highlighted the boundary of the diffuser so that you can see it, because if user has high transparency and has low reflectance.",
                    "label": 0
                },
                {
                    "sent": "And here's a laser pointer like this one, and now should direct on the White paper.",
                    "label": 0
                },
                {
                    "sent": "Then you'll see very bright and sharp dot.",
                    "label": 0
                },
                {
                    "sent": "If I move the laser onto the diffuser and the light will become defocused or scattered, and you see Gaussian like pattern on the white paper.",
                    "label": 0
                },
                {
                    "sent": "There are many different diffusers.",
                    "label": 0
                },
                {
                    "sent": "For example, granted gas or lenticular array or holographic diffuse.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And this is a holographic diffuser.",
                    "label": 1
                },
                {
                    "sent": "If you look at the.",
                    "label": 1
                },
                {
                    "sent": "Micrograph of this surface you can see many bumps.",
                    "label": 0
                },
                {
                    "sent": "Each of them can be as small as a few microns.",
                    "label": 0
                },
                {
                    "sent": "So diffusers very powerful device to control or modulators the lights.",
                    "label": 0
                },
                {
                    "sent": "You can at once in optics and fabrication techniques, enable us to design and manufacture.",
                    "label": 0
                },
                {
                    "sent": "This bumps had very high precision so that you can produce many different kind of diffusion patterns.",
                    "label": 0
                },
                {
                    "sent": "For example, the Gaussian pattern.",
                    "label": 0
                },
                {
                    "sent": "Like here you can get get also pillbox rings and even more.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "However, in computer vision, diffuser is still not a conventional device.",
                    "label": 0
                },
                {
                    "sent": "Some photographers use diffuser to soften the flash or put the diffuser at the image plan to preview the image.",
                    "label": 1
                },
                {
                    "sent": "Or they put in front lens to to make the image soft.",
                    "label": 0
                },
                {
                    "sent": "So for example, this image has some nice hair affect this because the diffuser.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This work we are going to use diffuser to encode depth information, so consider this setting as example.",
                    "label": 0
                },
                {
                    "sent": "So we have a crinkled magazine.",
                    "label": 0
                },
                {
                    "sent": "Here we have a point shoot camera here.",
                    "label": 0
                },
                {
                    "sent": "And we put the diffuser right in front of the object and take an image.",
                    "label": 0
                },
                {
                    "sent": "And this will be the image that you will see like image like this.",
                    "label": 0
                },
                {
                    "sent": "The text you can see it's diffused abroad to different amounts and the amount of diffusion abroad varies with depth.",
                    "label": 1
                },
                {
                    "sent": "That means the depth depth information is encoded in the diffusion.",
                    "label": 0
                },
                {
                    "sent": "So this problem is.",
                    "label": 0
                },
                {
                    "sent": "You may feel is very similar to the blur due to the lens defocus, and along this talk I will discuss the connection between the diffusion blur and defocus blur, and I'm going to show the bigger the advantage of using diffusion to encode apps.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, you understand the diffusion.",
                    "label": 0
                },
                {
                    "sent": "Let's look at the geometry first.",
                    "label": 0
                },
                {
                    "sent": "This is the pinhole camera.",
                    "label": 1
                },
                {
                    "sent": "So we know the four point object P only the light pass through the pinhole will reach the sensor.",
                    "label": 0
                },
                {
                    "sent": "If you put the diffuser in front of the object.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Some some light switch originally cannot reach the pinhole can be scattered into the pin code and here for simplicity.",
                    "label": 0
                },
                {
                    "sent": "We assume the diffuser has appeal box.",
                    "label": 0
                },
                {
                    "sent": "The future function to angle Theta, so that means the incoming light will be scattered uniformly into a column of angle Theta.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So then for all the lines from object P, if they intersect with the diffuser in a certain region, then it can be scattered in the pinhole.",
                    "label": 0
                },
                {
                    "sent": "And from the viewpoint of pinhole you will see a disk instead of points, and the disk maybe is a diameter of the disk.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Suppose the distance from the pinhole to the diffuser.",
                    "label": 0
                },
                {
                    "sent": "Is U and the distance from the object to the diffuser is Z and we can do some math and founder relation between UZ, an diffusion angle Theta and browser.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here AA is a field angle of the object.",
                    "label": 0
                },
                {
                    "sent": "Notice that this equation looks very similar to the Gaussian Lenz law, so we call this diffusion law.",
                    "label": 0
                },
                {
                    "sent": "From this diffusion law, we can easily derive the relation between the.",
                    "label": 0
                },
                {
                    "sent": "Diffusion size on the sensor R and the depth Z.",
                    "label": 0
                },
                {
                    "sent": "If we can compute the bra size of each of each pixel in the scene, we can get the depth.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Map of this scene.",
                    "label": 0
                },
                {
                    "sent": "So we can regard the diffuser as a proxy object, so the seeing is first mapped onto the diffuser, and for each pixel is blurred according to its distance to the diffuser.",
                    "label": 1
                },
                {
                    "sent": "Then the diffuser as the proxy object produce image on the pinhole camera.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So the diffusion size varies with spatial varying, but if we look at a small Patch in the scene, we can assume all the pixels at the small Patch equally fields equally.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Blood, then the captured image F can be formulated as a convolution of a clear image and the PSF diffusion PSF and the diffusion size is determined by the distance from object to the diffuser.",
                    "label": 1
                },
                {
                    "sent": "Then too.",
                    "label": 0
                },
                {
                    "sent": "OK, so so far we only consider.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Single camera, what if a lens camera?",
                    "label": 1
                },
                {
                    "sent": "Cause how is the diffusion will?",
                    "label": 0
                },
                {
                    "sent": "How is diffusion interact with lens and lens defocus?",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So let's look at the geometry of pinhole camera again.",
                    "label": 0
                },
                {
                    "sent": "So remember, the diffuser is a proxy object, and seeing is first map onto diffuser, then produce image in the pinhole camera, and if we.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Replace pinhole with the with the lens.",
                    "label": 0
                },
                {
                    "sent": "So it should be a less yeah, OK?",
                    "label": 0
                },
                {
                    "sent": "And if the lenses in focus you get exactly the same image as a pinhole camera.",
                    "label": 0
                },
                {
                    "sent": "And if The thing is out of focus, then you will get.",
                    "label": 0
                },
                {
                    "sent": "Actual.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "That means the final PSF will be the convolution of the defocus passive and diffusion PSF.",
                    "label": 1
                },
                {
                    "sent": "Here LD is a diffusion PSF.",
                    "label": 0
                },
                {
                    "sent": "If, uh, if the pin code was used.",
                    "label": 0
                },
                {
                    "sent": "And Eliza defocus PSF.",
                    "label": 0
                },
                {
                    "sent": "If the diffuser was removed, so it's quite simple formulation.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Then, based on this diffusion model, we can do depth from diffusion.",
                    "label": 1
                },
                {
                    "sent": "We capture 2 images or with diffuser and without diffuser.",
                    "label": 0
                },
                {
                    "sent": "So F1F2 and we know that F1 equals two F2 control with D here.",
                    "label": 0
                },
                {
                    "sent": "Note that L folks kernel is cancelled out.",
                    "label": 0
                },
                {
                    "sent": "So from F1F2 we can easily compute the are.",
                    "label": 0
                },
                {
                    "sent": "Actually this.",
                    "label": 0
                },
                {
                    "sent": "This form is same as in depth from defocus, so that because of this similarity many depth of focus algorithm can be used applied here too for depth from diffusion.",
                    "label": 1
                },
                {
                    "sent": "And if we have the bra size estimate from the image, we can compute the depth Z using our deficient law and the derived diffusion size equation.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So here you see absolutely focus and that absolute diffusion has very similar mathematical formulation.",
                    "label": 0
                },
                {
                    "sent": "But they have very different.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Physical causes behind the absolutely focus use, make use of focus property of lens.",
                    "label": 0
                },
                {
                    "sent": "For the object out of the focal plane, it appears the broad in the sensor and the bra size is determined by distance from the object to the focal plane.",
                    "label": 0
                },
                {
                    "sent": "That means the depth information is encoded in the block size.",
                    "label": 0
                },
                {
                    "sent": "And people can people can use the focus as a cue to recover depth, and this idea has been proposed and studied as early as 1980s.",
                    "label": 0
                },
                {
                    "sent": "And since there are a lot of work has been done in depth, only focus like in optimized camera setting or developing better algorithm to estimate, estimate Prosise from the image.",
                    "label": 0
                },
                {
                    "sent": "Also, some analysis has been done in depth from defocus, especially, people have shown that the precision of depth depth from defocus is proportional to the actual size and inversely proportional to the object distance.",
                    "label": 1
                },
                {
                    "sent": "And the proposed Epsom diffusion method relies on the diffuser which is placed on the object side.",
                    "label": 0
                },
                {
                    "sent": "Therefore, the land size or length quality does not matter in this technique because the depth information is encoded in diffusion.",
                    "label": 0
                },
                {
                    "sent": "Compared with depth of focus, the absolute diffusion has several significant.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Images.",
                    "label": 0
                },
                {
                    "sent": "Consider the following settings.",
                    "label": 0
                },
                {
                    "sent": "We suppose we have a 22.5 by 15 millimeter sensor and 10 Micron pixel and 10 millimeter focal length lens.",
                    "label": 0
                },
                {
                    "sent": "And we have object placed at 1 meter from the camera.",
                    "label": 0
                },
                {
                    "sent": "And suppose we won't get a depth map at precision .1 millimeter.",
                    "label": 0
                },
                {
                    "sent": "Stanford, Epsom diffusion.",
                    "label": 0
                },
                {
                    "sent": "We just need a positive future 21 about 21 degree in front of object.",
                    "label": 0
                },
                {
                    "sent": "And for depth.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Focus you may need a large aperture to get the same precision on the 1 millimeter, so the app.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Size will be huge, about 800 millimeters.",
                    "label": 0
                },
                {
                    "sent": "This actually is a astronomy telescope lens.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Consider another setting your moves objects far away from the camera to fire meters, and you won't achieve 1 millimeter precision for depth from diffusion, you just need a diffuser about 11 degree, and you get this precision.",
                    "label": 0
                },
                {
                    "sent": "If you want to do.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Absolutely focus.",
                    "label": 0
                },
                {
                    "sent": "You may need a large aperture aperture camera.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Amateur can be 2 meters, which is actually impossible.",
                    "label": 0
                },
                {
                    "sent": "But here I want it to be perfected.",
                    "label": 0
                },
                {
                    "sent": "Clear the depth from diffusion, get the increased precision at the cost you put in the diffuser at own object side.",
                    "label": 1
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To verify our model, we use a Canon camera and illuminated diffuser of 10 degree and point light source.",
                    "label": 0
                },
                {
                    "sent": "To measure the ourselves that the folks at 70 Fusion pair self.",
                    "label": 0
                },
                {
                    "sent": "So first we measure PSF at a small aperture 0 field field angle.",
                    "label": 0
                },
                {
                    "sent": "This is a captured PSF with diffuser placed at a different location.",
                    "label": 0
                },
                {
                    "sent": "And we plot the captured PSF and the model PSF on the light on in solid solid lines and dashed lines.",
                    "label": 0
                },
                {
                    "sent": "We found this PSF matching each other quite well.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We also test larger fields.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Angle and the large aperture in all of these experiments, the captured PSF, and there's a.",
                    "label": 0
                },
                {
                    "sent": "There's a model.",
                    "label": 0
                },
                {
                    "sent": "PSF are quite consistent.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, here are several experimental results using depth diffusion.",
                    "label": 0
                },
                {
                    "sent": "This is file piled playing cards.",
                    "label": 1
                },
                {
                    "sent": "Each of them is about .29 millimeter sick.",
                    "label": 0
                },
                {
                    "sent": "We use a Canon 2020 camera and 50 millimeter lens and a 20 degree diffuser.",
                    "label": 0
                },
                {
                    "sent": "We kept.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The two images, 1 without diffuser and one with the diffuser.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "From these two images, we can compute the depth map.",
                    "label": 1
                },
                {
                    "sent": "This map can have a precision of about 1 millimeter or even higher actually.",
                    "label": 0
                },
                {
                    "sent": "You may wonder what if we use absolutely focus and actually that's very difficult.",
                    "label": 0
                },
                {
                    "sent": "If you do that, you may get nothing 'cause the thickness of this thing is the total thickness actually is smaller than the depth of field of the lens, so you may not get anything.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In the second experiment, we use a point shoot camera, Canon G5 and five degree diffuser to recover the depth map of this small sculpture.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We capture 2 images without the diffuser and the wizard.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "From this to image you compute the depth map.",
                    "label": 0
                },
                {
                    "sent": "You can see the three discrete structure of these tiny buildings in the Sky.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Culture.",
                    "label": 0
                },
                {
                    "sent": "In this experiment, we use a Canon 20D camera and 10 degree diffuser to recover the depth map of a large object whose size is about 650 millimeters by 450 millimeter size, which is much larger than the object of the diffuser.",
                    "label": 0
                },
                {
                    "sent": "So we capture multiple image by swiping the diffuser over.",
                    "label": 0
                },
                {
                    "sent": "The object will take 10 images and we recover 10 depth Maps.",
                    "label": 0
                },
                {
                    "sent": "We register this depth Maps.",
                    "label": 0
                },
                {
                    "sent": "And stitch them together.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And we get this depth map for large objects.",
                    "label": 1
                },
                {
                    "sent": "You can zoom in the depth map and see.",
                    "label": 0
                },
                {
                    "sent": "The precision can be as high as one millimeter.",
                    "label": 0
                },
                {
                    "sent": "Note that when we take this image, we don't need to move the camera, we just need to move the diffuser, so that's very easy for you to register and stage all the other images.",
                    "label": 0
                },
                {
                    "sent": "And more details can be found in the paper.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, as a summary, we introduced optical diffuser and formulated the image formation when the diffuser is placed between the camera and and this object.",
                    "label": 1
                },
                {
                    "sent": "And based on this diffusion model, we proposed absolute diffusion.",
                    "label": 0
                },
                {
                    "sent": "Which will require us to put the diffuser on the object side.",
                    "label": 1
                },
                {
                    "sent": "Of course, this is not always possible in practice, but if you can do it, you can get high precision depth estimation even for distant objects, and this method have little requirement for lens, small lens or lens with operation should be fine for this method.",
                    "label": 1
                },
                {
                    "sent": "And we demonstrated high precision depth estimation by using several experiments.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Thank you.",
                    "label": 0
                },
                {
                    "sent": "So we have time for questions again, please come to the microphone, identify yourself and ask your question.",
                    "label": 0
                },
                {
                    "sent": "Daniel Charleston for Middlebury.",
                    "label": 0
                },
                {
                    "sent": "Just a quick question about the stitching.",
                    "label": 0
                },
                {
                    "sent": "You're measuring the distance relative to the diffuser, correct?",
                    "label": 0
                },
                {
                    "sent": "Yes, so that means you need to move the diffuser in the plane when you do the stitching.",
                    "label": 0
                },
                {
                    "sent": "Actually, when you move the diffuser you don't have to stay on the one plane.",
                    "label": 0
                },
                {
                    "sent": "When we take attack images, some overlapping.",
                    "label": 0
                },
                {
                    "sent": "You can use an overlapping region to find the.",
                    "label": 0
                },
                {
                    "sent": "Register the depth map and actually this kind of registration is quite straightforward, so you can do that if, say you change the angle, you can change angle.",
                    "label": 0
                },
                {
                    "sent": "Actually make the plane that you have.",
                    "label": 0
                },
                {
                    "sent": "Yeah, you don't have to stay perfect in the plane, you can move a little bit.",
                    "label": 0
                },
                {
                    "sent": "It's not so sensitive.",
                    "label": 0
                },
                {
                    "sent": "Go to Adobe Systems.",
                    "label": 0
                },
                {
                    "sent": "I just wanted to ask you about the precision of the algorithm for detecting depth along edges, because I notice that in the cards example there seems to be maybe like 2 three pixels of difference on which one the edge detection.",
                    "label": 0
                },
                {
                    "sent": "If you go.",
                    "label": 0
                },
                {
                    "sent": "A little further back.",
                    "label": 0
                },
                {
                    "sent": "Further back.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Yet here, so along the edges of the cards, how precise do you think you can?",
                    "label": 0
                },
                {
                    "sent": "Actually?",
                    "label": 0
                },
                {
                    "sent": "This is a very naive algorithm.",
                    "label": 0
                },
                {
                    "sent": "We just take two images and based on Patch based method to estimate the depth map with into any post processing.",
                    "label": 1
                },
                {
                    "sent": "If we want deal with the boundary, I think we need you.",
                    "label": 0
                },
                {
                    "sent": "Some bad algorithms.",
                    "label": 0
                },
                {
                    "sent": "Actually, this algorithm has been well studied, studied in depth from defocus.",
                    "label": 0
                },
                {
                    "sent": "OK, so you think that if we have multiple images it would be possible to improve this multiple image with the diffuser at different position?",
                    "label": 0
                },
                {
                    "sent": "OK yeah maybe yeah thanks.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Rely on the object.",
                    "label": 0
                },
                {
                    "sent": "How much does your algorithm rely on the object?",
                    "label": 0
                },
                {
                    "sent": "Having a lot of texture because I know if the color is uniform, you might not be able to tell how much the diffuser which method would require rich texture to work well if it was a texture is kind of weak then the depth map will be very sparse.",
                    "label": 0
                },
                {
                    "sent": "I think this is a common issue also for depth from defocus and many other.",
                    "label": 0
                },
                {
                    "sent": "Technique.",
                    "label": 0
                },
                {
                    "sent": "Can you talk something about like applying this for video?",
                    "label": 0
                },
                {
                    "sent": "Say if I want to get the depth map for video?",
                    "label": 0
                },
                {
                    "sent": "I mean, yeah, it's a great question.",
                    "label": 0
                },
                {
                    "sent": "So the problem actually is how can we recover tabs from a single image?",
                    "label": 0
                },
                {
                    "sent": "Write something like that?",
                    "label": 0
                },
                {
                    "sent": "Because if you take a video you need to because this method need positive user and remove this user.",
                    "label": 0
                },
                {
                    "sent": "Of course you can come up with some techniques like you can design A diffuser for each different part.",
                    "label": 0
                },
                {
                    "sent": "You have different diffusion angle.",
                    "label": 0
                },
                {
                    "sent": "Then you can swipe the diffuser over the object and take a video and you may be able to recover the depth map for the video.",
                    "label": 0
                },
                {
                    "sent": "How is the processing speed?",
                    "label": 0
                },
                {
                    "sent": "Processing can you do this in real time?",
                    "label": 0
                },
                {
                    "sent": "That's what depends on which kind of algorithm we're going to use.",
                    "label": 0
                },
                {
                    "sent": "If you some simple like a four year transform based method, I think we can.",
                    "label": 0
                },
                {
                    "sent": "OK, just where do you put the diffuser?",
                    "label": 0
                },
                {
                    "sent": "Diffuser should be right in front of the object.",
                    "label": 0
                },
                {
                    "sent": "The closer the better.",
                    "label": 0
                },
                {
                    "sent": "If they closed the object you get high precision and high resolution depth map.",
                    "label": 0
                },
                {
                    "sent": "If you move the diffuser away from objects and resolution of depth map will decrease.",
                    "label": 0
                },
                {
                    "sent": "OK so you don't think you can just put it in front of the camera and then do that.",
                    "label": 0
                },
                {
                    "sent": "Yeah no, I think it should be close to the object.",
                    "label": 0
                },
                {
                    "sent": "OK, thanks.",
                    "label": 0
                },
                {
                    "sent": "Let's thank the speaker one more time.",
                    "label": 0
                }
            ]
        }
    }
}