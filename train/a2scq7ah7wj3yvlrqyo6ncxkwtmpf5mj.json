{
    "id": "a2scq7ah7wj3yvlrqyo6ncxkwtmpf5mj",
    "title": "Sequential Information Maximization: When is Greedy Near-optimal?",
    "info": {
        "author": [
            "Yuxin Chen, Department of Computer Science, ETH Zurich"
        ],
        "published": "Aug. 20, 2015",
        "recorded": "July 2015",
        "category": [
            "Top->Computer Science->Machine Learning->Active Learning",
            "Top->Computer Science->Machine Learning->Computational Learning Theory",
            "Top->Computer Science->Machine Learning->On-line Learning",
            "Top->Computer Science->Machine Learning->Reinforcement Learning",
            "Top->Computer Science->Machine Learning->Semi-supervised Learning"
        ]
    },
    "url": "http://videolectures.net/colt2015_chen_information_maximization/",
    "segmentation": [
        [
            "Good morning everyone.",
            "My name is Wilson and I'm going to talk about our work on analyzing the greedy algorithm for the sequential information maximization problem.",
            "Alright, so this is joint work with my colleagues.",
            "Haha sunny from ATHI mean karbassi from yell and measure Andress crouser."
        ],
        [
            "OK, so let's start with an example.",
            "Suppose we take a."
        ],
        [
            "Be too bad clinic and we're trying to find out what disease it has, right?",
            "So we come to."
        ],
        [
            "Doctor and a doctor have some prior belief on the possible disease that there could possibly be.",
            "Oops, sorry.",
            "So now in this example, the amount of uncertainty in the disease in the hypothesis space is quite high.",
            "As we can see here and introduce 2."
        ],
        [
            "So based on the prior belief about the hypothesis, Doctor Pick one test."
        ],
        [
            "And then observe his outcome.",
            "So once we see this outcome, the doctor update the posterior belief about hypothesis."
        ],
        [
            "Alright, and then she should actually pick the next test to perform.",
            "And then a observed outcome."
        ],
        [
            "And then update prior to the posterior."
        ],
        [
            "And then pick the next test and so on."
        ],
        [
            "So as we can see from this."
        ],
        [
            "Example, the choice."
        ],
        [
            "Size of the next."
        ],
        [
            "This depends on the previous realization."
        ],
        [
            "Of the past test.",
            "I and if we if we observe something differently, then the performance will be different.",
            "So the natural question to ask is what is the optimal policy for the doctor to use and what is the most informative policy, right?"
        ],
        [
            "It turns out the finding the most informative policy is a problem.",
            "And in practice, people often use greedy heuristic which at each time it picks the maximum test with the maximum reduction in entropy on the hypothesis space.",
            "Given the past observations we have seen so far."
        ],
        [
            "So it turns out that this most informative selection policy has been widely used and started since the 1950s.",
            "And there are various number of applications including active learning, experimental design, active hypothesis testing and stickers to Boolean function, valuation and so on.",
            "Theoretically speaking, in a non adaptive case where we commit to other test before we even perform the test, the greedy algorithm is proven to be acting near optimally.",
            "And in the adaptive case where there is no noise on the test, the greedy algorithm also enjoy the same theoretical guarantee.",
            "So if we if we consider noise on the test, but we assume that.",
            "The test can be repeated with ID outcome.",
            "Then this scenario can be effectively reduced to the noiseless case by simply repeat the test for a fair amount of time.",
            "So in our paper, we present the first regular regular analysis of the gradient policy in the persistent noise setting, where the effect of the noise on the test remains the same every time.",
            "Repeat the test.",
            "So this is a very common case in practice, because say for the medical diagnostic example, a doctor can only perform the test on the patient once.",
            "So here's a quick look at our result."
        ],
        [
            "In our paper, we relate the performance of the greedy algorithm, meaning the information that can never be gathered by running greedy algorithm for K prime rounds.",
            "With the performance of the optimal algorithm, which is the maximum amount of information that can ever be obtained by running an algorithm of key rounds with the multiplicative factor.",
            "And this is this is a constant, so roughly speaking.",
            "To gain some information close to the optimal algorithm which will run for key rounds when it will run the greedy algorithm for an order of K times log in divided by as mean round.",
            "So this as manufacturer is a natural characterization of the noise in the model.",
            "So when the noise level is is low, for example, that means high, which means our lower or bound on the gritty performances reasonably good.",
            "So later on we show one example like demonstrating that the the effect or independency of the parameter asked mean our lower bound is necessary.",
            "OK."
        ],
        [
            "So if you are more interested please come talk with us and or we're going to have a longer talk in Asthma Workshop, so this, well, welcome to come as well.",
            "Thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Good morning everyone.",
                    "label": 0
                },
                {
                    "sent": "My name is Wilson and I'm going to talk about our work on analyzing the greedy algorithm for the sequential information maximization problem.",
                    "label": 1
                },
                {
                    "sent": "Alright, so this is joint work with my colleagues.",
                    "label": 0
                },
                {
                    "sent": "Haha sunny from ATHI mean karbassi from yell and measure Andress crouser.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so let's start with an example.",
                    "label": 0
                },
                {
                    "sent": "Suppose we take a.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Be too bad clinic and we're trying to find out what disease it has, right?",
                    "label": 0
                },
                {
                    "sent": "So we come to.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Doctor and a doctor have some prior belief on the possible disease that there could possibly be.",
                    "label": 0
                },
                {
                    "sent": "Oops, sorry.",
                    "label": 0
                },
                {
                    "sent": "So now in this example, the amount of uncertainty in the disease in the hypothesis space is quite high.",
                    "label": 0
                },
                {
                    "sent": "As we can see here and introduce 2.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So based on the prior belief about the hypothesis, Doctor Pick one test.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then observe his outcome.",
                    "label": 0
                },
                {
                    "sent": "So once we see this outcome, the doctor update the posterior belief about hypothesis.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Alright, and then she should actually pick the next test to perform.",
                    "label": 0
                },
                {
                    "sent": "And then a observed outcome.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then update prior to the posterior.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then pick the next test and so on.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So as we can see from this.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Example, the choice.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Size of the next.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This depends on the previous realization.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Of the past test.",
                    "label": 0
                },
                {
                    "sent": "I and if we if we observe something differently, then the performance will be different.",
                    "label": 0
                },
                {
                    "sent": "So the natural question to ask is what is the optimal policy for the doctor to use and what is the most informative policy, right?",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It turns out the finding the most informative policy is a problem.",
                    "label": 0
                },
                {
                    "sent": "And in practice, people often use greedy heuristic which at each time it picks the maximum test with the maximum reduction in entropy on the hypothesis space.",
                    "label": 0
                },
                {
                    "sent": "Given the past observations we have seen so far.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So it turns out that this most informative selection policy has been widely used and started since the 1950s.",
                    "label": 0
                },
                {
                    "sent": "And there are various number of applications including active learning, experimental design, active hypothesis testing and stickers to Boolean function, valuation and so on.",
                    "label": 0
                },
                {
                    "sent": "Theoretically speaking, in a non adaptive case where we commit to other test before we even perform the test, the greedy algorithm is proven to be acting near optimally.",
                    "label": 0
                },
                {
                    "sent": "And in the adaptive case where there is no noise on the test, the greedy algorithm also enjoy the same theoretical guarantee.",
                    "label": 0
                },
                {
                    "sent": "So if we if we consider noise on the test, but we assume that.",
                    "label": 0
                },
                {
                    "sent": "The test can be repeated with ID outcome.",
                    "label": 0
                },
                {
                    "sent": "Then this scenario can be effectively reduced to the noiseless case by simply repeat the test for a fair amount of time.",
                    "label": 0
                },
                {
                    "sent": "So in our paper, we present the first regular regular analysis of the gradient policy in the persistent noise setting, where the effect of the noise on the test remains the same every time.",
                    "label": 0
                },
                {
                    "sent": "Repeat the test.",
                    "label": 0
                },
                {
                    "sent": "So this is a very common case in practice, because say for the medical diagnostic example, a doctor can only perform the test on the patient once.",
                    "label": 0
                },
                {
                    "sent": "So here's a quick look at our result.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In our paper, we relate the performance of the greedy algorithm, meaning the information that can never be gathered by running greedy algorithm for K prime rounds.",
                    "label": 1
                },
                {
                    "sent": "With the performance of the optimal algorithm, which is the maximum amount of information that can ever be obtained by running an algorithm of key rounds with the multiplicative factor.",
                    "label": 0
                },
                {
                    "sent": "And this is this is a constant, so roughly speaking.",
                    "label": 0
                },
                {
                    "sent": "To gain some information close to the optimal algorithm which will run for key rounds when it will run the greedy algorithm for an order of K times log in divided by as mean round.",
                    "label": 1
                },
                {
                    "sent": "So this as manufacturer is a natural characterization of the noise in the model.",
                    "label": 0
                },
                {
                    "sent": "So when the noise level is is low, for example, that means high, which means our lower or bound on the gritty performances reasonably good.",
                    "label": 0
                },
                {
                    "sent": "So later on we show one example like demonstrating that the the effect or independency of the parameter asked mean our lower bound is necessary.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So if you are more interested please come talk with us and or we're going to have a longer talk in Asthma Workshop, so this, well, welcome to come as well.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                }
            ]
        }
    }
}