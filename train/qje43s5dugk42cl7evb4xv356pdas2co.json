{
    "id": "qje43s5dugk42cl7evb4xv356pdas2co",
    "title": "A simple multi-armed bandit algorithm with optimal variation-bounded regret",
    "info": {
        "author": [
            "Elad Hazan, Technion - Israel Institute of Technology"
        ],
        "published": "Aug. 2, 2011",
        "recorded": "July 2011",
        "category": [
            "Top->Computer Science->Algorithms and Data Structures"
        ]
    },
    "url": "http://videolectures.net/colt2011_hazan_regret/",
    "segmentation": [
        [
            "OK hi my name is Ella cousin.",
            "I introduce the problem which is.",
            "Device together with certain column.",
            "My colleague from Yahoo and moving to IBM and this problem deals with the multi armed bandit problem and specifically with the variation variation or regret bound for it."
        ],
        [
            "So just for, I'm sure all of you know about the multi armed bandit problem, but I will iterate it just for safety.",
            "So this is a fundamental decision making problem introduced by Robbins in the 50s and you can think of a decision maker who is K options to choose from, K decisions to choose from.",
            "So she makes a decision which we denoted by XT, and then she receives the loss which is between zero and one.",
            "And this is iterated again and again.",
            "And finally, we would like to have our average regret, which is the difference between our average loss and average loss of the best armor based decision.",
            "Go to zero as the number of iterations goes to Infinity.",
            "So again, it's a very Canonical machine learning primitive."
        ],
        [
            "And some known well known downs on this.",
            "I'm skipping a few years after Romans and lie.",
            "All men's seminal work.",
            "So this is I guess from the 90s by Peter will, nicholasa, Bianchi, and Fisher.",
            "They get log T regret bound for the stochastic setting, stochastic by stochastic I mean that each decision and by the way this is an open problem session, right?",
            "So you can feel free to shout in the middle and and ask questions so so this.",
            "This log T bound is for the case where each decision the loss come is a random variable IID random variable with a mean and fixed mean and variance.",
            "And the the Seminole work of ours is a Bianchi Freund and shop Erie, which was later improved by Audible and Bubeck gives the root T bound.",
            "So will TKK is the number of decisions.",
            "And here we have no assumptions whatsoever on the last sequence there can be arbitrary and even adversarial.",
            "First of all, that's problem dependent mode, right?",
            "That is, that is for the stochastic setting.",
            "Yeah yeah, stochastic setting and the second bound is assumption less completely assumptions.",
            "And both results are optimal in the sense that none of them can be improved by more than a constant, regardless of any computational yes question, I think I just want to repeat what it said.",
            "So the first bond is not a minimal spot, right?",
            "Like it's not the uniform bond, it's it's an individual bond like that.",
            "That is correct.",
            "Yes, that is correct.",
            "So this is like.",
            "It is these are different.",
            "These are different results, very different, even regret is I don't want to go into too much details.",
            "I only have, well, actually.",
            "I thought it's 5 minutes.",
            "I have 15.",
            "I don't know why it's so long, but now I get an answer so I have more time ask more."
        ],
        [
            "OK, so yeah, so we want so can we be more optimal so this reminds me of work from the complexity community.",
            "You know you keep on getting papers that there's more and more optimal bounds for such and such.",
            "So I said this is optimal in the sense in the sense of dependence on the number of iterations.",
            "But we can measure regret with a different metric, namely a metric called variation and variation is defined by if we have mu as the empirical mean of the vector of losses.",
            "We can define the variation by the sum of deviations from it by using the squared Euclidean norm.",
            "Again, assumption less adversarial, fully adversarial setting.",
            "This is a very natural measure.",
            "First of all, it is always bounded by the number of iterations times.",
            "Ki should note, but so bounding the regret by the valuation we lose nothing.",
            "On the other hand is it is meaningful in the statistical setting.",
            "It corresponds to something like the variance multiplied by number of iterations it interpolates between statistical and worst case settings.",
            "If all the losses are the same, we have Q to be 0.",
            "And the people who introduced this notion and ask the question?",
            "Or it's a Bianchi Mansour installs, they ask, can we get regret which is bounded by square root of this quantity Q rather than the number of iterations?",
            "Which is of course always strictly better than the previous bounds.",
            "And that's how we can be more optimal than."
        ],
        [
            "So in a sequence of work together with satian colour we have, we have obtained some bounds which depend on Q on the variation for for some online settings and namely the full information settings for online linear optimization.",
            "Also some log bounds for portfolio selection.",
            "And finally the problem that I'm interested in today, the multi armed bandit problem.",
            "We obtain some wood Q bounds, but.",
            "The important one is the one over here for the vanilla discrete multi unbanded problem.",
            "And this bound looks like K squared would Q, so K is the number of decisions, and that's an unfortunate.",
            "Well, unfortunately, but that's the best that we know term that we have there.",
            "And that's one unfortunate aspect of this result.",
            "The other is that the algorithm is very complicated.",
            "It is based on an algorithm by a bernetti myself from Rocklin for online optimization, which is uses some heavyweight techniques, and it has a slow running polynomially, but small running but large running time.",
            "And it has a bunch of other tricks inside, namely reservoir sampling, and we measure deviation.",
            "We estimate the losses by measuring deviations from the mean, not completely, and you.",
            "So the host of techniques here and the algorithm overall is complicated and slow and have this K squared factor in front."
        ],
        [
            "So to get to the main point is that the question is the following.",
            "Can you get a simple algorithm simple and elementary like the one introduced by our return?",
            "With regret, which is bounded by RT Q No K squared and know nothing linear time algorithm which would look like the well known expert three algorithm or the multiplicative weights based algorithms that we all know and love.",
            "And with maybe a little bit of one minute, liquor just finished my sentence yeah.",
            "And it doesn't have the New England will have to have a factor.",
            "So yeah, I said this Q here is actually the sum of variations.",
            "It's a vector variation, so it has a key embedded in it.",
            "So this is.",
            "So this in particular, this would be a root Katie in the worst case, but obviously in the statistical setting it could be much better.",
            "Thanks.",
            "So the question is, find nice, beautiful multiplicative update, simple algorithm with optimal bound.",
            "It should look like X3 with I can throw you in the direction which I think is correct.",
            "With the estimating the mean and estimating the losses, not the absolute losses, but their deviation from the mean so far historically historically shifted losses.",
            "And Shy Manor warned me that someone might solve that today in this conference.",
            "So if someone does, he will be treated to a restaurant in Budapest and otherwise in Tel Aviv.",
            "Self.",
            "OK any full Philly?",
            "Pray the travel expenses.",
            "That will be the largest amount ever offered, so that's on your own.",
            "Any further questions?",
            "We did figure out the log.",
            "That said, we didn't do a gap thing, but we define queue to be the sum of the variances of the arms, but we want to result without the gap and this is what you get in the Heidi settings.",
            "I think this is what you would get if you measure regret, so the usual way this state regret bounds in the statistical setting.",
            "They look not at the empirical.",
            "Mean, but the expected you know that there is.",
            "It's the same thing, but there is a whole T difference, right?",
            "Because the the expected loss, the best expected loss and the best experience loss.",
            "They differ by route.",
            "That's right, so if you are you don't care bout the logs.",
            "If you look at the hotel and then this is what you would get in the statistical setting exactly exactly.",
            "This is what you get.",
            "Yeah, so that's why this is sort of.",
            "This is the SMS conjectural stuff, that's why they guess this should be the correct measure, yeah?",
            "Oh yeah, please.",
            "The next three doesn't really drink, so.",
            "A good question.",
            "I guess it doesn't, but I don't know.",
            "I don't remember if I know how to prove it or not.",
            "I might know at some point I.",
            "My guess is that it doesn't do the trick.",
            "That's my guess because I somehow I feel I'm sorry I don't.",
            "I cannot see you.",
            "Somehow I feel that you need to estimate the difference from the historical mean.",
            "You cannot try to estimate as if you know nothing, because if you really let the valuation 0 right, you need to take into account what you remember from before.",
            "Three somehow doesn't do it.",
            "It's sort of.",
            "It constructs.",
            "An estimator was one over.",
            "The payoff at coordinate I is one over the probability for that coordinate without adjusting for the from the previous mean.",
            "So I think adjusting for the previous mean is important, but who knows?",
            "My exponent itself might might do it.",
            "OK.",
            "Thanks."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK hi my name is Ella cousin.",
                    "label": 0
                },
                {
                    "sent": "I introduce the problem which is.",
                    "label": 0
                },
                {
                    "sent": "Device together with certain column.",
                    "label": 0
                },
                {
                    "sent": "My colleague from Yahoo and moving to IBM and this problem deals with the multi armed bandit problem and specifically with the variation variation or regret bound for it.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So just for, I'm sure all of you know about the multi armed bandit problem, but I will iterate it just for safety.",
                    "label": 0
                },
                {
                    "sent": "So this is a fundamental decision making problem introduced by Robbins in the 50s and you can think of a decision maker who is K options to choose from, K decisions to choose from.",
                    "label": 1
                },
                {
                    "sent": "So she makes a decision which we denoted by XT, and then she receives the loss which is between zero and one.",
                    "label": 0
                },
                {
                    "sent": "And this is iterated again and again.",
                    "label": 0
                },
                {
                    "sent": "And finally, we would like to have our average regret, which is the difference between our average loss and average loss of the best armor based decision.",
                    "label": 0
                },
                {
                    "sent": "Go to zero as the number of iterations goes to Infinity.",
                    "label": 0
                },
                {
                    "sent": "So again, it's a very Canonical machine learning primitive.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And some known well known downs on this.",
                    "label": 0
                },
                {
                    "sent": "I'm skipping a few years after Romans and lie.",
                    "label": 0
                },
                {
                    "sent": "All men's seminal work.",
                    "label": 0
                },
                {
                    "sent": "So this is I guess from the 90s by Peter will, nicholasa, Bianchi, and Fisher.",
                    "label": 0
                },
                {
                    "sent": "They get log T regret bound for the stochastic setting, stochastic by stochastic I mean that each decision and by the way this is an open problem session, right?",
                    "label": 0
                },
                {
                    "sent": "So you can feel free to shout in the middle and and ask questions so so this.",
                    "label": 0
                },
                {
                    "sent": "This log T bound is for the case where each decision the loss come is a random variable IID random variable with a mean and fixed mean and variance.",
                    "label": 0
                },
                {
                    "sent": "And the the Seminole work of ours is a Bianchi Freund and shop Erie, which was later improved by Audible and Bubeck gives the root T bound.",
                    "label": 0
                },
                {
                    "sent": "So will TKK is the number of decisions.",
                    "label": 0
                },
                {
                    "sent": "And here we have no assumptions whatsoever on the last sequence there can be arbitrary and even adversarial.",
                    "label": 0
                },
                {
                    "sent": "First of all, that's problem dependent mode, right?",
                    "label": 0
                },
                {
                    "sent": "That is, that is for the stochastic setting.",
                    "label": 1
                },
                {
                    "sent": "Yeah yeah, stochastic setting and the second bound is assumption less completely assumptions.",
                    "label": 0
                },
                {
                    "sent": "And both results are optimal in the sense that none of them can be improved by more than a constant, regardless of any computational yes question, I think I just want to repeat what it said.",
                    "label": 1
                },
                {
                    "sent": "So the first bond is not a minimal spot, right?",
                    "label": 0
                },
                {
                    "sent": "Like it's not the uniform bond, it's it's an individual bond like that.",
                    "label": 0
                },
                {
                    "sent": "That is correct.",
                    "label": 0
                },
                {
                    "sent": "Yes, that is correct.",
                    "label": 0
                },
                {
                    "sent": "So this is like.",
                    "label": 0
                },
                {
                    "sent": "It is these are different.",
                    "label": 0
                },
                {
                    "sent": "These are different results, very different, even regret is I don't want to go into too much details.",
                    "label": 0
                },
                {
                    "sent": "I only have, well, actually.",
                    "label": 0
                },
                {
                    "sent": "I thought it's 5 minutes.",
                    "label": 0
                },
                {
                    "sent": "I have 15.",
                    "label": 0
                },
                {
                    "sent": "I don't know why it's so long, but now I get an answer so I have more time ask more.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so yeah, so we want so can we be more optimal so this reminds me of work from the complexity community.",
                    "label": 1
                },
                {
                    "sent": "You know you keep on getting papers that there's more and more optimal bounds for such and such.",
                    "label": 0
                },
                {
                    "sent": "So I said this is optimal in the sense in the sense of dependence on the number of iterations.",
                    "label": 0
                },
                {
                    "sent": "But we can measure regret with a different metric, namely a metric called variation and variation is defined by if we have mu as the empirical mean of the vector of losses.",
                    "label": 0
                },
                {
                    "sent": "We can define the variation by the sum of deviations from it by using the squared Euclidean norm.",
                    "label": 0
                },
                {
                    "sent": "Again, assumption less adversarial, fully adversarial setting.",
                    "label": 1
                },
                {
                    "sent": "This is a very natural measure.",
                    "label": 0
                },
                {
                    "sent": "First of all, it is always bounded by the number of iterations times.",
                    "label": 0
                },
                {
                    "sent": "Ki should note, but so bounding the regret by the valuation we lose nothing.",
                    "label": 0
                },
                {
                    "sent": "On the other hand is it is meaningful in the statistical setting.",
                    "label": 0
                },
                {
                    "sent": "It corresponds to something like the variance multiplied by number of iterations it interpolates between statistical and worst case settings.",
                    "label": 0
                },
                {
                    "sent": "If all the losses are the same, we have Q to be 0.",
                    "label": 0
                },
                {
                    "sent": "And the people who introduced this notion and ask the question?",
                    "label": 0
                },
                {
                    "sent": "Or it's a Bianchi Mansour installs, they ask, can we get regret which is bounded by square root of this quantity Q rather than the number of iterations?",
                    "label": 1
                },
                {
                    "sent": "Which is of course always strictly better than the previous bounds.",
                    "label": 0
                },
                {
                    "sent": "And that's how we can be more optimal than.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So in a sequence of work together with satian colour we have, we have obtained some bounds which depend on Q on the variation for for some online settings and namely the full information settings for online linear optimization.",
                    "label": 0
                },
                {
                    "sent": "Also some log bounds for portfolio selection.",
                    "label": 1
                },
                {
                    "sent": "And finally the problem that I'm interested in today, the multi armed bandit problem.",
                    "label": 0
                },
                {
                    "sent": "We obtain some wood Q bounds, but.",
                    "label": 0
                },
                {
                    "sent": "The important one is the one over here for the vanilla discrete multi unbanded problem.",
                    "label": 0
                },
                {
                    "sent": "And this bound looks like K squared would Q, so K is the number of decisions, and that's an unfortunate.",
                    "label": 0
                },
                {
                    "sent": "Well, unfortunately, but that's the best that we know term that we have there.",
                    "label": 0
                },
                {
                    "sent": "And that's one unfortunate aspect of this result.",
                    "label": 0
                },
                {
                    "sent": "The other is that the algorithm is very complicated.",
                    "label": 0
                },
                {
                    "sent": "It is based on an algorithm by a bernetti myself from Rocklin for online optimization, which is uses some heavyweight techniques, and it has a slow running polynomially, but small running but large running time.",
                    "label": 1
                },
                {
                    "sent": "And it has a bunch of other tricks inside, namely reservoir sampling, and we measure deviation.",
                    "label": 0
                },
                {
                    "sent": "We estimate the losses by measuring deviations from the mean, not completely, and you.",
                    "label": 0
                },
                {
                    "sent": "So the host of techniques here and the algorithm overall is complicated and slow and have this K squared factor in front.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So to get to the main point is that the question is the following.",
                    "label": 0
                },
                {
                    "sent": "Can you get a simple algorithm simple and elementary like the one introduced by our return?",
                    "label": 0
                },
                {
                    "sent": "With regret, which is bounded by RT Q No K squared and know nothing linear time algorithm which would look like the well known expert three algorithm or the multiplicative weights based algorithms that we all know and love.",
                    "label": 0
                },
                {
                    "sent": "And with maybe a little bit of one minute, liquor just finished my sentence yeah.",
                    "label": 0
                },
                {
                    "sent": "And it doesn't have the New England will have to have a factor.",
                    "label": 0
                },
                {
                    "sent": "So yeah, I said this Q here is actually the sum of variations.",
                    "label": 0
                },
                {
                    "sent": "It's a vector variation, so it has a key embedded in it.",
                    "label": 0
                },
                {
                    "sent": "So this is.",
                    "label": 0
                },
                {
                    "sent": "So this in particular, this would be a root Katie in the worst case, but obviously in the statistical setting it could be much better.",
                    "label": 0
                },
                {
                    "sent": "Thanks.",
                    "label": 0
                },
                {
                    "sent": "So the question is, find nice, beautiful multiplicative update, simple algorithm with optimal bound.",
                    "label": 1
                },
                {
                    "sent": "It should look like X3 with I can throw you in the direction which I think is correct.",
                    "label": 0
                },
                {
                    "sent": "With the estimating the mean and estimating the losses, not the absolute losses, but their deviation from the mean so far historically historically shifted losses.",
                    "label": 0
                },
                {
                    "sent": "And Shy Manor warned me that someone might solve that today in this conference.",
                    "label": 0
                },
                {
                    "sent": "So if someone does, he will be treated to a restaurant in Budapest and otherwise in Tel Aviv.",
                    "label": 0
                },
                {
                    "sent": "Self.",
                    "label": 0
                },
                {
                    "sent": "OK any full Philly?",
                    "label": 0
                },
                {
                    "sent": "Pray the travel expenses.",
                    "label": 0
                },
                {
                    "sent": "That will be the largest amount ever offered, so that's on your own.",
                    "label": 0
                },
                {
                    "sent": "Any further questions?",
                    "label": 0
                },
                {
                    "sent": "We did figure out the log.",
                    "label": 0
                },
                {
                    "sent": "That said, we didn't do a gap thing, but we define queue to be the sum of the variances of the arms, but we want to result without the gap and this is what you get in the Heidi settings.",
                    "label": 0
                },
                {
                    "sent": "I think this is what you would get if you measure regret, so the usual way this state regret bounds in the statistical setting.",
                    "label": 0
                },
                {
                    "sent": "They look not at the empirical.",
                    "label": 0
                },
                {
                    "sent": "Mean, but the expected you know that there is.",
                    "label": 0
                },
                {
                    "sent": "It's the same thing, but there is a whole T difference, right?",
                    "label": 0
                },
                {
                    "sent": "Because the the expected loss, the best expected loss and the best experience loss.",
                    "label": 0
                },
                {
                    "sent": "They differ by route.",
                    "label": 0
                },
                {
                    "sent": "That's right, so if you are you don't care bout the logs.",
                    "label": 0
                },
                {
                    "sent": "If you look at the hotel and then this is what you would get in the statistical setting exactly exactly.",
                    "label": 0
                },
                {
                    "sent": "This is what you get.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so that's why this is sort of.",
                    "label": 0
                },
                {
                    "sent": "This is the SMS conjectural stuff, that's why they guess this should be the correct measure, yeah?",
                    "label": 0
                },
                {
                    "sent": "Oh yeah, please.",
                    "label": 0
                },
                {
                    "sent": "The next three doesn't really drink, so.",
                    "label": 0
                },
                {
                    "sent": "A good question.",
                    "label": 0
                },
                {
                    "sent": "I guess it doesn't, but I don't know.",
                    "label": 0
                },
                {
                    "sent": "I don't remember if I know how to prove it or not.",
                    "label": 0
                },
                {
                    "sent": "I might know at some point I.",
                    "label": 0
                },
                {
                    "sent": "My guess is that it doesn't do the trick.",
                    "label": 0
                },
                {
                    "sent": "That's my guess because I somehow I feel I'm sorry I don't.",
                    "label": 0
                },
                {
                    "sent": "I cannot see you.",
                    "label": 0
                },
                {
                    "sent": "Somehow I feel that you need to estimate the difference from the historical mean.",
                    "label": 0
                },
                {
                    "sent": "You cannot try to estimate as if you know nothing, because if you really let the valuation 0 right, you need to take into account what you remember from before.",
                    "label": 0
                },
                {
                    "sent": "Three somehow doesn't do it.",
                    "label": 0
                },
                {
                    "sent": "It's sort of.",
                    "label": 0
                },
                {
                    "sent": "It constructs.",
                    "label": 0
                },
                {
                    "sent": "An estimator was one over.",
                    "label": 0
                },
                {
                    "sent": "The payoff at coordinate I is one over the probability for that coordinate without adjusting for the from the previous mean.",
                    "label": 0
                },
                {
                    "sent": "So I think adjusting for the previous mean is important, but who knows?",
                    "label": 0
                },
                {
                    "sent": "My exponent itself might might do it.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "Thanks.",
                    "label": 0
                }
            ]
        }
    }
}