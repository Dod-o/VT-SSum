{
    "id": "kw2auu6a3sasfzqipaoej3zn5zl54ykd",
    "title": "Detecting weak but hierarchically-structured patterns in networks",
    "info": {
        "author": [
            "Aarti Singh, Machine Learning Department, School of Computer Science, Carnegie Mellon University"
        ],
        "published": "June 3, 2010",
        "recorded": "May 2010",
        "category": [
            "Top->Computer Science->Network Analysis"
        ]
    },
    "url": "http://videolectures.net/aistats2010_singh_dwbh/",
    "segmentation": [
        [
            "OK morning everyone.",
            "So yeah, first of all I'd like to acknowledge that I do have two collaborators, and somehow Robert Carter Banks name was missing from the schedule.",
            "So let me start by motivating the problem and talking about why it's important to."
        ],
        [
            "So, uh, detect weak patterns in networks and where do they actually arise?",
            "So the first problem is detecting congestion in the Internet, and any network administrator is interested in detecting when, say, round trip times are starting to change, but do that as soon as possible so when the congestion is starting to build up right?",
            "So at a single node, the congestion may not be statistically significant or the changes in round trip time rather may not be statistically significant.",
            "But because more than one node is affected, you.",
            "Would be able to take that information into account and detect the signal even before it's significant enough at a single node.",
            "And similarly, the second problem would be say in a sensor network where the network is monitoring some kind of biochemical spread, or a contamination and you would like to detect it at the very early stages when the congestion is very faint or weak in strength."
        ],
        [
            "So let me just mention that we're actually going to look at a special formulation of this problem and the observation model we consider is that we have a network of P nodes and at every node we have essentially a Gaussian observation with some mean which is mu times XI.",
            "It's just split into two quantities.",
            "So mu denotes the signal strength an X denotes whether or not the node observes that activity.",
            "So the normal condition is.",
            "That there's no activity in the network or everything is started, so no changes.",
            "That's the null hypothesis, and we are interested in detecting when does we get some activity in the network, which means that mu X is are the signal strength is bigger than zero for at least some of the nodes.",
            "OK, so just wanted to stress again that we have the signal is basically consists of a signal strength which is unknown as well as a binary pattern which indicates which are.",
            "The notes observed the signal and that binary pattern is also unknown.",
            "OK, so for people who are in statistics, this is the familiar normal means problem.",
            "If you're familiar with that.",
            "And essentially the question we are interested in is what is the weakest signal that we can detect as a function of your network para meters, and how might we be able to detect it?",
            "And a lot has been axed."
        ],
        [
            "Done in this problem, under the condition when the activity at each node is independent of each other.",
            "OK, so in this setup the current known results essentially say that if you assume some linear sparsity, which means that the number of nodes which are observed a particular activity are some linear in the sense.",
            "If you have P nodes and only Peter the 1 minus Alpha of them observe some activation, then the thresholds for what is the weakest signal you can detect or estimate scales essentially like square root 2 * a constant times log P. And the constant actually depends on the sparsity level.",
            "So the spot my sparsity, I mean that the number of nodes that are affected, or that observ the activity, so the fewer the notes, the higher the sparsity.",
            "The fewer the nodes that observe the signal, and so the more the signal strength you need, and that's what you see in this plot, and you can see that there are distinct regions, so for certain signal strengths you can actually estimate the signal, which means that you can actually recover the binary pattern exactly, so you can identify which nodes.",
            "Observe the activity and which ones did not, whereas there's another region where you may not be able to recover the whole binary pattern, but you can still say whether or not something is active in the network.",
            "So you can't say which nodes are.",
            "Are observing the activation, but you can save some nodes are OK, so that's the distinction between detection and estimation.",
            "But bottom line is that for both detection and estimation, the threshold essentially scales like square root log P, which is a fundamental limit imposed by essentially the marks of Goshen variables.",
            "So if you have Gaussian noise, this is the best you can do."
        ],
        [
            "And the problem we are looked at is that in a network these activations are never really independent, so the patterns that we observe possess some structure.",
            "And how can we exploit these dependencies in the network activation process to detect even weaker network activity?",
            "So what's the threshold of detection when you do take into account that there are dependencies in your network and how can we if we don't know these dependencies, how it might we be able to learn those?"
        ],
        [
            "So specifically, we're focused on hierarchically structured patterns.",
            "So in typical networks, if you think about it, typical patterns appear to be supported over multi scale groups of nodes.",
            "For example, in the Internet you might have a router fail, and then it will affect a group of nodes.",
            "It might fail, or it might like start to develop congestion, so it affects a bunch of nodes together, and the router could be placed anywhere in the net Internet.",
            "So you could have different variations of the support of the.",
            "Activity so it's supported over multiscale groups of nodes, and in this case actually, if you are monitoring from a single node, you are saved measuring round trip times to a bunch of end hosts, then the reason that the patterns are helical is really because your topology is tree structured, whereas in any other general case you may not have the topology wheat restructured, but you could have just hierarchical latent factors that are not observed, but that might determine your pattern.",
            "But in general it makes sense to talk about patterns that are.",
            "Localized over groups of nodes are different scales.",
            "And this is the basic assumption."
        ],
        [
            "If you're focused under, so just too.",
            "Make it more rigorous.",
            "Essentially the assumption we place is that we have a pattern supported over different clusters and these Inter Inter cluster similarity which means the similarity amongst nodes within a cluster is more than the similarity between any two nodes in different clusters.",
            "OK so if you look at the similarity matrix, that essentially looks like this hierarchical block structured form.",
            "Of course, within each block your similarity can vary, so even though my image shows it's constant, it can vary within a block, but just that it has this block structured form, so nodes within a cluster tend to be more correlated than nodes are more similar than nodes across different clusters.",
            "OK, that's"
        ],
        [
            "The basic assumption will work under.",
            "So the method we propose to detect take into account this hierarchical structure and detect much weaker patterns.",
            "Essentially just this basic idea that.",
            "OK, so first of all, let's say we know the network structure or this hierarchical dependency structure.",
            "Then we can come up with a transform.",
            "You can think of it that there is a hidden transform which we don't know of, and we can divide the transform that uses this network dependency structure to transform the data into another domain where it's much more sparser.",
            "OK, so the plot I have on the left essentially shows the network data and you can see it might the path through pattern that is there in red tends to be clustered on nodes.",
            "An essentially will come up with a transformation B which is an orthonormal basis that will essentially not change the noise but specify the signal or in some sensitive fused.",
            "A number of nodes are active into a few large signal coefficients.",
            "OK, so because you have a few single coefficients, the energy gets posted so it's easier to detect in the transform domain, and that's basically the idea.",
            "So we try to look for a transform that specifies these hierarchical structure patterns, takes advantage of that, and then you can basically use any favorite detection detector in the transform domain essentially, and the one we will focus on is simply looking at the largest value of the coefficients.",
            "For those of you who are more familiar with the detection problems, very often the scan statistic is used in detecting anomalies, and you can think of the marks of the transform coefficients is essentially a scan statistic, but confined to the basis patterns where only matching over the basis patterns and not all possible patterns that might occur.",
            "So it's like the absolute construction over your patterns."
        ],
        [
            "OK, so before I actually mentioned how you might construct this transform, let me just tell you why it's important and how much does it by to exploit the structure and construct this transform.",
            "OK, so suppose we had in the Canonical domain we had Peter the 1 minus Alpha notes that we're observing the anomaly or this activation.",
            "Then in the transform domain, suppose you can come up with the transform.",
            "It specifies it even further.",
            "So now your sparsity is Peter.",
            "The 1 minus paid out, where beta is bigger than Alpha.",
            "So your signal is not compressed into fewer coefficients.",
            "Then essentially the signal strength, which was mu in the Canonical case now becomes knew times the maximum coefficient right?",
            "And the energy in the maximum coefficient is at least as large as the average energy.",
            "So the largest coefficient is at least as big as.",
            "Excuse me, square root of the energy in the signal, which is just norm X, not because it's a binary Patton divided by the number of coefficients that are non 0.",
            "So it's just the ratio of the sparsity in the two domains.",
            "Essentially what this says is that the Canonical domain limit we know for identifying these patterns was fixed at square root of log P. You can do not do much better than that, but by exploiting this transform now you get polynomial increase in the amount of signal strength that you can detect so you can detect much weaker signals and the amount of improvement is essentially given by P to the minus beta minus Alpha over two.",
            "We have better an Alpha or the sparsity's in the tools respective domains.",
            "So if we can construct a transform, it sparsifying these binary structured patterns, then we get a huge improvement in the detection threshold.",
            "OK, so the rest of the talk will basically.",
            "I'll just focus on proposing this transform and what kind of patterns it specifies.",
            "And we see that if we have that, then he should be doing pretty well in terms of return."
        ],
        [
            "So.",
            "I mean, if you think about binary patterns that have some hierarchical structure, the first thing that comes to mind is to use some kind of wavelets, right?",
            "They're very good for the sparsifying.",
            "These kind of patterns.",
            "Unfortunately.",
            "Wavelets are only known for standard domain, where everything is equally spaced and we're talking about a network or a graph here, but it's easy to actually extend the wavelet framework, at least for binary patterns, and the simple technique.",
            "He uses hierarchical clustering followed by an unbalanced hard wavelet construction.",
            "So the idea is we have some hierarchical structure and let's assume for now that we know the dependency structure, so we know similarities between these different nodes and they tend to have that hierarchical block structured form that I mentioned before then.",
            "Essentially we just look for the most similar pair of clusters.",
            "So we start at the lowest level where we only have the leaves of the tree.",
            "We look for the most similar pair of clusters and we construct a basis vector on that.",
            "What is the basis vector?",
            "It's just constant on each of the two elements of the cluster.",
            "Positive on one and negative on the other.",
            "And just normalized by the size of each cluster.",
            "In this case, it's one each in the first part, and so the blue denotes negative.",
            "Say red denotes positive here, so this is 1 basis vector.",
            "Then you merge the two nodes that you just picked and you update the similarity to all other nodes by simply taking the average of the similarities of these nodes to other nodes.",
            "And then you just repeat this process so you see in the next step will combine these two nodes at the third node and we get this unbalanced hardware which is negative 1.",
            "One of the on the new node that we merge than positive.",
            "Unconstant on the other two nodes and the strength on each is proportional to the number of nodes each cluster has.",
            "And so we can go on building this basis vector.",
            "And then finally we actually add in a global basis vector which is just constant over all the nodes.",
            "OK, so this turns out to be it's exactly orthonormal basis, and as you can see from the expression for the basis that and what it says is if I have a pattern that's constant on any two clusters C1 and C2, then if I project it onto this basis, I esentially get a 0 right?",
            "So it's sparsifying binary structured patterns that are supported over these clusters.",
            "Of notes multi scale clusters.",
            "So now you might say, well, this is nice.",
            "We have a transform, but in practice you never see that a whole cluster is actor right?",
            "In fact, as you have a few of the notes might observe the activity or may not observe the activity.",
            "So can we have a more realistic model for what kind of patterns does this transform?"
        ],
        [
            "If I.",
            "So we actually have a proposal for that.",
            "We look at a generated model for these hierarchically structured binary activations that's essentially based on the Ising model.",
            "So let me state what the icing model here is.",
            "It's built over a latent tree based graph, so all we observe are basically the leaves of this tree and then all the upper levels are hidden and they do not multi scale dependencies.",
            "So what this model says is that patterns for which there are more, no Dan parent agreements, they tend to be more likely, and there's a strength of interaction between each node and experience, which is determined by the level of the tree that you are looking at.",
            "So the gamma L here that strength of interaction, and we assume the strength of interaction increases with level, so at deeper levels nodes are more correlated or more.",
            "Interact, have stronger dependencies with each other as you will auditory the dependencies DK off so you can imagine that the patterns this will produce will tend to have these very focused kind of clusters at the bottom levels, and then as you go up the dependencies start to breakdown.",
            "So this supports the multiscale kind of groups, but allows for nodes to possibly deviate from the reading of their parents."
        ],
        [
            "So we can basically show that under this model.",
            "So if you consider a pattern that's generated by this latent tree based Ising model, here we are assuming for simplicity that the depth is the tree is not too unbalanced and we have uniform degree.",
            "And we forced the route to take the value 0.",
            "This is only important because we want the patterns to be canonically sparse.",
            "So if we allow the route to be zero or one, then you get sparse an on sparse patterns.",
            "So just to force Canonical domain sparsity so we can compare to previous results, we forced the route to take value 0, so route takes value zero and at a level gamma One North start flipping from the appearance with a certain probability that depends on gamma one and so on.",
            "For deeper levels and we can show is that under this model with high probability the Canonical sparsity.",
            "Skills as Peter the 1 minus gamma One will gamma one is the strength at this upper level, highest level and whereas the transform domain sparsity scales as gamma LP to the one minus gamma, which is the deepest level strength of interaction.",
            "So essentially what this is saying is that you tend to get patterns in Canonical domain, the normal domain.",
            "The patterns are essentially determined by whether or not things flip at the highest level, so you get these groups of activations together and the transform domain sparsity especially depends on how many change points are there in your pattern, and that's determined by the lowest level.",
            "But essentially, you can see that since we gamma L is larger than gamma one, we have a transform with sparsified these patterns and it would be useful for protection under this model."
        ],
        [
            "So, just to summarize, once again, if we know the dependency structure which is hierarchical, then we can have a transform that.",
            "If you project onto the transform, then your pattern gets sparsified answer your weak signals get amplified and then you can essentially use your favorite detector in the transform domain.",
            "And if you do that then you essentially get an improvement in your signal strength that you can detect by a factor that depends on essentially the ratio of the sparsity in the two levels.",
            "So you might ask, OK, what do we do?"
        ],
        [
            "We don't know the dependency structure of the network, right?",
            "Well, if you don't know this similarity matrix, or hierarchically structured graph.",
            "Then basically we are going to try to learn it right and actually show that since our procedure was based on hierarchical clustering, hierarchical clustering actually suffices to learn this model so.",
            "So for now I'll actually in the in the case where we don't know the dependency structure, let's focus on the similarity being the covariance matrix.",
            "Actually, the same arguments would hold for any similarity, as long as it satisfies the concentration inequality, but covariance is easier to work with.",
            "So basically we're assuming that now we have N snapshots of the network, so we have been on the network would end snapshots of it, then essentially our results show that with higher probability just from these snapshots at the leaves, you can learn the whole.",
            "Art restructure the latent restructure using only about log P of the measurements.",
            "So an only needs to scale like log P, and you can basically recover this tree structure under this condition that there's this gap between the Inter cluster and intra cluster similarities."
        ],
        [
            "And specifically what it says for the Ising model is that if you look at the covariance between any two elements in this tree based Ising model that is essentially proportional to the strength of interaction along the path that connects the shortest path that connects XI and XJ.",
            "So for the Ising model you do exactly have this hierarchical block structure similarity matrix, and so if you only use empirical covariance is you would still be able to recover this latent tree based Ising model using only measurements at the leaf nodes.",
            "By looking at covariances between them.",
            "So which is?",
            "I thought it was interesting result."
        ],
        [
            "Song.",
            "OK, so just to mention some experiments, so this was this is a simulation on our multiscale Ising model with 1296 leaves and degree of each node is 6 and we have 4 levels in the tree, so you can see that the blue line which denotes detection performance or the probability of detection versus signal strength.",
            "The blue line denotes the performance in the transform domain after you have done the projection onto this unbalanced heart basis and that outperforms several other detectors that we considered.",
            "In the Canonical domain, so we looked at the Max statistic in the Canonical domain Max of the just observations.",
            "Also, the global average statistic where you would some all the observations and test that against a threshold as well as false discovery rate statistic which which is proven to be slightly more efficient than the Mac statistic and standard domain Canonical domain.",
            "And you can see that it outperforms all of those, and in fact it does it for signal strength which are much weaker than the noise bond of .38 in this case.",
            "So all the signals friends are much weaker than that.",
            "Anne."
        ],
        [
            "I just briefly wanted to conclude by also mentioning some relatively new results which are not there in the paper, but we applied this technique to detect anomalies in networks and the figure I've shown on the left is actually Internet topology but simulated Internet topology using hot orbis graphs to plot it and the hot apologies.",
            "So if you look at the sample covariance matrix, which is generated based on this graph, so the graph is no longer this tree based Ising model, we're not sampling from that.",
            "So even when this condition under which our theory holds does not happen, even in that case, you can see that the sample covariance matrix for these kind of graphs actually tends to have this hierarchical block structure an if you build wavelets over it, then they do have this very nice property of inconstant on different clusters positive on one cluster, negative on the other, and it happens at multiple scales.",
            "So you can see that in the first basis vector you have this blue and red clusters of nodes and the second basis vector you actually refining one of the.",
            "Clusters in the first basis vector."
        ],
        [
            "And if you look at the performance and again in the transform basis, you get much better performance, which is the curves in red compared to the performance in the Canonical basis."
        ],
        [
            "And we have also looked at real Internet data an since there's no ground truth to verify whether you have detected anything or not.",
            "In this case you only look at compression that you might be able to achieve using round trip time measurements.",
            "So we look at Internet round trip time measurements sorted according to their magnitude, which is the blue lines.",
            "And if you project those onto this basis vector that we learned, then you can actually see that it does pacify those very well and so if there is an anomaly you would be you should be able to detect it much sooner using the transform domain.",
            "So I'll"
        ],
        [
            "Just like to end with that.",
            "And yeah, take any questions."
        ],
        [
            "So you make a very strong assumption that you get a full ride capestany, which always the maximum in cluster similarity is less than the minimum between cluster similarity.",
            "Now.",
            "Is there any realistic situation under which such a thing may happen?",
            "So we did observe that it happens for these Internet based graphs.",
            "Of course it does not hold exactly, you know perfection, but you do have this hierarchical block structured or tree based form and.",
            "Yeah, right, right?",
            "It is true.",
            "So yeah, if you have this Gaussian noise model, then this you actually need to have this gap to be able to say that OK.",
            "If all of your measurements can be corrupted by Gaussian noise, of course you need a gap to be able to distinguish the clusters.",
            "But we're also looking at cases where you might not have Gaussian measurement in all your observations, but only a few of the observations might be wrong.",
            "So most of your measurements are right, but you have a probability of error and then you can show something similar holds in that case as well.",
            "Are there any further questions anyway?",
            "I think you know, I notice that you didn't actually use information about which nodes are connected to whichever notes like the ages in the in the network, right?",
            "That is essentially incorporated when you're doing this clustering right?",
            "Because edges are essentially similarities in some sense, so you are using that structure to build the basis.",
            "Does that make sense?"
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK morning everyone.",
                    "label": 0
                },
                {
                    "sent": "So yeah, first of all I'd like to acknowledge that I do have two collaborators, and somehow Robert Carter Banks name was missing from the schedule.",
                    "label": 0
                },
                {
                    "sent": "So let me start by motivating the problem and talking about why it's important to.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So, uh, detect weak patterns in networks and where do they actually arise?",
                    "label": 1
                },
                {
                    "sent": "So the first problem is detecting congestion in the Internet, and any network administrator is interested in detecting when, say, round trip times are starting to change, but do that as soon as possible so when the congestion is starting to build up right?",
                    "label": 0
                },
                {
                    "sent": "So at a single node, the congestion may not be statistically significant or the changes in round trip time rather may not be statistically significant.",
                    "label": 0
                },
                {
                    "sent": "But because more than one node is affected, you.",
                    "label": 0
                },
                {
                    "sent": "Would be able to take that information into account and detect the signal even before it's significant enough at a single node.",
                    "label": 0
                },
                {
                    "sent": "And similarly, the second problem would be say in a sensor network where the network is monitoring some kind of biochemical spread, or a contamination and you would like to detect it at the very early stages when the congestion is very faint or weak in strength.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So let me just mention that we're actually going to look at a special formulation of this problem and the observation model we consider is that we have a network of P nodes and at every node we have essentially a Gaussian observation with some mean which is mu times XI.",
                    "label": 0
                },
                {
                    "sent": "It's just split into two quantities.",
                    "label": 0
                },
                {
                    "sent": "So mu denotes the signal strength an X denotes whether or not the node observes that activity.",
                    "label": 0
                },
                {
                    "sent": "So the normal condition is.",
                    "label": 0
                },
                {
                    "sent": "That there's no activity in the network or everything is started, so no changes.",
                    "label": 0
                },
                {
                    "sent": "That's the null hypothesis, and we are interested in detecting when does we get some activity in the network, which means that mu X is are the signal strength is bigger than zero for at least some of the nodes.",
                    "label": 0
                },
                {
                    "sent": "OK, so just wanted to stress again that we have the signal is basically consists of a signal strength which is unknown as well as a binary pattern which indicates which are.",
                    "label": 0
                },
                {
                    "sent": "The notes observed the signal and that binary pattern is also unknown.",
                    "label": 0
                },
                {
                    "sent": "OK, so for people who are in statistics, this is the familiar normal means problem.",
                    "label": 0
                },
                {
                    "sent": "If you're familiar with that.",
                    "label": 0
                },
                {
                    "sent": "And essentially the question we are interested in is what is the weakest signal that we can detect as a function of your network para meters, and how might we be able to detect it?",
                    "label": 1
                },
                {
                    "sent": "And a lot has been axed.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Done in this problem, under the condition when the activity at each node is independent of each other.",
                    "label": 1
                },
                {
                    "sent": "OK, so in this setup the current known results essentially say that if you assume some linear sparsity, which means that the number of nodes which are observed a particular activity are some linear in the sense.",
                    "label": 0
                },
                {
                    "sent": "If you have P nodes and only Peter the 1 minus Alpha of them observe some activation, then the thresholds for what is the weakest signal you can detect or estimate scales essentially like square root 2 * a constant times log P. And the constant actually depends on the sparsity level.",
                    "label": 0
                },
                {
                    "sent": "So the spot my sparsity, I mean that the number of nodes that are affected, or that observ the activity, so the fewer the notes, the higher the sparsity.",
                    "label": 0
                },
                {
                    "sent": "The fewer the nodes that observe the signal, and so the more the signal strength you need, and that's what you see in this plot, and you can see that there are distinct regions, so for certain signal strengths you can actually estimate the signal, which means that you can actually recover the binary pattern exactly, so you can identify which nodes.",
                    "label": 0
                },
                {
                    "sent": "Observe the activity and which ones did not, whereas there's another region where you may not be able to recover the whole binary pattern, but you can still say whether or not something is active in the network.",
                    "label": 0
                },
                {
                    "sent": "So you can't say which nodes are.",
                    "label": 0
                },
                {
                    "sent": "Are observing the activation, but you can save some nodes are OK, so that's the distinction between detection and estimation.",
                    "label": 0
                },
                {
                    "sent": "But bottom line is that for both detection and estimation, the threshold essentially scales like square root log P, which is a fundamental limit imposed by essentially the marks of Goshen variables.",
                    "label": 0
                },
                {
                    "sent": "So if you have Gaussian noise, this is the best you can do.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And the problem we are looked at is that in a network these activations are never really independent, so the patterns that we observe possess some structure.",
                    "label": 0
                },
                {
                    "sent": "And how can we exploit these dependencies in the network activation process to detect even weaker network activity?",
                    "label": 1
                },
                {
                    "sent": "So what's the threshold of detection when you do take into account that there are dependencies in your network and how can we if we don't know these dependencies, how it might we be able to learn those?",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So specifically, we're focused on hierarchically structured patterns.",
                    "label": 1
                },
                {
                    "sent": "So in typical networks, if you think about it, typical patterns appear to be supported over multi scale groups of nodes.",
                    "label": 0
                },
                {
                    "sent": "For example, in the Internet you might have a router fail, and then it will affect a group of nodes.",
                    "label": 0
                },
                {
                    "sent": "It might fail, or it might like start to develop congestion, so it affects a bunch of nodes together, and the router could be placed anywhere in the net Internet.",
                    "label": 0
                },
                {
                    "sent": "So you could have different variations of the support of the.",
                    "label": 0
                },
                {
                    "sent": "Activity so it's supported over multiscale groups of nodes, and in this case actually, if you are monitoring from a single node, you are saved measuring round trip times to a bunch of end hosts, then the reason that the patterns are helical is really because your topology is tree structured, whereas in any other general case you may not have the topology wheat restructured, but you could have just hierarchical latent factors that are not observed, but that might determine your pattern.",
                    "label": 1
                },
                {
                    "sent": "But in general it makes sense to talk about patterns that are.",
                    "label": 0
                },
                {
                    "sent": "Localized over groups of nodes are different scales.",
                    "label": 0
                },
                {
                    "sent": "And this is the basic assumption.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "If you're focused under, so just too.",
                    "label": 0
                },
                {
                    "sent": "Make it more rigorous.",
                    "label": 0
                },
                {
                    "sent": "Essentially the assumption we place is that we have a pattern supported over different clusters and these Inter Inter cluster similarity which means the similarity amongst nodes within a cluster is more than the similarity between any two nodes in different clusters.",
                    "label": 0
                },
                {
                    "sent": "OK so if you look at the similarity matrix, that essentially looks like this hierarchical block structured form.",
                    "label": 1
                },
                {
                    "sent": "Of course, within each block your similarity can vary, so even though my image shows it's constant, it can vary within a block, but just that it has this block structured form, so nodes within a cluster tend to be more correlated than nodes are more similar than nodes across different clusters.",
                    "label": 0
                },
                {
                    "sent": "OK, that's",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The basic assumption will work under.",
                    "label": 0
                },
                {
                    "sent": "So the method we propose to detect take into account this hierarchical structure and detect much weaker patterns.",
                    "label": 0
                },
                {
                    "sent": "Essentially just this basic idea that.",
                    "label": 0
                },
                {
                    "sent": "OK, so first of all, let's say we know the network structure or this hierarchical dependency structure.",
                    "label": 1
                },
                {
                    "sent": "Then we can come up with a transform.",
                    "label": 0
                },
                {
                    "sent": "You can think of it that there is a hidden transform which we don't know of, and we can divide the transform that uses this network dependency structure to transform the data into another domain where it's much more sparser.",
                    "label": 1
                },
                {
                    "sent": "OK, so the plot I have on the left essentially shows the network data and you can see it might the path through pattern that is there in red tends to be clustered on nodes.",
                    "label": 0
                },
                {
                    "sent": "An essentially will come up with a transformation B which is an orthonormal basis that will essentially not change the noise but specify the signal or in some sensitive fused.",
                    "label": 0
                },
                {
                    "sent": "A number of nodes are active into a few large signal coefficients.",
                    "label": 0
                },
                {
                    "sent": "OK, so because you have a few single coefficients, the energy gets posted so it's easier to detect in the transform domain, and that's basically the idea.",
                    "label": 0
                },
                {
                    "sent": "So we try to look for a transform that specifies these hierarchical structure patterns, takes advantage of that, and then you can basically use any favorite detection detector in the transform domain essentially, and the one we will focus on is simply looking at the largest value of the coefficients.",
                    "label": 0
                },
                {
                    "sent": "For those of you who are more familiar with the detection problems, very often the scan statistic is used in detecting anomalies, and you can think of the marks of the transform coefficients is essentially a scan statistic, but confined to the basis patterns where only matching over the basis patterns and not all possible patterns that might occur.",
                    "label": 0
                },
                {
                    "sent": "So it's like the absolute construction over your patterns.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so before I actually mentioned how you might construct this transform, let me just tell you why it's important and how much does it by to exploit the structure and construct this transform.",
                    "label": 0
                },
                {
                    "sent": "OK, so suppose we had in the Canonical domain we had Peter the 1 minus Alpha notes that we're observing the anomaly or this activation.",
                    "label": 0
                },
                {
                    "sent": "Then in the transform domain, suppose you can come up with the transform.",
                    "label": 0
                },
                {
                    "sent": "It specifies it even further.",
                    "label": 0
                },
                {
                    "sent": "So now your sparsity is Peter.",
                    "label": 0
                },
                {
                    "sent": "The 1 minus paid out, where beta is bigger than Alpha.",
                    "label": 0
                },
                {
                    "sent": "So your signal is not compressed into fewer coefficients.",
                    "label": 1
                },
                {
                    "sent": "Then essentially the signal strength, which was mu in the Canonical case now becomes knew times the maximum coefficient right?",
                    "label": 0
                },
                {
                    "sent": "And the energy in the maximum coefficient is at least as large as the average energy.",
                    "label": 0
                },
                {
                    "sent": "So the largest coefficient is at least as big as.",
                    "label": 0
                },
                {
                    "sent": "Excuse me, square root of the energy in the signal, which is just norm X, not because it's a binary Patton divided by the number of coefficients that are non 0.",
                    "label": 0
                },
                {
                    "sent": "So it's just the ratio of the sparsity in the two domains.",
                    "label": 0
                },
                {
                    "sent": "Essentially what this says is that the Canonical domain limit we know for identifying these patterns was fixed at square root of log P. You can do not do much better than that, but by exploiting this transform now you get polynomial increase in the amount of signal strength that you can detect so you can detect much weaker signals and the amount of improvement is essentially given by P to the minus beta minus Alpha over two.",
                    "label": 1
                },
                {
                    "sent": "We have better an Alpha or the sparsity's in the tools respective domains.",
                    "label": 0
                },
                {
                    "sent": "So if we can construct a transform, it sparsifying these binary structured patterns, then we get a huge improvement in the detection threshold.",
                    "label": 0
                },
                {
                    "sent": "OK, so the rest of the talk will basically.",
                    "label": 0
                },
                {
                    "sent": "I'll just focus on proposing this transform and what kind of patterns it specifies.",
                    "label": 0
                },
                {
                    "sent": "And we see that if we have that, then he should be doing pretty well in terms of return.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "I mean, if you think about binary patterns that have some hierarchical structure, the first thing that comes to mind is to use some kind of wavelets, right?",
                    "label": 0
                },
                {
                    "sent": "They're very good for the sparsifying.",
                    "label": 0
                },
                {
                    "sent": "These kind of patterns.",
                    "label": 0
                },
                {
                    "sent": "Unfortunately.",
                    "label": 0
                },
                {
                    "sent": "Wavelets are only known for standard domain, where everything is equally spaced and we're talking about a network or a graph here, but it's easy to actually extend the wavelet framework, at least for binary patterns, and the simple technique.",
                    "label": 0
                },
                {
                    "sent": "He uses hierarchical clustering followed by an unbalanced hard wavelet construction.",
                    "label": 0
                },
                {
                    "sent": "So the idea is we have some hierarchical structure and let's assume for now that we know the dependency structure, so we know similarities between these different nodes and they tend to have that hierarchical block structured form that I mentioned before then.",
                    "label": 0
                },
                {
                    "sent": "Essentially we just look for the most similar pair of clusters.",
                    "label": 0
                },
                {
                    "sent": "So we start at the lowest level where we only have the leaves of the tree.",
                    "label": 0
                },
                {
                    "sent": "We look for the most similar pair of clusters and we construct a basis vector on that.",
                    "label": 1
                },
                {
                    "sent": "What is the basis vector?",
                    "label": 0
                },
                {
                    "sent": "It's just constant on each of the two elements of the cluster.",
                    "label": 0
                },
                {
                    "sent": "Positive on one and negative on the other.",
                    "label": 0
                },
                {
                    "sent": "And just normalized by the size of each cluster.",
                    "label": 0
                },
                {
                    "sent": "In this case, it's one each in the first part, and so the blue denotes negative.",
                    "label": 0
                },
                {
                    "sent": "Say red denotes positive here, so this is 1 basis vector.",
                    "label": 0
                },
                {
                    "sent": "Then you merge the two nodes that you just picked and you update the similarity to all other nodes by simply taking the average of the similarities of these nodes to other nodes.",
                    "label": 0
                },
                {
                    "sent": "And then you just repeat this process so you see in the next step will combine these two nodes at the third node and we get this unbalanced hardware which is negative 1.",
                    "label": 0
                },
                {
                    "sent": "One of the on the new node that we merge than positive.",
                    "label": 0
                },
                {
                    "sent": "Unconstant on the other two nodes and the strength on each is proportional to the number of nodes each cluster has.",
                    "label": 0
                },
                {
                    "sent": "And so we can go on building this basis vector.",
                    "label": 0
                },
                {
                    "sent": "And then finally we actually add in a global basis vector which is just constant over all the nodes.",
                    "label": 0
                },
                {
                    "sent": "OK, so this turns out to be it's exactly orthonormal basis, and as you can see from the expression for the basis that and what it says is if I have a pattern that's constant on any two clusters C1 and C2, then if I project it onto this basis, I esentially get a 0 right?",
                    "label": 0
                },
                {
                    "sent": "So it's sparsifying binary structured patterns that are supported over these clusters.",
                    "label": 0
                },
                {
                    "sent": "Of notes multi scale clusters.",
                    "label": 0
                },
                {
                    "sent": "So now you might say, well, this is nice.",
                    "label": 0
                },
                {
                    "sent": "We have a transform, but in practice you never see that a whole cluster is actor right?",
                    "label": 0
                },
                {
                    "sent": "In fact, as you have a few of the notes might observe the activity or may not observe the activity.",
                    "label": 0
                },
                {
                    "sent": "So can we have a more realistic model for what kind of patterns does this transform?",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "If I.",
                    "label": 0
                },
                {
                    "sent": "So we actually have a proposal for that.",
                    "label": 0
                },
                {
                    "sent": "We look at a generated model for these hierarchically structured binary activations that's essentially based on the Ising model.",
                    "label": 1
                },
                {
                    "sent": "So let me state what the icing model here is.",
                    "label": 0
                },
                {
                    "sent": "It's built over a latent tree based graph, so all we observe are basically the leaves of this tree and then all the upper levels are hidden and they do not multi scale dependencies.",
                    "label": 0
                },
                {
                    "sent": "So what this model says is that patterns for which there are more, no Dan parent agreements, they tend to be more likely, and there's a strength of interaction between each node and experience, which is determined by the level of the tree that you are looking at.",
                    "label": 0
                },
                {
                    "sent": "So the gamma L here that strength of interaction, and we assume the strength of interaction increases with level, so at deeper levels nodes are more correlated or more.",
                    "label": 0
                },
                {
                    "sent": "Interact, have stronger dependencies with each other as you will auditory the dependencies DK off so you can imagine that the patterns this will produce will tend to have these very focused kind of clusters at the bottom levels, and then as you go up the dependencies start to breakdown.",
                    "label": 0
                },
                {
                    "sent": "So this supports the multiscale kind of groups, but allows for nodes to possibly deviate from the reading of their parents.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we can basically show that under this model.",
                    "label": 0
                },
                {
                    "sent": "So if you consider a pattern that's generated by this latent tree based Ising model, here we are assuming for simplicity that the depth is the tree is not too unbalanced and we have uniform degree.",
                    "label": 1
                },
                {
                    "sent": "And we forced the route to take the value 0.",
                    "label": 0
                },
                {
                    "sent": "This is only important because we want the patterns to be canonically sparse.",
                    "label": 0
                },
                {
                    "sent": "So if we allow the route to be zero or one, then you get sparse an on sparse patterns.",
                    "label": 0
                },
                {
                    "sent": "So just to force Canonical domain sparsity so we can compare to previous results, we forced the route to take value 0, so route takes value zero and at a level gamma One North start flipping from the appearance with a certain probability that depends on gamma one and so on.",
                    "label": 1
                },
                {
                    "sent": "For deeper levels and we can show is that under this model with high probability the Canonical sparsity.",
                    "label": 0
                },
                {
                    "sent": "Skills as Peter the 1 minus gamma One will gamma one is the strength at this upper level, highest level and whereas the transform domain sparsity scales as gamma LP to the one minus gamma, which is the deepest level strength of interaction.",
                    "label": 0
                },
                {
                    "sent": "So essentially what this is saying is that you tend to get patterns in Canonical domain, the normal domain.",
                    "label": 0
                },
                {
                    "sent": "The patterns are essentially determined by whether or not things flip at the highest level, so you get these groups of activations together and the transform domain sparsity especially depends on how many change points are there in your pattern, and that's determined by the lowest level.",
                    "label": 0
                },
                {
                    "sent": "But essentially, you can see that since we gamma L is larger than gamma one, we have a transform with sparsified these patterns and it would be useful for protection under this model.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So, just to summarize, once again, if we know the dependency structure which is hierarchical, then we can have a transform that.",
                    "label": 0
                },
                {
                    "sent": "If you project onto the transform, then your pattern gets sparsified answer your weak signals get amplified and then you can essentially use your favorite detector in the transform domain.",
                    "label": 1
                },
                {
                    "sent": "And if you do that then you essentially get an improvement in your signal strength that you can detect by a factor that depends on essentially the ratio of the sparsity in the two levels.",
                    "label": 0
                },
                {
                    "sent": "So you might ask, OK, what do we do?",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We don't know the dependency structure of the network, right?",
                    "label": 0
                },
                {
                    "sent": "Well, if you don't know this similarity matrix, or hierarchically structured graph.",
                    "label": 0
                },
                {
                    "sent": "Then basically we are going to try to learn it right and actually show that since our procedure was based on hierarchical clustering, hierarchical clustering actually suffices to learn this model so.",
                    "label": 0
                },
                {
                    "sent": "So for now I'll actually in the in the case where we don't know the dependency structure, let's focus on the similarity being the covariance matrix.",
                    "label": 0
                },
                {
                    "sent": "Actually, the same arguments would hold for any similarity, as long as it satisfies the concentration inequality, but covariance is easier to work with.",
                    "label": 0
                },
                {
                    "sent": "So basically we're assuming that now we have N snapshots of the network, so we have been on the network would end snapshots of it, then essentially our results show that with higher probability just from these snapshots at the leaves, you can learn the whole.",
                    "label": 0
                },
                {
                    "sent": "Art restructure the latent restructure using only about log P of the measurements.",
                    "label": 0
                },
                {
                    "sent": "So an only needs to scale like log P, and you can basically recover this tree structure under this condition that there's this gap between the Inter cluster and intra cluster similarities.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And specifically what it says for the Ising model is that if you look at the covariance between any two elements in this tree based Ising model that is essentially proportional to the strength of interaction along the path that connects the shortest path that connects XI and XJ.",
                    "label": 0
                },
                {
                    "sent": "So for the Ising model you do exactly have this hierarchical block structure similarity matrix, and so if you only use empirical covariance is you would still be able to recover this latent tree based Ising model using only measurements at the leaf nodes.",
                    "label": 1
                },
                {
                    "sent": "By looking at covariances between them.",
                    "label": 0
                },
                {
                    "sent": "So which is?",
                    "label": 0
                },
                {
                    "sent": "I thought it was interesting result.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Song.",
                    "label": 0
                },
                {
                    "sent": "OK, so just to mention some experiments, so this was this is a simulation on our multiscale Ising model with 1296 leaves and degree of each node is 6 and we have 4 levels in the tree, so you can see that the blue line which denotes detection performance or the probability of detection versus signal strength.",
                    "label": 0
                },
                {
                    "sent": "The blue line denotes the performance in the transform domain after you have done the projection onto this unbalanced heart basis and that outperforms several other detectors that we considered.",
                    "label": 0
                },
                {
                    "sent": "In the Canonical domain, so we looked at the Max statistic in the Canonical domain Max of the just observations.",
                    "label": 1
                },
                {
                    "sent": "Also, the global average statistic where you would some all the observations and test that against a threshold as well as false discovery rate statistic which which is proven to be slightly more efficient than the Mac statistic and standard domain Canonical domain.",
                    "label": 0
                },
                {
                    "sent": "And you can see that it outperforms all of those, and in fact it does it for signal strength which are much weaker than the noise bond of .38 in this case.",
                    "label": 0
                },
                {
                    "sent": "So all the signals friends are much weaker than that.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I just briefly wanted to conclude by also mentioning some relatively new results which are not there in the paper, but we applied this technique to detect anomalies in networks and the figure I've shown on the left is actually Internet topology but simulated Internet topology using hot orbis graphs to plot it and the hot apologies.",
                    "label": 0
                },
                {
                    "sent": "So if you look at the sample covariance matrix, which is generated based on this graph, so the graph is no longer this tree based Ising model, we're not sampling from that.",
                    "label": 1
                },
                {
                    "sent": "So even when this condition under which our theory holds does not happen, even in that case, you can see that the sample covariance matrix for these kind of graphs actually tends to have this hierarchical block structure an if you build wavelets over it, then they do have this very nice property of inconstant on different clusters positive on one cluster, negative on the other, and it happens at multiple scales.",
                    "label": 0
                },
                {
                    "sent": "So you can see that in the first basis vector you have this blue and red clusters of nodes and the second basis vector you actually refining one of the.",
                    "label": 0
                },
                {
                    "sent": "Clusters in the first basis vector.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And if you look at the performance and again in the transform basis, you get much better performance, which is the curves in red compared to the performance in the Canonical basis.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we have also looked at real Internet data an since there's no ground truth to verify whether you have detected anything or not.",
                    "label": 0
                },
                {
                    "sent": "In this case you only look at compression that you might be able to achieve using round trip time measurements.",
                    "label": 0
                },
                {
                    "sent": "So we look at Internet round trip time measurements sorted according to their magnitude, which is the blue lines.",
                    "label": 0
                },
                {
                    "sent": "And if you project those onto this basis vector that we learned, then you can actually see that it does pacify those very well and so if there is an anomaly you would be you should be able to detect it much sooner using the transform domain.",
                    "label": 0
                },
                {
                    "sent": "So I'll",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Just like to end with that.",
                    "label": 0
                },
                {
                    "sent": "And yeah, take any questions.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So you make a very strong assumption that you get a full ride capestany, which always the maximum in cluster similarity is less than the minimum between cluster similarity.",
                    "label": 0
                },
                {
                    "sent": "Now.",
                    "label": 0
                },
                {
                    "sent": "Is there any realistic situation under which such a thing may happen?",
                    "label": 0
                },
                {
                    "sent": "So we did observe that it happens for these Internet based graphs.",
                    "label": 0
                },
                {
                    "sent": "Of course it does not hold exactly, you know perfection, but you do have this hierarchical block structured or tree based form and.",
                    "label": 0
                },
                {
                    "sent": "Yeah, right, right?",
                    "label": 0
                },
                {
                    "sent": "It is true.",
                    "label": 0
                },
                {
                    "sent": "So yeah, if you have this Gaussian noise model, then this you actually need to have this gap to be able to say that OK.",
                    "label": 0
                },
                {
                    "sent": "If all of your measurements can be corrupted by Gaussian noise, of course you need a gap to be able to distinguish the clusters.",
                    "label": 0
                },
                {
                    "sent": "But we're also looking at cases where you might not have Gaussian measurement in all your observations, but only a few of the observations might be wrong.",
                    "label": 0
                },
                {
                    "sent": "So most of your measurements are right, but you have a probability of error and then you can show something similar holds in that case as well.",
                    "label": 0
                },
                {
                    "sent": "Are there any further questions anyway?",
                    "label": 0
                },
                {
                    "sent": "I think you know, I notice that you didn't actually use information about which nodes are connected to whichever notes like the ages in the in the network, right?",
                    "label": 0
                },
                {
                    "sent": "That is essentially incorporated when you're doing this clustering right?",
                    "label": 0
                },
                {
                    "sent": "Because edges are essentially similarities in some sense, so you are using that structure to build the basis.",
                    "label": 0
                },
                {
                    "sent": "Does that make sense?",
                    "label": 0
                }
            ]
        }
    }
}