{
    "id": "sv3rulgt3pvy3oodltn4sqnpvpjvsfja",
    "title": "Entity Deduplication on Scholarlydata",
    "info": {
        "author": [
            "Ziqi Zhang, School of Science and Technology, Nottingham Trent University"
        ],
        "published": "July 10, 2017",
        "recorded": "May 2017",
        "category": [
            "Top->Computer Science->Big Data",
            "Top->Computer Science->Semantic Web"
        ]
    },
    "url": "http://videolectures.net/eswc2017_zhang_entity_deduplication/",
    "segmentation": [
        [
            "Everybody, so my name is Vicki and.",
            "For the next half an hour or so, I'm going to talk about the work on empty duplication.",
            "Now, scholar data, and that's a collaborative work with.",
            "Andrea, who's sitting there and Annalisa, who's not able to come to the conference, unfortunately.",
            "So this."
        ],
        [
            "I'm going to do it.",
            "I'm going to 1st for give you a bit of context of the work we have done, so we look at the scholarly data.",
            "What it is, what kind of problem we have there, what kind of research problem we're trying to do is?",
            "Are there any really works that's already addressing similar problem?",
            "When the answer is yes.",
            "So how do we do it in a different way?",
            "And then we're going to talk about in detail our method, which we use supervised machine learning technique.",
            "I will talk about blocking, classification and UI harmonization in details.",
            "And then we move onto experiments where we evaluate our method and conclusion of future work."
        ],
        [
            "So what is correlate data while it is currently largest conference link datasets in the semantic web community.",
            "So he's orange and was actually the semantic Web dog food which contains.",
            "Facts about publications within our community.",
            "So Semantic web conference I SWC SWC.",
            "Whenever you publish a paper in these communities in conference or workshop, you're basically contributing to the augmentation of that data.",
            "So scholar today to take that and did something on top of that, we tried to improve the kind of this data set from the schema level.",
            "Which means that we try to improve the ontology addressing some of the issues there, and specifically we propose an unconference ontology following the ontology design patterns.",
            "And also there is a workflow in place which is called CODI.",
            "Think not sure how to pronounce it, but if you are really interested as an Android demand to ask all the questions.",
            "Also I want to make reference to the talk that is given yesterday in the Central Matrix Workshop, so there's a lot of information about scholar data."
        ],
        [
            "Now.",
            "The problems that we're trying to deal with in this work is slightly different, which is duplicate the instance level.",
            "So we looked at the previous work we have done with scholar data.",
            "Will look at problems whereas schema level but we didn't try to solve duplicate at instance level and that inherits from the historical data but also be cause.",
            "I'm sure we're all familiar with situation.",
            "When you introduce practice, you ask people to follow and people just ignore it.",
            "OK, so creating more and more and more problems.",
            "So we have a lot of your eyes that should be coreference that refer to the same entity, especially for personal organization.",
            "That need cleaning instead of set.",
            "And obviously, we don't want to do it manually.",
            "You want to do it automatically."
        ],
        [
            "So there's several areas that this work related to now.",
            "First of all, obviously the conference linked datasets.",
            "Our society started with meta data projects esw CIS WC.",
            "A cement ification of a conference data size has become very popular in the last few years.",
            "There's been promoted by a lot of publishers, such as Springer Lot of Index versus Google Scholar as well.",
            "Scholar data where we are.",
            "Well, we are the largest conference languages set in this area.",
            "So we're leading the development in this area.",
            "The other areas that the work is related to is your eye or entity deduplication.",
            "So because we're talking about looking at your eyes or refer to the same entity.",
            "You ask the coreference so there's a lot of work that we can relate to.",
            "For instance, link discovery or ontology alignment ontology mapping.",
            "I instance level so lots of works being down there with the novelty is that we look at different domain so demand attention.",
            "It may sound trivial, but actually it's not 'cause we're going to see in experiments that we take some state of our systems and you can see that without this kind of this kind of adaptation tailored approach, they're not going to work as well as the proof we propose here.",
            "Also.",
            "And we think that that is because we're using some features that specific design to deal with the unbalanced uses of your eyes.",
            "So you're going to have your one until refers to the same entity, but what's typical in this kind of data is you will have one UI that has been used a lot, whereas the other one not used very much.",
            "So that means that the classic methods, which relies on kind of quite.",
            "Quite balanced, the usage of the UI's will not work very."
        ],
        [
            "Well.",
            "In this kind of problem.",
            "And once we have identified you as a coreference, refer to the same entity.",
            "Now we're going to do is.",
            "To to consolidate them so we call UI harmonization.",
            "You may think that one too.",
            "We just use same as yes we can, but it's not the best solution because what we want to do also is to keep the provenance and to keep track of how these UIS has changed overtime and therefore the solution.",
            "Way common ways we use HTTP redirect.",
            "And also Sparkle Sparkle query rewriting for two neural in order to ensure backward compatibility."
        ],
        [
            "So onto the methodology and I'm going to give you an overview of some management methodology before I delve into the details, so we're going to start ways I input, which contains just a set of your eyes of the same type, so the URLs are easier, just organizational person.",
            "We choose these two to focus on his work, 'cause the the the causing the most problems in the data set.",
            "Basically, and most of the duplicates are found for these two types.",
            "So we got one set contents, just your eyes of the same type."
        ],
        [
            "Anne.",
            "The ultimately what you want to do is to identify the UIS the subgroups of your eyes that we refer to the same entity.",
            "OK, and it doesn't matter how you're going to do is whether you do is with the clustering approach or you're going to look at pairs at a time and classify them to say yes or no there coreference.",
            "One thing you have to do is to workout the pairwise similarity between your eyes and that if you think about it, given the size.",
            "Given a set of size and your eyes, and that's the problem of N, choose two, which is a lot of computation.",
            "So first up, we try to do is using the blocking technique that tries to use a lightweight process, but speech.",
            "This set of your eyes into subgroups which are likely to contain a lot of false positives, but hopefully contends also all of the two positives important send is these groups are much more smaller, and if we're going to look at the pairwise comparison within these subgroups, it's going to be a lot more manageable."
        ],
        [
            "And once we know that you know these are the sets of your eyes are likely to be contained the coreference, the true positive pairs, your eyes are the coreference next that we want to do.",
            "Is we actually look at these kind of the pairs and decide whether they are correct or not.",
            "So we use a classification approach in this work.",
            "Because we're looking at pairs of your eyes now we need to represent pairs using some kind of feature representation, and we also need to come up with some instrumentation for each individual UI before we can represent the pair."
        ],
        [
            "And finally, if we know that you know these, these are the set of pairs, your eyes that actually Coreference next tab is UI harmonization.",
            "So we're going to decide what we're going to do with the correct.",
            "Your eyes duplicate your eyes.",
            "And how do we integrate all this data to ensure backward compatibility?"
        ],
        [
            "So I'm going to talk about blocking.",
            "First of all, we're not trying to reinvent the wheel here, we just use some standard approach.",
            "In this top, so there's a lot of literature that's being done here.",
            "You probably heard of locality sensitive hashing, which is one of the approach.",
            "Now there are two types of approaches.",
            "One is the salted neighborhood methods.",
            "What you do is you typically just take your eyes, rank them by some order.",
            "For example, you can use the lexical graphic order the UI string for instance, or just the.",
            "The the name that are given by some particular predicates associated with that UI OK, and then once all these years being sorted, we just apply a fixed window threshold.",
            "To say OK, these five should be a group and next file should be another group and so on.",
            "Content based.",
            "Now, this time we're just looking at.",
            "We were getting some of the properties property values associated with each year.",
            "I so in this case looking at name like properties so our DFS label or conf name or fourth name right?",
            "If the values have some token sharing common between two rise, we put them into the same group.",
            "So that gives us blocks or groups that contains the pairs.",
            "That contains all of your eyes likely to cook Topeka reference with one another in the set."
        ],
        [
            "Announcer classification so this time we're going to take just the pairs of your eyes and these pairs are generated from the blocks that we just created before.",
            "And as I said, first of all, when you think about how do we represent each year?",
            "I so the way we do is we use a bag of radius representation.",
            "So bag of features back values how.",
            "However, you would like to see it.",
            "And for this we traverse the linked data graph.",
            "OK, so following some particular predefined paths that consist of one or multiple predicates, for example of the person type of your eyes, we use a features.",
            "Right, so for instance, you can see on the screen we have we have the name feature.",
            "We just follow the conference name property to get the name string value of that UI.",
            "You can see some examples on the rightmost column in a table, and we also look at other features you can see in the different roles of the table and just want to mention briefly the last one.",
            "We also look at just the title, abstract and keywords of the papers that that you are that person represented by the UI has written OK, so we use these.",
            "We collect all these keywords these words from the title, keywords, an abstract and just convert me to back off.",
            "Were the back of features.",
            "And that's how we represent person in your eyes."
        ],
        [
            "Organization similar story, but we just use.",
            "Different paths just travel, just follow different paths in the graph to get different values.",
            "So 4 features for organization your eye."
        ],
        [
            "OK, so we got to your eyes and your eye is represents a bag of features.",
            "Continue different types of features and next thing we want to do is want to represent the pairs which we need to say yes or no.",
            "You're correct or not.",
            "And to do this we calculate type wise features similarity.",
            "So let's say we got two pairs of.",
            "Let's see, we got a pair of two organizations.",
            "Your eyes, so organization, one and two.",
            "Anne.",
            "And what we're doing with the 1st or the 1st one is is the dice coefficient function.",
            "So what we do typically is, let's say for example we are looking at the Members of the organization, so we take the members of the first year.",
            "I first organization will take the members with second organization.",
            "We take the intersection, divide that by the Union and that gives you the value for the first equation.",
            "That second one just take the square root OK. Coverage.",
            "So again, using the same example, so I'm taking the intersection of the Members of the two UI, but this time I'm going to workout the fraction of that value.",
            "Against easier, just remember the size of the members of the first organization or the size of members of the second organization, and I'll take the maximum value.",
            "So that's the difference between coverage and ice.",
            "Now, so you can imagine this, this feature would possibly over predict because in my you know it might generate a lot of a lot of false positive pairs.",
            "But when is used together with the other features, an empirically works much better and I would say that that feature is exactly created.",
            "Deal with the unbalanced uses your eyes, because if you can, imagine if you're going to use the dice function when your eyes they use a lot in the data and the other one is not, you might get a very small figure for the dice, but use coverage.",
            "You can get a large value, so that's the purpose of using the coverage matrix.",
            "So.",
            "OK, for different types of your eyes or person organization we said we use different features.",
            "Represent them for person.",
            "We have eight types of features for your eye and then we're looking at pairs of person.",
            "Your eyes.",
            "We apply each one of these four matrix to each type of the features.",
            "That gave us 8 by 4 which is 32 features for a pair of person UI.",
            "OK and then 4 by 4 which is 16 features repair.",
            "Of organization, your eyes."
        ],
        [
            "And the classification try to determine whether or not that pair is coreference or whether they are duplicate entities.",
            "Now for this we use the classification models we use.",
            "As we said, we use a machine learning based techniques.",
            "We use classical models and we tried 5 and these are just taken from one of the most extensively used libraries.",
            "Ticket learn.",
            "And we didn't do much with the tuning.",
            "While the algorithm part of these models, which basically just take it and applied it to the data which contains parameters as well, which I'll come to in a minute.",
            "So fine models, we have stochastic gradient descent.",
            "So SGD logistic regression, our random forest, which is a flavor of decision trees.",
            "Linear as we are and a nonlinear as we are model so we."
        ],
        [
            "Find this file and want to use one that work best.",
            "And the last tabs in the method is that once you know these two curves couture your eyes actually Co referent.",
            "You want determine what you're going to do with them, OK?",
            "Because OK, first of all, there's closure identification.",
            "So we're trying to identify the chains of core reference, right?",
            "So it might be our number URA refers to your IP on your B is also same as you are see, so we need to first of all if this change and group them together.",
            "And then we decide what kind of candidate selection without which one we want to take.",
            "Once we decided the guys that we think we should keep next time we were going to decide what to do with your asset that we don't want to keep right.",
            "We don't want to just discard them because maybe in the future some new data is generated in this.",
            "Still refer to those those those old is your eyes.",
            "We can't force data publishers to just use one year and people do that.",
            "So for that reason.",
            "We use some heuristics, such as as we said HTTP referrer.",
            "Rinsing and sparkle query right and so on."
        ],
        [
            "OK, I'm going to talk about little about experiments, so now this is.",
            "This is a different problem that we look at from the literature.",
            "So therefore we created some datasets.",
            "By ourselves, so we looked at the two types of person organization and generates the pairs of the person or organization your eyes and we charge into whether they are correct or not so positive or negative.",
            "Supporting means yes, they are duplicated.",
            "Aircraft and negative means no, they're not."
        ],
        [
            "Blocking experiment.",
            "This is blocking what we're trying to do is try to split the data into subgroups that are likely to contain the true positives, so we want to make sure that you have you cover all the true positives right so we have the pair completeness metric.",
            "In the meantime, you also want to make sure that you get rid of as many false positive as possible.",
            "So that's the reduction ratio and the HM to harmonic mean is just the balance of the two.",
            "Now, as you can see, we have two types of methods we mentioned.",
            "So the SNM and content based right and the best performing for the person types.",
            "Obviously the content based metric OL means or we use the RDF RDF RDF'S label.",
            "Often UI and means user conference name and as.",
            "Is the common family name.",
            "OK, so we basically take these values and.",
            "Applied it with the content based matrix and that gives the best result."
        ],
        [
            "Same story for organization.",
            "Money."
        ],
        [
            "To talk more about that now for classification.",
            "So we use data set of created before and for training testing we split into 75% training 25% testing the unit training datasets.",
            "We also do parameter tuning with a 10 fold validation.",
            "On the training set, so fine models just reminder of what they are again.",
            "So SGD logistic regression error random forest linear swam and known as we we compare with two standards, that is limes and silk 4 lines.",
            "The two algorithms that worried about the time orientations we use both of them."
        ],
        [
            "OK, so on the top of this result.",
            "Page now we have come we have to be not just comparing the fire models that we have tested now as you can see that the random forest is the best performing one for both positive and negative examples.",
            "So we use that and we compare that with State Farm.",
            "So limes and.",
            "And silk, and that's in the second section of this slide, so lower part as you can see.",
            "Again, we have two types, the organization and person.",
            "Now the method we use.",
            "Random forest outperforms the other models by a really large margin.",
            "OK, I think I should point out that for the other, for the other 3 state route systems we're using the same features for your eyes.",
            "Keyboard for the.",
            "For the features of the pairs of your eyes, we rely on implementation of the system themselves, so I think they use for example, strength, string, symmetrix and maybe maybe dice function.",
            "Something like that.",
            "OK, so."
        ],
        [
            "You are home addition, so now we know what's the best performing blocking strategy was the best performing model.",
            "We just use them, apply, apply them to the entire data set, and this generates the pairs of core reference person pairs, coreference organizations, and we also perform some many variations who asked me to look at the data and tells how accurate that system has done done the job."
        ],
        [
            "And this will look precision.",
            "And as you can see, these are the numbers for a nation and person."
        ],
        [
            "Right and so are OK.",
            "I'm going to skip the conclusions of the first bullet point.",
            "I think I'm running out of time.",
            "Just want to mention we do for future work.",
            "So for future work we're looking at sparse features.",
            "Underused your eyes.",
            "What I mean is for some of your eyes you will notice that for example they don't have papers or they don't have all the organizations.",
            "They don't.",
            "They don't have participated events, right?",
            "There is a difference of that.",
            "You can't.",
            "You can't find these values as opposed to.",
            "You are getting a similarity feature signature of 0 right?",
            "So we want to distinguish that.",
            "How do we make sure that those of us does not have these features are not penalized because that implicit collects connections or features.",
            "So sometimes we see yes.",
            "WC 2015 Yes Yes 2020, 2012 for example.",
            "But obviously there is some connection between these two values.",
            "So how do we make use of that?",
            "And we also want to look in to extend this work into link discovery in general.",
            "So not just in this particular domain and that's all."
        ],
        [
            "Q.",
            "There was a worker.",
            "A few years ago, when actually I think it's around 2012, one of the authors were transfer charfauros know if you know it anyway, they were doing data cleansing based on campus udoke identification.",
            "That action in web datasets.",
            "So I was just wondering if you know the work, whether you think that that approach?",
            "I mean you didn't compare, you didn't apply.",
            "I don't know even if they have any.",
            "Reusable tool at Trader know.",
            "But just to know if you know if you think that that approach can be in some way integrated here or what you expect it to be.",
            "In case the difference, I think you need to give me a little bit more information about what exactly did so the pseudo key and key won't work well.",
            "So in that case of course I don't know the really the details, but the what I remember is that what I got is that they what they use is the semantic parser innocence.",
            "You do as well like.",
            "Looking at the relationship to use the features now, but they try to identify.",
            "Sets of relations that represent keys for keys in the sense of databases, keys.",
            "This is so unique identifier so, but they're enoree keys that innocence identify uniquely that type of entity, or the OR a specific entity.",
            "So I was wondering if in any in any way this may be applied or OK.",
            "I think I didn't look into that work, so I might be wrong, but I think.",
            "I will see that the work we've done is probably more generalizable because we're talking about keys.",
            "Essentially, I could think of that as just some of the features we used over here so you can see that we use the names of the person names of the organization, and I imagine that might be one of the keys that they could use as well, but obviously we use other features just done, you know, features other than just those, so I would think that the model would be more scalable and generalizable to the problems, but thanks for pointing that out and I will look into that one as well.",
            "OK. Wow, I gave you a lot of time for thinking OK, so I'll go there there there and there.",
            "OK for quick questions because you are for and I would like really to have all.",
            "So following up on your question about database unique keys, do you see because you mentioned persons and organizations right?",
            "Persons have actually unique identifier or kit which is not used by everyone yet but still and then for organizations there is grid, Eastney and Ringgold.",
            "Couple of other identifiers.",
            "Do you see how those identifiers can help you do this kind of mention?",
            "Yes, absolutely.",
            "I think in the datasets for some of the person you are as we already have the orkid.",
            "But that's not the I might be wrong.",
            "Sure, you can.",
            "Correct me.",
            "I think it's not the majority of the data set.",
            "That's why we use these, but actually we're trying to do is to think whether we can use those data that already tell us the correct for reference, but maybe very small proportion of the data.",
            "Use that as kind of seed training data to use that in a kind of bootstrapping or semi supervised machine learning algorithm in future.",
            "So that's the future work we're actually doing at the moment.",
            "Thank you.",
            "Thanks for your next presentation.",
            "I was just wondering in case of missing values how do you increase of missing values for the feature features?",
            "How does it work?",
            "What do you do well if and your eye does not have any features at all, then unfortunately you just can't do anything with it.",
            "But it also means that if you have well, if ever you are that does not have any values, is not connected to the graph at all, right?",
            "In that case, I don't think you can do anything about it, but I think that the problem is I think the problem we're looking at is probably the UI's which have sparse features.",
            "So instead of those eight features I just mentioned, maybe they don't have one or two, so one of the things I said was can we look at a way to distinguish that?",
            "So instead of saying while this UI does not, this person has not been to any conferences, therefore has zero similarity with the others.",
            "Can we say?",
            "We can't really say that this, to your eyes have similar 0 because they have not been to the same conference.",
            "But it's only because one of them has not got this data.",
            "So there is a way to do tweak this tweak feature in the machine algorithm to make that kind of distinction so we don't over penalize that kind of situation.",
            "And the other thing, nothing we could do is try to look at implicit.",
            "Links between your eyes.",
            "So if for example, the two people have been to the same organization or similar groups of organizations, can we make a connection just based on that one feature as opposed to all the other five?",
            "Incenses systems you are interested in, not merching items that are different, so you want to have very high precision, close to 100%.",
            "How does your system perform?",
            "If you really go to high precision in terms, for example of recall?",
            "I don't think I'll make a comment saying that we want just high precision.",
            "I think probably is the last slide.",
            "That would be misleading, so this part requires that we look at the precision.",
            "Well, that's only 'cause we apply the trained model to the entire data set this time, so that is.",
            "The modern thousand public, even 10s of thousands of your eyes were talking about, so it's not possible for us to to extensively check what's the recall.",
            "Therefore, for this part of the experiment, we only look at precision, but it doesn't mean that we just addressing precision, so we're looking for a model that is balanced between precision and recall.",
            "OK, before the last question, if the speaker, the second speaker is there can ask him or her to go to the podium and prepare please.",
            "So this is not OK.",
            "Thanks for your rice presentation.",
            "It's just like a note.",
            "Can you just you want screen sorry.",
            "Also I thought the second speaker is going to.",
            "Yeah right, you have another 30 seconds 30 minutes to go.",
            "Do you need to see the slides?",
            "Yeah, just look at evaluation slide.",
            "I'm just have a simple question do which to which algorithm from lines that you compare.",
            "Things to do?",
            "Wombats simple and wombat complete then your reference their own paper just a matter of speaking.",
            "OK, so the reference is around you see yeah is that offends you?",
            "Reference an old paper robots accepted in this year yes I've notice that one yes, OK OK OK thanks for that.",
            "OK, any other question while we wait for the next speaker to show up.",
            "No other questions.",
            "OK, thank you very much.",
            "Thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Everybody, so my name is Vicki and.",
                    "label": 0
                },
                {
                    "sent": "For the next half an hour or so, I'm going to talk about the work on empty duplication.",
                    "label": 0
                },
                {
                    "sent": "Now, scholar data, and that's a collaborative work with.",
                    "label": 0
                },
                {
                    "sent": "Andrea, who's sitting there and Annalisa, who's not able to come to the conference, unfortunately.",
                    "label": 0
                },
                {
                    "sent": "So this.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I'm going to do it.",
                    "label": 0
                },
                {
                    "sent": "I'm going to 1st for give you a bit of context of the work we have done, so we look at the scholarly data.",
                    "label": 0
                },
                {
                    "sent": "What it is, what kind of problem we have there, what kind of research problem we're trying to do is?",
                    "label": 0
                },
                {
                    "sent": "Are there any really works that's already addressing similar problem?",
                    "label": 0
                },
                {
                    "sent": "When the answer is yes.",
                    "label": 0
                },
                {
                    "sent": "So how do we do it in a different way?",
                    "label": 0
                },
                {
                    "sent": "And then we're going to talk about in detail our method, which we use supervised machine learning technique.",
                    "label": 1
                },
                {
                    "sent": "I will talk about blocking, classification and UI harmonization in details.",
                    "label": 0
                },
                {
                    "sent": "And then we move onto experiments where we evaluate our method and conclusion of future work.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So what is correlate data while it is currently largest conference link datasets in the semantic web community.",
                    "label": 1
                },
                {
                    "sent": "So he's orange and was actually the semantic Web dog food which contains.",
                    "label": 0
                },
                {
                    "sent": "Facts about publications within our community.",
                    "label": 0
                },
                {
                    "sent": "So Semantic web conference I SWC SWC.",
                    "label": 0
                },
                {
                    "sent": "Whenever you publish a paper in these communities in conference or workshop, you're basically contributing to the augmentation of that data.",
                    "label": 0
                },
                {
                    "sent": "So scholar today to take that and did something on top of that, we tried to improve the kind of this data set from the schema level.",
                    "label": 0
                },
                {
                    "sent": "Which means that we try to improve the ontology addressing some of the issues there, and specifically we propose an unconference ontology following the ontology design patterns.",
                    "label": 0
                },
                {
                    "sent": "And also there is a workflow in place which is called CODI.",
                    "label": 0
                },
                {
                    "sent": "Think not sure how to pronounce it, but if you are really interested as an Android demand to ask all the questions.",
                    "label": 0
                },
                {
                    "sent": "Also I want to make reference to the talk that is given yesterday in the Central Matrix Workshop, so there's a lot of information about scholar data.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now.",
                    "label": 0
                },
                {
                    "sent": "The problems that we're trying to deal with in this work is slightly different, which is duplicate the instance level.",
                    "label": 0
                },
                {
                    "sent": "So we looked at the previous work we have done with scholar data.",
                    "label": 0
                },
                {
                    "sent": "Will look at problems whereas schema level but we didn't try to solve duplicate at instance level and that inherits from the historical data but also be cause.",
                    "label": 1
                },
                {
                    "sent": "I'm sure we're all familiar with situation.",
                    "label": 0
                },
                {
                    "sent": "When you introduce practice, you ask people to follow and people just ignore it.",
                    "label": 0
                },
                {
                    "sent": "OK, so creating more and more and more problems.",
                    "label": 0
                },
                {
                    "sent": "So we have a lot of your eyes that should be coreference that refer to the same entity, especially for personal organization.",
                    "label": 0
                },
                {
                    "sent": "That need cleaning instead of set.",
                    "label": 0
                },
                {
                    "sent": "And obviously, we don't want to do it manually.",
                    "label": 0
                },
                {
                    "sent": "You want to do it automatically.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So there's several areas that this work related to now.",
                    "label": 0
                },
                {
                    "sent": "First of all, obviously the conference linked datasets.",
                    "label": 1
                },
                {
                    "sent": "Our society started with meta data projects esw CIS WC.",
                    "label": 0
                },
                {
                    "sent": "A cement ification of a conference data size has become very popular in the last few years.",
                    "label": 0
                },
                {
                    "sent": "There's been promoted by a lot of publishers, such as Springer Lot of Index versus Google Scholar as well.",
                    "label": 1
                },
                {
                    "sent": "Scholar data where we are.",
                    "label": 0
                },
                {
                    "sent": "Well, we are the largest conference languages set in this area.",
                    "label": 0
                },
                {
                    "sent": "So we're leading the development in this area.",
                    "label": 1
                },
                {
                    "sent": "The other areas that the work is related to is your eye or entity deduplication.",
                    "label": 0
                },
                {
                    "sent": "So because we're talking about looking at your eyes or refer to the same entity.",
                    "label": 1
                },
                {
                    "sent": "You ask the coreference so there's a lot of work that we can relate to.",
                    "label": 0
                },
                {
                    "sent": "For instance, link discovery or ontology alignment ontology mapping.",
                    "label": 0
                },
                {
                    "sent": "I instance level so lots of works being down there with the novelty is that we look at different domain so demand attention.",
                    "label": 0
                },
                {
                    "sent": "It may sound trivial, but actually it's not 'cause we're going to see in experiments that we take some state of our systems and you can see that without this kind of this kind of adaptation tailored approach, they're not going to work as well as the proof we propose here.",
                    "label": 1
                },
                {
                    "sent": "Also.",
                    "label": 0
                },
                {
                    "sent": "And we think that that is because we're using some features that specific design to deal with the unbalanced uses of your eyes.",
                    "label": 0
                },
                {
                    "sent": "So you're going to have your one until refers to the same entity, but what's typical in this kind of data is you will have one UI that has been used a lot, whereas the other one not used very much.",
                    "label": 0
                },
                {
                    "sent": "So that means that the classic methods, which relies on kind of quite.",
                    "label": 0
                },
                {
                    "sent": "Quite balanced, the usage of the UI's will not work very.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Well.",
                    "label": 0
                },
                {
                    "sent": "In this kind of problem.",
                    "label": 0
                },
                {
                    "sent": "And once we have identified you as a coreference, refer to the same entity.",
                    "label": 0
                },
                {
                    "sent": "Now we're going to do is.",
                    "label": 0
                },
                {
                    "sent": "To to consolidate them so we call UI harmonization.",
                    "label": 0
                },
                {
                    "sent": "You may think that one too.",
                    "label": 0
                },
                {
                    "sent": "We just use same as yes we can, but it's not the best solution because what we want to do also is to keep the provenance and to keep track of how these UIS has changed overtime and therefore the solution.",
                    "label": 0
                },
                {
                    "sent": "Way common ways we use HTTP redirect.",
                    "label": 1
                },
                {
                    "sent": "And also Sparkle Sparkle query rewriting for two neural in order to ensure backward compatibility.",
                    "label": 1
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So onto the methodology and I'm going to give you an overview of some management methodology before I delve into the details, so we're going to start ways I input, which contains just a set of your eyes of the same type, so the URLs are easier, just organizational person.",
                    "label": 0
                },
                {
                    "sent": "We choose these two to focus on his work, 'cause the the the causing the most problems in the data set.",
                    "label": 0
                },
                {
                    "sent": "Basically, and most of the duplicates are found for these two types.",
                    "label": 0
                },
                {
                    "sent": "So we got one set contents, just your eyes of the same type.",
                    "label": 1
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "The ultimately what you want to do is to identify the UIS the subgroups of your eyes that we refer to the same entity.",
                    "label": 0
                },
                {
                    "sent": "OK, and it doesn't matter how you're going to do is whether you do is with the clustering approach or you're going to look at pairs at a time and classify them to say yes or no there coreference.",
                    "label": 0
                },
                {
                    "sent": "One thing you have to do is to workout the pairwise similarity between your eyes and that if you think about it, given the size.",
                    "label": 0
                },
                {
                    "sent": "Given a set of size and your eyes, and that's the problem of N, choose two, which is a lot of computation.",
                    "label": 0
                },
                {
                    "sent": "So first up, we try to do is using the blocking technique that tries to use a lightweight process, but speech.",
                    "label": 0
                },
                {
                    "sent": "This set of your eyes into subgroups which are likely to contain a lot of false positives, but hopefully contends also all of the two positives important send is these groups are much more smaller, and if we're going to look at the pairwise comparison within these subgroups, it's going to be a lot more manageable.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And once we know that you know these are the sets of your eyes are likely to be contained the coreference, the true positive pairs, your eyes are the coreference next that we want to do.",
                    "label": 0
                },
                {
                    "sent": "Is we actually look at these kind of the pairs and decide whether they are correct or not.",
                    "label": 1
                },
                {
                    "sent": "So we use a classification approach in this work.",
                    "label": 0
                },
                {
                    "sent": "Because we're looking at pairs of your eyes now we need to represent pairs using some kind of feature representation, and we also need to come up with some instrumentation for each individual UI before we can represent the pair.",
                    "label": 1
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And finally, if we know that you know these, these are the set of pairs, your eyes that actually Coreference next tab is UI harmonization.",
                    "label": 0
                },
                {
                    "sent": "So we're going to decide what we're going to do with the correct.",
                    "label": 0
                },
                {
                    "sent": "Your eyes duplicate your eyes.",
                    "label": 0
                },
                {
                    "sent": "And how do we integrate all this data to ensure backward compatibility?",
                    "label": 1
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So I'm going to talk about blocking.",
                    "label": 0
                },
                {
                    "sent": "First of all, we're not trying to reinvent the wheel here, we just use some standard approach.",
                    "label": 0
                },
                {
                    "sent": "In this top, so there's a lot of literature that's being done here.",
                    "label": 0
                },
                {
                    "sent": "You probably heard of locality sensitive hashing, which is one of the approach.",
                    "label": 0
                },
                {
                    "sent": "Now there are two types of approaches.",
                    "label": 0
                },
                {
                    "sent": "One is the salted neighborhood methods.",
                    "label": 0
                },
                {
                    "sent": "What you do is you typically just take your eyes, rank them by some order.",
                    "label": 0
                },
                {
                    "sent": "For example, you can use the lexical graphic order the UI string for instance, or just the.",
                    "label": 0
                },
                {
                    "sent": "The the name that are given by some particular predicates associated with that UI OK, and then once all these years being sorted, we just apply a fixed window threshold.",
                    "label": 0
                },
                {
                    "sent": "To say OK, these five should be a group and next file should be another group and so on.",
                    "label": 0
                },
                {
                    "sent": "Content based.",
                    "label": 0
                },
                {
                    "sent": "Now, this time we're just looking at.",
                    "label": 0
                },
                {
                    "sent": "We were getting some of the properties property values associated with each year.",
                    "label": 0
                },
                {
                    "sent": "I so in this case looking at name like properties so our DFS label or conf name or fourth name right?",
                    "label": 0
                },
                {
                    "sent": "If the values have some token sharing common between two rise, we put them into the same group.",
                    "label": 0
                },
                {
                    "sent": "So that gives us blocks or groups that contains the pairs.",
                    "label": 0
                },
                {
                    "sent": "That contains all of your eyes likely to cook Topeka reference with one another in the set.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Announcer classification so this time we're going to take just the pairs of your eyes and these pairs are generated from the blocks that we just created before.",
                    "label": 0
                },
                {
                    "sent": "And as I said, first of all, when you think about how do we represent each year?",
                    "label": 0
                },
                {
                    "sent": "I so the way we do is we use a bag of radius representation.",
                    "label": 0
                },
                {
                    "sent": "So bag of features back values how.",
                    "label": 0
                },
                {
                    "sent": "However, you would like to see it.",
                    "label": 0
                },
                {
                    "sent": "And for this we traverse the linked data graph.",
                    "label": 0
                },
                {
                    "sent": "OK, so following some particular predefined paths that consist of one or multiple predicates, for example of the person type of your eyes, we use a features.",
                    "label": 0
                },
                {
                    "sent": "Right, so for instance, you can see on the screen we have we have the name feature.",
                    "label": 0
                },
                {
                    "sent": "We just follow the conference name property to get the name string value of that UI.",
                    "label": 0
                },
                {
                    "sent": "You can see some examples on the rightmost column in a table, and we also look at other features you can see in the different roles of the table and just want to mention briefly the last one.",
                    "label": 0
                },
                {
                    "sent": "We also look at just the title, abstract and keywords of the papers that that you are that person represented by the UI has written OK, so we use these.",
                    "label": 0
                },
                {
                    "sent": "We collect all these keywords these words from the title, keywords, an abstract and just convert me to back off.",
                    "label": 0
                },
                {
                    "sent": "Were the back of features.",
                    "label": 0
                },
                {
                    "sent": "And that's how we represent person in your eyes.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Organization similar story, but we just use.",
                    "label": 0
                },
                {
                    "sent": "Different paths just travel, just follow different paths in the graph to get different values.",
                    "label": 0
                },
                {
                    "sent": "So 4 features for organization your eye.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so we got to your eyes and your eye is represents a bag of features.",
                    "label": 0
                },
                {
                    "sent": "Continue different types of features and next thing we want to do is want to represent the pairs which we need to say yes or no.",
                    "label": 0
                },
                {
                    "sent": "You're correct or not.",
                    "label": 0
                },
                {
                    "sent": "And to do this we calculate type wise features similarity.",
                    "label": 1
                },
                {
                    "sent": "So let's say we got two pairs of.",
                    "label": 0
                },
                {
                    "sent": "Let's see, we got a pair of two organizations.",
                    "label": 0
                },
                {
                    "sent": "Your eyes, so organization, one and two.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "And what we're doing with the 1st or the 1st one is is the dice coefficient function.",
                    "label": 0
                },
                {
                    "sent": "So what we do typically is, let's say for example we are looking at the Members of the organization, so we take the members of the first year.",
                    "label": 0
                },
                {
                    "sent": "I first organization will take the members with second organization.",
                    "label": 0
                },
                {
                    "sent": "We take the intersection, divide that by the Union and that gives you the value for the first equation.",
                    "label": 0
                },
                {
                    "sent": "That second one just take the square root OK. Coverage.",
                    "label": 0
                },
                {
                    "sent": "So again, using the same example, so I'm taking the intersection of the Members of the two UI, but this time I'm going to workout the fraction of that value.",
                    "label": 0
                },
                {
                    "sent": "Against easier, just remember the size of the members of the first organization or the size of members of the second organization, and I'll take the maximum value.",
                    "label": 0
                },
                {
                    "sent": "So that's the difference between coverage and ice.",
                    "label": 0
                },
                {
                    "sent": "Now, so you can imagine this, this feature would possibly over predict because in my you know it might generate a lot of a lot of false positive pairs.",
                    "label": 0
                },
                {
                    "sent": "But when is used together with the other features, an empirically works much better and I would say that that feature is exactly created.",
                    "label": 0
                },
                {
                    "sent": "Deal with the unbalanced uses your eyes, because if you can, imagine if you're going to use the dice function when your eyes they use a lot in the data and the other one is not, you might get a very small figure for the dice, but use coverage.",
                    "label": 0
                },
                {
                    "sent": "You can get a large value, so that's the purpose of using the coverage matrix.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "OK, for different types of your eyes or person organization we said we use different features.",
                    "label": 0
                },
                {
                    "sent": "Represent them for person.",
                    "label": 0
                },
                {
                    "sent": "We have eight types of features for your eye and then we're looking at pairs of person.",
                    "label": 0
                },
                {
                    "sent": "Your eyes.",
                    "label": 1
                },
                {
                    "sent": "We apply each one of these four matrix to each type of the features.",
                    "label": 0
                },
                {
                    "sent": "That gave us 8 by 4 which is 32 features for a pair of person UI.",
                    "label": 0
                },
                {
                    "sent": "OK and then 4 by 4 which is 16 features repair.",
                    "label": 0
                },
                {
                    "sent": "Of organization, your eyes.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And the classification try to determine whether or not that pair is coreference or whether they are duplicate entities.",
                    "label": 0
                },
                {
                    "sent": "Now for this we use the classification models we use.",
                    "label": 0
                },
                {
                    "sent": "As we said, we use a machine learning based techniques.",
                    "label": 0
                },
                {
                    "sent": "We use classical models and we tried 5 and these are just taken from one of the most extensively used libraries.",
                    "label": 0
                },
                {
                    "sent": "Ticket learn.",
                    "label": 0
                },
                {
                    "sent": "And we didn't do much with the tuning.",
                    "label": 0
                },
                {
                    "sent": "While the algorithm part of these models, which basically just take it and applied it to the data which contains parameters as well, which I'll come to in a minute.",
                    "label": 0
                },
                {
                    "sent": "So fine models, we have stochastic gradient descent.",
                    "label": 1
                },
                {
                    "sent": "So SGD logistic regression, our random forest, which is a flavor of decision trees.",
                    "label": 1
                },
                {
                    "sent": "Linear as we are and a nonlinear as we are model so we.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Find this file and want to use one that work best.",
                    "label": 0
                },
                {
                    "sent": "And the last tabs in the method is that once you know these two curves couture your eyes actually Co referent.",
                    "label": 0
                },
                {
                    "sent": "You want determine what you're going to do with them, OK?",
                    "label": 0
                },
                {
                    "sent": "Because OK, first of all, there's closure identification.",
                    "label": 0
                },
                {
                    "sent": "So we're trying to identify the chains of core reference, right?",
                    "label": 0
                },
                {
                    "sent": "So it might be our number URA refers to your IP on your B is also same as you are see, so we need to first of all if this change and group them together.",
                    "label": 0
                },
                {
                    "sent": "And then we decide what kind of candidate selection without which one we want to take.",
                    "label": 0
                },
                {
                    "sent": "Once we decided the guys that we think we should keep next time we were going to decide what to do with your asset that we don't want to keep right.",
                    "label": 0
                },
                {
                    "sent": "We don't want to just discard them because maybe in the future some new data is generated in this.",
                    "label": 0
                },
                {
                    "sent": "Still refer to those those those old is your eyes.",
                    "label": 0
                },
                {
                    "sent": "We can't force data publishers to just use one year and people do that.",
                    "label": 0
                },
                {
                    "sent": "So for that reason.",
                    "label": 0
                },
                {
                    "sent": "We use some heuristics, such as as we said HTTP referrer.",
                    "label": 0
                },
                {
                    "sent": "Rinsing and sparkle query right and so on.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, I'm going to talk about little about experiments, so now this is.",
                    "label": 0
                },
                {
                    "sent": "This is a different problem that we look at from the literature.",
                    "label": 0
                },
                {
                    "sent": "So therefore we created some datasets.",
                    "label": 0
                },
                {
                    "sent": "By ourselves, so we looked at the two types of person organization and generates the pairs of the person or organization your eyes and we charge into whether they are correct or not so positive or negative.",
                    "label": 1
                },
                {
                    "sent": "Supporting means yes, they are duplicated.",
                    "label": 0
                },
                {
                    "sent": "Aircraft and negative means no, they're not.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Blocking experiment.",
                    "label": 0
                },
                {
                    "sent": "This is blocking what we're trying to do is try to split the data into subgroups that are likely to contain the true positives, so we want to make sure that you have you cover all the true positives right so we have the pair completeness metric.",
                    "label": 0
                },
                {
                    "sent": "In the meantime, you also want to make sure that you get rid of as many false positive as possible.",
                    "label": 0
                },
                {
                    "sent": "So that's the reduction ratio and the HM to harmonic mean is just the balance of the two.",
                    "label": 1
                },
                {
                    "sent": "Now, as you can see, we have two types of methods we mentioned.",
                    "label": 0
                },
                {
                    "sent": "So the SNM and content based right and the best performing for the person types.",
                    "label": 0
                },
                {
                    "sent": "Obviously the content based metric OL means or we use the RDF RDF RDF'S label.",
                    "label": 0
                },
                {
                    "sent": "Often UI and means user conference name and as.",
                    "label": 0
                },
                {
                    "sent": "Is the common family name.",
                    "label": 0
                },
                {
                    "sent": "OK, so we basically take these values and.",
                    "label": 0
                },
                {
                    "sent": "Applied it with the content based matrix and that gives the best result.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Same story for organization.",
                    "label": 0
                },
                {
                    "sent": "Money.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "To talk more about that now for classification.",
                    "label": 0
                },
                {
                    "sent": "So we use data set of created before and for training testing we split into 75% training 25% testing the unit training datasets.",
                    "label": 0
                },
                {
                    "sent": "We also do parameter tuning with a 10 fold validation.",
                    "label": 0
                },
                {
                    "sent": "On the training set, so fine models just reminder of what they are again.",
                    "label": 1
                },
                {
                    "sent": "So SGD logistic regression error random forest linear swam and known as we we compare with two standards, that is limes and silk 4 lines.",
                    "label": 0
                },
                {
                    "sent": "The two algorithms that worried about the time orientations we use both of them.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so on the top of this result.",
                    "label": 0
                },
                {
                    "sent": "Page now we have come we have to be not just comparing the fire models that we have tested now as you can see that the random forest is the best performing one for both positive and negative examples.",
                    "label": 0
                },
                {
                    "sent": "So we use that and we compare that with State Farm.",
                    "label": 0
                },
                {
                    "sent": "So limes and.",
                    "label": 0
                },
                {
                    "sent": "And silk, and that's in the second section of this slide, so lower part as you can see.",
                    "label": 0
                },
                {
                    "sent": "Again, we have two types, the organization and person.",
                    "label": 0
                },
                {
                    "sent": "Now the method we use.",
                    "label": 0
                },
                {
                    "sent": "Random forest outperforms the other models by a really large margin.",
                    "label": 0
                },
                {
                    "sent": "OK, I think I should point out that for the other, for the other 3 state route systems we're using the same features for your eyes.",
                    "label": 0
                },
                {
                    "sent": "Keyboard for the.",
                    "label": 0
                },
                {
                    "sent": "For the features of the pairs of your eyes, we rely on implementation of the system themselves, so I think they use for example, strength, string, symmetrix and maybe maybe dice function.",
                    "label": 0
                },
                {
                    "sent": "Something like that.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You are home addition, so now we know what's the best performing blocking strategy was the best performing model.",
                    "label": 0
                },
                {
                    "sent": "We just use them, apply, apply them to the entire data set, and this generates the pairs of core reference person pairs, coreference organizations, and we also perform some many variations who asked me to look at the data and tells how accurate that system has done done the job.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And this will look precision.",
                    "label": 0
                },
                {
                    "sent": "And as you can see, these are the numbers for a nation and person.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Right and so are OK.",
                    "label": 0
                },
                {
                    "sent": "I'm going to skip the conclusions of the first bullet point.",
                    "label": 0
                },
                {
                    "sent": "I think I'm running out of time.",
                    "label": 0
                },
                {
                    "sent": "Just want to mention we do for future work.",
                    "label": 1
                },
                {
                    "sent": "So for future work we're looking at sparse features.",
                    "label": 1
                },
                {
                    "sent": "Underused your eyes.",
                    "label": 0
                },
                {
                    "sent": "What I mean is for some of your eyes you will notice that for example they don't have papers or they don't have all the organizations.",
                    "label": 0
                },
                {
                    "sent": "They don't.",
                    "label": 0
                },
                {
                    "sent": "They don't have participated events, right?",
                    "label": 0
                },
                {
                    "sent": "There is a difference of that.",
                    "label": 0
                },
                {
                    "sent": "You can't.",
                    "label": 0
                },
                {
                    "sent": "You can't find these values as opposed to.",
                    "label": 0
                },
                {
                    "sent": "You are getting a similarity feature signature of 0 right?",
                    "label": 0
                },
                {
                    "sent": "So we want to distinguish that.",
                    "label": 0
                },
                {
                    "sent": "How do we make sure that those of us does not have these features are not penalized because that implicit collects connections or features.",
                    "label": 0
                },
                {
                    "sent": "So sometimes we see yes.",
                    "label": 0
                },
                {
                    "sent": "WC 2015 Yes Yes 2020, 2012 for example.",
                    "label": 0
                },
                {
                    "sent": "But obviously there is some connection between these two values.",
                    "label": 1
                },
                {
                    "sent": "So how do we make use of that?",
                    "label": 0
                },
                {
                    "sent": "And we also want to look in to extend this work into link discovery in general.",
                    "label": 0
                },
                {
                    "sent": "So not just in this particular domain and that's all.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Q.",
                    "label": 0
                },
                {
                    "sent": "There was a worker.",
                    "label": 0
                },
                {
                    "sent": "A few years ago, when actually I think it's around 2012, one of the authors were transfer charfauros know if you know it anyway, they were doing data cleansing based on campus udoke identification.",
                    "label": 0
                },
                {
                    "sent": "That action in web datasets.",
                    "label": 0
                },
                {
                    "sent": "So I was just wondering if you know the work, whether you think that that approach?",
                    "label": 0
                },
                {
                    "sent": "I mean you didn't compare, you didn't apply.",
                    "label": 0
                },
                {
                    "sent": "I don't know even if they have any.",
                    "label": 0
                },
                {
                    "sent": "Reusable tool at Trader know.",
                    "label": 0
                },
                {
                    "sent": "But just to know if you know if you think that that approach can be in some way integrated here or what you expect it to be.",
                    "label": 0
                },
                {
                    "sent": "In case the difference, I think you need to give me a little bit more information about what exactly did so the pseudo key and key won't work well.",
                    "label": 0
                },
                {
                    "sent": "So in that case of course I don't know the really the details, but the what I remember is that what I got is that they what they use is the semantic parser innocence.",
                    "label": 0
                },
                {
                    "sent": "You do as well like.",
                    "label": 0
                },
                {
                    "sent": "Looking at the relationship to use the features now, but they try to identify.",
                    "label": 0
                },
                {
                    "sent": "Sets of relations that represent keys for keys in the sense of databases, keys.",
                    "label": 0
                },
                {
                    "sent": "This is so unique identifier so, but they're enoree keys that innocence identify uniquely that type of entity, or the OR a specific entity.",
                    "label": 0
                },
                {
                    "sent": "So I was wondering if in any in any way this may be applied or OK.",
                    "label": 0
                },
                {
                    "sent": "I think I didn't look into that work, so I might be wrong, but I think.",
                    "label": 0
                },
                {
                    "sent": "I will see that the work we've done is probably more generalizable because we're talking about keys.",
                    "label": 0
                },
                {
                    "sent": "Essentially, I could think of that as just some of the features we used over here so you can see that we use the names of the person names of the organization, and I imagine that might be one of the keys that they could use as well, but obviously we use other features just done, you know, features other than just those, so I would think that the model would be more scalable and generalizable to the problems, but thanks for pointing that out and I will look into that one as well.",
                    "label": 0
                },
                {
                    "sent": "OK. Wow, I gave you a lot of time for thinking OK, so I'll go there there there and there.",
                    "label": 0
                },
                {
                    "sent": "OK for quick questions because you are for and I would like really to have all.",
                    "label": 0
                },
                {
                    "sent": "So following up on your question about database unique keys, do you see because you mentioned persons and organizations right?",
                    "label": 0
                },
                {
                    "sent": "Persons have actually unique identifier or kit which is not used by everyone yet but still and then for organizations there is grid, Eastney and Ringgold.",
                    "label": 0
                },
                {
                    "sent": "Couple of other identifiers.",
                    "label": 0
                },
                {
                    "sent": "Do you see how those identifiers can help you do this kind of mention?",
                    "label": 0
                },
                {
                    "sent": "Yes, absolutely.",
                    "label": 0
                },
                {
                    "sent": "I think in the datasets for some of the person you are as we already have the orkid.",
                    "label": 0
                },
                {
                    "sent": "But that's not the I might be wrong.",
                    "label": 0
                },
                {
                    "sent": "Sure, you can.",
                    "label": 0
                },
                {
                    "sent": "Correct me.",
                    "label": 0
                },
                {
                    "sent": "I think it's not the majority of the data set.",
                    "label": 0
                },
                {
                    "sent": "That's why we use these, but actually we're trying to do is to think whether we can use those data that already tell us the correct for reference, but maybe very small proportion of the data.",
                    "label": 0
                },
                {
                    "sent": "Use that as kind of seed training data to use that in a kind of bootstrapping or semi supervised machine learning algorithm in future.",
                    "label": 0
                },
                {
                    "sent": "So that's the future work we're actually doing at the moment.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                },
                {
                    "sent": "Thanks for your next presentation.",
                    "label": 0
                },
                {
                    "sent": "I was just wondering in case of missing values how do you increase of missing values for the feature features?",
                    "label": 0
                },
                {
                    "sent": "How does it work?",
                    "label": 0
                },
                {
                    "sent": "What do you do well if and your eye does not have any features at all, then unfortunately you just can't do anything with it.",
                    "label": 0
                },
                {
                    "sent": "But it also means that if you have well, if ever you are that does not have any values, is not connected to the graph at all, right?",
                    "label": 0
                },
                {
                    "sent": "In that case, I don't think you can do anything about it, but I think that the problem is I think the problem we're looking at is probably the UI's which have sparse features.",
                    "label": 0
                },
                {
                    "sent": "So instead of those eight features I just mentioned, maybe they don't have one or two, so one of the things I said was can we look at a way to distinguish that?",
                    "label": 0
                },
                {
                    "sent": "So instead of saying while this UI does not, this person has not been to any conferences, therefore has zero similarity with the others.",
                    "label": 0
                },
                {
                    "sent": "Can we say?",
                    "label": 0
                },
                {
                    "sent": "We can't really say that this, to your eyes have similar 0 because they have not been to the same conference.",
                    "label": 0
                },
                {
                    "sent": "But it's only because one of them has not got this data.",
                    "label": 0
                },
                {
                    "sent": "So there is a way to do tweak this tweak feature in the machine algorithm to make that kind of distinction so we don't over penalize that kind of situation.",
                    "label": 0
                },
                {
                    "sent": "And the other thing, nothing we could do is try to look at implicit.",
                    "label": 0
                },
                {
                    "sent": "Links between your eyes.",
                    "label": 0
                },
                {
                    "sent": "So if for example, the two people have been to the same organization or similar groups of organizations, can we make a connection just based on that one feature as opposed to all the other five?",
                    "label": 0
                },
                {
                    "sent": "Incenses systems you are interested in, not merching items that are different, so you want to have very high precision, close to 100%.",
                    "label": 0
                },
                {
                    "sent": "How does your system perform?",
                    "label": 0
                },
                {
                    "sent": "If you really go to high precision in terms, for example of recall?",
                    "label": 0
                },
                {
                    "sent": "I don't think I'll make a comment saying that we want just high precision.",
                    "label": 0
                },
                {
                    "sent": "I think probably is the last slide.",
                    "label": 0
                },
                {
                    "sent": "That would be misleading, so this part requires that we look at the precision.",
                    "label": 0
                },
                {
                    "sent": "Well, that's only 'cause we apply the trained model to the entire data set this time, so that is.",
                    "label": 0
                },
                {
                    "sent": "The modern thousand public, even 10s of thousands of your eyes were talking about, so it's not possible for us to to extensively check what's the recall.",
                    "label": 0
                },
                {
                    "sent": "Therefore, for this part of the experiment, we only look at precision, but it doesn't mean that we just addressing precision, so we're looking for a model that is balanced between precision and recall.",
                    "label": 0
                },
                {
                    "sent": "OK, before the last question, if the speaker, the second speaker is there can ask him or her to go to the podium and prepare please.",
                    "label": 0
                },
                {
                    "sent": "So this is not OK.",
                    "label": 0
                },
                {
                    "sent": "Thanks for your rice presentation.",
                    "label": 0
                },
                {
                    "sent": "It's just like a note.",
                    "label": 0
                },
                {
                    "sent": "Can you just you want screen sorry.",
                    "label": 0
                },
                {
                    "sent": "Also I thought the second speaker is going to.",
                    "label": 0
                },
                {
                    "sent": "Yeah right, you have another 30 seconds 30 minutes to go.",
                    "label": 0
                },
                {
                    "sent": "Do you need to see the slides?",
                    "label": 0
                },
                {
                    "sent": "Yeah, just look at evaluation slide.",
                    "label": 0
                },
                {
                    "sent": "I'm just have a simple question do which to which algorithm from lines that you compare.",
                    "label": 0
                },
                {
                    "sent": "Things to do?",
                    "label": 0
                },
                {
                    "sent": "Wombats simple and wombat complete then your reference their own paper just a matter of speaking.",
                    "label": 0
                },
                {
                    "sent": "OK, so the reference is around you see yeah is that offends you?",
                    "label": 0
                },
                {
                    "sent": "Reference an old paper robots accepted in this year yes I've notice that one yes, OK OK OK thanks for that.",
                    "label": 0
                },
                {
                    "sent": "OK, any other question while we wait for the next speaker to show up.",
                    "label": 0
                },
                {
                    "sent": "No other questions.",
                    "label": 0
                },
                {
                    "sent": "OK, thank you very much.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                }
            ]
        }
    }
}