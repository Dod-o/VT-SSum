{
    "id": "zv3hk65ogoxp3nepl5eibsg5r65n5cz6",
    "title": "Detecting SPARQL Query Templates for Data Prefetching",
    "info": {
        "introducer": [
            "Laura Hollink, Centrum Wiskunde & Informatica (CWI)"
        ],
        "author": [
            "Johannes Lorey, Hasso-Plattner-Institute, University of Potsdam"
        ],
        "published": "July 8, 2013",
        "recorded": "May 2013",
        "category": [
            "Top->Computer Science->Semantic Web",
            "Top->Computer Science->Big Data"
        ]
    },
    "url": "http://videolectures.net/eswc2013_lorey_data/",
    "segmentation": [
        [
            "Welcome back everybody.",
            "We're going to start this session actually with two presentations from Potsdam.",
            "The first one is by Johannes Lorry on.",
            "Detecting sparkle query templates for data prefetching.",
            "So welcome back from my side too.",
            "As long as that already I'm from Potsdam from the Aspen Institute and this is joint work with Felix Naumann.",
            "And before I start, since people are still coming in, I'd like to introduce my work with a little motivational example.",
            "So imagine you're organizing a successful conference, and for the past few years you've been to a remote island in the Mediterranean.",
            "But now you're looking for a new location basically, and you already kind of have your mindset on France or you want to go to France, but you're looking for the perfect spot.",
            "To host your conference to conference, and so Luckily there's somebody out there who already has created some sort of mashup that helps you in your decision making."
        ],
        [
            "And this is the conference organizers guide to France and also lucky for you.",
            "This is very easy to use, so you can just click on a specific."
        ],
        [
            "Location that might be interesting for your hosting, your conference, and also since this is Semantic Web conference, you're trying to plan the data that is being that is being retrieved for kind of helping you in your decision making process."
        ],
        [
            "Is retrieved from the DPD endpoint and this is the kind of request that might be generated by the mashup that I just showed that I was kind of the mock up example here, so you're asking for the abstract information population.",
            "And of course most importantly the sun hours in May because you don't want to go to a place where there is no sun.",
            "And this is the request that is being generated, and this is all for the resource that has the label little and you're sending this to the DB pedia endpoint."
        ],
        [
            "So.",
            "And of course it takes some time to process and you also have some latency and some delay, and then you get some results."
        ],
        [
            "And then you can of course visualize these results.",
            "And maybe, for example, for the northern France French city of Lille, you know there are not too many sun hours in May, so this might not be the perfect location for you."
        ],
        [
            "Next up, so maybe you try Paris.",
            "You click on Paris again."
        ],
        [
            "Request is being generated sent to the DB Pedia endpoint and you retrieve some results."
        ],
        [
            "Here you know Santeros still isn't too great, so maybe also not perfect location for your conference.",
            "So finally, maybe."
        ],
        [
            "Wanted by multiple year, which you kind of heard is a nice city to go to."
        ],
        [
            "Again, the same request is being generated.",
            "The band DVD endpoint is kind of freaking out because they're sending so many requests, but it's returning some results."
        ],
        [
            "And here you can see.",
            "Of course Monte is always sunny in May, apparently.",
            "And except for special cases, and so this is."
        ],
        [
            "Maybe where you where you want to host your conference.",
            "So."
        ],
        [
            "So the reason for this example of what I want to show in this example is that the response time for batches of sparkle queries is impaired by the aggregated network latency, and what I hopefully also showed and, but you kind of got from the example is that there are certain recurring patterns in sparkle queries that you might you may can exploit in order to decrease this.",
            "This aggregated latency, delay and the idea for all work thus is too.",
            "Prefetch the data that is relevant for those kind of requests by identifying so called query templates and what is the query template.",
            "So I'm going to introduce this kind of informally now and I'm going to come back to this later, so these are the requests I presented on the last slide and as you probably figured, the only thing changing throughout the query session here is the name of the city you're actually querying for, so the label here.",
            "And of course you can subsume these three queries using.",
            "This one query.",
            "So."
        ],
        [
            "So the workflow of our approach here is to identify the sub graph patterns that are eligible for matching, then determine actual matches based on similarity of these sub graph patterns and finally to merge the patterns to actually form query templates."
        ],
        [
            "And so this is the agenda for my talk today.",
            "I already talked about motivation, introduction, and Next up I'm going to present the."
        ],
        [
            "This pattern decomposition approach we are using."
        ],
        [
            "And here I'm relying on the well known graph pattern normal forms for sparkle queries.",
            "So in this example or in this slide, here P is a sparkle graph pattern and it's been shown that or it's trivial, actually that if P is a basic graph pattern, of course it can be expressed as a number of conjoined triple patterns it has."
        ],
        [
            "Joan, that P can always be expressed as a in this union normal form.",
            "Basically, where the individual sub patterns are union free graph patterns and."
        ],
        [
            "You also have this notion of well designed graph patterns that have the form presented here.",
            "We have a bunch of optional expressions that can be added together and they all have or the P1 to PN all have the same form.",
            "NP star is a basic graph pattern."
        ],
        [
            "So what we came up with the graph pattern decomposition, which is being presented as 3D composition functions, theater Union Vida and anti optional for the respective normal forms.",
            "And as you can imagine these take as input graph pattern and decompose it into the set of sub graph patterns.",
            "If the graph pattern is in the respective normal form.",
            "So for theater union the result is either the set of graph patterns if.",
            "Is the union normal form or it's an empty set?",
            "If it, if it isn't and then we have this for Theta and where the trivial cases that P is a triple pattern.",
            "And of course if you have a number of conjoined triple patterns or graph patterns conjoined by the keyword, and then the result is the set of these of these craft patterns, or the empty set if it's not in and normal form and optional, again, you have the set of.",
            "Graph patterns that are conjoined by other junk by."
        ],
        [
            "Optional we also introduced the conveniency composition function data P, which basically just checks all these three decomposition functions individually and tries to match the corresponding one to the to the graph pattern and to the normal form.",
            "The graph NP is in, and of course you can then apply theater P on the elements of the output of the of, applying it earlier.",
            "So if you have to pee, then you get a set of.",
            "Resulting graph patterns and on each of these graph patterns you can again apply ATW until you find triple patterns, which then have only way can only apply to and.",
            "What we also introduces the keyboard function Kappa P and this is meant as a as a device to determine the keyword of any graph pattern that has been discovered through this decomposition process.",
            "So Kappa P basically illustrates what the decomposition or what decomposition function has been applied to it.",
            "Current graph pattern and I'm not going to go into details here, but I'm going to show an example so."
        ],
        [
            "If you have this query pattern for a sparkle query, you can already kind of see that this is in Union normal form, so you have a union.",
            "Joining two separate graph patterns.",
            "So if we apply Theta Theta on PQ, this means we're essentially applying theater union on PQ and the result."
        ],
        [
            "Is are these two sub graph patterns or child graph patterns so one is a BGP and one is a graph pattern with an optional.",
            "And if you apply the Kappa keyboard function here on either one of these graph patterns."
        ],
        [
            "The result is a union again, so this is meant as a just an auxiliary tool to present the.",
            "Identify what the paragraph pattern was."
        ],
        [
            "So next I'm going to talk about the actual matching process, and I'm introducing this.",
            "Bottom up basically, so I'm going to present the triple pattern matching first."
        ],
        [
            "And here we use the aggregated Levenshtein distances of the subject predicate and object pairs.",
            "And we normalize the assistance if about the subject of both the predicates are both, the objects are either your eyes or literals.",
            "We normalize the distance and apply factor K less than one.",
            "If both are variables and we set it to one.",
            "Basically, if the two subjects or the two predicates or the two objects are of different types of one is the UI and one is a literal.",
            "In this example or in our work, we use K = 1/3 So you can see there is a small divergent in the subject which are two variables.",
            "The two predicates are equal, so there is a distance of zero, and there's a basic level.",
            "Should I normalized Levenshtein distance for the two object pairs here over the two objects?",
            "Another example here you can see in the object part there are two.",
            "Different types, so there's there's one your eye and one variable, so here the object distance is set to one and the maximum distance here for the maximum aggregated distance here of course is 3, and this is meant to represent the two triple patterns are in fact not equal at all, so maximum distance kind of is as a way of determining that these are very disjunct triple patterns."
        ],
        [
            "So now for graph pattern matching matching what we actually do is or what we what the problem we're trying to solve is is to determine the complete bipartite cover with minimum cost between 2 between the triple patterns of two basic graph patterns.",
            "And here we set the cost threshold for any match of two triple patterns to one.",
            "So at most the coast the cost I introduced in the last slide can be one."
        ],
        [
            "For group patterns, we're going back to the decomposition I introduced earlier, and we recursively decompose the group graph patterns into basic graph patterns and then match these and based on this we can match the parent graph patterns and we can only match these if the cardinality of the sets of the decomposition is equal.",
            "And of course if the keywords is equal, so we don't want to match an optional statement from an optional block with a statement from another block that is not an optional statement."
        ],
        [
            "What we're doing is we're using a greedy algorithm here, and this is a version of the Gale Shapely algorithm, which is typically used for the stable marriage problem, and this runs in quadratic time for the matching of the triple patterns and the result of this algorithm is then the minimum cost cover of the match triple patterns.",
            "If such a cost minimum cost cover exists."
        ],
        [
            "Next up, if we do determine a nonempty cover, we can merge individual pairs of matched triple patterns by replacing the non identical parts with unique variables.",
            "So this is what I introduced earlier informally.",
            "So now here you can see that the difference here in these two trouble lenses.",
            "In fact the object and the aggregated aggregated distance here is less than one, so we can merge these by introducing a new variable which is unique to.",
            "Query.",
            "Um?",
            "And in case in case we have at least one merge, so in case the two queries we analyzed are not identical and there is not a trivial kind of matching taking place, then the new query template we can generate is basically one of the previous queries.",
            "But we replace the non identical part or the non non matching or the non identical triple patterns that we have matched with the new merge triple pattern, that is that contains a new variable at all match queries in our approach for Mcqueary cluster.",
            "And these may overlap, so they might be queries that belong to multiple query clusters, so there can be they can be represented by different query templates."
        ],
        [
            "OK, next I'm going to evaluation and this is a two fold evaluation and I'm talking about.",
            "First, I'm talking about the actual data and actual recurrences in real world sparkle query logs.",
            "And then I'm going to present our pre fetching approach and introduce how this works and what the benefits are for this."
        ],
        [
            "So we analyzed the DB pedia.",
            "3.6 We relax provided for the use MoD Workshop last years Useful Workshop and these contain about 8.5 million anonymized sparkle queries for Ford Dot 3.6.",
            "And this is what the OR?",
            "This is an excerpt of the request, so you can see here that there is anonymized IP address, which is a really long hash and then we have a timestamp which is not by chance in hourly granularity.",
            "Because this is the granularity of the timestamps, there's only a full hour given.",
            "And so for our approach, we wanted to determine query sessions and what we did was we analyzed all queries from the same user.",
            "So from the same IP address with the same timestamp and these form query session our approach."
        ],
        [
            "So first I want to show the.",
            "The homogeneity of query session.",
            "So on the X axis here you see the frequency of sequences of queries from distinct clusters.",
            "So these kind of these phone kind of fingerprint where the queries come from which query clusters and on the Y axis you see the query session length.",
            "Or I should rather say query session size on average for the queries belonging to the different sessions or to the same session maybe?",
            "At two different sessions and what we term we use here is homogeneous query sessions for in case all queries will actually belong to the same cluster, so they all have one query template in common and teacher genius query sessions.",
            "There might be queries from different clusters.",
            "What's surprising here is that the homogeneous query sessions are actually more frequently than heat Regina's query sessions.",
            "So that means that of course based on our session.",
            "Delimitation approach there are more queries actually from the same user that are that have similar structures then then have not and what's also surprising or even more surprising, maybe is that on average the homogeneous group sessions are even longer, so you can imagine that there are many many similarly structured queries coming from the same user during the course of a session, many more so than for the heterogeneous query sessions where people are or requests differ in between the.",
            "Different queries."
        ],
        [
            "Next up, you want to show the conditional probability actually of two queries within a session being from the same pair from the same from the same cluster.",
            "And here on so both the X&Y axis here represent query clusters and we sorted these in descending size of the number of elements they contain, so you can basically so the lower left hand point basically visualizes how probable it is or how likely it is.",
            "For the most, for a query from the most frequent query cluster over the largest query cluster being followed from a query from the same query cluster.",
            "And as you can see here, or this is what I said, the diagonal here always means that there are two successive queries from the same cluster.",
            "And the 1st result is that the this matrix or this heat map is sparsely populated, so you don't have many options.",
            "Basically if you consider any given query then the successive query for this query throughout query sessions is most likely from only a number and limited number of other query clusters.",
            "And Secondly, of course there's a high chance that the two successive queries are actually from the same cluster and this is of course indicated here by.",
            "Diagonal and this kind of goes back to our point that there are recurring patterns in sparkle queries, and we want to exploit these.",
            "And this is kind of the.",
            "The hints we're taking from the real query logs."
        ],
        [
            "Next up, the data prefetching evaluation of our approach."
        ],
        [
            "And here this is very straightforward, so you can see here at this example.",
            "So this is a very very basic query asking for the English abstract of a specific resource and the longest sequence of curious we found in the query logs that contain only queries from this cluster.",
            "Of course distinct, so the resource changes the subject changes throughout this session or throughout the sequence.",
            "Contains about 56,000 queries, so this is a very long query session if you so will.",
            "Anne.",
            "And what we measured was the average response time from the DP endpoint.",
            "So we send these requests from our local machine to the depths of the public bday endpoint, and we measured an average response time for these queries from this cluster.",
            "Of course of five point, 2 milliseconds, and these are only, of course, retrieving at least at most one result.",
            "Some don't retrieve any result.",
            "And what we did is we basically replaced, then the concrete resource by a variable as discussed in the matching approach and the template generation approach.",
            "And we measured average response time from the DVD endpoint of 611 milliseconds.",
            "And this is for 1000 results or retrieving 1000 results at once.",
            "So you could argue that the speedup for treating the same amount of results achieves nearly factor 10.",
            "So if you if you issue 1000 queries from this cluster.",
            "Separately, then you will aggregate latency on factor 10 or with a factor of 10.",
            "Compared to the template prefetching approach.",
            "And."
        ],
        [
            "So of course the benefit of actually prefetching this data depends on the number of queries within a certain time frame, so it doesn't make sense to prefetch data if all you see is one or two or three requests, because you're actually prefetching large amount of results and what we did here was we analyzed the template coverage rate for different time frames and the template coverage rate is defined as the number of distinct results for individual queries in a certain time frame.",
            "Divided by the number of results the template actually prefetches, so these are all the results, and so we analyzed."
        ],
        [
            "This for individual query sessions and as you can see here already, there are some queries and so these are the top five largest query sessions that we extracted from the log files.",
            "As you can see, there are some sessions that already where the template already covers more than half of the results that were retrieved by individual request during the query session.",
            "An as I said on the previous slide, is that the speedup factor 10?",
            "So if you actually retrieve.",
            "All the all the results using the prefetching approach, then this, then for the first 4 query sessions you already have a benefit here by the template approach and then we also analyzed all queries within a specific day for for a user and here we can see that there are some queries where we have coverage rate of 100%, so all the resources that are in our all the results that are in the knowledge base I actually retrieved during the course of the day.",
            "From a specific user.",
            "So here of course the template template prefetching makes much sense because we're actually gathering all these results in advance and we don't waste a lot of time on individual retrieval of results."
        ],
        [
            "To sum up, So what we found was that there are many large scale query sessions containing recurring patterns in real world sparkle query logs and what we did was merging these similar patterns to establish query templates.",
            "We showed that the experimentally we showed that the response time per result is much higher than for the for the individual queries compared to the query templates and this is mostly due to latency, so this effect may vary depending on where their requests are actually being issued.",
            "And we can imagine many more application scenarios for this template approach.",
            "So you could imagine materialised views on the server side.",
            "So storing this data might be relevant for future requests.",
            "In my memory you could also see this as a kind of replication device for fault tolerance.",
            "So if an endpoint goes down then the data that is necessary for your particular mashup or application is already prefetched and I presented some more prefetching ideas in the useful Workshop on Sunday, and I'm going to sum this up on the workshop summary session on Thursday.",
            "And I would like to thank you.",
            "You said most of your speed up is due to latency, right?",
            "An I was an then you mentioned materialized views so.",
            "Do you think?",
            "You would get that kind of speedup.",
            "How?",
            "How much is there in just materializing the view and how much is there in the latency?",
            "And can you just say a little bit about that?",
            "Well, it's hard to say.",
            "I mean, even if I say that latency is one of the more that we benefit most by reducing latency.",
            "Overall, this is kind of biased as well because we're nowhere close to the DB endpoint maybe, and so latency isn't too much of an issue here.",
            "And maybe it depends much more on the query execution time on the DVD endpoint on the GPD endpoint side we haven't analyzed actually any sort of materialized view management or selection and creation and updating procedures because this.",
            "Comes with a whole bunch of other small problems, so I can't really give you an exact answer here.",
            "This was kind of the.",
            "Yeah, just.",
            "I don't there because I mean DPS also very specific in the distribution of its.",
            "The contents and the number of subjects and the requests.",
            "And so it so much depends on the concrete data you're looking at in the concrete queries, maybe so I'm sorry, but I I'm not.",
            "I'm not going into guessing here.",
            "Can you tell us a bit how much data you copied?",
            "During these prefetching and so this is a good question, I was kind of expecting.",
            "So, for example, for the for the abstract information, I think there about 303.5 million resources with an English abstract in DB pedia.",
            "So of course now prefetching approach and for example, I introduced all of these need to be retrieved so.",
            "This is kind of a simple answer, but of course I'm aware that this is a large amount of.",
            "Information you need to retrieve in advance and you need to know very so you need to be aware that you actually need this data subsequently.",
            "So, and this is kind of what I wanted to show in the first part of the evaluation that there are cases where it makes sense to have this to prefetch this large amounts of data in advance, you generalize the constants to variable, saying the object position of your triple, and so you could end up retrieving a lot of data.",
            "More than I need to have any sense of how often it happens that the prefetching then gets you know every city in the world except instead of solve the 100 cities that you want.",
            "So again, I mean this depends very much on the data that you're using, and so there might be query templates which look kind of like they're retrieving a whole bunch of results, but they don't because the endpoint you're issuing them against doesn't contain many results.",
            "So this in this case you're off the hook, basically.",
            "Anne.",
            "And but of course, you're right that you need to look very carefully at what the query session sessions look like, and that you need to know in advance what the data about the benefit of prefetching this data is.",
            "And here we are, kind of.",
            "We're kind of in a pickle because we use these query logs provided for the useful Workshop and they are very nice, clear logs and this is very nice data, But there are not too many features.",
            "I would say that we can use to determine if the queries are or if these are good representatives for such prefetching techniques.",
            "So here what we actually need to do and we're actually working on right now, is determining good features to know in advance for which queries it makes sense to prefetch this data.",
            "So this is kind of ongoing work right now.",
            "One way to solve this this problem might be to add a typing triple to your query that is determining the most specific common type of the of the instances in the pattern and then trying to constrain a little more viable right?",
            "So this is actually kind of what I presented in the Useful Workshop on Sunday, and But of course I mean this comes.",
            "This is a natural idea to have them.",
            "Thank you very much, your Highness."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Welcome back everybody.",
                    "label": 0
                },
                {
                    "sent": "We're going to start this session actually with two presentations from Potsdam.",
                    "label": 0
                },
                {
                    "sent": "The first one is by Johannes Lorry on.",
                    "label": 0
                },
                {
                    "sent": "Detecting sparkle query templates for data prefetching.",
                    "label": 1
                },
                {
                    "sent": "So welcome back from my side too.",
                    "label": 0
                },
                {
                    "sent": "As long as that already I'm from Potsdam from the Aspen Institute and this is joint work with Felix Naumann.",
                    "label": 0
                },
                {
                    "sent": "And before I start, since people are still coming in, I'd like to introduce my work with a little motivational example.",
                    "label": 0
                },
                {
                    "sent": "So imagine you're organizing a successful conference, and for the past few years you've been to a remote island in the Mediterranean.",
                    "label": 0
                },
                {
                    "sent": "But now you're looking for a new location basically, and you already kind of have your mindset on France or you want to go to France, but you're looking for the perfect spot.",
                    "label": 0
                },
                {
                    "sent": "To host your conference to conference, and so Luckily there's somebody out there who already has created some sort of mashup that helps you in your decision making.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And this is the conference organizers guide to France and also lucky for you.",
                    "label": 0
                },
                {
                    "sent": "This is very easy to use, so you can just click on a specific.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Location that might be interesting for your hosting, your conference, and also since this is Semantic Web conference, you're trying to plan the data that is being that is being retrieved for kind of helping you in your decision making process.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is retrieved from the DPD endpoint and this is the kind of request that might be generated by the mashup that I just showed that I was kind of the mock up example here, so you're asking for the abstract information population.",
                    "label": 0
                },
                {
                    "sent": "And of course most importantly the sun hours in May because you don't want to go to a place where there is no sun.",
                    "label": 0
                },
                {
                    "sent": "And this is the request that is being generated, and this is all for the resource that has the label little and you're sending this to the DB pedia endpoint.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "And of course it takes some time to process and you also have some latency and some delay, and then you get some results.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then you can of course visualize these results.",
                    "label": 0
                },
                {
                    "sent": "And maybe, for example, for the northern France French city of Lille, you know there are not too many sun hours in May, so this might not be the perfect location for you.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Next up, so maybe you try Paris.",
                    "label": 0
                },
                {
                    "sent": "You click on Paris again.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Request is being generated sent to the DB Pedia endpoint and you retrieve some results.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here you know Santeros still isn't too great, so maybe also not perfect location for your conference.",
                    "label": 0
                },
                {
                    "sent": "So finally, maybe.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Wanted by multiple year, which you kind of heard is a nice city to go to.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Again, the same request is being generated.",
                    "label": 0
                },
                {
                    "sent": "The band DVD endpoint is kind of freaking out because they're sending so many requests, but it's returning some results.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And here you can see.",
                    "label": 0
                },
                {
                    "sent": "Of course Monte is always sunny in May, apparently.",
                    "label": 0
                },
                {
                    "sent": "And except for special cases, and so this is.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Maybe where you where you want to host your conference.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the reason for this example of what I want to show in this example is that the response time for batches of sparkle queries is impaired by the aggregated network latency, and what I hopefully also showed and, but you kind of got from the example is that there are certain recurring patterns in sparkle queries that you might you may can exploit in order to decrease this.",
                    "label": 1
                },
                {
                    "sent": "This aggregated latency, delay and the idea for all work thus is too.",
                    "label": 1
                },
                {
                    "sent": "Prefetch the data that is relevant for those kind of requests by identifying so called query templates and what is the query template.",
                    "label": 0
                },
                {
                    "sent": "So I'm going to introduce this kind of informally now and I'm going to come back to this later, so these are the requests I presented on the last slide and as you probably figured, the only thing changing throughout the query session here is the name of the city you're actually querying for, so the label here.",
                    "label": 0
                },
                {
                    "sent": "And of course you can subsume these three queries using.",
                    "label": 0
                },
                {
                    "sent": "This one query.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the workflow of our approach here is to identify the sub graph patterns that are eligible for matching, then determine actual matches based on similarity of these sub graph patterns and finally to merge the patterns to actually form query templates.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And so this is the agenda for my talk today.",
                    "label": 0
                },
                {
                    "sent": "I already talked about motivation, introduction, and Next up I'm going to present the.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This pattern decomposition approach we are using.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And here I'm relying on the well known graph pattern normal forms for sparkle queries.",
                    "label": 0
                },
                {
                    "sent": "So in this example or in this slide, here P is a sparkle graph pattern and it's been shown that or it's trivial, actually that if P is a basic graph pattern, of course it can be expressed as a number of conjoined triple patterns it has.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Joan, that P can always be expressed as a in this union normal form.",
                    "label": 0
                },
                {
                    "sent": "Basically, where the individual sub patterns are union free graph patterns and.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "You also have this notion of well designed graph patterns that have the form presented here.",
                    "label": 1
                },
                {
                    "sent": "We have a bunch of optional expressions that can be added together and they all have or the P1 to PN all have the same form.",
                    "label": 1
                },
                {
                    "sent": "NP star is a basic graph pattern.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So what we came up with the graph pattern decomposition, which is being presented as 3D composition functions, theater Union Vida and anti optional for the respective normal forms.",
                    "label": 1
                },
                {
                    "sent": "And as you can imagine these take as input graph pattern and decompose it into the set of sub graph patterns.",
                    "label": 0
                },
                {
                    "sent": "If the graph pattern is in the respective normal form.",
                    "label": 0
                },
                {
                    "sent": "So for theater union the result is either the set of graph patterns if.",
                    "label": 0
                },
                {
                    "sent": "Is the union normal form or it's an empty set?",
                    "label": 0
                },
                {
                    "sent": "If it, if it isn't and then we have this for Theta and where the trivial cases that P is a triple pattern.",
                    "label": 0
                },
                {
                    "sent": "And of course if you have a number of conjoined triple patterns or graph patterns conjoined by the keyword, and then the result is the set of these of these craft patterns, or the empty set if it's not in and normal form and optional, again, you have the set of.",
                    "label": 0
                },
                {
                    "sent": "Graph patterns that are conjoined by other junk by.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Optional we also introduced the conveniency composition function data P, which basically just checks all these three decomposition functions individually and tries to match the corresponding one to the to the graph pattern and to the normal form.",
                    "label": 0
                },
                {
                    "sent": "The graph NP is in, and of course you can then apply theater P on the elements of the output of the of, applying it earlier.",
                    "label": 0
                },
                {
                    "sent": "So if you have to pee, then you get a set of.",
                    "label": 0
                },
                {
                    "sent": "Resulting graph patterns and on each of these graph patterns you can again apply ATW until you find triple patterns, which then have only way can only apply to and.",
                    "label": 0
                },
                {
                    "sent": "What we also introduces the keyboard function Kappa P and this is meant as a as a device to determine the keyword of any graph pattern that has been discovered through this decomposition process.",
                    "label": 1
                },
                {
                    "sent": "So Kappa P basically illustrates what the decomposition or what decomposition function has been applied to it.",
                    "label": 0
                },
                {
                    "sent": "Current graph pattern and I'm not going to go into details here, but I'm going to show an example so.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "If you have this query pattern for a sparkle query, you can already kind of see that this is in Union normal form, so you have a union.",
                    "label": 0
                },
                {
                    "sent": "Joining two separate graph patterns.",
                    "label": 0
                },
                {
                    "sent": "So if we apply Theta Theta on PQ, this means we're essentially applying theater union on PQ and the result.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is are these two sub graph patterns or child graph patterns so one is a BGP and one is a graph pattern with an optional.",
                    "label": 0
                },
                {
                    "sent": "And if you apply the Kappa keyboard function here on either one of these graph patterns.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The result is a union again, so this is meant as a just an auxiliary tool to present the.",
                    "label": 0
                },
                {
                    "sent": "Identify what the paragraph pattern was.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So next I'm going to talk about the actual matching process, and I'm introducing this.",
                    "label": 0
                },
                {
                    "sent": "Bottom up basically, so I'm going to present the triple pattern matching first.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And here we use the aggregated Levenshtein distances of the subject predicate and object pairs.",
                    "label": 1
                },
                {
                    "sent": "And we normalize the assistance if about the subject of both the predicates are both, the objects are either your eyes or literals.",
                    "label": 1
                },
                {
                    "sent": "We normalize the distance and apply factor K less than one.",
                    "label": 1
                },
                {
                    "sent": "If both are variables and we set it to one.",
                    "label": 0
                },
                {
                    "sent": "Basically, if the two subjects or the two predicates or the two objects are of different types of one is the UI and one is a literal.",
                    "label": 0
                },
                {
                    "sent": "In this example or in our work, we use K = 1/3 So you can see there is a small divergent in the subject which are two variables.",
                    "label": 0
                },
                {
                    "sent": "The two predicates are equal, so there is a distance of zero, and there's a basic level.",
                    "label": 0
                },
                {
                    "sent": "Should I normalized Levenshtein distance for the two object pairs here over the two objects?",
                    "label": 0
                },
                {
                    "sent": "Another example here you can see in the object part there are two.",
                    "label": 0
                },
                {
                    "sent": "Different types, so there's there's one your eye and one variable, so here the object distance is set to one and the maximum distance here for the maximum aggregated distance here of course is 3, and this is meant to represent the two triple patterns are in fact not equal at all, so maximum distance kind of is as a way of determining that these are very disjunct triple patterns.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So now for graph pattern matching matching what we actually do is or what we what the problem we're trying to solve is is to determine the complete bipartite cover with minimum cost between 2 between the triple patterns of two basic graph patterns.",
                    "label": 1
                },
                {
                    "sent": "And here we set the cost threshold for any match of two triple patterns to one.",
                    "label": 0
                },
                {
                    "sent": "So at most the coast the cost I introduced in the last slide can be one.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For group patterns, we're going back to the decomposition I introduced earlier, and we recursively decompose the group graph patterns into basic graph patterns and then match these and based on this we can match the parent graph patterns and we can only match these if the cardinality of the sets of the decomposition is equal.",
                    "label": 0
                },
                {
                    "sent": "And of course if the keywords is equal, so we don't want to match an optional statement from an optional block with a statement from another block that is not an optional statement.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "What we're doing is we're using a greedy algorithm here, and this is a version of the Gale Shapely algorithm, which is typically used for the stable marriage problem, and this runs in quadratic time for the matching of the triple patterns and the result of this algorithm is then the minimum cost cover of the match triple patterns.",
                    "label": 0
                },
                {
                    "sent": "If such a cost minimum cost cover exists.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Next up, if we do determine a nonempty cover, we can merge individual pairs of matched triple patterns by replacing the non identical parts with unique variables.",
                    "label": 1
                },
                {
                    "sent": "So this is what I introduced earlier informally.",
                    "label": 0
                },
                {
                    "sent": "So now here you can see that the difference here in these two trouble lenses.",
                    "label": 0
                },
                {
                    "sent": "In fact the object and the aggregated aggregated distance here is less than one, so we can merge these by introducing a new variable which is unique to.",
                    "label": 0
                },
                {
                    "sent": "Query.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 1
                },
                {
                    "sent": "And in case in case we have at least one merge, so in case the two queries we analyzed are not identical and there is not a trivial kind of matching taking place, then the new query template we can generate is basically one of the previous queries.",
                    "label": 0
                },
                {
                    "sent": "But we replace the non identical part or the non non matching or the non identical triple patterns that we have matched with the new merge triple pattern, that is that contains a new variable at all match queries in our approach for Mcqueary cluster.",
                    "label": 1
                },
                {
                    "sent": "And these may overlap, so they might be queries that belong to multiple query clusters, so there can be they can be represented by different query templates.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, next I'm going to evaluation and this is a two fold evaluation and I'm talking about.",
                    "label": 0
                },
                {
                    "sent": "First, I'm talking about the actual data and actual recurrences in real world sparkle query logs.",
                    "label": 0
                },
                {
                    "sent": "And then I'm going to present our pre fetching approach and introduce how this works and what the benefits are for this.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we analyzed the DB pedia.",
                    "label": 0
                },
                {
                    "sent": "3.6 We relax provided for the use MoD Workshop last years Useful Workshop and these contain about 8.5 million anonymized sparkle queries for Ford Dot 3.6.",
                    "label": 1
                },
                {
                    "sent": "And this is what the OR?",
                    "label": 0
                },
                {
                    "sent": "This is an excerpt of the request, so you can see here that there is anonymized IP address, which is a really long hash and then we have a timestamp which is not by chance in hourly granularity.",
                    "label": 0
                },
                {
                    "sent": "Because this is the granularity of the timestamps, there's only a full hour given.",
                    "label": 0
                },
                {
                    "sent": "And so for our approach, we wanted to determine query sessions and what we did was we analyzed all queries from the same user.",
                    "label": 1
                },
                {
                    "sent": "So from the same IP address with the same timestamp and these form query session our approach.",
                    "label": 1
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So first I want to show the.",
                    "label": 0
                },
                {
                    "sent": "The homogeneity of query session.",
                    "label": 1
                },
                {
                    "sent": "So on the X axis here you see the frequency of sequences of queries from distinct clusters.",
                    "label": 1
                },
                {
                    "sent": "So these kind of these phone kind of fingerprint where the queries come from which query clusters and on the Y axis you see the query session length.",
                    "label": 0
                },
                {
                    "sent": "Or I should rather say query session size on average for the queries belonging to the different sessions or to the same session maybe?",
                    "label": 0
                },
                {
                    "sent": "At two different sessions and what we term we use here is homogeneous query sessions for in case all queries will actually belong to the same cluster, so they all have one query template in common and teacher genius query sessions.",
                    "label": 0
                },
                {
                    "sent": "There might be queries from different clusters.",
                    "label": 0
                },
                {
                    "sent": "What's surprising here is that the homogeneous query sessions are actually more frequently than heat Regina's query sessions.",
                    "label": 0
                },
                {
                    "sent": "So that means that of course based on our session.",
                    "label": 0
                },
                {
                    "sent": "Delimitation approach there are more queries actually from the same user that are that have similar structures then then have not and what's also surprising or even more surprising, maybe is that on average the homogeneous group sessions are even longer, so you can imagine that there are many many similarly structured queries coming from the same user during the course of a session, many more so than for the heterogeneous query sessions where people are or requests differ in between the.",
                    "label": 0
                },
                {
                    "sent": "Different queries.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Next up, you want to show the conditional probability actually of two queries within a session being from the same pair from the same from the same cluster.",
                    "label": 0
                },
                {
                    "sent": "And here on so both the X&Y axis here represent query clusters and we sorted these in descending size of the number of elements they contain, so you can basically so the lower left hand point basically visualizes how probable it is or how likely it is.",
                    "label": 0
                },
                {
                    "sent": "For the most, for a query from the most frequent query cluster over the largest query cluster being followed from a query from the same query cluster.",
                    "label": 0
                },
                {
                    "sent": "And as you can see here, or this is what I said, the diagonal here always means that there are two successive queries from the same cluster.",
                    "label": 1
                },
                {
                    "sent": "And the 1st result is that the this matrix or this heat map is sparsely populated, so you don't have many options.",
                    "label": 1
                },
                {
                    "sent": "Basically if you consider any given query then the successive query for this query throughout query sessions is most likely from only a number and limited number of other query clusters.",
                    "label": 0
                },
                {
                    "sent": "And Secondly, of course there's a high chance that the two successive queries are actually from the same cluster and this is of course indicated here by.",
                    "label": 0
                },
                {
                    "sent": "Diagonal and this kind of goes back to our point that there are recurring patterns in sparkle queries, and we want to exploit these.",
                    "label": 0
                },
                {
                    "sent": "And this is kind of the.",
                    "label": 0
                },
                {
                    "sent": "The hints we're taking from the real query logs.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Next up, the data prefetching evaluation of our approach.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And here this is very straightforward, so you can see here at this example.",
                    "label": 0
                },
                {
                    "sent": "So this is a very very basic query asking for the English abstract of a specific resource and the longest sequence of curious we found in the query logs that contain only queries from this cluster.",
                    "label": 0
                },
                {
                    "sent": "Of course distinct, so the resource changes the subject changes throughout this session or throughout the sequence.",
                    "label": 0
                },
                {
                    "sent": "Contains about 56,000 queries, so this is a very long query session if you so will.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "And what we measured was the average response time from the DP endpoint.",
                    "label": 1
                },
                {
                    "sent": "So we send these requests from our local machine to the depths of the public bday endpoint, and we measured an average response time for these queries from this cluster.",
                    "label": 0
                },
                {
                    "sent": "Of course of five point, 2 milliseconds, and these are only, of course, retrieving at least at most one result.",
                    "label": 0
                },
                {
                    "sent": "Some don't retrieve any result.",
                    "label": 0
                },
                {
                    "sent": "And what we did is we basically replaced, then the concrete resource by a variable as discussed in the matching approach and the template generation approach.",
                    "label": 1
                },
                {
                    "sent": "And we measured average response time from the DVD endpoint of 611 milliseconds.",
                    "label": 1
                },
                {
                    "sent": "And this is for 1000 results or retrieving 1000 results at once.",
                    "label": 1
                },
                {
                    "sent": "So you could argue that the speedup for treating the same amount of results achieves nearly factor 10.",
                    "label": 1
                },
                {
                    "sent": "So if you if you issue 1000 queries from this cluster.",
                    "label": 0
                },
                {
                    "sent": "Separately, then you will aggregate latency on factor 10 or with a factor of 10.",
                    "label": 0
                },
                {
                    "sent": "Compared to the template prefetching approach.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So of course the benefit of actually prefetching this data depends on the number of queries within a certain time frame, so it doesn't make sense to prefetch data if all you see is one or two or three requests, because you're actually prefetching large amount of results and what we did here was we analyzed the template coverage rate for different time frames and the template coverage rate is defined as the number of distinct results for individual queries in a certain time frame.",
                    "label": 0
                },
                {
                    "sent": "Divided by the number of results the template actually prefetches, so these are all the results, and so we analyzed.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This for individual query sessions and as you can see here already, there are some queries and so these are the top five largest query sessions that we extracted from the log files.",
                    "label": 1
                },
                {
                    "sent": "As you can see, there are some sessions that already where the template already covers more than half of the results that were retrieved by individual request during the query session.",
                    "label": 0
                },
                {
                    "sent": "An as I said on the previous slide, is that the speedup factor 10?",
                    "label": 0
                },
                {
                    "sent": "So if you actually retrieve.",
                    "label": 0
                },
                {
                    "sent": "All the all the results using the prefetching approach, then this, then for the first 4 query sessions you already have a benefit here by the template approach and then we also analyzed all queries within a specific day for for a user and here we can see that there are some queries where we have coverage rate of 100%, so all the resources that are in our all the results that are in the knowledge base I actually retrieved during the course of the day.",
                    "label": 0
                },
                {
                    "sent": "From a specific user.",
                    "label": 0
                },
                {
                    "sent": "So here of course the template template prefetching makes much sense because we're actually gathering all these results in advance and we don't waste a lot of time on individual retrieval of results.",
                    "label": 1
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "To sum up, So what we found was that there are many large scale query sessions containing recurring patterns in real world sparkle query logs and what we did was merging these similar patterns to establish query templates.",
                    "label": 1
                },
                {
                    "sent": "We showed that the experimentally we showed that the response time per result is much higher than for the for the individual queries compared to the query templates and this is mostly due to latency, so this effect may vary depending on where their requests are actually being issued.",
                    "label": 1
                },
                {
                    "sent": "And we can imagine many more application scenarios for this template approach.",
                    "label": 1
                },
                {
                    "sent": "So you could imagine materialised views on the server side.",
                    "label": 0
                },
                {
                    "sent": "So storing this data might be relevant for future requests.",
                    "label": 1
                },
                {
                    "sent": "In my memory you could also see this as a kind of replication device for fault tolerance.",
                    "label": 0
                },
                {
                    "sent": "So if an endpoint goes down then the data that is necessary for your particular mashup or application is already prefetched and I presented some more prefetching ideas in the useful Workshop on Sunday, and I'm going to sum this up on the workshop summary session on Thursday.",
                    "label": 0
                },
                {
                    "sent": "And I would like to thank you.",
                    "label": 0
                },
                {
                    "sent": "You said most of your speed up is due to latency, right?",
                    "label": 0
                },
                {
                    "sent": "An I was an then you mentioned materialized views so.",
                    "label": 0
                },
                {
                    "sent": "Do you think?",
                    "label": 0
                },
                {
                    "sent": "You would get that kind of speedup.",
                    "label": 0
                },
                {
                    "sent": "How?",
                    "label": 0
                },
                {
                    "sent": "How much is there in just materializing the view and how much is there in the latency?",
                    "label": 0
                },
                {
                    "sent": "And can you just say a little bit about that?",
                    "label": 0
                },
                {
                    "sent": "Well, it's hard to say.",
                    "label": 0
                },
                {
                    "sent": "I mean, even if I say that latency is one of the more that we benefit most by reducing latency.",
                    "label": 0
                },
                {
                    "sent": "Overall, this is kind of biased as well because we're nowhere close to the DB endpoint maybe, and so latency isn't too much of an issue here.",
                    "label": 0
                },
                {
                    "sent": "And maybe it depends much more on the query execution time on the DVD endpoint on the GPD endpoint side we haven't analyzed actually any sort of materialized view management or selection and creation and updating procedures because this.",
                    "label": 0
                },
                {
                    "sent": "Comes with a whole bunch of other small problems, so I can't really give you an exact answer here.",
                    "label": 0
                },
                {
                    "sent": "This was kind of the.",
                    "label": 0
                },
                {
                    "sent": "Yeah, just.",
                    "label": 0
                },
                {
                    "sent": "I don't there because I mean DPS also very specific in the distribution of its.",
                    "label": 0
                },
                {
                    "sent": "The contents and the number of subjects and the requests.",
                    "label": 0
                },
                {
                    "sent": "And so it so much depends on the concrete data you're looking at in the concrete queries, maybe so I'm sorry, but I I'm not.",
                    "label": 0
                },
                {
                    "sent": "I'm not going into guessing here.",
                    "label": 0
                },
                {
                    "sent": "Can you tell us a bit how much data you copied?",
                    "label": 0
                },
                {
                    "sent": "During these prefetching and so this is a good question, I was kind of expecting.",
                    "label": 0
                },
                {
                    "sent": "So, for example, for the for the abstract information, I think there about 303.5 million resources with an English abstract in DB pedia.",
                    "label": 0
                },
                {
                    "sent": "So of course now prefetching approach and for example, I introduced all of these need to be retrieved so.",
                    "label": 0
                },
                {
                    "sent": "This is kind of a simple answer, but of course I'm aware that this is a large amount of.",
                    "label": 0
                },
                {
                    "sent": "Information you need to retrieve in advance and you need to know very so you need to be aware that you actually need this data subsequently.",
                    "label": 0
                },
                {
                    "sent": "So, and this is kind of what I wanted to show in the first part of the evaluation that there are cases where it makes sense to have this to prefetch this large amounts of data in advance, you generalize the constants to variable, saying the object position of your triple, and so you could end up retrieving a lot of data.",
                    "label": 0
                },
                {
                    "sent": "More than I need to have any sense of how often it happens that the prefetching then gets you know every city in the world except instead of solve the 100 cities that you want.",
                    "label": 0
                },
                {
                    "sent": "So again, I mean this depends very much on the data that you're using, and so there might be query templates which look kind of like they're retrieving a whole bunch of results, but they don't because the endpoint you're issuing them against doesn't contain many results.",
                    "label": 0
                },
                {
                    "sent": "So this in this case you're off the hook, basically.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "And but of course, you're right that you need to look very carefully at what the query session sessions look like, and that you need to know in advance what the data about the benefit of prefetching this data is.",
                    "label": 0
                },
                {
                    "sent": "And here we are, kind of.",
                    "label": 0
                },
                {
                    "sent": "We're kind of in a pickle because we use these query logs provided for the useful Workshop and they are very nice, clear logs and this is very nice data, But there are not too many features.",
                    "label": 0
                },
                {
                    "sent": "I would say that we can use to determine if the queries are or if these are good representatives for such prefetching techniques.",
                    "label": 0
                },
                {
                    "sent": "So here what we actually need to do and we're actually working on right now, is determining good features to know in advance for which queries it makes sense to prefetch this data.",
                    "label": 0
                },
                {
                    "sent": "So this is kind of ongoing work right now.",
                    "label": 0
                },
                {
                    "sent": "One way to solve this this problem might be to add a typing triple to your query that is determining the most specific common type of the of the instances in the pattern and then trying to constrain a little more viable right?",
                    "label": 0
                },
                {
                    "sent": "So this is actually kind of what I presented in the Useful Workshop on Sunday, and But of course I mean this comes.",
                    "label": 0
                },
                {
                    "sent": "This is a natural idea to have them.",
                    "label": 0
                },
                {
                    "sent": "Thank you very much, your Highness.",
                    "label": 0
                }
            ]
        }
    }
}