{
    "id": "63oqbju3g4inujwv5zwkipgkiituw6qt",
    "title": "Relational Learning as Collective Matrix Factorization",
    "info": {
        "author": [
            "Ajit Singh, The Auton Lab, School of Computer Science, Carnegie Mellon University"
        ],
        "published": "Feb. 14, 2008",
        "recorded": "February 2008",
        "category": [
            "Top->Computer Science->Machine Learning"
        ]
    },
    "url": "http://videolectures.net/cmulls08_singh_rlm/",
    "segmentation": [
        [
            "Hi so this is joint work with Jeff Gordon, my advisor.",
            "Hopefully the pace will be a little more tutorial like rather than throwing things at you.",
            "If you have any questions of clarification, feel free to ask them during the presentation, but I'd ask the broader questions be left for the end.",
            "OK."
        ],
        [
            "I don't know if it's complication, but can you clarify whether it move this out?",
            "Feel free to OK so the game that we have is the world consists of data which isn't just a single table of values, it's really generically relational and the simple simplest example of relational data that we deal with on a relatively frequent basis is a word is a document word matrix.",
            "So for example, the way that I view word occurrence matrices, these sort of bag of word models is a relationship that a word occurs in the document.",
            "And it's count value to just the value that occurs has is just the number of times that awards occur in this document.",
            "So we can represent this relation as a matrix where the rows correspond to one entity type documents and where the columns correspond to the other entity type words and the value of this matrix corresponds to the value of this relation.",
            "And there's no requirement that all of the values be filled in.",
            "There's no requirement values be filled in, and there's no requirement that.",
            "The values all be the same type.",
            "So for example, we could stack together different types of relations where some of the entries are Gaussian, where some of the entries are points on whatever."
        ],
        [
            "So a slightly more sophisticated example is a case where you have two types of data where you have word counts for documents and where you have some other side information.",
            "In this case authorship of papers where we also represent the author of relation as a matrix and the theme of this presentation and our perspective of relational learning is that you have these different sources of information.",
            "These different relations, each represented by a matrix.",
            "And what we want to do is we want to combine information from these two relations in a way that allows us to predict better on each of them, and so in this case, what we're saying is that we want to use authorship information for documents or word information from these documents to help predict authorship in addition to using what we know about Co authorship already.",
            "And so this model of relational data.",
            "This view allows us to encompass common tasks like link prediction.",
            "If you view a graph as a binary matrix, filling in values of that matrix corresponds to predicting links and link regression where you want to predict the value for a link.",
            "So in this case the Word document matrix filling in a value, there would be a link regression.",
            "We don't just want to know whether a word occurs, we want to know how many times it a curd."
        ],
        [
            "OK, and so our motivation here is this example of reconstructing authorship.",
            "So predicting authorship where we have authors for where we have authors for a set of documents an for the same documents, we also know what words occur in the abstract.",
            "This is actually data from NIPS.",
            "And so think of the why measure is loss so lower is better.",
            "And think of Alpha is a mixing constant where at one all we're doing is we're just using the author of matrix to predict authorship.",
            "We're not using any word information and at Alpha equals to zero.",
            "We're only using words to predict authorship, and so without going into the details of what this loss actually means, the intuition here is that the minimum loss overall values of the mixing is somewhere between zero and one.",
            "We don't just want to predict authorship using the authorship matrix and no word information.",
            "But the same time, we don't want to predict authorship, just using words we want to mix the two sources of information and the way in which we do this mixing is.",
            "The topic is really the scope of this talk.",
            "Yeah, stupid one, but.",
            "I didn't understand the right that you're using the author matrix to reconstruct the author of Matrix, so in that case it's really just.",
            "So the way we're going to do it is you can build.",
            "You can factorize each matrix and you can do the standard collaborative filtering tricks using coauthorship information to predict values that are missing from the matrix.",
            "OK, so you're shrinking, yeah, OK. Alpha is this mixing term, so how much are we mixing information between authorship and Word document and the occurrence of words in these documents?"
        ],
        [
            "We'll come back to that at the end of the talk and actually explain what all the terms mean.",
            "I just wanted to give you this intuition that mixing helps.",
            "OK, so.",
            "The building block of our models are going to be matrix factorization in the first half of this talk is going to cover largely this topic in fairly broad generality, so we're going to represent a binary relation as a matrix, like I mentioned on the 1st slide, and everything that we talk about generalizes to higher order relationships where the relation is in just over 2 entity types, but over three or more entity types.",
            "In that case, instead of using a matrix, you're going to use a tensor, and once you choose a basis for tensor, all of the math generalizes.",
            "So in the standard matrix factorization model, which is commonly referred to as SVD, you have a data matrix.",
            "N by M and you're going to build a low rank representation of this matrix where you corresponds to the factors to the row factors and where V corresponds to the column vectors.",
            "So in the Word document example, you are really word factors V or document factors, and these embed the these embed each of these entities into low dimensional spaces and hopefully there's some."
        ],
        [
            "Reconstruction here.",
            "So the key idea is that with a little bit of generalization, alot of algorithms are instances of matrix factorization and the broad approach that we're going to be taking even if you don't follow all of the individual points here is that the model, the standard matrix factorization model isn't a linear model, it's a bilinear model in the sense that if you fix you.",
            "That really is just a linear regression from V onto the data, and if you fix V, it's a linear regression from you onto the data, and So what we're going to do is we're going to take a lot of what we know about linear models in linear regressions and generalize it to the case of these bilinear models these matrix factorizations.",
            "OK, so what's the first generalization that we're going to make, yeah.",
            "The version of.",
            "Daniel Matrix entries are, yeah, so in standard STD there's this diagonal matrix which is positive definite and you can fold it into you.",
            "You can fold it into V for most of this talk, we're just going to fold it into one of them and just ignore it.",
            "But you can.",
            "Deal with the case where you have this dog."
        ],
        [
            "Sigma matrix.",
            "OK, so the first generalization that we're going to take over the standard SVD type model is data weights, so this is just a constant non negative matrix where the entries of this W matrix wait.",
            "The importance of each entry of the data matrix and so why is this useful?",
            "So if your data matrix X has missing values, which are these greyed out squares?",
            "Here you can zero them out in the weight, which effectively removes them from the data you have missing values.",
            "If you have missing values in a matrix and you just compute zero, you're going to be treating that zero like a significant value.",
            "Which in practice is not a good thing.",
            "So for example, say you had a user user movie matrix is sort of Netflix ratings matrix.",
            "Most of the entries are missing.",
            "It isn't that a 0 means that a user didn't rate rated the movie 0 is that they never watched it or never rated it, and so you really want to pull out those values from the factorization.",
            "And sometimes you care about focusing on certain pieces of the matrix, certain row, certain columns, certain blocks of the matrix, and you can do that here.",
            "It's a fixed matrix, doesn't change."
        ],
        [
            "Anything?",
            "So the second generalization is, what if the prediction?",
            "What if the relation between X and the parameters?",
            "UV transpose is nonlinear?",
            "So we're going to introduce this thing called a prediction link, which is just taking UV transpose and shoving it through prediction link, which is a convex elementwise function.",
            "So, for example, here we're going to say that it's the exponential function, and so all you're going to do is, for each entry of UV transpose, you're going to take the exponential of it, and that's going to be your prediction for X."
        ],
        [
            "So why do we want prediction links?",
            "Well, this gives us the matrix version of a generalized linear model, which is saying instead of X being UV instead of a particular entry of X being a row of you times a row of V. We're going to say that it soroa viewer ohavi through some nonlinear transformation, which gives you a generalized linear model.",
            "If you assume that F. Corresponds to an exponential family.",
            "Yeah, so actually some matrix function is a mapping from the matrix to matrix.",
            "Yeah, it's an elementwise function.",
            "So UV transpose is going to be the same size as X, and then just elementwise.",
            "We're going to apply this function.",
            "So convert this this elementary but convex.",
            "In one sense it's convex in the sense that app is a univariate function with positive gradient.",
            "So it doesn't have to be strictly convex, but it typically is, and so one of the nice things about generalized linear models is that allows you to encode some constraints in your output to respect certain properties of your data without making learning harder.",
            "And so in this case, we assume that the link is the exponential function, which means that all of your predictions are going to be positive.",
            "But yet the we're going to see that the optimization over the parameters UV transpose is going to be unconstrained.",
            "So instead of having to represent the positivity constraint on your data in a linear regression by putting constraints on U&V transpose, which makes the optimization harder.",
            "We're just going to shove it through a link function will see later on that you're not just inheriting a positivity constraint, you're inheriting a full distributional assumption and all that question.",
            "So when you have ways that are not old ones, then the punch and is no longer comics.",
            "So the entire objective I'll get to that point here, going ahead about five slides."
        ],
        [
            "OK, so the third generalization is the notion of a generalized order weighted loss, so I put this squiggly = between them in all of these diagrams, but I haven't really defined what that is.",
            "What this measure of reconstruction error is between X and UV transpose?",
            "So.",
            "We're going to say that in general, the matrix factorization can have any divergent.",
            "You can pick it as long as you take the data weights into account, and some common examples that we can view as losses or weighted divergences, or squared loss where you just look at the weighted sum of squared errors.",
            "KL divergences just a weighted version of KL Divergent, and there's lots of other choices."
        ],
        [
            "OK, so now we have this optimization problem where our model is X is equal to VTV transpose and what you need to do is you need to find the optimal factors U&V.",
            "So we have a function which is typically convex in UV transpose but typically not convex in U&V.",
            "To get to your question.",
            "But there are other issues that we still have to consider about.",
            "The model is still deficient in some way, So what about overfitting?",
            "If we want that, yeah.",
            "Send your objective function so X is observed matrix access the data, yes.",
            "Then the words about become from the data weights.",
            "These are the data weights that you fixed beforehand.",
            "So you're not optimal.",
            "Every cell in the matrix in some ways, yeah, and you can assume that they're all ones, which is what we often do.",
            "You don't have to.",
            "And FUV transpose.",
            "Without any effort, so you just ignore that doesn't work.",
            "You can ignore W if you want to, but for full generality we're going to include it in FUV.",
            "Transpose is just this estimate of X where you are the parameters and so the model is still deficient in the sense that you can have overfitting.",
            "There's a lot of parameters in the matrix factorization.",
            "Moreover, what if we want to put some sort of constraints on U&V?",
            "What if we have what we want you and me to be sparse?",
            "What if we want to constrain our factorization to be done negative?",
            "Going back to Lee and Ceilings, famous algorithm and we don't really know how hard the optimization is yet.",
            "For a given choice of a divergent in a given choice of prediction link."
        ],
        [
            "OK, so regularization there's a lot of parameters for every entity, so going back to the first slide for every document for every word, for every author we have K parameters where K is this embedding dimension.",
            "So you could overfit alot, which means that we're going to need to regularize the parameters.",
            "And like in a regular model, you can take all of the LP norm regularizers where you say look, I have some regularizer over my parameters U&V I'm going to treat you and V is in dependently regularised.",
            "And I can look at the L2 norm of U and the L2 norm of V. You can look at the L1.",
            "You can look at any of the LP norms where the term that we have here is just looking at them individually.",
            "You can encompass really all of the standard linear regression regularizers that you want.",
            "But there are also ones which are unique to matrix factorization.",
            "And one example here is a trace norm where you take U&V.",
            "You take UV transpose.",
            "You take that you take the sum of the singular values of UV transpose and we treat that as your regularizer.",
            "So why would we want to take the trace norm?",
            "Well, it's a continuous approximation for the rank that is the rank of UV transpose increases.",
            "So it is a trace norm.",
            "And what the trace norm allows you to do is it allows you to set K to be a very large value.",
            "Arbitrarily, anything that an arbitrarily large value, whatever you want it to be, and to penalize the reconstructions based on the true rank of UV transpose.",
            "Not just saying that the rank is, you know, in the worst case, K. Yes, yeah.",
            "Above the trees move there already have well established concepts about the effective degree of freedom.",
            "Then the based on a single single values or some single single single values of the original matrix.",
            "How this is?",
            "Truncated version approximately.",
            "When you do the SVD again, how does it related to that kind of?",
            "So it depends a lot on the divergent.",
            "It depends a lot on the prediction link, but what we can say is that as K approaches the minimum of Eminem, the data dimensions of your matrix, the.",
            "L2 regularizer is going to approach the trace norm.",
            "I mean there is no general statement that you can make about the relation between the trace between the rank of UV transpose in the rank of the data because we haven't talked we haven't fixed D. The standard definition of effective degrees of freedom, disrespect SVD for the original matrix.",
            "Probably a question better dealt with at the end of the presentation rather than now.",
            "Kind of tangential, so the optimization now is that you have these parameters U&V.",
            "We have a reconstruction error.",
            "We haven't specified what that is yet, so it's hard to make specific statements about it, and we have this regularising term."
        ],
        [
            "OK, so you can also have hard constraints and so thus far we haven't really said anything about U&V in our optimization.",
            "We've assumed that you and V. Can really exist anywhere in the real set, but in a lot about to encompass a lot of different algorithms into our matrix factorization framework.",
            "You need to consider constraints for the factors like orthonormality, which is just saying that each that the rows of you are perpendicular and the norm of each row view is 1.",
            "The clustering constraint says that each row of you is a probability distribution.",
            "You can also do a clustering constraint on V, saying that each row of Y is a probability distribution.",
            "Nonnegativity says the factors are non negative.",
            "The entries are non negative and you can put hard sparsity constraints which differs from L1 and that we're putting a cardinality constraint saying that at most P entries in any row of you or any row AV.",
            "Are non 0.",
            "And so typically the hard constraints, with the exception of Orthonormality lead to a constrained optimization.",
            "But now our generic optimization problem includes these.",
            "These constraints on U&V."
        ],
        [
            "OK, so we have all of this notation now.",
            "How does this help us describe things, but we'll take 2 examples.",
            "The 1st way to singular value Decomposition's and 2nd that latent semantic indexing or probabilistic latent semantic indexing?",
            "And we're going to talk about how we can fit them into our framework.",
            "So awaited singular value decomposition is the case where you want to reconstruct a matrix under squared loss.",
            "You have data weights typically because you want to zero out missing values.",
            "And So what you want to do is we have our prediction link F is going to be the identity function, X is equal to UV transpose.",
            "The divergences squared loss and the hard constraints are that we constrain V to be orthogonal and U transpose U as diagonal.",
            "You can include a regularizer by basically bounding the entries on the diagonal of U transpose you.",
            "He said that X is.",
            "So yeah, I'm sorry XX it another step.",
            "Yeah, so this is our data.",
            "This is our estimate X hat.",
            "Think of FUV transpose is X hat.",
            "OK. You did not include the transpose.",
            "We would be basically so in the weighted case if you there isn't always a solution when they are both orthogonal.",
            "Or orthonormal here, we're saying that the rows of you are perpendicular because its diagonal matrix, but we're not constraining the norm of each row of you to be.",
            "1.",
            "It's only reason cousin that it's to ensure that there's always a solution.",
            "So there are cases in the weighted case where you know if you transpose U is constrained to be the identity matrix, then the optimization the constraints are infeasible for certain objectives for certain."
        ],
        [
            "Use of the weights.",
            "OK.",
            "So the second example is probabilistic latent semantic indexing, and this is a technique for word and document clustering.",
            "So we've moved away from the prediction case where we just want to pick the values of X, and we're going to talk about something which is very different from what you typically view as an SVD.",
            "And So what you do is you have a document word matrix.",
            "And we're going to introduce well, so we're going to introduce K latent factors in the latent factors in the matrix factorization.",
            "Refer to as topics or aspects and PLSI.",
            "And what you're going to say is that the probability of a document Anna word corresponds to the probability of a document given a latent factor times the probability of a word given the latent factor times the prior over these latent factors integrated over your latents.",
            "And so, one way of fitting this into our matrix factorization framework is by looking at the log likelihood by looking at the probabilities of documents and words, which is this matrix on the left hand side.",
            "We're not going to deal with the data matrix here, because P LSI doesn't generate predictions it generates clusterings it can generate can be viewed as a matrix factorization of X.",
            "It can be viewed as a matrix factorization of the likelihood.",
            "Yeah.",
            "Should not be publisher Z given document.",
            "0 sum to one.",
            "Z given documents, let's see.",
            "No documents given latents so latents are the case.",
            "Each lawyer document.",
            "Yeah, in you.",
            "No, yeah, OK, so the probability this Red Square should be.",
            "Transpose to get a probability distribution.",
            "We're just looking at the probability of document two given to latent factors here.",
            "So we're not saying that comes to one.",
            "We're saying that the columns of you sum to one.",
            "Thanks.",
            "We have S, which goes back to the original question about SVD being this diagonal matrix which corresponds to the topic priors and V transpose being the probabilities of words given each of the latent topics.",
            "And so in the key point here is to note that we're not factorizing X were factorizing the probability of documents and words were factorizing the likelihood of the data.",
            "And so one thing we can do is we can fold the topic prior matrix S into UV.",
            "Yeah question about the topic parametric.",
            "Yeah I thought the point of LSA was too identified, like latent topics, so I'm trying to figure out if you don't know what the topics are ahead of time.",
            "The only meaningful things I can put in think of to put in the S is either just have it be the identity matrix or since this principle components just say well, there's going to be the primary component waiting that way.",
            "Can you give us some intuition for where is this coming from?",
            "Yeah, OK so.",
            "You have your like, so when you have this joint probability of the documents in the words and, they actually do the factorization over US&V transpose.",
            "So you start with some random some random ass matrix and in the standard way of doing PLSS you do EM over this model where when you do the updates you get iterative updates of your topics of the distribute.",
            "You get iterative updates of the probability of each of your latents each of your topic.",
            "So overall you're trying to solve for S but you start with initial estimate.",
            "Well NPL's eye.",
            "Often what you display is.",
            "Your results are the topics and the weights of the topics, but when you're actually doing predictions.",
            "You do want to look at how well each document participates in each topic.",
            "So how close so how much does each document belong to each particular topic which corresponds to row or column of you, depending how you view it, yeah?",
            "Nation point when you say topic for our market matrix X, but I think the latent semantic indexing.",
            "They just consider a prior prior is vector of topics.",
            "You know the current property.",
            "It's a diagonal matrix.",
            "Sorry, you can't see the zeros.",
            "I know, but this is.",
            "Standard as he indicated, but it's against the concept of a probability Ellis other side.",
            "We cannot think of areas of matrix there prior.",
            "Often work well.",
            "Probability one.",
            "If you go back to house one if you go back to how often presents it.",
            "This is P dot presented as the relationship between the log likelihood in the SVD 2.",
            "If you multiply it out, you get exactly the formulation that you're mentioning that you have."
        ],
        [
            "Vector of topics.",
            "OK, so we can fold ineson to you here.",
            "Which is just a convenient to fit into our notation, and so the game is.",
            "You have this like this, probability.",
            "You have factors U&V and you want to fit you in V by maximum likelihood where you have these hard constraints that you is a matrix is really a probability, entire matrix is a probability distribution and that the entries of UAV or probabilities."
        ],
        [
            "OK, so you have this.",
            "You can view this as a loss function so you can view this in our standard framework where the prediction link is the identity.",
            "Because U&V are probabilities Anna responses.",
            "These likelihoods are also probabilities, so you don't need to do anything fancy with the link.",
            "The loss is KL Divergent and this is a constrained optimization, typically solved using M, which is a major isation algorithm, but there's no reason why you can't do it using any of the other styles of solvers like grade like direct gradient descent or alternating Mac."
        ],
        [
            "Imitation.",
            "OK, so we have this overview of matrix of matrix factorization as a unified framework.",
            "We're going to segue into a particular class of divergences because in the previous slide that didn't really mention where the divergent D and where the prediction link ever coming from, and that they're going to come out of Bregman divergences which are motivated by exponential families.",
            "And finally, we'll get to the relational models."
        ],
        [
            "OK, so a Bregman divergences?",
            "Just imagine that you have to observe two observations in the reels.",
            "We're not dealing with matrices right now.",
            "Bregman divergences with respect to a close differentiable convex function.",
            "F is the formula on the screen.",
            "And if you squinted the equation for a moment, you can plot this transfer function F, and you can think about the relationship between F of X&F of Y plus the gradient of FY X -- Y.",
            "That's really the first term in the Taylor expansion.",
            "Of F of Y centered of F of X centered at Y.",
            "And so the Bregman divergences can be thought of is really the tail of a Taylor expansion, or the residual amount.",
            "And so if you change the definition of F, you're going to change the definition of the divergent or the distance.",
            "And the reason we deal with Bregman divergences, we can encompass a lot of different a lot of distinct notions of distances or loss measures like KL divergent, squared loss, Itakura Saito I divergent into a single framework."
        ],
        [
            "OK, so the reason we're dealing one class of distributions which we really care about that are fully encompassed by Bregman divergences or regular exponential families, and these encompass all of the standard distributions that you work with, like Gaussians like Pasoan like Pino Meals, Bernoulli's exponentials, whatever.",
            "The standard distributions in a textbook, like a cell emerger.",
            "So a regular exponential family is just a family of distributions with natural parameters, Theta particular form for the log likelihood, where the term that we care about is F of Theta, which is the log partition function that uniquely identifies the family.",
            "So if you look at the form of F you can know the Gaussians.",
            "All have a particular form for F, the paulsons all over particular form for, etc."
        ],
        [
            "But and so if you look at the log partition function for F, you uniquely identify a regular exponential family.",
            "So for example, the first F corresponds to Gaussians, this next one plus all the next one Bernoulli but log partition functions are all convex.",
            "In fact, they're strongly convex, so we could plug this F back into our earlier definition of a Bregman divergences, and if you do that, you find that look for this particular log partition function.",
            "We get squared loss if you apply the log partition function for Apostle.",
            "You get I divergents and if you apply the log partition function for a Bernoulli you get log loss and this is where you get a lot of standard statements that you'll see in intro machine learning where minimizing squared loss corresponds to maximizing the likelihood of a Gaussian distribution where minimizing log loss corresponds to fitting a Bernoulli distribution.",
            "This is a general statement about regular Bregman divergences and regular."
        ],
        [
            "Potential families so one thing that we need to actually fully formalize this definition of the relation between the two is the notion of duality.",
            "So the log partition function uniquely identifies a regular exponential family.",
            "But we can also uniquely identify a particular family by its convex conjugate.",
            "Where we refer to MU is the expectation parameter, so theater here will refer to as a natural parameters of the exponential family.",
            "But you can also.",
            "Compute you can also identify the family and identify divergences in terms of the expectation parameters, which means the expectation parameters.",
            "You can think of is predictions, which means all of our divergences can be done on the parameters of our model or on the predictions made by the model.",
            "Depending on whether you do it in the natural parameter space or in the dual spaces."
        ],
        [
            "Spectation space.",
            "OK, so the formal statement of the theorem is that the log likelihood corresponds to these first 2 terms, which don't vary with data, so the log of the base measure plus this convex conjugate with respect to X -- a Bregman divergences were the Bregman divergences defined by this dual.",
            "And where, importantly, the prediction link this F that we talked about earlier in matrix factorization corresponds to the gradient of the log partition function.",
            "So in general, if you want to maximize the left hand side, you want to minimize the Bregman divergent on the right hand side."
        ],
        [
            "And so we have a bunch of quantities available.",
            "We have an exponential family.",
            "We have log partition functions.",
            "We have prediction links and we have Bregman divergences.",
            "And because of this relationship between Bregman divergences and exponential families, picking any one of these corresponds to picking the rest of them.",
            "It gives you a choice for the rest of them.",
            "So if I say that my data is Gaussian distributed, it immediately tells me that the matching prediction link should be the identity link.",
            "If I assume that my data is passam distributed, it's going to give me a prediction link, which is going to correspond to the exponential function.",
            "And you're also going to get the corresponding Bregman divergences, and if you follow this formulation, what you're going to get is a problem which is convex, which is generally convex with respect to the first parameter of the vergence.",
            "Is there a simple answer of what to do if it's?",
            "If it is it?",
            "No, I don't think that there's any exponential family.",
            "That correspond to zip."
        ],
        [
            "Or at least a regular one.",
            "The same problem happens with Laplace.",
            "It's not regular exponential, so you can't fit into this framework.",
            "OK, so back to matrix factorization were given a matrix and the way we want to view it as to say that this matrix is a collection of samples which are drawn from an exponential family.",
            "So let's just say Gaussian or plus or whatever where the single natural parameter is.",
            "An entry of UV transpose and so in this diagram one entry of X corresponds to a draw from, let's say, a person distribution.",
            "Here with the natural parameters.",
            "Correspond to multiplying a row of Ian Row of Iubire OV and using that as your natural parameter, which is exactly equivalent to saying that X is approximately equal to UV transpose under some prediction link.",
            "And just to incorporate weights back into the whole thing, we can look at weighted log likelihoods and so you can also look at weighted Bregman divergences.",
            "The bottom of the slide where you just.",
            "Look at each entry of the matrix you correspond to Bregman Divergent on that single entry, and you waited appropriately.",
            "Nothing fancy, it's just."
        ],
        [
            "Decomposability assumption."
        ],
        [
            "OK.",
            "So relational models is collective matrix factorization.",
            "OK, so to simplify our notation, we can deal with any number of matrices in any sort of schema between binary relations.",
            "But to simplify the notation a lot so that it fits on one slide, we're going to look at the three entity type case where you have two matrices X&Y.",
            "Share dimension, so in this case you have users and movies you can think of this as a ratings matrix.",
            "You can think of why the binary matrix of genres where one corresponds to saying that a movie has that genre.",
            "And the key point here is that they share dimension.",
            "The movie Dimension is shared by X&Y and that's how we're going to transfer information about ratings, two genres and from genres to ratings."
        ],
        [
            "So we could factor the matrices independently under everything that we said about individual matrix factorizations.",
            "You get these two independent optimizations, but that's kind of silly given that our whole motivation is to share information."
        ],
        [
            "Between two matrices to be collected in our factorization.",
            "And so to share information between the related matrices, we're going to tie the movie factors together.",
            "If matrices shared dimension, we're going to tie their corresponding factor together in the model, and we're going to tie together the loss where I've dropped the regularising terms just for simplicity, and I've added this weighting factor Alpha, which is just a measure of how much we care about reconstructing one matrix over the other.",
            "So the higher Alpha is, the more we care about reconstructing X in our problem.",
            "And the less we care about reconstructing Y."
        ],
        [
            "OK. And so how do we solve this?",
            "Because I've given you a lot of models, but not a way of actually approaching it in."
        ],
        [
            "General, this optimization is going to be nonconvex and UV instead, but it turns out that cause we've picked break.",
            "If we assume that all of the divergences are Bregman divergences in the prediction links or the matching prediction links.",
            "If you fix all but one of the factors, so say you fix U&V and then you optimize Ed, that individual optimization is a convex problem.",
            "And that's entirely a consequence of matching losses and links.",
            "Which goes back to gaming's earlier question."
        ],
        [
            "And.",
            "And So what we're going to do is alternating projections, which is just a generic way of solving a non convex function.",
            "It's block coordinate descent.",
            "We're going to fix all but one of the factors, so fix Viens Ed leave you free and then optimize with respect to you.",
            "Once you do that, you fix you and said you optimize with respect to V. You fix, you envy, you optimize with respect to Z, and if you alternate, you're going to converge to a local Optima."
        ],
        [
            "OK."
        ],
        [
            "Now this still leaves, yeah.",
            "And the UNLV from one single data matrix collection, right?",
            "So that's a decomposition of a derived from one matrix and well worth it is easy.",
            "So you said that you have two source of data.",
            "Yeah, I just want to understand."
        ],
        [
            "OK, so we have two sources of data X&Y from X."
        ],
        [
            "Here's the UNLV, Yep.",
            "Why what you do so from we're going to factorize why?",
            "According to VSAT transpose it should be tilled be in this part but so yeah he is a shared via the shared factor so."
        ],
        [
            "Here in this example you corresponds to the user factors.",
            "V corresponds to the movie factors and we see movies in both matrices, and zed corresponds to genre factors.",
            "And by tying the movie factors together in this concrete example, we're going to allow information sharing between X and."
        ],
        [
            "Why?",
            "Because we're not just going to factorize X independently and then Y independently, we're going to factor them in a way by saying that you know you share these parameters V. So there's going to be some both X&Y are going to influence the update for V."
        ],
        [
            "OK.",
            "So this is a nonconvex problem and we've reduced it down to a series of convex optimizations, but we still haven't said how you're going to optimize that convex function.",
            "And so one way of doing it, there's lots."
        ],
        [
            "Different ways of doing it, but the simplest way is to just compute the gradient of the loss with respect to you when you're updating with respect to you with respect to V and with respect to Z.",
            "Since these are individual one factor optimizations, and if you munch through the algebra you get these terms and So what you can see is that you and zed aren't tide factors, so they only involve this one term.",
            "They only involve looking at the residuals of UV transpose compared to the data X.",
            "If you look at said it's the same thing you're looking at, the residuals of the prediction of Y between Y.",
            "But since V is a tide factor is shared between the two problems, you can see that the gradient is going to involve looking at the reconstruction, the gradient of with respect to the X matrix and the gradient with respect to the Y matrix, and that's where you're going to get the information tying in the optimization.",
            "And so the cost of the gradients is going to be dominated by computing residuals.",
            "Really computing UV transpose is expensive.",
            "Computing visa transposes expensive because in general these are going to be dense matrices.",
            "We haven't made any assumption about sparsity, nonnegativity, etc and so.",
            "In practice these gradients well gradients are typically the cheapest way of optimizing a function.",
            "It's still going to be proportional to the size, the cost of computing gradient is going to be proportional to the sum of the sizes of all of the matrices.",
            "Which is a problem if your matrices are big.",
            "So if you have a lot of documents, if you have a lot of if you have a lot of users.",
            "If you have a lot of movies.",
            "If you have a lot of genres.",
            "You kind of host in that case, yeah?",
            "I understand you correctly, so the FMF someone you said you mentioned.",
            "Other reduction for the UV matrix, no F sub one is a prediction link, so we're going to say that X is equal to is approximately equal to F1 UV transpose and we're going to say that.",
            "Why is approximately its reconstruction is visa transpose under the prediction link F2?",
            "Yeah, I'm trying to understand concepts.",
            "Early reconstruction is a title.",
            "Reconstructed the data under imagining produced record space, so the efforts of one is reduced to one subspace, an effort to reduce the second subspace, and so you don't really.",
            "So you do the.",
            "Use the reducer factor user pairwise.",
            "The variables provide metrics and for another matrix, but we did not really, so this is a design choice.",
            "I'm just want understand another alternative possibilities.",
            "Design choices reduce.",
            "A subspace is important.",
            "All three types of variables so, but I guess if you choose the pairwise.",
            "Yeah, so I think it means question.",
            "Is it an alternate formulation?",
            "So we tide the shared dimensions in the matrices together.",
            "There's lots of different ways you can conceptually share information between X&Y.",
            "And so one example would be to create a shared shared a unified space for both of the data matrices and then to factor them in that unified space, which would be something completely different from what we're talking about.",
            "What a Bayesian would say is that you don't type parameters directly together, that's very untrustworthy.",
            "You want to you want to put prior on all your parameters, and then a hyper prior and then tie them somewhere up there.",
            "There's different ways of basically sharing information you can draw this out as a graphical model.",
            "You can draw the Bayesian version of graphical model.",
            "You can draw the example that you gave me out.",
            "And they're all going to be different forms of information sharing.",
            "They're all interesting, but the one that we're going to be concerned about here is a specific case, but you're right, there are other choices.",
            "OK, so the problem with the gradient step is that when you do this in an alternating maximization, computing the gradient every time you want to take a gradient step, you have to.",
            "Reconstruct what is typically a very large matrix, and what happens is that the steps that you're taking typically are very small.",
            "And so you can let this run for days and you won't make any progress.",
            "Yes, how do you know?",
            "Could you wait?",
            "It will compute the Hessian there, so in the Newton step we're going to have to get the learning rate.",
            "Here we say that how we compute the learning rate is up to you.",
            "We use a one over root T schedule, so one over the number of vacation schedule you can use other things for any sufficiently small edits going to converge as long as you pick some schedule, it doesn't really matter for performance, they're all terrible."
        ],
        [
            "OK, so we need a better way of actually solving each of these optimizations and what we're going to show is that even though we have a lot of parameters in our model, the Newton step is actually practical because of the assumptions that we've made and which are the assumptions that everybody who does matrix factorization makes without actually knowing it.",
            "Sierra hypothetical Newton update.",
            "For you, the number of parameters and you is N * K where N is the number of entities.",
            "So in this case the number of users and or K is your embedding dimension, so you're hashing would be N K * N K. So is the number of users increases.",
            "The hashing gets larger and larger and since we hope to have more than like 5 users in our model.",
            "Inverting the hash and is going to be utterly impossible because you have to invert the Hessian to get a Newton step, and let's cubic in the size of the linear sit in NK.",
            "But because we've assumed that the losses decomposable, the Hessian is block diagonal, it has a special structure where most of the matrix is zero except for these diagonal blocks, and each of these diagonal blocks corresponds to the Hessian for a particular row of U and the same intuition applies to V&Z that while the Hessians are huge, there all blocked diagonal where the blocks correspond to a row of Ian said respective correspond, with each block corresponds to a row V into a row of Z respectively.",
            "And so you see again.",
            "Because the constraints that you put in you so because we assume that the loss is decomposable, so we assumed that.",
            "The reconstruction isn't that the reconstruction for a particular row of X doesn't depend on all of the factors of V on all of you and all of it depends on a particular row of you in a particular Rd V. So yeah.",
            "But for now.",
            "Yeah well, this is.",
            "If you constrain, well, no, this isn't if we've constrained it.",
            "What we've assumed is that in our reconstruction, XIJ is equal to UI to a row of U times a row V. Times are OV transpose.",
            "We didn't say that it's a row of U times all of V under some arbitrary non elementwise transformation.",
            "So this goes back to the idea of saying that our Bregman divergences separable, that we can evaluate it over each element of the matrix independently.",
            "If you didn't have that, if you had a Bregman divergent which was a function of the entire matrix, like, say for example, the log determinant versions on matrices, this trick doesn't work.",
            "The Hessian would be dense.",
            "I can answer the question more detail.",
            "Basically, if you cannot handle the full which goes back, there was yeah, so the separability assumption, like I mentioned in an earlier slide, is the Matrix version of Idleness in the sense that if your matrices are all vectors, it really."
        ],
        [
            "Is just tidiness.",
            "So because of this block structure, we can compute the Hessian.",
            "We can do an update on each row of you.",
            "Each row of each row of zed independently, where the Hessians have a relatively compact form.",
            "If you munch through the algebra and again, what you'll see is that with respect to you and said you're only looking at the Hessian with respect to the matrices with respect to X&Y respectively.",
            "But Becausw, why is tide?",
            "They're going to also be tide in the Hessian that it's going to depend on a weighted reconstruction of the Hessian with respect to the first matrix to X.",
            "And the hashing with respect to Y.",
            "And so the nice and really elegant thing about this formulation is that the cost of computing a Hessian in this model on a parole basis or overall is really only a factor of K more than computing the gradient.",
            "If you look at the cost of computing the gradient, it's dominated by the cost of actually computing these matrix reconstructions.",
            "But once you have them, you can pay a factor of K where K is the embedding dimension more and you can get full second order information.",
            "Now what this doesn't do is this doesn't take into account the cost of actually inverting the Hessian for the Newton step which is K cubed, but we're going to assume that K is typically small compared to the number of since it's a low rank approximation, the embedding dimension is going to be much smaller than the amount of data that you have.",
            "So yeah, it's K cubed, but it's puny compared to everything else.",
            "Yeah, during the day.",
            "Elements here.",
            "Yeah, so this is the elementwise separability.",
            "So this is the middle term is a diagonal matrix.",
            "But you would be in the transposer dense, obviously.",
            "So it's not just the diagonals of V in some sense.",
            "It's not just the diagonals of V, transpose V. And yeah, if you have sparsity, which I think is a broader question that you're getting, if you have sparsity in your data, you can exploit that here.",
            "In all of the matrix vector multiplies."
        ],
        [
            "OK, so we still have the case where both the gradient and Hessian are expensive because we have to reconstruct these matrices either on a per row basis or all in one shot.",
            "We're in the enviable situation where you don't have to decide between conjugate between gradients, conjugate gradients and Hessians, where the dominant cost is the number of parameters were.",
            "In the case where gradients are expensive, so you can't just say you know, use concrete gradient to be done with it, but one thing that works well for us is the notion of stochastic optimization, where instead of using all of the data in a row of X or a row of why to compute the gradient to compute the Hessian every time we need to compute gradient in every time we need to compute a hash, and you're going to sample.",
            "The entries of a row of X or a row of wire column of extra column of Y.",
            "And then you're going to update.",
            "So say in this case you need to compute UV transpose for every row of.",
            "You're going to need to look at all of V, which corresponds to all of the latent factors for movies.",
            "But it turns out that you don't need to look at all of the movies to get a relatively good update for a particular user.",
            "You can look at a subset of them, and for each user will look at a different subset of them.",
            "For user two, we look at these three movies for another user.",
            "You look at some other movies, and it turns out that if you dump the Hessian by a small by 1 / T factors, so you add a schedule to the Newton step.",
            "This all converges.",
            "And So what this is dressed is the fact that UV transpose visa transfers are the dominant costs.",
            "But instead of actually looking at all of the, we're just going to look at sub slices of it where we can control the size.",
            "You can look at as little as one V factor at a time.",
            "Yeah, instead of picking a random sample of movies, can you pick them from the ones that the user actually saw?",
            "Yes, so there's different ways and the way that we actually do it is we use the data weights.",
            "A combination of the data waits in the ratings to predict and that improves performance tremendously.",
            "I would think.",
            "So asymptotically it doesn't make a difference, but the theory for stochastic optimization is notoriously twitchy the convergence."
        ],
        [
            "Rates are very low.",
            "I would care more about that same product performance if I were immortal, yeah.",
            "OK, so just to emphasize with the step is will look at enough to Newton update for you where Q&Q prime or the gradient and Hessian with respect to a row of you let bar bar Q be the sample analogs for each one and so a stochastic Newton update is a regular Newton update where you replace the gradient in that room by the sample gradient in the sample henschen and you Additionally throw in this damping factor which we used to guarantee convergence.",
            "It's a submartingale analysis.",
            "It's kind of ugly.",
            "And you can show that as long as your estimate of the Hessian converges of the inverse of the Hessian converges overtime, then the overall optimization will converge as well, and the way we guarantee convergence of the Hessian is not just to look at the instantaneous action at each step, just to look at a hashing that we computed at time T but taken exponentially.",
            "Weighted moving average of the current estimate of the session with all of the past ones.",
            "And that's sufficient to guarantee that there is convergence of the inverse Hessian.",
            "How often do you have to re sample at each iteration?",
            "So we re sample.",
            "We grab a different sample at each iteration.",
            "I mean you can fix it.",
            "You can fix it for a few iterations for a finite number of iterations, it's just better to sample each time."
        ],
        [
            "And sampling isn't expensive.",
            "And so one of the problems here is we look OK, so we're looking at the training error of our three factor model on a relatively small example where the bottom line, the line which is reducing the loss most quickly, is the Newton optimization, and we look at three versions of Stochastic Newton where all we do is we vary the batch size.",
            "So the number of samples that we're picking, 100,000, two, 1000 and what you see is, you know, this looks really awful.",
            "The training error of the full Newton method is much much smaller than any of the stochastic Newton methods here.",
            "And it's not like each stochastic Newton iteration is super cheap, it's just a lot better than doing the full Newton step, and so we think OK, well, this is hopeless.",
            "The training error is so much worse for Stochastic Newton we shouldn't even try using it.",
            "So this is a full Newton step using all of the data.",
            "The lowest curve here where the Y axis is law is training error.",
            "So lower is better and more colors for this slide.",
            "Yeah, I know, sorry.",
            "And so each of the lines here corresponds to stochastic Newton with the batch size of 100.",
            "With the batch size of 1000 with the batch size of 2000.",
            "And so increasing the batch by a lot doesn't improve the training error by a whole lot, simply because."
        ],
        [
            "This one over the damping term, but you find that if you look at the test error for the reconstruction of X, and yes, I apologize for the lack of colors here.",
            "There isn't that much of a difference, so for the first iteration where the X axis CPU time, the stochastic methods are kind of terrible and this just corresponds to the notion of having a really bad Hessian estimate.",
            "But after that, since we have an action that converges overtime, you find that after, say, 80 seconds difference between each of the three methods is much smaller.",
            "I don't know if you can look at the bottom here, but this line here is the full Newton method, and these are the stochastic methods and they're all within.",
            "If you actually plot the error bars, they all overlap, so you have 20 seconds for iteration, more less.",
            "It's not 20 seconds per iteration.",
            "The iterations of the inflection points.",
            "But yeah, it's about.",
            "In this example is about 2030 seconds per duration.",
            "Yeah, I guess it's inflection points.",
            "OK, yeah, the inflection points, so the bottom curve is which one?",
            "The lowest curve here is the full Newton method, which is obviously going to be the best for a good model.",
            "Actually doing worse with bigger batch size.",
            "Yeah, so the problem with bigger batch sizes is with bigger batch sizes.",
            "You can take more aggressive action steps, but if the sample but the problem is that the cause of the power law distribution of rating data if your sample ends up picking up your sample is going to be biased towards the most frequent.",
            "In this case, the most frequently rated movies, which means that you're going to be overly confident that everything is a comedy and action movie or treacly drama, and you're not going to consider information about.",
            "Less frequent jamras of movies, for example.",
            "Which is why you get this weird inversion behavior between smaller batch sizes doing better than bigger batch sizes in the standard.",
            "In the ideal case it shouldn't be, but the power laws in the data it's good."
        ],
        [
            "Things up.",
            "OK, and so going back to this motivation.",
            "This is reconstructing the author of matrix using collective matrix factorization.",
            "You can use to cast a gradient to deal with the fact that you have a lot of entities here, and if you do this reconstruction, what?",
            "Why is this one of our Bregman losses?",
            "And what Alpha is with this Alpha factor that we showed in the three factor?",
            "This waiting in terms of the reconstruction of X versus Y?",
            "And so the takeaway story here.",
            "Broadly, from a relational perspective, is that by mixing information from multiple matrices according to this tide linear model, or the optimal mixing factors between point 7.8, you can do better than if you just did a collaborative filtering problem on the author matrix.",
            "Or if you did regression problem from words onto authorship prediction.",
            "And so that's there.",
            "The other big story is that if you're a little bit careful about the assumptions that you make, and thinking about the assumptions that you make in a matrix factorization.",
            "You can do a lot more than what people typically do in the literature, which is this small little gradient step.",
            "You can actually get a full Hessian step on a lot of very common cases, and you really should.",
            "It makes a huge difference, and on that point I'll take any questions that you have, thank you.",
            "Yes.",
            "What percent error or other pedestrian measure of error?",
            "This is the best .5%?",
            "You know this is.",
            "These experiments are pretty old, so I wouldn't hesitate.",
            "I don't exactly recall what it corresponds to under MC or MA, but the curve is similar.",
            "Sorry, I just don't remember what the numbers are for MA.",
            "Well now I'm just curious how how, how well can you do it.",
            "Reconstructed guessing.",
            "OK, so the reconstruction is.",
            "From what I recall on the full data set somewhere between 70 and 85% for all their predictions, which is and I mean for the full author matrix, just using all the ships like 60%.",
            "Yeah, you compare with the FPS optimization.",
            "Yeah, so the problem with the lobby FPS optimization is the Hessian is big, but you don't have to compute.",
            "Yeah, you can approximate it.",
            "We didn't actually compare to LBF's, which would be just optimizing over this non convex function.",
            "You could, I don't know what the results would be like.",
            "So on your previous slide, yeah."
        ],
        [
            "Can I see the previous slide?",
            "So it seems like you're doing better.",
            "For a given time, using the full Newton method.",
            "So what is what is this approximate stochastic thing?",
            "By you, the stochastic thing buys you that the computing the Hessian, so this is a small example.",
            "If you look at a bigger example where you have, say hundreds of thousands of users, you can't even compute one.",
            "You didn't learn the lines invert, and so you typically can't even compute 1 Newton iteration.",
            "This is just so I can show you all of the different methods.",
            "We used a small data set do to try and compensate for bias in your data.",
            "For bias in your data.",
            "In stochastic I'd adjust the sampling to reflect the sample by the inverse of the.",
            "Of the number of times that it's a curd, so just need to update the sampling for rare elements so it would be great to see that applied even to this size of the data set.",
            "Yeah, it would be interesting, OK, anything else?",
            "OK, thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Hi so this is joint work with Jeff Gordon, my advisor.",
                    "label": 0
                },
                {
                    "sent": "Hopefully the pace will be a little more tutorial like rather than throwing things at you.",
                    "label": 0
                },
                {
                    "sent": "If you have any questions of clarification, feel free to ask them during the presentation, but I'd ask the broader questions be left for the end.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I don't know if it's complication, but can you clarify whether it move this out?",
                    "label": 0
                },
                {
                    "sent": "Feel free to OK so the game that we have is the world consists of data which isn't just a single table of values, it's really generically relational and the simple simplest example of relational data that we deal with on a relatively frequent basis is a word is a document word matrix.",
                    "label": 0
                },
                {
                    "sent": "So for example, the way that I view word occurrence matrices, these sort of bag of word models is a relationship that a word occurs in the document.",
                    "label": 0
                },
                {
                    "sent": "And it's count value to just the value that occurs has is just the number of times that awards occur in this document.",
                    "label": 0
                },
                {
                    "sent": "So we can represent this relation as a matrix where the rows correspond to one entity type documents and where the columns correspond to the other entity type words and the value of this matrix corresponds to the value of this relation.",
                    "label": 0
                },
                {
                    "sent": "And there's no requirement that all of the values be filled in.",
                    "label": 0
                },
                {
                    "sent": "There's no requirement values be filled in, and there's no requirement that.",
                    "label": 0
                },
                {
                    "sent": "The values all be the same type.",
                    "label": 0
                },
                {
                    "sent": "So for example, we could stack together different types of relations where some of the entries are Gaussian, where some of the entries are points on whatever.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So a slightly more sophisticated example is a case where you have two types of data where you have word counts for documents and where you have some other side information.",
                    "label": 0
                },
                {
                    "sent": "In this case authorship of papers where we also represent the author of relation as a matrix and the theme of this presentation and our perspective of relational learning is that you have these different sources of information.",
                    "label": 0
                },
                {
                    "sent": "These different relations, each represented by a matrix.",
                    "label": 0
                },
                {
                    "sent": "And what we want to do is we want to combine information from these two relations in a way that allows us to predict better on each of them, and so in this case, what we're saying is that we want to use authorship information for documents or word information from these documents to help predict authorship in addition to using what we know about Co authorship already.",
                    "label": 0
                },
                {
                    "sent": "And so this model of relational data.",
                    "label": 1
                },
                {
                    "sent": "This view allows us to encompass common tasks like link prediction.",
                    "label": 0
                },
                {
                    "sent": "If you view a graph as a binary matrix, filling in values of that matrix corresponds to predicting links and link regression where you want to predict the value for a link.",
                    "label": 0
                },
                {
                    "sent": "So in this case the Word document matrix filling in a value, there would be a link regression.",
                    "label": 0
                },
                {
                    "sent": "We don't just want to know whether a word occurs, we want to know how many times it a curd.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, and so our motivation here is this example of reconstructing authorship.",
                    "label": 0
                },
                {
                    "sent": "So predicting authorship where we have authors for where we have authors for a set of documents an for the same documents, we also know what words occur in the abstract.",
                    "label": 0
                },
                {
                    "sent": "This is actually data from NIPS.",
                    "label": 0
                },
                {
                    "sent": "And so think of the why measure is loss so lower is better.",
                    "label": 0
                },
                {
                    "sent": "And think of Alpha is a mixing constant where at one all we're doing is we're just using the author of matrix to predict authorship.",
                    "label": 0
                },
                {
                    "sent": "We're not using any word information and at Alpha equals to zero.",
                    "label": 0
                },
                {
                    "sent": "We're only using words to predict authorship, and so without going into the details of what this loss actually means, the intuition here is that the minimum loss overall values of the mixing is somewhere between zero and one.",
                    "label": 0
                },
                {
                    "sent": "We don't just want to predict authorship using the authorship matrix and no word information.",
                    "label": 0
                },
                {
                    "sent": "But the same time, we don't want to predict authorship, just using words we want to mix the two sources of information and the way in which we do this mixing is.",
                    "label": 0
                },
                {
                    "sent": "The topic is really the scope of this talk.",
                    "label": 0
                },
                {
                    "sent": "Yeah, stupid one, but.",
                    "label": 0
                },
                {
                    "sent": "I didn't understand the right that you're using the author matrix to reconstruct the author of Matrix, so in that case it's really just.",
                    "label": 0
                },
                {
                    "sent": "So the way we're going to do it is you can build.",
                    "label": 0
                },
                {
                    "sent": "You can factorize each matrix and you can do the standard collaborative filtering tricks using coauthorship information to predict values that are missing from the matrix.",
                    "label": 0
                },
                {
                    "sent": "OK, so you're shrinking, yeah, OK. Alpha is this mixing term, so how much are we mixing information between authorship and Word document and the occurrence of words in these documents?",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We'll come back to that at the end of the talk and actually explain what all the terms mean.",
                    "label": 0
                },
                {
                    "sent": "I just wanted to give you this intuition that mixing helps.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "The building block of our models are going to be matrix factorization in the first half of this talk is going to cover largely this topic in fairly broad generality, so we're going to represent a binary relation as a matrix, like I mentioned on the 1st slide, and everything that we talk about generalizes to higher order relationships where the relation is in just over 2 entity types, but over three or more entity types.",
                    "label": 1
                },
                {
                    "sent": "In that case, instead of using a matrix, you're going to use a tensor, and once you choose a basis for tensor, all of the math generalizes.",
                    "label": 1
                },
                {
                    "sent": "So in the standard matrix factorization model, which is commonly referred to as SVD, you have a data matrix.",
                    "label": 0
                },
                {
                    "sent": "N by M and you're going to build a low rank representation of this matrix where you corresponds to the factors to the row factors and where V corresponds to the column vectors.",
                    "label": 0
                },
                {
                    "sent": "So in the Word document example, you are really word factors V or document factors, and these embed the these embed each of these entities into low dimensional spaces and hopefully there's some.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Reconstruction here.",
                    "label": 0
                },
                {
                    "sent": "So the key idea is that with a little bit of generalization, alot of algorithms are instances of matrix factorization and the broad approach that we're going to be taking even if you don't follow all of the individual points here is that the model, the standard matrix factorization model isn't a linear model, it's a bilinear model in the sense that if you fix you.",
                    "label": 1
                },
                {
                    "sent": "That really is just a linear regression from V onto the data, and if you fix V, it's a linear regression from you onto the data, and So what we're going to do is we're going to take a lot of what we know about linear models in linear regressions and generalize it to the case of these bilinear models these matrix factorizations.",
                    "label": 0
                },
                {
                    "sent": "OK, so what's the first generalization that we're going to make, yeah.",
                    "label": 0
                },
                {
                    "sent": "The version of.",
                    "label": 0
                },
                {
                    "sent": "Daniel Matrix entries are, yeah, so in standard STD there's this diagonal matrix which is positive definite and you can fold it into you.",
                    "label": 0
                },
                {
                    "sent": "You can fold it into V for most of this talk, we're just going to fold it into one of them and just ignore it.",
                    "label": 0
                },
                {
                    "sent": "But you can.",
                    "label": 0
                },
                {
                    "sent": "Deal with the case where you have this dog.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Sigma matrix.",
                    "label": 0
                },
                {
                    "sent": "OK, so the first generalization that we're going to take over the standard SVD type model is data weights, so this is just a constant non negative matrix where the entries of this W matrix wait.",
                    "label": 0
                },
                {
                    "sent": "The importance of each entry of the data matrix and so why is this useful?",
                    "label": 1
                },
                {
                    "sent": "So if your data matrix X has missing values, which are these greyed out squares?",
                    "label": 0
                },
                {
                    "sent": "Here you can zero them out in the weight, which effectively removes them from the data you have missing values.",
                    "label": 0
                },
                {
                    "sent": "If you have missing values in a matrix and you just compute zero, you're going to be treating that zero like a significant value.",
                    "label": 0
                },
                {
                    "sent": "Which in practice is not a good thing.",
                    "label": 0
                },
                {
                    "sent": "So for example, say you had a user user movie matrix is sort of Netflix ratings matrix.",
                    "label": 0
                },
                {
                    "sent": "Most of the entries are missing.",
                    "label": 0
                },
                {
                    "sent": "It isn't that a 0 means that a user didn't rate rated the movie 0 is that they never watched it or never rated it, and so you really want to pull out those values from the factorization.",
                    "label": 1
                },
                {
                    "sent": "And sometimes you care about focusing on certain pieces of the matrix, certain row, certain columns, certain blocks of the matrix, and you can do that here.",
                    "label": 0
                },
                {
                    "sent": "It's a fixed matrix, doesn't change.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Anything?",
                    "label": 0
                },
                {
                    "sent": "So the second generalization is, what if the prediction?",
                    "label": 1
                },
                {
                    "sent": "What if the relation between X and the parameters?",
                    "label": 1
                },
                {
                    "sent": "UV transpose is nonlinear?",
                    "label": 1
                },
                {
                    "sent": "So we're going to introduce this thing called a prediction link, which is just taking UV transpose and shoving it through prediction link, which is a convex elementwise function.",
                    "label": 0
                },
                {
                    "sent": "So, for example, here we're going to say that it's the exponential function, and so all you're going to do is, for each entry of UV transpose, you're going to take the exponential of it, and that's going to be your prediction for X.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So why do we want prediction links?",
                    "label": 0
                },
                {
                    "sent": "Well, this gives us the matrix version of a generalized linear model, which is saying instead of X being UV instead of a particular entry of X being a row of you times a row of V. We're going to say that it soroa viewer ohavi through some nonlinear transformation, which gives you a generalized linear model.",
                    "label": 0
                },
                {
                    "sent": "If you assume that F. Corresponds to an exponential family.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so actually some matrix function is a mapping from the matrix to matrix.",
                    "label": 1
                },
                {
                    "sent": "Yeah, it's an elementwise function.",
                    "label": 1
                },
                {
                    "sent": "So UV transpose is going to be the same size as X, and then just elementwise.",
                    "label": 0
                },
                {
                    "sent": "We're going to apply this function.",
                    "label": 0
                },
                {
                    "sent": "So convert this this elementary but convex.",
                    "label": 0
                },
                {
                    "sent": "In one sense it's convex in the sense that app is a univariate function with positive gradient.",
                    "label": 0
                },
                {
                    "sent": "So it doesn't have to be strictly convex, but it typically is, and so one of the nice things about generalized linear models is that allows you to encode some constraints in your output to respect certain properties of your data without making learning harder.",
                    "label": 1
                },
                {
                    "sent": "And so in this case, we assume that the link is the exponential function, which means that all of your predictions are going to be positive.",
                    "label": 0
                },
                {
                    "sent": "But yet the we're going to see that the optimization over the parameters UV transpose is going to be unconstrained.",
                    "label": 0
                },
                {
                    "sent": "So instead of having to represent the positivity constraint on your data in a linear regression by putting constraints on U&V transpose, which makes the optimization harder.",
                    "label": 0
                },
                {
                    "sent": "We're just going to shove it through a link function will see later on that you're not just inheriting a positivity constraint, you're inheriting a full distributional assumption and all that question.",
                    "label": 0
                },
                {
                    "sent": "So when you have ways that are not old ones, then the punch and is no longer comics.",
                    "label": 0
                },
                {
                    "sent": "So the entire objective I'll get to that point here, going ahead about five slides.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so the third generalization is the notion of a generalized order weighted loss, so I put this squiggly = between them in all of these diagrams, but I haven't really defined what that is.",
                    "label": 0
                },
                {
                    "sent": "What this measure of reconstruction error is between X and UV transpose?",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "We're going to say that in general, the matrix factorization can have any divergent.",
                    "label": 0
                },
                {
                    "sent": "You can pick it as long as you take the data weights into account, and some common examples that we can view as losses or weighted divergences, or squared loss where you just look at the weighted sum of squared errors.",
                    "label": 1
                },
                {
                    "sent": "KL divergences just a weighted version of KL Divergent, and there's lots of other choices.",
                    "label": 1
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so now we have this optimization problem where our model is X is equal to VTV transpose and what you need to do is you need to find the optimal factors U&V.",
                    "label": 0
                },
                {
                    "sent": "So we have a function which is typically convex in UV transpose but typically not convex in U&V.",
                    "label": 0
                },
                {
                    "sent": "To get to your question.",
                    "label": 0
                },
                {
                    "sent": "But there are other issues that we still have to consider about.",
                    "label": 0
                },
                {
                    "sent": "The model is still deficient in some way, So what about overfitting?",
                    "label": 1
                },
                {
                    "sent": "If we want that, yeah.",
                    "label": 0
                },
                {
                    "sent": "Send your objective function so X is observed matrix access the data, yes.",
                    "label": 0
                },
                {
                    "sent": "Then the words about become from the data weights.",
                    "label": 0
                },
                {
                    "sent": "These are the data weights that you fixed beforehand.",
                    "label": 0
                },
                {
                    "sent": "So you're not optimal.",
                    "label": 0
                },
                {
                    "sent": "Every cell in the matrix in some ways, yeah, and you can assume that they're all ones, which is what we often do.",
                    "label": 0
                },
                {
                    "sent": "You don't have to.",
                    "label": 0
                },
                {
                    "sent": "And FUV transpose.",
                    "label": 0
                },
                {
                    "sent": "Without any effort, so you just ignore that doesn't work.",
                    "label": 0
                },
                {
                    "sent": "You can ignore W if you want to, but for full generality we're going to include it in FUV.",
                    "label": 0
                },
                {
                    "sent": "Transpose is just this estimate of X where you are the parameters and so the model is still deficient in the sense that you can have overfitting.",
                    "label": 0
                },
                {
                    "sent": "There's a lot of parameters in the matrix factorization.",
                    "label": 0
                },
                {
                    "sent": "Moreover, what if we want to put some sort of constraints on U&V?",
                    "label": 0
                },
                {
                    "sent": "What if we have what we want you and me to be sparse?",
                    "label": 1
                },
                {
                    "sent": "What if we want to constrain our factorization to be done negative?",
                    "label": 0
                },
                {
                    "sent": "Going back to Lee and Ceilings, famous algorithm and we don't really know how hard the optimization is yet.",
                    "label": 0
                },
                {
                    "sent": "For a given choice of a divergent in a given choice of prediction link.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so regularization there's a lot of parameters for every entity, so going back to the first slide for every document for every word, for every author we have K parameters where K is this embedding dimension.",
                    "label": 1
                },
                {
                    "sent": "So you could overfit alot, which means that we're going to need to regularize the parameters.",
                    "label": 0
                },
                {
                    "sent": "And like in a regular model, you can take all of the LP norm regularizers where you say look, I have some regularizer over my parameters U&V I'm going to treat you and V is in dependently regularised.",
                    "label": 0
                },
                {
                    "sent": "And I can look at the L2 norm of U and the L2 norm of V. You can look at the L1.",
                    "label": 0
                },
                {
                    "sent": "You can look at any of the LP norms where the term that we have here is just looking at them individually.",
                    "label": 1
                },
                {
                    "sent": "You can encompass really all of the standard linear regression regularizers that you want.",
                    "label": 0
                },
                {
                    "sent": "But there are also ones which are unique to matrix factorization.",
                    "label": 0
                },
                {
                    "sent": "And one example here is a trace norm where you take U&V.",
                    "label": 0
                },
                {
                    "sent": "You take UV transpose.",
                    "label": 0
                },
                {
                    "sent": "You take that you take the sum of the singular values of UV transpose and we treat that as your regularizer.",
                    "label": 0
                },
                {
                    "sent": "So why would we want to take the trace norm?",
                    "label": 1
                },
                {
                    "sent": "Well, it's a continuous approximation for the rank that is the rank of UV transpose increases.",
                    "label": 0
                },
                {
                    "sent": "So it is a trace norm.",
                    "label": 0
                },
                {
                    "sent": "And what the trace norm allows you to do is it allows you to set K to be a very large value.",
                    "label": 0
                },
                {
                    "sent": "Arbitrarily, anything that an arbitrarily large value, whatever you want it to be, and to penalize the reconstructions based on the true rank of UV transpose.",
                    "label": 0
                },
                {
                    "sent": "Not just saying that the rank is, you know, in the worst case, K. Yes, yeah.",
                    "label": 0
                },
                {
                    "sent": "Above the trees move there already have well established concepts about the effective degree of freedom.",
                    "label": 0
                },
                {
                    "sent": "Then the based on a single single values or some single single single values of the original matrix.",
                    "label": 0
                },
                {
                    "sent": "How this is?",
                    "label": 0
                },
                {
                    "sent": "Truncated version approximately.",
                    "label": 0
                },
                {
                    "sent": "When you do the SVD again, how does it related to that kind of?",
                    "label": 1
                },
                {
                    "sent": "So it depends a lot on the divergent.",
                    "label": 0
                },
                {
                    "sent": "It depends a lot on the prediction link, but what we can say is that as K approaches the minimum of Eminem, the data dimensions of your matrix, the.",
                    "label": 0
                },
                {
                    "sent": "L2 regularizer is going to approach the trace norm.",
                    "label": 0
                },
                {
                    "sent": "I mean there is no general statement that you can make about the relation between the trace between the rank of UV transpose in the rank of the data because we haven't talked we haven't fixed D. The standard definition of effective degrees of freedom, disrespect SVD for the original matrix.",
                    "label": 0
                },
                {
                    "sent": "Probably a question better dealt with at the end of the presentation rather than now.",
                    "label": 0
                },
                {
                    "sent": "Kind of tangential, so the optimization now is that you have these parameters U&V.",
                    "label": 0
                },
                {
                    "sent": "We have a reconstruction error.",
                    "label": 0
                },
                {
                    "sent": "We haven't specified what that is yet, so it's hard to make specific statements about it, and we have this regularising term.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so you can also have hard constraints and so thus far we haven't really said anything about U&V in our optimization.",
                    "label": 1
                },
                {
                    "sent": "We've assumed that you and V. Can really exist anywhere in the real set, but in a lot about to encompass a lot of different algorithms into our matrix factorization framework.",
                    "label": 0
                },
                {
                    "sent": "You need to consider constraints for the factors like orthonormality, which is just saying that each that the rows of you are perpendicular and the norm of each row view is 1.",
                    "label": 0
                },
                {
                    "sent": "The clustering constraint says that each row of you is a probability distribution.",
                    "label": 0
                },
                {
                    "sent": "You can also do a clustering constraint on V, saying that each row of Y is a probability distribution.",
                    "label": 1
                },
                {
                    "sent": "Nonnegativity says the factors are non negative.",
                    "label": 0
                },
                {
                    "sent": "The entries are non negative and you can put hard sparsity constraints which differs from L1 and that we're putting a cardinality constraint saying that at most P entries in any row of you or any row AV.",
                    "label": 0
                },
                {
                    "sent": "Are non 0.",
                    "label": 0
                },
                {
                    "sent": "And so typically the hard constraints, with the exception of Orthonormality lead to a constrained optimization.",
                    "label": 1
                },
                {
                    "sent": "But now our generic optimization problem includes these.",
                    "label": 0
                },
                {
                    "sent": "These constraints on U&V.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so we have all of this notation now.",
                    "label": 0
                },
                {
                    "sent": "How does this help us describe things, but we'll take 2 examples.",
                    "label": 0
                },
                {
                    "sent": "The 1st way to singular value Decomposition's and 2nd that latent semantic indexing or probabilistic latent semantic indexing?",
                    "label": 0
                },
                {
                    "sent": "And we're going to talk about how we can fit them into our framework.",
                    "label": 0
                },
                {
                    "sent": "So awaited singular value decomposition is the case where you want to reconstruct a matrix under squared loss.",
                    "label": 1
                },
                {
                    "sent": "You have data weights typically because you want to zero out missing values.",
                    "label": 0
                },
                {
                    "sent": "And So what you want to do is we have our prediction link F is going to be the identity function, X is equal to UV transpose.",
                    "label": 1
                },
                {
                    "sent": "The divergences squared loss and the hard constraints are that we constrain V to be orthogonal and U transpose U as diagonal.",
                    "label": 0
                },
                {
                    "sent": "You can include a regularizer by basically bounding the entries on the diagonal of U transpose you.",
                    "label": 0
                },
                {
                    "sent": "He said that X is.",
                    "label": 0
                },
                {
                    "sent": "So yeah, I'm sorry XX it another step.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so this is our data.",
                    "label": 0
                },
                {
                    "sent": "This is our estimate X hat.",
                    "label": 0
                },
                {
                    "sent": "Think of FUV transpose is X hat.",
                    "label": 0
                },
                {
                    "sent": "OK. You did not include the transpose.",
                    "label": 0
                },
                {
                    "sent": "We would be basically so in the weighted case if you there isn't always a solution when they are both orthogonal.",
                    "label": 0
                },
                {
                    "sent": "Or orthonormal here, we're saying that the rows of you are perpendicular because its diagonal matrix, but we're not constraining the norm of each row of you to be.",
                    "label": 0
                },
                {
                    "sent": "1.",
                    "label": 0
                },
                {
                    "sent": "It's only reason cousin that it's to ensure that there's always a solution.",
                    "label": 0
                },
                {
                    "sent": "So there are cases in the weighted case where you know if you transpose U is constrained to be the identity matrix, then the optimization the constraints are infeasible for certain objectives for certain.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Use of the weights.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So the second example is probabilistic latent semantic indexing, and this is a technique for word and document clustering.",
                    "label": 1
                },
                {
                    "sent": "So we've moved away from the prediction case where we just want to pick the values of X, and we're going to talk about something which is very different from what you typically view as an SVD.",
                    "label": 0
                },
                {
                    "sent": "And So what you do is you have a document word matrix.",
                    "label": 0
                },
                {
                    "sent": "And we're going to introduce well, so we're going to introduce K latent factors in the latent factors in the matrix factorization.",
                    "label": 0
                },
                {
                    "sent": "Refer to as topics or aspects and PLSI.",
                    "label": 0
                },
                {
                    "sent": "And what you're going to say is that the probability of a document Anna word corresponds to the probability of a document given a latent factor times the probability of a word given the latent factor times the prior over these latent factors integrated over your latents.",
                    "label": 0
                },
                {
                    "sent": "And so, one way of fitting this into our matrix factorization framework is by looking at the log likelihood by looking at the probabilities of documents and words, which is this matrix on the left hand side.",
                    "label": 0
                },
                {
                    "sent": "We're not going to deal with the data matrix here, because P LSI doesn't generate predictions it generates clusterings it can generate can be viewed as a matrix factorization of X.",
                    "label": 0
                },
                {
                    "sent": "It can be viewed as a matrix factorization of the likelihood.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Should not be publisher Z given document.",
                    "label": 0
                },
                {
                    "sent": "0 sum to one.",
                    "label": 0
                },
                {
                    "sent": "Z given documents, let's see.",
                    "label": 0
                },
                {
                    "sent": "No documents given latents so latents are the case.",
                    "label": 0
                },
                {
                    "sent": "Each lawyer document.",
                    "label": 0
                },
                {
                    "sent": "Yeah, in you.",
                    "label": 0
                },
                {
                    "sent": "No, yeah, OK, so the probability this Red Square should be.",
                    "label": 0
                },
                {
                    "sent": "Transpose to get a probability distribution.",
                    "label": 0
                },
                {
                    "sent": "We're just looking at the probability of document two given to latent factors here.",
                    "label": 0
                },
                {
                    "sent": "So we're not saying that comes to one.",
                    "label": 0
                },
                {
                    "sent": "We're saying that the columns of you sum to one.",
                    "label": 0
                },
                {
                    "sent": "Thanks.",
                    "label": 0
                },
                {
                    "sent": "We have S, which goes back to the original question about SVD being this diagonal matrix which corresponds to the topic priors and V transpose being the probabilities of words given each of the latent topics.",
                    "label": 0
                },
                {
                    "sent": "And so in the key point here is to note that we're not factorizing X were factorizing the probability of documents and words were factorizing the likelihood of the data.",
                    "label": 1
                },
                {
                    "sent": "And so one thing we can do is we can fold the topic prior matrix S into UV.",
                    "label": 0
                },
                {
                    "sent": "Yeah question about the topic parametric.",
                    "label": 0
                },
                {
                    "sent": "Yeah I thought the point of LSA was too identified, like latent topics, so I'm trying to figure out if you don't know what the topics are ahead of time.",
                    "label": 0
                },
                {
                    "sent": "The only meaningful things I can put in think of to put in the S is either just have it be the identity matrix or since this principle components just say well, there's going to be the primary component waiting that way.",
                    "label": 0
                },
                {
                    "sent": "Can you give us some intuition for where is this coming from?",
                    "label": 0
                },
                {
                    "sent": "Yeah, OK so.",
                    "label": 0
                },
                {
                    "sent": "You have your like, so when you have this joint probability of the documents in the words and, they actually do the factorization over US&V transpose.",
                    "label": 0
                },
                {
                    "sent": "So you start with some random some random ass matrix and in the standard way of doing PLSS you do EM over this model where when you do the updates you get iterative updates of your topics of the distribute.",
                    "label": 0
                },
                {
                    "sent": "You get iterative updates of the probability of each of your latents each of your topic.",
                    "label": 0
                },
                {
                    "sent": "So overall you're trying to solve for S but you start with initial estimate.",
                    "label": 0
                },
                {
                    "sent": "Well NPL's eye.",
                    "label": 0
                },
                {
                    "sent": "Often what you display is.",
                    "label": 0
                },
                {
                    "sent": "Your results are the topics and the weights of the topics, but when you're actually doing predictions.",
                    "label": 0
                },
                {
                    "sent": "You do want to look at how well each document participates in each topic.",
                    "label": 0
                },
                {
                    "sent": "So how close so how much does each document belong to each particular topic which corresponds to row or column of you, depending how you view it, yeah?",
                    "label": 0
                },
                {
                    "sent": "Nation point when you say topic for our market matrix X, but I think the latent semantic indexing.",
                    "label": 0
                },
                {
                    "sent": "They just consider a prior prior is vector of topics.",
                    "label": 0
                },
                {
                    "sent": "You know the current property.",
                    "label": 0
                },
                {
                    "sent": "It's a diagonal matrix.",
                    "label": 0
                },
                {
                    "sent": "Sorry, you can't see the zeros.",
                    "label": 0
                },
                {
                    "sent": "I know, but this is.",
                    "label": 0
                },
                {
                    "sent": "Standard as he indicated, but it's against the concept of a probability Ellis other side.",
                    "label": 0
                },
                {
                    "sent": "We cannot think of areas of matrix there prior.",
                    "label": 0
                },
                {
                    "sent": "Often work well.",
                    "label": 0
                },
                {
                    "sent": "Probability one.",
                    "label": 0
                },
                {
                    "sent": "If you go back to house one if you go back to how often presents it.",
                    "label": 0
                },
                {
                    "sent": "This is P dot presented as the relationship between the log likelihood in the SVD 2.",
                    "label": 0
                },
                {
                    "sent": "If you multiply it out, you get exactly the formulation that you're mentioning that you have.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Vector of topics.",
                    "label": 0
                },
                {
                    "sent": "OK, so we can fold ineson to you here.",
                    "label": 0
                },
                {
                    "sent": "Which is just a convenient to fit into our notation, and so the game is.",
                    "label": 0
                },
                {
                    "sent": "You have this like this, probability.",
                    "label": 0
                },
                {
                    "sent": "You have factors U&V and you want to fit you in V by maximum likelihood where you have these hard constraints that you is a matrix is really a probability, entire matrix is a probability distribution and that the entries of UAV or probabilities.",
                    "label": 1
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so you have this.",
                    "label": 0
                },
                {
                    "sent": "You can view this as a loss function so you can view this in our standard framework where the prediction link is the identity.",
                    "label": 1
                },
                {
                    "sent": "Because U&V are probabilities Anna responses.",
                    "label": 0
                },
                {
                    "sent": "These likelihoods are also probabilities, so you don't need to do anything fancy with the link.",
                    "label": 0
                },
                {
                    "sent": "The loss is KL Divergent and this is a constrained optimization, typically solved using M, which is a major isation algorithm, but there's no reason why you can't do it using any of the other styles of solvers like grade like direct gradient descent or alternating Mac.",
                    "label": 1
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Imitation.",
                    "label": 0
                },
                {
                    "sent": "OK, so we have this overview of matrix of matrix factorization as a unified framework.",
                    "label": 1
                },
                {
                    "sent": "We're going to segue into a particular class of divergences because in the previous slide that didn't really mention where the divergent D and where the prediction link ever coming from, and that they're going to come out of Bregman divergences which are motivated by exponential families.",
                    "label": 1
                },
                {
                    "sent": "And finally, we'll get to the relational models.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so a Bregman divergences?",
                    "label": 0
                },
                {
                    "sent": "Just imagine that you have to observe two observations in the reels.",
                    "label": 0
                },
                {
                    "sent": "We're not dealing with matrices right now.",
                    "label": 0
                },
                {
                    "sent": "Bregman divergences with respect to a close differentiable convex function.",
                    "label": 1
                },
                {
                    "sent": "F is the formula on the screen.",
                    "label": 0
                },
                {
                    "sent": "And if you squinted the equation for a moment, you can plot this transfer function F, and you can think about the relationship between F of X&F of Y plus the gradient of FY X -- Y.",
                    "label": 0
                },
                {
                    "sent": "That's really the first term in the Taylor expansion.",
                    "label": 0
                },
                {
                    "sent": "Of F of Y centered of F of X centered at Y.",
                    "label": 0
                },
                {
                    "sent": "And so the Bregman divergences can be thought of is really the tail of a Taylor expansion, or the residual amount.",
                    "label": 0
                },
                {
                    "sent": "And so if you change the definition of F, you're going to change the definition of the divergent or the distance.",
                    "label": 0
                },
                {
                    "sent": "And the reason we deal with Bregman divergences, we can encompass a lot of different a lot of distinct notions of distances or loss measures like KL divergent, squared loss, Itakura Saito I divergent into a single framework.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so the reason we're dealing one class of distributions which we really care about that are fully encompassed by Bregman divergences or regular exponential families, and these encompass all of the standard distributions that you work with, like Gaussians like Pasoan like Pino Meals, Bernoulli's exponentials, whatever.",
                    "label": 0
                },
                {
                    "sent": "The standard distributions in a textbook, like a cell emerger.",
                    "label": 0
                },
                {
                    "sent": "So a regular exponential family is just a family of distributions with natural parameters, Theta particular form for the log likelihood, where the term that we care about is F of Theta, which is the log partition function that uniquely identifies the family.",
                    "label": 1
                },
                {
                    "sent": "So if you look at the form of F you can know the Gaussians.",
                    "label": 0
                },
                {
                    "sent": "All have a particular form for F, the paulsons all over particular form for, etc.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "But and so if you look at the log partition function for F, you uniquely identify a regular exponential family.",
                    "label": 0
                },
                {
                    "sent": "So for example, the first F corresponds to Gaussians, this next one plus all the next one Bernoulli but log partition functions are all convex.",
                    "label": 0
                },
                {
                    "sent": "In fact, they're strongly convex, so we could plug this F back into our earlier definition of a Bregman divergences, and if you do that, you find that look for this particular log partition function.",
                    "label": 1
                },
                {
                    "sent": "We get squared loss if you apply the log partition function for Apostle.",
                    "label": 0
                },
                {
                    "sent": "You get I divergents and if you apply the log partition function for a Bernoulli you get log loss and this is where you get a lot of standard statements that you'll see in intro machine learning where minimizing squared loss corresponds to maximizing the likelihood of a Gaussian distribution where minimizing log loss corresponds to fitting a Bernoulli distribution.",
                    "label": 0
                },
                {
                    "sent": "This is a general statement about regular Bregman divergences and regular.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Potential families so one thing that we need to actually fully formalize this definition of the relation between the two is the notion of duality.",
                    "label": 0
                },
                {
                    "sent": "So the log partition function uniquely identifies a regular exponential family.",
                    "label": 1
                },
                {
                    "sent": "But we can also uniquely identify a particular family by its convex conjugate.",
                    "label": 1
                },
                {
                    "sent": "Where we refer to MU is the expectation parameter, so theater here will refer to as a natural parameters of the exponential family.",
                    "label": 0
                },
                {
                    "sent": "But you can also.",
                    "label": 0
                },
                {
                    "sent": "Compute you can also identify the family and identify divergences in terms of the expectation parameters, which means the expectation parameters.",
                    "label": 0
                },
                {
                    "sent": "You can think of is predictions, which means all of our divergences can be done on the parameters of our model or on the predictions made by the model.",
                    "label": 0
                },
                {
                    "sent": "Depending on whether you do it in the natural parameter space or in the dual spaces.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Spectation space.",
                    "label": 0
                },
                {
                    "sent": "OK, so the formal statement of the theorem is that the log likelihood corresponds to these first 2 terms, which don't vary with data, so the log of the base measure plus this convex conjugate with respect to X -- a Bregman divergences were the Bregman divergences defined by this dual.",
                    "label": 0
                },
                {
                    "sent": "And where, importantly, the prediction link this F that we talked about earlier in matrix factorization corresponds to the gradient of the log partition function.",
                    "label": 0
                },
                {
                    "sent": "So in general, if you want to maximize the left hand side, you want to minimize the Bregman divergent on the right hand side.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And so we have a bunch of quantities available.",
                    "label": 0
                },
                {
                    "sent": "We have an exponential family.",
                    "label": 1
                },
                {
                    "sent": "We have log partition functions.",
                    "label": 1
                },
                {
                    "sent": "We have prediction links and we have Bregman divergences.",
                    "label": 0
                },
                {
                    "sent": "And because of this relationship between Bregman divergences and exponential families, picking any one of these corresponds to picking the rest of them.",
                    "label": 1
                },
                {
                    "sent": "It gives you a choice for the rest of them.",
                    "label": 1
                },
                {
                    "sent": "So if I say that my data is Gaussian distributed, it immediately tells me that the matching prediction link should be the identity link.",
                    "label": 0
                },
                {
                    "sent": "If I assume that my data is passam distributed, it's going to give me a prediction link, which is going to correspond to the exponential function.",
                    "label": 0
                },
                {
                    "sent": "And you're also going to get the corresponding Bregman divergences, and if you follow this formulation, what you're going to get is a problem which is convex, which is generally convex with respect to the first parameter of the vergence.",
                    "label": 0
                },
                {
                    "sent": "Is there a simple answer of what to do if it's?",
                    "label": 0
                },
                {
                    "sent": "If it is it?",
                    "label": 0
                },
                {
                    "sent": "No, I don't think that there's any exponential family.",
                    "label": 0
                },
                {
                    "sent": "That correspond to zip.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Or at least a regular one.",
                    "label": 0
                },
                {
                    "sent": "The same problem happens with Laplace.",
                    "label": 0
                },
                {
                    "sent": "It's not regular exponential, so you can't fit into this framework.",
                    "label": 0
                },
                {
                    "sent": "OK, so back to matrix factorization were given a matrix and the way we want to view it as to say that this matrix is a collection of samples which are drawn from an exponential family.",
                    "label": 1
                },
                {
                    "sent": "So let's just say Gaussian or plus or whatever where the single natural parameter is.",
                    "label": 0
                },
                {
                    "sent": "An entry of UV transpose and so in this diagram one entry of X corresponds to a draw from, let's say, a person distribution.",
                    "label": 0
                },
                {
                    "sent": "Here with the natural parameters.",
                    "label": 0
                },
                {
                    "sent": "Correspond to multiplying a row of Ian Row of Iubire OV and using that as your natural parameter, which is exactly equivalent to saying that X is approximately equal to UV transpose under some prediction link.",
                    "label": 0
                },
                {
                    "sent": "And just to incorporate weights back into the whole thing, we can look at weighted log likelihoods and so you can also look at weighted Bregman divergences.",
                    "label": 0
                },
                {
                    "sent": "The bottom of the slide where you just.",
                    "label": 0
                },
                {
                    "sent": "Look at each entry of the matrix you correspond to Bregman Divergent on that single entry, and you waited appropriately.",
                    "label": 0
                },
                {
                    "sent": "Nothing fancy, it's just.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Decomposability assumption.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So relational models is collective matrix factorization.",
                    "label": 1
                },
                {
                    "sent": "OK, so to simplify our notation, we can deal with any number of matrices in any sort of schema between binary relations.",
                    "label": 0
                },
                {
                    "sent": "But to simplify the notation a lot so that it fits on one slide, we're going to look at the three entity type case where you have two matrices X&Y.",
                    "label": 1
                },
                {
                    "sent": "Share dimension, so in this case you have users and movies you can think of this as a ratings matrix.",
                    "label": 0
                },
                {
                    "sent": "You can think of why the binary matrix of genres where one corresponds to saying that a movie has that genre.",
                    "label": 0
                },
                {
                    "sent": "And the key point here is that they share dimension.",
                    "label": 0
                },
                {
                    "sent": "The movie Dimension is shared by X&Y and that's how we're going to transfer information about ratings, two genres and from genres to ratings.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we could factor the matrices independently under everything that we said about individual matrix factorizations.",
                    "label": 0
                },
                {
                    "sent": "You get these two independent optimizations, but that's kind of silly given that our whole motivation is to share information.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Between two matrices to be collected in our factorization.",
                    "label": 0
                },
                {
                    "sent": "And so to share information between the related matrices, we're going to tie the movie factors together.",
                    "label": 1
                },
                {
                    "sent": "If matrices shared dimension, we're going to tie their corresponding factor together in the model, and we're going to tie together the loss where I've dropped the regularising terms just for simplicity, and I've added this weighting factor Alpha, which is just a measure of how much we care about reconstructing one matrix over the other.",
                    "label": 0
                },
                {
                    "sent": "So the higher Alpha is, the more we care about reconstructing X in our problem.",
                    "label": 0
                },
                {
                    "sent": "And the less we care about reconstructing Y.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK. And so how do we solve this?",
                    "label": 0
                },
                {
                    "sent": "Because I've given you a lot of models, but not a way of actually approaching it in.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "General, this optimization is going to be nonconvex and UV instead, but it turns out that cause we've picked break.",
                    "label": 0
                },
                {
                    "sent": "If we assume that all of the divergences are Bregman divergences in the prediction links or the matching prediction links.",
                    "label": 0
                },
                {
                    "sent": "If you fix all but one of the factors, so say you fix U&V and then you optimize Ed, that individual optimization is a convex problem.",
                    "label": 0
                },
                {
                    "sent": "And that's entirely a consequence of matching losses and links.",
                    "label": 0
                },
                {
                    "sent": "Which goes back to gaming's earlier question.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "And So what we're going to do is alternating projections, which is just a generic way of solving a non convex function.",
                    "label": 0
                },
                {
                    "sent": "It's block coordinate descent.",
                    "label": 0
                },
                {
                    "sent": "We're going to fix all but one of the factors, so fix Viens Ed leave you free and then optimize with respect to you.",
                    "label": 1
                },
                {
                    "sent": "Once you do that, you fix you and said you optimize with respect to V. You fix, you envy, you optimize with respect to Z, and if you alternate, you're going to converge to a local Optima.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now this still leaves, yeah.",
                    "label": 0
                },
                {
                    "sent": "And the UNLV from one single data matrix collection, right?",
                    "label": 0
                },
                {
                    "sent": "So that's a decomposition of a derived from one matrix and well worth it is easy.",
                    "label": 0
                },
                {
                    "sent": "So you said that you have two source of data.",
                    "label": 0
                },
                {
                    "sent": "Yeah, I just want to understand.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so we have two sources of data X&Y from X.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here's the UNLV, Yep.",
                    "label": 0
                },
                {
                    "sent": "Why what you do so from we're going to factorize why?",
                    "label": 0
                },
                {
                    "sent": "According to VSAT transpose it should be tilled be in this part but so yeah he is a shared via the shared factor so.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here in this example you corresponds to the user factors.",
                    "label": 0
                },
                {
                    "sent": "V corresponds to the movie factors and we see movies in both matrices, and zed corresponds to genre factors.",
                    "label": 0
                },
                {
                    "sent": "And by tying the movie factors together in this concrete example, we're going to allow information sharing between X and.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Why?",
                    "label": 0
                },
                {
                    "sent": "Because we're not just going to factorize X independently and then Y independently, we're going to factor them in a way by saying that you know you share these parameters V. So there's going to be some both X&Y are going to influence the update for V.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So this is a nonconvex problem and we've reduced it down to a series of convex optimizations, but we still haven't said how you're going to optimize that convex function.",
                    "label": 0
                },
                {
                    "sent": "And so one way of doing it, there's lots.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Different ways of doing it, but the simplest way is to just compute the gradient of the loss with respect to you when you're updating with respect to you with respect to V and with respect to Z.",
                    "label": 0
                },
                {
                    "sent": "Since these are individual one factor optimizations, and if you munch through the algebra you get these terms and So what you can see is that you and zed aren't tide factors, so they only involve this one term.",
                    "label": 0
                },
                {
                    "sent": "They only involve looking at the residuals of UV transpose compared to the data X.",
                    "label": 0
                },
                {
                    "sent": "If you look at said it's the same thing you're looking at, the residuals of the prediction of Y between Y.",
                    "label": 0
                },
                {
                    "sent": "But since V is a tide factor is shared between the two problems, you can see that the gradient is going to involve looking at the reconstruction, the gradient of with respect to the X matrix and the gradient with respect to the Y matrix, and that's where you're going to get the information tying in the optimization.",
                    "label": 0
                },
                {
                    "sent": "And so the cost of the gradients is going to be dominated by computing residuals.",
                    "label": 1
                },
                {
                    "sent": "Really computing UV transpose is expensive.",
                    "label": 0
                },
                {
                    "sent": "Computing visa transposes expensive because in general these are going to be dense matrices.",
                    "label": 0
                },
                {
                    "sent": "We haven't made any assumption about sparsity, nonnegativity, etc and so.",
                    "label": 0
                },
                {
                    "sent": "In practice these gradients well gradients are typically the cheapest way of optimizing a function.",
                    "label": 1
                },
                {
                    "sent": "It's still going to be proportional to the size, the cost of computing gradient is going to be proportional to the sum of the sizes of all of the matrices.",
                    "label": 0
                },
                {
                    "sent": "Which is a problem if your matrices are big.",
                    "label": 0
                },
                {
                    "sent": "So if you have a lot of documents, if you have a lot of if you have a lot of users.",
                    "label": 0
                },
                {
                    "sent": "If you have a lot of movies.",
                    "label": 0
                },
                {
                    "sent": "If you have a lot of genres.",
                    "label": 0
                },
                {
                    "sent": "You kind of host in that case, yeah?",
                    "label": 0
                },
                {
                    "sent": "I understand you correctly, so the FMF someone you said you mentioned.",
                    "label": 0
                },
                {
                    "sent": "Other reduction for the UV matrix, no F sub one is a prediction link, so we're going to say that X is equal to is approximately equal to F1 UV transpose and we're going to say that.",
                    "label": 0
                },
                {
                    "sent": "Why is approximately its reconstruction is visa transpose under the prediction link F2?",
                    "label": 0
                },
                {
                    "sent": "Yeah, I'm trying to understand concepts.",
                    "label": 0
                },
                {
                    "sent": "Early reconstruction is a title.",
                    "label": 0
                },
                {
                    "sent": "Reconstructed the data under imagining produced record space, so the efforts of one is reduced to one subspace, an effort to reduce the second subspace, and so you don't really.",
                    "label": 0
                },
                {
                    "sent": "So you do the.",
                    "label": 0
                },
                {
                    "sent": "Use the reducer factor user pairwise.",
                    "label": 0
                },
                {
                    "sent": "The variables provide metrics and for another matrix, but we did not really, so this is a design choice.",
                    "label": 0
                },
                {
                    "sent": "I'm just want understand another alternative possibilities.",
                    "label": 0
                },
                {
                    "sent": "Design choices reduce.",
                    "label": 0
                },
                {
                    "sent": "A subspace is important.",
                    "label": 0
                },
                {
                    "sent": "All three types of variables so, but I guess if you choose the pairwise.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so I think it means question.",
                    "label": 0
                },
                {
                    "sent": "Is it an alternate formulation?",
                    "label": 0
                },
                {
                    "sent": "So we tide the shared dimensions in the matrices together.",
                    "label": 0
                },
                {
                    "sent": "There's lots of different ways you can conceptually share information between X&Y.",
                    "label": 0
                },
                {
                    "sent": "And so one example would be to create a shared shared a unified space for both of the data matrices and then to factor them in that unified space, which would be something completely different from what we're talking about.",
                    "label": 0
                },
                {
                    "sent": "What a Bayesian would say is that you don't type parameters directly together, that's very untrustworthy.",
                    "label": 0
                },
                {
                    "sent": "You want to you want to put prior on all your parameters, and then a hyper prior and then tie them somewhere up there.",
                    "label": 0
                },
                {
                    "sent": "There's different ways of basically sharing information you can draw this out as a graphical model.",
                    "label": 0
                },
                {
                    "sent": "You can draw the Bayesian version of graphical model.",
                    "label": 0
                },
                {
                    "sent": "You can draw the example that you gave me out.",
                    "label": 0
                },
                {
                    "sent": "And they're all going to be different forms of information sharing.",
                    "label": 0
                },
                {
                    "sent": "They're all interesting, but the one that we're going to be concerned about here is a specific case, but you're right, there are other choices.",
                    "label": 0
                },
                {
                    "sent": "OK, so the problem with the gradient step is that when you do this in an alternating maximization, computing the gradient every time you want to take a gradient step, you have to.",
                    "label": 0
                },
                {
                    "sent": "Reconstruct what is typically a very large matrix, and what happens is that the steps that you're taking typically are very small.",
                    "label": 0
                },
                {
                    "sent": "And so you can let this run for days and you won't make any progress.",
                    "label": 0
                },
                {
                    "sent": "Yes, how do you know?",
                    "label": 0
                },
                {
                    "sent": "Could you wait?",
                    "label": 0
                },
                {
                    "sent": "It will compute the Hessian there, so in the Newton step we're going to have to get the learning rate.",
                    "label": 0
                },
                {
                    "sent": "Here we say that how we compute the learning rate is up to you.",
                    "label": 0
                },
                {
                    "sent": "We use a one over root T schedule, so one over the number of vacation schedule you can use other things for any sufficiently small edits going to converge as long as you pick some schedule, it doesn't really matter for performance, they're all terrible.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so we need a better way of actually solving each of these optimizations and what we're going to show is that even though we have a lot of parameters in our model, the Newton step is actually practical because of the assumptions that we've made and which are the assumptions that everybody who does matrix factorization makes without actually knowing it.",
                    "label": 0
                },
                {
                    "sent": "Sierra hypothetical Newton update.",
                    "label": 0
                },
                {
                    "sent": "For you, the number of parameters and you is N * K where N is the number of entities.",
                    "label": 0
                },
                {
                    "sent": "So in this case the number of users and or K is your embedding dimension, so you're hashing would be N K * N K. So is the number of users increases.",
                    "label": 0
                },
                {
                    "sent": "The hashing gets larger and larger and since we hope to have more than like 5 users in our model.",
                    "label": 0
                },
                {
                    "sent": "Inverting the hash and is going to be utterly impossible because you have to invert the Hessian to get a Newton step, and let's cubic in the size of the linear sit in NK.",
                    "label": 0
                },
                {
                    "sent": "But because we've assumed that the losses decomposable, the Hessian is block diagonal, it has a special structure where most of the matrix is zero except for these diagonal blocks, and each of these diagonal blocks corresponds to the Hessian for a particular row of U and the same intuition applies to V&Z that while the Hessians are huge, there all blocked diagonal where the blocks correspond to a row of Ian said respective correspond, with each block corresponds to a row V into a row of Z respectively.",
                    "label": 1
                },
                {
                    "sent": "And so you see again.",
                    "label": 0
                },
                {
                    "sent": "Because the constraints that you put in you so because we assume that the loss is decomposable, so we assumed that.",
                    "label": 0
                },
                {
                    "sent": "The reconstruction isn't that the reconstruction for a particular row of X doesn't depend on all of the factors of V on all of you and all of it depends on a particular row of you in a particular Rd V. So yeah.",
                    "label": 0
                },
                {
                    "sent": "But for now.",
                    "label": 0
                },
                {
                    "sent": "Yeah well, this is.",
                    "label": 0
                },
                {
                    "sent": "If you constrain, well, no, this isn't if we've constrained it.",
                    "label": 0
                },
                {
                    "sent": "What we've assumed is that in our reconstruction, XIJ is equal to UI to a row of U times a row V. Times are OV transpose.",
                    "label": 0
                },
                {
                    "sent": "We didn't say that it's a row of U times all of V under some arbitrary non elementwise transformation.",
                    "label": 0
                },
                {
                    "sent": "So this goes back to the idea of saying that our Bregman divergences separable, that we can evaluate it over each element of the matrix independently.",
                    "label": 0
                },
                {
                    "sent": "If you didn't have that, if you had a Bregman divergent which was a function of the entire matrix, like, say for example, the log determinant versions on matrices, this trick doesn't work.",
                    "label": 0
                },
                {
                    "sent": "The Hessian would be dense.",
                    "label": 0
                },
                {
                    "sent": "I can answer the question more detail.",
                    "label": 0
                },
                {
                    "sent": "Basically, if you cannot handle the full which goes back, there was yeah, so the separability assumption, like I mentioned in an earlier slide, is the Matrix version of Idleness in the sense that if your matrices are all vectors, it really.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Is just tidiness.",
                    "label": 0
                },
                {
                    "sent": "So because of this block structure, we can compute the Hessian.",
                    "label": 0
                },
                {
                    "sent": "We can do an update on each row of you.",
                    "label": 0
                },
                {
                    "sent": "Each row of each row of zed independently, where the Hessians have a relatively compact form.",
                    "label": 0
                },
                {
                    "sent": "If you munch through the algebra and again, what you'll see is that with respect to you and said you're only looking at the Hessian with respect to the matrices with respect to X&Y respectively.",
                    "label": 0
                },
                {
                    "sent": "But Becausw, why is tide?",
                    "label": 0
                },
                {
                    "sent": "They're going to also be tide in the Hessian that it's going to depend on a weighted reconstruction of the Hessian with respect to the first matrix to X.",
                    "label": 0
                },
                {
                    "sent": "And the hashing with respect to Y.",
                    "label": 0
                },
                {
                    "sent": "And so the nice and really elegant thing about this formulation is that the cost of computing a Hessian in this model on a parole basis or overall is really only a factor of K more than computing the gradient.",
                    "label": 1
                },
                {
                    "sent": "If you look at the cost of computing the gradient, it's dominated by the cost of actually computing these matrix reconstructions.",
                    "label": 0
                },
                {
                    "sent": "But once you have them, you can pay a factor of K where K is the embedding dimension more and you can get full second order information.",
                    "label": 0
                },
                {
                    "sent": "Now what this doesn't do is this doesn't take into account the cost of actually inverting the Hessian for the Newton step which is K cubed, but we're going to assume that K is typically small compared to the number of since it's a low rank approximation, the embedding dimension is going to be much smaller than the amount of data that you have.",
                    "label": 0
                },
                {
                    "sent": "So yeah, it's K cubed, but it's puny compared to everything else.",
                    "label": 0
                },
                {
                    "sent": "Yeah, during the day.",
                    "label": 0
                },
                {
                    "sent": "Elements here.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so this is the elementwise separability.",
                    "label": 0
                },
                {
                    "sent": "So this is the middle term is a diagonal matrix.",
                    "label": 0
                },
                {
                    "sent": "But you would be in the transposer dense, obviously.",
                    "label": 0
                },
                {
                    "sent": "So it's not just the diagonals of V in some sense.",
                    "label": 0
                },
                {
                    "sent": "It's not just the diagonals of V, transpose V. And yeah, if you have sparsity, which I think is a broader question that you're getting, if you have sparsity in your data, you can exploit that here.",
                    "label": 0
                },
                {
                    "sent": "In all of the matrix vector multiplies.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so we still have the case where both the gradient and Hessian are expensive because we have to reconstruct these matrices either on a per row basis or all in one shot.",
                    "label": 1
                },
                {
                    "sent": "We're in the enviable situation where you don't have to decide between conjugate between gradients, conjugate gradients and Hessians, where the dominant cost is the number of parameters were.",
                    "label": 0
                },
                {
                    "sent": "In the case where gradients are expensive, so you can't just say you know, use concrete gradient to be done with it, but one thing that works well for us is the notion of stochastic optimization, where instead of using all of the data in a row of X or a row of why to compute the gradient to compute the Hessian every time we need to compute gradient in every time we need to compute a hash, and you're going to sample.",
                    "label": 1
                },
                {
                    "sent": "The entries of a row of X or a row of wire column of extra column of Y.",
                    "label": 0
                },
                {
                    "sent": "And then you're going to update.",
                    "label": 0
                },
                {
                    "sent": "So say in this case you need to compute UV transpose for every row of.",
                    "label": 0
                },
                {
                    "sent": "You're going to need to look at all of V, which corresponds to all of the latent factors for movies.",
                    "label": 0
                },
                {
                    "sent": "But it turns out that you don't need to look at all of the movies to get a relatively good update for a particular user.",
                    "label": 0
                },
                {
                    "sent": "You can look at a subset of them, and for each user will look at a different subset of them.",
                    "label": 0
                },
                {
                    "sent": "For user two, we look at these three movies for another user.",
                    "label": 0
                },
                {
                    "sent": "You look at some other movies, and it turns out that if you dump the Hessian by a small by 1 / T factors, so you add a schedule to the Newton step.",
                    "label": 0
                },
                {
                    "sent": "This all converges.",
                    "label": 0
                },
                {
                    "sent": "And So what this is dressed is the fact that UV transpose visa transfers are the dominant costs.",
                    "label": 0
                },
                {
                    "sent": "But instead of actually looking at all of the, we're just going to look at sub slices of it where we can control the size.",
                    "label": 0
                },
                {
                    "sent": "You can look at as little as one V factor at a time.",
                    "label": 0
                },
                {
                    "sent": "Yeah, instead of picking a random sample of movies, can you pick them from the ones that the user actually saw?",
                    "label": 0
                },
                {
                    "sent": "Yes, so there's different ways and the way that we actually do it is we use the data weights.",
                    "label": 0
                },
                {
                    "sent": "A combination of the data waits in the ratings to predict and that improves performance tremendously.",
                    "label": 0
                },
                {
                    "sent": "I would think.",
                    "label": 0
                },
                {
                    "sent": "So asymptotically it doesn't make a difference, but the theory for stochastic optimization is notoriously twitchy the convergence.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Rates are very low.",
                    "label": 0
                },
                {
                    "sent": "I would care more about that same product performance if I were immortal, yeah.",
                    "label": 0
                },
                {
                    "sent": "OK, so just to emphasize with the step is will look at enough to Newton update for you where Q&Q prime or the gradient and Hessian with respect to a row of you let bar bar Q be the sample analogs for each one and so a stochastic Newton update is a regular Newton update where you replace the gradient in that room by the sample gradient in the sample henschen and you Additionally throw in this damping factor which we used to guarantee convergence.",
                    "label": 1
                },
                {
                    "sent": "It's a submartingale analysis.",
                    "label": 0
                },
                {
                    "sent": "It's kind of ugly.",
                    "label": 0
                },
                {
                    "sent": "And you can show that as long as your estimate of the Hessian converges of the inverse of the Hessian converges overtime, then the overall optimization will converge as well, and the way we guarantee convergence of the Hessian is not just to look at the instantaneous action at each step, just to look at a hashing that we computed at time T but taken exponentially.",
                    "label": 0
                },
                {
                    "sent": "Weighted moving average of the current estimate of the session with all of the past ones.",
                    "label": 0
                },
                {
                    "sent": "And that's sufficient to guarantee that there is convergence of the inverse Hessian.",
                    "label": 0
                },
                {
                    "sent": "How often do you have to re sample at each iteration?",
                    "label": 0
                },
                {
                    "sent": "So we re sample.",
                    "label": 0
                },
                {
                    "sent": "We grab a different sample at each iteration.",
                    "label": 0
                },
                {
                    "sent": "I mean you can fix it.",
                    "label": 0
                },
                {
                    "sent": "You can fix it for a few iterations for a finite number of iterations, it's just better to sample each time.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And sampling isn't expensive.",
                    "label": 0
                },
                {
                    "sent": "And so one of the problems here is we look OK, so we're looking at the training error of our three factor model on a relatively small example where the bottom line, the line which is reducing the loss most quickly, is the Newton optimization, and we look at three versions of Stochastic Newton where all we do is we vary the batch size.",
                    "label": 0
                },
                {
                    "sent": "So the number of samples that we're picking, 100,000, two, 1000 and what you see is, you know, this looks really awful.",
                    "label": 0
                },
                {
                    "sent": "The training error of the full Newton method is much much smaller than any of the stochastic Newton methods here.",
                    "label": 0
                },
                {
                    "sent": "And it's not like each stochastic Newton iteration is super cheap, it's just a lot better than doing the full Newton step, and so we think OK, well, this is hopeless.",
                    "label": 0
                },
                {
                    "sent": "The training error is so much worse for Stochastic Newton we shouldn't even try using it.",
                    "label": 1
                },
                {
                    "sent": "So this is a full Newton step using all of the data.",
                    "label": 0
                },
                {
                    "sent": "The lowest curve here where the Y axis is law is training error.",
                    "label": 0
                },
                {
                    "sent": "So lower is better and more colors for this slide.",
                    "label": 0
                },
                {
                    "sent": "Yeah, I know, sorry.",
                    "label": 0
                },
                {
                    "sent": "And so each of the lines here corresponds to stochastic Newton with the batch size of 100.",
                    "label": 0
                },
                {
                    "sent": "With the batch size of 1000 with the batch size of 2000.",
                    "label": 0
                },
                {
                    "sent": "And so increasing the batch by a lot doesn't improve the training error by a whole lot, simply because.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This one over the damping term, but you find that if you look at the test error for the reconstruction of X, and yes, I apologize for the lack of colors here.",
                    "label": 0
                },
                {
                    "sent": "There isn't that much of a difference, so for the first iteration where the X axis CPU time, the stochastic methods are kind of terrible and this just corresponds to the notion of having a really bad Hessian estimate.",
                    "label": 0
                },
                {
                    "sent": "But after that, since we have an action that converges overtime, you find that after, say, 80 seconds difference between each of the three methods is much smaller.",
                    "label": 0
                },
                {
                    "sent": "I don't know if you can look at the bottom here, but this line here is the full Newton method, and these are the stochastic methods and they're all within.",
                    "label": 0
                },
                {
                    "sent": "If you actually plot the error bars, they all overlap, so you have 20 seconds for iteration, more less.",
                    "label": 0
                },
                {
                    "sent": "It's not 20 seconds per iteration.",
                    "label": 0
                },
                {
                    "sent": "The iterations of the inflection points.",
                    "label": 0
                },
                {
                    "sent": "But yeah, it's about.",
                    "label": 0
                },
                {
                    "sent": "In this example is about 2030 seconds per duration.",
                    "label": 0
                },
                {
                    "sent": "Yeah, I guess it's inflection points.",
                    "label": 0
                },
                {
                    "sent": "OK, yeah, the inflection points, so the bottom curve is which one?",
                    "label": 0
                },
                {
                    "sent": "The lowest curve here is the full Newton method, which is obviously going to be the best for a good model.",
                    "label": 0
                },
                {
                    "sent": "Actually doing worse with bigger batch size.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so the problem with bigger batch sizes is with bigger batch sizes.",
                    "label": 0
                },
                {
                    "sent": "You can take more aggressive action steps, but if the sample but the problem is that the cause of the power law distribution of rating data if your sample ends up picking up your sample is going to be biased towards the most frequent.",
                    "label": 0
                },
                {
                    "sent": "In this case, the most frequently rated movies, which means that you're going to be overly confident that everything is a comedy and action movie or treacly drama, and you're not going to consider information about.",
                    "label": 0
                },
                {
                    "sent": "Less frequent jamras of movies, for example.",
                    "label": 0
                },
                {
                    "sent": "Which is why you get this weird inversion behavior between smaller batch sizes doing better than bigger batch sizes in the standard.",
                    "label": 0
                },
                {
                    "sent": "In the ideal case it shouldn't be, but the power laws in the data it's good.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Things up.",
                    "label": 0
                },
                {
                    "sent": "OK, and so going back to this motivation.",
                    "label": 0
                },
                {
                    "sent": "This is reconstructing the author of matrix using collective matrix factorization.",
                    "label": 1
                },
                {
                    "sent": "You can use to cast a gradient to deal with the fact that you have a lot of entities here, and if you do this reconstruction, what?",
                    "label": 0
                },
                {
                    "sent": "Why is this one of our Bregman losses?",
                    "label": 0
                },
                {
                    "sent": "And what Alpha is with this Alpha factor that we showed in the three factor?",
                    "label": 0
                },
                {
                    "sent": "This waiting in terms of the reconstruction of X versus Y?",
                    "label": 0
                },
                {
                    "sent": "And so the takeaway story here.",
                    "label": 0
                },
                {
                    "sent": "Broadly, from a relational perspective, is that by mixing information from multiple matrices according to this tide linear model, or the optimal mixing factors between point 7.8, you can do better than if you just did a collaborative filtering problem on the author matrix.",
                    "label": 0
                },
                {
                    "sent": "Or if you did regression problem from words onto authorship prediction.",
                    "label": 0
                },
                {
                    "sent": "And so that's there.",
                    "label": 0
                },
                {
                    "sent": "The other big story is that if you're a little bit careful about the assumptions that you make, and thinking about the assumptions that you make in a matrix factorization.",
                    "label": 0
                },
                {
                    "sent": "You can do a lot more than what people typically do in the literature, which is this small little gradient step.",
                    "label": 0
                },
                {
                    "sent": "You can actually get a full Hessian step on a lot of very common cases, and you really should.",
                    "label": 0
                },
                {
                    "sent": "It makes a huge difference, and on that point I'll take any questions that you have, thank you.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "What percent error or other pedestrian measure of error?",
                    "label": 0
                },
                {
                    "sent": "This is the best .5%?",
                    "label": 0
                },
                {
                    "sent": "You know this is.",
                    "label": 0
                },
                {
                    "sent": "These experiments are pretty old, so I wouldn't hesitate.",
                    "label": 0
                },
                {
                    "sent": "I don't exactly recall what it corresponds to under MC or MA, but the curve is similar.",
                    "label": 0
                },
                {
                    "sent": "Sorry, I just don't remember what the numbers are for MA.",
                    "label": 0
                },
                {
                    "sent": "Well now I'm just curious how how, how well can you do it.",
                    "label": 0
                },
                {
                    "sent": "Reconstructed guessing.",
                    "label": 0
                },
                {
                    "sent": "OK, so the reconstruction is.",
                    "label": 0
                },
                {
                    "sent": "From what I recall on the full data set somewhere between 70 and 85% for all their predictions, which is and I mean for the full author matrix, just using all the ships like 60%.",
                    "label": 0
                },
                {
                    "sent": "Yeah, you compare with the FPS optimization.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so the problem with the lobby FPS optimization is the Hessian is big, but you don't have to compute.",
                    "label": 0
                },
                {
                    "sent": "Yeah, you can approximate it.",
                    "label": 0
                },
                {
                    "sent": "We didn't actually compare to LBF's, which would be just optimizing over this non convex function.",
                    "label": 0
                },
                {
                    "sent": "You could, I don't know what the results would be like.",
                    "label": 0
                },
                {
                    "sent": "So on your previous slide, yeah.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Can I see the previous slide?",
                    "label": 0
                },
                {
                    "sent": "So it seems like you're doing better.",
                    "label": 0
                },
                {
                    "sent": "For a given time, using the full Newton method.",
                    "label": 0
                },
                {
                    "sent": "So what is what is this approximate stochastic thing?",
                    "label": 0
                },
                {
                    "sent": "By you, the stochastic thing buys you that the computing the Hessian, so this is a small example.",
                    "label": 0
                },
                {
                    "sent": "If you look at a bigger example where you have, say hundreds of thousands of users, you can't even compute one.",
                    "label": 0
                },
                {
                    "sent": "You didn't learn the lines invert, and so you typically can't even compute 1 Newton iteration.",
                    "label": 0
                },
                {
                    "sent": "This is just so I can show you all of the different methods.",
                    "label": 0
                },
                {
                    "sent": "We used a small data set do to try and compensate for bias in your data.",
                    "label": 0
                },
                {
                    "sent": "For bias in your data.",
                    "label": 0
                },
                {
                    "sent": "In stochastic I'd adjust the sampling to reflect the sample by the inverse of the.",
                    "label": 0
                },
                {
                    "sent": "Of the number of times that it's a curd, so just need to update the sampling for rare elements so it would be great to see that applied even to this size of the data set.",
                    "label": 0
                },
                {
                    "sent": "Yeah, it would be interesting, OK, anything else?",
                    "label": 0
                },
                {
                    "sent": "OK, thank you.",
                    "label": 0
                }
            ]
        }
    }
}