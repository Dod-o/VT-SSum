{
    "id": "5ydgk3tdctozkclii5ex4d5p54rb6x3t",
    "title": "Annotating Documents with Relevant Wikipedia Concepts",
    "info": {
        "author": [
            "Janez Brank, Artificial Intelligence Laboratory, Jo\u017eef Stefan Institute"
        ],
        "published": "Dec. 8, 2017",
        "recorded": "October 2017",
        "category": [
            "Top->Computer Science->Data Mining",
            "Top->Computer Science->Artificial Intelligence"
        ]
    },
    "url": "http://videolectures.net/sikdd2017_brank_wikipedia_concepts/",
    "segmentation": [
        [
            "When we sell, this broken service will be joint work with Dragon and Marco who aren't here today I guess.",
            "So the problem will be."
        ],
        [
            "We're dealing with today belongs to the subject of semantic annotation or enrichment of documents.",
            "So the problem you're dealing with is that you have some sort of documents and you want to add some kind of semantic annotations to them which are connected to some sort of ontology and make them hopefully better and more useful for further processing.",
            "Now.",
            "One particular kind of semantic enrichment is weak ification, so in this case we regard the Wikipedia as some sort of.",
            "All of you.",
            "Which individual Wikipedia pages are considered to be representations of concepts?",
            "So now Wikipedia is a large set of millions of concepts and for a given document we would like to identify which of these concepts are relevant, which of them are somehow mentioned in the document or connected to it?",
            "Why is this a good idea?",
            "So Wikipedia is quite a rich source of information.",
            "Each of these concepts corresponds to a page and therefore has a lot of text associated with it, and Furthermore these pages are linked amongst themselves with internal links which give us an idea about the relations between these concepts.",
            "There's also categorically information, so you have some sort of hierarchy if you want it, and Furthermore it's also available in a number of different languages.",
            "There are cross language links, so you can.",
            "You can process documents in different languages relatively easily, and so it's a.",
            "It's a fairly extensive resource you can think of it as a sort of general purpose on teologi is freely available.",
            "It has reasonably good coverage and so forth.",
            "So Wikipedia is a possibly a good way of enriching documents semantically.",
            "So this will lead us to the topic of disambiguation will have a bit more to say about that later when you are trying to annotate the documents.",
            "There are possibly several concepts that might be relevant to a particular passage and you have to decide which of them is the right one.",
            "And that's a big issue in the in the topic of rectification will have a few things to say about parallel processing, because this approach that we implement it is very suitable for parallel processing and it allows you to annotate a large volume of documents relatively quickly.",
            "The main application for our weekly fire is in the News Feed and Event Registry pipeline, which I'm guessing many of you are familiar with.",
            "So currently all the documents from News Feed or being annotated by our weekly fires violent.",
            "Later the event registry uses these annotations in the clustering process.",
            "So few."
        ],
        [
            "The basic idea of this approach, so let's say the first question that we that we have to answer when we're trying to annotate a document.",
            "This will be called our input document.",
            "The question is, for instance, which words or phrases in the document refer to some concepts from the Wikipedia.",
            "And one way to try answering this question is to make use of the internal links in the Wikipedia to identify such phrases.",
            "So here's an example.",
            "We have a Wikipedia page about the British Cattle Movement Service which contains this internal hyperlink.",
            "This phrase EU happens to be a link pointing to this other Wikipedia page about the European Union.",
            "So now the link consists of the anchor text or link text as the underlined phrase that the user can click.",
            "And then there's the link target, which is the page that the link points to, and there are of course many millions of search links in the Wikipedia.",
            "So now the idea is if this anchor text for example this word EU occurs in the input document that we are trying to annotate, then we might say that.",
            "Becaused this this phrase occurs in our input documents.",
            "It might constitute a mention of this page of this concept that the original link pointed too.",
            "So we'll say that this phrase where it occurred in our document is a mention of this concept in this concept, is the candidate annotation for our input document at this point.",
            "Now it might not be the relevant one, but at least it's a candidate.",
            "This is not the only way to generate candidates, but it's how it's done in the approach that we implemented."
        ],
        [
            "This leads us now to the problem of disambiguation.",
            "So in the Wikipedia you might have a large number of links with the same anchor text, the same word or phrase A and they might be pointing to many different pages to many different target concepts.",
            "For example, if we have the anchor text Tesla, this might refer to Tesla Rock Band or Tesla.",
            "The car manufacturing company, or the unit in physics, or the inventor or the graphics card, and possibly a number of other things.",
            "Now some of these.",
            "Links might be more frequent than others, but occasionally any of them might be relevant to our input document.",
            "So the question is which one to choose as the the relevant one.",
            "So if if this if this phrase appears in our input document, which of these concepts is actually relevant, if any?",
            "Now, you might say that there are, broadly speaking, two different approaches to disambiguation.",
            "Local approach in the global approach.",
            "So local disambiguation means that we treat each mention separately and disambiguate each of them separately without considering the other mentions in the document.",
            "Maybe we look a little bit in the context where this mention occurs in the input document, but basically we treat each of them as a separate problem.",
            "The global disambiguation means that we are trying to disambiguate.",
            "All the mentions in the documents together as a whole.",
            "In the hope that the information from from the different mentions can sort of help us with this invigorating, the other mentions as well the intuition behind this is that.",
            "Presumably the document the input document as a whole is about some topic, and therefore the annotations should mostly be about that topic as well.",
            "Now we don't know obviously what is the topic of the document, but hopefully the other mentions and their candidates can give us an idea about the topic.",
            "That's the kind of intuition behind the global approach.",
            "So for example, informally speaking, if we have the document about cars and we have a mention of the word Tesla in it, then it's perhaps more likely that this worth Tesla refers to Tesla.",
            "Car manufacturer rather than Tesla, the rock band.",
            "So the fact that we have other car related mentions in the document might help us disambiguate a particular mention of Tesla in our documents.",
            "That's the intuition behind the global approach.",
            "So the in our implementation we used Pagerank based globally simulation approach which was originally described by these authors and we mostly reimplemented it with some minor tweaks and will be describing this in the next couple of slides."
        ],
        [
            "So the patron based approach that we used starts by constructing a so-called mentioned concept graph, so that's a bipartite bipartite graph, so we have left vertices which correspond to mentions in our input documents and right versus vertices, which correspond to concepts.",
            "So, for example, will be presenting this on this little toy example we have is tiny documents which talks about the Tesla car manufacturer and so forth.",
            "So here are a few mentions that occur in this document.",
            "These aren't all the mentions that our wiki firewood identify, but it's just a toy example, so we have this phrase here is dementia, legal mask, and then testlets dimension and the Chief Executive is a mentioned electric car is a mansion, and there would be a few others if we try to draw the entire graph.",
            "Yeah, sure.",
            "So are we talking now that this document is the equivalent of a Wikipedia page?",
            "No, this is the input document that we're trying to annotate.",
            "So these are dimensions that we have identified in the document.",
            "And now on the right side in our graph will have the concepts from the Wikipedia which might be associated with these mentions and will add links in the graph.",
            "So we see that for example elonmusk dimension, the phrase might be associated with this concept.",
            "In other words, somewhere in the Wikipedia there is a link with this anchor text pointing to this target page, and similarly there are links in the Wikipedia with the anchor text Tesla that points to these three.",
            "Pages and of course to others as well, but I just do a small subset of the graph, so here are the different possible candidate annotations associated with this mention.",
            "We have to decide, of course.",
            "Which of them is relevant by looking at it.",
            "We can already see that this is the relevant one, but our Wiki Fire will have to figure this out and then, for example, the electric car is a mention of possible mention of this concept and there would be others as well.",
            "But this is just a subset of the graph.",
            "Now you see that they drew the links with different thickness.",
            "Because each of these links also has a transition probability associated with it, which is simply corresponds to the proportion amongst all the links.",
            "With this with this anchor text, what proportion of them points to this concept and what proportion points to this concept and so forth.",
            "So this is how we define our transition probabilities.",
            "We'll see how this is used later in the page rank calculation, so in this particular case it turns out that most of the mentions of Tesla in the.",
            "As the anchor text for Link actually pointed, Tesla the band in the Wikipedia, which is not ideal for us, but we'll see that this ambiguation comes out OK in this case anyway, so this is the first step and then."
        ],
        [
            "In the next step we add links between concepts.",
            "So on the on the right side of the graph will add links between concepts and the idea here is that the transition probability from one concept to another should be proportional to some sort of semantic relatedness between the two concepts, so that the link between two concepts is strong if they are semantically related in some sense.",
            "Now that's a fairly vague term.",
            "You might say one way that we can try to measure some sort of semantic relatedness.",
            "Is to make use of the internal link graph of the Wikipedia itself.",
            "So for each, for each, for each concept, see which corresponds to a page in the Wikipedia.",
            "Let else be the set of pages in the Wikipedia that contain links to see.",
            "So these are its immediate predecessors in the Wikipedia link graph, and now we can say, OK, C&C prime are related if similar pages points to both of them.",
            "That's basically the intuition.",
            "And this is 1 possible way of measuring it.",
            "So basically you ask yourself if.",
            "If the intersection of these two sets of predecessors is almost the same size as the as the sets of predecessors themselves, then the concepts are more related, and Furthermore, if these sets are large relative to the entire document set in the Wikipedia, then they are even more related.",
            "So basically it's a sort of intuitively reasonable measure that's relatively easy to calculate.",
            "Answer will add these these links between concepts.",
            "I didn't draw all of them because it would get massive, but these are some of the most important ones.",
            "So here the intuition is that Elon Musk and the Tesla car manufacturer have a much stronger relationship than, for example Ellon, Musk and Tesla.",
            "The band and or the inventor and so forth and the electric vehicle concept probably also has a relatively strong relationship with best of the car manufacturer.",
            "So now the.",
            "The concepts which kind of fit together thematically will be connected a little more strongly with these right hand links.",
            "So now with this graph we can start to compute Pagerank.",
            "This is the familiar."
        ],
        [
            "I thought if I threw it in formula so in each iteration the page ranks from the previous iteration get distributed following the links.",
            "Yeah, well, OK, so these links for arrows, but these links are supposed to be BI directional or undirected if you will.",
            "So I didn't draw the arrows on them, but basically Pagerank flows along both sides of these links, so each vertex distributes the page rank from the previous iterations along its outgoing links, and on top of that, each vertex also gets a certain amount of.",
            "Baseline page rank in each iteration and this baseline they drag is defined in the following way.",
            "For concept vertices on the right hand side, they don't get anything, but the mention vertices on the left hand side get a certain amount of baseline page rank which is proportionate to the probability.",
            "Given that this phrase occurs in a Wikipedia page, how likely is it that it occurs as the anchor text?",
            "Link in the page.",
            "So the idea is some phrases are very common and actually rarely occur as a link, so if that same phrase occurs in your input document, that's actually fairly weak evidence of it being a mention of some concept.",
            "But on the other hand, if a phrase almost always occurs as a link, then it's very strong, or evidence that it should also be treated as a mention of a concept in your input document.",
            "So this this definition of this baseline page rank if you will.",
            "Is useful for two reasons so.",
            "One thing, of course is to stabilize the site rative process to make it converge and the other thing is.",
            "That otherwise all the Pagerank would be flowing towards the right hand side.",
            "But thanks to this we shift some of it to the left hand side in each iteration.",
            "So we can compute the patriarchy."
        ],
        [
            "Few iterations now.",
            "The idea behind these these definitions in this page rank based approach is of course in the end when the page rank is completed.",
            "If I mention has several candidate annotations will use the one with the highest page rank and use that as our as our actual annotation.",
            "So in this case for example, the mention Tesla will be associated with these candidates.",
            "Here they are sorted by page rank and hopefully the correct one, which in this case is the car manufacturer will come out on top and that will be the one provided by the wiki, fires the annotation in this particular case, we'll say that this mentions supports that annotation, so we can talk about the support of mentioned sort of an annotation, and this can be listed in the output of the weekly fire.",
            "And the intuition behind this approach is that in our graph that we showed in the previous slides, the Pagerank flows into into a concept vertex, one of the right hand side vertices.",
            "It flows into it from mentions for which there exists a link in the Wikipedia with this anchor text that points to the concept see.",
            "So Page rank comes from the mentions into the concept.",
            "Plus it also comes from other concepts in our graph that are semantically closely related to it, so the intuition is that hopefully if we have a group of semantically related concepts that are also sufficiently well supported by mentions in our input document, then the concept concept links will help these concepts to boost each other with their page rank and come out on top.",
            "So that will end up with a group of semantically related concepts that are that are about the same topic as the document.",
            "That's the intuition.",
            "Basically, why why this sort of global page rank based disambiguation approach might work reasonably well.",
            "Um?",
            "Yeah, so this is what we're trying to do with the glue."
        ],
        [
            "Limitation of a few.",
            "A few little tweaks regarding highly ambiguous mention, so some mentions are extremely ambiguous in the sense that a given word or phrase occurs as the anchor text of very many links pointing to very many different pages.",
            "So this is a concrete example.",
            "The word country in the Wikipedia OK turns out most of the time when it appears as the anchor text of a link.",
            "It's a link to country music.",
            "Sometimes it's a link to country as a concept.",
            "Sometimes it's a link to this little slightly more specific concept nation states or the countryside as the rural area, but then much of the time it's also links to specific countries, so this is a highly highly ambiguous mention.",
            "What do we do about such mentions?",
            "First problem?",
            "OK, one obvious problem is that they are hard to disambiguate and they might generate wrong annotations.",
            "But another problem for this specific approach that we described here is that.",
            "If you end up adding all of these concepts as candidate annotations, our graph that will have a great number of vertices on the right hand side.",
            "Too many constant vertices, and then also too many links between those constant vertices in the whole process of annotating of computing page ranks would be quite slow and computationally intensive, so it's better to do something about such highly ambiguous mentions, and there are some heuristics that we employ for such things.",
            "One idea is to use an entropy based criterion so we can compute the entropy.",
            "The amount of uncertainty regarding the target of a link in the Wikipedia, conditioned on the fact that the anchor text of that link is the phrase that we're looking at.",
            "So for instance, in this case you could convert these frequencies into probabilities and then compute the entropy from that, and you might define the threshold.",
            "For example, the entropy is more than a certain number of bits.",
            "Then you say the dimension is too ambiguous and it's better to descend to discard it.",
            "Then to generate noise, another idea very obvious is to just use the top few.",
            "For example top 20 concepts ordered according to frequency and ignore the infrequent ones.",
            "But sometimes, of course you overlook something useful that way.",
            "Another idea that's benefited a little less if if the entire text of the phrase of dimension consists only of very frequent words, stop words you might say, then it's better to ignore it, for example.",
            "Otherwise we have words like the OR it, and so forth, being annotated because summer in the Wikipedia there's certainly going to be a link with just those the anchor text.",
            "We don't have a separate list of stop words for each language because we're trying to support a large number of languages that we just.",
            "Define this based on the frequency of words and.",
            "Another idea is that we can completely disregard concepts that belong to certain wiki data categories.",
            "So in the week data is an ontology associated with the Wikipedia with some class information, and for example we can simply discard concepts that are actually lists of things.",
            "There are a lot of such pages in the Wikipedia, but they aren't really useful for us as annotations."
        ],
        [
            "A few other heuristics that didn't really improve performance, but I'll mention them for completeness.",
            "Earlier we saw that the concept of semantic relatedness can be computed based on the comparing the sets of immediate predecessors in the Wikipedia link graph.",
            "So one idea that we tested was if we could use immediate successors or even all the neighbors instead of predecessors, but it's turned out not so really need to any improvements.",
            "Another possible improvement is the idea of a two stage disambiguation process.",
            "So after we compute the page rank, we have the candidate annotation Sofa mentioned that we're looking at and instead of just returning the one with the highest page rank, we can maybe select the top 20 or something like that based on page rank, and then re rank them using a different scoring function, possibly a more computationally intensive one, and see if that leads to better results.",
            "So the function that we tried that didn't really lead to improvements in performance, but.",
            "Anyway, possibly something of that sort might be useful is that we can, in addition to the page rank of the concept itself, we can look at how frequently the links with this with this anchor text point to a particular concepts.",
            "Now in principle this is already incorporated in our Pagerank computation process, but maybe we can include it more explicitly in the.",
            "In the RE ranking itself and then another idea is to look at the cosine similarity between the input document and the the text of the Wikipedia page for that concept.",
            "So maybe that gives us an idea of how similar they are thematically, how likely it is that the concept is relevant for this document and other similar idea is to use the context of the links.",
            "So you might say that the context of a link consists of the previous and next few words, and you likewise, so you look at the context of our mention in our input document.",
            "And also you look at the context of all the links to that concept in the Wikipedia and you compare those two again using cosine similarity.",
            "But our preliminary experiments with these ideas didn't really lead to improvements in performance, but they do increase the computational cost.",
            "So for the time being these things are disabled by default.",
            "Chip tuning the weights will be one in Level 2 and so we had a little.",
            "We mostly compared the output of our rectifier with that of another existing quickly fire and try to tune the weights so as to increase the matching between them.",
            "We also had one gold standard, manually annotated datasets.",
            "We say a little more about evaluation later, so basically I was trying to kind of tune the weight little by little to see how it affects performance.",
            "But it didn't really lead to significant improvements most of the time the changes were very small, so I decided to disable this for the time being."
        ],
        [
            "So few words about the implementation.",
            "The approach described here is very suitable for parallel processing, not on the level of an individual document, but on the level of multiple documents.",
            "So if you have several documents, they can easily be processed in parallel because the shared data structures need only to be accessed read only, so they can easily be shared by all the threads.",
            "So we have a highly parallelized implementation.",
            "Another nice thing about this approach is that it can work with any language.",
            "For each sufficiently large Wikipedia is available.",
            "Our implementation is available online, so if anybody wants to play with it, it's freely accessible.",
            "Currently handles about half a million documents per day with a total length of about 1GB, and there's still plenty of computational resources free.",
            "It supports about 1:30 languages, which is all the Wikipedia, all the languages for which Wikipedia of at least 1000 pages available.",
            "Now of course 1000 pages is much too small to have useful coverage.",
            "So not not all of these languages are really usefully supported, but on the other hand, about 60 languages have a Wikipedia of at least 100,000 pages, which can already be useful for at least some purposes.",
            "And optionally, identifier can return class memberships from wiki data or the DVD ontologies for possibly some further processing.",
            "There are also some other functionalities that I won't mention at this point."
        ],
        [
            "To conclude, with a small evaluation we found there isn't really a terrible wealth of suitable datasets for this sort of evaluation.",
            "We use this set of manually annotated news articles that was originally prepared by the authors of the either Wiki fire.",
            "So the way we can compare them with simply, we look at this set of annotations so document concept pairs for all the documents in the datasets, and when you have these two sets for two different wiki fires or for one week.",
            "In the gold standard, we can compute things like precision, recall the F measure, and so forth.",
            "So here's a little matrix.",
            "So here we have the gold standard, and various wiki fires, and the F measure that compares how well they match.",
            "So we see that comparing to the gold standard, we are not quite as good as the other wiki fire, but we're relatively close and the others are much worse.",
            "But what I also found very interesting was that the matches the matching between the agreement between the different wiki fires is relatively low.",
            "No matter which pair of wiki fires you look at, so I think on average I think the the lesson learned from this is that we could we fication is a is a relatively vaguely defined task.",
            "You know there's this idea.",
            "OK, we want to annotate a document with relevant concepts, but which concepts are actually relevant?",
            "And it turns out that different people have different ideas about that might depend on your application and so forth, so that different wiki fires are actually doing relatively different things, and it's hard to compare.",
            "It also means that comparison to a gold standard is likewise perhaps somewhat problematic.",
            "This you're using, I would guess much more updated Wikipedia set of links than the original authors of the gold standard annotation set, probably somewhat more up-to-date.",
            "Yeah, there are going to be more links probably than they were at that time that you're actually penalizing yourself more in the evaluation should could be could be, yeah.",
            "In the Wikipedia dump from the time that they were annotating right?",
            "Then you might have a fairer or you might have a better evaluation for yourself at a more representative.",
            "Yeah, true, true true.",
            "I think it also depends on what your goals that you are trying to pursue are.",
            "For example, in our Wiki fire, at least initially, the emphasis was kind of moron thinking about recall, not so much about precision, and I think maybe some of these others focused a little more in precision, so that also kind of affects the output and so forth.",
            "Some of them, I think, deliberately tried to avoid.",
            "Things which aren't named entities and so forth.",
            "So as I said, different people have different ideas as to what exactly counts is relevant.",
            "The documents also were generated at that point and also they don't mention penciler.",
            "Yeah, I think that was his idea that we are kind of having a harder job because we have a more recent Wikipedia and it might confuse us in ways that it wouldn't confuse the original authors.",
            "There might be something today.",
            "Yeah, and I think that."
        ],
        [
            "Yeah, so OK. Just to conclude.",
            "So we have an efficient and highly parallel implementation based on a global page rank based disambiguation.",
            "We have some ideas on future extensions and some are actually in progress.",
            "So one idea is to allow the user to define a set of pages or categories that should be completely ignored when processing the Wikipedia.",
            "Another is to allow users to define additional sets of annotations not really related to the Wikipedia that can be provided as additional annotations.",
            "This is already partly implemented in some people.",
            "To use it.",
            "In their projects there are also some ideas that I already mentioned about combining local and global disambiguation approaches using the context of a mention, we didn't get any improvements yet, but I think possibly some further work in that direction can be useful.",
            "Perhaps instead of using just plain bag of words to compare the context, we could use the word to vector some similar representation and.",
            "The rules have some ideas about how to handle small languages, languages for which Wikipedia does not have sufficient coverage.",
            "So maybe one idea was to use the links simply from other language Wikipedias to generate candidate annotations, and they won't really match up perfectly well, but they might match approximately, and for this to work we would need to combine the link graphs of different language Wikipedias into one common link graph, which can be done using the cross language information in the Wiki data Ontology.",
            "So we are in that I think, concludes my presentation.",
            "Thank you, thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "When we sell, this broken service will be joint work with Dragon and Marco who aren't here today I guess.",
                    "label": 0
                },
                {
                    "sent": "So the problem will be.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We're dealing with today belongs to the subject of semantic annotation or enrichment of documents.",
                    "label": 0
                },
                {
                    "sent": "So the problem you're dealing with is that you have some sort of documents and you want to add some kind of semantic annotations to them which are connected to some sort of ontology and make them hopefully better and more useful for further processing.",
                    "label": 0
                },
                {
                    "sent": "Now.",
                    "label": 0
                },
                {
                    "sent": "One particular kind of semantic enrichment is weak ification, so in this case we regard the Wikipedia as some sort of.",
                    "label": 0
                },
                {
                    "sent": "All of you.",
                    "label": 0
                },
                {
                    "sent": "Which individual Wikipedia pages are considered to be representations of concepts?",
                    "label": 0
                },
                {
                    "sent": "So now Wikipedia is a large set of millions of concepts and for a given document we would like to identify which of these concepts are relevant, which of them are somehow mentioned in the document or connected to it?",
                    "label": 0
                },
                {
                    "sent": "Why is this a good idea?",
                    "label": 0
                },
                {
                    "sent": "So Wikipedia is quite a rich source of information.",
                    "label": 0
                },
                {
                    "sent": "Each of these concepts corresponds to a page and therefore has a lot of text associated with it, and Furthermore these pages are linked amongst themselves with internal links which give us an idea about the relations between these concepts.",
                    "label": 0
                },
                {
                    "sent": "There's also categorically information, so you have some sort of hierarchy if you want it, and Furthermore it's also available in a number of different languages.",
                    "label": 0
                },
                {
                    "sent": "There are cross language links, so you can.",
                    "label": 0
                },
                {
                    "sent": "You can process documents in different languages relatively easily, and so it's a.",
                    "label": 0
                },
                {
                    "sent": "It's a fairly extensive resource you can think of it as a sort of general purpose on teologi is freely available.",
                    "label": 0
                },
                {
                    "sent": "It has reasonably good coverage and so forth.",
                    "label": 0
                },
                {
                    "sent": "So Wikipedia is a possibly a good way of enriching documents semantically.",
                    "label": 0
                },
                {
                    "sent": "So this will lead us to the topic of disambiguation will have a bit more to say about that later when you are trying to annotate the documents.",
                    "label": 0
                },
                {
                    "sent": "There are possibly several concepts that might be relevant to a particular passage and you have to decide which of them is the right one.",
                    "label": 0
                },
                {
                    "sent": "And that's a big issue in the in the topic of rectification will have a few things to say about parallel processing, because this approach that we implement it is very suitable for parallel processing and it allows you to annotate a large volume of documents relatively quickly.",
                    "label": 0
                },
                {
                    "sent": "The main application for our weekly fire is in the News Feed and Event Registry pipeline, which I'm guessing many of you are familiar with.",
                    "label": 0
                },
                {
                    "sent": "So currently all the documents from News Feed or being annotated by our weekly fires violent.",
                    "label": 0
                },
                {
                    "sent": "Later the event registry uses these annotations in the clustering process.",
                    "label": 0
                },
                {
                    "sent": "So few.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The basic idea of this approach, so let's say the first question that we that we have to answer when we're trying to annotate a document.",
                    "label": 0
                },
                {
                    "sent": "This will be called our input document.",
                    "label": 0
                },
                {
                    "sent": "The question is, for instance, which words or phrases in the document refer to some concepts from the Wikipedia.",
                    "label": 1
                },
                {
                    "sent": "And one way to try answering this question is to make use of the internal links in the Wikipedia to identify such phrases.",
                    "label": 1
                },
                {
                    "sent": "So here's an example.",
                    "label": 0
                },
                {
                    "sent": "We have a Wikipedia page about the British Cattle Movement Service which contains this internal hyperlink.",
                    "label": 0
                },
                {
                    "sent": "This phrase EU happens to be a link pointing to this other Wikipedia page about the European Union.",
                    "label": 0
                },
                {
                    "sent": "So now the link consists of the anchor text or link text as the underlined phrase that the user can click.",
                    "label": 0
                },
                {
                    "sent": "And then there's the link target, which is the page that the link points to, and there are of course many millions of search links in the Wikipedia.",
                    "label": 1
                },
                {
                    "sent": "So now the idea is if this anchor text for example this word EU occurs in the input document that we are trying to annotate, then we might say that.",
                    "label": 0
                },
                {
                    "sent": "Becaused this this phrase occurs in our input documents.",
                    "label": 0
                },
                {
                    "sent": "It might constitute a mention of this page of this concept that the original link pointed too.",
                    "label": 1
                },
                {
                    "sent": "So we'll say that this phrase where it occurred in our document is a mention of this concept in this concept, is the candidate annotation for our input document at this point.",
                    "label": 0
                },
                {
                    "sent": "Now it might not be the relevant one, but at least it's a candidate.",
                    "label": 0
                },
                {
                    "sent": "This is not the only way to generate candidates, but it's how it's done in the approach that we implemented.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This leads us now to the problem of disambiguation.",
                    "label": 0
                },
                {
                    "sent": "So in the Wikipedia you might have a large number of links with the same anchor text, the same word or phrase A and they might be pointing to many different pages to many different target concepts.",
                    "label": 0
                },
                {
                    "sent": "For example, if we have the anchor text Tesla, this might refer to Tesla Rock Band or Tesla.",
                    "label": 0
                },
                {
                    "sent": "The car manufacturing company, or the unit in physics, or the inventor or the graphics card, and possibly a number of other things.",
                    "label": 0
                },
                {
                    "sent": "Now some of these.",
                    "label": 0
                },
                {
                    "sent": "Links might be more frequent than others, but occasionally any of them might be relevant to our input document.",
                    "label": 0
                },
                {
                    "sent": "So the question is which one to choose as the the relevant one.",
                    "label": 0
                },
                {
                    "sent": "So if if this if this phrase appears in our input document, which of these concepts is actually relevant, if any?",
                    "label": 1
                },
                {
                    "sent": "Now, you might say that there are, broadly speaking, two different approaches to disambiguation.",
                    "label": 0
                },
                {
                    "sent": "Local approach in the global approach.",
                    "label": 1
                },
                {
                    "sent": "So local disambiguation means that we treat each mention separately and disambiguate each of them separately without considering the other mentions in the document.",
                    "label": 0
                },
                {
                    "sent": "Maybe we look a little bit in the context where this mention occurs in the input document, but basically we treat each of them as a separate problem.",
                    "label": 0
                },
                {
                    "sent": "The global disambiguation means that we are trying to disambiguate.",
                    "label": 0
                },
                {
                    "sent": "All the mentions in the documents together as a whole.",
                    "label": 1
                },
                {
                    "sent": "In the hope that the information from from the different mentions can sort of help us with this invigorating, the other mentions as well the intuition behind this is that.",
                    "label": 0
                },
                {
                    "sent": "Presumably the document the input document as a whole is about some topic, and therefore the annotations should mostly be about that topic as well.",
                    "label": 1
                },
                {
                    "sent": "Now we don't know obviously what is the topic of the document, but hopefully the other mentions and their candidates can give us an idea about the topic.",
                    "label": 0
                },
                {
                    "sent": "That's the kind of intuition behind the global approach.",
                    "label": 0
                },
                {
                    "sent": "So for example, informally speaking, if we have the document about cars and we have a mention of the word Tesla in it, then it's perhaps more likely that this worth Tesla refers to Tesla.",
                    "label": 0
                },
                {
                    "sent": "Car manufacturer rather than Tesla, the rock band.",
                    "label": 0
                },
                {
                    "sent": "So the fact that we have other car related mentions in the document might help us disambiguate a particular mention of Tesla in our documents.",
                    "label": 0
                },
                {
                    "sent": "That's the intuition behind the global approach.",
                    "label": 0
                },
                {
                    "sent": "So the in our implementation we used Pagerank based globally simulation approach which was originally described by these authors and we mostly reimplemented it with some minor tweaks and will be describing this in the next couple of slides.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the patron based approach that we used starts by constructing a so-called mentioned concept graph, so that's a bipartite bipartite graph, so we have left vertices which correspond to mentions in our input documents and right versus vertices, which correspond to concepts.",
                    "label": 1
                },
                {
                    "sent": "So, for example, will be presenting this on this little toy example we have is tiny documents which talks about the Tesla car manufacturer and so forth.",
                    "label": 0
                },
                {
                    "sent": "So here are a few mentions that occur in this document.",
                    "label": 0
                },
                {
                    "sent": "These aren't all the mentions that our wiki firewood identify, but it's just a toy example, so we have this phrase here is dementia, legal mask, and then testlets dimension and the Chief Executive is a mentioned electric car is a mansion, and there would be a few others if we try to draw the entire graph.",
                    "label": 0
                },
                {
                    "sent": "Yeah, sure.",
                    "label": 0
                },
                {
                    "sent": "So are we talking now that this document is the equivalent of a Wikipedia page?",
                    "label": 0
                },
                {
                    "sent": "No, this is the input document that we're trying to annotate.",
                    "label": 0
                },
                {
                    "sent": "So these are dimensions that we have identified in the document.",
                    "label": 0
                },
                {
                    "sent": "And now on the right side in our graph will have the concepts from the Wikipedia which might be associated with these mentions and will add links in the graph.",
                    "label": 0
                },
                {
                    "sent": "So we see that for example elonmusk dimension, the phrase might be associated with this concept.",
                    "label": 0
                },
                {
                    "sent": "In other words, somewhere in the Wikipedia there is a link with this anchor text pointing to this target page, and similarly there are links in the Wikipedia with the anchor text Tesla that points to these three.",
                    "label": 1
                },
                {
                    "sent": "Pages and of course to others as well, but I just do a small subset of the graph, so here are the different possible candidate annotations associated with this mention.",
                    "label": 0
                },
                {
                    "sent": "We have to decide, of course.",
                    "label": 0
                },
                {
                    "sent": "Which of them is relevant by looking at it.",
                    "label": 0
                },
                {
                    "sent": "We can already see that this is the relevant one, but our Wiki Fire will have to figure this out and then, for example, the electric car is a mention of possible mention of this concept and there would be others as well.",
                    "label": 0
                },
                {
                    "sent": "But this is just a subset of the graph.",
                    "label": 1
                },
                {
                    "sent": "Now you see that they drew the links with different thickness.",
                    "label": 0
                },
                {
                    "sent": "Because each of these links also has a transition probability associated with it, which is simply corresponds to the proportion amongst all the links.",
                    "label": 0
                },
                {
                    "sent": "With this with this anchor text, what proportion of them points to this concept and what proportion points to this concept and so forth.",
                    "label": 1
                },
                {
                    "sent": "So this is how we define our transition probabilities.",
                    "label": 0
                },
                {
                    "sent": "We'll see how this is used later in the page rank calculation, so in this particular case it turns out that most of the mentions of Tesla in the.",
                    "label": 0
                },
                {
                    "sent": "As the anchor text for Link actually pointed, Tesla the band in the Wikipedia, which is not ideal for us, but we'll see that this ambiguation comes out OK in this case anyway, so this is the first step and then.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In the next step we add links between concepts.",
                    "label": 0
                },
                {
                    "sent": "So on the on the right side of the graph will add links between concepts and the idea here is that the transition probability from one concept to another should be proportional to some sort of semantic relatedness between the two concepts, so that the link between two concepts is strong if they are semantically related in some sense.",
                    "label": 0
                },
                {
                    "sent": "Now that's a fairly vague term.",
                    "label": 0
                },
                {
                    "sent": "You might say one way that we can try to measure some sort of semantic relatedness.",
                    "label": 1
                },
                {
                    "sent": "Is to make use of the internal link graph of the Wikipedia itself.",
                    "label": 0
                },
                {
                    "sent": "So for each, for each, for each concept, see which corresponds to a page in the Wikipedia.",
                    "label": 0
                },
                {
                    "sent": "Let else be the set of pages in the Wikipedia that contain links to see.",
                    "label": 1
                },
                {
                    "sent": "So these are its immediate predecessors in the Wikipedia link graph, and now we can say, OK, C&C prime are related if similar pages points to both of them.",
                    "label": 0
                },
                {
                    "sent": "That's basically the intuition.",
                    "label": 0
                },
                {
                    "sent": "And this is 1 possible way of measuring it.",
                    "label": 0
                },
                {
                    "sent": "So basically you ask yourself if.",
                    "label": 0
                },
                {
                    "sent": "If the intersection of these two sets of predecessors is almost the same size as the as the sets of predecessors themselves, then the concepts are more related, and Furthermore, if these sets are large relative to the entire document set in the Wikipedia, then they are even more related.",
                    "label": 0
                },
                {
                    "sent": "So basically it's a sort of intuitively reasonable measure that's relatively easy to calculate.",
                    "label": 0
                },
                {
                    "sent": "Answer will add these these links between concepts.",
                    "label": 0
                },
                {
                    "sent": "I didn't draw all of them because it would get massive, but these are some of the most important ones.",
                    "label": 0
                },
                {
                    "sent": "So here the intuition is that Elon Musk and the Tesla car manufacturer have a much stronger relationship than, for example Ellon, Musk and Tesla.",
                    "label": 0
                },
                {
                    "sent": "The band and or the inventor and so forth and the electric vehicle concept probably also has a relatively strong relationship with best of the car manufacturer.",
                    "label": 0
                },
                {
                    "sent": "So now the.",
                    "label": 0
                },
                {
                    "sent": "The concepts which kind of fit together thematically will be connected a little more strongly with these right hand links.",
                    "label": 0
                },
                {
                    "sent": "So now with this graph we can start to compute Pagerank.",
                    "label": 0
                },
                {
                    "sent": "This is the familiar.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I thought if I threw it in formula so in each iteration the page ranks from the previous iteration get distributed following the links.",
                    "label": 0
                },
                {
                    "sent": "Yeah, well, OK, so these links for arrows, but these links are supposed to be BI directional or undirected if you will.",
                    "label": 0
                },
                {
                    "sent": "So I didn't draw the arrows on them, but basically Pagerank flows along both sides of these links, so each vertex distributes the page rank from the previous iterations along its outgoing links, and on top of that, each vertex also gets a certain amount of.",
                    "label": 0
                },
                {
                    "sent": "Baseline page rank in each iteration and this baseline they drag is defined in the following way.",
                    "label": 0
                },
                {
                    "sent": "For concept vertices on the right hand side, they don't get anything, but the mention vertices on the left hand side get a certain amount of baseline page rank which is proportionate to the probability.",
                    "label": 0
                },
                {
                    "sent": "Given that this phrase occurs in a Wikipedia page, how likely is it that it occurs as the anchor text?",
                    "label": 1
                },
                {
                    "sent": "Link in the page.",
                    "label": 0
                },
                {
                    "sent": "So the idea is some phrases are very common and actually rarely occur as a link, so if that same phrase occurs in your input document, that's actually fairly weak evidence of it being a mention of some concept.",
                    "label": 0
                },
                {
                    "sent": "But on the other hand, if a phrase almost always occurs as a link, then it's very strong, or evidence that it should also be treated as a mention of a concept in your input document.",
                    "label": 1
                },
                {
                    "sent": "So this this definition of this baseline page rank if you will.",
                    "label": 0
                },
                {
                    "sent": "Is useful for two reasons so.",
                    "label": 0
                },
                {
                    "sent": "One thing, of course is to stabilize the site rative process to make it converge and the other thing is.",
                    "label": 0
                },
                {
                    "sent": "That otherwise all the Pagerank would be flowing towards the right hand side.",
                    "label": 0
                },
                {
                    "sent": "But thanks to this we shift some of it to the left hand side in each iteration.",
                    "label": 0
                },
                {
                    "sent": "So we can compute the patriarchy.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Few iterations now.",
                    "label": 0
                },
                {
                    "sent": "The idea behind these these definitions in this page rank based approach is of course in the end when the page rank is completed.",
                    "label": 0
                },
                {
                    "sent": "If I mention has several candidate annotations will use the one with the highest page rank and use that as our as our actual annotation.",
                    "label": 1
                },
                {
                    "sent": "So in this case for example, the mention Tesla will be associated with these candidates.",
                    "label": 0
                },
                {
                    "sent": "Here they are sorted by page rank and hopefully the correct one, which in this case is the car manufacturer will come out on top and that will be the one provided by the wiki, fires the annotation in this particular case, we'll say that this mentions supports that annotation, so we can talk about the support of mentioned sort of an annotation, and this can be listed in the output of the weekly fire.",
                    "label": 0
                },
                {
                    "sent": "And the intuition behind this approach is that in our graph that we showed in the previous slides, the Pagerank flows into into a concept vertex, one of the right hand side vertices.",
                    "label": 1
                },
                {
                    "sent": "It flows into it from mentions for which there exists a link in the Wikipedia with this anchor text that points to the concept see.",
                    "label": 0
                },
                {
                    "sent": "So Page rank comes from the mentions into the concept.",
                    "label": 0
                },
                {
                    "sent": "Plus it also comes from other concepts in our graph that are semantically closely related to it, so the intuition is that hopefully if we have a group of semantically related concepts that are also sufficiently well supported by mentions in our input document, then the concept concept links will help these concepts to boost each other with their page rank and come out on top.",
                    "label": 1
                },
                {
                    "sent": "So that will end up with a group of semantically related concepts that are that are about the same topic as the document.",
                    "label": 0
                },
                {
                    "sent": "That's the intuition.",
                    "label": 0
                },
                {
                    "sent": "Basically, why why this sort of global page rank based disambiguation approach might work reasonably well.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Yeah, so this is what we're trying to do with the glue.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Limitation of a few.",
                    "label": 0
                },
                {
                    "sent": "A few little tweaks regarding highly ambiguous mention, so some mentions are extremely ambiguous in the sense that a given word or phrase occurs as the anchor text of very many links pointing to very many different pages.",
                    "label": 1
                },
                {
                    "sent": "So this is a concrete example.",
                    "label": 1
                },
                {
                    "sent": "The word country in the Wikipedia OK turns out most of the time when it appears as the anchor text of a link.",
                    "label": 0
                },
                {
                    "sent": "It's a link to country music.",
                    "label": 0
                },
                {
                    "sent": "Sometimes it's a link to country as a concept.",
                    "label": 0
                },
                {
                    "sent": "Sometimes it's a link to this little slightly more specific concept nation states or the countryside as the rural area, but then much of the time it's also links to specific countries, so this is a highly highly ambiguous mention.",
                    "label": 0
                },
                {
                    "sent": "What do we do about such mentions?",
                    "label": 0
                },
                {
                    "sent": "First problem?",
                    "label": 0
                },
                {
                    "sent": "OK, one obvious problem is that they are hard to disambiguate and they might generate wrong annotations.",
                    "label": 0
                },
                {
                    "sent": "But another problem for this specific approach that we described here is that.",
                    "label": 0
                },
                {
                    "sent": "If you end up adding all of these concepts as candidate annotations, our graph that will have a great number of vertices on the right hand side.",
                    "label": 0
                },
                {
                    "sent": "Too many constant vertices, and then also too many links between those constant vertices in the whole process of annotating of computing page ranks would be quite slow and computationally intensive, so it's better to do something about such highly ambiguous mentions, and there are some heuristics that we employ for such things.",
                    "label": 0
                },
                {
                    "sent": "One idea is to use an entropy based criterion so we can compute the entropy.",
                    "label": 0
                },
                {
                    "sent": "The amount of uncertainty regarding the target of a link in the Wikipedia, conditioned on the fact that the anchor text of that link is the phrase that we're looking at.",
                    "label": 0
                },
                {
                    "sent": "So for instance, in this case you could convert these frequencies into probabilities and then compute the entropy from that, and you might define the threshold.",
                    "label": 1
                },
                {
                    "sent": "For example, the entropy is more than a certain number of bits.",
                    "label": 0
                },
                {
                    "sent": "Then you say the dimension is too ambiguous and it's better to descend to discard it.",
                    "label": 0
                },
                {
                    "sent": "Then to generate noise, another idea very obvious is to just use the top few.",
                    "label": 0
                },
                {
                    "sent": "For example top 20 concepts ordered according to frequency and ignore the infrequent ones.",
                    "label": 0
                },
                {
                    "sent": "But sometimes, of course you overlook something useful that way.",
                    "label": 0
                },
                {
                    "sent": "Another idea that's benefited a little less if if the entire text of the phrase of dimension consists only of very frequent words, stop words you might say, then it's better to ignore it, for example.",
                    "label": 0
                },
                {
                    "sent": "Otherwise we have words like the OR it, and so forth, being annotated because summer in the Wikipedia there's certainly going to be a link with just those the anchor text.",
                    "label": 0
                },
                {
                    "sent": "We don't have a separate list of stop words for each language because we're trying to support a large number of languages that we just.",
                    "label": 0
                },
                {
                    "sent": "Define this based on the frequency of words and.",
                    "label": 1
                },
                {
                    "sent": "Another idea is that we can completely disregard concepts that belong to certain wiki data categories.",
                    "label": 0
                },
                {
                    "sent": "So in the week data is an ontology associated with the Wikipedia with some class information, and for example we can simply discard concepts that are actually lists of things.",
                    "label": 0
                },
                {
                    "sent": "There are a lot of such pages in the Wikipedia, but they aren't really useful for us as annotations.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "A few other heuristics that didn't really improve performance, but I'll mention them for completeness.",
                    "label": 0
                },
                {
                    "sent": "Earlier we saw that the concept of semantic relatedness can be computed based on the comparing the sets of immediate predecessors in the Wikipedia link graph.",
                    "label": 1
                },
                {
                    "sent": "So one idea that we tested was if we could use immediate successors or even all the neighbors instead of predecessors, but it's turned out not so really need to any improvements.",
                    "label": 0
                },
                {
                    "sent": "Another possible improvement is the idea of a two stage disambiguation process.",
                    "label": 0
                },
                {
                    "sent": "So after we compute the page rank, we have the candidate annotation Sofa mentioned that we're looking at and instead of just returning the one with the highest page rank, we can maybe select the top 20 or something like that based on page rank, and then re rank them using a different scoring function, possibly a more computationally intensive one, and see if that leads to better results.",
                    "label": 0
                },
                {
                    "sent": "So the function that we tried that didn't really lead to improvements in performance, but.",
                    "label": 0
                },
                {
                    "sent": "Anyway, possibly something of that sort might be useful is that we can, in addition to the page rank of the concept itself, we can look at how frequently the links with this with this anchor text point to a particular concepts.",
                    "label": 0
                },
                {
                    "sent": "Now in principle this is already incorporated in our Pagerank computation process, but maybe we can include it more explicitly in the.",
                    "label": 1
                },
                {
                    "sent": "In the RE ranking itself and then another idea is to look at the cosine similarity between the input document and the the text of the Wikipedia page for that concept.",
                    "label": 0
                },
                {
                    "sent": "So maybe that gives us an idea of how similar they are thematically, how likely it is that the concept is relevant for this document and other similar idea is to use the context of the links.",
                    "label": 1
                },
                {
                    "sent": "So you might say that the context of a link consists of the previous and next few words, and you likewise, so you look at the context of our mention in our input document.",
                    "label": 0
                },
                {
                    "sent": "And also you look at the context of all the links to that concept in the Wikipedia and you compare those two again using cosine similarity.",
                    "label": 0
                },
                {
                    "sent": "But our preliminary experiments with these ideas didn't really lead to improvements in performance, but they do increase the computational cost.",
                    "label": 0
                },
                {
                    "sent": "So for the time being these things are disabled by default.",
                    "label": 0
                },
                {
                    "sent": "Chip tuning the weights will be one in Level 2 and so we had a little.",
                    "label": 0
                },
                {
                    "sent": "We mostly compared the output of our rectifier with that of another existing quickly fire and try to tune the weights so as to increase the matching between them.",
                    "label": 0
                },
                {
                    "sent": "We also had one gold standard, manually annotated datasets.",
                    "label": 0
                },
                {
                    "sent": "We say a little more about evaluation later, so basically I was trying to kind of tune the weight little by little to see how it affects performance.",
                    "label": 0
                },
                {
                    "sent": "But it didn't really lead to significant improvements most of the time the changes were very small, so I decided to disable this for the time being.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So few words about the implementation.",
                    "label": 0
                },
                {
                    "sent": "The approach described here is very suitable for parallel processing, not on the level of an individual document, but on the level of multiple documents.",
                    "label": 0
                },
                {
                    "sent": "So if you have several documents, they can easily be processed in parallel because the shared data structures need only to be accessed read only, so they can easily be shared by all the threads.",
                    "label": 0
                },
                {
                    "sent": "So we have a highly parallelized implementation.",
                    "label": 0
                },
                {
                    "sent": "Another nice thing about this approach is that it can work with any language.",
                    "label": 1
                },
                {
                    "sent": "For each sufficiently large Wikipedia is available.",
                    "label": 1
                },
                {
                    "sent": "Our implementation is available online, so if anybody wants to play with it, it's freely accessible.",
                    "label": 0
                },
                {
                    "sent": "Currently handles about half a million documents per day with a total length of about 1GB, and there's still plenty of computational resources free.",
                    "label": 0
                },
                {
                    "sent": "It supports about 1:30 languages, which is all the Wikipedia, all the languages for which Wikipedia of at least 1000 pages available.",
                    "label": 1
                },
                {
                    "sent": "Now of course 1000 pages is much too small to have useful coverage.",
                    "label": 0
                },
                {
                    "sent": "So not not all of these languages are really usefully supported, but on the other hand, about 60 languages have a Wikipedia of at least 100,000 pages, which can already be useful for at least some purposes.",
                    "label": 1
                },
                {
                    "sent": "And optionally, identifier can return class memberships from wiki data or the DVD ontologies for possibly some further processing.",
                    "label": 0
                },
                {
                    "sent": "There are also some other functionalities that I won't mention at this point.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "To conclude, with a small evaluation we found there isn't really a terrible wealth of suitable datasets for this sort of evaluation.",
                    "label": 0
                },
                {
                    "sent": "We use this set of manually annotated news articles that was originally prepared by the authors of the either Wiki fire.",
                    "label": 1
                },
                {
                    "sent": "So the way we can compare them with simply, we look at this set of annotations so document concept pairs for all the documents in the datasets, and when you have these two sets for two different wiki fires or for one week.",
                    "label": 1
                },
                {
                    "sent": "In the gold standard, we can compute things like precision, recall the F measure, and so forth.",
                    "label": 0
                },
                {
                    "sent": "So here's a little matrix.",
                    "label": 0
                },
                {
                    "sent": "So here we have the gold standard, and various wiki fires, and the F measure that compares how well they match.",
                    "label": 0
                },
                {
                    "sent": "So we see that comparing to the gold standard, we are not quite as good as the other wiki fire, but we're relatively close and the others are much worse.",
                    "label": 0
                },
                {
                    "sent": "But what I also found very interesting was that the matches the matching between the agreement between the different wiki fires is relatively low.",
                    "label": 0
                },
                {
                    "sent": "No matter which pair of wiki fires you look at, so I think on average I think the the lesson learned from this is that we could we fication is a is a relatively vaguely defined task.",
                    "label": 0
                },
                {
                    "sent": "You know there's this idea.",
                    "label": 0
                },
                {
                    "sent": "OK, we want to annotate a document with relevant concepts, but which concepts are actually relevant?",
                    "label": 0
                },
                {
                    "sent": "And it turns out that different people have different ideas about that might depend on your application and so forth, so that different wiki fires are actually doing relatively different things, and it's hard to compare.",
                    "label": 0
                },
                {
                    "sent": "It also means that comparison to a gold standard is likewise perhaps somewhat problematic.",
                    "label": 0
                },
                {
                    "sent": "This you're using, I would guess much more updated Wikipedia set of links than the original authors of the gold standard annotation set, probably somewhat more up-to-date.",
                    "label": 0
                },
                {
                    "sent": "Yeah, there are going to be more links probably than they were at that time that you're actually penalizing yourself more in the evaluation should could be could be, yeah.",
                    "label": 0
                },
                {
                    "sent": "In the Wikipedia dump from the time that they were annotating right?",
                    "label": 0
                },
                {
                    "sent": "Then you might have a fairer or you might have a better evaluation for yourself at a more representative.",
                    "label": 0
                },
                {
                    "sent": "Yeah, true, true true.",
                    "label": 0
                },
                {
                    "sent": "I think it also depends on what your goals that you are trying to pursue are.",
                    "label": 0
                },
                {
                    "sent": "For example, in our Wiki fire, at least initially, the emphasis was kind of moron thinking about recall, not so much about precision, and I think maybe some of these others focused a little more in precision, so that also kind of affects the output and so forth.",
                    "label": 0
                },
                {
                    "sent": "Some of them, I think, deliberately tried to avoid.",
                    "label": 0
                },
                {
                    "sent": "Things which aren't named entities and so forth.",
                    "label": 0
                },
                {
                    "sent": "So as I said, different people have different ideas as to what exactly counts is relevant.",
                    "label": 0
                },
                {
                    "sent": "The documents also were generated at that point and also they don't mention penciler.",
                    "label": 0
                },
                {
                    "sent": "Yeah, I think that was his idea that we are kind of having a harder job because we have a more recent Wikipedia and it might confuse us in ways that it wouldn't confuse the original authors.",
                    "label": 0
                },
                {
                    "sent": "There might be something today.",
                    "label": 0
                },
                {
                    "sent": "Yeah, and I think that.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Yeah, so OK. Just to conclude.",
                    "label": 0
                },
                {
                    "sent": "So we have an efficient and highly parallel implementation based on a global page rank based disambiguation.",
                    "label": 1
                },
                {
                    "sent": "We have some ideas on future extensions and some are actually in progress.",
                    "label": 0
                },
                {
                    "sent": "So one idea is to allow the user to define a set of pages or categories that should be completely ignored when processing the Wikipedia.",
                    "label": 1
                },
                {
                    "sent": "Another is to allow users to define additional sets of annotations not really related to the Wikipedia that can be provided as additional annotations.",
                    "label": 0
                },
                {
                    "sent": "This is already partly implemented in some people.",
                    "label": 0
                },
                {
                    "sent": "To use it.",
                    "label": 1
                },
                {
                    "sent": "In their projects there are also some ideas that I already mentioned about combining local and global disambiguation approaches using the context of a mention, we didn't get any improvements yet, but I think possibly some further work in that direction can be useful.",
                    "label": 0
                },
                {
                    "sent": "Perhaps instead of using just plain bag of words to compare the context, we could use the word to vector some similar representation and.",
                    "label": 0
                },
                {
                    "sent": "The rules have some ideas about how to handle small languages, languages for which Wikipedia does not have sufficient coverage.",
                    "label": 0
                },
                {
                    "sent": "So maybe one idea was to use the links simply from other language Wikipedias to generate candidate annotations, and they won't really match up perfectly well, but they might match approximately, and for this to work we would need to combine the link graphs of different language Wikipedias into one common link graph, which can be done using the cross language information in the Wiki data Ontology.",
                    "label": 0
                },
                {
                    "sent": "So we are in that I think, concludes my presentation.",
                    "label": 0
                },
                {
                    "sent": "Thank you, thank you.",
                    "label": 0
                }
            ]
        }
    }
}