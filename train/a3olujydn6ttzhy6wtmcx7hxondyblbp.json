{
    "id": "a3olujydn6ttzhy6wtmcx7hxondyblbp",
    "title": "Concurrent classification of EL ontologies",
    "info": {
        "author": [
            "Yevgeny Kazakov, University of Ulm"
        ],
        "published": "Nov. 25, 2011",
        "recorded": "October 2011",
        "category": [
            "Top->Computer Science->Semantic Web->Ontologies"
        ]
    },
    "url": "http://videolectures.net/iswc2011_kazakov_classification/",
    "segmentation": [
        [
            "I'm going to speak about concurrent classification of your ontologies, and this is a joint work with Mark Marcus Crouch and Franciszek Semantic from the University of Oxford.",
            "So this work is."
        ],
        [
            "About classification of ontologists and well ontology classification is one of them.",
            "Key reasoning task for ontology development.",
            "And it is usually used as follows.",
            "So.",
            "Ontology developer.",
            "Works with ontology editors in order to express the domain of his that he is focused on and use ontology reasoner talk to produce hierarchical representation of the classes and this is called taxonomy and taxonomy is.",
            "Are used to assess the quality of the ontology so intelligent development inspects the taxonomy and makes necessary changes adjustment in the ontology and then repeats the whole process.",
            "So the reason are which is a part of this ontology.",
            "Development cycle is actually one of the key part of this ontology development cycle.",
            "It is allowing to classify the ontologies and the performance of the reasoner is.",
            "The performance of there is another is essential for.",
            "For.",
            "I'm making this whole process as most as possible, right?",
            "So there is a need to improve the performance of the reason that and I'm going to speak about one particular methods of how to improve."
        ],
        [
            "So how can one improve the classification process for ontologies?",
            "So one possibility would be to optimize the underlying algorithm, which is just Fanta logical suffocations.",
            "And there were several papers on this topics covering techniques such as locking, caching, dynamic Victor, backtracking, absorption, absorption and so on.",
            "So another approach which is will be the topic of this talk is to reduce the time span of computations by doing several.",
            "Operations in parallel.",
            "That this concurrently.",
            "So."
        ],
        [
            "What is the state of the art of the on this topic?",
            "So there are lots of actually papers on distributel concurrent reasoning over the data.",
            "Well, the topic of the stocks are are trying to cope with billions of instances, yes, so the one distinguishing feature which are not which couldn't be processed in one computer in there because they just don't fit into memory on one computer and therefore they require a clusters of computer to be processed.",
            "And, well, the difference is that between this works in what I'm trying to present here is that the schema languages are usually quite weak, so there.",
            "Instances of like PPD star or RDF S or sparkle right so I'm going to speak about more expressive languages with schema languages is more expressive, right?",
            "So in this area there were also many works on optimizing existing many tableau based procedures and book the works.",
            "Our techniques, such as ontology partitioning, so this is a kind of pay and the divide and conquer strategy.",
            "When ontology is divided on several parts which can be processed in parallel.",
            "But realizing non terministic branches in Tableau Reasoners.",
            "Eloquest construction of taxonomies distributed resolution, so the resolution techniques how it can work distributively and MapReduce approach for year.",
            "So there were several works, but unfortunately none of them has resulted in seems to be the menu reasoner because now existing reasoners make use actually of multicore multiprocessor systems right?",
            "But there is actually one reason and I'm going to present it now and we stop.",
            "OK, so.",
            "No so."
        ],
        [
            "What is our approach so our approach is based on the consequences based reasoning procedures, so these are new kind of of procedures which are distinguished from more conventional traditional tableau or model building procedures are used in the majority of prisoners.",
            "Is that they don't work by building models, but they work by deriving knew consequences sub axioms from the given ones using a dedicated inference rules.",
            "For example, given two subsumption.",
            "A substance by BB subsumed by C1 can infer.",
            "A new subscription is subsumed by sea or it's more complicated through with existentialist fiction they subsume exists GBB, subsume C exists RC subsumed by D, then a subsumed by the right.",
            "So the way such knew kinds of classification procedures were first introduced for the family of lightweight polynomial description logiciel.",
            "But recently it has been extended.",
            "The more expressive languages, such as horn shake and else so and our parallel based approach will be used on this kind of algorithm.",
            "So what is this distinguished features of these procedures?",
            "So distinguished properties are that these procedures are theoretically optimal, so they have the same worst case complexity as theoretical complexity.",
            "There often usually goal directed they have so-called pacey gold property, which means that if one restricts the procedure.",
            "The less expressive fragmente such as El, then they will reflect the complexity of this fragment.",
            "For example, if one restricts the procedure for horn shake or else to the L fragmente, then there will be polynomial, even if they're not polynomial in in general case.",
            "So now one additional new listings property will be that it is quite.",
            "I will show you that it's quite easy to make them parallel.",
            "So to turn them into concurrent procedures?",
            "OK, so what's the main idea of the approach?"
        ],
        [
            "So.",
            "This is a language that I will focus specifically in this talk.",
            "It's called ELH and these are all the inference rules.",
            "Consequences based insurance wholesalers and used in this language so you don't need to understand them all well.",
            "The main idea is that there are some initialization there also which introduce some previous assumption implies a subsumed by A4 atomic classes and there are rules for dealing with the constructors.",
            "So there is a rule for eliminating conjunctions here and introduce introducing conjunction here.",
            "And there is a role for existential restriction, again elimination and introducing and there is a rule that takes care.",
            "Of.",
            "Concept includes next human and there is a rule that takes care of Rd including maximum, so it's not very important how they work just well.",
            "Main thing is that there are not many of them right so."
        ],
        [
            "So how this this inference system can be implemented so well?",
            "It's not that difficult to implement them, so their implementation is typically a kind of.",
            "The same way for valuation of Datalog program, so it's it resembles the forward chaining rules right applications.",
            "So usually operate with two sets of axioms, one as a set of process axioms, another scheduled actions.",
            "So they said the processors are auto section between which between each the infinites already made.",
            "And the scheduled axiom, the axioms for which there's some inferences, are not made yet, right?",
            "So?",
            "And how would I set of axioms in saturated, well, all initial axioms?",
            "All initial axioms I put in this into the schedule Schedule Q and initially the process queue is empty, right?",
            "And then the following is repeated so.",
            "One takes the scheduled exeo."
        ],
        [
            "And mostly to the set of the process axiom."
        ],
        [
            "And perform inference is where the process takes."
        ],
        [
            "And what's the result and the scheduled Q?"
        ],
        [
            "And then continues like that, right?",
            "So the set of process axioms."
        ],
        [
            "Escape Escape duplicate free."
        ],
        [
            "So the infinite sum it only if a new axiom has been."
        ],
        [
            "Edit right so in this case."
        ],
        [
            "In some way.",
            "And in case there are some schedule text."
        ],
        [
            "Is already there?"
        ],
        [
            "No inference is made, right?"
        ],
        [
            "So on this pro."
        ],
        [
            "This is repeated."
        ],
        [
            "Yes they are."
        ],
        [
            "Bill."
        ],
        [
            "There is no scheduled axiom anymore."
        ],
        [
            "Right, so it's quite easy to show the correctness of this out."
        ],
        [
            "So it consists of three steps, soundness, completeness and termination.",
            "So soundness is shown that by using the property that only conclusions of inference is actually added to the set, right, there is no way one can at any other action.",
            "Completeness is a consequence of the fact that all inferences between processed axioms are made.",
            "So in the end, all actions are processed.",
            "It means that all the differences between the Axiom Summit so in termination is a bit more complicated, but it is a consequence of two invariances that either the process set increases so new axioms held in the process set, and since it is kept duplicate free, this process should be terminated in there or the set of scheduled axiom is decreasing, but the set of process axioms remains the same.",
            "OK, so this is how correctness works.",
            "So now the question of is it possible to make this?",
            "Make this procedure parallel OK, so actually there is no problem in that, so we can."
        ],
        [
            "Just add another worker which basically would do."
        ],
        [
            "The same operations, so we take first work."
        ],
        [
            "I will take the first element in the schedule.",
            "Kill second worker will."
        ],
        [
            "Text next element will folks."
        ],
        [
            "Worker will process the information, the inferences and adds to the Schedule cube back."
        ],
        [
            "So the second worker work."
        ],
        [
            "At the same time, so the most workers I mean."
        ],
        [
            "Connection."
        ],
        [
            "You can access the process scheduled actions at the same time."
        ],
        [
            "No problem and the."
        ],
        [
            "Correctness of the algorithm."
        ],
        [
            "Remains the same with the proof of correctness, right?",
            "And you can see that it has to."
        ],
        [
            "We made it much faster than on the previous slide, right?",
            "So, but although it looks quite simple in theory, yes there are some practical.",
            "Dizzy."
        ],
        [
            "So one problem is that implementing this procedure would require concurrent operations with shared data structure, because you can see that it can happen that one worker takes Nexium in the schedule queue at the same time.",
            "One another work is inserting element right?",
            "So this requires concurrent data structure.",
            "Well, this is not very complicated to implement with the queue, so we can just have a concurrent."
        ],
        [
            "But it's more tricky when to.",
            "The workers are insert inserting elements at the same time into the schedule in the set of process section.",
            "Because you need to keep this set, duplicate three so init user is usually implemented by blocking access to the sets right?",
            "But the main point is that.",
            "If one uses locking every time for accessing the set for inserting elements, then this kind of defeats the whole purpose of prioritization, 'cause then workers should work one after each other, right?",
            "So they cannot access an insert elements in the process queue at the same time.",
            "So what one can do?"
        ],
        [
            "So one can do a bit smarter thing, right?",
            "One can partition the set of X amount of sets like for the workers we have partition and a set of action and to the set one which is which will call context and set two which is called context and then perform influences on onto the on these two sets independently right?",
            "So the first set contains section 134.",
            "Another one is the 2 four so.",
            "No, that is not the partitioning, so it's the axiom.",
            "#4 belongs to both of these sets, right?",
            "So the only requirement about this?",
            "Assignment of exam not partitioning, but as I'm in the exam is that whenever an inference is possible between premises of axioms then at least one context should be assigned to both of the premises, right?",
            "This is the main requirement so that it works correctly, so not no inferences made is missed."
        ],
        [
            "Right, so how does work?",
            "So the workers are working with corresponding context sets, so they."
        ],
        [
            "They can insert to the set of the process and the corresponding set of the processed elements."
        ],
        [
            "They can access the queue."
        ],
        [
            "At the same time, so the same queue at the same time, it's it's.",
            "It's not a problem for the cure.",
            "As I said, it's a problem."
        ],
        [
            "Right?"
        ],
        [
            "OK, so and.",
            "Well."
        ],
        [
            "And.",
            "Everything works as before, so each worker is working on it with the with the corresponding set and can insert anywhere.",
            "Into the set of the process.",
            "Here, according to the for this partitioning assignment."
        ],
        [
            "So."
        ],
        [
            "And OK."
        ],
        [
            "Works fine when we have two dedicated dedicated partitions for the workers.",
            "Alright, well, but in practice what can you do if you have more than two partitions?",
            "So if you have more than two workers and the number of partitions don't correspond to the number of workers, how to improve?"
        ],
        [
            "And this procedure.",
            "So the bigger picture looks as follows, so have.",
            "Partitioning of axioms according to the context 1234, we have say, let's say three workers.",
            "So how the procedure implemented?",
            "The KD is based on the notion of an active con."
        ],
        [
            "Context, right?",
            "So Aquatics is not active if it has at least one axiom and the non processed queue right?",
            "So into this in the schedule queue, right?",
            "This three context I active because they have none empty schedule Q, But this this is not active 'cause it's already processed.",
            "All exams are over processed right?"
        ],
        [
            "And in the beginning we keep just another queue which collects the which contains all active context right?",
            "So and then the procedure works as well as so."
        ],
        [
            "Idle worker Fix the head element of the."
        ],
        [
            "Still starts working with the corresponding."
        ],
        [
            "Context right so?"
        ],
        [
            "All three workers"
        ],
        [
            "Working with the context so there is no element in the active queue anymore."
        ],
        [
            "So while working they can insert elements into other contexts, right?",
            "E and the context can be activated like in."
        ],
        [
            "This case it was not active before.",
            "Now is active and it is.",
            "It should be inserted in this case and the set of into the queue of active context, right?",
            "So new context can be created if if one axiom is insert for the first time, right?",
            "So when the worker is."
        ],
        [
            "On processing some context like this one, it takes the next one."
        ],
        [
            "And the active cure and stock price."
        ],
        [
            "Sing it and well, that process continues and becausw the queue is maintained.",
            "Duplicate three.",
            "It is ensure that no work is processing the same context and at the same time so we don't need to use concurrent thread safe data structures.",
            "We can use normal.",
            "Data structure for sets right?",
            "OK, so."
        ],
        [
            "This is the basic idea.",
            "And we have implemented this algorithm."
        ],
        [
            "OK, so one last point is that.",
            "Well, this is on the high level, but how we do the context assignment?"
        ],
        [
            "Our specifically for our logic laj, so one the easiest solution would be just to sign.",
            "So recall that we need to.",
            "We need to ensure that whenever an inference is possible between two axioms, then both of them will have at least one contexts assigned.",
            "In common right?",
            "So the easiest way to fulfill this obligation is to assign.",
            "Assign to every axiom this set of inference rules where they sent this axiom can participate.",
            "For example, if we have this axiom SIM plus the one and detail right, we can assign.",
            "A context conjunction so it can participate in influence and with conjunction.",
            "But also it can participate and influence with this inference because it can be used as this premise of this premise.",
            "So it will be assigned and this as well.",
            "And this is well, OK.",
            "But not this, and not this.",
            "If you wanted you to another equivalency, right?",
            "But this is not very good strategy because it will result in not many very many different contexts and it will result in that sometimes some workers can can can start because there is no job for them available, right?"
        ],
        [
            "So I better stretch it.",
            "They said that you will be as follows.",
            "So look note that in every premises of the rules we can have a common context, common concepts within axioms.",
            "So the premise premises available Rd will share one.",
            "Share one common concept so and what we can do is we can assign to every axiom context that concept that matches this respective position right?",
            "And this is what we actually implemented and there are lots of different contexts, so it works in practice.",
            "Well, so the workers don't starve, so they have all this job to do."
        ],
        [
            "So we haven't implemented this algorithm, and to the system called Elk Elk regional and is a Java based reasoner Ann, we are planning to support all to your profile well and this is the URL which you should take a look.",
            "And it is available for free and open source and under Apache 2 license.",
            "Currently today we are releasing the version 0.2 which supports fragment of El Howell profile that corresponds to the deal here plus and has features such as conjunction, existential restriction at all chains and well it has a binding for all API Protege plugin.",
            "It is developed in my Maven an it works with this normal city and it can be used in snow owl.",
            "So the development environment for developing a snowstorm in city."
        ],
        [
            "So this experiment results with help, so we have experience with tested.",
            "The usually learned ologist that are usually used for testing ontology reasoners.",
            "It's not mad City gallon fman genealogy, so most interesting is the first column.",
            "The largest ontology is normal city which contains about 300,000 concepts right?",
            "And we can see that.",
            "Well this is the result for elk.",
            "With several workers for one to four with based on the work or machine right?",
            "And we can see that already for one work here we have best in class performance, so the closest one is the performance of CB and the performance improves when we add more workers.",
            "So you can classify an ontology and it's less is 5 seconds right?",
            "But rather than showing you this table I guess.",
            "It will be much better if I will show you how.",
            "How does it run?"
        ],
        [
            "Pick 'em so this is Roger and I loaded the anthologist now at City with all these 300,000 classes.",
            "So if I choose the reasoner elk.",
            "Well, they make sure that they just.",
            "Right?",
            "I can start the classification, So what is in the beginning is happening.",
            "It loads the whole ontology to the reasoner, right?",
            "And then classifieds that?",
            "And in the experimental results, we measured only the classification stage, which is here and I'll show you why.",
            "So the developer will usually load anthology once and then continue editing this anthology.",
            "So whenever, whenever.",
            "I mean everything is done, so I'm so this is classification is done in 1.",
            "One can now browse this class taxonomy here.",
            "Yeah, so this is what ontology editor usually inspects.",
            "And yes, when ontology editor make some changes with ontology or my mixer.",
            "Is it change I delete something?",
            "This will this cause deleting some actions.",
            "OK, and I reclassified ontology so you see notice that doesn't load it anymore.",
            "'cause L supports dynamic loading.",
            "Dynamic updates of ontologists so it only.",
            "Make some changes and of adding removal of axioms and the time spent here is menu on the classification and not loading as you notice that I mean it's it's already done so it's quite fast.",
            "OK, so.",
            "I continue with a bit more.",
            "Of experimental results.",
            "So this is a comparison of speed up.",
            "So we experimented with more than four cores.",
            "More than four workers and so on the server and on a laptop environment.",
            "So lot on laptop we have Quad core computer with two gigabytes into four I7 processors and on a desktop we have the dual Quad core Intel Xeon processor processor, right?",
            "So you can see that.",
            "So this graph represents the timings for gallon and snowmelt city, so gallons will be smaller.",
            "Ontology and you can see that the.",
            "Classification times improve in most of this.",
            "I mean in both scenarios for laptop and for the server, but the improvement is not as dramatical when it hits for workers, right?",
            "On on the laptop because it has only four cores, but it can still improve on the server which has more than four processors or similar picture can be observed personal city, but the improvement is not linear of course, and there are several reasons for that.",
            "So because for example with one core processor running in higher Clock usually then with several cores.",
            "Well in process.",
            "I. I mean.",
            "To assess the scalability issues, so we also compared."
        ],
        [
            "Our approach, with the ideal embarrassingly parallel scenario, as it usually called, is that we took several copies of ontology gallium right, and we classify them separately, and we compare the result of classification.",
            "The Times for the classification with the classification of elk on the whole ontology with N copies, right?",
            "And we can see that well that I'm the times grows with the number of copies, so this is the number of copies SO123 and up to 8 ontologies.",
            "Just copy, it was renamed classes right?",
            "So we created anthology which is 8 times larger than the original 1, right?",
            "So ideally the classification time should stay the same, at least if you have 8 cores, but in practice it will grow for this for the same reasons that I mentioned, because the processor is not as effective when it has a larger load.",
            "Right, but what important is important?",
            "What can be observed in this picture?",
            "Is that the difference between paper ship partition scenario.",
            "So when we manually partitioned ontology and then classify them independently but in parallel on parallel workers working parallel sets without interaction whatsoever is more or less the same as in our approach.",
            "So which means that our approach works as effective as pre partitioning approach?",
            "OK, so that thing I think I'm finished with that.",
            "I don't have anymore slice.",
            "So I start with one.",
            "Can I go to slide seven there again just sorry now, but I was a bit confused about was that."
        ],
        [
            "This look like no OK, but it's the the one where you had two workers basically.",
            "So it seems like to me that the two workers can kind of consume to schedule the axioms kind of concurrently.",
            "So where is then the the communication happening between?",
            "Is there any communication happening between the two workers?",
            "If they consume two things which can basically, so it's it's, it's not a communication concurrency, it's a shared memory concurrency.",
            "So what workers can access the shared?",
            "Shared state set of actions.",
            "While they can both read and write into them.",
            "So in this in this scenario, so while they process this scheduled two scheduled exams, they can still both access those.",
            "Yes in principle, but it is organized such that I mean the first whenever the worker processing scheduling axiom then it takes it from the queue and it's no longer there, right?",
            "So if these takes control the queue, it's no longer there, so the next one can take only the next one, so there will not be processing.",
            "The same maximum at the same time.",
            "So every work is processing a different exam.",
            "Because it's secure, you can take only once the head of the queue.",
            "So that it can happen that they kind of process that they there are two exams which are invisible, basically mutually to each other, which could together fire rewriting or.",
            "Which can fire was just wondering.",
            "I didn't really get that.",
            "I can I can repeat it complete, then I can repeat the example.",
            "So the first worker takes the first scheduled axiom, moves it to the set of the Pro section at the same time the 2nd work we can set, take the second scheduled actions.",
            "Most of the process actions, while in the first worker will process and then put there.",
            "It's already seen by the OK.",
            "I would like to ask a clarification, but the way I like very much this work.",
            "So I see two new things here that could have improved your.",
            "It could be the justification of the improvement of the performance and the fact that the user kind of natural deduction or forward reasoning rules and the fact that you partition the axioms.",
            "So I'm wondering who like to understand if if just applying the partition of the axioms in as you have done and you in parallel apply that the flow of the standard blowup algorithm you obtain similar results, or it's also because we use this type of rules.",
            "That you have this improvement.",
            "Well, the tabloids get its work completely differently here.",
            "And of course, the improvement is largely attributed, but by the calculus, because I mean, for this fragment, the calculus is polynomial while it is specifically tailored for this fragments.",
            "That's why it's more efficient, but we wanted to go beyond that.",
            "We wanted to make it even more efficient, so as if I scroll on this.",
            "Cable weather"
        ],
        [
            "Results.",
            "You can see that all the calculus in case of just one worker, not concurrent version, is already outperforming the tableau based Reasoner, which is basically effect plus plus pilot.",
            "We should be home in somewhere.",
            "I think Kermit couldn't process.",
            "It's not me.",
            "That's why it's not here.",
            "So they're outperforming Tableau based reasoners already.",
            "This is blood out through the new kind of calculus consequence based.",
            "And we can improve further more by making the procedure concurrent so we can reduce considerably the classification time even beyond that.",
            "OK, one more questions about technical.",
            "You said the process taxim should be duplicate free, but now you have the different context and each context had list of processed axioms.",
            "Do you have to keep them duplicate free across context or is it just?",
            "Duplicate free within one context.",
            "No, it's only duplicate free within each context, that's OK.",
            "So it's it's easy.",
            "You don't have to look over all the context all the time.",
            "That's the main reason, yeah.",
            "We don't want do we just don't want to miss the inference that's our Member.",
            "Maybe we can derive several axioms twice, but as long as we can read out the result of the classification from that, it's not the problem and it actually doesn't happen very often.",
            "It doesn't happen at all.",
            "I think in our calculus or and I mean, one can argue that there are some things that can be inefficient because of that, because some axioms can be copied into several contexts.",
            "But actually this is not the case, be cause.",
            "This is happening because one axioms can participate in several inference rules, and for each entrance rules one would have to index them anyway into different ways, so we don't actually copy the axioms as they are.",
            "We could just pointers to this excellent actually keep the pointers in such a way how they can be used in this specific situations with the influences on again on this technical side.",
            "I don't understand if the processor who process and generate a new axiom.",
            "If these are some is stored in the context associated to the processor or it is distributed across the other context as well.",
            "Becauses in the first case you have a kind of property of your calculus, you have to rely on the property of your concludes that the new action generated in one context are not relevant for the other context or so."
        ],
        [
            "If you can clarify on this, I guess this clarifies that, so you.",
            "So several workers can concert at the same time into the same context, but that's not a problem because it's a queue and it's easy to have a queue concurrent so you don't care about the duplicate.",
            "Duplications in the queue.",
            "Right?",
            "It's more difficult if several workers with insert in the set, in which case, in which case you need to keep the set duplicate free, and this is usually done using locking."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I'm going to speak about concurrent classification of your ontologies, and this is a joint work with Mark Marcus Crouch and Franciszek Semantic from the University of Oxford.",
                    "label": 0
                },
                {
                    "sent": "So this work is.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "About classification of ontologists and well ontology classification is one of them.",
                    "label": 1
                },
                {
                    "sent": "Key reasoning task for ontology development.",
                    "label": 0
                },
                {
                    "sent": "And it is usually used as follows.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Ontology developer.",
                    "label": 0
                },
                {
                    "sent": "Works with ontology editors in order to express the domain of his that he is focused on and use ontology reasoner talk to produce hierarchical representation of the classes and this is called taxonomy and taxonomy is.",
                    "label": 0
                },
                {
                    "sent": "Are used to assess the quality of the ontology so intelligent development inspects the taxonomy and makes necessary changes adjustment in the ontology and then repeats the whole process.",
                    "label": 0
                },
                {
                    "sent": "So the reason are which is a part of this ontology.",
                    "label": 0
                },
                {
                    "sent": "Development cycle is actually one of the key part of this ontology development cycle.",
                    "label": 0
                },
                {
                    "sent": "It is allowing to classify the ontologies and the performance of the reasoner is.",
                    "label": 0
                },
                {
                    "sent": "The performance of there is another is essential for.",
                    "label": 0
                },
                {
                    "sent": "For.",
                    "label": 0
                },
                {
                    "sent": "I'm making this whole process as most as possible, right?",
                    "label": 0
                },
                {
                    "sent": "So there is a need to improve the performance of the reason that and I'm going to speak about one particular methods of how to improve.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So how can one improve the classification process for ontologies?",
                    "label": 0
                },
                {
                    "sent": "So one possibility would be to optimize the underlying algorithm, which is just Fanta logical suffocations.",
                    "label": 0
                },
                {
                    "sent": "And there were several papers on this topics covering techniques such as locking, caching, dynamic Victor, backtracking, absorption, absorption and so on.",
                    "label": 0
                },
                {
                    "sent": "So another approach which is will be the topic of this talk is to reduce the time span of computations by doing several.",
                    "label": 1
                },
                {
                    "sent": "Operations in parallel.",
                    "label": 0
                },
                {
                    "sent": "That this concurrently.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "What is the state of the art of the on this topic?",
                    "label": 1
                },
                {
                    "sent": "So there are lots of actually papers on distributel concurrent reasoning over the data.",
                    "label": 0
                },
                {
                    "sent": "Well, the topic of the stocks are are trying to cope with billions of instances, yes, so the one distinguishing feature which are not which couldn't be processed in one computer in there because they just don't fit into memory on one computer and therefore they require a clusters of computer to be processed.",
                    "label": 1
                },
                {
                    "sent": "And, well, the difference is that between this works in what I'm trying to present here is that the schema languages are usually quite weak, so there.",
                    "label": 0
                },
                {
                    "sent": "Instances of like PPD star or RDF S or sparkle right so I'm going to speak about more expressive languages with schema languages is more expressive, right?",
                    "label": 0
                },
                {
                    "sent": "So in this area there were also many works on optimizing existing many tableau based procedures and book the works.",
                    "label": 0
                },
                {
                    "sent": "Our techniques, such as ontology partitioning, so this is a kind of pay and the divide and conquer strategy.",
                    "label": 0
                },
                {
                    "sent": "When ontology is divided on several parts which can be processed in parallel.",
                    "label": 0
                },
                {
                    "sent": "But realizing non terministic branches in Tableau Reasoners.",
                    "label": 1
                },
                {
                    "sent": "Eloquest construction of taxonomies distributed resolution, so the resolution techniques how it can work distributively and MapReduce approach for year.",
                    "label": 0
                },
                {
                    "sent": "So there were several works, but unfortunately none of them has resulted in seems to be the menu reasoner because now existing reasoners make use actually of multicore multiprocessor systems right?",
                    "label": 0
                },
                {
                    "sent": "But there is actually one reason and I'm going to present it now and we stop.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "No so.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "What is our approach so our approach is based on the consequences based reasoning procedures, so these are new kind of of procedures which are distinguished from more conventional traditional tableau or model building procedures are used in the majority of prisoners.",
                    "label": 1
                },
                {
                    "sent": "Is that they don't work by building models, but they work by deriving knew consequences sub axioms from the given ones using a dedicated inference rules.",
                    "label": 0
                },
                {
                    "sent": "For example, given two subsumption.",
                    "label": 0
                },
                {
                    "sent": "A substance by BB subsumed by C1 can infer.",
                    "label": 0
                },
                {
                    "sent": "A new subscription is subsumed by sea or it's more complicated through with existentialist fiction they subsume exists GBB, subsume C exists RC subsumed by D, then a subsumed by the right.",
                    "label": 1
                },
                {
                    "sent": "So the way such knew kinds of classification procedures were first introduced for the family of lightweight polynomial description logiciel.",
                    "label": 0
                },
                {
                    "sent": "But recently it has been extended.",
                    "label": 1
                },
                {
                    "sent": "The more expressive languages, such as horn shake and else so and our parallel based approach will be used on this kind of algorithm.",
                    "label": 0
                },
                {
                    "sent": "So what is this distinguished features of these procedures?",
                    "label": 0
                },
                {
                    "sent": "So distinguished properties are that these procedures are theoretically optimal, so they have the same worst case complexity as theoretical complexity.",
                    "label": 0
                },
                {
                    "sent": "There often usually goal directed they have so-called pacey gold property, which means that if one restricts the procedure.",
                    "label": 0
                },
                {
                    "sent": "The less expressive fragmente such as El, then they will reflect the complexity of this fragment.",
                    "label": 0
                },
                {
                    "sent": "For example, if one restricts the procedure for horn shake or else to the L fragmente, then there will be polynomial, even if they're not polynomial in in general case.",
                    "label": 0
                },
                {
                    "sent": "So now one additional new listings property will be that it is quite.",
                    "label": 0
                },
                {
                    "sent": "I will show you that it's quite easy to make them parallel.",
                    "label": 0
                },
                {
                    "sent": "So to turn them into concurrent procedures?",
                    "label": 0
                },
                {
                    "sent": "OK, so what's the main idea of the approach?",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "This is a language that I will focus specifically in this talk.",
                    "label": 0
                },
                {
                    "sent": "It's called ELH and these are all the inference rules.",
                    "label": 0
                },
                {
                    "sent": "Consequences based insurance wholesalers and used in this language so you don't need to understand them all well.",
                    "label": 0
                },
                {
                    "sent": "The main idea is that there are some initialization there also which introduce some previous assumption implies a subsumed by A4 atomic classes and there are rules for dealing with the constructors.",
                    "label": 0
                },
                {
                    "sent": "So there is a rule for eliminating conjunctions here and introduce introducing conjunction here.",
                    "label": 0
                },
                {
                    "sent": "And there is a role for existential restriction, again elimination and introducing and there is a rule that takes care.",
                    "label": 0
                },
                {
                    "sent": "Of.",
                    "label": 0
                },
                {
                    "sent": "Concept includes next human and there is a rule that takes care of Rd including maximum, so it's not very important how they work just well.",
                    "label": 0
                },
                {
                    "sent": "Main thing is that there are not many of them right so.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So how this this inference system can be implemented so well?",
                    "label": 0
                },
                {
                    "sent": "It's not that difficult to implement them, so their implementation is typically a kind of.",
                    "label": 0
                },
                {
                    "sent": "The same way for valuation of Datalog program, so it's it resembles the forward chaining rules right applications.",
                    "label": 0
                },
                {
                    "sent": "So usually operate with two sets of axioms, one as a set of process axioms, another scheduled actions.",
                    "label": 0
                },
                {
                    "sent": "So they said the processors are auto section between which between each the infinites already made.",
                    "label": 0
                },
                {
                    "sent": "And the scheduled axiom, the axioms for which there's some inferences, are not made yet, right?",
                    "label": 0
                },
                {
                    "sent": "So?",
                    "label": 0
                },
                {
                    "sent": "And how would I set of axioms in saturated, well, all initial axioms?",
                    "label": 0
                },
                {
                    "sent": "All initial axioms I put in this into the schedule Schedule Q and initially the process queue is empty, right?",
                    "label": 0
                },
                {
                    "sent": "And then the following is repeated so.",
                    "label": 0
                },
                {
                    "sent": "One takes the scheduled exeo.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And mostly to the set of the process axiom.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And perform inference is where the process takes.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And what's the result and the scheduled Q?",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then continues like that, right?",
                    "label": 0
                },
                {
                    "sent": "So the set of process axioms.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Escape Escape duplicate free.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the infinite sum it only if a new axiom has been.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Edit right so in this case.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In some way.",
                    "label": 0
                },
                {
                    "sent": "And in case there are some schedule text.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is already there?",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "No inference is made, right?",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So on this pro.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is repeated.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Yes they are.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Bill.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "There is no scheduled axiom anymore.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Right, so it's quite easy to show the correctness of this out.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So it consists of three steps, soundness, completeness and termination.",
                    "label": 0
                },
                {
                    "sent": "So soundness is shown that by using the property that only conclusions of inference is actually added to the set, right, there is no way one can at any other action.",
                    "label": 0
                },
                {
                    "sent": "Completeness is a consequence of the fact that all inferences between processed axioms are made.",
                    "label": 0
                },
                {
                    "sent": "So in the end, all actions are processed.",
                    "label": 0
                },
                {
                    "sent": "It means that all the differences between the Axiom Summit so in termination is a bit more complicated, but it is a consequence of two invariances that either the process set increases so new axioms held in the process set, and since it is kept duplicate free, this process should be terminated in there or the set of scheduled axiom is decreasing, but the set of process axioms remains the same.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is how correctness works.",
                    "label": 0
                },
                {
                    "sent": "So now the question of is it possible to make this?",
                    "label": 0
                },
                {
                    "sent": "Make this procedure parallel OK, so actually there is no problem in that, so we can.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Just add another worker which basically would do.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The same operations, so we take first work.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I will take the first element in the schedule.",
                    "label": 0
                },
                {
                    "sent": "Kill second worker will.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Text next element will folks.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Worker will process the information, the inferences and adds to the Schedule cube back.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the second worker work.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "At the same time, so the most workers I mean.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Connection.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You can access the process scheduled actions at the same time.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "No problem and the.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Correctness of the algorithm.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Remains the same with the proof of correctness, right?",
                    "label": 0
                },
                {
                    "sent": "And you can see that it has to.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We made it much faster than on the previous slide, right?",
                    "label": 0
                },
                {
                    "sent": "So, but although it looks quite simple in theory, yes there are some practical.",
                    "label": 0
                },
                {
                    "sent": "Dizzy.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So one problem is that implementing this procedure would require concurrent operations with shared data structure, because you can see that it can happen that one worker takes Nexium in the schedule queue at the same time.",
                    "label": 0
                },
                {
                    "sent": "One another work is inserting element right?",
                    "label": 0
                },
                {
                    "sent": "So this requires concurrent data structure.",
                    "label": 0
                },
                {
                    "sent": "Well, this is not very complicated to implement with the queue, so we can just have a concurrent.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But it's more tricky when to.",
                    "label": 0
                },
                {
                    "sent": "The workers are insert inserting elements at the same time into the schedule in the set of process section.",
                    "label": 0
                },
                {
                    "sent": "Because you need to keep this set, duplicate three so init user is usually implemented by blocking access to the sets right?",
                    "label": 0
                },
                {
                    "sent": "But the main point is that.",
                    "label": 0
                },
                {
                    "sent": "If one uses locking every time for accessing the set for inserting elements, then this kind of defeats the whole purpose of prioritization, 'cause then workers should work one after each other, right?",
                    "label": 0
                },
                {
                    "sent": "So they cannot access an insert elements in the process queue at the same time.",
                    "label": 0
                },
                {
                    "sent": "So what one can do?",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So one can do a bit smarter thing, right?",
                    "label": 0
                },
                {
                    "sent": "One can partition the set of X amount of sets like for the workers we have partition and a set of action and to the set one which is which will call context and set two which is called context and then perform influences on onto the on these two sets independently right?",
                    "label": 0
                },
                {
                    "sent": "So the first set contains section 134.",
                    "label": 0
                },
                {
                    "sent": "Another one is the 2 four so.",
                    "label": 0
                },
                {
                    "sent": "No, that is not the partitioning, so it's the axiom.",
                    "label": 0
                },
                {
                    "sent": "#4 belongs to both of these sets, right?",
                    "label": 0
                },
                {
                    "sent": "So the only requirement about this?",
                    "label": 0
                },
                {
                    "sent": "Assignment of exam not partitioning, but as I'm in the exam is that whenever an inference is possible between premises of axioms then at least one context should be assigned to both of the premises, right?",
                    "label": 0
                },
                {
                    "sent": "This is the main requirement so that it works correctly, so not no inferences made is missed.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Right, so how does work?",
                    "label": 0
                },
                {
                    "sent": "So the workers are working with corresponding context sets, so they.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "They can insert to the set of the process and the corresponding set of the processed elements.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "They can access the queue.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "At the same time, so the same queue at the same time, it's it's.",
                    "label": 0
                },
                {
                    "sent": "It's not a problem for the cure.",
                    "label": 0
                },
                {
                    "sent": "As I said, it's a problem.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Right?",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so and.",
                    "label": 0
                },
                {
                    "sent": "Well.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "Everything works as before, so each worker is working on it with the with the corresponding set and can insert anywhere.",
                    "label": 0
                },
                {
                    "sent": "Into the set of the process.",
                    "label": 0
                },
                {
                    "sent": "Here, according to the for this partitioning assignment.",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_49": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And OK.",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Works fine when we have two dedicated dedicated partitions for the workers.",
                    "label": 0
                },
                {
                    "sent": "Alright, well, but in practice what can you do if you have more than two partitions?",
                    "label": 0
                },
                {
                    "sent": "So if you have more than two workers and the number of partitions don't correspond to the number of workers, how to improve?",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And this procedure.",
                    "label": 0
                },
                {
                    "sent": "So the bigger picture looks as follows, so have.",
                    "label": 0
                },
                {
                    "sent": "Partitioning of axioms according to the context 1234, we have say, let's say three workers.",
                    "label": 0
                },
                {
                    "sent": "So how the procedure implemented?",
                    "label": 0
                },
                {
                    "sent": "The KD is based on the notion of an active con.",
                    "label": 0
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Context, right?",
                    "label": 0
                },
                {
                    "sent": "So Aquatics is not active if it has at least one axiom and the non processed queue right?",
                    "label": 0
                },
                {
                    "sent": "So into this in the schedule queue, right?",
                    "label": 0
                },
                {
                    "sent": "This three context I active because they have none empty schedule Q, But this this is not active 'cause it's already processed.",
                    "label": 0
                },
                {
                    "sent": "All exams are over processed right?",
                    "label": 0
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And in the beginning we keep just another queue which collects the which contains all active context right?",
                    "label": 0
                },
                {
                    "sent": "So and then the procedure works as well as so.",
                    "label": 0
                }
            ]
        },
        "clip_55": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Idle worker Fix the head element of the.",
                    "label": 0
                }
            ]
        },
        "clip_56": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Still starts working with the corresponding.",
                    "label": 0
                }
            ]
        },
        "clip_57": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Context right so?",
                    "label": 0
                }
            ]
        },
        "clip_58": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "All three workers",
                    "label": 0
                }
            ]
        },
        "clip_59": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Working with the context so there is no element in the active queue anymore.",
                    "label": 0
                }
            ]
        },
        "clip_60": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So while working they can insert elements into other contexts, right?",
                    "label": 0
                },
                {
                    "sent": "E and the context can be activated like in.",
                    "label": 0
                }
            ]
        },
        "clip_61": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This case it was not active before.",
                    "label": 0
                },
                {
                    "sent": "Now is active and it is.",
                    "label": 1
                },
                {
                    "sent": "It should be inserted in this case and the set of into the queue of active context, right?",
                    "label": 0
                },
                {
                    "sent": "So new context can be created if if one axiom is insert for the first time, right?",
                    "label": 0
                },
                {
                    "sent": "So when the worker is.",
                    "label": 0
                }
            ]
        },
        "clip_62": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "On processing some context like this one, it takes the next one.",
                    "label": 0
                }
            ]
        },
        "clip_63": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And the active cure and stock price.",
                    "label": 0
                }
            ]
        },
        "clip_64": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Sing it and well, that process continues and becausw the queue is maintained.",
                    "label": 0
                },
                {
                    "sent": "Duplicate three.",
                    "label": 0
                },
                {
                    "sent": "It is ensure that no work is processing the same context and at the same time so we don't need to use concurrent thread safe data structures.",
                    "label": 0
                },
                {
                    "sent": "We can use normal.",
                    "label": 0
                },
                {
                    "sent": "Data structure for sets right?",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                }
            ]
        },
        "clip_65": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is the basic idea.",
                    "label": 0
                },
                {
                    "sent": "And we have implemented this algorithm.",
                    "label": 0
                }
            ]
        },
        "clip_66": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so one last point is that.",
                    "label": 0
                },
                {
                    "sent": "Well, this is on the high level, but how we do the context assignment?",
                    "label": 0
                }
            ]
        },
        "clip_67": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Our specifically for our logic laj, so one the easiest solution would be just to sign.",
                    "label": 0
                },
                {
                    "sent": "So recall that we need to.",
                    "label": 0
                },
                {
                    "sent": "We need to ensure that whenever an inference is possible between two axioms, then both of them will have at least one contexts assigned.",
                    "label": 1
                },
                {
                    "sent": "In common right?",
                    "label": 0
                },
                {
                    "sent": "So the easiest way to fulfill this obligation is to assign.",
                    "label": 0
                },
                {
                    "sent": "Assign to every axiom this set of inference rules where they sent this axiom can participate.",
                    "label": 0
                },
                {
                    "sent": "For example, if we have this axiom SIM plus the one and detail right, we can assign.",
                    "label": 1
                },
                {
                    "sent": "A context conjunction so it can participate in influence and with conjunction.",
                    "label": 0
                },
                {
                    "sent": "But also it can participate and influence with this inference because it can be used as this premise of this premise.",
                    "label": 0
                },
                {
                    "sent": "So it will be assigned and this as well.",
                    "label": 0
                },
                {
                    "sent": "And this is well, OK.",
                    "label": 0
                },
                {
                    "sent": "But not this, and not this.",
                    "label": 0
                },
                {
                    "sent": "If you wanted you to another equivalency, right?",
                    "label": 0
                },
                {
                    "sent": "But this is not very good strategy because it will result in not many very many different contexts and it will result in that sometimes some workers can can can start because there is no job for them available, right?",
                    "label": 0
                }
            ]
        },
        "clip_68": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So I better stretch it.",
                    "label": 0
                },
                {
                    "sent": "They said that you will be as follows.",
                    "label": 0
                },
                {
                    "sent": "So look note that in every premises of the rules we can have a common context, common concepts within axioms.",
                    "label": 0
                },
                {
                    "sent": "So the premise premises available Rd will share one.",
                    "label": 0
                },
                {
                    "sent": "Share one common concept so and what we can do is we can assign to every axiom context that concept that matches this respective position right?",
                    "label": 0
                },
                {
                    "sent": "And this is what we actually implemented and there are lots of different contexts, so it works in practice.",
                    "label": 0
                },
                {
                    "sent": "Well, so the workers don't starve, so they have all this job to do.",
                    "label": 0
                }
            ]
        },
        "clip_69": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we haven't implemented this algorithm, and to the system called Elk Elk regional and is a Java based reasoner Ann, we are planning to support all to your profile well and this is the URL which you should take a look.",
                    "label": 0
                },
                {
                    "sent": "And it is available for free and open source and under Apache 2 license.",
                    "label": 0
                },
                {
                    "sent": "Currently today we are releasing the version 0.2 which supports fragment of El Howell profile that corresponds to the deal here plus and has features such as conjunction, existential restriction at all chains and well it has a binding for all API Protege plugin.",
                    "label": 0
                },
                {
                    "sent": "It is developed in my Maven an it works with this normal city and it can be used in snow owl.",
                    "label": 0
                },
                {
                    "sent": "So the development environment for developing a snowstorm in city.",
                    "label": 0
                }
            ]
        },
        "clip_70": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this experiment results with help, so we have experience with tested.",
                    "label": 0
                },
                {
                    "sent": "The usually learned ologist that are usually used for testing ontology reasoners.",
                    "label": 0
                },
                {
                    "sent": "It's not mad City gallon fman genealogy, so most interesting is the first column.",
                    "label": 0
                },
                {
                    "sent": "The largest ontology is normal city which contains about 300,000 concepts right?",
                    "label": 0
                },
                {
                    "sent": "And we can see that.",
                    "label": 0
                },
                {
                    "sent": "Well this is the result for elk.",
                    "label": 0
                },
                {
                    "sent": "With several workers for one to four with based on the work or machine right?",
                    "label": 0
                },
                {
                    "sent": "And we can see that already for one work here we have best in class performance, so the closest one is the performance of CB and the performance improves when we add more workers.",
                    "label": 0
                },
                {
                    "sent": "So you can classify an ontology and it's less is 5 seconds right?",
                    "label": 0
                },
                {
                    "sent": "But rather than showing you this table I guess.",
                    "label": 0
                },
                {
                    "sent": "It will be much better if I will show you how.",
                    "label": 0
                },
                {
                    "sent": "How does it run?",
                    "label": 0
                }
            ]
        },
        "clip_71": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Pick 'em so this is Roger and I loaded the anthologist now at City with all these 300,000 classes.",
                    "label": 0
                },
                {
                    "sent": "So if I choose the reasoner elk.",
                    "label": 0
                },
                {
                    "sent": "Well, they make sure that they just.",
                    "label": 0
                },
                {
                    "sent": "Right?",
                    "label": 0
                },
                {
                    "sent": "I can start the classification, So what is in the beginning is happening.",
                    "label": 0
                },
                {
                    "sent": "It loads the whole ontology to the reasoner, right?",
                    "label": 0
                },
                {
                    "sent": "And then classifieds that?",
                    "label": 0
                },
                {
                    "sent": "And in the experimental results, we measured only the classification stage, which is here and I'll show you why.",
                    "label": 0
                },
                {
                    "sent": "So the developer will usually load anthology once and then continue editing this anthology.",
                    "label": 0
                },
                {
                    "sent": "So whenever, whenever.",
                    "label": 0
                },
                {
                    "sent": "I mean everything is done, so I'm so this is classification is done in 1.",
                    "label": 0
                },
                {
                    "sent": "One can now browse this class taxonomy here.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so this is what ontology editor usually inspects.",
                    "label": 0
                },
                {
                    "sent": "And yes, when ontology editor make some changes with ontology or my mixer.",
                    "label": 0
                },
                {
                    "sent": "Is it change I delete something?",
                    "label": 0
                },
                {
                    "sent": "This will this cause deleting some actions.",
                    "label": 0
                },
                {
                    "sent": "OK, and I reclassified ontology so you see notice that doesn't load it anymore.",
                    "label": 0
                },
                {
                    "sent": "'cause L supports dynamic loading.",
                    "label": 0
                },
                {
                    "sent": "Dynamic updates of ontologists so it only.",
                    "label": 0
                },
                {
                    "sent": "Make some changes and of adding removal of axioms and the time spent here is menu on the classification and not loading as you notice that I mean it's it's already done so it's quite fast.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "I continue with a bit more.",
                    "label": 0
                },
                {
                    "sent": "Of experimental results.",
                    "label": 0
                },
                {
                    "sent": "So this is a comparison of speed up.",
                    "label": 0
                },
                {
                    "sent": "So we experimented with more than four cores.",
                    "label": 0
                },
                {
                    "sent": "More than four workers and so on the server and on a laptop environment.",
                    "label": 0
                },
                {
                    "sent": "So lot on laptop we have Quad core computer with two gigabytes into four I7 processors and on a desktop we have the dual Quad core Intel Xeon processor processor, right?",
                    "label": 0
                },
                {
                    "sent": "So you can see that.",
                    "label": 0
                },
                {
                    "sent": "So this graph represents the timings for gallon and snowmelt city, so gallons will be smaller.",
                    "label": 0
                },
                {
                    "sent": "Ontology and you can see that the.",
                    "label": 0
                },
                {
                    "sent": "Classification times improve in most of this.",
                    "label": 0
                },
                {
                    "sent": "I mean in both scenarios for laptop and for the server, but the improvement is not as dramatical when it hits for workers, right?",
                    "label": 0
                },
                {
                    "sent": "On on the laptop because it has only four cores, but it can still improve on the server which has more than four processors or similar picture can be observed personal city, but the improvement is not linear of course, and there are several reasons for that.",
                    "label": 0
                },
                {
                    "sent": "So because for example with one core processor running in higher Clock usually then with several cores.",
                    "label": 0
                },
                {
                    "sent": "Well in process.",
                    "label": 0
                },
                {
                    "sent": "I. I mean.",
                    "label": 0
                },
                {
                    "sent": "To assess the scalability issues, so we also compared.",
                    "label": 0
                }
            ]
        },
        "clip_72": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Our approach, with the ideal embarrassingly parallel scenario, as it usually called, is that we took several copies of ontology gallium right, and we classify them separately, and we compare the result of classification.",
                    "label": 0
                },
                {
                    "sent": "The Times for the classification with the classification of elk on the whole ontology with N copies, right?",
                    "label": 1
                },
                {
                    "sent": "And we can see that well that I'm the times grows with the number of copies, so this is the number of copies SO123 and up to 8 ontologies.",
                    "label": 0
                },
                {
                    "sent": "Just copy, it was renamed classes right?",
                    "label": 0
                },
                {
                    "sent": "So we created anthology which is 8 times larger than the original 1, right?",
                    "label": 0
                },
                {
                    "sent": "So ideally the classification time should stay the same, at least if you have 8 cores, but in practice it will grow for this for the same reasons that I mentioned, because the processor is not as effective when it has a larger load.",
                    "label": 1
                },
                {
                    "sent": "Right, but what important is important?",
                    "label": 1
                },
                {
                    "sent": "What can be observed in this picture?",
                    "label": 0
                },
                {
                    "sent": "Is that the difference between paper ship partition scenario.",
                    "label": 0
                },
                {
                    "sent": "So when we manually partitioned ontology and then classify them independently but in parallel on parallel workers working parallel sets without interaction whatsoever is more or less the same as in our approach.",
                    "label": 0
                },
                {
                    "sent": "So which means that our approach works as effective as pre partitioning approach?",
                    "label": 0
                },
                {
                    "sent": "OK, so that thing I think I'm finished with that.",
                    "label": 0
                },
                {
                    "sent": "I don't have anymore slice.",
                    "label": 0
                },
                {
                    "sent": "So I start with one.",
                    "label": 0
                },
                {
                    "sent": "Can I go to slide seven there again just sorry now, but I was a bit confused about was that.",
                    "label": 0
                }
            ]
        },
        "clip_73": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This look like no OK, but it's the the one where you had two workers basically.",
                    "label": 0
                },
                {
                    "sent": "So it seems like to me that the two workers can kind of consume to schedule the axioms kind of concurrently.",
                    "label": 0
                },
                {
                    "sent": "So where is then the the communication happening between?",
                    "label": 0
                },
                {
                    "sent": "Is there any communication happening between the two workers?",
                    "label": 0
                },
                {
                    "sent": "If they consume two things which can basically, so it's it's, it's not a communication concurrency, it's a shared memory concurrency.",
                    "label": 0
                },
                {
                    "sent": "So what workers can access the shared?",
                    "label": 0
                },
                {
                    "sent": "Shared state set of actions.",
                    "label": 0
                },
                {
                    "sent": "While they can both read and write into them.",
                    "label": 0
                },
                {
                    "sent": "So in this in this scenario, so while they process this scheduled two scheduled exams, they can still both access those.",
                    "label": 0
                },
                {
                    "sent": "Yes in principle, but it is organized such that I mean the first whenever the worker processing scheduling axiom then it takes it from the queue and it's no longer there, right?",
                    "label": 0
                },
                {
                    "sent": "So if these takes control the queue, it's no longer there, so the next one can take only the next one, so there will not be processing.",
                    "label": 0
                },
                {
                    "sent": "The same maximum at the same time.",
                    "label": 0
                },
                {
                    "sent": "So every work is processing a different exam.",
                    "label": 0
                },
                {
                    "sent": "Because it's secure, you can take only once the head of the queue.",
                    "label": 0
                },
                {
                    "sent": "So that it can happen that they kind of process that they there are two exams which are invisible, basically mutually to each other, which could together fire rewriting or.",
                    "label": 0
                },
                {
                    "sent": "Which can fire was just wondering.",
                    "label": 0
                },
                {
                    "sent": "I didn't really get that.",
                    "label": 0
                },
                {
                    "sent": "I can I can repeat it complete, then I can repeat the example.",
                    "label": 0
                },
                {
                    "sent": "So the first worker takes the first scheduled axiom, moves it to the set of the Pro section at the same time the 2nd work we can set, take the second scheduled actions.",
                    "label": 0
                },
                {
                    "sent": "Most of the process actions, while in the first worker will process and then put there.",
                    "label": 0
                },
                {
                    "sent": "It's already seen by the OK.",
                    "label": 0
                },
                {
                    "sent": "I would like to ask a clarification, but the way I like very much this work.",
                    "label": 0
                },
                {
                    "sent": "So I see two new things here that could have improved your.",
                    "label": 0
                },
                {
                    "sent": "It could be the justification of the improvement of the performance and the fact that the user kind of natural deduction or forward reasoning rules and the fact that you partition the axioms.",
                    "label": 0
                },
                {
                    "sent": "So I'm wondering who like to understand if if just applying the partition of the axioms in as you have done and you in parallel apply that the flow of the standard blowup algorithm you obtain similar results, or it's also because we use this type of rules.",
                    "label": 0
                },
                {
                    "sent": "That you have this improvement.",
                    "label": 0
                },
                {
                    "sent": "Well, the tabloids get its work completely differently here.",
                    "label": 0
                },
                {
                    "sent": "And of course, the improvement is largely attributed, but by the calculus, because I mean, for this fragment, the calculus is polynomial while it is specifically tailored for this fragments.",
                    "label": 0
                },
                {
                    "sent": "That's why it's more efficient, but we wanted to go beyond that.",
                    "label": 0
                },
                {
                    "sent": "We wanted to make it even more efficient, so as if I scroll on this.",
                    "label": 0
                },
                {
                    "sent": "Cable weather",
                    "label": 0
                }
            ]
        },
        "clip_74": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Results.",
                    "label": 0
                },
                {
                    "sent": "You can see that all the calculus in case of just one worker, not concurrent version, is already outperforming the tableau based Reasoner, which is basically effect plus plus pilot.",
                    "label": 0
                },
                {
                    "sent": "We should be home in somewhere.",
                    "label": 0
                },
                {
                    "sent": "I think Kermit couldn't process.",
                    "label": 0
                },
                {
                    "sent": "It's not me.",
                    "label": 0
                },
                {
                    "sent": "That's why it's not here.",
                    "label": 0
                },
                {
                    "sent": "So they're outperforming Tableau based reasoners already.",
                    "label": 0
                },
                {
                    "sent": "This is blood out through the new kind of calculus consequence based.",
                    "label": 0
                },
                {
                    "sent": "And we can improve further more by making the procedure concurrent so we can reduce considerably the classification time even beyond that.",
                    "label": 0
                },
                {
                    "sent": "OK, one more questions about technical.",
                    "label": 0
                },
                {
                    "sent": "You said the process taxim should be duplicate free, but now you have the different context and each context had list of processed axioms.",
                    "label": 0
                },
                {
                    "sent": "Do you have to keep them duplicate free across context or is it just?",
                    "label": 0
                },
                {
                    "sent": "Duplicate free within one context.",
                    "label": 0
                },
                {
                    "sent": "No, it's only duplicate free within each context, that's OK.",
                    "label": 0
                },
                {
                    "sent": "So it's it's easy.",
                    "label": 0
                },
                {
                    "sent": "You don't have to look over all the context all the time.",
                    "label": 0
                },
                {
                    "sent": "That's the main reason, yeah.",
                    "label": 0
                },
                {
                    "sent": "We don't want do we just don't want to miss the inference that's our Member.",
                    "label": 0
                },
                {
                    "sent": "Maybe we can derive several axioms twice, but as long as we can read out the result of the classification from that, it's not the problem and it actually doesn't happen very often.",
                    "label": 0
                },
                {
                    "sent": "It doesn't happen at all.",
                    "label": 0
                },
                {
                    "sent": "I think in our calculus or and I mean, one can argue that there are some things that can be inefficient because of that, because some axioms can be copied into several contexts.",
                    "label": 0
                },
                {
                    "sent": "But actually this is not the case, be cause.",
                    "label": 0
                },
                {
                    "sent": "This is happening because one axioms can participate in several inference rules, and for each entrance rules one would have to index them anyway into different ways, so we don't actually copy the axioms as they are.",
                    "label": 0
                },
                {
                    "sent": "We could just pointers to this excellent actually keep the pointers in such a way how they can be used in this specific situations with the influences on again on this technical side.",
                    "label": 0
                },
                {
                    "sent": "I don't understand if the processor who process and generate a new axiom.",
                    "label": 0
                },
                {
                    "sent": "If these are some is stored in the context associated to the processor or it is distributed across the other context as well.",
                    "label": 0
                },
                {
                    "sent": "Becauses in the first case you have a kind of property of your calculus, you have to rely on the property of your concludes that the new action generated in one context are not relevant for the other context or so.",
                    "label": 0
                }
            ]
        },
        "clip_75": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "If you can clarify on this, I guess this clarifies that, so you.",
                    "label": 0
                },
                {
                    "sent": "So several workers can concert at the same time into the same context, but that's not a problem because it's a queue and it's easy to have a queue concurrent so you don't care about the duplicate.",
                    "label": 0
                },
                {
                    "sent": "Duplications in the queue.",
                    "label": 0
                },
                {
                    "sent": "Right?",
                    "label": 0
                },
                {
                    "sent": "It's more difficult if several workers with insert in the set, in which case, in which case you need to keep the set duplicate free, and this is usually done using locking.",
                    "label": 0
                }
            ]
        }
    }
}