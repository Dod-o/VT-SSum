{
    "id": "pfnzk2ir34wcy46vkygwj54ibuw3kfud",
    "title": "Monte Carlo Methods",
    "info": {
        "author": [
            "Arnaud Doucet, Department of Statistics, University of Oxford"
        ],
        "published": "Oct. 12, 2011",
        "recorded": "September 2011",
        "category": [
            "Top->Computer Science->Machine Learning->Monte Carlo Methods"
        ]
    },
    "url": "http://videolectures.net/mlss2011_doucet_montecarlo/",
    "segmentation": [
        [
            "So the courses organize follow for those of you've never.",
            "Basically we don't know anything about Monte Carlo methods.",
            "I will review very briefly in the first, like 20 minutes, half an hour.",
            "the Monte Carlo principles.",
            "OK, then we will move on basically by discussing introducing the class of Markov chain Monte Carlo methods on there.",
            "I will review the such as Gibbs sampling or Metro processing algorithm on.",
            "Then I will discuss more sophisticated techniques such as slice sampling, Hamiltonian MCMC.",
            "Or party tampering.",
            "So that should take us one owner off.",
            "OK, so we want to lose.",
            "Won't waste anytime during basically this morning after that after the break we really start discussing the class of sequential Monte Carlo methods, which is the 2nd essentially large class of Monte Carlo methods, also known in the literature.",
            "Sometime as particle filters.",
            "OK, so I'll do first time.",
            "First one owner of MTM signal off SMC.",
            "I'll mix basically tomorrow.",
            "Once we have understood all those techniques were empty anteon SMC then we will describe essentially Monte Carlo methods, which essentially our combination of both MCMC on SMT methods on this will include actually very recent material that have been published actually last year or even should be published.",
            "Actually very soon.",
            "OK, so for those of you are really special summer kilometres, I'm afraid you're not going to learn much things this morning.",
            "OK, but definitely tomorrow at least you should basically get to learn a few new tricks in this field."
        ],
        [
            "OK, so let's talk basically with bit of motivation.",
            "Why am I interested in doing multi kilometres?",
            "Well, essentially me.",
            "It's coming from my interest invasion statistics.",
            "OK, so essentially you have Asian model choir on the like glued on.",
            "You use the base root on.",
            "Here we go, you have the posterior distribution of Teeter.",
            "Given the observation, first typo does very nice.",
            "First Slider found a typo.",
            "This is why here this is not a good start.",
            "OK, so this is.",
            "This is the first step.",
            "Solution, essentially, as soon as you have basically model which are little bit complex, you don't have a closed form expression for this poster distribution, so you need to approximate it on the tools of shares in the stats community on increasingly in the machine learning community consists of using Monte Carlo methods.",
            "OK, so that's why we will be interested in that.",
            "Similarly, when you don't want to do send some kind of model selection in a Bayesian framework, you have essentially to compute the marginal likelihood of the observation.",
            "Which once more is I dimensional integral typically used."
        ],
        [
            "The collimated OK, so everything you will each time you interested in computing his teammates.",
            "For complicated version modeled say you want to compute the posterior distribution of the parameter Tita under the posterior or posterior variance.",
            "Who wants more?",
            "You have high dimensional integrals.",
            "So basically multicolor matters at what you need to use.",
            "As soon as you have no like complex model.",
            "OK so I'm not going to go like give much more detail about that.",
            "You will have a course by Peter Green.",
            "Basically two more on Bayesian modeling.",
            "Each time you're doing essentially Bayesian modeling on you having nuns, non standard mode or you're gonna have to deal movement in kilometres so as to compute marginal distribution.",
            "Or if you."
        ],
        [
            "Choice did say in computing, say the predictive distribution of a noob Salvation.",
            "Given the call up Salvation once more this season, I dimensionality or once more you have to use multicolumn.",
            "It's OK, you have to use identical.",
            "So that's essentially my motivation.",
            "Bayesian statistics.",
            "I want to approximate like high dimensional posterior distribution, however."
        ],
        [
            "OK, for all the remaining, the rest of this talk I will not put any on faces.",
            "Essentially on Bayesian statistics I will just assume that I'm interested in a given target distribution.",
            "Quality distribution turns out from the application point of view, it's typically a posterior distribution, but all the tools obviously I'm describing can be generally used, can be used in a much, much wider context, right?",
            "So I say for those of you never seen anybody.",
            "Animators I'm just gonna review, essentially very briefly.",
            "The main idea behind multi kilometres.",
            "So let's start with the kind of silly toy example.",
            "The simplest thing you can think of.",
            "So we consider we have essentially a circle inscribed in rectangle."
        ],
        [
            "OK, basically I'm supposing OK, so that's really silly example that basically I've got to idealize rain that falls uniformly on the square OK.",
            "The Blue Square here OK?",
            "All I'm interested basically in computing the probability.",
            "For drop to fall in a given region, a OK so which is proportional.",
            "Obviously today our have a because they assume that the drops holds uniformly.",
            "Basically on the square.",
            "Alright.",
            "So basically in this case you don't need to do to do anything.",
            "Basically you know that if you define as D random variable that represent the location of drop on a region of interest, say the circle in my case in the previous slide.",
            "OK then the probability.",
            "That drop basically belong that D belongs to a OK deep in my random variable corresponding to drop location is simply the integral of the cell phase of our have a given.",
            "Basically, I did buy the total area of the square OK where X&Y are the Cartesian coordinates corresponding to the location of the top.",
            "So like it's really the most basic thing here.",
            "Obviously I use the fact that I use the assumption by my Rainford uniformly.",
            "OK, so now assume you don't know how to compute this guy exactly OK, because a for example has very very complex shape.",
            "Complex shape is not a simple circle then.",
            "Basically what we're proposing we're going to discuss a simple numerical method.",
            "The Multicolumn entered through us to approximate numerically this integral.",
            "OK, so we're going to work is very simple, so assume that you observe and such drop independent drops of rain.",
            "Each of them being distributed uniformly on the square on Arduino, Daisy Klebe, Idi, essentially the random location of drop I OK, so I assume you want to compute."
        ],
        [
            "Basically, so this is basically the graph you up.",
            "So this is basically the initial square you have your random drops here that are you observe capital and of them each of them is uniformly distributed according to under on the unit square on.",
            "Basically you are interested in computing the area of the circle where.",
            "What could you do is very simple."
        ],
        [
            "Well, the simple thing, the probability basically for drop to belong to the number to belong to circle given that basically they uniformly distributed where you don't need to have done any stats to know that.",
            "Basically a good estimate of that could be simply the number of dropped you observe that fell into the circle given divided by the total number of drops."
        ],
        [
            "OK, so that's all I did I said to compute the probability of belonging to the circle.",
            "Just I come the number of gather full have fallen into the circle and I divided total number of drops that."
        ],
        [
            "Equal to capital alright?",
            "So let's have a little bit of statistical justification for it.",
            "This is really."
        ],
        [
            "The basic of multicolumn into, well.",
            "To do that, we tried to formalize a little bit what we've been doing, so I'm introducing basically an indicator function for the set A, which is equal to essentially one, either point of coordinates.",
            "XY belongs to a on 0, otherwise OK on simply what I'm not doing, I'm doing simple modification, I rewrite the probability was interested in, that is the party that drops belong basically to the set a as simply.",
            "The expectation of basically this indicator function under this guy, or is this guy is simply the uniform distribution over the square.",
            "OK, so there's a factor 1 four here because remember, my square goes from minus one to one.",
            "Oh yes Sir, this is it and is simple it.",
            "So now basically what we've been doing essentially is that E for you or introduce a new random valuable OK which is simply defined as the indicator function basically applied to the random variable D. Then you have BOD which is essentially.",
            "Random variable which takes value zero or one Eve dies within Aiden.",
            "Visit V of these equal to 1.",
            "Basically, if D is outside Aiden V of D is equal to 0 on.",
            "Essentially, we've managed to rewrite essentially the probability distribution of interest as the expectation of such random variable and the uniform distribution on the square of interest.",
            "The initial square S OK, so that's it.",
            "So essentially.",
            "You think of it, it said, no, what we've been doing really do this.",
            "The initial kind of intuitive estimate of the party I was proposing was simply basically counting the number of drop that fell into a divided by the total number of drop.",
            "You can write that simply as the sum of those random variable VR Y / N is just rewriting essentially of what I've been doing before."
        ],
        [
            "OK, so just really like simple thing re formalizing.",
            "Basically intern properly in terms of random variable.",
            "What I've just been doing intuitively.",
            "OK, now.",
            "Well basically what do we know?",
            "Well, we know that we have here essentially one over and some from equal 1 two end of independent random variable V. OK, so basically if you take the limit as N goes to plus Infinity, you have the strong law of large number that tells you that.",
            "Essentially as of then my estimates given conversion must surely toward the expectation of the under.",
            "Basically the uniform distribution on the square S. Which is exactly what I was interested.",
            "So essentially what we've been doing with what we've been using when we were using this estimate is implicitly we are using the law of large numbers of.",
            "OK, that's all.",
            "OK, so essentially when is is large enough?",
            "That's kind of justified the use."
        ],
        [
            "This estimate.",
            "OK, so that's good.",
            "That's good.",
            "Now what about basically the properties of this estimate?",
            "Well, what we know where it's quite trivial to show that obviously SN is an unbiased estimate of the quantities of interest, which in the case of advice basically apology or belonging to a circle is equal to \u03c0 / 4.",
            "OK, so now my estimate is unbiased was basically the auto characterized the property that the quality of my estimate.",
            "Typically we're going to use the valiance, so I've gotta valiance of SN, which is an average of independent random variable, so obviously essentially it's equal to essentially variants or one random variable.",
            "They're all the same, so I can put any index here divided by 1 / N the number of samples.",
            "OK, so based on that so you have a variant which decrease in one of them, which is good.",
            "OK, all, you can also basically invoke a central limit theorem, so not only you have a random estimate.",
            "Which converter synthetically towards basically the quantity of interest?",
            "It's unbiased, which is not something I really care because invasion, but also it has basically satisfy yourself or limit time.",
            "OK, so that's good if you want to play a lot of you are doing like learning bones and so on.",
            "So if you want to use finite bounds, basically you can also play with it on obtain some kind of finite bounds for this type of estimate.",
            "I won't go for that OK."
        ],
        [
            "So let's basically here or simple illustration of the behavior.",
            "My estimate basically as a function of them.",
            "So this is basically I expected.",
            "Obviously as N goes to increase to Infinity is going to converge.",
            "This is the basically the error SN minus \u03c0 for my estimate X.",
            "Expect this guy to converge towards zero as N goes to Infinity.",
            "This is unsure by the Central Limit theorem, OK?",
            "So why do I show something like that?",
            "Actually, this is really silly example where you see this is a troll.",
            "Your problem.",
            "What we're doing now you're trying to compute essentially the area of a circle, basically using using some watercolor method.",
            "Well can see that the valuation can be actually quite useful for basically low dimensional problem, so multi color method is a method of last resort."
        ],
        [
            "So what about basically so this is the convergence.",
            "This is over 100 realization.",
            "The behavior of the errors and we see that you're going realization.",
            "We obviously, as expected, that valuation."
        ],
        [
            "Quite significant.",
            "OK, so you are."
        ],
        [
            "All those properties are satisfied, so OK, so I just say I would just basically discussing that for people who never ordered Monte Carlo method.",
            "Everything I've been doing here in the case we are having having a unit square on the circle within a square can be generalized essentially to any domain, any space.",
            "So in particular you could have essentially that instead of adding, say, a square on the 2D plan, you could have essentially your.",
            "Hypercube basically of dimension NX on NX could be of dimension say 1000 OK on.",
            "Similarly, you might be interested in computing said the volume or the polity of belonging to the hyperbowl.",
            "Basically in the space of dimension NX OK on use Monte Carlo.",
            "Everything I've been saying before does apply also in this context, I've never used whatsoever at anytime, anytime in my previous argument.",
            "The dimension of the original space.",
            "OK, so multi Collimators will remain valid in this case if I have it, I can observe and hyper rain in the hypercube uniformly distributed on the hypercube SNX.",
            "Then I can count the number of drops which fall within the hyperbowl arm.",
            "Basically if I divide that by the total number of drops I will have an estimate of the probability of belonging to the hyperbowl OK.",
            "So in particular, what is great?",
            "We want a collimated.",
            "Is that the rate of convergence of the estimator?",
            "If you look at the Valiants is still always going to be in one of the capital and whatever being the dimension of the original space.",
            "OK, so this is essentially the main argument for using motor kilometres, because if you use Donald Monte Carlo method, typically this rate of convergence is dependent.",
            "The rate of convergence to zero obvious teammate is dependent of the dimension of the original space.",
            "On for more sophisticated method on the regularity of the contour of basically the area you're trying to compute the volume, so that's really what is really nice or Monte Carlo rate of convergence independent of the dimension, and This is why really typically people are using multi kilometers."
        ],
        [
            "Yeah.",
            "So no, basically one should be also a bit careful about what what we're doing.",
            "So if you look at the literature, sometimes people claim that Monte Carlo bid the curse of dimensionality because the rate of convergence of UST May is going to be one of a capital N, and on being the number of samples, whatever being the dimension of the space.",
            "This is not true.",
            "OK, you have to be very careful with that.",
            "OK, so let's come back to the problem of essentially looking at my problem, where I mean the hypercube OK. Of dimension NX on I'm looking at basically computing the probability of falling into the hyperbowl hyper sphere of radius R equals one OK using Monte Carlo method.",
            "OK, so I know in this case that analytically the volume of the atmosphere of radius one.",
            "Basically he has a function with dimension with space is given by this expression on in particular.",
            "It converge to zero as N goes.",
            "The dimensional space increases.",
            "OK, so don't try to kind of like what happens in low dimension.",
            "Often can be a bit misleading for dimension, so assume you're trying to compute.",
            "The probability using Monte Carlo falling within the atmosphere given that you have an eye for rain, observing the iPad cube.",
            "OK, so was the violence of your estimate.",
            "In this case, where essentially it's equal to approximately 2, the probability the original party I'm interested in of falling within the hyper sphere divided by the total number of some polls.",
            "So you could feel that's great because this is very small.",
            "This is a very small property, but you should know."
        ],
        [
            "Never forget that actually, what matters when you're doing Monte Carlo is not the variance of your estimate, but typically what matters is the related violence of you estimate.",
            "OK, so.",
            "Once more, be careful when you're doing Monte Carlo method.",
            "You want to compute an integral.",
            "What typically matters is computing the relativ is having an estimate which has good or related variance OK, so the relative ion being defined essentially by the violent divided by the square of the expectation.",
            "OK, so in this case what you find what you would find is that essentially the variance the related violence would be something which indeed decrease in one of the capitolin, but basically one of appear next is extremely small.",
            "So the related violence is really really huge.",
            "So if you want to related variants of, say, about the 10 -- 2, it means that essentially in a dimension 20 you will need like 4 billion samples.",
            "OK on 1440 you will need like 10 to the power forward, 20 sample.",
            "OK so monticola metered nice internal rate of convergence but in love scenario it doesn't break the curse of dimensionality.",
            "In this case it shouldn't be a kind of a mystery to you if you saw.",
            "Orly blindly into space on you, tried to eat the hyper sphere here using sample for the hypercube is really like finding a needle in a stack.",
            "In such I dimension on essentially such blind Monte Carlo methods will be a bit stupid, so it's just a bit of cautionary warning about multi Cal."
        ],
        [
            "Limited, Oh yeah, so now let's move to the allied.",
            "That's it for the really general introduction to Monte Carlo method.",
            "So let's move already to the general problem, trying to solve.",
            "OK, So what I'm going to be interested in doing is computing.",
            "Essentially Joey speaking coming up with this teammate of expectation of function F with respect to party distribution Pyrex, so typically it's possible that your point might not be initially posed this way that you have to write it as an expectation.",
            "Respect to quality distribution, I assume for the time being that you've done the job for me alright.",
            "So.",
            "Basically, here pie is going to be essentially any arbitrary polity density function.",
            "I assume that your work and basically RNX, but could be any space.",
            "This now relative base that essentially is nothing particular being working with numbers."
        ],
        [
            "OK so I will introduce some notation.",
            "Basically that we already use later on quite alert, so I will introduce the Delta Jack function Delta X Note which is basically, whereas if you integrate any function F respect to tell that your function located X notes is equal to FX note, so I won't use measure theoretic notation in this set of lectures.",
            "You could obviously to be completely rigorous.",
            "Obviously you should write Delta X, not DX instead of this.",
            "This integral is not quite rigorous, but as a notation have adopted not to overload notation.",
            "OK, so if you think or what multicolour really doing, OK it's very simple.",
            "If you have capital and sampol distributed according to \u03c0 in previously there was my drops that were distributed according to the uniform distribution then TV.",
            "Clearly what you're doing, what Monte Carlo corresponds to it correspond to doing an approximation of the initial distribution of interests.",
            "Approximating it by non PR equal measure, which is essentially basically assume the related some of the Delta mass located at the party at the random samples location.",
            "OK so Monica Lemaitre intuitively why is basically not bad.",
            "It's not so stupid despite the fact that if you do things blindly it's not really efficient.",
            "It simply because essentially you approximate basically the target distribution of interest biodex by simply Sarah set of random.",
            "Coins which automatically concentrate themselves in region of high priority mass.",
            "OK, that's why it's quite clever.",
            "OK, so this is a bit funny way of reasoning because weather when you're doing stampley parametric statistics you have like some polls a data on you try to come up with functional representation of your data.",
            "So you try to approximate that via Goshen of given mean and variance.",
            "Here is when you're doing what are calories the reverse way you have typically ornate expression for the target distribution of interest on you.",
            "Come up with.",
            "Basically, we've we've multicolor representation of it through samples.",
            "OK, so that's kind of weird."
        ],
        [
            "Thinking.",
            "OK, so this is a simple trivial example, so this is my multi color approximation of univariate Goshen.",
            "It seems really silly to make such approximation why dimension on it is follow dimension.",
            "Multi kilometers would be precluded, but for I dimension essentially the concentration of essentially a random sample regional high probability mass is going to be quite actually."
        ],
        [
            "Relevant.",
            "OK, so Monte Carlo.",
            "I'm just redoing very quickly the benefit of basically this estimate, so assume you have capital and sampol distributed according to part you want to approximate the expectation of a function F, respect a pie.",
            "What you do very simple.",
            "You simply substitute to buy the empirical measure of your sample.",
            "Here we go.",
            "This is 1 over and some of FSI is simple.",
            "Is a simple visit generalization of what we've done for the drops where F at this stage was basically an indicator function of a set.",
            "So similarly hello large numbers, it's on buyers on the violence basically decrease as one over and whatever.",
            "Basically being the dimension of the space doesn't mean that it breaks the curse of dimensionality on you have this on for limited time.",
            "OK so that's basically Multicolumn entered.",
            "Similarly what is now it's also about it is not only you have an estimate of the quantity of interest, which is the expectation here, but you can also approximate the variance of this estimate quite easily using the sample by doing simply what?",
            "A Monte Carlo approximation of the Vine."
        ],
        [
            "So simplifying simple thing, once you are basically high dimensional target distribution, so you have a distribution we've set of argument X One X2 X One X2 obviously can be multivariate.",
            "If you're interested in having an estimate of the marginal distribution of one of the guys, basically say X1 the way you do your motor approximation.",
            "Very simple, you discard the sample, the component X2 of the sample that give you an approximation of the marginal next one.",
            "OK, so you can do a lot of things like that."
        ],
        [
            "OK, so that's basically a actually the multi colored pen support come up you some poor for the parties assert deep store vision Pi K you want to approximate that give you essentially nonpolar equal measure which had the property that essentially automatically you focus.",
            "You do kind of grade random sampling region of high probability mass.",
            "Once you have this guy, you can compute easily and take all you can marginalized.",
            "Easily integrate easily some.",
            "Some valuable is very simple.",
            "Alright, so that's quite nice, OK, but you realize basically only abilities to sample from the point distribution of interest pie.",
            "OK, so that's nice.",
            "But basically the question is if I give you a party distribution Pi.",
            "So let's say I give you a complex Bayesian model.",
            "The razor thin target distribution is the posterior distribution of the random variable and wouldn't rise given the observation.",
            "Or do you sample from that OK?"
        ],
        [
            "And the answer is, there's essentially no general way of doing if the distribution of interest, easy lava, stone up forms a Goshen multivariate Gaussian exponential.",
            "I don't know like Basil or whatever.",
            "Then.",
            "Basically you can sample from it exactly OK, But as soon as typically you're dealing with more complicated scenarios, you are going to have to come up with some kind of more sophisticated techniques on essentially.",
            "All the techniques I will discuss essentially are based on the idea of proposing samples from an over distribution, which is easy to sample on.",
            "Tried to use some kind of mechanism so as to move your sample from a distribution where he's easy to solve poor form to the target distribution.",
            "That's what we'll do.",
            "OK, so.",
            "In any case, if you're interested basically in looking at least at some exact simulation techniques to sample from standard distribution.",
            "Basically I ask.",
            "I mean, you should have a look at the book back to avoid, which is actually extremely good, but we won't discuss basically this type of technique here.",
            "OK, everything is available, typically in a MATLAB toolbox or Python or whatever.",
            "I'm going to basically discuss the scenario where I'm having target distribution which are quite complicated on.",
            "I don't need to stand out form.",
            "OK, on TV Kelly TV Kelly.",
            "In all the scenarios I'm going to deal with.",
            "OK, I'm going to deal with the case where this is going to be important later on where the distribution.",
            "I won't to some poor form is known only up to normalizing constant.",
            "OK, so I'm going to deal primarily with the case, essentially where say \u03c0.",
            "So they said Pi of X is equal to a function gamma X divided by its normalizing constant, which is the integral of gamma over the world integration domain.",
            "OK, where gamma is known pointwise, but it's normalizing constant is unknown, so the typical example.",
            "Say you're doing Bayesian statistics.",
            "You know the POI analytically.",
            "You know the likelihood analytically, but the posterior distribution is known only up to a normalizing constant, because proportional to the prior on the likelihood that can be evaluated.",
            "But you don't have access typically to the marginal likelihood, which is the integral of the likelihood over the pile.",
            "OK, so typically I will.",
            "I want to add method which are surgeon that allows me to simulate form pie, but I only need to know Pi up to normalizing constant.",
            "Alright, so the 1st all like the most general techniques to do that to do exact simulation of such distribution is core rejection sampling.",
            "He was proposed by Vonda Man.",
            "I think during the Los Alamos project.",
            "OK, so."
        ],
        [
            "So this is going to go for it, so regular sampling you want to sample from distribution PIO X is proportional to gamma of X. OK, so you have access to a normalized version of the target distribution gamma of X, but you typically don't know the normalizing constant, which is integral of gamma over the end of the domain of definition capital X.",
            "Or do you do in a resolution sampling where you say OK?",
            "What I'm going to do, I'm going to basically sampul.",
            "I'm going to put some candidates on Poles from none other.",
            "Essentially proposal quality distribution on the same space, which is going to be like you and I also assume that basically queue is known up to normalizing constant, whereas typically you know it exactly.",
            "But let's say for the sake of generality that I only know queue up to noisy constant, so you have five you want to sample from pie, you introduce the probability distribution Q.",
            "On this solution, Q has been picked so that it's easy to sample, form OK, and then you want to introduce kind of mechanism which essentially once you propose sample from Q is going to do some kind of light, some kind of feeling like filtering mechanism.",
            "That's going to provide you with sample from pipe.",
            "OK, so to do that we're going to need to introduce assumption and Q and essentially assumption I make is that essentially gamma over Q star.",
            "Is basically a bonded, so here I.",
            "Obviously I could have put \u03c0 / Q is upper bounded.",
            "OK, so essentially what this condition means when you obviously it implies that wherever you've got mass under the initial distribution, you need to have mass under the popular distribution?",
            "OK, that makes sense, but is also make sure that essentially you need to have a probable distribution which essentially as featured tails than the tales of the target distribution.",
            "OK, this is really essentially.",
            "This condition means so you want basically a popular distribution that speaker tell OK, so this is the condition we introduced on Q 2, so I don't say it's easy to set up.",
            "This is the assumption I need to make."
        ],
        [
            "OK, now basically you might not be able to compute exactly the sub between gamma on Q star which is given by C. So let's consider.",
            "But let's say that even if."
        ],
        [
            "I don't know how to compute this guy exactly.",
            "You can find an upper bound on that which is given by C prime OK."
        ],
        [
            "Then access project procedure policy that's follow, so you get a sampul.",
            "So let's basically show it.",
            "So I had done already.",
            "Draw.",
            "Morning, so this is the way it works, so this is the target distribution of interest.",
            "OK, which is unnormalized on bloops.",
            "This is gamma of X.",
            "Basically I have access to another anomalous proposal, Q star, which hurts when it's like multiplied by C prime.",
            "I've got C prime, Q star X which is always superior to gamma of X.",
            "So basically this black curve which correspond to see primetime Q star X always dominates.",
            "Essentially the target distribution.",
            "The Unnormalized target distribution gamma.",
            "So what do I do?",
            "I sampul one guy.",
            "From Q, the popular distribution of assume it's easy.",
            "OK arm.",
            "Then I saw him pull a uniform, basically random variable in the interval 0C prime Q star.",
            "Why OK?",
            "So this is this thing is the uniform distribution on this interval OK?",
            "If you is inferior to gamma, why then I return why and I say why is it exact sample from pipe all the way or return to step one?",
            "So you basically assume you have a sample white here.",
            "OK, so then.",
            "You need to sample the uniform random variable in this interval, which is 0 C prime, Q star Y.",
            "So you draw a uniform random number basically.",
            "In this interval, if it's here, the resulting sample you have U which is superior to gamma.",
            "Why?",
            "Because this is above the blue chair, so you reject the sample.",
            "OK, so reject here.",
            "EBay Dick lips ear.",
            "You are basically so you obtain a sample U which is in this part of the space that is below gamma Y.",
            "Then you accept the sample.",
            "That's what you do.",
            "That's very simple thing.",
            "OK so that's basically a rejection sampling.",
            "That's all it is.",
            "OK, so that's that's a very simple thing."
        ],
        [
            "To pull this correct because this is obviously just a graph explaining explaining what we're doing OK, but he's not opposed to poets correct?",
            "I won't go through actually it.",
            "Oh, I see I can do it so well.",
            "Essentially what you say you look at the probability to prove that it's correct.",
            "You're going to have to look at the probability that the random variable why you accepted as the right distribution.",
            "So let's look at a party that why is inferior 2X on why is accepted, where this is the expectation.",
            "Of the event that you is inferior to gamma Y under the distribution of essentially why on you on the distribution the density of Y is Q.",
            "This is a proposal OK on the city associated to you is the uniform distribution of one of the 01 Q star?",
            "Why so?",
            "This is why I've got this factor here and then you have the UDY here that I've been cutting my expression.",
            "So here.",
            "There's an integral of respect to you on why.",
            "OK, so you do the calculation simply.",
            "You can integrate our respect to you very easily.",
            "That gets this factor gamma while that gets out here.",
            "OK, once you get a party that why isn't fair to X or Y is accepted, you can obviously by picking up what's working here simply with the Royal line, but it's true for any case when they were priority that why is accepted.",
            "You just basically take X going to Infinity that give you a party there.",
            "Why is accepted?",
            "K. On when basically you combine both result, what is the distribution of idea?",
            "Why is inferior to small value X given it's been accepted where you use basically apology of a given B is probably a very ambiguous divided by quality of B.",
            "Here we go, you have basically the that.",
            "Basically this is the distribution function, the CDF associated to the density Pi, so ends why is distributed according to pipe.",
            "Sorry you have to.",
            "You have to compute it yourself on.",
            "This is obviously going to be a big problem.",
            "So yeah, I agree with you.",
            "So this thing requires actually indeed a lot of work, because as pointed out by."
        ],
        [
            "Colleague, you need essentially to come up with an upper bound on this.",
            "This ratio, or that's not easy when you're going to deal with high dimensional scenarios.",
            "So indeed that's a bit of a pain actually.",
            "OK."
        ],
        [
            "The average is going to go, so you got loads of look at the speed, the acceptance probability so."
        ],
        [
            "Zoom basically let's have a look at apology acceptance, where essentially that's going to be there to quantify the quality of your algorithm.",
            "Because if you have to wait, say you have to propose 1 billion candidates to get one sample from pine or really efficient, where we see that indeed apology acceptance where is directly proportional to 1 / C prime.",
            "So indeed you could try to be do lose job on picking SQL as a huge constant to be sure that you are bound, but you pay the price automatically because if you increase the primes.",
            "To make sure like that, basically you have an upper bound, say between gamma antipyretics work.",
            "You start then.",
            "Basically it's going to be bad.",
            "OK, you get accepted is going to it."
        ],
        [
            "Probably small, so that's not good.",
            "That's not good at all, actually OK."
        ],
        [
            "OK, so that's that's a limitation of it.",
            "Another limitation which is more important is that this thing doesn't scale at all in high dimension.",
            "OK, so let's take basically the target distribution.",
            "OK, we're X as an real component, which are essentially independent normal random variable, so this is the target distribution.",
            "This is just a multivariate Goshen Zero mean unit variance.",
            "OK, let's say that you use for rejection sampling.",
            "Probable distribution, which has exactly the same essentially functional shape.",
            "This is a product of univariate Goshen, except that not each component has a variance in mask.",
            "Well, OK. Well, clearly we want \u03c0 / Q to be upper bounded, or equivalently normalized version of \u03c0 divided by novelization of Q to be upper bounded.",
            "So we won't basically do proposal to have essentially feature bound thicker tails than the target.",
            "So you want Sigma squared to be superior to one.",
            "OK, so that's a necessary condition to essentially use rejection sampling in this case, so that's the ratio \u03c0 / Q. OK, and if you do a calculation even by essentially picking essentially the best majorization constant between \u03c0 and Q, you find acceptence polarity or rejection sampling is in one of the Sigma to the power NX.",
            "OK, so signals to be superior to one, and essentially you're going to have the access point 5 decrease exponentially fast with the dimensional space.",
            "That doesn't work.",
            "Essentially, that's going to be very, very limited."
        ],
        [
            "OK, so there's a problem with the rejection sampling.",
            "He just basically works in very like limited dimension on.",
            "The problem is essentially what you're trying to do, where you trying to support everything, like in one go, support all the components I dimensional put some possibly idea module component simultaneously on.",
            "There's no correcting mechanism.",
            "Essentially you want to sample some components in and can never come back somehow.",
            "So that's essentially kind of pointing rejection sampling Isabella 2.",
            "Bold, essentially a Porsche to simulation.",
            "Alright, so instead what we're going to do is instead of trying to win, whoever I dimensional problem.",
            "OK to try to sampul.",
            "Essentially the all the components simultaneously.",
            "One thing are trying to do is to come up with some kind of iterative mechanism so as basically to sample from pie.",
            "So that's that's the kind of idea, essentially just on our way to do that.",
            "Is Mark up channel to kilometer?",
            "OK, so I'm just going to go through an inventory."
        ],
        [
            "Sample so this is an example, is actually quite famous invasion literature which is like around the nuclear pump data.",
            "OK so I'm just going to explain describe you.",
            "The model is kind of motivating example for MCMC on the data you have as follows.",
            "So you have access to basically data which have been taken from some nuclear plants.",
            "These are real data by the way, so you have like you monitor essentially 10 pumps.",
            "OK, you know nuclear nuclear.",
            "Nuclear plants OK on you up server.",
            "For each pump you will given 2 information which is essentially.",
            "The amount of time you observe you monitored this pump OK so you monitor set pump #362 minutes or 62 days ago.",
            "Remember what's the unit is still relevant during that time you were given a filler or number of upsell fillers.",
            "OK so say the problem #3 over like 62 days.",
            "Yup cell 5 fillers which is quite a lot.",
            "Actually by the way never mind OK. On you know, tried to sit to, to to, basically set to statistical model on that.",
            "OK, So what you're going to say is essentially that you're going to make that.",
            "Basically the number of failure of palm number K is just going to follow question process with the parameter Lambda K which independent of the pump pump index.",
            "OK, so that essentially if you assume that the failures basically follow person positive parameter Lambda K over and observe time TK.",
            "Number of fillers PK.",
            "Easy question follow person distribution of power meter, long decay time TK OK.",
            "So that's the model for the data.",
            "OK um."
        ],
        [
            "Basically know what I'm going to do.",
            "I'm going to Beijing here.",
            "Essentially what I want to do is, given the observation I have on this person, assumption, I want to infer esentially the unknown, basically person right Lambda K associated to each pump.",
            "OK, so I've got this person model for the palm fillers.",
            "So now what I need to fit my basically my data.",
            "I'm going to follow and we want to infer those parameter Lambda K from the data.",
            "Blue, beige, and a portion.",
            "So I'm going to basically follow the following a Porsche.",
            "I'm going to say that conditional opens for my parameter Alpha beta loan that K the parameters longer care are independent on distributed according to gamma distribution of parameter Alpha beta OK.",
            "Essentially, you know what I'm going to do, which is something that will be discussed at length by by, by Peter Peter Grain tomorrow, where I'm going to be actually a bit more bit cleverer than that.",
            "I'm going to try, essentially, to tide up the prior between all those parameter Lambda one, only to learn that tent by simply setting a random additional hyper prior on the parameter beta.",
            "OK, so this is a simple yockey called model model.",
            "Where essentially, nada marginal Power Distribution of along the $1 too long at 10.",
            "They're basically it's exchangeable on its own independent anymore, so this kind of models allow you to both transform the observation from over bumps.",
            "No, basically, under such a model, even if you're not interested in Bayesian stats under such a model, I've got other random variable I'm interested in are basically the failure rate, Lambda want along that turn on the additional hyperparameter beta.",
            "Basically from the Asian POV, it means that what I'm interested in you mentioned in the posterior distribution over on that one.",
            "I'm not too long at 10 bit are given basically the observation time on the number of fellows.",
            "So it's very simple is proportional simply.",
            "To display Salvation is proportional to the prior OK on the prior follow gamma distribution for each parameter given beta.",
            "OK, so This is why I've got those terms coming from the Gamma Pi.",
            "Are these things coming basically from the diaper party on beta on?",
            "This is essentially the light blue term corresponding to my person assumption.",
            "OK, so I'm interested in is posterior distribution OK?",
            "It's really simple model on.",
            "Still I have no clue essentially or to approximate it.",
            "Even doing like deterministic approximation here would be already standard method with the pain OK and you tried to do injection sampling here you would need to come up with a kind of like popular distribution in order to do that.",
            "I mean it's too high dimensional to kind of good popular distribution."
        ],
        [
            "It's a pity because essentially this part this this essentially this problem seems to have a lot of structure.",
            "In particular also the joint distribution of Lambda and beta group Salvation is quite complicated.",
            "What do some expose some conditional distribution have a much simpler form, so if you look at the conditional distribution of the parameter Lambda given data on the observation well by using elementary calculation you see that this thing factorizes a product of gamma distribution.",
            "It's quite simple.",
            "Similarly, if you look at the conditional distribution of beta, given the observation on the parameter Lambda, this thing is a simple gamma distribution as well.",
            "So the joint distribution is a nightmare, but the conditional distribution of longer given beta and beta, given Lambda, are quite simple, OK.",
            "So what we gonna propose, we're going to try to look at an algorithm which is called actually Gibbs sampler, and I will try to justify later on.",
            "So instead we're going posing so as to approximate the posterior distribution of Lambda on beta given the option."
        ],
        [
            "Station is the following iterative algorithm and this is known in the literature Gibbs sampler, so that's going to be longer.",
            "ISM is not going to be like rejection sampling.",
            "OK, I'm not going to be gone till later on to have some point exactly the speed.",
            "According to put, Syria, it's an iterative algorithm that's going to proceed as follow.",
            "So assuming the iteration, I OK. Basically you have a set of parameters.",
            "We sell the current value of the parameter Lambda on the current value of beta.",
            "On where are you proposing to do alliteration?",
            "I plus one of your.",
            "Iterative algorithm is that conditional upon the current value of beta you sampol the parameter Lambda according to the conditional distribution.",
            "Or this is a product of gamma distribution.",
            "OK, on once you are basically new or revised values for the parameter Lambda, you update basically beta your parameter beta by sampling it for according to its condition or distribution.",
            "Given the current value of Lambda on the observation.",
            "OK, so that I know because the conditional distribution are very easy, so that's good.",
            "So I have this kind of algorithm which basically instead of trying to sample now in this 11 dimensional space, I just need to solve for simple essentially easier random variable distributed according to standard Gamma.",
            "And I can do that using Matlab say OK.",
            "So you could do that OK. Or you could also update the things randomly."
        ],
        [
            "I never see the question is basically where.",
            "You do that.",
            "You sample from this conditional distribution.",
            "Is it going to give you basically sample approximately distributed according to the joint distribution of interest?",
            "It seems like it's a complete terroristic for the time being on.",
            "If basically is the case is basically situated algorithm converge in some sense throughout the target distribution.",
            "How many times should I basically iterate this algorithm so as to get sample approximately distributed according to target?",
            "OK, on the way, essentially to look at this, this kind of question to answer this question.",
            "Is basically to realize that essentially the sequence of defined this way iteratively is nothing but a Markov chain on a Markov chain that has extremely nice properties, OK?"
        ],
        [
            "So let's brief.",
            "Introduction to Markov chain.",
            "OK, so I'm going to call you all know about Markov chain, I'm sure.",
            "OK, so I'm going to call you to sequence.",
            "Random variable is going to be a Markov chain, is satisfied the following property that is the probability that XN belongs to a set to a given the path value.",
            "I've observed X notice a superscript T. Rex, not X1 X N -- 1 is only based is equal to the probability distribution of accent given only X N -- 1.",
            "OK, so that's basically.",
            "To stand out definition for Markov process OK here XN text value in arbitrary space.",
            "Capital X is not obviously necessarily a finite state space.",
            "OK, on, I will denote basically the transition kernel of this Markov chain, pxy soda, pH, DY.",
            "If you want the probability to move from basically to being in a state X on moving the infinitesimal neighborhood or on YDY.",
            "OK.",
            "So this is my Markov care.",
            "Notify integrate over a that give me the polarity of being in a given the current value that X N -- 1 is equal to small X. OK, so now what do we know where?",
            "Basically if you look basically at the marginal joint distribution of X N -- 1 XN OK, then the joint distribution of that of the distribution and probably the Texan minus one belongs to a onexton belongs to be where is going to be basically the probability likes and minus one belongs DX where I sum over the space a * X = B. OK.",
            "Which is what where you simply.",
            "Basically the probability that X N -- 1 by applying now that P of X N -- 1 XN is P of X N -- 1 time period send you an X and minus one that give me basically that the probability of being in X N -- 1 time.",
            "The probability transition kernel of moving from X to the set big.",
            "So these thing in the literature is known as Chapman Kolmogorov equation.",
            "OK so essentially well as nothing much here.",
            "I'm just saying that basically.",
            "You can ride the joint as basically the marginal time the transition counter."
        ],
        [
            "So what I want to do, essentially, you might want Malcolm to kilometers do on this is the key idea and I'm going to see that this is satisfied by the artistic algorithm patented before what?",
            "Do is that essentially they say you are given the target distribution Pi OK, which are only known up to normalizing constant.",
            "Essentially you want to build a Markov chain, a Markov process.",
            "Of transition kernel P OK, that define essentially the party to moving from X to Y or you want to design this kernel surge at essentially.",
            "If you add your age 60 C value, you've simulated of XN or fire XN.",
            "Then essentially this guy will satisfy your lower number on the will converse to the expectation of five under the target pipe.",
            "OK, so that's really the idea you try to simulate.",
            "A Markov process will basically search that when you look at century this kind of average of essentially the iteration number that converts word integral of interest.",
            "Home or this?",
            "Because this is not necessary later on.",
            "Essentially you want to come up with an algorithm such that at some, particularly in the number of iterations, the sample generator distribution, which is approximately distributed according to Pi.",
            "This is going to be just approximation, so for this thing to be valid, you don't need that actually.",
            "But this thing is a condition we will try to ensure that I'm OK.",
            "So you want to come up with such a Markov kernel on?",
            "You want to serve with the check mark of Colonel so that it's easy to simulate the Markov chain even if Pi is highly complex.",
            "So that's really what we want to do.",
            "OK, so one kind of natural requirement for that.",
            "A natural requirement for that is that you if basically you want.",
            "Basically, if you want this kind of condition to be satisfied, natural requirement is that your transition counter would satisfy the following thing.",
            "If XN minus one was to be distributed according to \u03c0 that you want to make sure that at the following iteration the random variable XN is also going to be distributed according to Pi.",
            "OK, so that's actually essentially the kind of thing we want to ensure.",
            "I want this kind of process, which essentially admits pies as an invariant distribution."
        ],
        [
            "OK, so I'm going to give you an example here which has nothing to do for the time being we've some kind of empty empty, so consider the following normal auto regressive process.",
            "OK, where essentially Alpha absolute value of Alpha is inferior to one.",
            "OK, so you got XN is equal to FX N -- 1 plus VN OK, so this thing it defines the Markov process on the real line search that essentially the.",
            "Tom T shirt and the priority of moving from X to Y.",
            "If I write everything in don't city, I'm going to write pxy OK then basically what it is where it's normal distribution of basically so like here if I go with the distribution of X and given X and minus one is a normal distribution of mean Alpha X and minus one on variants.",
            "Basically Sigma square.",
            "So basically the transition kernel of non Markov process is given by this guy.",
            "OK so normal kernel.",
            "Now one can easily check OK that bike if you basically look at the scale node.",
            "You can easily check that if you look if you consider introduced this target distribution Pyrex, which is a normal distribution or mean zero and variance in my square over 1 minus Alpha Square, then if X and minus one where to be distributed according to Pi of X, then if you basically simulate to some pool why?",
            "According to this foundation Colonel using simply this occasion then you obtain a new sample which is also exactly distributed.",
            "Adding to its normal distribution.",
            "So in this case you can say that you can think of it that basically if you're on a Markov chain, OK, according to this condition kernel, then you expect that essentially this Markov chain is going to be such that after a few times step, basically the sample you generate are approximately distributed according to Pi of X. OK, so it's really the reasoning behind it underlying beyond OK.",
            "So obviously that would be a silly way to sample from this normal distribution.",
            "In this case we know how to sample exactly from PIE in this case, so we don't need to run some kind of markup chain Markov process to simulate from it.",
            "But basically MCMC will be used in a much more complex scenarios where you don't know pie.",
            "You cannot sample from Pi exactly on yet, you can come up, you can simulate Markov process which are such that essentially aseptically their distributed.",
            "They're the sample are going to do this really according to \u03c0. OK."
        ],
        [
            "So I'm just going to give you a simple example in this case.",
            "So say you want to simulate from the standard normal density.",
            "But instead of using the sampling directly from it, you're going to simulate some.",
            "You're going to run Markov chains.",
            "Basically you can simulate some Markov process which admits basically this target distribution as inbound distribution as limiting distribution, then basically.",
            "Let's have a look at what's happening, so you assume that initial distribution of the Markov chain is basically uniform on the interval zero 20 OK, and then for each of these Markov chain you run the process.",
            "You run this following Markov process on you look at what's going on."
        ],
        [
            "OK.",
            "So this is what's happening, so at time one you have simulate you have simulated 10 in the 1000 dependent Markov chain, which are basically with the initial set is distributed uniformly on the interval zero 20 on.",
            "Then those Markov chain you make them this thing you make them involved in dependently according to the normal auto regressive process.",
            "OK you look, basically add the distribution of the resulting.",
            "1000 Sampul after say, 10 iteration.",
            "100 iteration, on sale, and so forth.",
            "And what you see what happens is that what happened is what you expected we were expecting is that essentially after essentially a few few times step, then the distribution of the simulated sample approximate the limiting target, the invariant distribution Pi of X. OK, so this is the kind of idea."
        ],
        [
            "So in this case, the target normal distribution in this summer is going to be fixed point for the simulated.",
            "The distribution of simulated sample.",
            "OK, you never go away once.",
            "Basically you've reached this distribution.",
            "Basically, the histogram never drift away from the target distribution of interest.",
            "OK, so that seems that too.",
            "This is a way perhaps to proceed OK in the general case, E5 goods target distribution pie, which is very complex to sample from, not a normal.",
            "Perhaps I could come up with basically chocolate sample from Pike directly past where I could come up with easily easier Markov process, which basically admits which is such that when I simulated on the long run is going to generate sample distributed according to \u03a0. OK, that's the kind of idea on turns on.",
            "Actually, instead of.",
            "Also what you're going to do, you're going to try to come up instead of simulating in parallel a lot of Markov chain here, you just go."
        ],
        [
            "Simulator one is going to be much easier."
        ],
        [
            "So that's the idea, OK?",
            "Alright, so that's what I want to do.",
            "Essentially I want to come up, so let's keep a lot of thing here.",
            "Essentially, what I want to come up, I want to come up with.",
            "I want to generate a Markov process which is going to be such that essentially as the number of iteration increase, these guys are going to converge toward these guy on.",
            "Hopefully the distribution of the simulated sample is going to be \u03c0. OK.",
            "So this is a bit not stand out in the sense that obviously now I'm going to simulate the Markov chain, so the simulated samples are not statistically dependent.",
            "Still we can show that despite the fact that those guys are going to be dependent, basically never mind, you can still have a lot of large numbers on the central limit."
        ],
        [
            "That doesn't matter, alright so.",
            "Well, the thing you have to remember.",
            "So essentially you want to sample from pie.",
            "You want to design A transition kernel.",
            "OK that if basically you start from pie you have sample from pie.",
            "Then you apply this foundation can hold and the resulting distribution is still pie.",
            "So this is essentially by the fixed point of the transition kernel or new one.",
            "Essentially that the resulting admiration of the simulated Markov chain.",
            "This Markov chain being simulated about this transition kernel converse with the expectation of interest on hopefully.",
            "Did you have that the sample approximately distributed according to?"
        ],
        [
            "Right, OK?",
            "So the point I'm actually is that given Pyrex is not that, it's difficult to build such a kernel that satisfy that is actually very easy to come up with an infinite number of kernel that do satisfy that they are invariant perspecta pie.",
            "OK, so basically we're going to have to pick some of them on the CD art of MCMC.",
            "So if you have a kernel OK, you managed to below kernel which is invariant respect to buy.",
            "That is, if you're.",
            "This will according to \u03a0 and then you execute build according to \u03a0 and then you simulator next sample according to transition Kernel P. Then the next sample as distribution Pi that that's very easy.",
            "Now to ensure that basically you're going to have also convergent Latvia rage on the sample are approximately display according to target.",
            "You're going to need more assumption you're going to need basically or reduce ability on a periodicity.",
            "We already use ability means that essentially your Markov can only search that you can reach any state of positive math on the pipe on a periodicity meter.",
            "Essentially, your Markov transition kernel prevent the kind of funny periodic exploration of the space OK.",
            "So the other MCMC as I said, is essentially come up with some kind of kernel which satisfy this.",
            "OK.",
            "So generally speaking, I should say that it's very difficult.",
            "It's very easy to be such.",
            "Kernel is very difficult to obtain quantitative rate of convergence that tells you that you sample at iteration and is that far from the target distribution.",
            "So that's really a big big problem.",
            "With MCMC.",
            "We can easily come up with process P transition to a Markov chain which had the right amount distribution, but coming up with basically right of convergence of the algorithm toward the targeted solution is going to be extremely difficult."
        ],
        [
            "OK. Yeah.",
            "That means we need to know something about leasing.",
            "Yeah, yeah we need something about mixing time on, but for as soon as you're dealing with typically invasion computation is like continuous state space.",
            "The literature on that it is quite detailed and there's a lot of our research in particular by Garth Robertson, Jeff Rosenthal.",
            "But you need a lot of work because you need to use for Stepanov criteria on this kind of fixed yet.",
            "You can have very conservative estimate, but which are essentially pretty useless unfortunately.",
            "So you can come up with conservative estimate for sure, but typically they're not very.",
            "They're not very useful on actually, you know lot of situation you don't even.",
            "You cannot even come up with them actually requires a lot of work actually.",
            "Especially when you're dealing with continuous space, it's not easy to come up with like informative estimate.",
            "OK, so to build such let's continue like basically or building of such market transition kernel.",
            "So we're going to use several facts that are going to be quite useful.",
            "Say assume you ever basically two Markov kernel OK, which both of them are invariant with respect to pipe that is dissatisfied this equation.",
            "OK, if this will be according to Pi you apply P1 then you discourage according to \u03c0.",
            "If you apply P2 is the same OK, then one thing you can easily see is that.",
            "If you apply P1 then P2 OK. Then obviously this algorithm is still going to leave Pie invariant.",
            "OK, so if you have two.",
            "Essentially Markov transition kernel which at the right invariant distribution if you compose them, applying them successively, then you still have the right inbound distribution.",
            "OK. No, if basically what you do is search that there still both in via build a market transition kernel which is search that say.",
            "We have probability Lambda you pick.",
            "You are on .81 minus Lambda, you pick P2, then the ready to transition.",
            "Kernel is still involved actually, so if this is true, obviously if instead of having two kernel you have capital.",
            "I said P of the capital care of them.",
            "OK, so as soon as you have.",
            "Small transition kernel which have function kernel which basically pyres inbound distribution.",
            "You can compose them actually by composition or essentially mixture.",
            "So it's quite a quite a useful thing."
        ],
        [
            "So in particular, let's basically see or we could use that to prove that essentially the algorithm I've been discussing the kind of artistic algorithm was proposing for nuclear problems is actually valid.",
            "So consider target distribution Pyrex, which are essentially two component X, one X2, both X one X2 can be actually multi dimensional OK.",
            "The Gibbs sampler.",
            "I'd say the algorithm is called Gibbs sampling.",
            "The literature proceed as follows.",
            "So you initialize your Markov chain by picking some initial arbitrary value for the company X one X2.",
            "This is basically the iteration number of Markov chain.",
            "Then what you do?",
            "Iteration I use on polar.",
            "X1 you update X1 by sampling it from this conditional distribution according to under Pi.",
            "Given the current value of X2.",
            "And then once you got a new value, you simulated a new value of X1.",
            "You simulate basically a new value of X2 according to its conditional distribution on the pipe.",
            "This is exactly what I was doing for the nuclear bomb problem.",
            "We're basically in mice, nuclear bomb problem X one was corresponding to all the value, Lambda one number too long at 10 or next to Westcott Christ bonding to basically beta OK.",
            "So this is what I was doing.",
            "First question, as this algorithm.",
            "The right environment distribution OK."
        ],
        [
            "Well, I tell you, this is very easy because you can think of this algorithm as it basically a combination of composition of two Markov transition kernel which are both invariant prospecta pie because each of the transition kernel is involved.",
            "Respect to buy the composition is going to be in violent perspective pie.",
            "So the first transition kernel are going to consider is the following one.",
            "Say you in X one X2 you propose new component Y1Y2 on the way you do it.",
            "Let's follow you some.",
            "Pulled a new component.",
            "Why won't you update it by sampling it according to its conditional distribution given the current value of X2 on?",
            "Basically, you don't modify the component X2.",
            "This is what I was doing OK at first, so this thing tells you simply don't modify the components to.",
            "Then the second kernel I'm considering is considering the following kernel, which basically what it does.",
            "It doesn't modify the current value of X1 on the update, the component, the current value of.",
            "Of the update.",
            "Basically the second component by sampling according to its conditional distribution.",
            "It's very easy to check that both P1 and P2R Pi invariant.",
            "OK, so I can do it for P1.",
            "I'm not.",
            "I'm going to tell you the detail, but it's really, really simple to show that both P1 as basically Pi's inbound distribution P2 as Pi's inbound distribution.",
            "So the composition of those two channels as basically pious inbound distribution.",
            "So I know that you're gonna propose leaf pie invariant, which is actually something which is actually unnecessary requ."
        ],
        [
            "Moment for MTM see.",
            "That doesn't mean that basically you converse with doing ground distribution.",
            "As I say, you need additional condition.",
            "You need to ensure that basically whatever set which has on that and it's positive mass on the target property.",
            "So you need to ensure that whatever being the initial point, you can reach any set of positive quality mass on the target on.",
            "You need to essentially to rule out also parallel behavior."
        ],
        [
            "So OK, I'm just going."
        ],
        [
            "Through that OK.",
            "So."
        ],
        [
            "This is basically what you need, so generally speaking you can generalize this algorithm also to the case where instead having two components you have P components.",
            "So let's say that X can be separated can be divided in like P groups of random variable X, One X2, XP.",
            "Well, basically the algorithm the way to Gibbs sampler will work in this case so as to simulate approximately from the target distribution is following at iteration.",
            "I basically you're going to cycle.",
            "For the component want to the component P on.",
            "Basically you're gonna update the component XKI called in by sampling according to its conditional distribution and the pie given the current value of the other components.",
            "That is, in this scenario, the K -- 1 first component I've already been updated at iteration.",
            "I on the remaining basically components which are at iteration minus one because they haven't been sampled yet.",
            "OK, so this algorithm, by using the strike generalization of what I've been discussing before, is and it basically pie as inbound distribution on.",
            "You can also instead of cycling deterministically under from one to PETA component, you can basically some pull them."
        ],
        [
            "Sample this company.",
            "The component to update randomly.",
            "Basically according to a distribution, say uniform distribution over the set 1 to P. OK.",
            "So instead of cycling for it, you sample randomly the basically the component you want to update.",
            "OK said K, that's going to give you a return value which is uniformly distributed accounting in the set 1 to pee on.",
            "You update this.",
            "Distribute this component according to his full conditional distribution.",
            "This guy corresponds to a mixture of kernels also using the same argument.",
            "It admits basically the right invariant distribution."
        ],
        [
            "OK, so if you come back to basically or nuclear pump again, I've told you we've shown are that basically this algorithm I was proposing is just a simple example of the Gibbs sampler.",
            "OK, so I know it means the right invariant distribution, OK?",
            "What about this condition will basically with additional condition that briefly sketch which are that?",
            "Basically I need to be able to reach any basically set of probability of positive polytomous under the target, whatever being the starting point where it's going to be automatically on shore, because all the conditional distribution are strictly positive on 0 plus Infinity on.",
            "Similarly, basically my Markov chain doesn't exhibit any periodic behavior because similarly all the conditional.",
            "3 positive so I know this algorithm is going to basically generate sample that essentially as I going to go to plus Infinity converge to other target distribution.",
            "What about the rate of convergence where that is going to be much more complicated on this simple example, actually some people have established some result on that actually on the simplest example is simple enough that you can get rid of convergent Jerry speaking is going to be much more complicated.",
            "Alright, so that's basically keep sampler.",
            "Alright, so now you should be a bit careful when you do this type of algorithm where the problem is that it's very nice to come up with this kind of separating.",
            "Essentially said the company shall state vector insap component updating one conditional upon the other, but conditioning is going to come at a serious price."
        ],
        [
            "So let's look at the other really toy example, which is essentially univariate Gaussian distribution.",
            "OK, sorry bivariate, Gaussian distribution of 0 mean on covariance.",
            "Basically variance covariance matrix which is given by this guy.",
            "OK, so all is the correlation coefficient here actually I just assumed that basically there's unit unit unit lines.",
            "OK, so in this case, OK, obviously you would not use the Gibbs sampler, but if you were to use the gift sampler.",
            "On trying to sampul from these joint target distribution by eatery, iteratively sampling from the conditional distribution of X given Y and then Y given X.",
            "Then this is the form of the conditional distribution.",
            "OK, where what you see is obviously.",
            "So this is the expression.",
            "So if you can rewrite it, basically you can think that the Gibbs sampler would proceed as follow essentially.",
            "So this is the first component, so you would at time at iteration N plus one of the algorithm X N + 1.",
            "They always end time this noise.",
            "While in plus one is updated according to this location.",
            "OK, on you see obviously the problem you're going to get with this algorithm used as soon as essentially absolute value of war is going to be very very close to one that is there really strong correlation between the random variable X&Y under the target distribution then?",
            "Essentially you've got X N + 1 user pproximately equal to YNOK on YN, plus one is approximately equal to X N + 1.",
            "So we have a Markov process which indeed if you iterate it long enough, it's going to converge basically toward the right target, but it might take ages if actually who is?"
        ],
        [
            "Very close to work.",
            "OK, so it means that actually what you're going to see.",
            "So here.",
            "Let's say this is that corresponds to the level set of my by via Goshen distribution.",
            "Basically, if you look at the exploration that basically the end the markup change is going to take a lot of time to move.",
            "Basically from to explore the world Purcell distribution here in this case, for example, it doesn't explore this whole part of the target distribution, so it's not because you have.",
            "Essentially argues billion appears in the city that basically."
        ],
        [
            "First, hopefully so.",
            "Also reap sampler is nice.",
            "OK, because somehow it's reduced.",
            "The pile of sampling from my dimensional target distribution to the problem, essentially sampling from lower dimensional distribution.",
            "It doesn't necessarily kind of going to work really well.",
            "OK, because essentially the problem is that if you ever component which are highly correlated, OK under the posterior, the target distribution of interest, if you update, then basically.",
            "Independently one from each other.",
            "Then basically the algorithm is not going to work well at all, OK?",
            "So that's actually one of the problem.",
            "So you need to be a little bit careful when you use the Gibbs sampler, so there's a lot of application, for example, of the deep sampling machine learning.",
            "So too are really complicated, like testicle models such as the Yahiko leadership process.",
            "If you use a naive Gibbs sampler on such kind of model, I mean you can already expect to sample from the target.",
            "You should be aware realistic, you might have an algorithm in iterative process that's going to come with.",
            "That's going to basically go in origin of reasonable.",
            "I polytomous, but you do not sample from the posterior distribution.",
            "OK, so be a little bit careful when you use this type of algorithm on be very critical about basically the result you obtain even on cineport problem, the Gibbs sampler basically can struggle.",
            "So on super high dimensional structure, statistical modeling might be real."
        ],
        [
            "Difficult.",
            "OK, so we go to trade so impact is tried to have as few blocks as possible.",
            "Essentially tried to update correlated variables simultaneously if possible OK?",
            "There's a way that is not often used in machine learning, which is away.",
            "That's where often there are some kind of clever or parametrizations of the model that limits basically the correlation with target the between the random variable under the target on it can really help from a practical point of view on whenever you can integrate out some on the London valuable analytically, please do it.",
            "So that's good.",
            "All this Gibbs sampler, but it somehow is also remain limited, because the only degree of freedom you have is the choice of the partition.",
            "OK, so on each required to submit a bowl to sample from the conditional distribution of components XK.",
            "Given the remaining component.",
            "So there are cases where you're not going to be able to do that, in which case you're going to need to use essentially and of algorithm, which is comforting as an alternative or more exactly sexually or generalization of natural processing."
        ],
        [
            "OK, so.",
            "I don't know what's going on.",
            "I'm sorry.",
            "OK, so one point whipsawn player behind the fact that basically.",
            "You have to try to update correlated, valuable simulataneously.",
            "He died for the time.",
            "It does require being able to simulate essentially from this condition.",
            "This kind of conditional distribution for the simple nuclear bomb data I've been looking at, it was visible.",
            "There's a lot of example where basically even such conditional distribution cannot be sampled from exactly OK.",
            "So in this case, you're going to need to come up."
        ],
        [
            "Something else on essentially an alternative algorithm for doing that is basically made for protesting.",
            "OK, I say so kind.",
            "Actually it's a generalization of it, so we're going to come up with a more general mechanism.",
            "To essentially come up with Markov chain, which admits essentially a given and ion distribution Pi of X. Oh, that's actually use absolutely everywhere, so you should actually know about it, even if you're not interested in Monte Carlo methods.",
            "That's at least something that has been that should be used the origin or Metro police algorithm was proposed.",
            "Laughing in the 50s by some physicists, and is actually the most cited scientific player publication of the 20th century.",
            "There's, like, literally want to receive like 50,000 citations, some ridiculous, right?"
        ],
        [
            "So the way it's going to work, this algorithm that follow OK is a V in some sense quite similar to rejection sampling in the sense that similarly to reject and prompting what you're going to propose, you're going to introduce a proposal distribution within your algorithm.",
            "OK, so here we go.",
            "So you're going to introduce basically given account value, current value of your Shane X.",
            "You're going to introduce this conditional.",
            "Probably don't city OK, so this is a transition kernel from X to Y, so this is positive on the sums.",
            "Basically to one when you integrate respect towards this is conditional on city of why Unix OK, you're going to pick it so that basically it's very easy to sample from this guy.",
            "So for example this guy could be.",
            "Essentially it could be something which is independent of the current value of X.",
            "So normal distribution in Y of mean 0.1.",
            "But it also could be say normal distribution.",
            "Of argument why mean X on violence?",
            "One Valentina squares.",
            "OK, now the basic idea of Metro protesting looks a lot like rejection sampling.",
            "OK, so.",
            "You are in account value, so you're going to generate a Markov chain OK.",
            "So I assume that the current value of the current state of the market Chinese X UJ rate, the new candidate from a proposal distribution.",
            "OK, which can be parameterized by X, so it's a little bit different here from objection, because rejection sampling of there's no notion like totem pole notion, so it in the car in the rejection sampling is just basically independent of X.",
            "But here you propose a new candidate from this conditional distribution.",
            "OK, on then you make sure you introduce kind of arbitrary, not arbitrary, appropriate quality.",
            "We are going to function of Alpha X&Y, which unsure by construction that essentially the simulated Markov chain admits as invariant distribution Pyrex.",
            "OK, so this is where we're going."
        ],
        [
            "On the Android access follow so Middleby testings who sampled from Pyrex.",
            "So you have initial value X at iteration I you have said the current value of the Markov chain is XI minus one.",
            "You simulate a candidate according to this proposal distribution OK, and then you compute these access points probability which is the minimum between one the ratio of the target distribution evaluated a current value of the Markov chain on the purpose value.",
            "On the ratio essentially of the probable distribution, the probability distribution you've been using to simulate why?",
            "OK?",
            "So this is a Q XI minus one Y.",
            "All you also need to compute OK, add the numerator.",
            "The reverse essentially transition that hasn't been simulated, which is the probability essentially of moving from Y to X I -- 1 under Q. OK, now we pull ability so you get to.",
            "So essentially you simulator random variable between zero and one.",
            "If it is inferior to Alpha then you accept the candidate.",
            "All the while you stay where you are.",
            "That's it.",
            "That's very generic algorithm.",
            "Very very simple.",
            "OK."
        ],
        [
            "So now we're going to show is that it actually is which possessing algorithm is indeed admits indeed, basically PIE as an invariant distribution.",
            "OK, so to show that I'm going to show something a little bit more general, I'm going to show that basically something a bit more actually a general with something which we chose that essentially.",
            "K is what we say pie reversible.",
            "So K is priority, but that is essentially under station or a gym.",
            "That is when X is distributed according to \u03a0, then the probability of being this way according to \u03c0 or moving to K according to KXY is equal to portability of basically being this way.",
            "According to why I'm moving from Y to X OK, so essentially under the stationary regime, essentially the condition the joint distribution of X&Y is also the call to the joint distribution of Y&X.",
            "OK, that's actually quite quite powerful thick, so the way I showed that basically just follow.",
            "So what is the transition kernel that is implied by the algorithm of written down?",
            "Where?",
            "What do you do?",
            "So this is a transition kernel to move from KX to Y.",
            "The transition color Metro processing algorithm?",
            "What do you do when you do it in that to Metro police you sampul?",
            "Why according to Q?",
            "You accept it with probability Alpha XY.",
            "OK on what is this guy where it's correspond to the rejection, basically probabilities.",
            "So what is the probability of rejecting a move where it's going to be 1 minus the integral?",
            "Basically of this term respect to Y prime?",
            "Times basically a Delta mass Y equal X. OK, so essentially this thing corresponds to the move.",
            "I've been accepted this thing this components correspond to.",
            "Basically I've rejected my move OK. No so.",
            "This is transition kernel.",
            "Now I want to check this thing.",
            "OK that I've got this equality.",
            "Well I'm telling you that I only need obviously to check it from the Dundee generated component of the Metro police testing schedule because for the generated component, essentially I've got X = Y anyway, so I just check it for the generated, the nondegenerate component of the Markov kernel.",
            "I want to check that.",
            "So I just basically do essence elementary calculation on using the fundamental processing acceptance ratio.",
            "I should I see that indeed I've got that pie.",
            "Is Kerry Versible case OK?",
            "Is piracy?",
            "OK, no.",
            "Basically I'm telling you that obviously the pie Oreos ability of K implies the pie invariants of K, where it's very easy to check.",
            "So we've established that basically these properties is satisfied.",
            "For the current position Colonel K, If I integrate on both side with respect to X, I've got basically that integral of Pi X DX times transition kernel KXY is going to be part of why time the integral respect to X of KYX DX, which is one OK.",
            "So these things Pirates ability implies basically pie invariants.",
            "OK, so I know that the MCMC kernel I've been dealing with a proposed essentially admits essentially.",
            "High as a fixed point that is very good.",
            "This is very generic."
        ],
        [
            "It is a. OK.",
            "So.",
            "To ensure a disability, which is, you know this condition that you need to a market share kernel that are basically our search that from any starting point you can reach any set of positive quality on the pie where the scission condition, where consists of picking and basically transition kernel which has positive mass everywhere where the target has mass.",
            "It is absolutely not necessary.",
            "OK you as long as basically.",
            "If you iterate, basically you mark your proposal long enough, you can explore any original is going to be fine on appearance, it is automatically onshore.",
            "Basically in this algorithm because of the rejection probability you can rule out any periodic behavior of the Markov chain.",
            "OK, so this algorithm you can show that it converge in the extremely weak assumption throughout the target distribution.",
            "OK, but once more the choice of Q is paramount for good behavior of the algorithm.",
            "So basically what I'll do is that the net."
        ],
        [
            "Well known off I will discuss essentially some of those kind of sonar settings so as to set the proposal distribution in MTMT algorithm on.",
            "I will discuss advanced more advanced MCMC algorithm, so we're going to take a break now for half an hour and then we come back.",
            "We'll discuss more carefully.",
            "Metro protesting on advanced MCMC such as slice sampling, parallel tempering on terms of course.",
            "I said oil."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the courses organize follow for those of you've never.",
                    "label": 0
                },
                {
                    "sent": "Basically we don't know anything about Monte Carlo methods.",
                    "label": 0
                },
                {
                    "sent": "I will review very briefly in the first, like 20 minutes, half an hour.",
                    "label": 0
                },
                {
                    "sent": "the Monte Carlo principles.",
                    "label": 0
                },
                {
                    "sent": "OK, then we will move on basically by discussing introducing the class of Markov chain Monte Carlo methods on there.",
                    "label": 1
                },
                {
                    "sent": "I will review the such as Gibbs sampling or Metro processing algorithm on.",
                    "label": 0
                },
                {
                    "sent": "Then I will discuss more sophisticated techniques such as slice sampling, Hamiltonian MCMC.",
                    "label": 0
                },
                {
                    "sent": "Or party tampering.",
                    "label": 0
                },
                {
                    "sent": "So that should take us one owner off.",
                    "label": 0
                },
                {
                    "sent": "OK, so we want to lose.",
                    "label": 0
                },
                {
                    "sent": "Won't waste anytime during basically this morning after that after the break we really start discussing the class of sequential Monte Carlo methods, which is the 2nd essentially large class of Monte Carlo methods, also known in the literature.",
                    "label": 0
                },
                {
                    "sent": "Sometime as particle filters.",
                    "label": 0
                },
                {
                    "sent": "OK, so I'll do first time.",
                    "label": 0
                },
                {
                    "sent": "First one owner of MTM signal off SMC.",
                    "label": 0
                },
                {
                    "sent": "I'll mix basically tomorrow.",
                    "label": 0
                },
                {
                    "sent": "Once we have understood all those techniques were empty anteon SMC then we will describe essentially Monte Carlo methods, which essentially our combination of both MCMC on SMT methods on this will include actually very recent material that have been published actually last year or even should be published.",
                    "label": 0
                },
                {
                    "sent": "Actually very soon.",
                    "label": 0
                },
                {
                    "sent": "OK, so for those of you are really special summer kilometres, I'm afraid you're not going to learn much things this morning.",
                    "label": 0
                },
                {
                    "sent": "OK, but definitely tomorrow at least you should basically get to learn a few new tricks in this field.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so let's talk basically with bit of motivation.",
                    "label": 0
                },
                {
                    "sent": "Why am I interested in doing multi kilometres?",
                    "label": 0
                },
                {
                    "sent": "Well, essentially me.",
                    "label": 0
                },
                {
                    "sent": "It's coming from my interest invasion statistics.",
                    "label": 0
                },
                {
                    "sent": "OK, so essentially you have Asian model choir on the like glued on.",
                    "label": 0
                },
                {
                    "sent": "You use the base root on.",
                    "label": 0
                },
                {
                    "sent": "Here we go, you have the posterior distribution of Teeter.",
                    "label": 1
                },
                {
                    "sent": "Given the observation, first typo does very nice.",
                    "label": 0
                },
                {
                    "sent": "First Slider found a typo.",
                    "label": 0
                },
                {
                    "sent": "This is why here this is not a good start.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is.",
                    "label": 0
                },
                {
                    "sent": "This is the first step.",
                    "label": 0
                },
                {
                    "sent": "Solution, essentially, as soon as you have basically model which are little bit complex, you don't have a closed form expression for this poster distribution, so you need to approximate it on the tools of shares in the stats community on increasingly in the machine learning community consists of using Monte Carlo methods.",
                    "label": 1
                },
                {
                    "sent": "OK, so that's why we will be interested in that.",
                    "label": 1
                },
                {
                    "sent": "Similarly, when you don't want to do send some kind of model selection in a Bayesian framework, you have essentially to compute the marginal likelihood of the observation.",
                    "label": 1
                },
                {
                    "sent": "Which once more is I dimensional integral typically used.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The collimated OK, so everything you will each time you interested in computing his teammates.",
                    "label": 0
                },
                {
                    "sent": "For complicated version modeled say you want to compute the posterior distribution of the parameter Tita under the posterior or posterior variance.",
                    "label": 0
                },
                {
                    "sent": "Who wants more?",
                    "label": 0
                },
                {
                    "sent": "You have high dimensional integrals.",
                    "label": 0
                },
                {
                    "sent": "So basically multicolor matters at what you need to use.",
                    "label": 0
                },
                {
                    "sent": "As soon as you have no like complex model.",
                    "label": 0
                },
                {
                    "sent": "OK so I'm not going to go like give much more detail about that.",
                    "label": 0
                },
                {
                    "sent": "You will have a course by Peter Green.",
                    "label": 0
                },
                {
                    "sent": "Basically two more on Bayesian modeling.",
                    "label": 0
                },
                {
                    "sent": "Each time you're doing essentially Bayesian modeling on you having nuns, non standard mode or you're gonna have to deal movement in kilometres so as to compute marginal distribution.",
                    "label": 0
                },
                {
                    "sent": "Or if you.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Choice did say in computing, say the predictive distribution of a noob Salvation.",
                    "label": 0
                },
                {
                    "sent": "Given the call up Salvation once more this season, I dimensionality or once more you have to use multicolumn.",
                    "label": 0
                },
                {
                    "sent": "It's OK, you have to use identical.",
                    "label": 0
                },
                {
                    "sent": "So that's essentially my motivation.",
                    "label": 0
                },
                {
                    "sent": "Bayesian statistics.",
                    "label": 0
                },
                {
                    "sent": "I want to approximate like high dimensional posterior distribution, however.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, for all the remaining, the rest of this talk I will not put any on faces.",
                    "label": 0
                },
                {
                    "sent": "Essentially on Bayesian statistics I will just assume that I'm interested in a given target distribution.",
                    "label": 0
                },
                {
                    "sent": "Quality distribution turns out from the application point of view, it's typically a posterior distribution, but all the tools obviously I'm describing can be generally used, can be used in a much, much wider context, right?",
                    "label": 0
                },
                {
                    "sent": "So I say for those of you never seen anybody.",
                    "label": 0
                },
                {
                    "sent": "Animators I'm just gonna review, essentially very briefly.",
                    "label": 0
                },
                {
                    "sent": "The main idea behind multi kilometres.",
                    "label": 0
                },
                {
                    "sent": "So let's start with the kind of silly toy example.",
                    "label": 0
                },
                {
                    "sent": "The simplest thing you can think of.",
                    "label": 0
                },
                {
                    "sent": "So we consider we have essentially a circle inscribed in rectangle.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, basically I'm supposing OK, so that's really silly example that basically I've got to idealize rain that falls uniformly on the square OK.",
                    "label": 1
                },
                {
                    "sent": "The Blue Square here OK?",
                    "label": 1
                },
                {
                    "sent": "All I'm interested basically in computing the probability.",
                    "label": 0
                },
                {
                    "sent": "For drop to fall in a given region, a OK so which is proportional.",
                    "label": 1
                },
                {
                    "sent": "Obviously today our have a because they assume that the drops holds uniformly.",
                    "label": 0
                },
                {
                    "sent": "Basically on the square.",
                    "label": 0
                },
                {
                    "sent": "Alright.",
                    "label": 0
                },
                {
                    "sent": "So basically in this case you don't need to do to do anything.",
                    "label": 0
                },
                {
                    "sent": "Basically you know that if you define as D random variable that represent the location of drop on a region of interest, say the circle in my case in the previous slide.",
                    "label": 0
                },
                {
                    "sent": "OK then the probability.",
                    "label": 0
                },
                {
                    "sent": "That drop basically belong that D belongs to a OK deep in my random variable corresponding to drop location is simply the integral of the cell phase of our have a given.",
                    "label": 0
                },
                {
                    "sent": "Basically, I did buy the total area of the square OK where X&Y are the Cartesian coordinates corresponding to the location of the top.",
                    "label": 1
                },
                {
                    "sent": "So like it's really the most basic thing here.",
                    "label": 0
                },
                {
                    "sent": "Obviously I use the fact that I use the assumption by my Rainford uniformly.",
                    "label": 0
                },
                {
                    "sent": "OK, so now assume you don't know how to compute this guy exactly OK, because a for example has very very complex shape.",
                    "label": 0
                },
                {
                    "sent": "Complex shape is not a simple circle then.",
                    "label": 0
                },
                {
                    "sent": "Basically what we're proposing we're going to discuss a simple numerical method.",
                    "label": 0
                },
                {
                    "sent": "The Multicolumn entered through us to approximate numerically this integral.",
                    "label": 0
                },
                {
                    "sent": "OK, so we're going to work is very simple, so assume that you observe and such drop independent drops of rain.",
                    "label": 0
                },
                {
                    "sent": "Each of them being distributed uniformly on the square on Arduino, Daisy Klebe, Idi, essentially the random location of drop I OK, so I assume you want to compute.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Basically, so this is basically the graph you up.",
                    "label": 0
                },
                {
                    "sent": "So this is basically the initial square you have your random drops here that are you observe capital and of them each of them is uniformly distributed according to under on the unit square on.",
                    "label": 0
                },
                {
                    "sent": "Basically you are interested in computing the area of the circle where.",
                    "label": 0
                },
                {
                    "sent": "What could you do is very simple.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Well, the simple thing, the probability basically for drop to belong to the number to belong to circle given that basically they uniformly distributed where you don't need to have done any stats to know that.",
                    "label": 0
                },
                {
                    "sent": "Basically a good estimate of that could be simply the number of dropped you observe that fell into the circle given divided by the total number of drops.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so that's all I did I said to compute the probability of belonging to the circle.",
                    "label": 0
                },
                {
                    "sent": "Just I come the number of gather full have fallen into the circle and I divided total number of drops that.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Equal to capital alright?",
                    "label": 0
                },
                {
                    "sent": "So let's have a little bit of statistical justification for it.",
                    "label": 0
                },
                {
                    "sent": "This is really.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The basic of multicolumn into, well.",
                    "label": 0
                },
                {
                    "sent": "To do that, we tried to formalize a little bit what we've been doing, so I'm introducing basically an indicator function for the set A, which is equal to essentially one, either point of coordinates.",
                    "label": 0
                },
                {
                    "sent": "XY belongs to a on 0, otherwise OK on simply what I'm not doing, I'm doing simple modification, I rewrite the probability was interested in, that is the party that drops belong basically to the set a as simply.",
                    "label": 1
                },
                {
                    "sent": "The expectation of basically this indicator function under this guy, or is this guy is simply the uniform distribution over the square.",
                    "label": 0
                },
                {
                    "sent": "OK, so there's a factor 1 four here because remember, my square goes from minus one to one.",
                    "label": 0
                },
                {
                    "sent": "Oh yes Sir, this is it and is simple it.",
                    "label": 0
                },
                {
                    "sent": "So now basically what we've been doing essentially is that E for you or introduce a new random valuable OK which is simply defined as the indicator function basically applied to the random variable D. Then you have BOD which is essentially.",
                    "label": 0
                },
                {
                    "sent": "Random variable which takes value zero or one Eve dies within Aiden.",
                    "label": 0
                },
                {
                    "sent": "Visit V of these equal to 1.",
                    "label": 0
                },
                {
                    "sent": "Basically, if D is outside Aiden V of D is equal to 0 on.",
                    "label": 0
                },
                {
                    "sent": "Essentially, we've managed to rewrite essentially the probability distribution of interest as the expectation of such random variable and the uniform distribution on the square of interest.",
                    "label": 0
                },
                {
                    "sent": "The initial square S OK, so that's it.",
                    "label": 0
                },
                {
                    "sent": "So essentially.",
                    "label": 0
                },
                {
                    "sent": "You think of it, it said, no, what we've been doing really do this.",
                    "label": 0
                },
                {
                    "sent": "The initial kind of intuitive estimate of the party I was proposing was simply basically counting the number of drop that fell into a divided by the total number of drop.",
                    "label": 0
                },
                {
                    "sent": "You can write that simply as the sum of those random variable VR Y / N is just rewriting essentially of what I've been doing before.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so just really like simple thing re formalizing.",
                    "label": 0
                },
                {
                    "sent": "Basically intern properly in terms of random variable.",
                    "label": 0
                },
                {
                    "sent": "What I've just been doing intuitively.",
                    "label": 0
                },
                {
                    "sent": "OK, now.",
                    "label": 0
                },
                {
                    "sent": "Well basically what do we know?",
                    "label": 0
                },
                {
                    "sent": "Well, we know that we have here essentially one over and some from equal 1 two end of independent random variable V. OK, so basically if you take the limit as N goes to plus Infinity, you have the strong law of large number that tells you that.",
                    "label": 1
                },
                {
                    "sent": "Essentially as of then my estimates given conversion must surely toward the expectation of the under.",
                    "label": 0
                },
                {
                    "sent": "Basically the uniform distribution on the square S. Which is exactly what I was interested.",
                    "label": 0
                },
                {
                    "sent": "So essentially what we've been doing with what we've been using when we were using this estimate is implicitly we are using the law of large numbers of.",
                    "label": 1
                },
                {
                    "sent": "OK, that's all.",
                    "label": 0
                },
                {
                    "sent": "OK, so essentially when is is large enough?",
                    "label": 0
                },
                {
                    "sent": "That's kind of justified the use.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This estimate.",
                    "label": 0
                },
                {
                    "sent": "OK, so that's good.",
                    "label": 0
                },
                {
                    "sent": "That's good.",
                    "label": 0
                },
                {
                    "sent": "Now what about basically the properties of this estimate?",
                    "label": 0
                },
                {
                    "sent": "Well, what we know where it's quite trivial to show that obviously SN is an unbiased estimate of the quantities of interest, which in the case of advice basically apology or belonging to a circle is equal to \u03c0 / 4.",
                    "label": 1
                },
                {
                    "sent": "OK, so now my estimate is unbiased was basically the auto characterized the property that the quality of my estimate.",
                    "label": 0
                },
                {
                    "sent": "Typically we're going to use the valiance, so I've gotta valiance of SN, which is an average of independent random variable, so obviously essentially it's equal to essentially variants or one random variable.",
                    "label": 1
                },
                {
                    "sent": "They're all the same, so I can put any index here divided by 1 / N the number of samples.",
                    "label": 0
                },
                {
                    "sent": "OK, so based on that so you have a variant which decrease in one of them, which is good.",
                    "label": 1
                },
                {
                    "sent": "OK, all, you can also basically invoke a central limit theorem, so not only you have a random estimate.",
                    "label": 0
                },
                {
                    "sent": "Which converter synthetically towards basically the quantity of interest?",
                    "label": 0
                },
                {
                    "sent": "It's unbiased, which is not something I really care because invasion, but also it has basically satisfy yourself or limit time.",
                    "label": 0
                },
                {
                    "sent": "OK, so that's good if you want to play a lot of you are doing like learning bones and so on.",
                    "label": 0
                },
                {
                    "sent": "So if you want to use finite bounds, basically you can also play with it on obtain some kind of finite bounds for this type of estimate.",
                    "label": 0
                },
                {
                    "sent": "I won't go for that OK.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So let's basically here or simple illustration of the behavior.",
                    "label": 0
                },
                {
                    "sent": "My estimate basically as a function of them.",
                    "label": 1
                },
                {
                    "sent": "So this is basically I expected.",
                    "label": 0
                },
                {
                    "sent": "Obviously as N goes to increase to Infinity is going to converge.",
                    "label": 0
                },
                {
                    "sent": "This is the basically the error SN minus \u03c0 for my estimate X.",
                    "label": 0
                },
                {
                    "sent": "Expect this guy to converge towards zero as N goes to Infinity.",
                    "label": 0
                },
                {
                    "sent": "This is unsure by the Central Limit theorem, OK?",
                    "label": 0
                },
                {
                    "sent": "So why do I show something like that?",
                    "label": 0
                },
                {
                    "sent": "Actually, this is really silly example where you see this is a troll.",
                    "label": 0
                },
                {
                    "sent": "Your problem.",
                    "label": 0
                },
                {
                    "sent": "What we're doing now you're trying to compute essentially the area of a circle, basically using using some watercolor method.",
                    "label": 0
                },
                {
                    "sent": "Well can see that the valuation can be actually quite useful for basically low dimensional problem, so multi color method is a method of last resort.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So what about basically so this is the convergence.",
                    "label": 0
                },
                {
                    "sent": "This is over 100 realization.",
                    "label": 0
                },
                {
                    "sent": "The behavior of the errors and we see that you're going realization.",
                    "label": 0
                },
                {
                    "sent": "We obviously, as expected, that valuation.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Quite significant.",
                    "label": 0
                },
                {
                    "sent": "OK, so you are.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "All those properties are satisfied, so OK, so I just say I would just basically discussing that for people who never ordered Monte Carlo method.",
                    "label": 0
                },
                {
                    "sent": "Everything I've been doing here in the case we are having having a unit square on the circle within a square can be generalized essentially to any domain, any space.",
                    "label": 0
                },
                {
                    "sent": "So in particular you could have essentially that instead of adding, say, a square on the 2D plan, you could have essentially your.",
                    "label": 0
                },
                {
                    "sent": "Hypercube basically of dimension NX on NX could be of dimension say 1000 OK on.",
                    "label": 0
                },
                {
                    "sent": "Similarly, you might be interested in computing said the volume or the polity of belonging to the hyperbowl.",
                    "label": 0
                },
                {
                    "sent": "Basically in the space of dimension NX OK on use Monte Carlo.",
                    "label": 1
                },
                {
                    "sent": "Everything I've been saying before does apply also in this context, I've never used whatsoever at anytime, anytime in my previous argument.",
                    "label": 0
                },
                {
                    "sent": "The dimension of the original space.",
                    "label": 0
                },
                {
                    "sent": "OK, so multi Collimators will remain valid in this case if I have it, I can observe and hyper rain in the hypercube uniformly distributed on the hypercube SNX.",
                    "label": 0
                },
                {
                    "sent": "Then I can count the number of drops which fall within the hyperbowl arm.",
                    "label": 0
                },
                {
                    "sent": "Basically if I divide that by the total number of drops I will have an estimate of the probability of belonging to the hyperbowl OK.",
                    "label": 0
                },
                {
                    "sent": "So in particular, what is great?",
                    "label": 0
                },
                {
                    "sent": "We want a collimated.",
                    "label": 0
                },
                {
                    "sent": "Is that the rate of convergence of the estimator?",
                    "label": 1
                },
                {
                    "sent": "If you look at the Valiants is still always going to be in one of the capital and whatever being the dimension of the original space.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is essentially the main argument for using motor kilometres, because if you use Donald Monte Carlo method, typically this rate of convergence is dependent.",
                    "label": 0
                },
                {
                    "sent": "The rate of convergence to zero obvious teammate is dependent of the dimension of the original space.",
                    "label": 0
                },
                {
                    "sent": "On for more sophisticated method on the regularity of the contour of basically the area you're trying to compute the volume, so that's really what is really nice or Monte Carlo rate of convergence independent of the dimension, and This is why really typically people are using multi kilometers.",
                    "label": 1
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "So no, basically one should be also a bit careful about what what we're doing.",
                    "label": 0
                },
                {
                    "sent": "So if you look at the literature, sometimes people claim that Monte Carlo bid the curse of dimensionality because the rate of convergence of UST May is going to be one of a capital N, and on being the number of samples, whatever being the dimension of the space.",
                    "label": 1
                },
                {
                    "sent": "This is not true.",
                    "label": 0
                },
                {
                    "sent": "OK, you have to be very careful with that.",
                    "label": 1
                },
                {
                    "sent": "OK, so let's come back to the problem of essentially looking at my problem, where I mean the hypercube OK. Of dimension NX on I'm looking at basically computing the probability of falling into the hyperbowl hyper sphere of radius R equals one OK using Monte Carlo method.",
                    "label": 0
                },
                {
                    "sent": "OK, so I know in this case that analytically the volume of the atmosphere of radius one.",
                    "label": 0
                },
                {
                    "sent": "Basically he has a function with dimension with space is given by this expression on in particular.",
                    "label": 0
                },
                {
                    "sent": "It converge to zero as N goes.",
                    "label": 0
                },
                {
                    "sent": "The dimensional space increases.",
                    "label": 0
                },
                {
                    "sent": "OK, so don't try to kind of like what happens in low dimension.",
                    "label": 0
                },
                {
                    "sent": "Often can be a bit misleading for dimension, so assume you're trying to compute.",
                    "label": 0
                },
                {
                    "sent": "The probability using Monte Carlo falling within the atmosphere given that you have an eye for rain, observing the iPad cube.",
                    "label": 0
                },
                {
                    "sent": "OK, so was the violence of your estimate.",
                    "label": 0
                },
                {
                    "sent": "In this case, where essentially it's equal to approximately 2, the probability the original party I'm interested in of falling within the hyper sphere divided by the total number of some polls.",
                    "label": 0
                },
                {
                    "sent": "So you could feel that's great because this is very small.",
                    "label": 0
                },
                {
                    "sent": "This is a very small property, but you should know.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Never forget that actually, what matters when you're doing Monte Carlo is not the variance of your estimate, but typically what matters is the related violence of you estimate.",
                    "label": 1
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "Once more, be careful when you're doing Monte Carlo method.",
                    "label": 0
                },
                {
                    "sent": "You want to compute an integral.",
                    "label": 0
                },
                {
                    "sent": "What typically matters is computing the relativ is having an estimate which has good or related variance OK, so the relative ion being defined essentially by the violent divided by the square of the expectation.",
                    "label": 0
                },
                {
                    "sent": "OK, so in this case what you find what you would find is that essentially the variance the related violence would be something which indeed decrease in one of the capitolin, but basically one of appear next is extremely small.",
                    "label": 0
                },
                {
                    "sent": "So the related violence is really really huge.",
                    "label": 0
                },
                {
                    "sent": "So if you want to related variants of, say, about the 10 -- 2, it means that essentially in a dimension 20 you will need like 4 billion samples.",
                    "label": 0
                },
                {
                    "sent": "OK on 1440 you will need like 10 to the power forward, 20 sample.",
                    "label": 0
                },
                {
                    "sent": "OK so monticola metered nice internal rate of convergence but in love scenario it doesn't break the curse of dimensionality.",
                    "label": 0
                },
                {
                    "sent": "In this case it shouldn't be a kind of a mystery to you if you saw.",
                    "label": 1
                },
                {
                    "sent": "Orly blindly into space on you, tried to eat the hyper sphere here using sample for the hypercube is really like finding a needle in a stack.",
                    "label": 1
                },
                {
                    "sent": "In such I dimension on essentially such blind Monte Carlo methods will be a bit stupid, so it's just a bit of cautionary warning about multi Cal.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Limited, Oh yeah, so now let's move to the allied.",
                    "label": 0
                },
                {
                    "sent": "That's it for the really general introduction to Monte Carlo method.",
                    "label": 0
                },
                {
                    "sent": "So let's move already to the general problem, trying to solve.",
                    "label": 0
                },
                {
                    "sent": "OK, So what I'm going to be interested in doing is computing.",
                    "label": 0
                },
                {
                    "sent": "Essentially Joey speaking coming up with this teammate of expectation of function F with respect to party distribution Pyrex, so typically it's possible that your point might not be initially posed this way that you have to write it as an expectation.",
                    "label": 0
                },
                {
                    "sent": "Respect to quality distribution, I assume for the time being that you've done the job for me alright.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Basically, here pie is going to be essentially any arbitrary polity density function.",
                    "label": 0
                },
                {
                    "sent": "I assume that your work and basically RNX, but could be any space.",
                    "label": 0
                },
                {
                    "sent": "This now relative base that essentially is nothing particular being working with numbers.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK so I will introduce some notation.",
                    "label": 0
                },
                {
                    "sent": "Basically that we already use later on quite alert, so I will introduce the Delta Jack function Delta X Note which is basically, whereas if you integrate any function F respect to tell that your function located X notes is equal to FX note, so I won't use measure theoretic notation in this set of lectures.",
                    "label": 0
                },
                {
                    "sent": "You could obviously to be completely rigorous.",
                    "label": 0
                },
                {
                    "sent": "Obviously you should write Delta X, not DX instead of this.",
                    "label": 0
                },
                {
                    "sent": "This integral is not quite rigorous, but as a notation have adopted not to overload notation.",
                    "label": 0
                },
                {
                    "sent": "OK, so if you think or what multicolour really doing, OK it's very simple.",
                    "label": 0
                },
                {
                    "sent": "If you have capital and sampol distributed according to \u03c0 in previously there was my drops that were distributed according to the uniform distribution then TV.",
                    "label": 0
                },
                {
                    "sent": "Clearly what you're doing, what Monte Carlo corresponds to it correspond to doing an approximation of the initial distribution of interests.",
                    "label": 0
                },
                {
                    "sent": "Approximating it by non PR equal measure, which is essentially basically assume the related some of the Delta mass located at the party at the random samples location.",
                    "label": 0
                },
                {
                    "sent": "OK so Monica Lemaitre intuitively why is basically not bad.",
                    "label": 0
                },
                {
                    "sent": "It's not so stupid despite the fact that if you do things blindly it's not really efficient.",
                    "label": 0
                },
                {
                    "sent": "It simply because essentially you approximate basically the target distribution of interest biodex by simply Sarah set of random.",
                    "label": 0
                },
                {
                    "sent": "Coins which automatically concentrate themselves in region of high priority mass.",
                    "label": 0
                },
                {
                    "sent": "OK, that's why it's quite clever.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is a bit funny way of reasoning because weather when you're doing stampley parametric statistics you have like some polls a data on you try to come up with functional representation of your data.",
                    "label": 0
                },
                {
                    "sent": "So you try to approximate that via Goshen of given mean and variance.",
                    "label": 0
                },
                {
                    "sent": "Here is when you're doing what are calories the reverse way you have typically ornate expression for the target distribution of interest on you.",
                    "label": 0
                },
                {
                    "sent": "Come up with.",
                    "label": 0
                },
                {
                    "sent": "Basically, we've we've multicolor representation of it through samples.",
                    "label": 0
                },
                {
                    "sent": "OK, so that's kind of weird.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Thinking.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is a simple trivial example, so this is my multi color approximation of univariate Goshen.",
                    "label": 0
                },
                {
                    "sent": "It seems really silly to make such approximation why dimension on it is follow dimension.",
                    "label": 0
                },
                {
                    "sent": "Multi kilometers would be precluded, but for I dimension essentially the concentration of essentially a random sample regional high probability mass is going to be quite actually.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Relevant.",
                    "label": 0
                },
                {
                    "sent": "OK, so Monte Carlo.",
                    "label": 0
                },
                {
                    "sent": "I'm just redoing very quickly the benefit of basically this estimate, so assume you have capital and sampol distributed according to part you want to approximate the expectation of a function F, respect a pie.",
                    "label": 1
                },
                {
                    "sent": "What you do very simple.",
                    "label": 1
                },
                {
                    "sent": "You simply substitute to buy the empirical measure of your sample.",
                    "label": 0
                },
                {
                    "sent": "Here we go.",
                    "label": 0
                },
                {
                    "sent": "This is 1 over and some of FSI is simple.",
                    "label": 1
                },
                {
                    "sent": "Is a simple visit generalization of what we've done for the drops where F at this stage was basically an indicator function of a set.",
                    "label": 0
                },
                {
                    "sent": "So similarly hello large numbers, it's on buyers on the violence basically decrease as one over and whatever.",
                    "label": 0
                },
                {
                    "sent": "Basically being the dimension of the space doesn't mean that it breaks the curse of dimensionality on you have this on for limited time.",
                    "label": 0
                },
                {
                    "sent": "OK so that's basically Multicolumn entered.",
                    "label": 0
                },
                {
                    "sent": "Similarly what is now it's also about it is not only you have an estimate of the quantity of interest, which is the expectation here, but you can also approximate the variance of this estimate quite easily using the sample by doing simply what?",
                    "label": 1
                },
                {
                    "sent": "A Monte Carlo approximation of the Vine.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So simplifying simple thing, once you are basically high dimensional target distribution, so you have a distribution we've set of argument X One X2 X One X2 obviously can be multivariate.",
                    "label": 0
                },
                {
                    "sent": "If you're interested in having an estimate of the marginal distribution of one of the guys, basically say X1 the way you do your motor approximation.",
                    "label": 0
                },
                {
                    "sent": "Very simple, you discard the sample, the component X2 of the sample that give you an approximation of the marginal next one.",
                    "label": 0
                },
                {
                    "sent": "OK, so you can do a lot of things like that.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so that's basically a actually the multi colored pen support come up you some poor for the parties assert deep store vision Pi K you want to approximate that give you essentially nonpolar equal measure which had the property that essentially automatically you focus.",
                    "label": 0
                },
                {
                    "sent": "You do kind of grade random sampling region of high probability mass.",
                    "label": 0
                },
                {
                    "sent": "Once you have this guy, you can compute easily and take all you can marginalized.",
                    "label": 0
                },
                {
                    "sent": "Easily integrate easily some.",
                    "label": 0
                },
                {
                    "sent": "Some valuable is very simple.",
                    "label": 0
                },
                {
                    "sent": "Alright, so that's quite nice, OK, but you realize basically only abilities to sample from the point distribution of interest pie.",
                    "label": 0
                },
                {
                    "sent": "OK, so that's nice.",
                    "label": 0
                },
                {
                    "sent": "But basically the question is if I give you a party distribution Pi.",
                    "label": 0
                },
                {
                    "sent": "So let's say I give you a complex Bayesian model.",
                    "label": 0
                },
                {
                    "sent": "The razor thin target distribution is the posterior distribution of the random variable and wouldn't rise given the observation.",
                    "label": 0
                },
                {
                    "sent": "Or do you sample from that OK?",
                    "label": 1
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And the answer is, there's essentially no general way of doing if the distribution of interest, easy lava, stone up forms a Goshen multivariate Gaussian exponential.",
                    "label": 0
                },
                {
                    "sent": "I don't know like Basil or whatever.",
                    "label": 0
                },
                {
                    "sent": "Then.",
                    "label": 0
                },
                {
                    "sent": "Basically you can sample from it exactly OK, But as soon as typically you're dealing with more complicated scenarios, you are going to have to come up with some kind of more sophisticated techniques on essentially.",
                    "label": 0
                },
                {
                    "sent": "All the techniques I will discuss essentially are based on the idea of proposing samples from an over distribution, which is easy to sample on.",
                    "label": 1
                },
                {
                    "sent": "Tried to use some kind of mechanism so as to move your sample from a distribution where he's easy to solve poor form to the target distribution.",
                    "label": 0
                },
                {
                    "sent": "That's what we'll do.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "In any case, if you're interested basically in looking at least at some exact simulation techniques to sample from standard distribution.",
                    "label": 0
                },
                {
                    "sent": "Basically I ask.",
                    "label": 0
                },
                {
                    "sent": "I mean, you should have a look at the book back to avoid, which is actually extremely good, but we won't discuss basically this type of technique here.",
                    "label": 0
                },
                {
                    "sent": "OK, everything is available, typically in a MATLAB toolbox or Python or whatever.",
                    "label": 0
                },
                {
                    "sent": "I'm going to basically discuss the scenario where I'm having target distribution which are quite complicated on.",
                    "label": 0
                },
                {
                    "sent": "I don't need to stand out form.",
                    "label": 0
                },
                {
                    "sent": "OK, on TV Kelly TV Kelly.",
                    "label": 0
                },
                {
                    "sent": "In all the scenarios I'm going to deal with.",
                    "label": 0
                },
                {
                    "sent": "OK, I'm going to deal with the case where this is going to be important later on where the distribution.",
                    "label": 1
                },
                {
                    "sent": "I won't to some poor form is known only up to normalizing constant.",
                    "label": 0
                },
                {
                    "sent": "OK, so I'm going to deal primarily with the case, essentially where say \u03c0.",
                    "label": 0
                },
                {
                    "sent": "So they said Pi of X is equal to a function gamma X divided by its normalizing constant, which is the integral of gamma over the world integration domain.",
                    "label": 0
                },
                {
                    "sent": "OK, where gamma is known pointwise, but it's normalizing constant is unknown, so the typical example.",
                    "label": 0
                },
                {
                    "sent": "Say you're doing Bayesian statistics.",
                    "label": 0
                },
                {
                    "sent": "You know the POI analytically.",
                    "label": 0
                },
                {
                    "sent": "You know the likelihood analytically, but the posterior distribution is known only up to a normalizing constant, because proportional to the prior on the likelihood that can be evaluated.",
                    "label": 0
                },
                {
                    "sent": "But you don't have access typically to the marginal likelihood, which is the integral of the likelihood over the pile.",
                    "label": 0
                },
                {
                    "sent": "OK, so typically I will.",
                    "label": 0
                },
                {
                    "sent": "I want to add method which are surgeon that allows me to simulate form pie, but I only need to know Pi up to normalizing constant.",
                    "label": 0
                },
                {
                    "sent": "Alright, so the 1st all like the most general techniques to do that to do exact simulation of such distribution is core rejection sampling.",
                    "label": 1
                },
                {
                    "sent": "He was proposed by Vonda Man.",
                    "label": 0
                },
                {
                    "sent": "I think during the Los Alamos project.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is going to go for it, so regular sampling you want to sample from distribution PIO X is proportional to gamma of X. OK, so you have access to a normalized version of the target distribution gamma of X, but you typically don't know the normalizing constant, which is integral of gamma over the end of the domain of definition capital X.",
                    "label": 0
                },
                {
                    "sent": "Or do you do in a resolution sampling where you say OK?",
                    "label": 0
                },
                {
                    "sent": "What I'm going to do, I'm going to basically sampul.",
                    "label": 0
                },
                {
                    "sent": "I'm going to put some candidates on Poles from none other.",
                    "label": 0
                },
                {
                    "sent": "Essentially proposal quality distribution on the same space, which is going to be like you and I also assume that basically queue is known up to normalizing constant, whereas typically you know it exactly.",
                    "label": 0
                },
                {
                    "sent": "But let's say for the sake of generality that I only know queue up to noisy constant, so you have five you want to sample from pie, you introduce the probability distribution Q.",
                    "label": 0
                },
                {
                    "sent": "On this solution, Q has been picked so that it's easy to sample, form OK, and then you want to introduce kind of mechanism which essentially once you propose sample from Q is going to do some kind of light, some kind of feeling like filtering mechanism.",
                    "label": 0
                },
                {
                    "sent": "That's going to provide you with sample from pipe.",
                    "label": 0
                },
                {
                    "sent": "OK, so to do that we're going to need to introduce assumption and Q and essentially assumption I make is that essentially gamma over Q star.",
                    "label": 0
                },
                {
                    "sent": "Is basically a bonded, so here I.",
                    "label": 0
                },
                {
                    "sent": "Obviously I could have put \u03c0 / Q is upper bounded.",
                    "label": 0
                },
                {
                    "sent": "OK, so essentially what this condition means when you obviously it implies that wherever you've got mass under the initial distribution, you need to have mass under the popular distribution?",
                    "label": 0
                },
                {
                    "sent": "OK, that makes sense, but is also make sure that essentially you need to have a probable distribution which essentially as featured tails than the tales of the target distribution.",
                    "label": 0
                },
                {
                    "sent": "OK, this is really essentially.",
                    "label": 0
                },
                {
                    "sent": "This condition means so you want basically a popular distribution that speaker tell OK, so this is the condition we introduced on Q 2, so I don't say it's easy to set up.",
                    "label": 0
                },
                {
                    "sent": "This is the assumption I need to make.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, now basically you might not be able to compute exactly the sub between gamma on Q star which is given by C. So let's consider.",
                    "label": 0
                },
                {
                    "sent": "But let's say that even if.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I don't know how to compute this guy exactly.",
                    "label": 0
                },
                {
                    "sent": "You can find an upper bound on that which is given by C prime OK.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Then access project procedure policy that's follow, so you get a sampul.",
                    "label": 0
                },
                {
                    "sent": "So let's basically show it.",
                    "label": 0
                },
                {
                    "sent": "So I had done already.",
                    "label": 0
                },
                {
                    "sent": "Draw.",
                    "label": 0
                },
                {
                    "sent": "Morning, so this is the way it works, so this is the target distribution of interest.",
                    "label": 0
                },
                {
                    "sent": "OK, which is unnormalized on bloops.",
                    "label": 0
                },
                {
                    "sent": "This is gamma of X.",
                    "label": 0
                },
                {
                    "sent": "Basically I have access to another anomalous proposal, Q star, which hurts when it's like multiplied by C prime.",
                    "label": 0
                },
                {
                    "sent": "I've got C prime, Q star X which is always superior to gamma of X.",
                    "label": 0
                },
                {
                    "sent": "So basically this black curve which correspond to see primetime Q star X always dominates.",
                    "label": 0
                },
                {
                    "sent": "Essentially the target distribution.",
                    "label": 0
                },
                {
                    "sent": "The Unnormalized target distribution gamma.",
                    "label": 0
                },
                {
                    "sent": "So what do I do?",
                    "label": 0
                },
                {
                    "sent": "I sampul one guy.",
                    "label": 0
                },
                {
                    "sent": "From Q, the popular distribution of assume it's easy.",
                    "label": 0
                },
                {
                    "sent": "OK arm.",
                    "label": 0
                },
                {
                    "sent": "Then I saw him pull a uniform, basically random variable in the interval 0C prime Q star.",
                    "label": 0
                },
                {
                    "sent": "Why OK?",
                    "label": 0
                },
                {
                    "sent": "So this is this thing is the uniform distribution on this interval OK?",
                    "label": 0
                },
                {
                    "sent": "If you is inferior to gamma, why then I return why and I say why is it exact sample from pipe all the way or return to step one?",
                    "label": 1
                },
                {
                    "sent": "So you basically assume you have a sample white here.",
                    "label": 0
                },
                {
                    "sent": "OK, so then.",
                    "label": 1
                },
                {
                    "sent": "You need to sample the uniform random variable in this interval, which is 0 C prime, Q star Y.",
                    "label": 0
                },
                {
                    "sent": "So you draw a uniform random number basically.",
                    "label": 0
                },
                {
                    "sent": "In this interval, if it's here, the resulting sample you have U which is superior to gamma.",
                    "label": 0
                },
                {
                    "sent": "Why?",
                    "label": 0
                },
                {
                    "sent": "Because this is above the blue chair, so you reject the sample.",
                    "label": 0
                },
                {
                    "sent": "OK, so reject here.",
                    "label": 0
                },
                {
                    "sent": "EBay Dick lips ear.",
                    "label": 0
                },
                {
                    "sent": "You are basically so you obtain a sample U which is in this part of the space that is below gamma Y.",
                    "label": 0
                },
                {
                    "sent": "Then you accept the sample.",
                    "label": 0
                },
                {
                    "sent": "That's what you do.",
                    "label": 0
                },
                {
                    "sent": "That's very simple thing.",
                    "label": 0
                },
                {
                    "sent": "OK so that's basically a rejection sampling.",
                    "label": 0
                },
                {
                    "sent": "That's all it is.",
                    "label": 0
                },
                {
                    "sent": "OK, so that's that's a very simple thing.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To pull this correct because this is obviously just a graph explaining explaining what we're doing OK, but he's not opposed to poets correct?",
                    "label": 0
                },
                {
                    "sent": "I won't go through actually it.",
                    "label": 0
                },
                {
                    "sent": "Oh, I see I can do it so well.",
                    "label": 0
                },
                {
                    "sent": "Essentially what you say you look at the probability to prove that it's correct.",
                    "label": 0
                },
                {
                    "sent": "You're going to have to look at the probability that the random variable why you accepted as the right distribution.",
                    "label": 0
                },
                {
                    "sent": "So let's look at a party that why is inferior 2X on why is accepted, where this is the expectation.",
                    "label": 0
                },
                {
                    "sent": "Of the event that you is inferior to gamma Y under the distribution of essentially why on you on the distribution the density of Y is Q.",
                    "label": 0
                },
                {
                    "sent": "This is a proposal OK on the city associated to you is the uniform distribution of one of the 01 Q star?",
                    "label": 0
                },
                {
                    "sent": "Why so?",
                    "label": 0
                },
                {
                    "sent": "This is why I've got this factor here and then you have the UDY here that I've been cutting my expression.",
                    "label": 0
                },
                {
                    "sent": "So here.",
                    "label": 0
                },
                {
                    "sent": "There's an integral of respect to you on why.",
                    "label": 0
                },
                {
                    "sent": "OK, so you do the calculation simply.",
                    "label": 0
                },
                {
                    "sent": "You can integrate our respect to you very easily.",
                    "label": 0
                },
                {
                    "sent": "That gets this factor gamma while that gets out here.",
                    "label": 0
                },
                {
                    "sent": "OK, once you get a party that why isn't fair to X or Y is accepted, you can obviously by picking up what's working here simply with the Royal line, but it's true for any case when they were priority that why is accepted.",
                    "label": 0
                },
                {
                    "sent": "You just basically take X going to Infinity that give you a party there.",
                    "label": 0
                },
                {
                    "sent": "Why is accepted?",
                    "label": 0
                },
                {
                    "sent": "K. On when basically you combine both result, what is the distribution of idea?",
                    "label": 0
                },
                {
                    "sent": "Why is inferior to small value X given it's been accepted where you use basically apology of a given B is probably a very ambiguous divided by quality of B.",
                    "label": 0
                },
                {
                    "sent": "Here we go, you have basically the that.",
                    "label": 0
                },
                {
                    "sent": "Basically this is the distribution function, the CDF associated to the density Pi, so ends why is distributed according to pipe.",
                    "label": 0
                },
                {
                    "sent": "Sorry you have to.",
                    "label": 0
                },
                {
                    "sent": "You have to compute it yourself on.",
                    "label": 0
                },
                {
                    "sent": "This is obviously going to be a big problem.",
                    "label": 0
                },
                {
                    "sent": "So yeah, I agree with you.",
                    "label": 0
                },
                {
                    "sent": "So this thing requires actually indeed a lot of work, because as pointed out by.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Colleague, you need essentially to come up with an upper bound on this.",
                    "label": 0
                },
                {
                    "sent": "This ratio, or that's not easy when you're going to deal with high dimensional scenarios.",
                    "label": 0
                },
                {
                    "sent": "So indeed that's a bit of a pain actually.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The average is going to go, so you got loads of look at the speed, the acceptance probability so.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Zoom basically let's have a look at apology acceptance, where essentially that's going to be there to quantify the quality of your algorithm.",
                    "label": 0
                },
                {
                    "sent": "Because if you have to wait, say you have to propose 1 billion candidates to get one sample from pine or really efficient, where we see that indeed apology acceptance where is directly proportional to 1 / C prime.",
                    "label": 0
                },
                {
                    "sent": "So indeed you could try to be do lose job on picking SQL as a huge constant to be sure that you are bound, but you pay the price automatically because if you increase the primes.",
                    "label": 0
                },
                {
                    "sent": "To make sure like that, basically you have an upper bound, say between gamma antipyretics work.",
                    "label": 0
                },
                {
                    "sent": "You start then.",
                    "label": 0
                },
                {
                    "sent": "Basically it's going to be bad.",
                    "label": 0
                },
                {
                    "sent": "OK, you get accepted is going to it.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Probably small, so that's not good.",
                    "label": 0
                },
                {
                    "sent": "That's not good at all, actually OK.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so that's that's a limitation of it.",
                    "label": 0
                },
                {
                    "sent": "Another limitation which is more important is that this thing doesn't scale at all in high dimension.",
                    "label": 0
                },
                {
                    "sent": "OK, so let's take basically the target distribution.",
                    "label": 0
                },
                {
                    "sent": "OK, we're X as an real component, which are essentially independent normal random variable, so this is the target distribution.",
                    "label": 0
                },
                {
                    "sent": "This is just a multivariate Goshen Zero mean unit variance.",
                    "label": 0
                },
                {
                    "sent": "OK, let's say that you use for rejection sampling.",
                    "label": 0
                },
                {
                    "sent": "Probable distribution, which has exactly the same essentially functional shape.",
                    "label": 0
                },
                {
                    "sent": "This is a product of univariate Goshen, except that not each component has a variance in mask.",
                    "label": 0
                },
                {
                    "sent": "Well, OK. Well, clearly we want \u03c0 / Q to be upper bounded, or equivalently normalized version of \u03c0 divided by novelization of Q to be upper bounded.",
                    "label": 0
                },
                {
                    "sent": "So we won't basically do proposal to have essentially feature bound thicker tails than the target.",
                    "label": 0
                },
                {
                    "sent": "So you want Sigma squared to be superior to one.",
                    "label": 0
                },
                {
                    "sent": "OK, so that's a necessary condition to essentially use rejection sampling in this case, so that's the ratio \u03c0 / Q. OK, and if you do a calculation even by essentially picking essentially the best majorization constant between \u03c0 and Q, you find acceptence polarity or rejection sampling is in one of the Sigma to the power NX.",
                    "label": 0
                },
                {
                    "sent": "OK, so signals to be superior to one, and essentially you're going to have the access point 5 decrease exponentially fast with the dimensional space.",
                    "label": 0
                },
                {
                    "sent": "That doesn't work.",
                    "label": 0
                },
                {
                    "sent": "Essentially, that's going to be very, very limited.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so there's a problem with the rejection sampling.",
                    "label": 1
                },
                {
                    "sent": "He just basically works in very like limited dimension on.",
                    "label": 0
                },
                {
                    "sent": "The problem is essentially what you're trying to do, where you trying to support everything, like in one go, support all the components I dimensional put some possibly idea module component simultaneously on.",
                    "label": 0
                },
                {
                    "sent": "There's no correcting mechanism.",
                    "label": 0
                },
                {
                    "sent": "Essentially you want to sample some components in and can never come back somehow.",
                    "label": 1
                },
                {
                    "sent": "So that's essentially kind of pointing rejection sampling Isabella 2.",
                    "label": 0
                },
                {
                    "sent": "Bold, essentially a Porsche to simulation.",
                    "label": 0
                },
                {
                    "sent": "Alright, so instead what we're going to do is instead of trying to win, whoever I dimensional problem.",
                    "label": 1
                },
                {
                    "sent": "OK to try to sampul.",
                    "label": 1
                },
                {
                    "sent": "Essentially the all the components simultaneously.",
                    "label": 1
                },
                {
                    "sent": "One thing are trying to do is to come up with some kind of iterative mechanism so as basically to sample from pie.",
                    "label": 0
                },
                {
                    "sent": "So that's that's the kind of idea, essentially just on our way to do that.",
                    "label": 0
                },
                {
                    "sent": "Is Mark up channel to kilometer?",
                    "label": 0
                },
                {
                    "sent": "OK, so I'm just going to go through an inventory.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Sample so this is an example, is actually quite famous invasion literature which is like around the nuclear pump data.",
                    "label": 1
                },
                {
                    "sent": "OK so I'm just going to explain describe you.",
                    "label": 0
                },
                {
                    "sent": "The model is kind of motivating example for MCMC on the data you have as follows.",
                    "label": 0
                },
                {
                    "sent": "So you have access to basically data which have been taken from some nuclear plants.",
                    "label": 0
                },
                {
                    "sent": "These are real data by the way, so you have like you monitor essentially 10 pumps.",
                    "label": 0
                },
                {
                    "sent": "OK, you know nuclear nuclear.",
                    "label": 0
                },
                {
                    "sent": "Nuclear plants OK on you up server.",
                    "label": 0
                },
                {
                    "sent": "For each pump you will given 2 information which is essentially.",
                    "label": 0
                },
                {
                    "sent": "The amount of time you observe you monitored this pump OK so you monitor set pump #362 minutes or 62 days ago.",
                    "label": 0
                },
                {
                    "sent": "Remember what's the unit is still relevant during that time you were given a filler or number of upsell fillers.",
                    "label": 0
                },
                {
                    "sent": "OK so say the problem #3 over like 62 days.",
                    "label": 0
                },
                {
                    "sent": "Yup cell 5 fillers which is quite a lot.",
                    "label": 0
                },
                {
                    "sent": "Actually by the way never mind OK. On you know, tried to sit to, to to, basically set to statistical model on that.",
                    "label": 0
                },
                {
                    "sent": "OK, So what you're going to say is essentially that you're going to make that.",
                    "label": 0
                },
                {
                    "sent": "Basically the number of failure of palm number K is just going to follow question process with the parameter Lambda K which independent of the pump pump index.",
                    "label": 1
                },
                {
                    "sent": "OK, so that essentially if you assume that the failures basically follow person positive parameter Lambda K over and observe time TK.",
                    "label": 1
                },
                {
                    "sent": "Number of fillers PK.",
                    "label": 0
                },
                {
                    "sent": "Easy question follow person distribution of power meter, long decay time TK OK.",
                    "label": 0
                },
                {
                    "sent": "So that's the model for the data.",
                    "label": 0
                },
                {
                    "sent": "OK um.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Basically know what I'm going to do.",
                    "label": 0
                },
                {
                    "sent": "I'm going to Beijing here.",
                    "label": 0
                },
                {
                    "sent": "Essentially what I want to do is, given the observation I have on this person, assumption, I want to infer esentially the unknown, basically person right Lambda K associated to each pump.",
                    "label": 0
                },
                {
                    "sent": "OK, so I've got this person model for the palm fillers.",
                    "label": 0
                },
                {
                    "sent": "So now what I need to fit my basically my data.",
                    "label": 0
                },
                {
                    "sent": "I'm going to follow and we want to infer those parameter Lambda K from the data.",
                    "label": 0
                },
                {
                    "sent": "Blue, beige, and a portion.",
                    "label": 0
                },
                {
                    "sent": "So I'm going to basically follow the following a Porsche.",
                    "label": 0
                },
                {
                    "sent": "I'm going to say that conditional opens for my parameter Alpha beta loan that K the parameters longer care are independent on distributed according to gamma distribution of parameter Alpha beta OK.",
                    "label": 0
                },
                {
                    "sent": "Essentially, you know what I'm going to do, which is something that will be discussed at length by by, by Peter Peter Grain tomorrow, where I'm going to be actually a bit more bit cleverer than that.",
                    "label": 0
                },
                {
                    "sent": "I'm going to try, essentially, to tide up the prior between all those parameter Lambda one, only to learn that tent by simply setting a random additional hyper prior on the parameter beta.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is a simple yockey called model model.",
                    "label": 0
                },
                {
                    "sent": "Where essentially, nada marginal Power Distribution of along the $1 too long at 10.",
                    "label": 0
                },
                {
                    "sent": "They're basically it's exchangeable on its own independent anymore, so this kind of models allow you to both transform the observation from over bumps.",
                    "label": 0
                },
                {
                    "sent": "No, basically, under such a model, even if you're not interested in Bayesian stats under such a model, I've got other random variable I'm interested in are basically the failure rate, Lambda want along that turn on the additional hyperparameter beta.",
                    "label": 0
                },
                {
                    "sent": "Basically from the Asian POV, it means that what I'm interested in you mentioned in the posterior distribution over on that one.",
                    "label": 1
                },
                {
                    "sent": "I'm not too long at 10 bit are given basically the observation time on the number of fellows.",
                    "label": 0
                },
                {
                    "sent": "So it's very simple is proportional simply.",
                    "label": 0
                },
                {
                    "sent": "To display Salvation is proportional to the prior OK on the prior follow gamma distribution for each parameter given beta.",
                    "label": 1
                },
                {
                    "sent": "OK, so This is why I've got those terms coming from the Gamma Pi.",
                    "label": 0
                },
                {
                    "sent": "Are these things coming basically from the diaper party on beta on?",
                    "label": 1
                },
                {
                    "sent": "This is essentially the light blue term corresponding to my person assumption.",
                    "label": 0
                },
                {
                    "sent": "OK, so I'm interested in is posterior distribution OK?",
                    "label": 0
                },
                {
                    "sent": "It's really simple model on.",
                    "label": 0
                },
                {
                    "sent": "Still I have no clue essentially or to approximate it.",
                    "label": 0
                },
                {
                    "sent": "Even doing like deterministic approximation here would be already standard method with the pain OK and you tried to do injection sampling here you would need to come up with a kind of like popular distribution in order to do that.",
                    "label": 0
                },
                {
                    "sent": "I mean it's too high dimensional to kind of good popular distribution.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It's a pity because essentially this part this this essentially this problem seems to have a lot of structure.",
                    "label": 0
                },
                {
                    "sent": "In particular also the joint distribution of Lambda and beta group Salvation is quite complicated.",
                    "label": 0
                },
                {
                    "sent": "What do some expose some conditional distribution have a much simpler form, so if you look at the conditional distribution of the parameter Lambda given data on the observation well by using elementary calculation you see that this thing factorizes a product of gamma distribution.",
                    "label": 0
                },
                {
                    "sent": "It's quite simple.",
                    "label": 0
                },
                {
                    "sent": "Similarly, if you look at the conditional distribution of beta, given the observation on the parameter Lambda, this thing is a simple gamma distribution as well.",
                    "label": 0
                },
                {
                    "sent": "So the joint distribution is a nightmare, but the conditional distribution of longer given beta and beta, given Lambda, are quite simple, OK.",
                    "label": 0
                },
                {
                    "sent": "So what we gonna propose, we're going to try to look at an algorithm which is called actually Gibbs sampler, and I will try to justify later on.",
                    "label": 0
                },
                {
                    "sent": "So instead we're going posing so as to approximate the posterior distribution of Lambda on beta given the option.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Station is the following iterative algorithm and this is known in the literature Gibbs sampler, so that's going to be longer.",
                    "label": 0
                },
                {
                    "sent": "ISM is not going to be like rejection sampling.",
                    "label": 0
                },
                {
                    "sent": "OK, I'm not going to be gone till later on to have some point exactly the speed.",
                    "label": 0
                },
                {
                    "sent": "According to put, Syria, it's an iterative algorithm that's going to proceed as follow.",
                    "label": 0
                },
                {
                    "sent": "So assuming the iteration, I OK. Basically you have a set of parameters.",
                    "label": 0
                },
                {
                    "sent": "We sell the current value of the parameter Lambda on the current value of beta.",
                    "label": 0
                },
                {
                    "sent": "On where are you proposing to do alliteration?",
                    "label": 0
                },
                {
                    "sent": "I plus one of your.",
                    "label": 0
                },
                {
                    "sent": "Iterative algorithm is that conditional upon the current value of beta you sampol the parameter Lambda according to the conditional distribution.",
                    "label": 0
                },
                {
                    "sent": "Or this is a product of gamma distribution.",
                    "label": 0
                },
                {
                    "sent": "OK, on once you are basically new or revised values for the parameter Lambda, you update basically beta your parameter beta by sampling it for according to its condition or distribution.",
                    "label": 0
                },
                {
                    "sent": "Given the current value of Lambda on the observation.",
                    "label": 0
                },
                {
                    "sent": "OK, so that I know because the conditional distribution are very easy, so that's good.",
                    "label": 0
                },
                {
                    "sent": "So I have this kind of algorithm which basically instead of trying to sample now in this 11 dimensional space, I just need to solve for simple essentially easier random variable distributed according to standard Gamma.",
                    "label": 0
                },
                {
                    "sent": "And I can do that using Matlab say OK.",
                    "label": 0
                },
                {
                    "sent": "So you could do that OK. Or you could also update the things randomly.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I never see the question is basically where.",
                    "label": 0
                },
                {
                    "sent": "You do that.",
                    "label": 0
                },
                {
                    "sent": "You sample from this conditional distribution.",
                    "label": 0
                },
                {
                    "sent": "Is it going to give you basically sample approximately distributed according to the joint distribution of interest?",
                    "label": 0
                },
                {
                    "sent": "It seems like it's a complete terroristic for the time being on.",
                    "label": 0
                },
                {
                    "sent": "If basically is the case is basically situated algorithm converge in some sense throughout the target distribution.",
                    "label": 0
                },
                {
                    "sent": "How many times should I basically iterate this algorithm so as to get sample approximately distributed according to target?",
                    "label": 1
                },
                {
                    "sent": "OK, on the way, essentially to look at this, this kind of question to answer this question.",
                    "label": 0
                },
                {
                    "sent": "Is basically to realize that essentially the sequence of defined this way iteratively is nothing but a Markov chain on a Markov chain that has extremely nice properties, OK?",
                    "label": 1
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So let's brief.",
                    "label": 0
                },
                {
                    "sent": "Introduction to Markov chain.",
                    "label": 0
                },
                {
                    "sent": "OK, so I'm going to call you all know about Markov chain, I'm sure.",
                    "label": 0
                },
                {
                    "sent": "OK, so I'm going to call you to sequence.",
                    "label": 0
                },
                {
                    "sent": "Random variable is going to be a Markov chain, is satisfied the following property that is the probability that XN belongs to a set to a given the path value.",
                    "label": 0
                },
                {
                    "sent": "I've observed X notice a superscript T. Rex, not X1 X N -- 1 is only based is equal to the probability distribution of accent given only X N -- 1.",
                    "label": 0
                },
                {
                    "sent": "OK, so that's basically.",
                    "label": 0
                },
                {
                    "sent": "To stand out definition for Markov process OK here XN text value in arbitrary space.",
                    "label": 0
                },
                {
                    "sent": "Capital X is not obviously necessarily a finite state space.",
                    "label": 0
                },
                {
                    "sent": "OK, on, I will denote basically the transition kernel of this Markov chain, pxy soda, pH, DY.",
                    "label": 0
                },
                {
                    "sent": "If you want the probability to move from basically to being in a state X on moving the infinitesimal neighborhood or on YDY.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So this is my Markov care.",
                    "label": 0
                },
                {
                    "sent": "Notify integrate over a that give me the polarity of being in a given the current value that X N -- 1 is equal to small X. OK, so now what do we know where?",
                    "label": 0
                },
                {
                    "sent": "Basically if you look basically at the marginal joint distribution of X N -- 1 XN OK, then the joint distribution of that of the distribution and probably the Texan minus one belongs to a onexton belongs to be where is going to be basically the probability likes and minus one belongs DX where I sum over the space a * X = B. OK.",
                    "label": 1
                },
                {
                    "sent": "Which is what where you simply.",
                    "label": 1
                },
                {
                    "sent": "Basically the probability that X N -- 1 by applying now that P of X N -- 1 XN is P of X N -- 1 time period send you an X and minus one that give me basically that the probability of being in X N -- 1 time.",
                    "label": 0
                },
                {
                    "sent": "The probability transition kernel of moving from X to the set big.",
                    "label": 0
                },
                {
                    "sent": "So these thing in the literature is known as Chapman Kolmogorov equation.",
                    "label": 0
                },
                {
                    "sent": "OK so essentially well as nothing much here.",
                    "label": 0
                },
                {
                    "sent": "I'm just saying that basically.",
                    "label": 0
                },
                {
                    "sent": "You can ride the joint as basically the marginal time the transition counter.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So what I want to do, essentially, you might want Malcolm to kilometers do on this is the key idea and I'm going to see that this is satisfied by the artistic algorithm patented before what?",
                    "label": 0
                },
                {
                    "sent": "Do is that essentially they say you are given the target distribution Pi OK, which are only known up to normalizing constant.",
                    "label": 0
                },
                {
                    "sent": "Essentially you want to build a Markov chain, a Markov process.",
                    "label": 0
                },
                {
                    "sent": "Of transition kernel P OK, that define essentially the party to moving from X to Y or you want to design this kernel surge at essentially.",
                    "label": 0
                },
                {
                    "sent": "If you add your age 60 C value, you've simulated of XN or fire XN.",
                    "label": 0
                },
                {
                    "sent": "Then essentially this guy will satisfy your lower number on the will converse to the expectation of five under the target pipe.",
                    "label": 0
                },
                {
                    "sent": "OK, so that's really the idea you try to simulate.",
                    "label": 0
                },
                {
                    "sent": "A Markov process will basically search that when you look at century this kind of average of essentially the iteration number that converts word integral of interest.",
                    "label": 0
                },
                {
                    "sent": "Home or this?",
                    "label": 0
                },
                {
                    "sent": "Because this is not necessary later on.",
                    "label": 0
                },
                {
                    "sent": "Essentially you want to come up with an algorithm such that at some, particularly in the number of iterations, the sample generator distribution, which is approximately distributed according to Pi.",
                    "label": 0
                },
                {
                    "sent": "This is going to be just approximation, so for this thing to be valid, you don't need that actually.",
                    "label": 0
                },
                {
                    "sent": "But this thing is a condition we will try to ensure that I'm OK.",
                    "label": 0
                },
                {
                    "sent": "So you want to come up with such a Markov kernel on?",
                    "label": 0
                },
                {
                    "sent": "You want to serve with the check mark of Colonel so that it's easy to simulate the Markov chain even if Pi is highly complex.",
                    "label": 1
                },
                {
                    "sent": "So that's really what we want to do.",
                    "label": 0
                },
                {
                    "sent": "OK, so one kind of natural requirement for that.",
                    "label": 0
                },
                {
                    "sent": "A natural requirement for that is that you if basically you want.",
                    "label": 0
                },
                {
                    "sent": "Basically, if you want this kind of condition to be satisfied, natural requirement is that your transition counter would satisfy the following thing.",
                    "label": 0
                },
                {
                    "sent": "If XN minus one was to be distributed according to \u03c0 that you want to make sure that at the following iteration the random variable XN is also going to be distributed according to Pi.",
                    "label": 0
                },
                {
                    "sent": "OK, so that's actually essentially the kind of thing we want to ensure.",
                    "label": 0
                },
                {
                    "sent": "I want this kind of process, which essentially admits pies as an invariant distribution.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so I'm going to give you an example here which has nothing to do for the time being we've some kind of empty empty, so consider the following normal auto regressive process.",
                    "label": 0
                },
                {
                    "sent": "OK, where essentially Alpha absolute value of Alpha is inferior to one.",
                    "label": 0
                },
                {
                    "sent": "OK, so you got XN is equal to FX N -- 1 plus VN OK, so this thing it defines the Markov process on the real line search that essentially the.",
                    "label": 0
                },
                {
                    "sent": "Tom T shirt and the priority of moving from X to Y.",
                    "label": 0
                },
                {
                    "sent": "If I write everything in don't city, I'm going to write pxy OK then basically what it is where it's normal distribution of basically so like here if I go with the distribution of X and given X and minus one is a normal distribution of mean Alpha X and minus one on variants.",
                    "label": 0
                },
                {
                    "sent": "Basically Sigma square.",
                    "label": 0
                },
                {
                    "sent": "So basically the transition kernel of non Markov process is given by this guy.",
                    "label": 0
                },
                {
                    "sent": "OK so normal kernel.",
                    "label": 0
                },
                {
                    "sent": "Now one can easily check OK that bike if you basically look at the scale node.",
                    "label": 1
                },
                {
                    "sent": "You can easily check that if you look if you consider introduced this target distribution Pyrex, which is a normal distribution or mean zero and variance in my square over 1 minus Alpha Square, then if X and minus one where to be distributed according to Pi of X, then if you basically simulate to some pool why?",
                    "label": 0
                },
                {
                    "sent": "According to this foundation Colonel using simply this occasion then you obtain a new sample which is also exactly distributed.",
                    "label": 0
                },
                {
                    "sent": "Adding to its normal distribution.",
                    "label": 0
                },
                {
                    "sent": "So in this case you can say that you can think of it that basically if you're on a Markov chain, OK, according to this condition kernel, then you expect that essentially this Markov chain is going to be such that after a few times step, basically the sample you generate are approximately distributed according to Pi of X. OK, so it's really the reasoning behind it underlying beyond OK.",
                    "label": 1
                },
                {
                    "sent": "So obviously that would be a silly way to sample from this normal distribution.",
                    "label": 1
                },
                {
                    "sent": "In this case we know how to sample exactly from PIE in this case, so we don't need to run some kind of markup chain Markov process to simulate from it.",
                    "label": 0
                },
                {
                    "sent": "But basically MCMC will be used in a much more complex scenarios where you don't know pie.",
                    "label": 0
                },
                {
                    "sent": "You cannot sample from Pi exactly on yet, you can come up, you can simulate Markov process which are such that essentially aseptically their distributed.",
                    "label": 0
                },
                {
                    "sent": "They're the sample are going to do this really according to \u03c0. OK.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So I'm just going to give you a simple example in this case.",
                    "label": 0
                },
                {
                    "sent": "So say you want to simulate from the standard normal density.",
                    "label": 0
                },
                {
                    "sent": "But instead of using the sampling directly from it, you're going to simulate some.",
                    "label": 0
                },
                {
                    "sent": "You're going to run Markov chains.",
                    "label": 0
                },
                {
                    "sent": "Basically you can simulate some Markov process which admits basically this target distribution as inbound distribution as limiting distribution, then basically.",
                    "label": 0
                },
                {
                    "sent": "Let's have a look at what's happening, so you assume that initial distribution of the Markov chain is basically uniform on the interval zero 20 OK, and then for each of these Markov chain you run the process.",
                    "label": 1
                },
                {
                    "sent": "You run this following Markov process on you look at what's going on.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So this is what's happening, so at time one you have simulate you have simulated 10 in the 1000 dependent Markov chain, which are basically with the initial set is distributed uniformly on the interval zero 20 on.",
                    "label": 0
                },
                {
                    "sent": "Then those Markov chain you make them this thing you make them involved in dependently according to the normal auto regressive process.",
                    "label": 0
                },
                {
                    "sent": "OK you look, basically add the distribution of the resulting.",
                    "label": 0
                },
                {
                    "sent": "1000 Sampul after say, 10 iteration.",
                    "label": 0
                },
                {
                    "sent": "100 iteration, on sale, and so forth.",
                    "label": 0
                },
                {
                    "sent": "And what you see what happens is that what happened is what you expected we were expecting is that essentially after essentially a few few times step, then the distribution of the simulated sample approximate the limiting target, the invariant distribution Pi of X. OK, so this is the kind of idea.",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So in this case, the target normal distribution in this summer is going to be fixed point for the simulated.",
                    "label": 1
                },
                {
                    "sent": "The distribution of simulated sample.",
                    "label": 0
                },
                {
                    "sent": "OK, you never go away once.",
                    "label": 0
                },
                {
                    "sent": "Basically you've reached this distribution.",
                    "label": 1
                },
                {
                    "sent": "Basically, the histogram never drift away from the target distribution of interest.",
                    "label": 0
                },
                {
                    "sent": "OK, so that seems that too.",
                    "label": 0
                },
                {
                    "sent": "This is a way perhaps to proceed OK in the general case, E5 goods target distribution pie, which is very complex to sample from, not a normal.",
                    "label": 0
                },
                {
                    "sent": "Perhaps I could come up with basically chocolate sample from Pike directly past where I could come up with easily easier Markov process, which basically admits which is such that when I simulated on the long run is going to generate sample distributed according to \u03a0. OK, that's the kind of idea on turns on.",
                    "label": 0
                },
                {
                    "sent": "Actually, instead of.",
                    "label": 0
                },
                {
                    "sent": "Also what you're going to do, you're going to try to come up instead of simulating in parallel a lot of Markov chain here, you just go.",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Simulator one is going to be much easier.",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So that's the idea, OK?",
                    "label": 0
                },
                {
                    "sent": "Alright, so that's what I want to do.",
                    "label": 0
                },
                {
                    "sent": "Essentially I want to come up, so let's keep a lot of thing here.",
                    "label": 0
                },
                {
                    "sent": "Essentially, what I want to come up, I want to come up with.",
                    "label": 0
                },
                {
                    "sent": "I want to generate a Markov process which is going to be such that essentially as the number of iteration increase, these guys are going to converge toward these guy on.",
                    "label": 1
                },
                {
                    "sent": "Hopefully the distribution of the simulated sample is going to be \u03c0. OK.",
                    "label": 1
                },
                {
                    "sent": "So this is a bit not stand out in the sense that obviously now I'm going to simulate the Markov chain, so the simulated samples are not statistically dependent.",
                    "label": 1
                },
                {
                    "sent": "Still we can show that despite the fact that those guys are going to be dependent, basically never mind, you can still have a lot of large numbers on the central limit.",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "That doesn't matter, alright so.",
                    "label": 0
                },
                {
                    "sent": "Well, the thing you have to remember.",
                    "label": 0
                },
                {
                    "sent": "So essentially you want to sample from pie.",
                    "label": 0
                },
                {
                    "sent": "You want to design A transition kernel.",
                    "label": 0
                },
                {
                    "sent": "OK that if basically you start from pie you have sample from pie.",
                    "label": 0
                },
                {
                    "sent": "Then you apply this foundation can hold and the resulting distribution is still pie.",
                    "label": 0
                },
                {
                    "sent": "So this is essentially by the fixed point of the transition kernel or new one.",
                    "label": 1
                },
                {
                    "sent": "Essentially that the resulting admiration of the simulated Markov chain.",
                    "label": 0
                },
                {
                    "sent": "This Markov chain being simulated about this transition kernel converse with the expectation of interest on hopefully.",
                    "label": 0
                },
                {
                    "sent": "Did you have that the sample approximately distributed according to?",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Right, OK?",
                    "label": 0
                },
                {
                    "sent": "So the point I'm actually is that given Pyrex is not that, it's difficult to build such a kernel that satisfy that is actually very easy to come up with an infinite number of kernel that do satisfy that they are invariant perspecta pie.",
                    "label": 1
                },
                {
                    "sent": "OK, so basically we're going to have to pick some of them on the CD art of MCMC.",
                    "label": 0
                },
                {
                    "sent": "So if you have a kernel OK, you managed to below kernel which is invariant respect to buy.",
                    "label": 0
                },
                {
                    "sent": "That is, if you're.",
                    "label": 0
                },
                {
                    "sent": "This will according to \u03a0 and then you execute build according to \u03a0 and then you simulator next sample according to transition Kernel P. Then the next sample as distribution Pi that that's very easy.",
                    "label": 0
                },
                {
                    "sent": "Now to ensure that basically you're going to have also convergent Latvia rage on the sample are approximately display according to target.",
                    "label": 0
                },
                {
                    "sent": "You're going to need more assumption you're going to need basically or reduce ability on a periodicity.",
                    "label": 0
                },
                {
                    "sent": "We already use ability means that essentially your Markov can only search that you can reach any state of positive math on the pipe on a periodicity meter.",
                    "label": 0
                },
                {
                    "sent": "Essentially, your Markov transition kernel prevent the kind of funny periodic exploration of the space OK.",
                    "label": 0
                },
                {
                    "sent": "So the other MCMC as I said, is essentially come up with some kind of kernel which satisfy this.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So generally speaking, I should say that it's very difficult.",
                    "label": 0
                },
                {
                    "sent": "It's very easy to be such.",
                    "label": 1
                },
                {
                    "sent": "Kernel is very difficult to obtain quantitative rate of convergence that tells you that you sample at iteration and is that far from the target distribution.",
                    "label": 0
                },
                {
                    "sent": "So that's really a big big problem.",
                    "label": 0
                },
                {
                    "sent": "With MCMC.",
                    "label": 0
                },
                {
                    "sent": "We can easily come up with process P transition to a Markov chain which had the right amount distribution, but coming up with basically right of convergence of the algorithm toward the targeted solution is going to be extremely difficult.",
                    "label": 0
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK. Yeah.",
                    "label": 0
                },
                {
                    "sent": "That means we need to know something about leasing.",
                    "label": 0
                },
                {
                    "sent": "Yeah, yeah we need something about mixing time on, but for as soon as you're dealing with typically invasion computation is like continuous state space.",
                    "label": 0
                },
                {
                    "sent": "The literature on that it is quite detailed and there's a lot of our research in particular by Garth Robertson, Jeff Rosenthal.",
                    "label": 0
                },
                {
                    "sent": "But you need a lot of work because you need to use for Stepanov criteria on this kind of fixed yet.",
                    "label": 0
                },
                {
                    "sent": "You can have very conservative estimate, but which are essentially pretty useless unfortunately.",
                    "label": 0
                },
                {
                    "sent": "So you can come up with conservative estimate for sure, but typically they're not very.",
                    "label": 0
                },
                {
                    "sent": "They're not very useful on actually, you know lot of situation you don't even.",
                    "label": 0
                },
                {
                    "sent": "You cannot even come up with them actually requires a lot of work actually.",
                    "label": 0
                },
                {
                    "sent": "Especially when you're dealing with continuous space, it's not easy to come up with like informative estimate.",
                    "label": 0
                },
                {
                    "sent": "OK, so to build such let's continue like basically or building of such market transition kernel.",
                    "label": 0
                },
                {
                    "sent": "So we're going to use several facts that are going to be quite useful.",
                    "label": 0
                },
                {
                    "sent": "Say assume you ever basically two Markov kernel OK, which both of them are invariant with respect to pipe that is dissatisfied this equation.",
                    "label": 0
                },
                {
                    "sent": "OK, if this will be according to Pi you apply P1 then you discourage according to \u03c0.",
                    "label": 0
                },
                {
                    "sent": "If you apply P2 is the same OK, then one thing you can easily see is that.",
                    "label": 0
                },
                {
                    "sent": "If you apply P1 then P2 OK. Then obviously this algorithm is still going to leave Pie invariant.",
                    "label": 0
                },
                {
                    "sent": "OK, so if you have two.",
                    "label": 0
                },
                {
                    "sent": "Essentially Markov transition kernel which at the right invariant distribution if you compose them, applying them successively, then you still have the right inbound distribution.",
                    "label": 0
                },
                {
                    "sent": "OK. No, if basically what you do is search that there still both in via build a market transition kernel which is search that say.",
                    "label": 0
                },
                {
                    "sent": "We have probability Lambda you pick.",
                    "label": 0
                },
                {
                    "sent": "You are on .81 minus Lambda, you pick P2, then the ready to transition.",
                    "label": 0
                },
                {
                    "sent": "Kernel is still involved actually, so if this is true, obviously if instead of having two kernel you have capital.",
                    "label": 0
                },
                {
                    "sent": "I said P of the capital care of them.",
                    "label": 0
                },
                {
                    "sent": "OK, so as soon as you have.",
                    "label": 0
                },
                {
                    "sent": "Small transition kernel which have function kernel which basically pyres inbound distribution.",
                    "label": 0
                },
                {
                    "sent": "You can compose them actually by composition or essentially mixture.",
                    "label": 0
                },
                {
                    "sent": "So it's quite a quite a useful thing.",
                    "label": 0
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So in particular, let's basically see or we could use that to prove that essentially the algorithm I've been discussing the kind of artistic algorithm was proposing for nuclear problems is actually valid.",
                    "label": 0
                },
                {
                    "sent": "So consider target distribution Pyrex, which are essentially two component X, one X2, both X one X2 can be actually multi dimensional OK.",
                    "label": 1
                },
                {
                    "sent": "The Gibbs sampler.",
                    "label": 0
                },
                {
                    "sent": "I'd say the algorithm is called Gibbs sampling.",
                    "label": 1
                },
                {
                    "sent": "The literature proceed as follows.",
                    "label": 0
                },
                {
                    "sent": "So you initialize your Markov chain by picking some initial arbitrary value for the company X one X2.",
                    "label": 0
                },
                {
                    "sent": "This is basically the iteration number of Markov chain.",
                    "label": 1
                },
                {
                    "sent": "Then what you do?",
                    "label": 0
                },
                {
                    "sent": "Iteration I use on polar.",
                    "label": 0
                },
                {
                    "sent": "X1 you update X1 by sampling it from this conditional distribution according to under Pi.",
                    "label": 0
                },
                {
                    "sent": "Given the current value of X2.",
                    "label": 0
                },
                {
                    "sent": "And then once you got a new value, you simulated a new value of X1.",
                    "label": 0
                },
                {
                    "sent": "You simulate basically a new value of X2 according to its conditional distribution on the pipe.",
                    "label": 0
                },
                {
                    "sent": "This is exactly what I was doing for the nuclear bomb problem.",
                    "label": 0
                },
                {
                    "sent": "We're basically in mice, nuclear bomb problem X one was corresponding to all the value, Lambda one number too long at 10 or next to Westcott Christ bonding to basically beta OK.",
                    "label": 0
                },
                {
                    "sent": "So this is what I was doing.",
                    "label": 0
                },
                {
                    "sent": "First question, as this algorithm.",
                    "label": 0
                },
                {
                    "sent": "The right environment distribution OK.",
                    "label": 0
                }
            ]
        },
        "clip_55": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Well, I tell you, this is very easy because you can think of this algorithm as it basically a combination of composition of two Markov transition kernel which are both invariant prospecta pie because each of the transition kernel is involved.",
                    "label": 1
                },
                {
                    "sent": "Respect to buy the composition is going to be in violent perspective pie.",
                    "label": 0
                },
                {
                    "sent": "So the first transition kernel are going to consider is the following one.",
                    "label": 0
                },
                {
                    "sent": "Say you in X one X2 you propose new component Y1Y2 on the way you do it.",
                    "label": 0
                },
                {
                    "sent": "Let's follow you some.",
                    "label": 0
                },
                {
                    "sent": "Pulled a new component.",
                    "label": 0
                },
                {
                    "sent": "Why won't you update it by sampling it according to its conditional distribution given the current value of X2 on?",
                    "label": 0
                },
                {
                    "sent": "Basically, you don't modify the component X2.",
                    "label": 0
                },
                {
                    "sent": "This is what I was doing OK at first, so this thing tells you simply don't modify the components to.",
                    "label": 0
                },
                {
                    "sent": "Then the second kernel I'm considering is considering the following kernel, which basically what it does.",
                    "label": 0
                },
                {
                    "sent": "It doesn't modify the current value of X1 on the update, the component, the current value of.",
                    "label": 0
                },
                {
                    "sent": "Of the update.",
                    "label": 0
                },
                {
                    "sent": "Basically the second component by sampling according to its conditional distribution.",
                    "label": 0
                },
                {
                    "sent": "It's very easy to check that both P1 and P2R Pi invariant.",
                    "label": 0
                },
                {
                    "sent": "OK, so I can do it for P1.",
                    "label": 0
                },
                {
                    "sent": "I'm not.",
                    "label": 0
                },
                {
                    "sent": "I'm going to tell you the detail, but it's really, really simple to show that both P1 as basically Pi's inbound distribution P2 as Pi's inbound distribution.",
                    "label": 0
                },
                {
                    "sent": "So the composition of those two channels as basically pious inbound distribution.",
                    "label": 0
                },
                {
                    "sent": "So I know that you're gonna propose leaf pie invariant, which is actually something which is actually unnecessary requ.",
                    "label": 0
                }
            ]
        },
        "clip_56": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Moment for MTM see.",
                    "label": 0
                },
                {
                    "sent": "That doesn't mean that basically you converse with doing ground distribution.",
                    "label": 0
                },
                {
                    "sent": "As I say, you need additional condition.",
                    "label": 0
                },
                {
                    "sent": "You need to ensure that basically whatever set which has on that and it's positive mass on the target property.",
                    "label": 0
                },
                {
                    "sent": "So you need to ensure that whatever being the initial point, you can reach any set of positive quality mass on the target on.",
                    "label": 1
                },
                {
                    "sent": "You need to essentially to rule out also parallel behavior.",
                    "label": 0
                }
            ]
        },
        "clip_57": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So OK, I'm just going.",
                    "label": 0
                }
            ]
        },
        "clip_58": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Through that OK.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_59": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is basically what you need, so generally speaking you can generalize this algorithm also to the case where instead having two components you have P components.",
                    "label": 0
                },
                {
                    "sent": "So let's say that X can be separated can be divided in like P groups of random variable X, One X2, XP.",
                    "label": 0
                },
                {
                    "sent": "Well, basically the algorithm the way to Gibbs sampler will work in this case so as to simulate approximately from the target distribution is following at iteration.",
                    "label": 0
                },
                {
                    "sent": "I basically you're going to cycle.",
                    "label": 0
                },
                {
                    "sent": "For the component want to the component P on.",
                    "label": 0
                },
                {
                    "sent": "Basically you're gonna update the component XKI called in by sampling according to its conditional distribution and the pie given the current value of the other components.",
                    "label": 0
                },
                {
                    "sent": "That is, in this scenario, the K -- 1 first component I've already been updated at iteration.",
                    "label": 0
                },
                {
                    "sent": "I on the remaining basically components which are at iteration minus one because they haven't been sampled yet.",
                    "label": 0
                },
                {
                    "sent": "OK, so this algorithm, by using the strike generalization of what I've been discussing before, is and it basically pie as inbound distribution on.",
                    "label": 0
                },
                {
                    "sent": "You can also instead of cycling deterministically under from one to PETA component, you can basically some pull them.",
                    "label": 0
                }
            ]
        },
        "clip_60": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Sample this company.",
                    "label": 0
                },
                {
                    "sent": "The component to update randomly.",
                    "label": 0
                },
                {
                    "sent": "Basically according to a distribution, say uniform distribution over the set 1 to P. OK.",
                    "label": 0
                },
                {
                    "sent": "So instead of cycling for it, you sample randomly the basically the component you want to update.",
                    "label": 0
                },
                {
                    "sent": "OK said K, that's going to give you a return value which is uniformly distributed accounting in the set 1 to pee on.",
                    "label": 0
                },
                {
                    "sent": "You update this.",
                    "label": 0
                },
                {
                    "sent": "Distribute this component according to his full conditional distribution.",
                    "label": 0
                },
                {
                    "sent": "This guy corresponds to a mixture of kernels also using the same argument.",
                    "label": 0
                },
                {
                    "sent": "It admits basically the right invariant distribution.",
                    "label": 0
                }
            ]
        },
        "clip_61": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so if you come back to basically or nuclear pump again, I've told you we've shown are that basically this algorithm I was proposing is just a simple example of the Gibbs sampler.",
                    "label": 0
                },
                {
                    "sent": "OK, so I know it means the right invariant distribution, OK?",
                    "label": 0
                },
                {
                    "sent": "What about this condition will basically with additional condition that briefly sketch which are that?",
                    "label": 0
                },
                {
                    "sent": "Basically I need to be able to reach any basically set of probability of positive polytomous under the target, whatever being the starting point where it's going to be automatically on shore, because all the conditional distribution are strictly positive on 0 plus Infinity on.",
                    "label": 0
                },
                {
                    "sent": "Similarly, basically my Markov chain doesn't exhibit any periodic behavior because similarly all the conditional.",
                    "label": 0
                },
                {
                    "sent": "3 positive so I know this algorithm is going to basically generate sample that essentially as I going to go to plus Infinity converge to other target distribution.",
                    "label": 0
                },
                {
                    "sent": "What about the rate of convergence where that is going to be much more complicated on this simple example, actually some people have established some result on that actually on the simplest example is simple enough that you can get rid of convergent Jerry speaking is going to be much more complicated.",
                    "label": 0
                },
                {
                    "sent": "Alright, so that's basically keep sampler.",
                    "label": 0
                },
                {
                    "sent": "Alright, so now you should be a bit careful when you do this type of algorithm where the problem is that it's very nice to come up with this kind of separating.",
                    "label": 0
                },
                {
                    "sent": "Essentially said the company shall state vector insap component updating one conditional upon the other, but conditioning is going to come at a serious price.",
                    "label": 0
                }
            ]
        },
        "clip_62": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So let's look at the other really toy example, which is essentially univariate Gaussian distribution.",
                    "label": 0
                },
                {
                    "sent": "OK, sorry bivariate, Gaussian distribution of 0 mean on covariance.",
                    "label": 0
                },
                {
                    "sent": "Basically variance covariance matrix which is given by this guy.",
                    "label": 0
                },
                {
                    "sent": "OK, so all is the correlation coefficient here actually I just assumed that basically there's unit unit unit lines.",
                    "label": 1
                },
                {
                    "sent": "OK, so in this case, OK, obviously you would not use the Gibbs sampler, but if you were to use the gift sampler.",
                    "label": 0
                },
                {
                    "sent": "On trying to sampul from these joint target distribution by eatery, iteratively sampling from the conditional distribution of X given Y and then Y given X.",
                    "label": 0
                },
                {
                    "sent": "Then this is the form of the conditional distribution.",
                    "label": 0
                },
                {
                    "sent": "OK, where what you see is obviously.",
                    "label": 0
                },
                {
                    "sent": "So this is the expression.",
                    "label": 0
                },
                {
                    "sent": "So if you can rewrite it, basically you can think that the Gibbs sampler would proceed as follow essentially.",
                    "label": 0
                },
                {
                    "sent": "So this is the first component, so you would at time at iteration N plus one of the algorithm X N + 1.",
                    "label": 0
                },
                {
                    "sent": "They always end time this noise.",
                    "label": 0
                },
                {
                    "sent": "While in plus one is updated according to this location.",
                    "label": 0
                },
                {
                    "sent": "OK, on you see obviously the problem you're going to get with this algorithm used as soon as essentially absolute value of war is going to be very very close to one that is there really strong correlation between the random variable X&Y under the target distribution then?",
                    "label": 1
                },
                {
                    "sent": "Essentially you've got X N + 1 user pproximately equal to YNOK on YN, plus one is approximately equal to X N + 1.",
                    "label": 0
                },
                {
                    "sent": "So we have a Markov process which indeed if you iterate it long enough, it's going to converge basically toward the right target, but it might take ages if actually who is?",
                    "label": 0
                }
            ]
        },
        "clip_63": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Very close to work.",
                    "label": 0
                },
                {
                    "sent": "OK, so it means that actually what you're going to see.",
                    "label": 0
                },
                {
                    "sent": "So here.",
                    "label": 0
                },
                {
                    "sent": "Let's say this is that corresponds to the level set of my by via Goshen distribution.",
                    "label": 0
                },
                {
                    "sent": "Basically, if you look at the exploration that basically the end the markup change is going to take a lot of time to move.",
                    "label": 0
                },
                {
                    "sent": "Basically from to explore the world Purcell distribution here in this case, for example, it doesn't explore this whole part of the target distribution, so it's not because you have.",
                    "label": 0
                },
                {
                    "sent": "Essentially argues billion appears in the city that basically.",
                    "label": 0
                }
            ]
        },
        "clip_64": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "First, hopefully so.",
                    "label": 0
                },
                {
                    "sent": "Also reap sampler is nice.",
                    "label": 1
                },
                {
                    "sent": "OK, because somehow it's reduced.",
                    "label": 0
                },
                {
                    "sent": "The pile of sampling from my dimensional target distribution to the problem, essentially sampling from lower dimensional distribution.",
                    "label": 1
                },
                {
                    "sent": "It doesn't necessarily kind of going to work really well.",
                    "label": 0
                },
                {
                    "sent": "OK, because essentially the problem is that if you ever component which are highly correlated, OK under the posterior, the target distribution of interest, if you update, then basically.",
                    "label": 0
                },
                {
                    "sent": "Independently one from each other.",
                    "label": 0
                },
                {
                    "sent": "Then basically the algorithm is not going to work well at all, OK?",
                    "label": 1
                },
                {
                    "sent": "So that's actually one of the problem.",
                    "label": 0
                },
                {
                    "sent": "So you need to be a little bit careful when you use the Gibbs sampler, so there's a lot of application, for example, of the deep sampling machine learning.",
                    "label": 0
                },
                {
                    "sent": "So too are really complicated, like testicle models such as the Yahiko leadership process.",
                    "label": 0
                },
                {
                    "sent": "If you use a naive Gibbs sampler on such kind of model, I mean you can already expect to sample from the target.",
                    "label": 1
                },
                {
                    "sent": "You should be aware realistic, you might have an algorithm in iterative process that's going to come with.",
                    "label": 0
                },
                {
                    "sent": "That's going to basically go in origin of reasonable.",
                    "label": 0
                },
                {
                    "sent": "I polytomous, but you do not sample from the posterior distribution.",
                    "label": 0
                },
                {
                    "sent": "OK, so be a little bit careful when you use this type of algorithm on be very critical about basically the result you obtain even on cineport problem, the Gibbs sampler basically can struggle.",
                    "label": 0
                },
                {
                    "sent": "So on super high dimensional structure, statistical modeling might be real.",
                    "label": 0
                }
            ]
        },
        "clip_65": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Difficult.",
                    "label": 0
                },
                {
                    "sent": "OK, so we go to trade so impact is tried to have as few blocks as possible.",
                    "label": 1
                },
                {
                    "sent": "Essentially tried to update correlated variables simultaneously if possible OK?",
                    "label": 0
                },
                {
                    "sent": "There's a way that is not often used in machine learning, which is away.",
                    "label": 0
                },
                {
                    "sent": "That's where often there are some kind of clever or parametrizations of the model that limits basically the correlation with target the between the random variable under the target on it can really help from a practical point of view on whenever you can integrate out some on the London valuable analytically, please do it.",
                    "label": 0
                },
                {
                    "sent": "So that's good.",
                    "label": 0
                },
                {
                    "sent": "All this Gibbs sampler, but it somehow is also remain limited, because the only degree of freedom you have is the choice of the partition.",
                    "label": 1
                },
                {
                    "sent": "OK, so on each required to submit a bowl to sample from the conditional distribution of components XK.",
                    "label": 0
                },
                {
                    "sent": "Given the remaining component.",
                    "label": 0
                },
                {
                    "sent": "So there are cases where you're not going to be able to do that, in which case you're going to need to use essentially and of algorithm, which is comforting as an alternative or more exactly sexually or generalization of natural processing.",
                    "label": 0
                }
            ]
        },
        "clip_66": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "I don't know what's going on.",
                    "label": 0
                },
                {
                    "sent": "I'm sorry.",
                    "label": 0
                },
                {
                    "sent": "OK, so one point whipsawn player behind the fact that basically.",
                    "label": 0
                },
                {
                    "sent": "You have to try to update correlated, valuable simulataneously.",
                    "label": 0
                },
                {
                    "sent": "He died for the time.",
                    "label": 0
                },
                {
                    "sent": "It does require being able to simulate essentially from this condition.",
                    "label": 0
                },
                {
                    "sent": "This kind of conditional distribution for the simple nuclear bomb data I've been looking at, it was visible.",
                    "label": 0
                },
                {
                    "sent": "There's a lot of example where basically even such conditional distribution cannot be sampled from exactly OK.",
                    "label": 0
                },
                {
                    "sent": "So in this case, you're going to need to come up.",
                    "label": 0
                }
            ]
        },
        "clip_67": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Something else on essentially an alternative algorithm for doing that is basically made for protesting.",
                    "label": 0
                },
                {
                    "sent": "OK, I say so kind.",
                    "label": 0
                },
                {
                    "sent": "Actually it's a generalization of it, so we're going to come up with a more general mechanism.",
                    "label": 1
                },
                {
                    "sent": "To essentially come up with Markov chain, which admits essentially a given and ion distribution Pi of X. Oh, that's actually use absolutely everywhere, so you should actually know about it, even if you're not interested in Monte Carlo methods.",
                    "label": 1
                },
                {
                    "sent": "That's at least something that has been that should be used the origin or Metro police algorithm was proposed.",
                    "label": 0
                },
                {
                    "sent": "Laughing in the 50s by some physicists, and is actually the most cited scientific player publication of the 20th century.",
                    "label": 1
                },
                {
                    "sent": "There's, like, literally want to receive like 50,000 citations, some ridiculous, right?",
                    "label": 0
                }
            ]
        },
        "clip_68": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the way it's going to work, this algorithm that follow OK is a V in some sense quite similar to rejection sampling in the sense that similarly to reject and prompting what you're going to propose, you're going to introduce a proposal distribution within your algorithm.",
                    "label": 0
                },
                {
                    "sent": "OK, so here we go.",
                    "label": 0
                },
                {
                    "sent": "So you're going to introduce basically given account value, current value of your Shane X.",
                    "label": 0
                },
                {
                    "sent": "You're going to introduce this conditional.",
                    "label": 0
                },
                {
                    "sent": "Probably don't city OK, so this is a transition kernel from X to Y, so this is positive on the sums.",
                    "label": 0
                },
                {
                    "sent": "Basically to one when you integrate respect towards this is conditional on city of why Unix OK, you're going to pick it so that basically it's very easy to sample from this guy.",
                    "label": 0
                },
                {
                    "sent": "So for example this guy could be.",
                    "label": 0
                },
                {
                    "sent": "Essentially it could be something which is independent of the current value of X.",
                    "label": 0
                },
                {
                    "sent": "So normal distribution in Y of mean 0.1.",
                    "label": 0
                },
                {
                    "sent": "But it also could be say normal distribution.",
                    "label": 0
                },
                {
                    "sent": "Of argument why mean X on violence?",
                    "label": 1
                },
                {
                    "sent": "One Valentina squares.",
                    "label": 0
                },
                {
                    "sent": "OK, now the basic idea of Metro protesting looks a lot like rejection sampling.",
                    "label": 1
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "You are in account value, so you're going to generate a Markov chain OK.",
                    "label": 0
                },
                {
                    "sent": "So I assume that the current value of the current state of the market Chinese X UJ rate, the new candidate from a proposal distribution.",
                    "label": 1
                },
                {
                    "sent": "OK, which can be parameterized by X, so it's a little bit different here from objection, because rejection sampling of there's no notion like totem pole notion, so it in the car in the rejection sampling is just basically independent of X.",
                    "label": 0
                },
                {
                    "sent": "But here you propose a new candidate from this conditional distribution.",
                    "label": 0
                },
                {
                    "sent": "OK, on then you make sure you introduce kind of arbitrary, not arbitrary, appropriate quality.",
                    "label": 0
                },
                {
                    "sent": "We are going to function of Alpha X&Y, which unsure by construction that essentially the simulated Markov chain admits as invariant distribution Pyrex.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is where we're going.",
                    "label": 0
                }
            ]
        },
        "clip_69": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "On the Android access follow so Middleby testings who sampled from Pyrex.",
                    "label": 0
                },
                {
                    "sent": "So you have initial value X at iteration I you have said the current value of the Markov chain is XI minus one.",
                    "label": 0
                },
                {
                    "sent": "You simulate a candidate according to this proposal distribution OK, and then you compute these access points probability which is the minimum between one the ratio of the target distribution evaluated a current value of the Markov chain on the purpose value.",
                    "label": 0
                },
                {
                    "sent": "On the ratio essentially of the probable distribution, the probability distribution you've been using to simulate why?",
                    "label": 0
                },
                {
                    "sent": "OK?",
                    "label": 0
                },
                {
                    "sent": "So this is a Q XI minus one Y.",
                    "label": 0
                },
                {
                    "sent": "All you also need to compute OK, add the numerator.",
                    "label": 0
                },
                {
                    "sent": "The reverse essentially transition that hasn't been simulated, which is the probability essentially of moving from Y to X I -- 1 under Q. OK, now we pull ability so you get to.",
                    "label": 0
                },
                {
                    "sent": "So essentially you simulator random variable between zero and one.",
                    "label": 0
                },
                {
                    "sent": "If it is inferior to Alpha then you accept the candidate.",
                    "label": 0
                },
                {
                    "sent": "All the while you stay where you are.",
                    "label": 0
                },
                {
                    "sent": "That's it.",
                    "label": 0
                },
                {
                    "sent": "That's very generic algorithm.",
                    "label": 0
                },
                {
                    "sent": "Very very simple.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_70": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So now we're going to show is that it actually is which possessing algorithm is indeed admits indeed, basically PIE as an invariant distribution.",
                    "label": 0
                },
                {
                    "sent": "OK, so to show that I'm going to show something a little bit more general, I'm going to show that basically something a bit more actually a general with something which we chose that essentially.",
                    "label": 0
                },
                {
                    "sent": "K is what we say pie reversible.",
                    "label": 0
                },
                {
                    "sent": "So K is priority, but that is essentially under station or a gym.",
                    "label": 0
                },
                {
                    "sent": "That is when X is distributed according to \u03a0, then the probability of being this way according to \u03c0 or moving to K according to KXY is equal to portability of basically being this way.",
                    "label": 0
                },
                {
                    "sent": "According to why I'm moving from Y to X OK, so essentially under the stationary regime, essentially the condition the joint distribution of X&Y is also the call to the joint distribution of Y&X.",
                    "label": 0
                },
                {
                    "sent": "OK, that's actually quite quite powerful thick, so the way I showed that basically just follow.",
                    "label": 0
                },
                {
                    "sent": "So what is the transition kernel that is implied by the algorithm of written down?",
                    "label": 0
                },
                {
                    "sent": "Where?",
                    "label": 0
                },
                {
                    "sent": "What do you do?",
                    "label": 0
                },
                {
                    "sent": "So this is a transition kernel to move from KX to Y.",
                    "label": 0
                },
                {
                    "sent": "The transition color Metro processing algorithm?",
                    "label": 0
                },
                {
                    "sent": "What do you do when you do it in that to Metro police you sampul?",
                    "label": 0
                },
                {
                    "sent": "Why according to Q?",
                    "label": 0
                },
                {
                    "sent": "You accept it with probability Alpha XY.",
                    "label": 0
                },
                {
                    "sent": "OK on what is this guy where it's correspond to the rejection, basically probabilities.",
                    "label": 0
                },
                {
                    "sent": "So what is the probability of rejecting a move where it's going to be 1 minus the integral?",
                    "label": 0
                },
                {
                    "sent": "Basically of this term respect to Y prime?",
                    "label": 0
                },
                {
                    "sent": "Times basically a Delta mass Y equal X. OK, so essentially this thing corresponds to the move.",
                    "label": 0
                },
                {
                    "sent": "I've been accepted this thing this components correspond to.",
                    "label": 0
                },
                {
                    "sent": "Basically I've rejected my move OK. No so.",
                    "label": 0
                },
                {
                    "sent": "This is transition kernel.",
                    "label": 0
                },
                {
                    "sent": "Now I want to check this thing.",
                    "label": 0
                },
                {
                    "sent": "OK that I've got this equality.",
                    "label": 0
                },
                {
                    "sent": "Well I'm telling you that I only need obviously to check it from the Dundee generated component of the Metro police testing schedule because for the generated component, essentially I've got X = Y anyway, so I just check it for the generated, the nondegenerate component of the Markov kernel.",
                    "label": 0
                },
                {
                    "sent": "I want to check that.",
                    "label": 0
                },
                {
                    "sent": "So I just basically do essence elementary calculation on using the fundamental processing acceptance ratio.",
                    "label": 0
                },
                {
                    "sent": "I should I see that indeed I've got that pie.",
                    "label": 0
                },
                {
                    "sent": "Is Kerry Versible case OK?",
                    "label": 0
                },
                {
                    "sent": "Is piracy?",
                    "label": 0
                },
                {
                    "sent": "OK, no.",
                    "label": 0
                },
                {
                    "sent": "Basically I'm telling you that obviously the pie Oreos ability of K implies the pie invariants of K, where it's very easy to check.",
                    "label": 0
                },
                {
                    "sent": "So we've established that basically these properties is satisfied.",
                    "label": 0
                },
                {
                    "sent": "For the current position Colonel K, If I integrate on both side with respect to X, I've got basically that integral of Pi X DX times transition kernel KXY is going to be part of why time the integral respect to X of KYX DX, which is one OK.",
                    "label": 0
                },
                {
                    "sent": "So these things Pirates ability implies basically pie invariants.",
                    "label": 0
                },
                {
                    "sent": "OK, so I know that the MCMC kernel I've been dealing with a proposed essentially admits essentially.",
                    "label": 0
                },
                {
                    "sent": "High as a fixed point that is very good.",
                    "label": 0
                },
                {
                    "sent": "This is very generic.",
                    "label": 0
                }
            ]
        },
        "clip_71": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "It is a. OK.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "To ensure a disability, which is, you know this condition that you need to a market share kernel that are basically our search that from any starting point you can reach any set of positive quality on the pie where the scission condition, where consists of picking and basically transition kernel which has positive mass everywhere where the target has mass.",
                    "label": 0
                },
                {
                    "sent": "It is absolutely not necessary.",
                    "label": 1
                },
                {
                    "sent": "OK you as long as basically.",
                    "label": 0
                },
                {
                    "sent": "If you iterate, basically you mark your proposal long enough, you can explore any original is going to be fine on appearance, it is automatically onshore.",
                    "label": 0
                },
                {
                    "sent": "Basically in this algorithm because of the rejection probability you can rule out any periodic behavior of the Markov chain.",
                    "label": 1
                },
                {
                    "sent": "OK, so this algorithm you can show that it converge in the extremely weak assumption throughout the target distribution.",
                    "label": 1
                },
                {
                    "sent": "OK, but once more the choice of Q is paramount for good behavior of the algorithm.",
                    "label": 0
                },
                {
                    "sent": "So basically what I'll do is that the net.",
                    "label": 1
                }
            ]
        },
        "clip_72": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Well known off I will discuss essentially some of those kind of sonar settings so as to set the proposal distribution in MTMT algorithm on.",
                    "label": 1
                },
                {
                    "sent": "I will discuss advanced more advanced MCMC algorithm, so we're going to take a break now for half an hour and then we come back.",
                    "label": 0
                },
                {
                    "sent": "We'll discuss more carefully.",
                    "label": 0
                },
                {
                    "sent": "Metro protesting on advanced MCMC such as slice sampling, parallel tempering on terms of course.",
                    "label": 0
                },
                {
                    "sent": "I said oil.",
                    "label": 0
                }
            ]
        }
    }
}