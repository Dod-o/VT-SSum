{
    "id": "am6k6xsadufkdnogawbsgiqdxjagkwbp",
    "title": "Feature Selection Stability Assessment based on the Jensen-Shannon Divergence",
    "info": {
        "author": [
            "Roc\u00edo Alaiz-Rodriguez, Universidad de Le\u00f3n"
        ],
        "published": "Oct. 3, 2011",
        "recorded": "September 2011",
        "category": [
            "Top->Computer Science->Machine Learning->Feature Selection"
        ]
    },
    "url": "http://videolectures.net/ecmlpkdd2011_alaiz_rodriguez_feauture/",
    "segmentation": [
        [
            "Joint work also with Robert Goodman and we both come from the University of Lyon in Spain and in this paper we have addressed the issue of robustness in feature selection techniques."
        ],
        [
            "Let me give you just a brief outline of this talk.",
            "First of all, I will present the problem of instability in feature selection and feature ranking algorithms.",
            "Then some common metrics used to quantify this instability and next our approach based on the Jensen Shannon Divergent, some empirical stylist, and finally conclusion."
        ],
        [
            "Consider we have a data set where it's example is described by a set of features.",
            "I will illustrate it with gas 10 features, but obviously."
        ],
        [
            "The feature selection techniques are fundamental step.",
            "When we work with multi dimensional data basically.",
            "There are three types of feature selection algorithms.",
            "Those that are a filter approach, so they selected feature regardless of the classification machine or robot proper approach.",
            "When the feature importance depends on only classification model or even embedded approaches which are specific for a given model.",
            "And the study of stability has become a topic of high interest.",
            "Why is it like that?",
            "I would say that today there are many applications whose goal is to find or to struct information and knowledge from the data.",
            "So the fact that different research findings have come from different research works make this study necessary.",
            "For example, consider that we have a research team working on some data and they find that genes abrc.",
            "Are very important for this illness or correlated with an illness, but in other work in other team working with other data, they find that these genes are not important, but the ones that are important are genes D&E.",
            "So we have to be careful with this and we have to make sure that the feature selection algorithm is stable enough in order to draw meaningful conclusions.",
            "Otherwise there would be disparity and we cannot analyze this."
        ],
        [
            "OK, let's focus on the feature ranking outcomes as I have been.",
            "Said consider we take a sample from the data and we run the feature ranking algorithm and what we get.",
            "Is this ranking where feature 9 is given the highest rank?",
            "This is the most important.",
            "Feature.",
            "What's a feature for?",
            "Is the least important?",
            "But if we run the algorithm again with another sample from the same data, we may get different result and then.",
            "And the feature feature 9 that was considered.",
            "The most important now it is in the in the ranking, the seventh position.",
            "It may happen with another Sam."
        ],
        [
            "Kohl's if we talk about feature selection techniques.",
            "Also from 1 sample we may get the feature 5.",
            "One and eight are the three most important, but if we run the algorithm with other data.",
            "Still, feature 5 is considered most one of the three most important features, but now we get feature two and feature 3."
        ],
        [
            "So the way to present the result.",
            "In general, when we rank when we run a feature ranking algorithm, we get full rank list.",
            "That is a vector with as many elements as are the features we are analyzing and the element.",
            "Represents the rug, with one being the highest rank.",
            "So when we see this, our intuition is that the algorithm is not very stable.",
            "So we need to quantify the stability of this algorithm."
        ],
        [
            "And we work with feature selection techniques.",
            "Let me use the representation where the output is given with the vector with zeros and ones and only once in the position of the top K most important features and again.",
            "Yes, our intuition shares that we need to quantify."
        ],
        [
            "Fiesta"
        ],
        [
            "So I've been said it is a disparity among different research findings.",
            "What has made this study necessary, and in particular fields like biomedicine, bioinformatics, chemometrics where they do not only require an accurate classification model, but they want to interpret the data to analyze the data or the outcomes of this.",
            "This algorithms in order to understand the underlying process.",
            "So if a small variations in the data lead to different outcomes, they conclusions the repro.",
            "Net are not reliable.",
            "So how can we measure this stability?",
            "We need a magic that tell us where we are between perfect stable ranking algorithm and a complete random ranking algorithm."
        ],
        [
            "So far.",
            "There have been a proposed several metrics.",
            "But each one for different kind of list.",
            "For example for full rank list, the most widely used is this paraments Frank correlation coefficient that takes by value between minus one and one.",
            "But there are others like a Manhattan distance.",
            "If we work with top K lists where we retrieve only the came most important features.",
            "There are many metrics, but probably the most important one is the Conservative stability Index.",
            "But let's say that these representations have like 2 extreme cases, because either we have the full rank list where we keep the rank of each feature, or we retrieve the top K most important features, But then we don't know their relative importance, which is more important than the other."
        ],
        [
            "There are other lists.",
            "Call partial rank list or top K rank list where we keep the became most important features, but we still keep your relative importance.",
            "This is quite common in domains like information retrieval will retrieve the top K most important documents, but it's still we know which is the most important.",
            "However, no metrics have been proposed for for this kind of list.",
            "And.",
            "We consider that feature importances something that we have."
        ],
        [
            "Take into account.",
            "So given these metrics, what we normally do is.",
            "We have we run the algorithm several times.",
            "We get some output, some ranking outputs and then we compare them.",
            "In in a bird waste way.",
            "So this is quite expensive in terms of computation.",
            "Here are the similarity metric.",
            "Maybe any of the ones we have been talking about."
        ],
        [
            "Would we propose is a probabilistic approach based on the Jensen sign."
        ],
        [
            "Divergents and we propose in metric that is able to handle either full rank lists or top K lists.",
            "Partial rank list.",
            "Our role.",
            "Is that if the ranking is considered different?",
            "I mean if the ranking is considering we are working with Partner Rank list or Full Rank list the differences at the top of the list would be given more important than the differences that appear at the bottom of the list.",
            "And we follow.",
            "This approach.",
            "At first, to map the the ranking vector into a probability vector following Ashland 2007, we give a probability to each feature.",
            "According to your rank it has, so we map a ranking factor into a probability vector and then the problem can be stated that as how do we measure the divergents or the disparity similarity between these two probability vectors?"
        ],
        [
            "Well, when it comes to measure this, probably the most widely used option is to use the KL Divergent.",
            "But it has some drawbacks, like it is a symmetric and it does not generalize when we have more than two distributions, as it is the case.",
            "So we have opt for the Jensen Sandy Vergence.",
            "It is like a symmetric version of the KL Divergent and given a set of any distributions where each one comes from different run of the algorithm, we compute the Jensen Sandy vergence.",
            "Which basically does is computing the probability of a given feature with respect to the main probability."
        ],
        [
            "And based on these divergences we propose the stability metric as one minus the vergence divided by a normalizing vector that correspond.",
            "To the Department it would have a random ranking algorithm, a complete frontal ranking, and it only depends on the number of features and it can be computed before hand.",
            "So in this setting.",
            "If we have a stable ranking algorithm.",
            "The probability of a given feature would be equal to the mean probability.",
            "So the divergent would be 0 on disability one, and if it is a random ranking algorithm, diversions would be equal to the normalizing vector factor.",
            "Sorry, and the stability would go to zero.",
            "And if we solve in between, it would be bounded between zero and one.",
            "And this is how it works when we have a full rank list.",
            "But how do we stand this to top K lists or partial rank list it?"
        ],
        [
            "Quite straightforward.",
            "Partial ranked list.",
            "All we have to do is to change the mapping and assign.",
            "It probability zero to those.",
            "Those features who rank is lower than than the became most important features.",
            "So then they asked the normalizing factor changes according to this assigned probabilities and that's it."
        ],
        [
            "And if we want to apply it to top K lists.",
            "Again, the probability we're saying in this case is well for all the features that the became most important features.",
            "The normalizing factor only depends on on L. That is the total number of features and OK that is they came most important features.",
            "So in this sense, the metric we propose it's general enough to be applied to any of the different.",
            "Output formats of."
        ],
        [
            "An algorithm."
        ],
        [
            "We have illustrated this on two different settings, one artificial and the other.",
            "Related to spectral data.",
            "They will regard to the artificial one what we have done is to create.",
            "A feature ranking algorithms that may be completely stable or completely run and something in between.",
            "And we have generated 100 rankings.",
            "Of 2000 features the way we have done it and we have named them Fr.",
            "Zero has 100 random rankings, completely random and if our two for example with two identical rankings and then the remaining are completely random.",
            "So it goes like this until Fr 100 where all the rankings are.",
            "So what we get in the X axis, we have the.",
            "The algorithms in the Y axis we have our metric and the blue line corresponds to our stability metric applied.",
            "In this case, the full rank list.",
            "We see how it varies from zero to 1 and we also can see a.",
            "Can see how it behaves compared with the well known spermin rank correlation coefficient coefficient.",
            "They behave very closely."
        ],
        [
            "If we work with top calist.",
            "We have extracted this list from the feature ranking algorithms previously described, just keeping the 600 most important features.",
            "We get the value of this metric compared with the consumer index.",
            "And we also see that.",
            "In this setting they are quite similar."
        ],
        [
            "But when we apply.",
            "Add this to partial rank list.",
            "Obviously the chamber in this cannot take into account the relative ranking between them.",
            "So here what we compare.",
            "Is set of list with 600 most important features.",
            "And the overlap between this list is around 350 features.",
            "If we apply this to the Quintela.",
            "Trying to measure the current with the Culture index will get the red line, and if we apply our metric without considering the feature importance, we get the blue line.",
            "But when we consider the feature importances applying too full to partial rank list, we get this cure.",
            "On the left we have at least.",
            "Where the differences appear at the bottom for the lowest rank features and on the right we get we have the list that whose differences appear at the top for the most important features and we see how this metric varies.",
            "So if the differences appear at the bottom of the list, it gives that less important and the value of stability is higher, but it drops to a low value when these differences appear at the bottom of the list.",
            "So we can say that the metrics like."
        ],
        [
            "The Quinta by index cannot handle this information.",
            "Here, yes, another illustration where we keep the 600 most important features on the list contain the same features, but the orders of the rankings are different.",
            "Both the Culture Index on our metric applied to top K lists give a value of 1 because they agree the features.",
            "The 600 most important features are the same.",
            "But our metric gives the value of all .9.",
            "When that is complete agreement about the most important features, but disagreement about which one is the most important, well, their relative importance."
        ],
        [
            "And we also have a valuated.",
            "Is the magic on spectral data.",
            "These data come from fat samples.",
            "Problems from lamps and the goal is to discriminate between those lamps who have fed with milk replacer or.",
            "Maternal milk.",
            "And data is defined by more than 1600 features.",
            "And what the experts want to know is which regions of the spectrum are the most important in order to better understand which assets in the interfere in this."
        ],
        [
            "So we split the data set randomly in 10 falls will run the feature ranking algorithm in nine out of 10 in consecutive ways, and we did it five times.",
            "So insulted in 50 rankings.",
            "If we apply it to full rank list comparing for feature ranking algorithm like 1R Chi Square Game Rating relief, we get that really fun going rate.",
            "You are like a stable so the conclusions from them may be quite reliable at least."
        ],
        [
            "In terms of stability.",
            "Here we can see how it behaves when we keep the top K most important features, both considering the rank or just the features themselves.",
            "We see that.",
            "If we focus on the in the continuous line that where the ranking is not considered, we may think that.",
            "The stability goes to a low value as the value of key increases.",
            "However, would we propose is to consider this ranking using partial rank list and we get this continuous line that is always higher than the other and it because the differences appear at the at the bottom of the list.",
            "So the algorithms are indeed quite stable."
        ],
        [
            "So in conclusion, the robustness of feature ranking and selection algorithms is used for knowledge discovery is an issue of high interest.",
            "We tackle this problem proposing a metric based on the Jensen son on Divergent that first.",
            "The ranks are mapping to probability vectors and then the difference between vectors compute using a GS divergences.",
            "A disabled to work, either with full rank list top K lists or partial rank list and the differences at the top are getting more more penalized for giving more important and what is very important is the last thing that is not the least important that there is no need comparisons.",
            "So we compare like its output with the average output and is less.",
            "Computers, certainly expensive, so this metric give us an idea of the amount of randomness associated with with the feature selection algorithm, regardless of the feature list size, and that's all."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Joint work also with Robert Goodman and we both come from the University of Lyon in Spain and in this paper we have addressed the issue of robustness in feature selection techniques.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Let me give you just a brief outline of this talk.",
                    "label": 0
                },
                {
                    "sent": "First of all, I will present the problem of instability in feature selection and feature ranking algorithms.",
                    "label": 0
                },
                {
                    "sent": "Then some common metrics used to quantify this instability and next our approach based on the Jensen Shannon Divergent, some empirical stylist, and finally conclusion.",
                    "label": 1
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Consider we have a data set where it's example is described by a set of features.",
                    "label": 0
                },
                {
                    "sent": "I will illustrate it with gas 10 features, but obviously.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The feature selection techniques are fundamental step.",
                    "label": 0
                },
                {
                    "sent": "When we work with multi dimensional data basically.",
                    "label": 0
                },
                {
                    "sent": "There are three types of feature selection algorithms.",
                    "label": 1
                },
                {
                    "sent": "Those that are a filter approach, so they selected feature regardless of the classification machine or robot proper approach.",
                    "label": 0
                },
                {
                    "sent": "When the feature importance depends on only classification model or even embedded approaches which are specific for a given model.",
                    "label": 0
                },
                {
                    "sent": "And the study of stability has become a topic of high interest.",
                    "label": 1
                },
                {
                    "sent": "Why is it like that?",
                    "label": 0
                },
                {
                    "sent": "I would say that today there are many applications whose goal is to find or to struct information and knowledge from the data.",
                    "label": 0
                },
                {
                    "sent": "So the fact that different research findings have come from different research works make this study necessary.",
                    "label": 0
                },
                {
                    "sent": "For example, consider that we have a research team working on some data and they find that genes abrc.",
                    "label": 0
                },
                {
                    "sent": "Are very important for this illness or correlated with an illness, but in other work in other team working with other data, they find that these genes are not important, but the ones that are important are genes D&E.",
                    "label": 0
                },
                {
                    "sent": "So we have to be careful with this and we have to make sure that the feature selection algorithm is stable enough in order to draw meaningful conclusions.",
                    "label": 0
                },
                {
                    "sent": "Otherwise there would be disparity and we cannot analyze this.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, let's focus on the feature ranking outcomes as I have been.",
                    "label": 1
                },
                {
                    "sent": "Said consider we take a sample from the data and we run the feature ranking algorithm and what we get.",
                    "label": 0
                },
                {
                    "sent": "Is this ranking where feature 9 is given the highest rank?",
                    "label": 0
                },
                {
                    "sent": "This is the most important.",
                    "label": 0
                },
                {
                    "sent": "Feature.",
                    "label": 0
                },
                {
                    "sent": "What's a feature for?",
                    "label": 0
                },
                {
                    "sent": "Is the least important?",
                    "label": 0
                },
                {
                    "sent": "But if we run the algorithm again with another sample from the same data, we may get different result and then.",
                    "label": 0
                },
                {
                    "sent": "And the feature feature 9 that was considered.",
                    "label": 0
                },
                {
                    "sent": "The most important now it is in the in the ranking, the seventh position.",
                    "label": 0
                },
                {
                    "sent": "It may happen with another Sam.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Kohl's if we talk about feature selection techniques.",
                    "label": 1
                },
                {
                    "sent": "Also from 1 sample we may get the feature 5.",
                    "label": 0
                },
                {
                    "sent": "One and eight are the three most important, but if we run the algorithm with other data.",
                    "label": 0
                },
                {
                    "sent": "Still, feature 5 is considered most one of the three most important features, but now we get feature two and feature 3.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the way to present the result.",
                    "label": 0
                },
                {
                    "sent": "In general, when we rank when we run a feature ranking algorithm, we get full rank list.",
                    "label": 0
                },
                {
                    "sent": "That is a vector with as many elements as are the features we are analyzing and the element.",
                    "label": 0
                },
                {
                    "sent": "Represents the rug, with one being the highest rank.",
                    "label": 0
                },
                {
                    "sent": "So when we see this, our intuition is that the algorithm is not very stable.",
                    "label": 0
                },
                {
                    "sent": "So we need to quantify the stability of this algorithm.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we work with feature selection techniques.",
                    "label": 0
                },
                {
                    "sent": "Let me use the representation where the output is given with the vector with zeros and ones and only once in the position of the top K most important features and again.",
                    "label": 0
                },
                {
                    "sent": "Yes, our intuition shares that we need to quantify.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Fiesta",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So I've been said it is a disparity among different research findings.",
                    "label": 1
                },
                {
                    "sent": "What has made this study necessary, and in particular fields like biomedicine, bioinformatics, chemometrics where they do not only require an accurate classification model, but they want to interpret the data to analyze the data or the outcomes of this.",
                    "label": 0
                },
                {
                    "sent": "This algorithms in order to understand the underlying process.",
                    "label": 0
                },
                {
                    "sent": "So if a small variations in the data lead to different outcomes, they conclusions the repro.",
                    "label": 1
                },
                {
                    "sent": "Net are not reliable.",
                    "label": 0
                },
                {
                    "sent": "So how can we measure this stability?",
                    "label": 0
                },
                {
                    "sent": "We need a magic that tell us where we are between perfect stable ranking algorithm and a complete random ranking algorithm.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So far.",
                    "label": 0
                },
                {
                    "sent": "There have been a proposed several metrics.",
                    "label": 0
                },
                {
                    "sent": "But each one for different kind of list.",
                    "label": 0
                },
                {
                    "sent": "For example for full rank list, the most widely used is this paraments Frank correlation coefficient that takes by value between minus one and one.",
                    "label": 0
                },
                {
                    "sent": "But there are others like a Manhattan distance.",
                    "label": 1
                },
                {
                    "sent": "If we work with top K lists where we retrieve only the came most important features.",
                    "label": 0
                },
                {
                    "sent": "There are many metrics, but probably the most important one is the Conservative stability Index.",
                    "label": 0
                },
                {
                    "sent": "But let's say that these representations have like 2 extreme cases, because either we have the full rank list where we keep the rank of each feature, or we retrieve the top K most important features, But then we don't know their relative importance, which is more important than the other.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "There are other lists.",
                    "label": 0
                },
                {
                    "sent": "Call partial rank list or top K rank list where we keep the became most important features, but we still keep your relative importance.",
                    "label": 0
                },
                {
                    "sent": "This is quite common in domains like information retrieval will retrieve the top K most important documents, but it's still we know which is the most important.",
                    "label": 0
                },
                {
                    "sent": "However, no metrics have been proposed for for this kind of list.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "We consider that feature importances something that we have.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Take into account.",
                    "label": 0
                },
                {
                    "sent": "So given these metrics, what we normally do is.",
                    "label": 0
                },
                {
                    "sent": "We have we run the algorithm several times.",
                    "label": 0
                },
                {
                    "sent": "We get some output, some ranking outputs and then we compare them.",
                    "label": 0
                },
                {
                    "sent": "In in a bird waste way.",
                    "label": 0
                },
                {
                    "sent": "So this is quite expensive in terms of computation.",
                    "label": 0
                },
                {
                    "sent": "Here are the similarity metric.",
                    "label": 0
                },
                {
                    "sent": "Maybe any of the ones we have been talking about.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Would we propose is a probabilistic approach based on the Jensen sign.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Divergents and we propose in metric that is able to handle either full rank lists or top K lists.",
                    "label": 0
                },
                {
                    "sent": "Partial rank list.",
                    "label": 0
                },
                {
                    "sent": "Our role.",
                    "label": 0
                },
                {
                    "sent": "Is that if the ranking is considered different?",
                    "label": 0
                },
                {
                    "sent": "I mean if the ranking is considering we are working with Partner Rank list or Full Rank list the differences at the top of the list would be given more important than the differences that appear at the bottom of the list.",
                    "label": 0
                },
                {
                    "sent": "And we follow.",
                    "label": 0
                },
                {
                    "sent": "This approach.",
                    "label": 0
                },
                {
                    "sent": "At first, to map the the ranking vector into a probability vector following Ashland 2007, we give a probability to each feature.",
                    "label": 0
                },
                {
                    "sent": "According to your rank it has, so we map a ranking factor into a probability vector and then the problem can be stated that as how do we measure the divergents or the disparity similarity between these two probability vectors?",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Well, when it comes to measure this, probably the most widely used option is to use the KL Divergent.",
                    "label": 1
                },
                {
                    "sent": "But it has some drawbacks, like it is a symmetric and it does not generalize when we have more than two distributions, as it is the case.",
                    "label": 1
                },
                {
                    "sent": "So we have opt for the Jensen Sandy Vergence.",
                    "label": 0
                },
                {
                    "sent": "It is like a symmetric version of the KL Divergent and given a set of any distributions where each one comes from different run of the algorithm, we compute the Jensen Sandy vergence.",
                    "label": 1
                },
                {
                    "sent": "Which basically does is computing the probability of a given feature with respect to the main probability.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And based on these divergences we propose the stability metric as one minus the vergence divided by a normalizing vector that correspond.",
                    "label": 0
                },
                {
                    "sent": "To the Department it would have a random ranking algorithm, a complete frontal ranking, and it only depends on the number of features and it can be computed before hand.",
                    "label": 1
                },
                {
                    "sent": "So in this setting.",
                    "label": 1
                },
                {
                    "sent": "If we have a stable ranking algorithm.",
                    "label": 0
                },
                {
                    "sent": "The probability of a given feature would be equal to the mean probability.",
                    "label": 0
                },
                {
                    "sent": "So the divergent would be 0 on disability one, and if it is a random ranking algorithm, diversions would be equal to the normalizing vector factor.",
                    "label": 0
                },
                {
                    "sent": "Sorry, and the stability would go to zero.",
                    "label": 0
                },
                {
                    "sent": "And if we solve in between, it would be bounded between zero and one.",
                    "label": 0
                },
                {
                    "sent": "And this is how it works when we have a full rank list.",
                    "label": 0
                },
                {
                    "sent": "But how do we stand this to top K lists or partial rank list it?",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Quite straightforward.",
                    "label": 0
                },
                {
                    "sent": "Partial ranked list.",
                    "label": 0
                },
                {
                    "sent": "All we have to do is to change the mapping and assign.",
                    "label": 0
                },
                {
                    "sent": "It probability zero to those.",
                    "label": 0
                },
                {
                    "sent": "Those features who rank is lower than than the became most important features.",
                    "label": 0
                },
                {
                    "sent": "So then they asked the normalizing factor changes according to this assigned probabilities and that's it.",
                    "label": 1
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And if we want to apply it to top K lists.",
                    "label": 0
                },
                {
                    "sent": "Again, the probability we're saying in this case is well for all the features that the became most important features.",
                    "label": 0
                },
                {
                    "sent": "The normalizing factor only depends on on L. That is the total number of features and OK that is they came most important features.",
                    "label": 1
                },
                {
                    "sent": "So in this sense, the metric we propose it's general enough to be applied to any of the different.",
                    "label": 0
                },
                {
                    "sent": "Output formats of.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "An algorithm.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We have illustrated this on two different settings, one artificial and the other.",
                    "label": 0
                },
                {
                    "sent": "Related to spectral data.",
                    "label": 0
                },
                {
                    "sent": "They will regard to the artificial one what we have done is to create.",
                    "label": 0
                },
                {
                    "sent": "A feature ranking algorithms that may be completely stable or completely run and something in between.",
                    "label": 1
                },
                {
                    "sent": "And we have generated 100 rankings.",
                    "label": 0
                },
                {
                    "sent": "Of 2000 features the way we have done it and we have named them Fr.",
                    "label": 0
                },
                {
                    "sent": "Zero has 100 random rankings, completely random and if our two for example with two identical rankings and then the remaining are completely random.",
                    "label": 1
                },
                {
                    "sent": "So it goes like this until Fr 100 where all the rankings are.",
                    "label": 0
                },
                {
                    "sent": "So what we get in the X axis, we have the.",
                    "label": 0
                },
                {
                    "sent": "The algorithms in the Y axis we have our metric and the blue line corresponds to our stability metric applied.",
                    "label": 0
                },
                {
                    "sent": "In this case, the full rank list.",
                    "label": 0
                },
                {
                    "sent": "We see how it varies from zero to 1 and we also can see a.",
                    "label": 0
                },
                {
                    "sent": "Can see how it behaves compared with the well known spermin rank correlation coefficient coefficient.",
                    "label": 0
                },
                {
                    "sent": "They behave very closely.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "If we work with top calist.",
                    "label": 0
                },
                {
                    "sent": "We have extracted this list from the feature ranking algorithms previously described, just keeping the 600 most important features.",
                    "label": 0
                },
                {
                    "sent": "We get the value of this metric compared with the consumer index.",
                    "label": 0
                },
                {
                    "sent": "And we also see that.",
                    "label": 0
                },
                {
                    "sent": "In this setting they are quite similar.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "But when we apply.",
                    "label": 0
                },
                {
                    "sent": "Add this to partial rank list.",
                    "label": 0
                },
                {
                    "sent": "Obviously the chamber in this cannot take into account the relative ranking between them.",
                    "label": 0
                },
                {
                    "sent": "So here what we compare.",
                    "label": 0
                },
                {
                    "sent": "Is set of list with 600 most important features.",
                    "label": 1
                },
                {
                    "sent": "And the overlap between this list is around 350 features.",
                    "label": 0
                },
                {
                    "sent": "If we apply this to the Quintela.",
                    "label": 0
                },
                {
                    "sent": "Trying to measure the current with the Culture index will get the red line, and if we apply our metric without considering the feature importance, we get the blue line.",
                    "label": 0
                },
                {
                    "sent": "But when we consider the feature importances applying too full to partial rank list, we get this cure.",
                    "label": 0
                },
                {
                    "sent": "On the left we have at least.",
                    "label": 0
                },
                {
                    "sent": "Where the differences appear at the bottom for the lowest rank features and on the right we get we have the list that whose differences appear at the top for the most important features and we see how this metric varies.",
                    "label": 0
                },
                {
                    "sent": "So if the differences appear at the bottom of the list, it gives that less important and the value of stability is higher, but it drops to a low value when these differences appear at the bottom of the list.",
                    "label": 0
                },
                {
                    "sent": "So we can say that the metrics like.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The Quinta by index cannot handle this information.",
                    "label": 0
                },
                {
                    "sent": "Here, yes, another illustration where we keep the 600 most important features on the list contain the same features, but the orders of the rankings are different.",
                    "label": 0
                },
                {
                    "sent": "Both the Culture Index on our metric applied to top K lists give a value of 1 because they agree the features.",
                    "label": 0
                },
                {
                    "sent": "The 600 most important features are the same.",
                    "label": 1
                },
                {
                    "sent": "But our metric gives the value of all .9.",
                    "label": 0
                },
                {
                    "sent": "When that is complete agreement about the most important features, but disagreement about which one is the most important, well, their relative importance.",
                    "label": 1
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And we also have a valuated.",
                    "label": 0
                },
                {
                    "sent": "Is the magic on spectral data.",
                    "label": 1
                },
                {
                    "sent": "These data come from fat samples.",
                    "label": 0
                },
                {
                    "sent": "Problems from lamps and the goal is to discriminate between those lamps who have fed with milk replacer or.",
                    "label": 0
                },
                {
                    "sent": "Maternal milk.",
                    "label": 0
                },
                {
                    "sent": "And data is defined by more than 1600 features.",
                    "label": 0
                },
                {
                    "sent": "And what the experts want to know is which regions of the spectrum are the most important in order to better understand which assets in the interfere in this.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we split the data set randomly in 10 falls will run the feature ranking algorithm in nine out of 10 in consecutive ways, and we did it five times.",
                    "label": 1
                },
                {
                    "sent": "So insulted in 50 rankings.",
                    "label": 0
                },
                {
                    "sent": "If we apply it to full rank list comparing for feature ranking algorithm like 1R Chi Square Game Rating relief, we get that really fun going rate.",
                    "label": 0
                },
                {
                    "sent": "You are like a stable so the conclusions from them may be quite reliable at least.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In terms of stability.",
                    "label": 0
                },
                {
                    "sent": "Here we can see how it behaves when we keep the top K most important features, both considering the rank or just the features themselves.",
                    "label": 0
                },
                {
                    "sent": "We see that.",
                    "label": 0
                },
                {
                    "sent": "If we focus on the in the continuous line that where the ranking is not considered, we may think that.",
                    "label": 0
                },
                {
                    "sent": "The stability goes to a low value as the value of key increases.",
                    "label": 0
                },
                {
                    "sent": "However, would we propose is to consider this ranking using partial rank list and we get this continuous line that is always higher than the other and it because the differences appear at the at the bottom of the list.",
                    "label": 1
                },
                {
                    "sent": "So the algorithms are indeed quite stable.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_30": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So in conclusion, the robustness of feature ranking and selection algorithms is used for knowledge discovery is an issue of high interest.",
                    "label": 1
                },
                {
                    "sent": "We tackle this problem proposing a metric based on the Jensen son on Divergent that first.",
                    "label": 0
                },
                {
                    "sent": "The ranks are mapping to probability vectors and then the difference between vectors compute using a GS divergences.",
                    "label": 0
                },
                {
                    "sent": "A disabled to work, either with full rank list top K lists or partial rank list and the differences at the top are getting more more penalized for giving more important and what is very important is the last thing that is not the least important that there is no need comparisons.",
                    "label": 1
                },
                {
                    "sent": "So we compare like its output with the average output and is less.",
                    "label": 0
                },
                {
                    "sent": "Computers, certainly expensive, so this metric give us an idea of the amount of randomness associated with with the feature selection algorithm, regardless of the feature list size, and that's all.",
                    "label": 0
                }
            ]
        }
    }
}