{
    "id": "2adms5rgppe45go7odo6y2xd65mw4odr",
    "title": "Deep learning for plant identification",
    "info": {
        "author": [
            "Ivica Dimitrovski, Department of Knowledge Technologies, Jo\u017eef Stefan Institute"
        ],
        "published": "Jan. 31, 2017",
        "recorded": "September 2016",
        "category": [
            "Top->Computer Science",
            "Top->Data Science"
        ]
    },
    "url": "http://videolectures.net/miningdata2016_dimitrovski_plant_identification/",
    "segmentation": [
        [
            "I will present an application of deep learning for.",
            "Case of plant identification, so this is.",
            "Application application that we.",
            "That we have doing in the last five years.",
            "First we need firstly using conventional feature extraction methods and learning methods and anything.",
            "The last two years deep learning so.",
            "The outline."
        ],
        [
            "Presentation first, I will give a brief introduction of the problem.",
            "Then I will explain the data set that we used in this particular research.",
            "Then I will give an overview of the plant identification approaches.",
            "So before the deep learning, the segmentation methods, the feature extraction methods, the classification methods and so on, and then I will explain how.",
            "Explain how we are using deep learning for the purpose of plant identification.",
            "Some experiments, results, issues, some problems that we have to solve and some conclusion, conclusions and for the work that we are planning.",
            "That that we are planning for the near future."
        ],
        [
            "If you don't find plans, specious is usually impossible for the general public, and often it is a very difficult task for even a professional, such as farmers or enthusia.",
            "Stick with exploiters and so on.",
            "Physical science classes for the botanist themselves.",
            "So the image based image based plans edification is the most problem.",
            "Promising solutions solution towards bringing the bridging.",
            "The botanical taxonomic gap in the recent years there there is an emergence of dedicated mobile applications such as Leaf snap and plant net that can be used for.",
            "Image classification image identification application.",
            "These applications are quite promising, but their performance is still far from the requirements for the fully automated ecological surveillance scenario just."
        ],
        [
            "Does the example in 2015 more than two million 2 million square escape being submitted by the users of the plant net mobile applications, the OS version and Android version, but only less than 3% of them were finally share them collaboratively.",
            "Validated this is a very low percentage of them.",
            "Entire set of queries that have been submitted, so it is crucial.",
            "To boost the performance of the machine learning algorithms for the purpose of automated identification, notification of these plans, but most only building effective computer vision and machine learning technique.",
            "This is crucial for for bridging this taxonomical gap problem, it is crucial to have appropriate training data and so collecting computing appropriate training data is becoming one of the most central problems for solving the economic gap problem."
        ],
        [
            "Now you search, we're using the plant cube data set for this data set contains more than 100,000 images.",
            "Some example images are shown on this slide.",
            "This slide we're using two versions of this data set.",
            "The version, the version from 2014 and 2015 Plant Cliff competition.",
            "The images from the test data set are from mom classes in this case, and for the plant left for 2016.",
            "We have a open world recognition problem in the test set we have images that are not planned on images that are images with plans that are from different classes that we have in the training set.",
            "So the plant left 2016 is more more challenging or data set, so more challenging."
        ],
        [
            "Problem some example images from this data set just to see how the images and the plans are diverse.",
            "Their diverse taking into account the leaf.",
            "We have coloration, global shape variation.",
            "We have left margin variation, number of leaflets, variation, leafless relative position variation and so on.",
            "So it's quite.",
            "Like white leaf diversity."
        ],
        [
            "If we.",
            "If we analyze this flower images, we can see that there is also diversity.",
            "The buffer between the Flowers present in this data set.",
            "The flower is often the key to identify a specious of the plant, but as I mentioned, there is a great diversity within the Flowers.",
            "Flowers for the data set can be categorized according to the color to the symmetry to the structure, orientation and the size.",
            "Also for one same species, the Flowers can have different colors, so this is even more.",
            "Other, more challenging."
        ],
        [
            "On this slide, slide some.",
            "Sorry.",
            "What this slide?",
            "We have some variation in the fruit table stem type, the entire plant in the branch.",
            "Great diversity of the type of fruits that are better represented.",
            "Troubles, speeches of the plan view data set.",
            "The stem is generally a difficult plant organ for identifying suspicious, maybe because the visual information is mainly expressed with texture, not color, an shape and because of the age of the plant the stem is changing through time.",
            "We have to take this into account also also this the entire view of the tree generally does not contain enough information.",
            "So we cannot use it.",
            "First, the purpose of plant identification, but surely can help.",
            "You can help.",
            "Combined with the other plant organs, very different appearance depending on the geographical and climatical condition condition.",
            "This is for the entire plant and for the branch."
        ],
        [
            "From the images of this data set, we have a rich metadata.",
            "The metadata is described here.",
            "The most important part is observation ID.",
            "The plan operation idea for, from which several picture can be associated with.",
            "We have also here the species, genus, family, the data vault, the original user rating of the image quality locality and so on.",
            "Uh."
        ],
        [
            "What is observation over plant is a set of 1 several images depicting the same individual plant observed, observed by the same person the same day.",
            "We will say in device there is example.",
            "Here we have this plant and several images representing leaves and Flowers of these plans.",
            "So all of these images will have the same observation ID and actually all of these images we can use later too.",
            "Predict the species for this particular plant."
        ],
        [
            "Some general information of the the two version of the of the data set for the plank left 2015.",
            "Seven plant organs 7000 image content flower, fruit fruit leaves.",
            "Live scan, entire tree branches, theme stem and so on.",
            "1000 plant classes.",
            "More than 100,000 images for over 43,000 of duration as mentioned.",
            "One observational 15 images of a plant, and this is actually a multi query challenge.",
            "We have to take into account all the images when classifying.",
            "Come on observation."
        ],
        [
            "For the blank left 2016, as I mentioned, the test data set is composed of unknown plants, vicious and normal plant objects.",
            "To create an open world plant data set so we have recognized unknown class features, but also to reject downloading plans and the objects.",
            "Also example images from this this.",
            "Except these are the example images from the test set.",
            "The train step is the same as the land Class 2015."
        ],
        [
            "15 So that the.",
            "Platelets 2016 is open center or open world recognition challenging testing computer vision as well as samples from how long classes could be present so we have to develop algorithm that is robust to unknown.",
            "Ever seen in categories?",
            "So beyond the brute force classification across the known classes of the training set of big challenge, here is to automatically reject the full the full positive classification hits caused by Dan.",
            "Unknown classes and the normal object image is present in the present in the data set."
        ],
        [
            "The test set is composed of 8000 images.",
            "Some of the images are labeled with one of the 1000 known classes of the training set.",
            "The rest of the images are from unknown classes or even known plant images.",
            "Among the first images that are that are labeled with known classes, they are 366 images stacked as invasive, according to a select list of potentially.",
            "Invasive species"
        ],
        [
            "That is the description of the datasets that we used in our experiments.",
            "Now briefly overview of the plant edification approaches that were used before deep learning approach.",
            "I will tell you something about English innovation, feature extraction, classification, and Fusion.",
            "The image."
        ],
        [
            "Imitation process can be crucial in the plant ification test becausw the image segmentation is trying to segment the main object and extract the regional feed interests and remove the relevant background which could introduce noise to a classifier that we are using different segmentation approaches for the different plan to organize.",
            "We have to use brief."
        ],
        [
            "Be about these segmentation approaches.",
            "For example, for the flower and fruit images, if we attempted a flower or fruit is usually more red compared to the lives we can locate the region of which there red channel is larger than the green Channel, and later on each color image we can convert to a Gray value image and the localized red regions are then employed as initial masking.",
            "Sing anything the flower or fruit in the great value image using the active contour method.",
            "Then we can compute the minimum bounding box of the flower or fruit as the region of interest to example images and the region of interest extracted from these images.",
            "In so in the classification step we are using these images instead of the.",
            "We are using this the small images instead of the entire image with the background."
        ],
        [
            "This data set contain contains also release scans, either as simple images.",
            "The lift is scant, usually on the white background, but there is a variation among the background color for the segmentation purpose.",
            "Here in this scenario we are no normalizing the background with the consistent.",
            "Why follow later on we are converting the core images to a great value mission applied automatically to computer.",
            "Shall the pixel great value smaller than the fresh water level is big round and those big big round pixel in the personal info images are signed with the white Board to example images images after the simple."
        ],
        [
            "Imitation for the leaf images.",
            "Because the leaf is usually located in the center area of the picture, there are typically some margin between the leaf boundaries and the picture border.",
            "So we in this area.",
            "In this case, we're just extracting the object that is located in the center of the of the pictures.",
            "To remove them the background."
        ],
        [
            "For the same images.",
            "Similar as the leaf usually located in the center of language compared the color image to Gray value image credit create a central mask of the image by cropping percent from left from right.",
            "With reevaluating each, using this mask bounding box of the resulting idea to obtain the region of interest for the steam image."
        ],
        [
            "OK, well we have done the user segmentation.",
            "Then we are proceeding with the next step.",
            "The feature extraction step.",
            "In this step we are using basically some of the feature that on the way already mentioning his presentation.",
            "We're using her local feature extraction around here, just pointing the segmented images.",
            "Some example in some example of feature extraction methods that can be used our rotation invariant invariant local band.",
            "Binary partners still inviting future can storm the speedup fahrion surf fully fully on his program.",
            "Instrumentation histogram.",
            "Some variants of the histogram in different color spaces, and so on when where we have the local features, we can construct a visual index of this local features.",
            "For example, if you're computing the local features from the training images.",
            "Then we can compress and index them using for example random maximum margin, fishing, tupeni, castables and later on for each local features from feature from the query image we compressed it with this.",
            "With this hashing, then approximative K means neighbors or search for probing multiple neighboring buckets in the hash tables to obtain the channel list of most relevant images for this query.",
            "For this query image."
        ],
        [
            "Besides the doing this, we can also construct the standard bag of visual words.",
            "You can use the standard bag of visual words approach.",
            "We can construct us.",
            "We can construct for example visual codebook for each plant organ.",
            "For doing this we can use.",
            "For example K means or approximative K means or predicted or even predicted clustering trees if we have many number of local strip clubs and if we are clustering.",
            "These local distributors seen many clusters or visual words.",
            "We cannot experience experiments using Approximative Kings.",
            "Also, predictive clustering trees later on we can use the term frequency inverse document frequency.",
            "Some normalization normalization to count the similarities between these.",
            "These images also besides the bag of visual words, we can use the feature parallel feature coding.",
            "We can compute losing richer models in the SIFT.",
            "This space that this alternative to the bag of visual words approaching these are the local feature extraction techniques that thing that can be used."
        ],
        [
            "Can also use some feature extraction techniques that are global that they take into account the entire the entire image.",
            "Entire picture.",
            "For example, we have the multi scale triangle shape.",
            "Descriptor that can that is.",
            "Validated and variously database.",
            "Very robust and fast to compute.",
            "It is used for local mage matching of shapes and that's why it is best for the images with leaves.",
            "How it briefly, how it is computed, the shape boundary is represented with a sequence sequence on of sampling points which are uniformly distributed over the contours.",
            "Another thing the code wise order for example and then for each point each point actually is represented by a.",
            "383 angles computed at different different different scales."
        ],
        [
            "The classification algorithms we can use KNN classifier.",
            "We can build for example.",
            "For example, set an classifier for the seven different plant organs.",
            "We can use support vector machines.",
            "We can use different similarity metrics.",
            "Is crucial to use some sort of Fusion scheme to obtain the final prediction.",
            "We cause.",
            "Usually we have many feature descriptors also seven classifiers.",
            "So somehow to obtain the the classes for the observation we have to fuse these different predictions from the different feature extraction methods and from the different from the different classifiers."
        ],
        [
            "Summary of this approach is.",
            "As I mentioned, these approaches are before the before the start, before deep learning applies to the planet signification problem.",
            "If you want to use something that is not declaring the best choice would be Fisher.",
            "Vector encoding contain state of the art results results we have to extract densities and color moments in the images to produce each local feature to a 60 four dimension.",
            "Dimensions after using PCA.",
            "Estimated using mixture models, for example with five prominent until components to produce the Fisher vector representation for the images, and then as a classifier to use them.",
            "Linear SVM, one for each side of the future.",
            "Features Sift and the color moments.",
            "This is the paper that describes this.",
            "Please set up.",
            "The results are about 40% of miniature precision.",
            "OK."
        ],
        [
            "And now something about the deep learning approach.",
            "You know that thing deep.",
            "Learning the raw data data is fit into the convolutional neural networking multiple levels.",
            "Evolution of neural network automatically discover, discover, Skype level features or plant which is recognition.",
            "The deep learning approaches Sky computational complexity to be trained from scratch, and that's why usually we're using pre trained networks that are fine tuned for plant identification purposes.",
            "For example, we're using.",
            "CNET or Google Maps to.",
            "That are pre trained on the large image set and later on we are fine tuning them for the purpose of plant plant identification purposes."
        ],
        [
            "The first step that we are going in the deep learning approaches day termination date of mentation we're applying data augmentation to decrease the chance of overfitting during training and to improve the performance of them of the convolutional neural networks.",
            "Actually with the with the data innovation, we're increasing the data set size.",
            "We're doing artificial expansion of the data set.",
            "Using accommodation by rotation by mirroring clustering.",
            "All sorts of different augmentation techniques can be used to artificially expand the the initial data set.",
            "The white spaces after the mentation are filled with the latest set mean value."
        ],
        [
            "Some example image the the initial image and the image obtain after the rotation augmented image.",
            "The white spaces are filled with the data set mean value."
        ],
        [
            "Then augmentation by mirroring."
        ],
        [
            "In augmentation by skewing.",
            "In this way, we are enlarging the training data set data set that we are.",
            "We are going to use for training for fine tuning to classify."
        ],
        [
            "This is the overall overall."
        ],
        [
            "System architecture we have the initial training set and test set.",
            "The train set is.",
            "Through the application model module.",
            "To obtain the Elemental train set with artificially added images, we are using the Google Maps Model 3 training on the large set of images, 40,000,000 images from image net.",
            "If you are fine tuning this model with the elemented.",
            "Documented data set from the from the plant review.",
            "We are obtaining the predictions and in the later phase we are using some sort of Fusion to take into account the images in the observation and we're doing some evaluation and presenting that final result."
        ],
        [
            "Results.",
            "This is the Google net model that we used in this application as a nation is pre trained on the image.",
            "Net data set implemented in the fake convolutional neural network with 27 layers we take into account the inception layers.",
            "Receptive field is 224 by 224.",
            "The images that are in the energy color space and as I mentioned we have inception architecture.",
            "We have accept."
        ],
        [
            "Inception architecture in this model, the inception model in the convolutional neural network are designed to allow for deeper, larger convolutional layers, while at the same time allowing for more efficient computations.",
            "How is this done?",
            "This is done by using one by one convolution convolutions with small feature map size is an example here.",
            "190 two, 28 by 28 sites feature Maps can be reduced to 6428 by 28 future Max 264 one by one convolution because of the reduced size.",
            "This one by our convolution can be follow up with larger convolution conclusions for size 3 by 3 or 5 by 5 by 5 in the output of the reception module.",
            "All the.",
            "Large convolutions are concatenated into a big feature map, which is then fed into the next layer of the of the convolutional neural net."
        ],
        [
            "The Google Maps layer Sir presented here.",
            "You can see the convolutional layers.",
            "The Max pooling layers, the inception layers and in the later the last layer is the softmax layer.",
            "You can see also here the output size of each layer, also the parameters.",
            "Oh, did we obtain each of these layers?"
        ],
        [
            "Some experiments first.",
            "Experiments to see how the data set size and the diversity of the data set data set to impact the classification performance.",
            "Then we also did some experiments to see how the data argumentation impact the overall performance.",
            "Also of our of our approach."
        ],
        [
            "Power system these are the experiments.",
            "Here we are using the volume for the 2014 and plan 2015 data set several experiments only using Google, Google Maps, Google Maps, model train from scratch using the plant 2014 data.",
            "Set up your Google Maps only on the image net, not fine tuned on the plan data set Google Net on Image net and.",
            "Fine Tune complaint 2014 Google Net retrain from image net.",
            "Fine tuned with the difference.",
            "Expand Expanded datasets using them, augmentation methods, and in the last the last experiment, experiment with using the Google Net.",
            "Jeanette, but fine tunes on the plants 2015."
        ],
        [
            "Sets the results as I as well as to be expected.",
            "If you're using your Google Maps.",
            "Not fine tuned on the planet data set we are obtaining.",
            "Very low.",
            "Move accuracy very little.",
            "Very bit resolve.",
            "These are the results if we're using.",
            "If you are using convolutional neural network training from scratch using only the plant 2014 data set, the results are between 18%.",
            "This is the Google net trained on image net training.",
            "Retraining can image net and fine tune with the images from.",
            "Left 2014 you can see that boost in measure.",
            "Others.",
            "The first images only take into account.",
            "If we if we have the correct label for the first image, so we are.",
            "You're a prisoner papers.",
            "Google net on the image net pre training and plan 2014.",
            "See the boosting the performance compared to the Google net trained from scratch from this data set.",
            "If we compare the performance of the augmented data set set, we can see that if we augmented the data set then we obtain further improvement of the performance compared to the original original data set.",
            "If we use them.",
            "Planet 2015 data set.",
            "We are obtaining.",
            "We are the difference between the.",
            "Then 2014 and plan 2015 is that the plan 2015 has 1000 classes and the plan 2014 has 500 classes.",
            "So this data set is actually bigger than this data set.",
            "We are training on the we are training the fine tuning the network on the these data set, but we are testing on on the plans 2014.",
            "I wanted to ask so if you have 500,000 plus is so accuracy 45% is quite good.",
            "Would you check?",
            "So, did you try measuring the accuracy in North or identifying each individual species, but instead seeing if the genus is correct?",
            "No, we have not taken into account here here that economy upgrade.",
            "You're only interested in the in the lower.",
            "Yes, people will do that as well.",
            "It might look much, much better perhaps.",
            "Actually, we we we are planning this for the framework we are.",
            "We are somehow trying to incorporate the hierarchy of the taxonomy into the learning process.",
            "Some color, but we haven't done that yet.",
            "We are planning to do that.",
            "Football.",
            "When you say you're fine tuning Imagenet, you mean that you're throwing away the last layer.",
            "Keeping the weights from Imagemaps very trainable.",
            "So have you tested how much though?",
            "The weights of the lower level are actually changing overnight.",
            "Or is it just that you're just living a different classifier on the representation of engagement?",
            "And what happens if you run like?",
            "Ask about the machine on the on the representation information.",
            "If we run without, you know.",
            "Doing backpropagation and we have done that, but the results are worse, much worse.",
            "Maybe by I don't know.",
            "I don't know the exact number, so I think by 50% or maybe worse, OK?",
            "That's why we decided to use this new setup.",
            "The results were similar with the the other approaches that I mentioned before.",
            "The linear SVM station.",
            "The whole message is the Fisher vector from here, sorry.",
            "You're not deep learning.",
            "It was interesting in the 2014 competition.",
            "The Fisher vector encoding using linear SVM's was the best ranked.",
            "A result if us around 50% I think in the final scoring and the same team applied also deep learning deep learning the results from different learning more about 20 or so percent so.",
            "But in the next year most of the team started using only deep learning.",
            "Come, the results increased quite for this year.",
            "The best result is.",
            "80%.",
            "Quiting increase compared to the previous years.",
            "We participated in.",
            "Attempt 2014 and we did not manage to submit the results for 2015, but if we have submitted we would view rank type thing.",
            "Second transfer."
        ],
        [
            "This is the learning curve.",
            "Increase of accuracy and the increase of the loss during the training process and want to get into details."
        ],
        [
            "Here it was interesting as I mentioned, for the planet left 2016.",
            "The organizers of this competition includes unknown classes.",
            "You just normal classes and normal plant images in the test data set.",
            "So for this particular competition we have to somehow.",
            "First, separately Finetune Googlenet model for a binary classification problem.",
            "For example plan versus non plant images.",
            "For this set up the training data data set contains plant images from life 2015 unknown plant images for the floor scale competition and using the results for results from the binary classifier, we can reject the images that are.",
            "Classifier classify does not make images.",
            "Unassign a low confidence storing data in the final main plant signification unification system.",
            "So first we are training.",
            "A binary classifier, but can distinguish two classes, plant versus non plants.",
            "Then we are using the same setup as previous but we are decreasing the probabilities were signed both in store for this images that are classified classified as non plant images in them.",
            "In the final.",
            "In the final result."
        ],
        [
            "It is interesting here that the degree of novelty in the test set is a strong influence on the performance.",
            "For example, in this year, blank left 2016 competition when 25% of the various still belong to a known class.",
            "None of the system region mean average precision greater and greater than.",
            "C Zero point 45 compared to the zero point 83 in the closed world world.",
            "Set up where the classes in the training images are from the.",
            "You may just be the test data set.",
            "Test data set are.",
            "With the classes from the training data set, so this is quite quite a problem in a real case scenario this number is much lower because if the user has the mobile phone and it goes and.",
            "Take take picture of everything and submitted the queries.",
            "The number, the number of of this number will be will be much lower, so the performance is is can be decorated even even more so this is this is quite a quite a problem that have to be solved, solved in the plans magnification task.",
            "Additional."
        ],
        [
            "Problems that we have here is that the original net model requires input image of facial size 124 by 224.",
            "The images in the planet left versions are arbitrarily sized so.",
            "Following the special size restriction in Google Maps model, the input images gets to be either copper or lead to information loss there is."
        ],
        [
            "Solution for this problem?",
            "We can try this, yet we can use spatial spatial pyramid pooling layer.",
            "The feature we can divide a feature map spatially 1 by 1 two by 4 by 4 in total.",
            "If anyone region then each region can be average pulled producing a vector of pick sides.",
            "For example, if we have 5050 generals in the last convolutional layer, you're paying a vector of fixed size 1010 thousand 77155.",
            "Um?",
            "55 scalars in the vector.",
            "Um?",
            "This conversion of arbitrary size feature mapping to the into a fixed size vector or allow the model to accept input image obtaining size.",
            "We can skip that step when we are processing the images in the fixed.",
            "Sized OK."
        ],
        [
            "Make some conclusions and further work.",
            "Mushel neural networks.",
            "Three training on large datasets set and fine tuned on towamencin datasets to the specific domain to get the best way to get the best results is is our recommendation, but the convolutional neural network is strongly affected by the higher rates of images belonging to unknown class, so we have to find the solution for this.",
            "We are as a further work we are.",
            "We will definitely try different.",
            "Set up self convolutional neural networks.",
            "Somehow we can create an example of convolutional neural network networks with different set up with different convolutional layer and so on and then we can combine the tradition to increase the classification performance.",
            "We are also planning to somehow combine the handcrafted features into the feature features obtained into the convolutional neural networks.",
            "We are we have done another application similar to this but in that application we had only lift images and it was quite interesting.",
            "The results were quite interesting.",
            "Some of the classes that are very that were very difficult to be distinguished even looking by I from North by some expert were correctly classified by the convolutional neural network and some of the images that were quite distinct.",
            "Were wrongly classified by the Convolutional neural network.",
            "In this case, if we have applied standard conventional methods.",
            "Feature extraction methods.",
            "Location methods them.",
            "These images would be correct in the classifier, so we can somehow combine with interactive features and convolutional neural networking in order to eliminate these problems.",
            "Also we are.",
            "We can also try to use them higher here of the taxonomy into in the convolutional neural networks too.",
            "Do something to somehow boost the overall performance of.",
            "Of this approach."
        ],
        [
            "Let's see."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I will present an application of deep learning for.",
                    "label": 1
                },
                {
                    "sent": "Case of plant identification, so this is.",
                    "label": 0
                },
                {
                    "sent": "Application application that we.",
                    "label": 0
                },
                {
                    "sent": "That we have doing in the last five years.",
                    "label": 0
                },
                {
                    "sent": "First we need firstly using conventional feature extraction methods and learning methods and anything.",
                    "label": 0
                },
                {
                    "sent": "The last two years deep learning so.",
                    "label": 0
                },
                {
                    "sent": "The outline.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Presentation first, I will give a brief introduction of the problem.",
                    "label": 0
                },
                {
                    "sent": "Then I will explain the data set that we used in this particular research.",
                    "label": 0
                },
                {
                    "sent": "Then I will give an overview of the plant identification approaches.",
                    "label": 1
                },
                {
                    "sent": "So before the deep learning, the segmentation methods, the feature extraction methods, the classification methods and so on, and then I will explain how.",
                    "label": 0
                },
                {
                    "sent": "Explain how we are using deep learning for the purpose of plant identification.",
                    "label": 1
                },
                {
                    "sent": "Some experiments, results, issues, some problems that we have to solve and some conclusion, conclusions and for the work that we are planning.",
                    "label": 0
                },
                {
                    "sent": "That that we are planning for the near future.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "If you don't find plans, specious is usually impossible for the general public, and often it is a very difficult task for even a professional, such as farmers or enthusia.",
                    "label": 1
                },
                {
                    "sent": "Stick with exploiters and so on.",
                    "label": 0
                },
                {
                    "sent": "Physical science classes for the botanist themselves.",
                    "label": 1
                },
                {
                    "sent": "So the image based image based plans edification is the most problem.",
                    "label": 0
                },
                {
                    "sent": "Promising solutions solution towards bringing the bridging.",
                    "label": 0
                },
                {
                    "sent": "The botanical taxonomic gap in the recent years there there is an emergence of dedicated mobile applications such as Leaf snap and plant net that can be used for.",
                    "label": 0
                },
                {
                    "sent": "Image classification image identification application.",
                    "label": 0
                },
                {
                    "sent": "These applications are quite promising, but their performance is still far from the requirements for the fully automated ecological surveillance scenario just.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Does the example in 2015 more than two million 2 million square escape being submitted by the users of the plant net mobile applications, the OS version and Android version, but only less than 3% of them were finally share them collaboratively.",
                    "label": 1
                },
                {
                    "sent": "Validated this is a very low percentage of them.",
                    "label": 0
                },
                {
                    "sent": "Entire set of queries that have been submitted, so it is crucial.",
                    "label": 1
                },
                {
                    "sent": "To boost the performance of the machine learning algorithms for the purpose of automated identification, notification of these plans, but most only building effective computer vision and machine learning technique.",
                    "label": 0
                },
                {
                    "sent": "This is crucial for for bridging this taxonomical gap problem, it is crucial to have appropriate training data and so collecting computing appropriate training data is becoming one of the most central problems for solving the economic gap problem.",
                    "label": 1
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now you search, we're using the plant cube data set for this data set contains more than 100,000 images.",
                    "label": 0
                },
                {
                    "sent": "Some example images are shown on this slide.",
                    "label": 0
                },
                {
                    "sent": "This slide we're using two versions of this data set.",
                    "label": 1
                },
                {
                    "sent": "The version, the version from 2014 and 2015 Plant Cliff competition.",
                    "label": 0
                },
                {
                    "sent": "The images from the test data set are from mom classes in this case, and for the plant left for 2016.",
                    "label": 1
                },
                {
                    "sent": "We have a open world recognition problem in the test set we have images that are not planned on images that are images with plans that are from different classes that we have in the training set.",
                    "label": 0
                },
                {
                    "sent": "So the plant left 2016 is more more challenging or data set, so more challenging.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Problem some example images from this data set just to see how the images and the plans are diverse.",
                    "label": 0
                },
                {
                    "sent": "Their diverse taking into account the leaf.",
                    "label": 0
                },
                {
                    "sent": "We have coloration, global shape variation.",
                    "label": 0
                },
                {
                    "sent": "We have left margin variation, number of leaflets, variation, leafless relative position variation and so on.",
                    "label": 0
                },
                {
                    "sent": "So it's quite.",
                    "label": 0
                },
                {
                    "sent": "Like white leaf diversity.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "If we.",
                    "label": 0
                },
                {
                    "sent": "If we analyze this flower images, we can see that there is also diversity.",
                    "label": 0
                },
                {
                    "sent": "The buffer between the Flowers present in this data set.",
                    "label": 0
                },
                {
                    "sent": "The flower is often the key to identify a specious of the plant, but as I mentioned, there is a great diversity within the Flowers.",
                    "label": 0
                },
                {
                    "sent": "Flowers for the data set can be categorized according to the color to the symmetry to the structure, orientation and the size.",
                    "label": 0
                },
                {
                    "sent": "Also for one same species, the Flowers can have different colors, so this is even more.",
                    "label": 0
                },
                {
                    "sent": "Other, more challenging.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "On this slide, slide some.",
                    "label": 0
                },
                {
                    "sent": "Sorry.",
                    "label": 0
                },
                {
                    "sent": "What this slide?",
                    "label": 0
                },
                {
                    "sent": "We have some variation in the fruit table stem type, the entire plant in the branch.",
                    "label": 0
                },
                {
                    "sent": "Great diversity of the type of fruits that are better represented.",
                    "label": 0
                },
                {
                    "sent": "Troubles, speeches of the plan view data set.",
                    "label": 0
                },
                {
                    "sent": "The stem is generally a difficult plant organ for identifying suspicious, maybe because the visual information is mainly expressed with texture, not color, an shape and because of the age of the plant the stem is changing through time.",
                    "label": 0
                },
                {
                    "sent": "We have to take this into account also also this the entire view of the tree generally does not contain enough information.",
                    "label": 0
                },
                {
                    "sent": "So we cannot use it.",
                    "label": 0
                },
                {
                    "sent": "First, the purpose of plant identification, but surely can help.",
                    "label": 0
                },
                {
                    "sent": "You can help.",
                    "label": 0
                },
                {
                    "sent": "Combined with the other plant organs, very different appearance depending on the geographical and climatical condition condition.",
                    "label": 0
                },
                {
                    "sent": "This is for the entire plant and for the branch.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "From the images of this data set, we have a rich metadata.",
                    "label": 0
                },
                {
                    "sent": "The metadata is described here.",
                    "label": 0
                },
                {
                    "sent": "The most important part is observation ID.",
                    "label": 1
                },
                {
                    "sent": "The plan operation idea for, from which several picture can be associated with.",
                    "label": 1
                },
                {
                    "sent": "We have also here the species, genus, family, the data vault, the original user rating of the image quality locality and so on.",
                    "label": 1
                },
                {
                    "sent": "Uh.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "What is observation over plant is a set of 1 several images depicting the same individual plant observed, observed by the same person the same day.",
                    "label": 1
                },
                {
                    "sent": "We will say in device there is example.",
                    "label": 0
                },
                {
                    "sent": "Here we have this plant and several images representing leaves and Flowers of these plans.",
                    "label": 0
                },
                {
                    "sent": "So all of these images will have the same observation ID and actually all of these images we can use later too.",
                    "label": 0
                },
                {
                    "sent": "Predict the species for this particular plant.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Some general information of the the two version of the of the data set for the plank left 2015.",
                    "label": 0
                },
                {
                    "sent": "Seven plant organs 7000 image content flower, fruit fruit leaves.",
                    "label": 1
                },
                {
                    "sent": "Live scan, entire tree branches, theme stem and so on.",
                    "label": 0
                },
                {
                    "sent": "1000 plant classes.",
                    "label": 0
                },
                {
                    "sent": "More than 100,000 images for over 43,000 of duration as mentioned.",
                    "label": 1
                },
                {
                    "sent": "One observational 15 images of a plant, and this is actually a multi query challenge.",
                    "label": 1
                },
                {
                    "sent": "We have to take into account all the images when classifying.",
                    "label": 0
                },
                {
                    "sent": "Come on observation.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "For the blank left 2016, as I mentioned, the test data set is composed of unknown plants, vicious and normal plant objects.",
                    "label": 1
                },
                {
                    "sent": "To create an open world plant data set so we have recognized unknown class features, but also to reject downloading plans and the objects.",
                    "label": 1
                },
                {
                    "sent": "Also example images from this this.",
                    "label": 0
                },
                {
                    "sent": "Except these are the example images from the test set.",
                    "label": 0
                },
                {
                    "sent": "The train step is the same as the land Class 2015.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "15 So that the.",
                    "label": 0
                },
                {
                    "sent": "Platelets 2016 is open center or open world recognition challenging testing computer vision as well as samples from how long classes could be present so we have to develop algorithm that is robust to unknown.",
                    "label": 1
                },
                {
                    "sent": "Ever seen in categories?",
                    "label": 0
                },
                {
                    "sent": "So beyond the brute force classification across the known classes of the training set of big challenge, here is to automatically reject the full the full positive classification hits caused by Dan.",
                    "label": 1
                },
                {
                    "sent": "Unknown classes and the normal object image is present in the present in the data set.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The test set is composed of 8000 images.",
                    "label": 1
                },
                {
                    "sent": "Some of the images are labeled with one of the 1000 known classes of the training set.",
                    "label": 1
                },
                {
                    "sent": "The rest of the images are from unknown classes or even known plant images.",
                    "label": 0
                },
                {
                    "sent": "Among the first images that are that are labeled with known classes, they are 366 images stacked as invasive, according to a select list of potentially.",
                    "label": 0
                },
                {
                    "sent": "Invasive species",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "That is the description of the datasets that we used in our experiments.",
                    "label": 0
                },
                {
                    "sent": "Now briefly overview of the plant edification approaches that were used before deep learning approach.",
                    "label": 1
                },
                {
                    "sent": "I will tell you something about English innovation, feature extraction, classification, and Fusion.",
                    "label": 1
                },
                {
                    "sent": "The image.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Imitation process can be crucial in the plant ification test becausw the image segmentation is trying to segment the main object and extract the regional feed interests and remove the relevant background which could introduce noise to a classifier that we are using different segmentation approaches for the different plan to organize.",
                    "label": 0
                },
                {
                    "sent": "We have to use brief.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Be about these segmentation approaches.",
                    "label": 0
                },
                {
                    "sent": "For example, for the flower and fruit images, if we attempted a flower or fruit is usually more red compared to the lives we can locate the region of which there red channel is larger than the green Channel, and later on each color image we can convert to a Gray value image and the localized red regions are then employed as initial masking.",
                    "label": 1
                },
                {
                    "sent": "Sing anything the flower or fruit in the great value image using the active contour method.",
                    "label": 0
                },
                {
                    "sent": "Then we can compute the minimum bounding box of the flower or fruit as the region of interest to example images and the region of interest extracted from these images.",
                    "label": 0
                },
                {
                    "sent": "In so in the classification step we are using these images instead of the.",
                    "label": 0
                },
                {
                    "sent": "We are using this the small images instead of the entire image with the background.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This data set contain contains also release scans, either as simple images.",
                    "label": 0
                },
                {
                    "sent": "The lift is scant, usually on the white background, but there is a variation among the background color for the segmentation purpose.",
                    "label": 1
                },
                {
                    "sent": "Here in this scenario we are no normalizing the background with the consistent.",
                    "label": 1
                },
                {
                    "sent": "Why follow later on we are converting the core images to a great value mission applied automatically to computer.",
                    "label": 0
                },
                {
                    "sent": "Shall the pixel great value smaller than the fresh water level is big round and those big big round pixel in the personal info images are signed with the white Board to example images images after the simple.",
                    "label": 1
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Imitation for the leaf images.",
                    "label": 0
                },
                {
                    "sent": "Because the leaf is usually located in the center area of the picture, there are typically some margin between the leaf boundaries and the picture border.",
                    "label": 1
                },
                {
                    "sent": "So we in this area.",
                    "label": 1
                },
                {
                    "sent": "In this case, we're just extracting the object that is located in the center of the of the pictures.",
                    "label": 0
                },
                {
                    "sent": "To remove them the background.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "For the same images.",
                    "label": 0
                },
                {
                    "sent": "Similar as the leaf usually located in the center of language compared the color image to Gray value image credit create a central mask of the image by cropping percent from left from right.",
                    "label": 1
                },
                {
                    "sent": "With reevaluating each, using this mask bounding box of the resulting idea to obtain the region of interest for the steam image.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, well we have done the user segmentation.",
                    "label": 0
                },
                {
                    "sent": "Then we are proceeding with the next step.",
                    "label": 0
                },
                {
                    "sent": "The feature extraction step.",
                    "label": 0
                },
                {
                    "sent": "In this step we are using basically some of the feature that on the way already mentioning his presentation.",
                    "label": 0
                },
                {
                    "sent": "We're using her local feature extraction around here, just pointing the segmented images.",
                    "label": 1
                },
                {
                    "sent": "Some example in some example of feature extraction methods that can be used our rotation invariant invariant local band.",
                    "label": 0
                },
                {
                    "sent": "Binary partners still inviting future can storm the speedup fahrion surf fully fully on his program.",
                    "label": 0
                },
                {
                    "sent": "Instrumentation histogram.",
                    "label": 1
                },
                {
                    "sent": "Some variants of the histogram in different color spaces, and so on when where we have the local features, we can construct a visual index of this local features.",
                    "label": 0
                },
                {
                    "sent": "For example, if you're computing the local features from the training images.",
                    "label": 0
                },
                {
                    "sent": "Then we can compress and index them using for example random maximum margin, fishing, tupeni, castables and later on for each local features from feature from the query image we compressed it with this.",
                    "label": 1
                },
                {
                    "sent": "With this hashing, then approximative K means neighbors or search for probing multiple neighboring buckets in the hash tables to obtain the channel list of most relevant images for this query.",
                    "label": 0
                },
                {
                    "sent": "For this query image.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Besides the doing this, we can also construct the standard bag of visual words.",
                    "label": 0
                },
                {
                    "sent": "You can use the standard bag of visual words approach.",
                    "label": 0
                },
                {
                    "sent": "We can construct us.",
                    "label": 0
                },
                {
                    "sent": "We can construct for example visual codebook for each plant organ.",
                    "label": 1
                },
                {
                    "sent": "For doing this we can use.",
                    "label": 0
                },
                {
                    "sent": "For example K means or approximative K means or predicted or even predicted clustering trees if we have many number of local strip clubs and if we are clustering.",
                    "label": 0
                },
                {
                    "sent": "These local distributors seen many clusters or visual words.",
                    "label": 0
                },
                {
                    "sent": "We cannot experience experiments using Approximative Kings.",
                    "label": 1
                },
                {
                    "sent": "Also, predictive clustering trees later on we can use the term frequency inverse document frequency.",
                    "label": 0
                },
                {
                    "sent": "Some normalization normalization to count the similarities between these.",
                    "label": 1
                },
                {
                    "sent": "These images also besides the bag of visual words, we can use the feature parallel feature coding.",
                    "label": 0
                },
                {
                    "sent": "We can compute losing richer models in the SIFT.",
                    "label": 0
                },
                {
                    "sent": "This space that this alternative to the bag of visual words approaching these are the local feature extraction techniques that thing that can be used.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Can also use some feature extraction techniques that are global that they take into account the entire the entire image.",
                    "label": 0
                },
                {
                    "sent": "Entire picture.",
                    "label": 0
                },
                {
                    "sent": "For example, we have the multi scale triangle shape.",
                    "label": 0
                },
                {
                    "sent": "Descriptor that can that is.",
                    "label": 0
                },
                {
                    "sent": "Validated and variously database.",
                    "label": 0
                },
                {
                    "sent": "Very robust and fast to compute.",
                    "label": 1
                },
                {
                    "sent": "It is used for local mage matching of shapes and that's why it is best for the images with leaves.",
                    "label": 1
                },
                {
                    "sent": "How it briefly, how it is computed, the shape boundary is represented with a sequence sequence on of sampling points which are uniformly distributed over the contours.",
                    "label": 1
                },
                {
                    "sent": "Another thing the code wise order for example and then for each point each point actually is represented by a.",
                    "label": 1
                },
                {
                    "sent": "383 angles computed at different different different scales.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The classification algorithms we can use KNN classifier.",
                    "label": 1
                },
                {
                    "sent": "We can build for example.",
                    "label": 0
                },
                {
                    "sent": "For example, set an classifier for the seven different plant organs.",
                    "label": 0
                },
                {
                    "sent": "We can use support vector machines.",
                    "label": 1
                },
                {
                    "sent": "We can use different similarity metrics.",
                    "label": 0
                },
                {
                    "sent": "Is crucial to use some sort of Fusion scheme to obtain the final prediction.",
                    "label": 1
                },
                {
                    "sent": "We cause.",
                    "label": 0
                },
                {
                    "sent": "Usually we have many feature descriptors also seven classifiers.",
                    "label": 0
                },
                {
                    "sent": "So somehow to obtain the the classes for the observation we have to fuse these different predictions from the different feature extraction methods and from the different from the different classifiers.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Summary of this approach is.",
                    "label": 1
                },
                {
                    "sent": "As I mentioned, these approaches are before the before the start, before deep learning applies to the planet signification problem.",
                    "label": 0
                },
                {
                    "sent": "If you want to use something that is not declaring the best choice would be Fisher.",
                    "label": 0
                },
                {
                    "sent": "Vector encoding contain state of the art results results we have to extract densities and color moments in the images to produce each local feature to a 60 four dimension.",
                    "label": 1
                },
                {
                    "sent": "Dimensions after using PCA.",
                    "label": 0
                },
                {
                    "sent": "Estimated using mixture models, for example with five prominent until components to produce the Fisher vector representation for the images, and then as a classifier to use them.",
                    "label": 1
                },
                {
                    "sent": "Linear SVM, one for each side of the future.",
                    "label": 0
                },
                {
                    "sent": "Features Sift and the color moments.",
                    "label": 0
                },
                {
                    "sent": "This is the paper that describes this.",
                    "label": 0
                },
                {
                    "sent": "Please set up.",
                    "label": 0
                },
                {
                    "sent": "The results are about 40% of miniature precision.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And now something about the deep learning approach.",
                    "label": 0
                },
                {
                    "sent": "You know that thing deep.",
                    "label": 0
                },
                {
                    "sent": "Learning the raw data data is fit into the convolutional neural networking multiple levels.",
                    "label": 1
                },
                {
                    "sent": "Evolution of neural network automatically discover, discover, Skype level features or plant which is recognition.",
                    "label": 1
                },
                {
                    "sent": "The deep learning approaches Sky computational complexity to be trained from scratch, and that's why usually we're using pre trained networks that are fine tuned for plant identification purposes.",
                    "label": 0
                },
                {
                    "sent": "For example, we're using.",
                    "label": 0
                },
                {
                    "sent": "CNET or Google Maps to.",
                    "label": 0
                },
                {
                    "sent": "That are pre trained on the large image set and later on we are fine tuning them for the purpose of plant plant identification purposes.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The first step that we are going in the deep learning approaches day termination date of mentation we're applying data augmentation to decrease the chance of overfitting during training and to improve the performance of them of the convolutional neural networks.",
                    "label": 1
                },
                {
                    "sent": "Actually with the with the data innovation, we're increasing the data set size.",
                    "label": 1
                },
                {
                    "sent": "We're doing artificial expansion of the data set.",
                    "label": 1
                },
                {
                    "sent": "Using accommodation by rotation by mirroring clustering.",
                    "label": 0
                },
                {
                    "sent": "All sorts of different augmentation techniques can be used to artificially expand the the initial data set.",
                    "label": 1
                },
                {
                    "sent": "The white spaces after the mentation are filled with the latest set mean value.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Some example image the the initial image and the image obtain after the rotation augmented image.",
                    "label": 0
                },
                {
                    "sent": "The white spaces are filled with the data set mean value.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Then augmentation by mirroring.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In augmentation by skewing.",
                    "label": 0
                },
                {
                    "sent": "In this way, we are enlarging the training data set data set that we are.",
                    "label": 0
                },
                {
                    "sent": "We are going to use for training for fine tuning to classify.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is the overall overall.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "System architecture we have the initial training set and test set.",
                    "label": 0
                },
                {
                    "sent": "The train set is.",
                    "label": 0
                },
                {
                    "sent": "Through the application model module.",
                    "label": 0
                },
                {
                    "sent": "To obtain the Elemental train set with artificially added images, we are using the Google Maps Model 3 training on the large set of images, 40,000,000 images from image net.",
                    "label": 0
                },
                {
                    "sent": "If you are fine tuning this model with the elemented.",
                    "label": 0
                },
                {
                    "sent": "Documented data set from the from the plant review.",
                    "label": 0
                },
                {
                    "sent": "We are obtaining the predictions and in the later phase we are using some sort of Fusion to take into account the images in the observation and we're doing some evaluation and presenting that final result.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Results.",
                    "label": 0
                },
                {
                    "sent": "This is the Google net model that we used in this application as a nation is pre trained on the image.",
                    "label": 0
                },
                {
                    "sent": "Net data set implemented in the fake convolutional neural network with 27 layers we take into account the inception layers.",
                    "label": 1
                },
                {
                    "sent": "Receptive field is 224 by 224.",
                    "label": 0
                },
                {
                    "sent": "The images that are in the energy color space and as I mentioned we have inception architecture.",
                    "label": 0
                },
                {
                    "sent": "We have accept.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Inception architecture in this model, the inception model in the convolutional neural network are designed to allow for deeper, larger convolutional layers, while at the same time allowing for more efficient computations.",
                    "label": 1
                },
                {
                    "sent": "How is this done?",
                    "label": 1
                },
                {
                    "sent": "This is done by using one by one convolution convolutions with small feature map size is an example here.",
                    "label": 0
                },
                {
                    "sent": "190 two, 28 by 28 sites feature Maps can be reduced to 6428 by 28 future Max 264 one by one convolution because of the reduced size.",
                    "label": 0
                },
                {
                    "sent": "This one by our convolution can be follow up with larger convolution conclusions for size 3 by 3 or 5 by 5 by 5 in the output of the reception module.",
                    "label": 0
                },
                {
                    "sent": "All the.",
                    "label": 1
                },
                {
                    "sent": "Large convolutions are concatenated into a big feature map, which is then fed into the next layer of the of the convolutional neural net.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The Google Maps layer Sir presented here.",
                    "label": 0
                },
                {
                    "sent": "You can see the convolutional layers.",
                    "label": 0
                },
                {
                    "sent": "The Max pooling layers, the inception layers and in the later the last layer is the softmax layer.",
                    "label": 0
                },
                {
                    "sent": "You can see also here the output size of each layer, also the parameters.",
                    "label": 0
                },
                {
                    "sent": "Oh, did we obtain each of these layers?",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Some experiments first.",
                    "label": 0
                },
                {
                    "sent": "Experiments to see how the data set size and the diversity of the data set data set to impact the classification performance.",
                    "label": 1
                },
                {
                    "sent": "Then we also did some experiments to see how the data argumentation impact the overall performance.",
                    "label": 0
                },
                {
                    "sent": "Also of our of our approach.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Power system these are the experiments.",
                    "label": 0
                },
                {
                    "sent": "Here we are using the volume for the 2014 and plan 2015 data set several experiments only using Google, Google Maps, Google Maps, model train from scratch using the plant 2014 data.",
                    "label": 0
                },
                {
                    "sent": "Set up your Google Maps only on the image net, not fine tuned on the plan data set Google Net on Image net and.",
                    "label": 0
                },
                {
                    "sent": "Fine Tune complaint 2014 Google Net retrain from image net.",
                    "label": 0
                },
                {
                    "sent": "Fine tuned with the difference.",
                    "label": 0
                },
                {
                    "sent": "Expand Expanded datasets using them, augmentation methods, and in the last the last experiment, experiment with using the Google Net.",
                    "label": 0
                },
                {
                    "sent": "Jeanette, but fine tunes on the plants 2015.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Sets the results as I as well as to be expected.",
                    "label": 0
                },
                {
                    "sent": "If you're using your Google Maps.",
                    "label": 0
                },
                {
                    "sent": "Not fine tuned on the planet data set we are obtaining.",
                    "label": 0
                },
                {
                    "sent": "Very low.",
                    "label": 0
                },
                {
                    "sent": "Move accuracy very little.",
                    "label": 0
                },
                {
                    "sent": "Very bit resolve.",
                    "label": 0
                },
                {
                    "sent": "These are the results if we're using.",
                    "label": 0
                },
                {
                    "sent": "If you are using convolutional neural network training from scratch using only the plant 2014 data set, the results are between 18%.",
                    "label": 0
                },
                {
                    "sent": "This is the Google net trained on image net training.",
                    "label": 0
                },
                {
                    "sent": "Retraining can image net and fine tune with the images from.",
                    "label": 0
                },
                {
                    "sent": "Left 2014 you can see that boost in measure.",
                    "label": 0
                },
                {
                    "sent": "Others.",
                    "label": 0
                },
                {
                    "sent": "The first images only take into account.",
                    "label": 0
                },
                {
                    "sent": "If we if we have the correct label for the first image, so we are.",
                    "label": 0
                },
                {
                    "sent": "You're a prisoner papers.",
                    "label": 0
                },
                {
                    "sent": "Google net on the image net pre training and plan 2014.",
                    "label": 0
                },
                {
                    "sent": "See the boosting the performance compared to the Google net trained from scratch from this data set.",
                    "label": 0
                },
                {
                    "sent": "If we compare the performance of the augmented data set set, we can see that if we augmented the data set then we obtain further improvement of the performance compared to the original original data set.",
                    "label": 0
                },
                {
                    "sent": "If we use them.",
                    "label": 0
                },
                {
                    "sent": "Planet 2015 data set.",
                    "label": 0
                },
                {
                    "sent": "We are obtaining.",
                    "label": 0
                },
                {
                    "sent": "We are the difference between the.",
                    "label": 0
                },
                {
                    "sent": "Then 2014 and plan 2015 is that the plan 2015 has 1000 classes and the plan 2014 has 500 classes.",
                    "label": 0
                },
                {
                    "sent": "So this data set is actually bigger than this data set.",
                    "label": 0
                },
                {
                    "sent": "We are training on the we are training the fine tuning the network on the these data set, but we are testing on on the plans 2014.",
                    "label": 0
                },
                {
                    "sent": "I wanted to ask so if you have 500,000 plus is so accuracy 45% is quite good.",
                    "label": 0
                },
                {
                    "sent": "Would you check?",
                    "label": 0
                },
                {
                    "sent": "So, did you try measuring the accuracy in North or identifying each individual species, but instead seeing if the genus is correct?",
                    "label": 0
                },
                {
                    "sent": "No, we have not taken into account here here that economy upgrade.",
                    "label": 0
                },
                {
                    "sent": "You're only interested in the in the lower.",
                    "label": 0
                },
                {
                    "sent": "Yes, people will do that as well.",
                    "label": 0
                },
                {
                    "sent": "It might look much, much better perhaps.",
                    "label": 0
                },
                {
                    "sent": "Actually, we we we are planning this for the framework we are.",
                    "label": 0
                },
                {
                    "sent": "We are somehow trying to incorporate the hierarchy of the taxonomy into the learning process.",
                    "label": 0
                },
                {
                    "sent": "Some color, but we haven't done that yet.",
                    "label": 0
                },
                {
                    "sent": "We are planning to do that.",
                    "label": 0
                },
                {
                    "sent": "Football.",
                    "label": 0
                },
                {
                    "sent": "When you say you're fine tuning Imagenet, you mean that you're throwing away the last layer.",
                    "label": 0
                },
                {
                    "sent": "Keeping the weights from Imagemaps very trainable.",
                    "label": 0
                },
                {
                    "sent": "So have you tested how much though?",
                    "label": 0
                },
                {
                    "sent": "The weights of the lower level are actually changing overnight.",
                    "label": 0
                },
                {
                    "sent": "Or is it just that you're just living a different classifier on the representation of engagement?",
                    "label": 0
                },
                {
                    "sent": "And what happens if you run like?",
                    "label": 0
                },
                {
                    "sent": "Ask about the machine on the on the representation information.",
                    "label": 0
                },
                {
                    "sent": "If we run without, you know.",
                    "label": 0
                },
                {
                    "sent": "Doing backpropagation and we have done that, but the results are worse, much worse.",
                    "label": 0
                },
                {
                    "sent": "Maybe by I don't know.",
                    "label": 0
                },
                {
                    "sent": "I don't know the exact number, so I think by 50% or maybe worse, OK?",
                    "label": 0
                },
                {
                    "sent": "That's why we decided to use this new setup.",
                    "label": 0
                },
                {
                    "sent": "The results were similar with the the other approaches that I mentioned before.",
                    "label": 0
                },
                {
                    "sent": "The linear SVM station.",
                    "label": 0
                },
                {
                    "sent": "The whole message is the Fisher vector from here, sorry.",
                    "label": 0
                },
                {
                    "sent": "You're not deep learning.",
                    "label": 0
                },
                {
                    "sent": "It was interesting in the 2014 competition.",
                    "label": 0
                },
                {
                    "sent": "The Fisher vector encoding using linear SVM's was the best ranked.",
                    "label": 0
                },
                {
                    "sent": "A result if us around 50% I think in the final scoring and the same team applied also deep learning deep learning the results from different learning more about 20 or so percent so.",
                    "label": 0
                },
                {
                    "sent": "But in the next year most of the team started using only deep learning.",
                    "label": 0
                },
                {
                    "sent": "Come, the results increased quite for this year.",
                    "label": 0
                },
                {
                    "sent": "The best result is.",
                    "label": 0
                },
                {
                    "sent": "80%.",
                    "label": 0
                },
                {
                    "sent": "Quiting increase compared to the previous years.",
                    "label": 0
                },
                {
                    "sent": "We participated in.",
                    "label": 0
                },
                {
                    "sent": "Attempt 2014 and we did not manage to submit the results for 2015, but if we have submitted we would view rank type thing.",
                    "label": 0
                },
                {
                    "sent": "Second transfer.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is the learning curve.",
                    "label": 0
                },
                {
                    "sent": "Increase of accuracy and the increase of the loss during the training process and want to get into details.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Here it was interesting as I mentioned, for the planet left 2016.",
                    "label": 0
                },
                {
                    "sent": "The organizers of this competition includes unknown classes.",
                    "label": 0
                },
                {
                    "sent": "You just normal classes and normal plant images in the test data set.",
                    "label": 0
                },
                {
                    "sent": "So for this particular competition we have to somehow.",
                    "label": 0
                },
                {
                    "sent": "First, separately Finetune Googlenet model for a binary classification problem.",
                    "label": 1
                },
                {
                    "sent": "For example plan versus non plant images.",
                    "label": 0
                },
                {
                    "sent": "For this set up the training data data set contains plant images from life 2015 unknown plant images for the floor scale competition and using the results for results from the binary classifier, we can reject the images that are.",
                    "label": 1
                },
                {
                    "sent": "Classifier classify does not make images.",
                    "label": 0
                },
                {
                    "sent": "Unassign a low confidence storing data in the final main plant signification unification system.",
                    "label": 0
                },
                {
                    "sent": "So first we are training.",
                    "label": 0
                },
                {
                    "sent": "A binary classifier, but can distinguish two classes, plant versus non plants.",
                    "label": 0
                },
                {
                    "sent": "Then we are using the same setup as previous but we are decreasing the probabilities were signed both in store for this images that are classified classified as non plant images in them.",
                    "label": 0
                },
                {
                    "sent": "In the final.",
                    "label": 0
                },
                {
                    "sent": "In the final result.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "It is interesting here that the degree of novelty in the test set is a strong influence on the performance.",
                    "label": 1
                },
                {
                    "sent": "For example, in this year, blank left 2016 competition when 25% of the various still belong to a known class.",
                    "label": 0
                },
                {
                    "sent": "None of the system region mean average precision greater and greater than.",
                    "label": 0
                },
                {
                    "sent": "C Zero point 45 compared to the zero point 83 in the closed world world.",
                    "label": 0
                },
                {
                    "sent": "Set up where the classes in the training images are from the.",
                    "label": 0
                },
                {
                    "sent": "You may just be the test data set.",
                    "label": 0
                },
                {
                    "sent": "Test data set are.",
                    "label": 0
                },
                {
                    "sent": "With the classes from the training data set, so this is quite quite a problem in a real case scenario this number is much lower because if the user has the mobile phone and it goes and.",
                    "label": 0
                },
                {
                    "sent": "Take take picture of everything and submitted the queries.",
                    "label": 0
                },
                {
                    "sent": "The number, the number of of this number will be will be much lower, so the performance is is can be decorated even even more so this is this is quite a quite a problem that have to be solved, solved in the plans magnification task.",
                    "label": 0
                },
                {
                    "sent": "Additional.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Problems that we have here is that the original net model requires input image of facial size 124 by 224.",
                    "label": 1
                },
                {
                    "sent": "The images in the planet left versions are arbitrarily sized so.",
                    "label": 1
                },
                {
                    "sent": "Following the special size restriction in Google Maps model, the input images gets to be either copper or lead to information loss there is.",
                    "label": 1
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Solution for this problem?",
                    "label": 0
                },
                {
                    "sent": "We can try this, yet we can use spatial spatial pyramid pooling layer.",
                    "label": 1
                },
                {
                    "sent": "The feature we can divide a feature map spatially 1 by 1 two by 4 by 4 in total.",
                    "label": 0
                },
                {
                    "sent": "If anyone region then each region can be average pulled producing a vector of pick sides.",
                    "label": 0
                },
                {
                    "sent": "For example, if we have 5050 generals in the last convolutional layer, you're paying a vector of fixed size 1010 thousand 77155.",
                    "label": 1
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "55 scalars in the vector.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "This conversion of arbitrary size feature mapping to the into a fixed size vector or allow the model to accept input image obtaining size.",
                    "label": 1
                },
                {
                    "sent": "We can skip that step when we are processing the images in the fixed.",
                    "label": 0
                },
                {
                    "sent": "Sized OK.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Make some conclusions and further work.",
                    "label": 1
                },
                {
                    "sent": "Mushel neural networks.",
                    "label": 0
                },
                {
                    "sent": "Three training on large datasets set and fine tuned on towamencin datasets to the specific domain to get the best way to get the best results is is our recommendation, but the convolutional neural network is strongly affected by the higher rates of images belonging to unknown class, so we have to find the solution for this.",
                    "label": 1
                },
                {
                    "sent": "We are as a further work we are.",
                    "label": 0
                },
                {
                    "sent": "We will definitely try different.",
                    "label": 1
                },
                {
                    "sent": "Set up self convolutional neural networks.",
                    "label": 0
                },
                {
                    "sent": "Somehow we can create an example of convolutional neural network networks with different set up with different convolutional layer and so on and then we can combine the tradition to increase the classification performance.",
                    "label": 0
                },
                {
                    "sent": "We are also planning to somehow combine the handcrafted features into the feature features obtained into the convolutional neural networks.",
                    "label": 0
                },
                {
                    "sent": "We are we have done another application similar to this but in that application we had only lift images and it was quite interesting.",
                    "label": 0
                },
                {
                    "sent": "The results were quite interesting.",
                    "label": 0
                },
                {
                    "sent": "Some of the classes that are very that were very difficult to be distinguished even looking by I from North by some expert were correctly classified by the convolutional neural network and some of the images that were quite distinct.",
                    "label": 0
                },
                {
                    "sent": "Were wrongly classified by the Convolutional neural network.",
                    "label": 0
                },
                {
                    "sent": "In this case, if we have applied standard conventional methods.",
                    "label": 0
                },
                {
                    "sent": "Feature extraction methods.",
                    "label": 0
                },
                {
                    "sent": "Location methods them.",
                    "label": 0
                },
                {
                    "sent": "These images would be correct in the classifier, so we can somehow combine with interactive features and convolutional neural networking in order to eliminate these problems.",
                    "label": 0
                },
                {
                    "sent": "Also we are.",
                    "label": 0
                },
                {
                    "sent": "We can also try to use them higher here of the taxonomy into in the convolutional neural networks too.",
                    "label": 0
                },
                {
                    "sent": "Do something to somehow boost the overall performance of.",
                    "label": 0
                },
                {
                    "sent": "Of this approach.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Let's see.",
                    "label": 0
                }
            ]
        }
    }
}