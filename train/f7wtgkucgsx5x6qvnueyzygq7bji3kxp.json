{
    "id": "f7wtgkucgsx5x6qvnueyzygq7bji3kxp",
    "title": "Hybrid Generative-Discriminative Nucleus Classification of Renal Cell Carcinoma",
    "info": {
        "author": [
            "Ayd\u0131n Ula\u015f, Department of Computer Science, University of Verona"
        ],
        "published": "Oct. 17, 2011",
        "recorded": "September 2011",
        "category": [
            "Top->Computer Science->Bioinformatics",
            "Top->Computer Science->Machine Learning"
        ]
    },
    "url": "http://videolectures.net/simbad2011_ulas_carcinoma/",
    "segmentation": [
        [
            "I'm going to present with generative discriminative Nicholas classification of renal cell carcinoma.",
            "This a joint paper with Etoh, Zuri, and this data is one of the benchmark data sets of the symbol project so."
        ],
        [
            "I will start with the problem and the data set.",
            "I will continually do probabilistic latent semantic analysis, which is the generative model we applied on this problem, and I'm going to go ahead with methodology and results and finish with discussion and future work."
        ],
        [
            "For the salad.",
            "Very common human sense.",
            "Cancer and the cancer cells are known to divide uncontrollably so they they divide iron control and in this specific type of cancer there are four stages of the Council which are known from stage one to stage four.",
            "It's important to identify these stages because they correspond to different kind of therapies, treatments ranging from medical treatments to surgery."
        ],
        [
            "For the staging, the grading of different protein expression levels might be relevant.",
            "Might be used to us.",
            "So for example, mid one is one of those protein proteins which.",
            "Great the salad.",
            "Divide so when the cancer is more severe, the cells divide more and this protein helps us to identify cells which are dividing more.",
            "So what?",
            "Doctors or what is we try to find is to find this magic proteins which will help us detect these stages of cancer for treatment and our aim is to automate this process."
        ],
        [
            "So here are some examples of meabon grading.",
            "So on the left on top is high grade and left on the bottom is zero.",
            "Greater than medium grade and low grade.",
            "So the cells which are dividing are which are graded by myvar shown in.",
            "From and the other cells are shown with blue."
        ],
        [
            "So the grade is actually the number of Romney clues among all the cancer cells.",
            "Human breeding is also possible, but usually not feasable 'cause it's very time consuming.",
            "It is difficult and it's very subjective and humans of course prefer the words fuzzy words such as no low, medium, high, etc.",
            "So they don't give numbers, they prefer fuzzy words and many ratings on the Microsoft is also inconsistent cause it changes from Doctor to Doctor.",
            "We are going to see.",
            "When we introduced the data set."
        ],
        [
            "So in that email analysis pipeline.",
            "But here is the selective detection.",
            "The segmentation and classification in this talk.",
            "We are going to talk about the classification part we have.",
            "They already segmented nuclei in terms of patches, and they exert some features and then we do the classification using PSA."
        ],
        [
            "So I cannot see the top left button so that you are extracted by two portages.",
            "We have ATM images from 8 pages and in total there are 1600 patches.",
            "Of those we use that rifles.",
            "So the three pictures which two pathologists agree on the label, so there are almost 25% where the percentages actually don't take free on the label of those pictures speak normal.",
            "Then we use only the patches which the two pathologists agree on the labels."
        ],
        [
            "The new segmentation is done by graph cut so.",
            "Round shapes are favored.",
            "So this is how the segmentation is done.",
            "I will skip these parts."
        ],
        [
            "From mobile pages spacetrack some histograms features which are background intensity, foreground intensity for features and some region properties etc.",
            "So we have a different feature types all in histogram representation.",
            "And we are trying to come up with a good classification accuracy to detect if the sale is cancelled."
        ],
        [
            "Or not.",
            "So the methodology we apply is probabilistic latent semantic."
        ],
        [
            "Notice we had a sale, which is a topic model.",
            "A topic model is widely used in text analysis, so the idea is you are given a set of words and you are given documents containing words and there is a latent variable which is shown as Z in the picture which represents the topics.",
            "So what you're given is a document containing words and what you say is there is a.",
            "He then went over there, which is the topic shown by an."
        ],
        [
            "Can you text analysis?",
            "This corresponds to the back of an extension of the bag of words approach, so we are given a document and we are not interested in the position, but the number of occurrences offers.",
            "So we have the histograms, so the comments are characterized by verbal curious as you see on the right."
        ],
        [
            "So as an example, different words in different contexts, maybe something else.",
            "For example Windows when you're talking about computers means something you are talking about the house.",
            "It needs something else.",
            "Four Seasons like that with weather and sports.",
            "Also with computer shows.",
            "So sorry, television shows.",
            "And when you're talking about space they all mean something else in the context.",
            "So this context is the latent variable in our representation.",
            "That's what we are trying to model."
        ],
        [
            "So.",
            "The words which we talked about in the previous slide they can be disaggregated by looking at the context, which is the topic which is the concept of topic.",
            "That's what we are talking about and every document this way is characterized by the presence of one of more topics.",
            "In this analogy, anything with the account.",
            "So any histogram can actually be used in this sense as the count of words in a document, and then we can apply for the sale."
        ],
        [
            "To find or to find the distribution of that.",
            "So what we're doing is a matrix of is accounting metrics, number of occurrences of word W in the document T, which is in our case is going to be the histograms, the frequencies of the histogram bins and the LSA permits us to decompose the probability through the topics distributions."
        ],
        [
            "So in the space we are the only observed word distributions are given with WMD, and then what the training step does is to estimate PW, Givens, NP, set given WPZQW is what we are going to use as a new space.",
            "So what we're going to do in this?",
            "In this example, in this classification cases, use P. Then given WS as vectors.",
            "So what we have done is to protect our data into a new vector space.",
            "Then we're going to apply classical classification algorithms and we will see that we have."
        ],
        [
            "Better accuracies."
        ],
        [
            "So methodology, so we consider the frequencies as dark counts in a document.",
            "We then apply the PSA to train and find P that given D and then on this new space we apply the classification algorithms.",
            "So that's the whole point."
        ],
        [
            "As for this work, we use only at three patient subset of the mentioned data set, and we use Temple Stratified Cross validation.",
            "We have eight different representations.",
            "In this case we didn't try to combine the representation, so I'm going to give only single classifier results and the number of topics which is one of the crucial points to estimate is chosen by cross validation and then.",
            "We are going to compare our results using the original feature space."
        ],
        [
            "We have applied 3 support vector machine classifiers based classifiers with linear kernel polynomial kernel with degree two and a radial basis function kernel and we applied for other classification algorithms, linear discriminant classifier, quadratic discriminant classifier K nearest neighbor and the decision tree.",
            "All of these were implemented using PR tools."
        ],
        [
            "So coming to the results.",
            "On the right or the radial basis function resource which is against our proposal.",
            "But we see that on the original space, support vectors with radial basis functions are usually better than the space on the PSA.",
            "But they may consider support vector machines with linear kernel and with the polynomial can we get almost always better results to increase with bowl which cannot be seeing clearly have statistically significantly more accurate results than its corresponding version using T tests?",
            "So thankful.",
            "T test at Alpha 0.05.",
            "So what we can see is almost always except for the support vector machine trendell basis functions.",
            "The new space created by the topic distribution is has better accuracy what we have."
        ],
        [
            "Is transformed our problem into a new space.",
            "Value can be separated easily or easier.",
            "And these others or other classifiers.",
            "Again here, except decision trees, most of the time we have the PSA version greater than the original space accuracies, the ones with the star values shoulder most accurate accuracy using that kind of classifier.",
            "So."
        ],
        [
            "Is a discussion and conclusions what we propose this to use the generative abilities of PSA to project our data in a new space.",
            "So what we have done is we didn't use regenerative.",
            "Abilities of Parasite to classify, but we use the hybrid, generative, discriminative approach.",
            "We use the generative PSA to transpose or transform our problem into a new space, and in this space we use the discriminative classifiers to come up with better accuracies and this is the idea comes from natural language processing, which works really well also for some shape recognition and computer vision tasks, and except for some specific cases.",
            "We have seen with radial basis functions and this is in trees.",
            "The new space has better classification accuracy and the best results are obtained on this new space."
        ],
        [
            "Is it future work?",
            "So here we have used the all of the PSA is features in a new vector space.",
            "What we can do is so the outputs are actually provided and functions we can directly apply kernels on this new space.",
            "Or we can use other score spaces.",
            "So an example is coming in pre 2011 where we applied the ETT can information, theoretical kernels or careless.",
            "Best generative score spaces."
        ],
        [
            "So.",
            "My clothes for me, thanks in part project for the financial support we used implementation of Doktorlar Bake for PSA unused portals for the implementation of the classification or teams."
        ],
        [
            "Stay out of my talk, thank.",
            "So I mean, have you considered any alternatives to PNS, aka?",
            "Case actually we have the LDA, the latent triplet Trish let allocation, which is in theory, which is a better version of that version, but which is a better generative model than PSA is better generalization power?",
            "And in parallel, so you have to estimate the number of topics.",
            "It assumes a delicate dish net.",
            "Prior in this case we have applied and in our preliminary experience experiments we have seen that the accuracies did not have too many differences.",
            "So in the end we just used PSA.",
            "So in theory, LDA is known to be better than PSA, but in practice in our experiments they were almost the same.",
            "Also the problem with PSA is the estimating the number of toppings, which can also be.",
            "Use we can also apply the information theoretic measures like DIC or AIC so that we can come up with an automatic way of estimating the number of topics, which reduces one problem with PSA.",
            "Your experience is difference that you to design over.",
            "A new algorithm outperformed both.",
            "Not yet.",
            "So any questions?",
            "Home.",
            "So.",
            "OK, so that's a good question in this kind.",
            "In this study we did not.",
            "We in our previous study, not mine, but in our groups it was the.",
            "Analysis of genes and topics meant something to the doctors.",
            "In this case, we didn't really try to interpret the results, but we can.",
            "For now we don't have any idea.",
            "And since the number of topics are estimated by using cross validation, I actually don't know the number of topics for any of those.",
            "But yeah, that's a good question and I think we should discuss this with the medical doctors.",
            "If they mean something or not.",
            "But the good what the advantage of piracy is to be interpreted to interpret results.",
            "For this case, we didn't do that."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I'm going to present with generative discriminative Nicholas classification of renal cell carcinoma.",
                    "label": 0
                },
                {
                    "sent": "This a joint paper with Etoh, Zuri, and this data is one of the benchmark data sets of the symbol project so.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I will start with the problem and the data set.",
                    "label": 0
                },
                {
                    "sent": "I will continually do probabilistic latent semantic analysis, which is the generative model we applied on this problem, and I'm going to go ahead with methodology and results and finish with discussion and future work.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "For the salad.",
                    "label": 0
                },
                {
                    "sent": "Very common human sense.",
                    "label": 0
                },
                {
                    "sent": "Cancer and the cancer cells are known to divide uncontrollably so they they divide iron control and in this specific type of cancer there are four stages of the Council which are known from stage one to stage four.",
                    "label": 1
                },
                {
                    "sent": "It's important to identify these stages because they correspond to different kind of therapies, treatments ranging from medical treatments to surgery.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "For the staging, the grading of different protein expression levels might be relevant.",
                    "label": 1
                },
                {
                    "sent": "Might be used to us.",
                    "label": 0
                },
                {
                    "sent": "So for example, mid one is one of those protein proteins which.",
                    "label": 0
                },
                {
                    "sent": "Great the salad.",
                    "label": 0
                },
                {
                    "sent": "Divide so when the cancer is more severe, the cells divide more and this protein helps us to identify cells which are dividing more.",
                    "label": 0
                },
                {
                    "sent": "So what?",
                    "label": 0
                },
                {
                    "sent": "Doctors or what is we try to find is to find this magic proteins which will help us detect these stages of cancer for treatment and our aim is to automate this process.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So here are some examples of meabon grading.",
                    "label": 1
                },
                {
                    "sent": "So on the left on top is high grade and left on the bottom is zero.",
                    "label": 0
                },
                {
                    "sent": "Greater than medium grade and low grade.",
                    "label": 1
                },
                {
                    "sent": "So the cells which are dividing are which are graded by myvar shown in.",
                    "label": 0
                },
                {
                    "sent": "From and the other cells are shown with blue.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the grade is actually the number of Romney clues among all the cancer cells.",
                    "label": 0
                },
                {
                    "sent": "Human breeding is also possible, but usually not feasable 'cause it's very time consuming.",
                    "label": 1
                },
                {
                    "sent": "It is difficult and it's very subjective and humans of course prefer the words fuzzy words such as no low, medium, high, etc.",
                    "label": 1
                },
                {
                    "sent": "So they don't give numbers, they prefer fuzzy words and many ratings on the Microsoft is also inconsistent cause it changes from Doctor to Doctor.",
                    "label": 0
                },
                {
                    "sent": "We are going to see.",
                    "label": 0
                },
                {
                    "sent": "When we introduced the data set.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So in that email analysis pipeline.",
                    "label": 1
                },
                {
                    "sent": "But here is the selective detection.",
                    "label": 0
                },
                {
                    "sent": "The segmentation and classification in this talk.",
                    "label": 0
                },
                {
                    "sent": "We are going to talk about the classification part we have.",
                    "label": 0
                },
                {
                    "sent": "They already segmented nuclei in terms of patches, and they exert some features and then we do the classification using PSA.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So I cannot see the top left button so that you are extracted by two portages.",
                    "label": 1
                },
                {
                    "sent": "We have ATM images from 8 pages and in total there are 1600 patches.",
                    "label": 1
                },
                {
                    "sent": "Of those we use that rifles.",
                    "label": 0
                },
                {
                    "sent": "So the three pictures which two pathologists agree on the label, so there are almost 25% where the percentages actually don't take free on the label of those pictures speak normal.",
                    "label": 1
                },
                {
                    "sent": "Then we use only the patches which the two pathologists agree on the labels.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The new segmentation is done by graph cut so.",
                    "label": 1
                },
                {
                    "sent": "Round shapes are favored.",
                    "label": 0
                },
                {
                    "sent": "So this is how the segmentation is done.",
                    "label": 0
                },
                {
                    "sent": "I will skip these parts.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "From mobile pages spacetrack some histograms features which are background intensity, foreground intensity for features and some region properties etc.",
                    "label": 0
                },
                {
                    "sent": "So we have a different feature types all in histogram representation.",
                    "label": 0
                },
                {
                    "sent": "And we are trying to come up with a good classification accuracy to detect if the sale is cancelled.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Or not.",
                    "label": 0
                },
                {
                    "sent": "So the methodology we apply is probabilistic latent semantic.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Notice we had a sale, which is a topic model.",
                    "label": 0
                },
                {
                    "sent": "A topic model is widely used in text analysis, so the idea is you are given a set of words and you are given documents containing words and there is a latent variable which is shown as Z in the picture which represents the topics.",
                    "label": 1
                },
                {
                    "sent": "So what you're given is a document containing words and what you say is there is a.",
                    "label": 0
                },
                {
                    "sent": "He then went over there, which is the topic shown by an.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Can you text analysis?",
                    "label": 0
                },
                {
                    "sent": "This corresponds to the back of an extension of the bag of words approach, so we are given a document and we are not interested in the position, but the number of occurrences offers.",
                    "label": 1
                },
                {
                    "sent": "So we have the histograms, so the comments are characterized by verbal curious as you see on the right.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So as an example, different words in different contexts, maybe something else.",
                    "label": 0
                },
                {
                    "sent": "For example Windows when you're talking about computers means something you are talking about the house.",
                    "label": 0
                },
                {
                    "sent": "It needs something else.",
                    "label": 0
                },
                {
                    "sent": "Four Seasons like that with weather and sports.",
                    "label": 0
                },
                {
                    "sent": "Also with computer shows.",
                    "label": 0
                },
                {
                    "sent": "So sorry, television shows.",
                    "label": 0
                },
                {
                    "sent": "And when you're talking about space they all mean something else in the context.",
                    "label": 0
                },
                {
                    "sent": "So this context is the latent variable in our representation.",
                    "label": 0
                },
                {
                    "sent": "That's what we are trying to model.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "The words which we talked about in the previous slide they can be disaggregated by looking at the context, which is the topic which is the concept of topic.",
                    "label": 1
                },
                {
                    "sent": "That's what we are talking about and every document this way is characterized by the presence of one of more topics.",
                    "label": 1
                },
                {
                    "sent": "In this analogy, anything with the account.",
                    "label": 0
                },
                {
                    "sent": "So any histogram can actually be used in this sense as the count of words in a document, and then we can apply for the sale.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To find or to find the distribution of that.",
                    "label": 0
                },
                {
                    "sent": "So what we're doing is a matrix of is accounting metrics, number of occurrences of word W in the document T, which is in our case is going to be the histograms, the frequencies of the histogram bins and the LSA permits us to decompose the probability through the topics distributions.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So in the space we are the only observed word distributions are given with WMD, and then what the training step does is to estimate PW, Givens, NP, set given WPZQW is what we are going to use as a new space.",
                    "label": 1
                },
                {
                    "sent": "So what we're going to do in this?",
                    "label": 0
                },
                {
                    "sent": "In this example, in this classification cases, use P. Then given WS as vectors.",
                    "label": 0
                },
                {
                    "sent": "So what we have done is to protect our data into a new vector space.",
                    "label": 0
                },
                {
                    "sent": "Then we're going to apply classical classification algorithms and we will see that we have.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Better accuracies.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So methodology, so we consider the frequencies as dark counts in a document.",
                    "label": 1
                },
                {
                    "sent": "We then apply the PSA to train and find P that given D and then on this new space we apply the classification algorithms.",
                    "label": 0
                },
                {
                    "sent": "So that's the whole point.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "As for this work, we use only at three patient subset of the mentioned data set, and we use Temple Stratified Cross validation.",
                    "label": 0
                },
                {
                    "sent": "We have eight different representations.",
                    "label": 0
                },
                {
                    "sent": "In this case we didn't try to combine the representation, so I'm going to give only single classifier results and the number of topics which is one of the crucial points to estimate is chosen by cross validation and then.",
                    "label": 0
                },
                {
                    "sent": "We are going to compare our results using the original feature space.",
                    "label": 1
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We have applied 3 support vector machine classifiers based classifiers with linear kernel polynomial kernel with degree two and a radial basis function kernel and we applied for other classification algorithms, linear discriminant classifier, quadratic discriminant classifier K nearest neighbor and the decision tree.",
                    "label": 0
                },
                {
                    "sent": "All of these were implemented using PR tools.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So coming to the results.",
                    "label": 0
                },
                {
                    "sent": "On the right or the radial basis function resource which is against our proposal.",
                    "label": 0
                },
                {
                    "sent": "But we see that on the original space, support vectors with radial basis functions are usually better than the space on the PSA.",
                    "label": 0
                },
                {
                    "sent": "But they may consider support vector machines with linear kernel and with the polynomial can we get almost always better results to increase with bowl which cannot be seeing clearly have statistically significantly more accurate results than its corresponding version using T tests?",
                    "label": 0
                },
                {
                    "sent": "So thankful.",
                    "label": 0
                },
                {
                    "sent": "T test at Alpha 0.05.",
                    "label": 0
                },
                {
                    "sent": "So what we can see is almost always except for the support vector machine trendell basis functions.",
                    "label": 0
                },
                {
                    "sent": "The new space created by the topic distribution is has better accuracy what we have.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is transformed our problem into a new space.",
                    "label": 0
                },
                {
                    "sent": "Value can be separated easily or easier.",
                    "label": 0
                },
                {
                    "sent": "And these others or other classifiers.",
                    "label": 0
                },
                {
                    "sent": "Again here, except decision trees, most of the time we have the PSA version greater than the original space accuracies, the ones with the star values shoulder most accurate accuracy using that kind of classifier.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Is a discussion and conclusions what we propose this to use the generative abilities of PSA to project our data in a new space.",
                    "label": 1
                },
                {
                    "sent": "So what we have done is we didn't use regenerative.",
                    "label": 0
                },
                {
                    "sent": "Abilities of Parasite to classify, but we use the hybrid, generative, discriminative approach.",
                    "label": 0
                },
                {
                    "sent": "We use the generative PSA to transpose or transform our problem into a new space, and in this space we use the discriminative classifiers to come up with better accuracies and this is the idea comes from natural language processing, which works really well also for some shape recognition and computer vision tasks, and except for some specific cases.",
                    "label": 0
                },
                {
                    "sent": "We have seen with radial basis functions and this is in trees.",
                    "label": 1
                },
                {
                    "sent": "The new space has better classification accuracy and the best results are obtained on this new space.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Is it future work?",
                    "label": 0
                },
                {
                    "sent": "So here we have used the all of the PSA is features in a new vector space.",
                    "label": 0
                },
                {
                    "sent": "What we can do is so the outputs are actually provided and functions we can directly apply kernels on this new space.",
                    "label": 0
                },
                {
                    "sent": "Or we can use other score spaces.",
                    "label": 1
                },
                {
                    "sent": "So an example is coming in pre 2011 where we applied the ETT can information, theoretical kernels or careless.",
                    "label": 0
                },
                {
                    "sent": "Best generative score spaces.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "My clothes for me, thanks in part project for the financial support we used implementation of Doktorlar Bake for PSA unused portals for the implementation of the classification or teams.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Stay out of my talk, thank.",
                    "label": 0
                },
                {
                    "sent": "So I mean, have you considered any alternatives to PNS, aka?",
                    "label": 0
                },
                {
                    "sent": "Case actually we have the LDA, the latent triplet Trish let allocation, which is in theory, which is a better version of that version, but which is a better generative model than PSA is better generalization power?",
                    "label": 0
                },
                {
                    "sent": "And in parallel, so you have to estimate the number of topics.",
                    "label": 0
                },
                {
                    "sent": "It assumes a delicate dish net.",
                    "label": 0
                },
                {
                    "sent": "Prior in this case we have applied and in our preliminary experience experiments we have seen that the accuracies did not have too many differences.",
                    "label": 0
                },
                {
                    "sent": "So in the end we just used PSA.",
                    "label": 0
                },
                {
                    "sent": "So in theory, LDA is known to be better than PSA, but in practice in our experiments they were almost the same.",
                    "label": 0
                },
                {
                    "sent": "Also the problem with PSA is the estimating the number of toppings, which can also be.",
                    "label": 0
                },
                {
                    "sent": "Use we can also apply the information theoretic measures like DIC or AIC so that we can come up with an automatic way of estimating the number of topics, which reduces one problem with PSA.",
                    "label": 0
                },
                {
                    "sent": "Your experience is difference that you to design over.",
                    "label": 0
                },
                {
                    "sent": "A new algorithm outperformed both.",
                    "label": 0
                },
                {
                    "sent": "Not yet.",
                    "label": 0
                },
                {
                    "sent": "So any questions?",
                    "label": 0
                },
                {
                    "sent": "Home.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "OK, so that's a good question in this kind.",
                    "label": 0
                },
                {
                    "sent": "In this study we did not.",
                    "label": 0
                },
                {
                    "sent": "We in our previous study, not mine, but in our groups it was the.",
                    "label": 0
                },
                {
                    "sent": "Analysis of genes and topics meant something to the doctors.",
                    "label": 0
                },
                {
                    "sent": "In this case, we didn't really try to interpret the results, but we can.",
                    "label": 0
                },
                {
                    "sent": "For now we don't have any idea.",
                    "label": 0
                },
                {
                    "sent": "And since the number of topics are estimated by using cross validation, I actually don't know the number of topics for any of those.",
                    "label": 0
                },
                {
                    "sent": "But yeah, that's a good question and I think we should discuss this with the medical doctors.",
                    "label": 0
                },
                {
                    "sent": "If they mean something or not.",
                    "label": 0
                },
                {
                    "sent": "But the good what the advantage of piracy is to be interpreted to interpret results.",
                    "label": 0
                },
                {
                    "sent": "For this case, we didn't do that.",
                    "label": 0
                }
            ]
        }
    }
}