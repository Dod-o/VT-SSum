{
    "id": "yzsbrvcgk4netxv5twm35ju2ludv7is5",
    "title": "Linked Data-based Concept Recommendation: Comparison of Different Methods in Open Innovation Scenario",
    "info": {
        "author": [
            "Danica Damljanovi\u0107, Department of Molecular Biology and Biotechnology, University of Sheffield"
        ],
        "published": "July 4, 2012",
        "recorded": "May 2012",
        "category": [
            "Top->Computer Science->Web Search",
            "Top->Computer Science->Semantic Computing"
        ]
    },
    "url": "http://videolectures.net/eswc2012_damljanovic_innovation/",
    "segmentation": [
        [
            "So thanks for introduction.",
            "So this can you hear me?",
            "So I will talk about different methods for constant recommendation and the use case we choose is the innovation.",
            "So in fact open innovation scenario and."
        ],
        [
            "Why do we choose this?",
            "Well, innovation is very important in any company which wants to survive the competition.",
            "So usually these companies have research and development labs which too valuable research and then provide the innovative solutions and so on.",
            "But often that is not really enough and what they do is they search for some kind of a negative solutions outside to the companies who do what is called nowadays.",
            "Open innovation and.",
            "Companies such as Hypers.",
            "Build platforms for open innovation and what they basically do is."
        ],
        [
            "On the left hand side we have the those companies who basically have the problems and they want to find people.",
            "The experts who can solve these problems.",
            "So what they do is they just give these problems to happy hours and then have yours.",
            "Points, or the role of this platform and happiness in general is defined to locate the experts who can actually be potentially good solvers of these problems.",
            "So now how to solve how this platform is actually developed and what's important so it's not really just that they they have a database of experts.",
            "It's also about trying to make a good match between the problems and those who could actually solve it.",
            "So as you can imagine, the information retrieval methods play a very important role because it's a lot about finding the right keywords, which one can use to actually locate this these experts.",
            "However, it is not a very basic information retrieval problem."
        ],
        [
            "And this is for various reasons.",
            "So one of the reasons is that different communities even use different vocabulary to basically express the same.",
            "The same thing, sort of semantically related things, and on the other hand even more important problem is that sometimes the wording of the problems problem descriptions doesn't really give enough specific details about actually people who could solve it.",
            "So for example.",
            "If the problem is talking about the claim mining, maybe a potentially good or not maybe, but for sure the question who has done something about Caroline's extraction from rocks could be potentially very good solver, but it is quite difficult to actually find this relation between these two concepts.",
            "So to solve this problem, we developed methods for concept, recommendation and."
        ],
        [
            "These these concepts are basically those that we would be useful to locate experts, but we might not be aware of them so.",
            "For example, usually in high pills or other companies similar companies there are people who who we called the problem promoters, so their job is basically based on the problem description to to use the Internet Google Blevel tools.",
            "They have to basically find the target ING Group or groups to come, then then need to send the problem so that then they can get some potential solution submissions for the.",
            "For solving these problems.",
            "So as you can imagine, this problem promoters cannot really be experts in all the fields that that are needed and one of the problems that actually tried to solve here is trying to automate or to help them.",
            "Maybe extend the list of already existing concepts that they have.",
            "So in that sense, what the concepts of how do we actually measure whether these concepts that we recommend our code or not?",
            "So it's not that they're just they are relevant to the problem, but it's also are they what we call unexpected.",
            "So that means if the problem promoter have never heard of the problem of the concept that you recommend, and the problem and that is relevant, then that's very good for us.",
            "So we call that discovery.",
            "So as I have mentioned, it's not."
        ],
        [
            "Only about words and finding contextually similar words or synonyms and so on.",
            "It's also about finding some natural concepts or concepts that maybe we wouldn't really know that there is a relation between them.",
            "And I will show later bits for example.",
            "So you can get the idea of what I mean.",
            "So the two methods that I'm going to talk about our high proximity, so that's the first one.",
            "It's structure based similarity, which means that it only explores the graph, so only export the link to inside this case to actually develop this.",
            "Metric and the other one is a well known method from information retrieval called random indexing.",
            "So the difference to what we are doing here is that we apply random indexing to RDF, so whereas usually it's it's applied to Suman readable text.",
            "So on a high level, how do we how do this?"
        ],
        [
            "Methods work, so we start with some textual input.",
            "This is the problem description for example, or the abstract.",
            "And from that we first extract the PDF viewer Roy San.",
            "For this we use amount us, so we could use any other services.",
            "And from this list or this list of GPU rris extracted from the problems is used as input to our methods and as output we produce a list of recommendations.",
            "So as on this slide you CDPD exploration, which is basically for this concrete presentation scenario, we really use DB pedia as a data set.",
            "And both methods that are not described basically used.",
            "Pizza is as a main source of information."
        ],
        [
            "So I will now briefly introduce you to high proximity, so both high proximity and Rhonda mixing as I as I mentioned, are used in some other scenarios.",
            "So for example, million will present one of them in the next talk, and random indexing has been used previously in the log project and in some others.",
            "So these are just some of the applications of these two methods.",
            "So high proximity as you can see on the bottom of this page is a problem description.",
            "So starts from problem descriptions from which we extract the red, red, red nodes and this graph is actually say part of DB pedia in this case.",
            "So it's support of some graph with the metrics operating the graph.",
            "And then what we're trying to do is we're trying to go from red to black, so I don't know if I I walked back.",
            "I just want to show something rough.",
            "Is this work?",
            "Does this work?",
            "OK, so so from from the red one you are she want to go to work towards the black ones which means something.",
            "So which represents something, for example experts or the research papers, patterns or or maybe companies who are doing some similar things.",
            "So usually you start from the seat concepts and then you walk through the graph to actually find those that that that are kind of related to this graph and the more seed concepts are related to the specific concept and the more.",
            "Approximate there on the metrics actually reflects the high proximity reflects this.",
            "Another important factor is the.",
            "The concepts of found the shorter distance actually considered more more important.",
            "So there are different distance functions that could be used.",
            "So for example, this lot."
        ],
        [
            "You see the hierarchical of 1, so the metrics operates in properties, so there are different properties that you can use to actually.",
            "Measure the importance of the concepts.",
            "So on this slide we see, for example, the red nodes again or those that are seed concepts of Paris and belf.",
            "And what we are doing is we are using the category relation such as goes broader and also type type and subclass solve 2 actually.",
            "Developer rates a certain concept.",
            "So.",
            "Another another way to look at the graph or explore the properties is to look at the properties which are which we called."
        ],
        [
            "Once Russell, so this is those that kind of relate concepts.",
            "So for example, that pleasure is a competitor being W, and also it is not only about one.",
            "Let's say one step exploration.",
            "So for example Paris is famous for fashion.",
            "Profession is actually a literal and channel is famous for fashion.",
            "So there's certain relations aren't we consider that when.",
            "Calculating the high proximity so the 3rd way to actually.",
            "The third, the terms of flavor of high proximity, is the mixed approach, which is basically a linear linear combination of the two and this is.",
            "Sorry and yeah, Milan can tell you actually about the linear combination of secret formula which we.",
            "So the next method is."
        ],
        [
            "Some indexing, so random indexing is as I mentioned, one of the methods that is good for finding contextually related terms.",
            "So for example, if you want to find synonyms then it's very good to use this method, so another similar method is for example at the semantic analysis.",
            "Some people are more variable, that's random indexing.",
            "It's kind of the same.",
            "The same type of method that would be able to detect the synonyms so.",
            "It is used a lot in bioinformatics or for finding the words that do not have really direct relationship.",
            "As you can imagine them as synonyms usually do not really appear the same in the same documents.",
            "They appear in the same they appear with the same set of other words.",
            "So in the same context.",
            "In that sense, this is what this method captures very well so.",
            "As this is another set of formation with treble method, it operates."
        ],
        [
            "On text, so it means documents.",
            "It needs words and in this case we have a graph.",
            "So what we do is we try to basically flatten this graph somehow.",
            "So to basically generate what we call virtual documents.",
            "So for each URL in the graph we generate one document and I'll tell.",
            "I'll show the next.",
            "Why how I see that?",
            "Is done, then the next step is now that we have these documents or the next step is very common step in information retrieval which is preprocessing.",
            "Which basically means remove all the punctuation.",
            "Remove stop words and clean a bit the corpus so that we can actually build better semantic space.",
            "So the third step is generating this semantic space or semantic index, which we call him a call.",
            "Here it's basically avec."
        ],
        [
            "Space.",
            "So that during the search operation, if we have your Y as input, what is what we do is basically try to calculate the cosine similarity between the vector of that term or that you are I and those other ones that exist in this semantic space.",
            "So how do we generate this virtual documents?",
            "So if we so I said 4."
        ],
        [
            "Each you around the graph, we generate one document.",
            "So from this example for you RIS, we basically fetch all the statements for this, as is a subject, and then for all statements where the object is AURI or in addition we fetch all the statements were that you are wise, is subject and then the object is Electro.",
            "So this is what is shown actually on this slide 'cause I know it sounds a bit complicated and then from this set of statements which we now decide that this is our UIS.",
            "We do lexical I set.",
            "And the document eventually looks something like this.",
            "So in a way it looks as maybe maybe a bit like an triple format, but it's actually it's not because for these properties for the statements were as a subject and the object is you arrive.",
            "We also include the full path starting with us.",
            "So these are the statements down there which basically do not have three elements but five.",
            "And this is to compensate to basically make the TF IDF work.",
            "Because as you can imagine, this is quite an artificial way to actually generate documents, whereas usually in human readable text there's no such problem.",
            "So to valuate these methods, we have conducted two types of experiments, so first."
        ],
        [
            "We collected 26 real problems for from hyper so these were problems that we took from the last year and that were basically published and the people then submitted the solutions to these problems.",
            "The measure of success was basically whether the suggested concepts would appear in actual solutions, so this way we could calculate precision and recall and also F measure as harmonic mean of the precision recall and the goods.",
            "Good size of this about rationes because it was quite realistic, so these are real problems.",
            "We had lots of the list of concepts were quite is quite large, and on the other side it might be.",
            "Seen as in not so complete list, although that basically means that we could not.",
            "Really there could be some experts that are relevant that just didn't submit the solutions.",
            "So in that sense it's not complete.",
            "So to compensate for that part for you conducted the user study where we basically asked the people to look at the results and to.",
            "Mark whether the concepts were relevant and also to mark whether the concepts were unexpected.",
            "So this is how we measure discovery, which I mentioned earlier.",
            "Another useful the useful thing from this evaluation from its users was that we had the chance to actually get some insights in the subjective.",
            "Feelings of the of these users who actually looked at the concept.",
            "So as I mentioned, we used the picture date set for this and what we?"
        ],
        [
            "Did for both methods we were, we could say we customize them a bit because we didn't really use the whole graph, but we found the whale discovered a way to actually identify the properties that are relevant or useful for the open innovation scenario.",
            "And we did this by basically looking into some problems and some solutions from the past and then extracting URLs from them and then trying to look at DB pedia and reach.",
            "Which properties were actually used to connect these concepts?",
            "So that's how we ended up with several of actually properties.",
            "They are shown on this slide.",
            "So like product product, have the street genre and so on.",
            "So using those fences."
        ],
        [
            "Our problems we created what we call gold standard on the quotes.",
            "So first of all we extracted problem your eyes from the problems and then from solutions we extracted the solution your eyes and then we fed the problem.",
            "You're wise internal methods and then we evaluated how many of these recommended concepts actually overlapped with the solution your eyes.",
            "So that's how we measure the precision, recall and as a baseline we used Google Adwords keyword tool.",
            "This is, let's say, the state of the art tool which is based on the distribution in textual corpora and called Prada search queries.",
            "And it is very good to be used as a baseline for many reasons.",
            "One of them is the high PS for example and other similar companies use this tool Bakshi to perform this task.",
            "So, given that they don't have any other other methods, it's capable of suggesting up to 600 concepts, which is good, and then these concepts could be used for example for.",
            "Web crawling as well.",
            "So in this logic seems a result."
        ],
        [
            "Of this experiment, and on the top left side there is a precision, so X axis here shows the top number of top concepts that we evaluated and Y axis shows the precision.",
            "Recall F measure, so top left is a precision and we can see that high proximity and in fact the mix little bit scored best, whereas in terms of recall, random indexing most performing best for top two concepts.",
            "And then for after that there was there was high proximity transfers or which was a bit better and then so that measure high proximity was best.",
            "So just just different.",
            "Type of it.",
            "So for example, transfer was or mixed was best for like top 100 concepts and then it goes as the number of top concepts increases.",
            "We have either mixed strategy or transfer so being passed so.",
            "As we can see from here, there is a kind of complementary.",
            "I mean, these two methods are all the random indexing.",
            "For example, is even worse than baseline in terms of precision.",
            "It is much better in terms of recalls.",
            "So basically based on the use case that you have, you could select different methods and use and use it.",
            "So for example, if you're doing web crawling, then you don't really care if it stopped 6 country oh or 1000 concepts, but if you are doing some user evaluation then you really care about precision.",
            "So in the user study, as I said, we were, we wanted to measure discovery.",
            "So how many of?"
        ],
        [
            "Relevant concepts where they are and where they unexpected.",
            "So how useful this was for this experiment?",
            "So we had 12 users and 30 four problem valuations.",
            "So this was this means that there were more than three 3000 concepts that the users looked at.",
            "And the users were basically presented with the with the concept and with the top 30 concepts generated by each method.",
            "So something like this.",
            "So."
        ],
        [
            "For example, we see that for, so first column is high proximity or another read the second random indexing and the third one is Edward.",
            "So as you can see here, although these methods are kind of meant to do the same, the same kind of thing.",
            "The list of concept is quite different.",
            "So for example, Randomising suggested lots of.",
            "Mining.",
            "I don't know like more general concepts like oil and so on, but it's high proximity.",
            "Had some really really specific names in there.",
            "So like shoulders Brown the question and so on and it was.",
            "Was sometimes very, very much shopping oriented, so for example.",
            "So for this problem, which was about clay morning, it came out because location was in Brazil.",
            "It came out with the with keyword such as Brazil, Holidays or flies to Brazil or dry clean shampoo and many things that you could actually buy which have nothing to do with mining.",
            "So the results."
        ],
        [
            "This study, in terms of relevance, showed that high proximity is called fast, so this was a scale from 1 to 5 and high proximity scored three points almost 3.7 in terms of unexpectedness, the random indexing method was was actually best.",
            "However, what's about we really are interested in?",
            "Here is a combination of relevance and unexpectedness, and in that regard we got.",
            "Random indexing to be better than.",
            "When the relevancy was equal or greater than four and then hyper simiti betterment relevancy was equal to 5."
        ],
        [
            "So this brings me to the conclusion that these methods and link data, which is basically what is very very much used by these methods, are valuable source, and the two methods as which I've described anyway, complementary so high proximity, seems to be better for precision, whereas the random indexing, since we very good for recall, especially for the top 200 concepts.",
            "And in terms of user study discovery, so both the relevance and unexpectedness measure together was higher for both methods in comparison to the baseline.",
            "So this is good.",
            "And in the user study, one interesting outcome was when we ask them to to use some adjective to describe the methods.",
            "What they usually came up with random indexing was that it was generic for high proximity that was granular.",
            "And for Edwards that it was redundant.",
            "So.",
            "That brings me to the end of my talk.",
            "And if you want to know more, there is a link to help us research and you can also talk to me or Milan if you want to run anything.",
            "And I'm happy to accept any questions."
        ],
        [
            "Thank you.",
            "Hi, my question is about the first step of the process about concept extraction.",
            "So there you relied on the Amanda right?",
            "How did that perform in terms of ambiguity?",
            "Now I'm yeah.",
            "Many times I was surprised by the quality of the result.",
            "Many times I was I told to myself, oh, it didn't make an error here, but I don't have any qualitative data.",
            "So for qualitative data you can refer to this this paper, which is called nerd.",
            "Just had a very quick question about how optical and and lateral similarities that we have.",
            "Can you detail a bit more how you compute those and or is that just like a length of the path between two different nodes?",
            "And if so, how do you add scale, find?",
            "Find that?",
            "Yeah, I know that I said in the data set as big as DB pedia.",
            "So this is a question I can reply partially here, but I think it's better to save this question for the next presentation where we have the concrete formula of how we actually combine the hierarchical and transversal properties and about scalability.",
            "This is this is indeed a good question.",
            "The main difference in our approach in in the algorithm which we will not show because it's really a detail that you can find in the paper, is that as opposed to Google and other page rank algorithms that calculate their measure on all the data set basically at once, we do it.",
            "Partially we have a pattern graph pattern that we recognize a certain distance and when we find this pattern in a surrounding of a concept, we say yeah, this is a point.",
            "At this distance.",
            "So we are not obliged to cover all the graph to see whether distances we can stop at some point.",
            "When we found enough concepts at at the immediate surrounding.",
            "So this is how we actually treat the scaling problem.",
            "We go really locally, and then we expand as we need.",
            "If we need 1600 concepts, we will go further more.",
            "If not, we will go just do one step or two step further, an really wonder what's the goal of.",
            "I proximity so I went to the UI that you have provided, but currently it redirect to a page which we require the key to have more information I guess so.",
            "Is it intended to be a toolkit that people can reuse or what's?",
            "What's the plan?",
            "So I can again refer to Milan.",
            "Sorry question for me.",
            "So yes, the kind proximity was developed first as a research project as a part of my thesis, so it has quite broad applicability.",
            "Range the question of what was his final destiny is a commercial one because it is also in a company context that we have developed it.",
            "So it's a question for what we can find.",
            "The business model.",
            "Can we sell it?",
            "Every selling effort requires.",
            "Commercial people which require salary so there is there is all this gamma of questions that need to be answered, but of course for the research purposes there is an API and if anyone of you is interested in using our tool I can give you.",
            "You can email me and I can give you the code so that you can test the tool online using the web interface and I can also give you access to an API for of course a limited number of we don't have a really good server but.",
            "It's responsive for a limited number of requests, so you can even use it in your own projects if you like.",
            "We can set up now, so thanks again.",
            "I think we have to move to the second talk."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So thanks for introduction.",
                    "label": 0
                },
                {
                    "sent": "So this can you hear me?",
                    "label": 0
                },
                {
                    "sent": "So I will talk about different methods for constant recommendation and the use case we choose is the innovation.",
                    "label": 0
                },
                {
                    "sent": "So in fact open innovation scenario and.",
                    "label": 1
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Why do we choose this?",
                    "label": 0
                },
                {
                    "sent": "Well, innovation is very important in any company which wants to survive the competition.",
                    "label": 0
                },
                {
                    "sent": "So usually these companies have research and development labs which too valuable research and then provide the innovative solutions and so on.",
                    "label": 0
                },
                {
                    "sent": "But often that is not really enough and what they do is they search for some kind of a negative solutions outside to the companies who do what is called nowadays.",
                    "label": 0
                },
                {
                    "sent": "Open innovation and.",
                    "label": 0
                },
                {
                    "sent": "Companies such as Hypers.",
                    "label": 0
                },
                {
                    "sent": "Build platforms for open innovation and what they basically do is.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "On the left hand side we have the those companies who basically have the problems and they want to find people.",
                    "label": 0
                },
                {
                    "sent": "The experts who can solve these problems.",
                    "label": 1
                },
                {
                    "sent": "So what they do is they just give these problems to happy hours and then have yours.",
                    "label": 0
                },
                {
                    "sent": "Points, or the role of this platform and happiness in general is defined to locate the experts who can actually be potentially good solvers of these problems.",
                    "label": 0
                },
                {
                    "sent": "So now how to solve how this platform is actually developed and what's important so it's not really just that they they have a database of experts.",
                    "label": 0
                },
                {
                    "sent": "It's also about trying to make a good match between the problems and those who could actually solve it.",
                    "label": 0
                },
                {
                    "sent": "So as you can imagine, the information retrieval methods play a very important role because it's a lot about finding the right keywords, which one can use to actually locate this these experts.",
                    "label": 0
                },
                {
                    "sent": "However, it is not a very basic information retrieval problem.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And this is for various reasons.",
                    "label": 0
                },
                {
                    "sent": "So one of the reasons is that different communities even use different vocabulary to basically express the same.",
                    "label": 0
                },
                {
                    "sent": "The same thing, sort of semantically related things, and on the other hand even more important problem is that sometimes the wording of the problems problem descriptions doesn't really give enough specific details about actually people who could solve it.",
                    "label": 0
                },
                {
                    "sent": "So for example.",
                    "label": 0
                },
                {
                    "sent": "If the problem is talking about the claim mining, maybe a potentially good or not maybe, but for sure the question who has done something about Caroline's extraction from rocks could be potentially very good solver, but it is quite difficult to actually find this relation between these two concepts.",
                    "label": 0
                },
                {
                    "sent": "So to solve this problem, we developed methods for concept, recommendation and.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "These these concepts are basically those that we would be useful to locate experts, but we might not be aware of them so.",
                    "label": 1
                },
                {
                    "sent": "For example, usually in high pills or other companies similar companies there are people who who we called the problem promoters, so their job is basically based on the problem description to to use the Internet Google Blevel tools.",
                    "label": 1
                },
                {
                    "sent": "They have to basically find the target ING Group or groups to come, then then need to send the problem so that then they can get some potential solution submissions for the.",
                    "label": 0
                },
                {
                    "sent": "For solving these problems.",
                    "label": 0
                },
                {
                    "sent": "So as you can imagine, this problem promoters cannot really be experts in all the fields that that are needed and one of the problems that actually tried to solve here is trying to automate or to help them.",
                    "label": 0
                },
                {
                    "sent": "Maybe extend the list of already existing concepts that they have.",
                    "label": 0
                },
                {
                    "sent": "So in that sense, what the concepts of how do we actually measure whether these concepts that we recommend our code or not?",
                    "label": 0
                },
                {
                    "sent": "So it's not that they're just they are relevant to the problem, but it's also are they what we call unexpected.",
                    "label": 0
                },
                {
                    "sent": "So that means if the problem promoter have never heard of the problem of the concept that you recommend, and the problem and that is relevant, then that's very good for us.",
                    "label": 0
                },
                {
                    "sent": "So we call that discovery.",
                    "label": 0
                },
                {
                    "sent": "So as I have mentioned, it's not.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Only about words and finding contextually similar words or synonyms and so on.",
                    "label": 0
                },
                {
                    "sent": "It's also about finding some natural concepts or concepts that maybe we wouldn't really know that there is a relation between them.",
                    "label": 0
                },
                {
                    "sent": "And I will show later bits for example.",
                    "label": 0
                },
                {
                    "sent": "So you can get the idea of what I mean.",
                    "label": 0
                },
                {
                    "sent": "So the two methods that I'm going to talk about our high proximity, so that's the first one.",
                    "label": 0
                },
                {
                    "sent": "It's structure based similarity, which means that it only explores the graph, so only export the link to inside this case to actually develop this.",
                    "label": 0
                },
                {
                    "sent": "Metric and the other one is a well known method from information retrieval called random indexing.",
                    "label": 1
                },
                {
                    "sent": "So the difference to what we are doing here is that we apply random indexing to RDF, so whereas usually it's it's applied to Suman readable text.",
                    "label": 0
                },
                {
                    "sent": "So on a high level, how do we how do this?",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Methods work, so we start with some textual input.",
                    "label": 1
                },
                {
                    "sent": "This is the problem description for example, or the abstract.",
                    "label": 0
                },
                {
                    "sent": "And from that we first extract the PDF viewer Roy San.",
                    "label": 0
                },
                {
                    "sent": "For this we use amount us, so we could use any other services.",
                    "label": 0
                },
                {
                    "sent": "And from this list or this list of GPU rris extracted from the problems is used as input to our methods and as output we produce a list of recommendations.",
                    "label": 0
                },
                {
                    "sent": "So as on this slide you CDPD exploration, which is basically for this concrete presentation scenario, we really use DB pedia as a data set.",
                    "label": 0
                },
                {
                    "sent": "And both methods that are not described basically used.",
                    "label": 0
                },
                {
                    "sent": "Pizza is as a main source of information.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So I will now briefly introduce you to high proximity, so both high proximity and Rhonda mixing as I as I mentioned, are used in some other scenarios.",
                    "label": 0
                },
                {
                    "sent": "So for example, million will present one of them in the next talk, and random indexing has been used previously in the log project and in some others.",
                    "label": 1
                },
                {
                    "sent": "So these are just some of the applications of these two methods.",
                    "label": 0
                },
                {
                    "sent": "So high proximity as you can see on the bottom of this page is a problem description.",
                    "label": 0
                },
                {
                    "sent": "So starts from problem descriptions from which we extract the red, red, red nodes and this graph is actually say part of DB pedia in this case.",
                    "label": 0
                },
                {
                    "sent": "So it's support of some graph with the metrics operating the graph.",
                    "label": 0
                },
                {
                    "sent": "And then what we're trying to do is we're trying to go from red to black, so I don't know if I I walked back.",
                    "label": 0
                },
                {
                    "sent": "I just want to show something rough.",
                    "label": 0
                },
                {
                    "sent": "Is this work?",
                    "label": 0
                },
                {
                    "sent": "Does this work?",
                    "label": 0
                },
                {
                    "sent": "OK, so so from from the red one you are she want to go to work towards the black ones which means something.",
                    "label": 0
                },
                {
                    "sent": "So which represents something, for example experts or the research papers, patterns or or maybe companies who are doing some similar things.",
                    "label": 0
                },
                {
                    "sent": "So usually you start from the seat concepts and then you walk through the graph to actually find those that that that are kind of related to this graph and the more seed concepts are related to the specific concept and the more.",
                    "label": 1
                },
                {
                    "sent": "Approximate there on the metrics actually reflects the high proximity reflects this.",
                    "label": 0
                },
                {
                    "sent": "Another important factor is the.",
                    "label": 0
                },
                {
                    "sent": "The concepts of found the shorter distance actually considered more more important.",
                    "label": 1
                },
                {
                    "sent": "So there are different distance functions that could be used.",
                    "label": 0
                },
                {
                    "sent": "So for example, this lot.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You see the hierarchical of 1, so the metrics operates in properties, so there are different properties that you can use to actually.",
                    "label": 0
                },
                {
                    "sent": "Measure the importance of the concepts.",
                    "label": 0
                },
                {
                    "sent": "So on this slide we see, for example, the red nodes again or those that are seed concepts of Paris and belf.",
                    "label": 0
                },
                {
                    "sent": "And what we are doing is we are using the category relation such as goes broader and also type type and subclass solve 2 actually.",
                    "label": 0
                },
                {
                    "sent": "Developer rates a certain concept.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Another another way to look at the graph or explore the properties is to look at the properties which are which we called.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Once Russell, so this is those that kind of relate concepts.",
                    "label": 0
                },
                {
                    "sent": "So for example, that pleasure is a competitor being W, and also it is not only about one.",
                    "label": 0
                },
                {
                    "sent": "Let's say one step exploration.",
                    "label": 0
                },
                {
                    "sent": "So for example Paris is famous for fashion.",
                    "label": 0
                },
                {
                    "sent": "Profession is actually a literal and channel is famous for fashion.",
                    "label": 0
                },
                {
                    "sent": "So there's certain relations aren't we consider that when.",
                    "label": 0
                },
                {
                    "sent": "Calculating the high proximity so the 3rd way to actually.",
                    "label": 0
                },
                {
                    "sent": "The third, the terms of flavor of high proximity, is the mixed approach, which is basically a linear linear combination of the two and this is.",
                    "label": 0
                },
                {
                    "sent": "Sorry and yeah, Milan can tell you actually about the linear combination of secret formula which we.",
                    "label": 0
                },
                {
                    "sent": "So the next method is.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Some indexing, so random indexing is as I mentioned, one of the methods that is good for finding contextually related terms.",
                    "label": 0
                },
                {
                    "sent": "So for example, if you want to find synonyms then it's very good to use this method, so another similar method is for example at the semantic analysis.",
                    "label": 0
                },
                {
                    "sent": "Some people are more variable, that's random indexing.",
                    "label": 0
                },
                {
                    "sent": "It's kind of the same.",
                    "label": 0
                },
                {
                    "sent": "The same type of method that would be able to detect the synonyms so.",
                    "label": 0
                },
                {
                    "sent": "It is used a lot in bioinformatics or for finding the words that do not have really direct relationship.",
                    "label": 0
                },
                {
                    "sent": "As you can imagine them as synonyms usually do not really appear the same in the same documents.",
                    "label": 0
                },
                {
                    "sent": "They appear in the same they appear with the same set of other words.",
                    "label": 1
                },
                {
                    "sent": "So in the same context.",
                    "label": 0
                },
                {
                    "sent": "In that sense, this is what this method captures very well so.",
                    "label": 0
                },
                {
                    "sent": "As this is another set of formation with treble method, it operates.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "On text, so it means documents.",
                    "label": 0
                },
                {
                    "sent": "It needs words and in this case we have a graph.",
                    "label": 0
                },
                {
                    "sent": "So what we do is we try to basically flatten this graph somehow.",
                    "label": 0
                },
                {
                    "sent": "So to basically generate what we call virtual documents.",
                    "label": 1
                },
                {
                    "sent": "So for each URL in the graph we generate one document and I'll tell.",
                    "label": 0
                },
                {
                    "sent": "I'll show the next.",
                    "label": 0
                },
                {
                    "sent": "Why how I see that?",
                    "label": 0
                },
                {
                    "sent": "Is done, then the next step is now that we have these documents or the next step is very common step in information retrieval which is preprocessing.",
                    "label": 1
                },
                {
                    "sent": "Which basically means remove all the punctuation.",
                    "label": 0
                },
                {
                    "sent": "Remove stop words and clean a bit the corpus so that we can actually build better semantic space.",
                    "label": 1
                },
                {
                    "sent": "So the third step is generating this semantic space or semantic index, which we call him a call.",
                    "label": 0
                },
                {
                    "sent": "Here it's basically avec.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Space.",
                    "label": 0
                },
                {
                    "sent": "So that during the search operation, if we have your Y as input, what is what we do is basically try to calculate the cosine similarity between the vector of that term or that you are I and those other ones that exist in this semantic space.",
                    "label": 0
                },
                {
                    "sent": "So how do we generate this virtual documents?",
                    "label": 0
                },
                {
                    "sent": "So if we so I said 4.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Each you around the graph, we generate one document.",
                    "label": 0
                },
                {
                    "sent": "So from this example for you RIS, we basically fetch all the statements for this, as is a subject, and then for all statements where the object is AURI or in addition we fetch all the statements were that you are wise, is subject and then the object is Electro.",
                    "label": 0
                },
                {
                    "sent": "So this is what is shown actually on this slide 'cause I know it sounds a bit complicated and then from this set of statements which we now decide that this is our UIS.",
                    "label": 0
                },
                {
                    "sent": "We do lexical I set.",
                    "label": 0
                },
                {
                    "sent": "And the document eventually looks something like this.",
                    "label": 0
                },
                {
                    "sent": "So in a way it looks as maybe maybe a bit like an triple format, but it's actually it's not because for these properties for the statements were as a subject and the object is you arrive.",
                    "label": 0
                },
                {
                    "sent": "We also include the full path starting with us.",
                    "label": 0
                },
                {
                    "sent": "So these are the statements down there which basically do not have three elements but five.",
                    "label": 0
                },
                {
                    "sent": "And this is to compensate to basically make the TF IDF work.",
                    "label": 0
                },
                {
                    "sent": "Because as you can imagine, this is quite an artificial way to actually generate documents, whereas usually in human readable text there's no such problem.",
                    "label": 0
                },
                {
                    "sent": "So to valuate these methods, we have conducted two types of experiments, so first.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We collected 26 real problems for from hyper so these were problems that we took from the last year and that were basically published and the people then submitted the solutions to these problems.",
                    "label": 0
                },
                {
                    "sent": "The measure of success was basically whether the suggested concepts would appear in actual solutions, so this way we could calculate precision and recall and also F measure as harmonic mean of the precision recall and the goods.",
                    "label": 1
                },
                {
                    "sent": "Good size of this about rationes because it was quite realistic, so these are real problems.",
                    "label": 0
                },
                {
                    "sent": "We had lots of the list of concepts were quite is quite large, and on the other side it might be.",
                    "label": 0
                },
                {
                    "sent": "Seen as in not so complete list, although that basically means that we could not.",
                    "label": 0
                },
                {
                    "sent": "Really there could be some experts that are relevant that just didn't submit the solutions.",
                    "label": 0
                },
                {
                    "sent": "So in that sense it's not complete.",
                    "label": 0
                },
                {
                    "sent": "So to compensate for that part for you conducted the user study where we basically asked the people to look at the results and to.",
                    "label": 0
                },
                {
                    "sent": "Mark whether the concepts were relevant and also to mark whether the concepts were unexpected.",
                    "label": 0
                },
                {
                    "sent": "So this is how we measure discovery, which I mentioned earlier.",
                    "label": 0
                },
                {
                    "sent": "Another useful the useful thing from this evaluation from its users was that we had the chance to actually get some insights in the subjective.",
                    "label": 0
                },
                {
                    "sent": "Feelings of the of these users who actually looked at the concept.",
                    "label": 0
                },
                {
                    "sent": "So as I mentioned, we used the picture date set for this and what we?",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Did for both methods we were, we could say we customize them a bit because we didn't really use the whole graph, but we found the whale discovered a way to actually identify the properties that are relevant or useful for the open innovation scenario.",
                    "label": 0
                },
                {
                    "sent": "And we did this by basically looking into some problems and some solutions from the past and then extracting URLs from them and then trying to look at DB pedia and reach.",
                    "label": 0
                },
                {
                    "sent": "Which properties were actually used to connect these concepts?",
                    "label": 0
                },
                {
                    "sent": "So that's how we ended up with several of actually properties.",
                    "label": 0
                },
                {
                    "sent": "They are shown on this slide.",
                    "label": 0
                },
                {
                    "sent": "So like product product, have the street genre and so on.",
                    "label": 0
                },
                {
                    "sent": "So using those fences.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Our problems we created what we call gold standard on the quotes.",
                    "label": 0
                },
                {
                    "sent": "So first of all we extracted problem your eyes from the problems and then from solutions we extracted the solution your eyes and then we fed the problem.",
                    "label": 0
                },
                {
                    "sent": "You're wise internal methods and then we evaluated how many of these recommended concepts actually overlapped with the solution your eyes.",
                    "label": 0
                },
                {
                    "sent": "So that's how we measure the precision, recall and as a baseline we used Google Adwords keyword tool.",
                    "label": 1
                },
                {
                    "sent": "This is, let's say, the state of the art tool which is based on the distribution in textual corpora and called Prada search queries.",
                    "label": 1
                },
                {
                    "sent": "And it is very good to be used as a baseline for many reasons.",
                    "label": 0
                },
                {
                    "sent": "One of them is the high PS for example and other similar companies use this tool Bakshi to perform this task.",
                    "label": 1
                },
                {
                    "sent": "So, given that they don't have any other other methods, it's capable of suggesting up to 600 concepts, which is good, and then these concepts could be used for example for.",
                    "label": 0
                },
                {
                    "sent": "Web crawling as well.",
                    "label": 0
                },
                {
                    "sent": "So in this logic seems a result.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Of this experiment, and on the top left side there is a precision, so X axis here shows the top number of top concepts that we evaluated and Y axis shows the precision.",
                    "label": 0
                },
                {
                    "sent": "Recall F measure, so top left is a precision and we can see that high proximity and in fact the mix little bit scored best, whereas in terms of recall, random indexing most performing best for top two concepts.",
                    "label": 0
                },
                {
                    "sent": "And then for after that there was there was high proximity transfers or which was a bit better and then so that measure high proximity was best.",
                    "label": 0
                },
                {
                    "sent": "So just just different.",
                    "label": 0
                },
                {
                    "sent": "Type of it.",
                    "label": 0
                },
                {
                    "sent": "So for example, transfer was or mixed was best for like top 100 concepts and then it goes as the number of top concepts increases.",
                    "label": 0
                },
                {
                    "sent": "We have either mixed strategy or transfer so being passed so.",
                    "label": 0
                },
                {
                    "sent": "As we can see from here, there is a kind of complementary.",
                    "label": 0
                },
                {
                    "sent": "I mean, these two methods are all the random indexing.",
                    "label": 0
                },
                {
                    "sent": "For example, is even worse than baseline in terms of precision.",
                    "label": 0
                },
                {
                    "sent": "It is much better in terms of recalls.",
                    "label": 0
                },
                {
                    "sent": "So basically based on the use case that you have, you could select different methods and use and use it.",
                    "label": 0
                },
                {
                    "sent": "So for example, if you're doing web crawling, then you don't really care if it stopped 6 country oh or 1000 concepts, but if you are doing some user evaluation then you really care about precision.",
                    "label": 0
                },
                {
                    "sent": "So in the user study, as I said, we were, we wanted to measure discovery.",
                    "label": 0
                },
                {
                    "sent": "So how many of?",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Relevant concepts where they are and where they unexpected.",
                    "label": 0
                },
                {
                    "sent": "So how useful this was for this experiment?",
                    "label": 0
                },
                {
                    "sent": "So we had 12 users and 30 four problem valuations.",
                    "label": 1
                },
                {
                    "sent": "So this was this means that there were more than three 3000 concepts that the users looked at.",
                    "label": 0
                },
                {
                    "sent": "And the users were basically presented with the with the concept and with the top 30 concepts generated by each method.",
                    "label": 1
                },
                {
                    "sent": "So something like this.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For example, we see that for, so first column is high proximity or another read the second random indexing and the third one is Edward.",
                    "label": 0
                },
                {
                    "sent": "So as you can see here, although these methods are kind of meant to do the same, the same kind of thing.",
                    "label": 0
                },
                {
                    "sent": "The list of concept is quite different.",
                    "label": 0
                },
                {
                    "sent": "So for example, Randomising suggested lots of.",
                    "label": 0
                },
                {
                    "sent": "Mining.",
                    "label": 0
                },
                {
                    "sent": "I don't know like more general concepts like oil and so on, but it's high proximity.",
                    "label": 0
                },
                {
                    "sent": "Had some really really specific names in there.",
                    "label": 0
                },
                {
                    "sent": "So like shoulders Brown the question and so on and it was.",
                    "label": 0
                },
                {
                    "sent": "Was sometimes very, very much shopping oriented, so for example.",
                    "label": 0
                },
                {
                    "sent": "So for this problem, which was about clay morning, it came out because location was in Brazil.",
                    "label": 0
                },
                {
                    "sent": "It came out with the with keyword such as Brazil, Holidays or flies to Brazil or dry clean shampoo and many things that you could actually buy which have nothing to do with mining.",
                    "label": 0
                },
                {
                    "sent": "So the results.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This study, in terms of relevance, showed that high proximity is called fast, so this was a scale from 1 to 5 and high proximity scored three points almost 3.7 in terms of unexpectedness, the random indexing method was was actually best.",
                    "label": 0
                },
                {
                    "sent": "However, what's about we really are interested in?",
                    "label": 0
                },
                {
                    "sent": "Here is a combination of relevance and unexpectedness, and in that regard we got.",
                    "label": 0
                },
                {
                    "sent": "Random indexing to be better than.",
                    "label": 0
                },
                {
                    "sent": "When the relevancy was equal or greater than four and then hyper simiti betterment relevancy was equal to 5.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this brings me to the conclusion that these methods and link data, which is basically what is very very much used by these methods, are valuable source, and the two methods as which I've described anyway, complementary so high proximity, seems to be better for precision, whereas the random indexing, since we very good for recall, especially for the top 200 concepts.",
                    "label": 1
                },
                {
                    "sent": "And in terms of user study discovery, so both the relevance and unexpectedness measure together was higher for both methods in comparison to the baseline.",
                    "label": 0
                },
                {
                    "sent": "So this is good.",
                    "label": 0
                },
                {
                    "sent": "And in the user study, one interesting outcome was when we ask them to to use some adjective to describe the methods.",
                    "label": 0
                },
                {
                    "sent": "What they usually came up with random indexing was that it was generic for high proximity that was granular.",
                    "label": 0
                },
                {
                    "sent": "And for Edwards that it was redundant.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "That brings me to the end of my talk.",
                    "label": 0
                },
                {
                    "sent": "And if you want to know more, there is a link to help us research and you can also talk to me or Milan if you want to run anything.",
                    "label": 0
                },
                {
                    "sent": "And I'm happy to accept any questions.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Thank you.",
                    "label": 0
                },
                {
                    "sent": "Hi, my question is about the first step of the process about concept extraction.",
                    "label": 0
                },
                {
                    "sent": "So there you relied on the Amanda right?",
                    "label": 0
                },
                {
                    "sent": "How did that perform in terms of ambiguity?",
                    "label": 0
                },
                {
                    "sent": "Now I'm yeah.",
                    "label": 0
                },
                {
                    "sent": "Many times I was surprised by the quality of the result.",
                    "label": 0
                },
                {
                    "sent": "Many times I was I told to myself, oh, it didn't make an error here, but I don't have any qualitative data.",
                    "label": 0
                },
                {
                    "sent": "So for qualitative data you can refer to this this paper, which is called nerd.",
                    "label": 0
                },
                {
                    "sent": "Just had a very quick question about how optical and and lateral similarities that we have.",
                    "label": 0
                },
                {
                    "sent": "Can you detail a bit more how you compute those and or is that just like a length of the path between two different nodes?",
                    "label": 0
                },
                {
                    "sent": "And if so, how do you add scale, find?",
                    "label": 0
                },
                {
                    "sent": "Find that?",
                    "label": 0
                },
                {
                    "sent": "Yeah, I know that I said in the data set as big as DB pedia.",
                    "label": 0
                },
                {
                    "sent": "So this is a question I can reply partially here, but I think it's better to save this question for the next presentation where we have the concrete formula of how we actually combine the hierarchical and transversal properties and about scalability.",
                    "label": 0
                },
                {
                    "sent": "This is this is indeed a good question.",
                    "label": 0
                },
                {
                    "sent": "The main difference in our approach in in the algorithm which we will not show because it's really a detail that you can find in the paper, is that as opposed to Google and other page rank algorithms that calculate their measure on all the data set basically at once, we do it.",
                    "label": 0
                },
                {
                    "sent": "Partially we have a pattern graph pattern that we recognize a certain distance and when we find this pattern in a surrounding of a concept, we say yeah, this is a point.",
                    "label": 0
                },
                {
                    "sent": "At this distance.",
                    "label": 0
                },
                {
                    "sent": "So we are not obliged to cover all the graph to see whether distances we can stop at some point.",
                    "label": 0
                },
                {
                    "sent": "When we found enough concepts at at the immediate surrounding.",
                    "label": 0
                },
                {
                    "sent": "So this is how we actually treat the scaling problem.",
                    "label": 0
                },
                {
                    "sent": "We go really locally, and then we expand as we need.",
                    "label": 0
                },
                {
                    "sent": "If we need 1600 concepts, we will go further more.",
                    "label": 0
                },
                {
                    "sent": "If not, we will go just do one step or two step further, an really wonder what's the goal of.",
                    "label": 0
                },
                {
                    "sent": "I proximity so I went to the UI that you have provided, but currently it redirect to a page which we require the key to have more information I guess so.",
                    "label": 0
                },
                {
                    "sent": "Is it intended to be a toolkit that people can reuse or what's?",
                    "label": 0
                },
                {
                    "sent": "What's the plan?",
                    "label": 0
                },
                {
                    "sent": "So I can again refer to Milan.",
                    "label": 0
                },
                {
                    "sent": "Sorry question for me.",
                    "label": 0
                },
                {
                    "sent": "So yes, the kind proximity was developed first as a research project as a part of my thesis, so it has quite broad applicability.",
                    "label": 0
                },
                {
                    "sent": "Range the question of what was his final destiny is a commercial one because it is also in a company context that we have developed it.",
                    "label": 0
                },
                {
                    "sent": "So it's a question for what we can find.",
                    "label": 0
                },
                {
                    "sent": "The business model.",
                    "label": 0
                },
                {
                    "sent": "Can we sell it?",
                    "label": 0
                },
                {
                    "sent": "Every selling effort requires.",
                    "label": 0
                },
                {
                    "sent": "Commercial people which require salary so there is there is all this gamma of questions that need to be answered, but of course for the research purposes there is an API and if anyone of you is interested in using our tool I can give you.",
                    "label": 0
                },
                {
                    "sent": "You can email me and I can give you the code so that you can test the tool online using the web interface and I can also give you access to an API for of course a limited number of we don't have a really good server but.",
                    "label": 0
                },
                {
                    "sent": "It's responsive for a limited number of requests, so you can even use it in your own projects if you like.",
                    "label": 0
                },
                {
                    "sent": "We can set up now, so thanks again.",
                    "label": 0
                },
                {
                    "sent": "I think we have to move to the second talk.",
                    "label": 0
                }
            ]
        }
    }
}