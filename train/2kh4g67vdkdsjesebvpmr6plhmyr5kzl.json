{
    "id": "2kh4g67vdkdsjesebvpmr6plhmyr5kzl",
    "title": "Optimization in Learning and Data Analysis",
    "info": {
        "author": [
            "Stephen J. Wright, Computer Sciences Department, University of Wisconsin-Madison"
        ],
        "published": "Sept. 27, 2013",
        "recorded": "August 2013",
        "category": [
            "Top->Computer Science->Data Mining",
            "Top->Computer Science->Knowledge Extraction"
        ]
    },
    "url": "http://videolectures.net/kdd2013_wright_data_analysis/",
    "segmentation": [
        [
            "I wanted to say a little bit today about as integer indicated, the intersection between optimization."
        ],
        [
            "And and.",
            "Data analysis and learning problems and my slides are on the web.",
            "By the way, if you can find my homepage which shouldn't be too hard, there's a prominent link at the top to this slide deck.",
            "So if you want to download it, follow along or ambush me at some point.",
            "Feel free to do that.",
            "This summarizes my theme and that is that the field of optimization I think provides a powerful toolbox of techniques for addressing data analysis and learning problems, and I should mention that the particular requirements of these problems are driving a lot of new research and optimization, and the new work isn't just being done in their core optimization community.",
            "Much of it is being done by you by you guys in the machine learning data analysis Community.",
            "Another interesting feature of this is that there's some old algorithmic work which was sort of sitting on the shelf for years that suddenly been found to be very useful again.",
            "So there are several techniques that I'll talk about that have sort of burst back into prominence and, and also, as I mentioned at the end of the talk, if I have time, there are sort of interesting intersections with with work in systems and databases and so on.",
            "Alright."
        ],
        [
            "OK, so this is the outline of the talk.",
            "I want to talk first about some Canonical formulations of of problems in data analysis and machine learning.",
            "These are problems that are probably majority of them will be familiar to most of you, but I'll just sketch the more briefly and mention in particular how they're written as optimization problems.",
            "So this is material that probably will be familiar with.",
            "Then I'll talk about I sort of focus on 6 particular tools from optimization that are being used to address a lot of these problems, and a lot of the other problems that come up in the area, such as the ones I saw in the at the poster session last night.",
            "And then I'll briefly talk about how the techniques are being matched with the application.",
            "So I've got a couple of slides where I have some representative publications that show how the optimization tools are addressing the formulations that I talked about in Part one, and then at the end I'll talk about some new work that we've been doing on asynchronous multi core algorithms of stochastic gradient and coordinate descent type, and if there's still time at the end, I'll talk about some very recent work that we've done at Wisconsin on applying these methods too.",
            "Linear programs of large scale, particularly problems, are linear problems that arise in in data analysis type applications."
        ],
        [
            "Alright.",
            "OK, so here's my laundry list of of Canonical problems that I'll just go over very quickly.",
            "Linear regression, variable selection, compressed sensing, support vector machines, logistic regression, matrix completion, estimation of sparse inverse covariance matrices, little bit about deep belief networks, image processing and then data assimilation, which probably isn't such a big topic in this community, but still is an extremely important in."
        ],
        [
            "Essence of big data.",
            "So linear regression.",
            "In a sense, this is the granddaddy of all data analysis problems and you will know that you know the setup is that you've got a bunch of feature vectors, AI living in RN.",
            "You've got a bunch of outcomes and you're seeking a weight vector X such that when you wake the features with the components of X, you approximately predict BI.",
            "So one way to find X is to write down an objective function which consists of the sum of squares of the discrepancies and so you end up with his classic linear least squares problem.",
            "If you want something more robust, you can instead take the vector of discrepancies and take an L1 norm that's more robust to outliers.",
            "And then there's the Huber function, which is a sort of a combination of L2 and L1.",
            "The thing to note about all these is that they're separable functions, so all of them are sums from one to M and each terminus.",
            "I'm involves a single item of data, and that sort of structure is.",
            "Is a recurring theme in data analysis that of course the algorithms."
        ],
        [
            "To exploit.",
            "It's always been of interest to look for sparse solutions to regression problems.",
            "That is, look for vectors X that only have a relatively few non zeros because that tells you which of the features are important in doing the classification, or regression or whatever task you're doing.",
            "And so there's this classic paper in the statistics literature from Tibshirani which points out that you can do this by introducing A1 norm into the formulation of 1 norm of X, and you can either add a multiple of the one norm onto the sum of squares objective, or you can impose it as a constraint either way, for appropriate choices of the parameters Lambda and T, you'll get an X which has relatively few non zeros."
        ],
        [
            "Now compressed sensing this has been an area that's sort of exploded into prominence across multiple communities.",
            "Statistics, signal processing, applied math and optimization also got involved, and really the formulation of compressed sensing is identical to last suit.",
            "Formally, it looks the same, but the properties of the Matrix A are typically different in compressed sensing applications in a lot of feature selection applications, a typically has more rows and columns and compressed sensing.",
            "It's often the other way around these system ASC.",
            "Equals B is underdetermined, but you have some prior knowledge that the vector X is sparse or approximately sparse.",
            "That is only a few significantly nonzero components in act, and your goal is to recover X as it always is to get to try to get that perspective back by solving some sort of problem.",
            "In this case an optimization problem.",
            "Now typically in compressed sensing, A is also assumed to have this special property called restricted isometry or incoherence, and basically what that property is is if you take narrow column sub matrices of a, they tend to be well conditioned, so that's that turns out to be very important.",
            "And the idea is that you can recover.",
            "There's a theorem.",
            "This paper of famous paper candles, Romberg and Tao from 2006 that says that if a has this nice property and if the true solution X is sparse, you can actually recover X by solving this optimization problem, even when the number of rows of A is much smaller than dimension of X.",
            "So in other words, you just have to make some a very small number of observations of X.",
            "The number of observations is tide mostly to the sparsity of X, the number of non zero elements.",
            "And yet, even though you are sampling a vector of length in using only M observations, where M is much less than N, you can still recover the whole signal, so that's that was a very important result, and it turns out to be applicable to allow."
        ],
        [
            "Areas.",
            "Now support vector machines.",
            "This really is a topic that I think needs no introduction, but I'll just point out here that the setup is similar to the regression case, except here instead of trying to predict a real outcome, you're just trying to predict a category one category or another in the.",
            "In the binary case.",
            "And so again, you've got a bunch of data vectors.",
            "You're seeking a weight vector Z.",
            "Change the notation a little bit here, so that extra XI transpose Y has the sign that's appropriate for its class.",
            "If you're doing supervised learning.",
            "So the way that this is written as an optimization problem, or certainly one way to do it, is to make up this separable penalty function, where each term is positive if the item is classified incorrectly, and zero if it's classified correctly.",
            "And then as this extra term at the end, which has this function of making the hyperplane separate, the two classes as much as possible if they are separable.",
            "So I think this formulation with the so called hinge loss will be familiar to many of you if you take it's a convex quadratic program, or at least it can be written that way if you take the dual of that convex QP, you get another probably equally familiar form which is given here, and this involves the kernel matrix.",
            "OK is a matrix, and in the linear case K the elements of K basically consists of inner product so.",
            "Of two feature vectors, but it's been known as a so called kernel trick that you can replace these inner products with the kernel function.",
            "And in effect, what you're doing is projecting the feature vectors into some high dimensional space before you do the classification.",
            "And so there are.",
            "You know that this was one of the sides, say one of the first areas where optimization was deployed in machine learning in the late 90s."
        ],
        [
            "Logistic regression, sort of, is quite similar in many ways to classification problem, except it here not just looking for a prediction of which Class A given feature vector belongs to, but you'd like odds of it being in one class or another.",
            "So you're trying to reconstruct these parameterized odds functions P plus in P minus, so that when the vector XI is in class 1P plus avec Scienze, Z is chosen so that P plus is close to one and P minus is close to 0.",
            "And vice versa for the other class.",
            "So by writing down a log likelihood function for that and taking the negative of that function, you end up with an objective that you can minimize to try to identify an appropriate weight vector for these weight vector Z that parameterized these odds functions.",
            "You can also do this trick of adding on a multiple of the one norm in order to try to get a sparsity, so to try to home in on the features from XI that most important in constructing the function.",
            "And that's very often important in practice, and you can also extend these ideas to multiple class regression.",
            "In fact, the speech processing people work with a lot of classes."
        ],
        [
            "Matrix completion this is another problem that's only been around for a few years, but it's a very important one and a lot of the applications that people here are interested in in the game here is that they are known as a matrix rather than a vector.",
            "Again, as in compressed sensing, you know our priority that it's got some desired structure.",
            "You're looking for matrices often that are low rank or maybe sparse, or maybe some combination of those things.",
            "And the data that you've got to work with is some observations of that matrix.",
            "A limited set of observations so they could be elementwise observations.",
            "They could be some sort of more general linear combination of the components of X, but in any case you've got this vector V of observations, you've got an observation operator A and you're trying to recover X from that.",
            "Now again we've got this regularization term at the end, and that's the term that sort of tries to enforce their desired structure on X.",
            "So it's well known by now that if you.",
            "If you use, if you define side to be the nuclear norm, that is the sum of the singular values of X.",
            "You tend to get low rank solutions by minimizing this function.",
            "And of course, and if you want to sparse matrix X, you can use this circle elementwise 1.",
            "Normally, just sum up the absolute values of all the components of X."
        ],
        [
            "Inverse covariance estimation, again spin around, maybe for five or six years, and the game here is that you're making a bunch of observations of a Gaussian random vector where the elements who got Y one through YM and they're all observing the same random variable.",
            "If you form a sample covariance from that sample, you'll get a dense matrix, or almost always, but often the random variable that you're observing is actually coming from a structure where there are a lot of conditional independence is between the components, so there might there might be some graph structure that defines the dependencies between the components of why.",
            "And what you'd like to do from by observing these random variables is you'd like to recover the graph structure, and one way to do that is you can take the sample covariance and look for an approximate inverse of that matrix.",
            "That's also sparse.",
            "So that can be written as an optimization problem by first of all, writing down the log likelihood for the inverse covariance, which is P, and then adding on this regularization term some multiple of the element wise, one norm of P and that sort of enforces.",
            "Or that induces some sparsity structure on P. So this is useful and sort of recovering network structure from a bunch of observations."
        ],
        [
            "Deep belief networks.",
            "Of course, this is another area that's become very, very popular, and particularly I'd say in speech processing some extent in computer vision.",
            "One way I like to think of delete deep belief networks is it's a way of transforming feature vectors into some alternative form that's in some sense easier to work with, easier to classify.",
            "Or whatever, so here's an example from a paper of Hinton in 2007 where coming in at the bottom of this network you have a 28 by 28 pixel map of a think it's just a picture of a digit and and undergoes a bunch of transformations at each level of this network.",
            "Essentially all that's happening at each layer is that there's a bunch of inputs there multiplied by a matrix to produce a bunch of outputs.",
            "And the parameters in the deep belief network are simply the matrices that do these transformations, and once you get out at the top, it so happens here that what comes out at the top is another 28 by 28 pixel image.",
            "Of course, generally the shape of the output is different from the input in a deep belief network.",
            "Here it happens to be the same.",
            "But the and hopefully the thing that comes out at the top is in some sense easier to classify."
        ],
        [
            "I can run an SVM or do some other something simpler with the output features.",
            "So the point.",
            "So I want to make about these networks are firstly that again you tend to get when you're training these networks.",
            "When you're trying to identify the parameters.",
            "In this case the matrices W1W2.",
            "You again typically have a separable objective where there's one term in the objective for each item of data.",
            "Each character, each utterance, and so on.",
            "Another feature of these networks is that they each layer tends to be very simple.",
            "It could be a linear transformation, a sigmoid or softmax or something.",
            "So each layer is simple, but when you compose them one on top of the other, the resulting function becomes very nonlinear, very nonconvex, and so and therefore hard to deal with for certainly from an optimization viewpoint.",
            "And also very often in these applications too, you want to do some sort of regularization.",
            "You want to impose some kind of structure on the solution, and the solution in this case of the parameters that define each layer."
        ],
        [
            "Image processing OK, so this takes off from the observation that natural pictures are not random.",
            "So you when you look at these two pictures, you'll see very clearly that the one on the left is just white.",
            "Noise is really no information in that the one on the right looks more like a natural image in that you've got these large areas where the color is constant.",
            "You've got these sort of edges that separate different regions of different colors and so on.",
            "But often an image processing you presented with a blurred or noisy picture and you want to remove the noise and remove the blur and recover a natural image.",
            "And you can use this knowledge is this knowledge of what is a natural image to do that to help in that task?"
        ],
        [
            "So how do you do that?",
            "Well, as a classic paper, that's now 20 ideas old where they introduced the concept of total variation regularization.",
            "And so here they say that natural images 1 where if you have got an image map here you which basically Maps the unit square to some intensity map or color map.",
            "In images natural if when I take spatial derivatives of you that is a differentiated in both X&Y directions.",
            "To get this gradient here, take the two norm of that vector and then integrate that quantity over the entire image space.",
            "If that quantity.",
            "If that measure is relatively small, then the image is natural.",
            "If you've got a lot of noise in the image, this quantity will be large.",
            "You'll see a lot of jumps in the derivative, but in a natural image you'll only see jumps when you've got edges in the image and the.",
            "Not too many of those.",
            "So if you you can write in standard as an optimization problem.",
            "If you're given a noisy image F, you can write it down as a problem where you select you to be the image that minimizes this objective.",
            "The first term is just a least squares loss, and the second term is this total variation that I mentioned earlier.",
            "So if you apply this to this sort of classic test problem in this area, the image on the left has got a lot of noise in it.",
            "When we minimize this total variation, we get the image on the right, from which most of the noise has been removed.",
            "And it looks more natural."
        ],
        [
            "And finally, data assimilation.",
            "I wanted to mention this partly because I was just at a meeting on this topic a couple of weeks ago, but also because it's really a critical area where big Data is sort of combined with scientific computing, meteorology, PD models and so on to produce results that we all of us find extremely useful.",
            "And data assimilation is really the basis of weather forecasting and weather forecasting.",
            "You've got a huge amount of data, you've got observations of the atmospheric state taken over a large.",
            "Spatial area taken over a time interval, usually the last two days or so.",
            "You want to assimilate all that data, put it into a PD model and figure out what the state of the atmosphere was, say, 24 hours ago, because once you figured that out, you can then just integrate the PD model forward in time, 10 days or whatever it is to get a forecast.",
            "So this is what they do.",
            "You know every six hours or every 12 hours they have to solve this huge big data problem that assimilates all this data and comes up with a forecast ultimately.",
            "So there's a lot of physics in this.",
            "There's a lot of meteorology.",
            "There's a lot of scientific computing is a lot of parallel computing.",
            "These things run on huge warehouses and parallel computers.",
            "There's a lot of data and have also.",
            "Of course, this error in the observation.",
            "So in order to do a good job of the assimilation, they need a statistical model of the noise in the observations an for many, many years.",
            "They only had very naive models of noise, and it's only really in the last few years that this Community has started to pay more attention to issues of estimating covariance matrices and so on.",
            "And also prior knowledge is very important in this in this application.",
            "So I just wanted to mention this because it is an area where the statistics and where the where the desire for better noise models is."
        ],
        [
            "Driving a lot of the recent research.",
            "So that finishes my very quick survey of Canonical.",
            "Problems in data analysis and machine learning.",
            "Of course there are many others that I didn't talk about that are equally important to the ones that I mentioned, but I think this captures a lot of problems where optimization plays an important role as a formulation tool and as a solution tool.",
            "So moving on to saying a little bit about optimization tools perceive, I just want to point out at the start the properties of these problems, some sort of common or typical properties are that first of all, of course they all involve data.",
            "Secondly, they involve some sort of model, and by the time it's written down as an optimization problem, the model is being parameterized by that point.",
            "And this model sort of captures the relationship between the data and whatever meaning we're trying to get from it.",
            "And Thirdly, there's an objective that measures the mismatch between the current model and current set of parameters and the observed data, so it measures errors between predictions and observations, and it also might incorporate the objective might also incorporate information about the prior knowledge of the solution and something about the desired structure that we're looking for.",
            "So some other typical problems that are not things that we use the traditionally dealt with in optimization, that often you only need sort of a low to medium accuracy mission, and some of these these applications, because often you're minimizing some, just some sort of empirical risk function, so there's no point in accurate in solution solving it to 6 digits of accuracy.",
            "The fact that we've got some prior knowledge about the parameters is something that we typically didn't have an optimization.",
            "And Lastly, the fact that we're only looking we were looking for solutions that are only approximate minimizes the objective, but also have some desired structure.",
            "That's another feature that optimizes of only sort of come to grips with fairly recently.",
            "So in some cases, the formulation of machine learning problems as optimization problems is well settled, and some of the examples I've just given fall into that category.",
            "But in other areas of course people are very interested in still working on formulations of coming up with interesting formulations, and I notice that the poster session last night there were many posters where people had had cooked up their own formulation to capture the.",
            "All caps."
        ],
        [
            "The thing that they were trying to the problem that we're trying to address.",
            "So these are the six areas that I wanted to point out, which I think are relevant to many of the applications I discussed in many others and I just want to sketch them very briefly and then put the two things together.",
            "So firstly, I'll say a little bit about accelerated gradient methods.",
            "I think this is something that some of you might find useful if you don't already know about it.",
            "Stochastic gradient is now a well studied topic in this area.",
            "Coordinate descent methods.",
            "Again, something that's been quite popular.",
            "Shrinking techniques that go along with regularization.",
            "Higher order methods I use higher than first order information and then a little bit about augmented lagrangians Adm.",
            "I understand that Steve Boyd talked to you two years ago and he loves to talk about a DMM.",
            "I'm sure he told you something about that.",
            "It remains a very important topic.",
            "Sold."
        ],
        [
            "And it also.",
            "So the first one gradient method.",
            "So firstly if I give you a very simple optimization problem, that is, you want to minimize a function F. There are no constraints.",
            "This function is a smooth function of a bunch of real variables.",
            "You can actually get a second derivative site, or in principle you could.",
            "You could get a second derivative.",
            "So a first order method just makes progress on the basis of calculating the gradient of F OK and the natural thing to do.",
            "If you've got the gradient of effort and given it a RTX cake, the natural thing to do is just to move in the negative gradient direction, 'cause that's the direction where the function is going most steeply downhill.",
            "If you look at the contours of the function, that's the direction where the contours of sort of most closely bunched together, so you get most bang for the Buck by traveling in that direction.",
            "So totally reasonable thing to do to move from XC2X K plus one.",
            "You just take a step of like the Alpha K negative gradient direction.",
            "Now, if you actually know something more about this function, if you know that the hash and the second derivative matrix has eigenvalues that are bounded between you and L view is a lower bound, and I'm sure I'll assume here I'm dealing with a convex function, so use greater equal to 0.",
            "Then I can actually set the step length Alpha K to be simply two overview plus Li can fix it to this constant value and I can just blindly take these steps in the negative gradient direction.",
            "With this given step link.",
            "And without too much effort, you can prove that you can actually figure out what the convergence rate of that process is.",
            "The difference between the function at XK and the optimal function X star is given by this expression times the initial error, so this expression is a number slightly less than one raised to the power 2K, and this number depends on Kappa, which is the conditioning of this function, so it's the ratio of the biggest eigenvalue L to the smallest eigenvalue mute.",
            "OK, so using this complexity estimate, this is what I call a linear convergence rate.",
            "Some people like to say exponential, which sounds much sexier, but you know.",
            "I think linear is a bit more descriptive.",
            "Using this right?",
            "You can show that if you if your aim is to reduce the initial error by a factor of epsilon.",
            "Then the number of iterations you need is order K, log order, capital log epsilon where captures the condition.",
            "OK, so will condition problems are harder to solve.",
            "The surprising thing about this very basic method is that you really can't do better than even if you take a lot more trouble to find the step length Alpha K, you do an exact search.",
            "You typically don't get a better convergence rate than this very naive way of setting that the step length.",
            "Now that I just sort of mentioned this math."
        ],
        [
            "By way of introduction, because there's a very simple change you can make to that method, which can dramatically improve its performance, and it uses this idea of momentum.",
            "So the idea is instead of just moving from exc 8X K plus one along the negative gradient direction, you throw in a component of the previous step that you just took from XK minus one to XK, and so the net effect is that you're taking a step that has two components and negative gradient component Anna contribution from the previous step, and this idea is sort of cropped up in many different guises.",
            "There's one called Heavy Ball, which is.",
            "Which I have on this slide, the conjugate gradient method, which is very well known in linear algebra and to some extent optimization is essentially this kind of a method and then as accelerated gradient, which I'll talk about in the next slide.",
            "So in the heavy ball method again it assumes that you know what Ellen you are.",
            "These bounds on the eigenvalues of the Hessian, and you can just set Alpha kata.",
            "This value beta cater this value both of them constant.",
            "Notice that Alpha K If Kappa is fairly large.",
            "If you got a somewhat ill condition problem.",
            "Alpha K is about 4 / L beta K is sort of close to 1.",
            "So most of the step is actually coming from the is just almost equal to the previous step with a little bit of a tweak to incorporate the latest gradient.",
            "OK, so you can show with only about 2 slides of analysis, just a few lines of analysis, you can show that the linear convergence rate of this method.",
            "Is the complexity is basically order square root of capital log epsilon rather than order catalog epsilon.",
            "So if you've got a function that's gotta condition number about 100, this is going to be about 10 times faster than steepest descent and there's no extra work involved.",
            "You only have to compute one gradient in each iteration.",
            "You maybe have to store one extra vector, but that's it.",
            "So if you're using steepest descent, if you got a smooth function, try this out.",
            "Chances are you'll you'll see an immediate improvement with just a couple of extra lines of."
        ],
        [
            "Code.",
            "Accelerated gradient methods.",
            "These have really been latched onto in learning and analysis and compressed sensing communities.",
            "Image analysis communities.",
            "These are basically the same idea.",
            "The only difference is that the contribution from the negative gradient and the previous step are kind of torn apart.",
            "So instead of combining them both into a step you take first of all, you just take a negative gradient step 1st and then you do a little bit of mumbo jumbo calculation to figure out the beta and then you take the momentum step.",
            "So you sort of do them sequentially rather than together.",
            "OK, and the this paper this famous paper called Pfister buy back into Bill from 2009 basically does this using a different set of formulas.",
            "But it's really the same idea."
        ],
        [
            "Skip over that one.",
            "Alright, so that's accelerated gradient.",
            "That's sort of an easy win for a lot of applications.",
            "Second, topic stochastic gradient.",
            "Again, this is something I think that's fairly familiar, and here we're specifically going to look at functions that are the sum of a bunch of FIS where each FI could be a loss function for a single item of data.",
            "Or it could be a loss function from mini batch of data, and as I've already pointed out, this sort of structure is very common.",
            "So one thing to note about this sort of objective is that it's very, very difficult to compute a function value.",
            "You basically have to scan the entire data set to get a function value, so that makes any algorithm that needs to compute function values completely impractical.",
            "However, you can get an unbiased estimate of the gradient very cheaply if I just select one indexi at random and evaluate the gradient of FI.",
            "I've got an unbiased estimate of the gradient of the whole function F, and so I can take a step in that direction and hope to make some progress.",
            "So this idea actually goes back to Robbins and Monro from 1951.",
            "So it's a classical paper.",
            "It was worked on a lot in the Russian literature.",
            "It was worked on a lot in the machine learning literature, going back 20 or 25 years."
        ],
        [
            "And again, the analysis of the fundamental method is very, very simple, but there's a beautiful paper insheim optimization by Nemerofsky ET al that I think appears in their reference list for this talk, where they summarize the relevant analysis on just a few pages at the start of the paper.",
            "And here is the result.",
            "Here's the basic result for the basic method.",
            "First of all, if I assume that the gradients of the FIS are in some sense uniformly bounded or their average is bounded by this quantity M. If I use a K. To be the expected value of the error or the squared error, Notice I have to use expected values because this is a random algorithm.",
            "Every time I run it, I'm going to get a different result because I'm going to make a different set of choices of indices.",
            "So in any, so I cannot, but I can still analyze the expectation OK, and you can show with a few lines of analysis that the expected error K plus one is less than or equal to this multiple of the expected error K plus this extra term.",
            "And this choice is step length.",
            "Alpha K is critical here.",
            "You can show that by choosing Alpha K to be 1 / K times, mew mew is a lower bound on the eigenvalues of of the Hessian of F. Then you can apply a very simple argument to show that you get a sub linear convergence rate.",
            "AKA goes down like 1 / K, so it's not the sort of geometric linear rate that we saw for steepest descent accelerated gradient, but at least it's going to zero at sort of a recognizable rate.",
            "You wouldn't expect a blockbuster convergence rate because you're using this very typically very crude estimate of the gradient at each step, so you wouldn't expect to get something that sort of matched steepest descent."
        ],
        [
            "So there are many, many variants of this basic approach.",
            "There's a variant where you sort of set a target for how low you want the expected error to do, and then try to find a constant step length that gets you there in a number of iterations.",
            "There's this idea of averaging where you don't just take the latest it as your guess of the solution, but you form a weighted average of all the iterative seen so far that tends to behave more stable.",
            "It tends to be less sensitive to choice of step length.",
            "And there's a dual averaging idea, which is very simple way that you use the search direction to be the average of all the approximate gradients you've seen so far, not just one random gradient.",
            "Again, that tends to be more stable.",
            "And I just want to make the comment here that a lot of people call this method STD for stochastic gradient descent, but I actually don't like that terminology because it's not a dissent method.",
            "The descent method is where F is going downhill at every iteration, and that's not happening almost never have happening here, so I just like to call it SG for stochastic grade."
        ],
        [
            "OK, third topic.",
            "Coordinate descent.",
            "So again here we're just going to going to consider initially just an unconstrained minimization of a function F. The idea of coordinate descent is that, again, you pick one coordinate of X at random, or can be at random.",
            "Or it could be according to some schedule.",
            "But in any case, the single coordinate and you take a move just in that coordinate.",
            "OK, so you could have, for example evaluate that element of the gradient vector.",
            "You could do some sort of more exhaustive minimization along that component.",
            "But any case you only change one component.",
            "So there are deterministic variants where you go through the components of X in some fixed order, like a cyclic order through stochastic variance where you choose them at random, maybe uniformly, maybe according to some weighted ski.",
            "So this is a reasonable thing to do.",
            "For example, if you're able to get individual gradients cheaply, or if you're able to do the minimization over an individ."
        ],
        [
            "Gradient cheaply.",
            "So here's a schematic picture of coordinate descent applied to a very simple two variable function.",
            "In fact, there's two functions here and you can see that the steps indicated by the red path are moving either horizontally or vertically according to the axis direction.",
            "So you typically see this sort of zig zag."
        ],
        [
            "King behavior.",
            "Now there are many extensions of this basic idea.",
            "You can instead of looking at single components, you can look at blocks of variables, and in fact there are many interesting methods in this community where you just break the variables into two blocks and take steps alternately between the two blocks.",
            "You can also apply these methods when there are some sort of constraints on the variable.",
            "So for example, for example if you got bounds on X, or if you got constraints that are separable with respect to the blocks, you can do that.",
            "You can do these these things.",
            "So convergence for these methods, actually the convergence analysis is surprisingly recent as far as I can tell, linear convergence rates for these methods have only been proved in the last few years, both for deterministic and stochastic variance, but I could be wrong about that.",
            "There could be some old papers are hiding in the literature that prove linear convergence rates, but the ones I could find were only from the last couple of years."
        ],
        [
            "So OK, first topic or maybe fifth.",
            "I've lost count, but regularization, so I've already talked a lot about regularization about adding on this function that induces some sparsity in the solution, and I've already mentioned most of these examples.",
            "I'll mention one more and that's group sparsity, so this is the case where the if you got an unknown X the components of X are not independent, they could represent, for example, the coefficients in a wavelet expansion.",
            "So they could sort of have some sort of hierarchical.",
            "Relationship that's defined by a tree.",
            "And so when you're looking for structure in that solution, you're not necessarily looking just for sparsity, but you're looking for some sort of subset of X of the components of X to be non zero at a time.",
            "OK, so for example, in the wavelet ICS expansion you might be looking for the non zeros and X to correspond to a subtree in the tree that describes the relationships between the coefficients.",
            "So all of these sorts of structures that I've talked about.",
            "If you formulate them in a naive way, you typically get an intractable optimization formulation.",
            "So if you explicitly try to put a bound on the number of nonzeros, you'll typically get an intractable problem.",
            "But as we've already noticed, there are ways to add functions to the formulation.",
            "That sort of end."
        ],
        [
            "Giving you a tractable problem that often has this sort of structure that you're looking for.",
            "So of course, very famously, as already mentioned, the L1 norm has been used to recover sparsity, and I've got some more comments about this here, and in fact it was rigorously proved in the Candace Romberg Tao paper that in fact this convex reformulation under these strong assumptions on the Matrix A of the least squares problem actually gives you.",
            "The probably gives you the same solution as the intractable formulation."
        ],
        [
            "And these other structures have already discussed, so the use of nuclear norm to capture low rank matrices, the use of elementwise L1 norm.",
            "To get sparse matrices and maybe combinations of that this is the discrete version of the total variation norm, which tends to give you sort of naturalness and images and then groups past norms.",
            "You often can get regularizers that give you group sparse solutions by forming two norms of the sub vectors of X that correspond to a group of variables and then just summing all those up across all the groups.",
            "Very similar to the one norm."
        ],
        [
            "OK, so what's the point of talking about that?",
            "Again, the point is that these algorithms that I mentioned a moment ago for minimizing smooth functions there can be extended to this formulation where you've got a smooth function plus a regularization term.",
            "By this very simple device of a shrink operate.",
            "OK, so if you've got a method that takes a step in X for example, it steps in the negative gradient direction.",
            "You can modify that method to work for this regularizer function by the following device.",
            "First of all, you notice that if you have just dealing with F, you can express the step X minus Alpha G as the minimizer of this quadratic.",
            "OK, so X plus is.",
            "The is the value of Z that minimizes this very simple unconstrained quadratic.",
            "Now, if you now you want to take account of the regularizer size so all you do is take this min problem, this subproblem that gives you the next iterate and add on site multiplied by Lambda, which is the regularization constant and also multiplied by Alpha, which is the which is the step length you want to take.",
            "So now instead of just minimizing a quadratic, you minimize a quadratic plus the regularizer.",
            "Now, if that's a tractable problem, if that's a simple problem, this gives you a very simple way of extending your favorite algorithm, accelerated gradient, stochastic gradient, whatever.",
            "From the smooth case to this regularize case.",
            "And all you have to do is solve this problem at each iteration for many of the regularizers that I talked about, particularly L1 norm, it's very easy to solve this subproblem.",
            "It's it's sort of an order N operation."
        ],
        [
            "And so this is a practical way of extending.",
            "You know, projected gradient ideas to this to this setting.",
            "So this sort of setting can be used to enforce constraints.",
            "You can simply define site to be the indicator function of a constraint, set Omega, and in this case the shrink already just becomes a projection underwear mega.",
            "So you recover projected gradient is a special case of this.",
            "Of this technique, and as I just mentioned, this whole collection of interesting methods for smooth problems can be extended to regularize."
        ],
        [
            "Problems using this device OK. Newton's method alright.",
            "This is the fifth of the six tools I wanted to talk about.",
            "Newton's method is the sort of Canonical higher order method for minimization.",
            "So again, if we go back to thinking about a smooth function F, if you write down a second order expansion of F, the 1st three terms from the Taylor series, that gives you an approximation in the vicinity of the current iterate X.",
            "If you minimize that approximation, and if the Hessian is positive definite, you can actually explicitly figure out what the step D is, and you can do it.",
            "You can just take the.",
            "Write down the optimality conditions for this quadratic and set them to zero OK and you get a set of linear equations that you can solve to find the Newton step.",
            "So the difficulty with with applying this usually is that the Hessian is often hard to calculate, soften, expensive and it can be expensive to solve this system, but."
        ],
        [
            "Of course, this is just a launching point for a whole family of methods that don't require you to compute the gradient exactly, or to solve the system.",
            "For example, quasi Newton methods the technique LBF GS is probably known to many of you.",
            "It doesn't ever explicitly calculate the hash and but it uses grading information to sort of build up knowledge of the hashing, and it uses an approximate Hessian to take modifications of the gradient step.",
            "There are inexact Newton methods where you maybe do compute the Hessian, but you only solve that system in exactly.",
            "In fact, you can implement these methods without ever having to compute a hash and just using finite difference of gradients to approximate Hessian vector multiplies their approximate methods where you maybe do a sample approximation to the Hessian.",
            "And the other thing which is important in this setting is that very often in data analysis problems, the solution that we're looking for lies on a very low dimensional manifold of a high dimensional space.",
            "And so.",
            "Rather than applying a second order method on the full space, you can wait until your first order algorithm has identified in sort of the interesting part of this space, interesting subspace, and then start taking higher order steps on that reduce space, and that might be much more practical.",
            "It might be much cheaper to get higher order information on a subspace, and it is on the full space, and so there are sort of a lot of interesting to phase."
        ],
        [
            "Methods basically use that strategy.",
            "Then the last of the topics I wanted to mention was augmented Lagrangian, which is the launching point for the method of multi for Adm app.",
            "So.",
            "There's a very nice derivation of augmented Lagrangian, which I unfortunately don't have time to tell you about it.",
            "I'm just going to write down the formulas, so if you've got minimization of a smooth function subject to the set of linear constraints, you can write down this Lagrangian function which combines the objective and the constraints in this linear relationship here, and brings in elies LaGrange multiplier vector Lambda also includes a penalty term which penalizes violations of the constraints, and then you go into this loop where you fixed Lambda.",
            "You fix row the penalty parameter.",
            "You minimize with respect to X OK and then having done that you then update the lambdas.",
            "You update your estimate of LaGrange multipliers and continue.",
            "And maybe you adjust the penalty parameter row depending on how much progress you make.",
            "So very simple approach.",
            "This extends in a straightforward way to inequality constraints to nonlinear constraints.",
            "The idea seems to go back to 1969 and these are some people that have worked a lot on that in this area."
        ],
        [
            "So HMM, basically applies this method, but it tweaks it for for problems and constraints with certain special structure and the structure that we're looking for in a DMM is the situation where the variables in the objective and or the constraints almost can be separated out.",
            "You can almost tear the problem apart into a bunch of independent problems, but not quite.",
            "There's something that sort of couples them together and so here is an illustration of that.",
            "Suppose you have a problem.",
            "Where the sort of two groups of variables, X&Z and the objective function is completely separable in X&Z, you can break it out into an F of X plus in each of Z, but the X&Z appear together in the constraints that they are coupled through the constraints.",
            "OK, now if you write down that augmented Lagrangian from the previous slide for this problem, you get this picture.",
            "You get this formula here and now if you apply the standard metal Lagrangian method at every iteration, what you have to do is to minimize L jointly with respect to X&Z.",
            "OK, but in a DMM you don't do that.",
            "You minimize just with respect to X, fixing all the other variables, and then you fix X and then minimize with respect to Z OK, and that's where the alternating comes from.",
            "You alternate between X&Z, Minimizations and then you update Lambda as before.",
            "So this approach is useful when it's easy to minimize with respect to X&Z separately this Lagrangian, but hard to do it jointly.",
            "And there are a lot of applications."
        ],
        [
            "Have that flavor.",
            "So hmm, it actually traces its roots way back into the 50s, but there was this important paper in 1992 by you came from John Eksteins thesis with Dimitri Bertsekas and they published a paper and I remember seeing this paper in preprint form and it was.",
            "Reasonably well known in the optimization community and you know, we all knew it, but it just sort of sat there for about 15 years and then suddenly when people in machine learning and compressed sensing and data analysis discovered this technique, you can see it.",
            "Citation statistics have sort of skyrocketed in the last few years.",
            "So it's."
        ],
        [
            "It's become a very important method.",
            "So here's one instance of applying a DMM.",
            "If you've got a problem where you're trying to minimize an objective where X is, it has to belong to an intersection of a bunch of sets, convex sets, and it could be that minimizing over a single constraint set is easy, but minimizing over the intersection is hard.",
            "So what you can do to apply a DMM is you can make a bunch of copies of the of the variable X.",
            "You can copy it into M different copies and assign one copy to each constraint set.",
            "And then you can just add this constraint to the formulation that basically said all the copies have to be the same.",
            "OK, so this equality constraint formulation is identical to the original formulation.",
            "So if you now go ahead and apply a DMM to this.",
            "To this.",
            "So this reformulation what you find is that the minimizations with respect to the XI to the copied variables can all be done independently in parallel, and they're all simply minimizations of a quadratic over a single constraint set.",
            "And then when you have to minimize over X, you basically got an unconstrained minimum involving the function F. And so you can alternate between these.",
            "You can adjust the LaGrange multipliers and ultimately if you set things correctly, you can get a convergent method where."
        ],
        [
            "Subproblems are easy to solve.",
            "OK, so let me say a few words about matching the tools that I've talked about to the applications I talked about at the start and I won't have time to go over these slides in detail, but I refer you to the slides if you're interested in chasing up the references.",
            "The point I'm trying to make here is that the tools that I told you about can all be applied to those problems I mentioned at the start.",
            "They can be combined in weird and imaginative ways, and there's a huge literature on this by now, and I've tried to cite in each case some sort of representative paper.",
            "I'm sure it's not the best one, but.",
            "It's what I could come up with based on a search, so of course the linear regression problem has been around forever, and in fact Rogers talk yesterday.",
            "One of the examples he gave of Hadoop implementation of a data analysis problem was in fact the large least squares problem as sort of a stochastic gradient method.",
            "Variable selection and compressed sensing.",
            "That's really been a happy hunting ground in the last few years for all kinds of men."
        ],
        [
            "That's support vector machines of course have been a lot of very imaginative applications of the techniques that are discussed in many different combinations to that area.",
            "Similar for logistic regression, particularly in the last few years.",
            "There's been a lot of literature on that.",
            "Matrix completion hasn't been around very long, but again, many of the techniques I've mentioned have been applied in different combinations."
        ],
        [
            "Inverse covariance again is only been around since about 2008, but people have proposed accelerated gradient techniques, coordinate descent, admn techniques, deep belief networks to casted gradient is extremely popular there.",
            "More recently there's been some work on doing higher order methods on reduced subspace is particularly also I think of pre training and deep belief networks is a kind of coordinate descent method in pre training is your only letting the parameters for one layer of the network change.",
            "And that's sort of like coordinate descent, where you're just letting one block of variables change.",
            "Image processing again.",
            "Many of these techniques have been applied, some citations there, and data assimilation.",
            "As I said, a different community from this, but it's one that you know it might be worth getting involved in a little bit because there's a lot of interest there, and I said as I said."
        ],
        [
            "Coming up with good coverage models.",
            "So in the last 10 minutes or so 10 minutes.",
            "Is that OK in digital?",
            "OK.",
            "I'll try to do it in 10.",
            "OK, so I'll try to say something about some some recent stuff that we've been doing with the group at Madison on multicore asynchronous methods.",
            "Alright, so these are methods that have been around in some form for a long time, and if you had gone to an optimizer five or six years ago and said, you know I'm going to work on coordinate descent, they'd sort of say, well, aren't these really old, slow, simple sort of boring methods?",
            "In fact, the latest edition of my book with not So in 2006 we have some stuff about coordinate descent, but it's sort of.",
            "Fairly dismissive in tone, I would say alright.",
            "But in fact it's turned out that these methods have found a lot of interesting applications in this community.",
            "Sure, they're slow if you do them on a serial processor, but often there are good fit for multicore clastic computers.",
            "Simple, well, So what simple is good?",
            "And it turns out a lot of the analysis is not so simple, particularly if you're trying to analyze the performance on on models of parallel computation.",
            "And also if you make sort of different assumptions about the data, whether it's streaming or batch or whatever, and of course they are old, but now they're being retool for asynchronous implementation and there's a lot of new analysis and a lot of new heuristics have to go into making them work.",
            "So I want to mention there's a quote my colleague Bill drop my former colleague from Argonne gave a plenary at the Siam Computational Science Meeting in February where he said Asynchronicity is the key to speed up on modern architecture.",
            "So we've tried to emphasize that in.",
            "In Al variance on these methods we tried to to devise them so that they can run asynchronously and we can still get so."
        ],
        [
            "Sort of interesting analysis.",
            "So firstly, some work that I did with Ben Recht and Chris Ray and other colleagues at at Argonne.",
            "Uh, sorry at Wisconsin on the stochastic gradient methods.",
            "So just reminding what stochastic gradient is.",
            "This is where F is the sum of a bunch of functions FI and we estimate the gradient by selecting one eye at random and taking a step in that direction.",
            "So there are many ways to parallelize this.",
            "It looks very sequential as it's written, but there was a lot of interest in the last few years at paralyzing it.",
            "This idea of letting if you've got a multicore architecture.",
            "You let the cause take turns and updating X where X is stored in some central central iaccessible location.",
            "This idea of averaging where you let each of the cores or each of the processes evaluate a bunch of gradients and then aggregate all that information and then take a step we came up with this asynchronous method where."
        ],
        [
            "We just let each processor basically run independently, run a stochastic gradient process so each core is picking an element IK from from the range one to M. It's reading extra memory, it's evaluating the gradient of FIK.",
            "And then it's updating those components of the gradient that it just calculated.",
            "And they're they're not trying to coordinate.",
            "They're all doing this independently.",
            "So of course, when this happens, you're going to get different cores treading on each others toys, and by the time you get in the gap between you reading X and and and the time you update it, other cores would have had their turn it updating X, and so the information that you're using to update by the time you actually use it, it's it's all right.",
            "It could be, say, up to tower cycles.",
            "All we assume there's a bound and how old it can be.",
            "However, a lot of these applications of stochastic gradient, the individual gradients are often quite sparse.",
            "OK, if you look at the gradients of HFI in many applications, I've only got 2, three, you know five non zero elements, and so this problem of different cores overriding each others work usually is not.",
            "For that reason it's often not very.",
            "It's not a very serious problem and so we can still analyze the speed of convergence of these methods by assuming that is not too much overlap.",
            "So we can introduce some quantities Ro I.",
            "So RAW is the number of indices J such that FI&FJ have overlapping support and then roll bar is some sort of average of all the row wise.",
            "It's some sort of rate average rate of overlap.",
            "So if robot is close to one, you've got a situation where the different FIS are not don't have don't generally have common support.",
            "If sorry for those close to zero, they don't have much common support.",
            "If it's close to one and they do have a lot of support and that's easy, that's more diffic."
        ],
        [
            "To parallelize, so we have pages of analysis.",
            "It was recently simplified by Peter Richterich.",
            "It's sort of ugly, but a lot of these constants have appeared earlier in the slides.",
            "I've had mu, which is the lower bound on the basically the modulus of strong convexity.",
            "M Big M is abound in the gradient.",
            "The uniform gradient are bound little M as a number of gradient cell is a Lipschitz constant, and so on.",
            "Towers of delay parameter.",
            "So the moral here is that there is a constant choice of step link that you can take.",
            "In this asynchronous process, and there's also about in the number of iterates you need to achieve a target a given target error.",
            "OK, and you can actually analyze this using this model of computation.",
            "Using these assumptions about the amount of overlap so you can see that Roo bar this quantity that quantifies how much overlap there is between the support, it appears in the iteratee down.",
            "So if Roo Bar is close to one then you have to take more.",
            "Iterative is close to zero, you don't actually pay a very big price for running this asynchronously, so you can still recover a kind of a 1 / K convergence rate which is the classical convergence rate for STD that can be preserved in the asynchronous implementation provided you have these.",
            "Extra assumption satisfied."
        ],
        [
            "And we got some performance of this was from a NIPS paper from the end of 2011, and I should point out that these other methods doing round Robin taking turns doing averaging a gradient in different circumstances.",
            "These work well, but we had problems from SVM from matrix completion from graph cuts where the individual FIS were very, very simple, and in that case the asynchronous approach is best.",
            "In the case where the individual FIS are more complicated, these other techniques are much more competitive generally."
        ],
        [
            "I've got we got speedups on a 10 core machine, sometimes up to up to."
        ],
        [
            "Nine almost.",
            "OK, so this is some your work and asynchronous coordinate descent.",
            "So again to remind you here, we're just trying to minimize the function F. We're picking a component of exit random and where evaluating the gradient with respect to that component.",
            "And then we're just taking a step in that component using that gradient.",
            "OK, so the big the big trick here is choosing gamma, the step length, gamma, and the game is to come up with a gamma such that when you run this asynchronously this is being run in just the way hog wild was, each processor is independently doing its thing.",
            "But the game is to choose gamma so that you can still prove some sort of convergence rate.",
            "And again, I'm going to use the same sort of model as I did in Hog Wild, where we're assuming that no more than tower cycles passed between when you read X and when you get to do the update, OK, Tau is typically related to the number of cores that you're dealing."
        ],
        [
            "So again, to do the the analysis of this is again very technical and it depends on a lot of constants that characterize the properties of F. So here the key seems to be the what I call the diagonal ecity.",
            "Actually my student Jilu came up with this term and I'm not sure if he meant to say this, but I sort of latched onto it as an interesting term.",
            "Dying listening basically is a measure of the degree of diagonal dominance of the hashing.",
            "So L Max is the maximum element on the diagonal of the Hessian, L raises the maximum Royal.",
            "You want the ratio valras to all Max to be small, close to one OK, and if that's the case then you've got a hash and it's sort of diagonally dominant.",
            "Its maximum is square root of N. If it's square root of N, then the whole thing is harder to parallelize."
        ],
        [
            "So in this picture here, this is the same picture I showed you earlier.",
            "The image on the left has basically you want the.",
            "The principle components of the contours of the ellipse ellipse oil contours to more or less line up with the coordinate axes OK, and if that's the case, you've got the parallelism is easier.",
            "You can paralyze this to higher degree in the case on the right where they don't line up with the axes very well.",
            "That tends to be slower.",
            "OK."
        ],
        [
            "So again, the analysis is very complicated, but it all boils down to a very simple requirement where trying to choose the step length so that the change in the expected size of the gradient.",
            "Of course, the gradient hopefully is going to zero as either it's progresses.",
            "We're approaching a solution, but we want the change in the expected gradient to not be very much from one iteration to the next.",
            "OK, now that might be surprising.",
            "You might say, well, I don't.",
            "Wouldn't you be happy if you had a method that made a big change in the gradient that got much closer to 0 after one step.",
            "Well, the answer is no, because if you're trying to run this asynchronously, if one step makes a big improvement of the gradient, then when the other cores come in and do their updates, they're all using this irrelevant information.",
            "So you be using information from when the gradient is large, and they might actually make they might actually mess things up again, so we're looking to make sort of slow, steady progress in decreasing the gradient, so we want to pick this constant row, and we want to make sure that the change in the grading is within is between one over rho and rho, so that's the principle that guides the selection of the of the step gamma.",
            "And in the end we can show that you can choose a gamma, that sort of threads the threads the.",
            "Threads the needle between being too fast and too slow and you can end up getting."
        ],
        [
            "Sort of linear convergence rate in the expected error.",
            "That sort of comparable to the right that you get from steepest descent when you allow for the fact that the cost of a stochastic coordinate descent update is about one over end of the cost of a steepest descent update, you get a sort of a consistent convergence rate."
        ],
        [
            "And we work with our colleagues Chris Ray and students Victor Bit off and and Christmas reader and we got the we ran this on a 40 core machine recently and basically we see that for this little test problem when you run it up to 40 cores, the number of iterates you need to converge is basically doesn't change so that the graph on the left is very boring.",
            "There's no.",
            "Basically, you just need the same amount of work, but the speedup actually is not quite linear because there are sort of memory contention affect, so we get speedups of up to about 20."
        ],
        [
            "26 or so in a 40 core machine.",
            "So if I have maybe two more minutes, is that alright?",
            "OK, I just want to say something at the end about very large scale linear programming because this was something that I worked on way back in the late 80s and my colleagues in Madison.",
            "All the mega Sarah and also worked on this.",
            "We basically took the basic linear programming problem, an applied augmented LaGrange into it, and I've told you what elemental Lagrangian is already, so that gives you quadratic programming subproblems.",
            "OK, that basically look like this.",
            "We"
        ],
        [
            "That an extra term on the end here, which also is a term that penalizes how far you move from your latest estimate of the solution.",
            "So basically we're taking LP and expressing it as a sequence of bound constrained convex quadratic programs, and when we did this back."
        ],
        [
            "In the 80s and we generated random LP's, it seemed to work OK.",
            "It seems to be promising, but when we took real LP's from a real test set it was incredibly bad.",
            "Not at all competitive with with simplex methods and then more recently interior point methods."
        ],
        [
            "However.",
            "Chris Ray sort of was convinced that if you took this approach and applied it to very large LP's that come from relaxations of very large combinatorial problems, it might be.",
            "It.",
            "Might have a place OK and and maybe this is a plausible scenario because often for these rounded LP approximations you don't need a highly accurate solution.",
            "Accrued solution is perfectly OK. Also, this approach never needs to do matrix factorization so.",
            "Potentially you can deal with much bigger problems and so for those reasons we thought at least it was worth trying.",
            "So one example, we ran it on.",
            "This is the easiest one to describe as vertex cover.",
            "So if you got a very big graph bunch of vertices V bunch of edges E, you're trying to choose a subset of the vertices such that every edge is touched by at least one vertex in the subset.",
            "So you can write this down as a binary program like this where the the Unknowns XV are constrained to be binary variables.",
            "You can relax it to an LP, you can solve the LP and then sort of collapse it back to a feasible solution for the integer program.",
            "So when we do that."
        ],
        [
            "We're able to take these graphs and solve this problem with the number of variables going up into the millions couple of million, and we're able to get this is, by the way, is after we've done a pre solve step, which is a which doesn't do any optimization but able to."
        ],
        [
            "I'm a lot of variables and we compare that with standard.",
            "Simplex method from the seaplex solver.",
            "Very well known commercial solver.",
            "And we're able to get solutions about sort of 10 times faster.",
            "But more importantly, for the large problem, we're able to get a solution where Seaplex wasn't able to solve it within an hour."
        ],
        [
            "So there is some promise in this application, so this is the end.",
            "I've sort of I've given you.",
            "I think a bit of a whirlwind tour of Canonical applications, fundamental optimization tools tells you a bit about how they match up.",
            "I want to make the point that this is not at all an exhaustive summary, as many of you know, there are many other areas that are potential or current applications of optimization, But I hope I've demonstrated that the optimization toolkit is a very important resource in in addressing the problems that that you have in this Community.",
            "Thank you very much for your attention."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I wanted to say a little bit today about as integer indicated, the intersection between optimization.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And and.",
                    "label": 0
                },
                {
                    "sent": "Data analysis and learning problems and my slides are on the web.",
                    "label": 0
                },
                {
                    "sent": "By the way, if you can find my homepage which shouldn't be too hard, there's a prominent link at the top to this slide deck.",
                    "label": 0
                },
                {
                    "sent": "So if you want to download it, follow along or ambush me at some point.",
                    "label": 0
                },
                {
                    "sent": "Feel free to do that.",
                    "label": 0
                },
                {
                    "sent": "This summarizes my theme and that is that the field of optimization I think provides a powerful toolbox of techniques for addressing data analysis and learning problems, and I should mention that the particular requirements of these problems are driving a lot of new research and optimization, and the new work isn't just being done in their core optimization community.",
                    "label": 1
                },
                {
                    "sent": "Much of it is being done by you by you guys in the machine learning data analysis Community.",
                    "label": 0
                },
                {
                    "sent": "Another interesting feature of this is that there's some old algorithmic work which was sort of sitting on the shelf for years that suddenly been found to be very useful again.",
                    "label": 0
                },
                {
                    "sent": "So there are several techniques that I'll talk about that have sort of burst back into prominence and, and also, as I mentioned at the end of the talk, if I have time, there are sort of interesting intersections with with work in systems and databases and so on.",
                    "label": 0
                },
                {
                    "sent": "Alright.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so this is the outline of the talk.",
                    "label": 0
                },
                {
                    "sent": "I want to talk first about some Canonical formulations of of problems in data analysis and machine learning.",
                    "label": 1
                },
                {
                    "sent": "These are problems that are probably majority of them will be familiar to most of you, but I'll just sketch the more briefly and mention in particular how they're written as optimization problems.",
                    "label": 0
                },
                {
                    "sent": "So this is material that probably will be familiar with.",
                    "label": 0
                },
                {
                    "sent": "Then I'll talk about I sort of focus on 6 particular tools from optimization that are being used to address a lot of these problems, and a lot of the other problems that come up in the area, such as the ones I saw in the at the poster session last night.",
                    "label": 0
                },
                {
                    "sent": "And then I'll briefly talk about how the techniques are being matched with the application.",
                    "label": 1
                },
                {
                    "sent": "So I've got a couple of slides where I have some representative publications that show how the optimization tools are addressing the formulations that I talked about in Part one, and then at the end I'll talk about some new work that we've been doing on asynchronous multi core algorithms of stochastic gradient and coordinate descent type, and if there's still time at the end, I'll talk about some very recent work that we've done at Wisconsin on applying these methods too.",
                    "label": 0
                },
                {
                    "sent": "Linear programs of large scale, particularly problems, are linear problems that arise in in data analysis type applications.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Alright.",
                    "label": 0
                },
                {
                    "sent": "OK, so here's my laundry list of of Canonical problems that I'll just go over very quickly.",
                    "label": 0
                },
                {
                    "sent": "Linear regression, variable selection, compressed sensing, support vector machines, logistic regression, matrix completion, estimation of sparse inverse covariance matrices, little bit about deep belief networks, image processing and then data assimilation, which probably isn't such a big topic in this community, but still is an extremely important in.",
                    "label": 1
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Essence of big data.",
                    "label": 0
                },
                {
                    "sent": "So linear regression.",
                    "label": 0
                },
                {
                    "sent": "In a sense, this is the granddaddy of all data analysis problems and you will know that you know the setup is that you've got a bunch of feature vectors, AI living in RN.",
                    "label": 0
                },
                {
                    "sent": "You've got a bunch of outcomes and you're seeking a weight vector X such that when you wake the features with the components of X, you approximately predict BI.",
                    "label": 0
                },
                {
                    "sent": "So one way to find X is to write down an objective function which consists of the sum of squares of the discrepancies and so you end up with his classic linear least squares problem.",
                    "label": 0
                },
                {
                    "sent": "If you want something more robust, you can instead take the vector of discrepancies and take an L1 norm that's more robust to outliers.",
                    "label": 0
                },
                {
                    "sent": "And then there's the Huber function, which is a sort of a combination of L2 and L1.",
                    "label": 0
                },
                {
                    "sent": "The thing to note about all these is that they're separable functions, so all of them are sums from one to M and each terminus.",
                    "label": 0
                },
                {
                    "sent": "I'm involves a single item of data, and that sort of structure is.",
                    "label": 0
                },
                {
                    "sent": "Is a recurring theme in data analysis that of course the algorithms.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To exploit.",
                    "label": 0
                },
                {
                    "sent": "It's always been of interest to look for sparse solutions to regression problems.",
                    "label": 0
                },
                {
                    "sent": "That is, look for vectors X that only have a relatively few non zeros because that tells you which of the features are important in doing the classification, or regression or whatever task you're doing.",
                    "label": 0
                },
                {
                    "sent": "And so there's this classic paper in the statistics literature from Tibshirani which points out that you can do this by introducing A1 norm into the formulation of 1 norm of X, and you can either add a multiple of the one norm onto the sum of squares objective, or you can impose it as a constraint either way, for appropriate choices of the parameters Lambda and T, you'll get an X which has relatively few non zeros.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now compressed sensing this has been an area that's sort of exploded into prominence across multiple communities.",
                    "label": 0
                },
                {
                    "sent": "Statistics, signal processing, applied math and optimization also got involved, and really the formulation of compressed sensing is identical to last suit.",
                    "label": 1
                },
                {
                    "sent": "Formally, it looks the same, but the properties of the Matrix A are typically different in compressed sensing applications in a lot of feature selection applications, a typically has more rows and columns and compressed sensing.",
                    "label": 0
                },
                {
                    "sent": "It's often the other way around these system ASC.",
                    "label": 0
                },
                {
                    "sent": "Equals B is underdetermined, but you have some prior knowledge that the vector X is sparse or approximately sparse.",
                    "label": 0
                },
                {
                    "sent": "That is only a few significantly nonzero components in act, and your goal is to recover X as it always is to get to try to get that perspective back by solving some sort of problem.",
                    "label": 0
                },
                {
                    "sent": "In this case an optimization problem.",
                    "label": 0
                },
                {
                    "sent": "Now typically in compressed sensing, A is also assumed to have this special property called restricted isometry or incoherence, and basically what that property is is if you take narrow column sub matrices of a, they tend to be well conditioned, so that's that turns out to be very important.",
                    "label": 1
                },
                {
                    "sent": "And the idea is that you can recover.",
                    "label": 0
                },
                {
                    "sent": "There's a theorem.",
                    "label": 0
                },
                {
                    "sent": "This paper of famous paper candles, Romberg and Tao from 2006 that says that if a has this nice property and if the true solution X is sparse, you can actually recover X by solving this optimization problem, even when the number of rows of A is much smaller than dimension of X.",
                    "label": 1
                },
                {
                    "sent": "So in other words, you just have to make some a very small number of observations of X.",
                    "label": 0
                },
                {
                    "sent": "The number of observations is tide mostly to the sparsity of X, the number of non zero elements.",
                    "label": 0
                },
                {
                    "sent": "And yet, even though you are sampling a vector of length in using only M observations, where M is much less than N, you can still recover the whole signal, so that's that was a very important result, and it turns out to be applicable to allow.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Areas.",
                    "label": 0
                },
                {
                    "sent": "Now support vector machines.",
                    "label": 0
                },
                {
                    "sent": "This really is a topic that I think needs no introduction, but I'll just point out here that the setup is similar to the regression case, except here instead of trying to predict a real outcome, you're just trying to predict a category one category or another in the.",
                    "label": 0
                },
                {
                    "sent": "In the binary case.",
                    "label": 0
                },
                {
                    "sent": "And so again, you've got a bunch of data vectors.",
                    "label": 0
                },
                {
                    "sent": "You're seeking a weight vector Z.",
                    "label": 0
                },
                {
                    "sent": "Change the notation a little bit here, so that extra XI transpose Y has the sign that's appropriate for its class.",
                    "label": 0
                },
                {
                    "sent": "If you're doing supervised learning.",
                    "label": 0
                },
                {
                    "sent": "So the way that this is written as an optimization problem, or certainly one way to do it, is to make up this separable penalty function, where each term is positive if the item is classified incorrectly, and zero if it's classified correctly.",
                    "label": 0
                },
                {
                    "sent": "And then as this extra term at the end, which has this function of making the hyperplane separate, the two classes as much as possible if they are separable.",
                    "label": 0
                },
                {
                    "sent": "So I think this formulation with the so called hinge loss will be familiar to many of you if you take it's a convex quadratic program, or at least it can be written that way if you take the dual of that convex QP, you get another probably equally familiar form which is given here, and this involves the kernel matrix.",
                    "label": 0
                },
                {
                    "sent": "OK is a matrix, and in the linear case K the elements of K basically consists of inner product so.",
                    "label": 0
                },
                {
                    "sent": "Of two feature vectors, but it's been known as a so called kernel trick that you can replace these inner products with the kernel function.",
                    "label": 0
                },
                {
                    "sent": "And in effect, what you're doing is projecting the feature vectors into some high dimensional space before you do the classification.",
                    "label": 0
                },
                {
                    "sent": "And so there are.",
                    "label": 0
                },
                {
                    "sent": "You know that this was one of the sides, say one of the first areas where optimization was deployed in machine learning in the late 90s.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Logistic regression, sort of, is quite similar in many ways to classification problem, except it here not just looking for a prediction of which Class A given feature vector belongs to, but you'd like odds of it being in one class or another.",
                    "label": 0
                },
                {
                    "sent": "So you're trying to reconstruct these parameterized odds functions P plus in P minus, so that when the vector XI is in class 1P plus avec Scienze, Z is chosen so that P plus is close to one and P minus is close to 0.",
                    "label": 1
                },
                {
                    "sent": "And vice versa for the other class.",
                    "label": 1
                },
                {
                    "sent": "So by writing down a log likelihood function for that and taking the negative of that function, you end up with an objective that you can minimize to try to identify an appropriate weight vector for these weight vector Z that parameterized these odds functions.",
                    "label": 0
                },
                {
                    "sent": "You can also do this trick of adding on a multiple of the one norm in order to try to get a sparsity, so to try to home in on the features from XI that most important in constructing the function.",
                    "label": 0
                },
                {
                    "sent": "And that's very often important in practice, and you can also extend these ideas to multiple class regression.",
                    "label": 0
                },
                {
                    "sent": "In fact, the speech processing people work with a lot of classes.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Matrix completion this is another problem that's only been around for a few years, but it's a very important one and a lot of the applications that people here are interested in in the game here is that they are known as a matrix rather than a vector.",
                    "label": 1
                },
                {
                    "sent": "Again, as in compressed sensing, you know our priority that it's got some desired structure.",
                    "label": 0
                },
                {
                    "sent": "You're looking for matrices often that are low rank or maybe sparse, or maybe some combination of those things.",
                    "label": 0
                },
                {
                    "sent": "And the data that you've got to work with is some observations of that matrix.",
                    "label": 0
                },
                {
                    "sent": "A limited set of observations so they could be elementwise observations.",
                    "label": 0
                },
                {
                    "sent": "They could be some sort of more general linear combination of the components of X, but in any case you've got this vector V of observations, you've got an observation operator A and you're trying to recover X from that.",
                    "label": 0
                },
                {
                    "sent": "Now again we've got this regularization term at the end, and that's the term that sort of tries to enforce their desired structure on X.",
                    "label": 0
                },
                {
                    "sent": "So it's well known by now that if you.",
                    "label": 0
                },
                {
                    "sent": "If you use, if you define side to be the nuclear norm, that is the sum of the singular values of X.",
                    "label": 1
                },
                {
                    "sent": "You tend to get low rank solutions by minimizing this function.",
                    "label": 0
                },
                {
                    "sent": "And of course, and if you want to sparse matrix X, you can use this circle elementwise 1.",
                    "label": 1
                },
                {
                    "sent": "Normally, just sum up the absolute values of all the components of X.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Inverse covariance estimation, again spin around, maybe for five or six years, and the game here is that you're making a bunch of observations of a Gaussian random vector where the elements who got Y one through YM and they're all observing the same random variable.",
                    "label": 1
                },
                {
                    "sent": "If you form a sample covariance from that sample, you'll get a dense matrix, or almost always, but often the random variable that you're observing is actually coming from a structure where there are a lot of conditional independence is between the components, so there might there might be some graph structure that defines the dependencies between the components of why.",
                    "label": 0
                },
                {
                    "sent": "And what you'd like to do from by observing these random variables is you'd like to recover the graph structure, and one way to do that is you can take the sample covariance and look for an approximate inverse of that matrix.",
                    "label": 0
                },
                {
                    "sent": "That's also sparse.",
                    "label": 0
                },
                {
                    "sent": "So that can be written as an optimization problem by first of all, writing down the log likelihood for the inverse covariance, which is P, and then adding on this regularization term some multiple of the element wise, one norm of P and that sort of enforces.",
                    "label": 0
                },
                {
                    "sent": "Or that induces some sparsity structure on P. So this is useful and sort of recovering network structure from a bunch of observations.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Deep belief networks.",
                    "label": 0
                },
                {
                    "sent": "Of course, this is another area that's become very, very popular, and particularly I'd say in speech processing some extent in computer vision.",
                    "label": 0
                },
                {
                    "sent": "One way I like to think of delete deep belief networks is it's a way of transforming feature vectors into some alternative form that's in some sense easier to work with, easier to classify.",
                    "label": 1
                },
                {
                    "sent": "Or whatever, so here's an example from a paper of Hinton in 2007 where coming in at the bottom of this network you have a 28 by 28 pixel map of a think it's just a picture of a digit and and undergoes a bunch of transformations at each level of this network.",
                    "label": 0
                },
                {
                    "sent": "Essentially all that's happening at each layer is that there's a bunch of inputs there multiplied by a matrix to produce a bunch of outputs.",
                    "label": 0
                },
                {
                    "sent": "And the parameters in the deep belief network are simply the matrices that do these transformations, and once you get out at the top, it so happens here that what comes out at the top is another 28 by 28 pixel image.",
                    "label": 0
                },
                {
                    "sent": "Of course, generally the shape of the output is different from the input in a deep belief network.",
                    "label": 1
                },
                {
                    "sent": "Here it happens to be the same.",
                    "label": 0
                },
                {
                    "sent": "But the and hopefully the thing that comes out at the top is in some sense easier to classify.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I can run an SVM or do some other something simpler with the output features.",
                    "label": 1
                },
                {
                    "sent": "So the point.",
                    "label": 0
                },
                {
                    "sent": "So I want to make about these networks are firstly that again you tend to get when you're training these networks.",
                    "label": 0
                },
                {
                    "sent": "When you're trying to identify the parameters.",
                    "label": 0
                },
                {
                    "sent": "In this case the matrices W1W2.",
                    "label": 1
                },
                {
                    "sent": "You again typically have a separable objective where there's one term in the objective for each item of data.",
                    "label": 0
                },
                {
                    "sent": "Each character, each utterance, and so on.",
                    "label": 1
                },
                {
                    "sent": "Another feature of these networks is that they each layer tends to be very simple.",
                    "label": 0
                },
                {
                    "sent": "It could be a linear transformation, a sigmoid or softmax or something.",
                    "label": 1
                },
                {
                    "sent": "So each layer is simple, but when you compose them one on top of the other, the resulting function becomes very nonlinear, very nonconvex, and so and therefore hard to deal with for certainly from an optimization viewpoint.",
                    "label": 0
                },
                {
                    "sent": "And also very often in these applications too, you want to do some sort of regularization.",
                    "label": 0
                },
                {
                    "sent": "You want to impose some kind of structure on the solution, and the solution in this case of the parameters that define each layer.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Image processing OK, so this takes off from the observation that natural pictures are not random.",
                    "label": 1
                },
                {
                    "sent": "So you when you look at these two pictures, you'll see very clearly that the one on the left is just white.",
                    "label": 0
                },
                {
                    "sent": "Noise is really no information in that the one on the right looks more like a natural image in that you've got these large areas where the color is constant.",
                    "label": 0
                },
                {
                    "sent": "You've got these sort of edges that separate different regions of different colors and so on.",
                    "label": 1
                },
                {
                    "sent": "But often an image processing you presented with a blurred or noisy picture and you want to remove the noise and remove the blur and recover a natural image.",
                    "label": 0
                },
                {
                    "sent": "And you can use this knowledge is this knowledge of what is a natural image to do that to help in that task?",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So how do you do that?",
                    "label": 0
                },
                {
                    "sent": "Well, as a classic paper, that's now 20 ideas old where they introduced the concept of total variation regularization.",
                    "label": 1
                },
                {
                    "sent": "And so here they say that natural images 1 where if you have got an image map here you which basically Maps the unit square to some intensity map or color map.",
                    "label": 0
                },
                {
                    "sent": "In images natural if when I take spatial derivatives of you that is a differentiated in both X&Y directions.",
                    "label": 0
                },
                {
                    "sent": "To get this gradient here, take the two norm of that vector and then integrate that quantity over the entire image space.",
                    "label": 0
                },
                {
                    "sent": "If that quantity.",
                    "label": 0
                },
                {
                    "sent": "If that measure is relatively small, then the image is natural.",
                    "label": 1
                },
                {
                    "sent": "If you've got a lot of noise in the image, this quantity will be large.",
                    "label": 0
                },
                {
                    "sent": "You'll see a lot of jumps in the derivative, but in a natural image you'll only see jumps when you've got edges in the image and the.",
                    "label": 0
                },
                {
                    "sent": "Not too many of those.",
                    "label": 0
                },
                {
                    "sent": "So if you you can write in standard as an optimization problem.",
                    "label": 0
                },
                {
                    "sent": "If you're given a noisy image F, you can write it down as a problem where you select you to be the image that minimizes this objective.",
                    "label": 1
                },
                {
                    "sent": "The first term is just a least squares loss, and the second term is this total variation that I mentioned earlier.",
                    "label": 0
                },
                {
                    "sent": "So if you apply this to this sort of classic test problem in this area, the image on the left has got a lot of noise in it.",
                    "label": 0
                },
                {
                    "sent": "When we minimize this total variation, we get the image on the right, from which most of the noise has been removed.",
                    "label": 0
                },
                {
                    "sent": "And it looks more natural.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And finally, data assimilation.",
                    "label": 0
                },
                {
                    "sent": "I wanted to mention this partly because I was just at a meeting on this topic a couple of weeks ago, but also because it's really a critical area where big Data is sort of combined with scientific computing, meteorology, PD models and so on to produce results that we all of us find extremely useful.",
                    "label": 0
                },
                {
                    "sent": "And data assimilation is really the basis of weather forecasting and weather forecasting.",
                    "label": 1
                },
                {
                    "sent": "You've got a huge amount of data, you've got observations of the atmospheric state taken over a large.",
                    "label": 0
                },
                {
                    "sent": "Spatial area taken over a time interval, usually the last two days or so.",
                    "label": 0
                },
                {
                    "sent": "You want to assimilate all that data, put it into a PD model and figure out what the state of the atmosphere was, say, 24 hours ago, because once you figured that out, you can then just integrate the PD model forward in time, 10 days or whatever it is to get a forecast.",
                    "label": 0
                },
                {
                    "sent": "So this is what they do.",
                    "label": 0
                },
                {
                    "sent": "You know every six hours or every 12 hours they have to solve this huge big data problem that assimilates all this data and comes up with a forecast ultimately.",
                    "label": 0
                },
                {
                    "sent": "So there's a lot of physics in this.",
                    "label": 0
                },
                {
                    "sent": "There's a lot of meteorology.",
                    "label": 1
                },
                {
                    "sent": "There's a lot of scientific computing is a lot of parallel computing.",
                    "label": 0
                },
                {
                    "sent": "These things run on huge warehouses and parallel computers.",
                    "label": 0
                },
                {
                    "sent": "There's a lot of data and have also.",
                    "label": 0
                },
                {
                    "sent": "Of course, this error in the observation.",
                    "label": 1
                },
                {
                    "sent": "So in order to do a good job of the assimilation, they need a statistical model of the noise in the observations an for many, many years.",
                    "label": 0
                },
                {
                    "sent": "They only had very naive models of noise, and it's only really in the last few years that this Community has started to pay more attention to issues of estimating covariance matrices and so on.",
                    "label": 1
                },
                {
                    "sent": "And also prior knowledge is very important in this in this application.",
                    "label": 0
                },
                {
                    "sent": "So I just wanted to mention this because it is an area where the statistics and where the where the desire for better noise models is.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Driving a lot of the recent research.",
                    "label": 0
                },
                {
                    "sent": "So that finishes my very quick survey of Canonical.",
                    "label": 0
                },
                {
                    "sent": "Problems in data analysis and machine learning.",
                    "label": 0
                },
                {
                    "sent": "Of course there are many others that I didn't talk about that are equally important to the ones that I mentioned, but I think this captures a lot of problems where optimization plays an important role as a formulation tool and as a solution tool.",
                    "label": 0
                },
                {
                    "sent": "So moving on to saying a little bit about optimization tools perceive, I just want to point out at the start the properties of these problems, some sort of common or typical properties are that first of all, of course they all involve data.",
                    "label": 0
                },
                {
                    "sent": "Secondly, they involve some sort of model, and by the time it's written down as an optimization problem, the model is being parameterized by that point.",
                    "label": 0
                },
                {
                    "sent": "And this model sort of captures the relationship between the data and whatever meaning we're trying to get from it.",
                    "label": 1
                },
                {
                    "sent": "And Thirdly, there's an objective that measures the mismatch between the current model and current set of parameters and the observed data, so it measures errors between predictions and observations, and it also might incorporate the objective might also incorporate information about the prior knowledge of the solution and something about the desired structure that we're looking for.",
                    "label": 1
                },
                {
                    "sent": "So some other typical problems that are not things that we use the traditionally dealt with in optimization, that often you only need sort of a low to medium accuracy mission, and some of these these applications, because often you're minimizing some, just some sort of empirical risk function, so there's no point in accurate in solution solving it to 6 digits of accuracy.",
                    "label": 0
                },
                {
                    "sent": "The fact that we've got some prior knowledge about the parameters is something that we typically didn't have an optimization.",
                    "label": 0
                },
                {
                    "sent": "And Lastly, the fact that we're only looking we were looking for solutions that are only approximate minimizes the objective, but also have some desired structure.",
                    "label": 1
                },
                {
                    "sent": "That's another feature that optimizes of only sort of come to grips with fairly recently.",
                    "label": 0
                },
                {
                    "sent": "So in some cases, the formulation of machine learning problems as optimization problems is well settled, and some of the examples I've just given fall into that category.",
                    "label": 0
                },
                {
                    "sent": "But in other areas of course people are very interested in still working on formulations of coming up with interesting formulations, and I notice that the poster session last night there were many posters where people had had cooked up their own formulation to capture the.",
                    "label": 0
                },
                {
                    "sent": "All caps.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The thing that they were trying to the problem that we're trying to address.",
                    "label": 0
                },
                {
                    "sent": "So these are the six areas that I wanted to point out, which I think are relevant to many of the applications I discussed in many others and I just want to sketch them very briefly and then put the two things together.",
                    "label": 0
                },
                {
                    "sent": "So firstly, I'll say a little bit about accelerated gradient methods.",
                    "label": 0
                },
                {
                    "sent": "I think this is something that some of you might find useful if you don't already know about it.",
                    "label": 0
                },
                {
                    "sent": "Stochastic gradient is now a well studied topic in this area.",
                    "label": 0
                },
                {
                    "sent": "Coordinate descent methods.",
                    "label": 0
                },
                {
                    "sent": "Again, something that's been quite popular.",
                    "label": 0
                },
                {
                    "sent": "Shrinking techniques that go along with regularization.",
                    "label": 0
                },
                {
                    "sent": "Higher order methods I use higher than first order information and then a little bit about augmented lagrangians Adm.",
                    "label": 0
                },
                {
                    "sent": "I understand that Steve Boyd talked to you two years ago and he loves to talk about a DMM.",
                    "label": 0
                },
                {
                    "sent": "I'm sure he told you something about that.",
                    "label": 0
                },
                {
                    "sent": "It remains a very important topic.",
                    "label": 0
                },
                {
                    "sent": "Sold.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And it also.",
                    "label": 0
                },
                {
                    "sent": "So the first one gradient method.",
                    "label": 0
                },
                {
                    "sent": "So firstly if I give you a very simple optimization problem, that is, you want to minimize a function F. There are no constraints.",
                    "label": 0
                },
                {
                    "sent": "This function is a smooth function of a bunch of real variables.",
                    "label": 0
                },
                {
                    "sent": "You can actually get a second derivative site, or in principle you could.",
                    "label": 0
                },
                {
                    "sent": "You could get a second derivative.",
                    "label": 0
                },
                {
                    "sent": "So a first order method just makes progress on the basis of calculating the gradient of F OK and the natural thing to do.",
                    "label": 1
                },
                {
                    "sent": "If you've got the gradient of effort and given it a RTX cake, the natural thing to do is just to move in the negative gradient direction, 'cause that's the direction where the function is going most steeply downhill.",
                    "label": 0
                },
                {
                    "sent": "If you look at the contours of the function, that's the direction where the contours of sort of most closely bunched together, so you get most bang for the Buck by traveling in that direction.",
                    "label": 0
                },
                {
                    "sent": "So totally reasonable thing to do to move from XC2X K plus one.",
                    "label": 0
                },
                {
                    "sent": "You just take a step of like the Alpha K negative gradient direction.",
                    "label": 0
                },
                {
                    "sent": "Now, if you actually know something more about this function, if you know that the hash and the second derivative matrix has eigenvalues that are bounded between you and L view is a lower bound, and I'm sure I'll assume here I'm dealing with a convex function, so use greater equal to 0.",
                    "label": 0
                },
                {
                    "sent": "Then I can actually set the step length Alpha K to be simply two overview plus Li can fix it to this constant value and I can just blindly take these steps in the negative gradient direction.",
                    "label": 0
                },
                {
                    "sent": "With this given step link.",
                    "label": 0
                },
                {
                    "sent": "And without too much effort, you can prove that you can actually figure out what the convergence rate of that process is.",
                    "label": 0
                },
                {
                    "sent": "The difference between the function at XK and the optimal function X star is given by this expression times the initial error, so this expression is a number slightly less than one raised to the power 2K, and this number depends on Kappa, which is the conditioning of this function, so it's the ratio of the biggest eigenvalue L to the smallest eigenvalue mute.",
                    "label": 0
                },
                {
                    "sent": "OK, so using this complexity estimate, this is what I call a linear convergence rate.",
                    "label": 1
                },
                {
                    "sent": "Some people like to say exponential, which sounds much sexier, but you know.",
                    "label": 0
                },
                {
                    "sent": "I think linear is a bit more descriptive.",
                    "label": 0
                },
                {
                    "sent": "Using this right?",
                    "label": 0
                },
                {
                    "sent": "You can show that if you if your aim is to reduce the initial error by a factor of epsilon.",
                    "label": 1
                },
                {
                    "sent": "Then the number of iterations you need is order K, log order, capital log epsilon where captures the condition.",
                    "label": 0
                },
                {
                    "sent": "OK, so will condition problems are harder to solve.",
                    "label": 0
                },
                {
                    "sent": "The surprising thing about this very basic method is that you really can't do better than even if you take a lot more trouble to find the step length Alpha K, you do an exact search.",
                    "label": 0
                },
                {
                    "sent": "You typically don't get a better convergence rate than this very naive way of setting that the step length.",
                    "label": 0
                },
                {
                    "sent": "Now that I just sort of mentioned this math.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "By way of introduction, because there's a very simple change you can make to that method, which can dramatically improve its performance, and it uses this idea of momentum.",
                    "label": 0
                },
                {
                    "sent": "So the idea is instead of just moving from exc 8X K plus one along the negative gradient direction, you throw in a component of the previous step that you just took from XK minus one to XK, and so the net effect is that you're taking a step that has two components and negative gradient component Anna contribution from the previous step, and this idea is sort of cropped up in many different guises.",
                    "label": 0
                },
                {
                    "sent": "There's one called Heavy Ball, which is.",
                    "label": 0
                },
                {
                    "sent": "Which I have on this slide, the conjugate gradient method, which is very well known in linear algebra and to some extent optimization is essentially this kind of a method and then as accelerated gradient, which I'll talk about in the next slide.",
                    "label": 0
                },
                {
                    "sent": "So in the heavy ball method again it assumes that you know what Ellen you are.",
                    "label": 0
                },
                {
                    "sent": "These bounds on the eigenvalues of the Hessian, and you can just set Alpha kata.",
                    "label": 0
                },
                {
                    "sent": "This value beta cater this value both of them constant.",
                    "label": 0
                },
                {
                    "sent": "Notice that Alpha K If Kappa is fairly large.",
                    "label": 0
                },
                {
                    "sent": "If you got a somewhat ill condition problem.",
                    "label": 0
                },
                {
                    "sent": "Alpha K is about 4 / L beta K is sort of close to 1.",
                    "label": 1
                },
                {
                    "sent": "So most of the step is actually coming from the is just almost equal to the previous step with a little bit of a tweak to incorporate the latest gradient.",
                    "label": 0
                },
                {
                    "sent": "OK, so you can show with only about 2 slides of analysis, just a few lines of analysis, you can show that the linear convergence rate of this method.",
                    "label": 1
                },
                {
                    "sent": "Is the complexity is basically order square root of capital log epsilon rather than order catalog epsilon.",
                    "label": 0
                },
                {
                    "sent": "So if you've got a function that's gotta condition number about 100, this is going to be about 10 times faster than steepest descent and there's no extra work involved.",
                    "label": 1
                },
                {
                    "sent": "You only have to compute one gradient in each iteration.",
                    "label": 0
                },
                {
                    "sent": "You maybe have to store one extra vector, but that's it.",
                    "label": 0
                },
                {
                    "sent": "So if you're using steepest descent, if you got a smooth function, try this out.",
                    "label": 0
                },
                {
                    "sent": "Chances are you'll you'll see an immediate improvement with just a couple of extra lines of.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Code.",
                    "label": 0
                },
                {
                    "sent": "Accelerated gradient methods.",
                    "label": 0
                },
                {
                    "sent": "These have really been latched onto in learning and analysis and compressed sensing communities.",
                    "label": 0
                },
                {
                    "sent": "Image analysis communities.",
                    "label": 0
                },
                {
                    "sent": "These are basically the same idea.",
                    "label": 0
                },
                {
                    "sent": "The only difference is that the contribution from the negative gradient and the previous step are kind of torn apart.",
                    "label": 0
                },
                {
                    "sent": "So instead of combining them both into a step you take first of all, you just take a negative gradient step 1st and then you do a little bit of mumbo jumbo calculation to figure out the beta and then you take the momentum step.",
                    "label": 0
                },
                {
                    "sent": "So you sort of do them sequentially rather than together.",
                    "label": 0
                },
                {
                    "sent": "OK, and the this paper this famous paper called Pfister buy back into Bill from 2009 basically does this using a different set of formulas.",
                    "label": 0
                },
                {
                    "sent": "But it's really the same idea.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Skip over that one.",
                    "label": 0
                },
                {
                    "sent": "Alright, so that's accelerated gradient.",
                    "label": 0
                },
                {
                    "sent": "That's sort of an easy win for a lot of applications.",
                    "label": 0
                },
                {
                    "sent": "Second, topic stochastic gradient.",
                    "label": 0
                },
                {
                    "sent": "Again, this is something I think that's fairly familiar, and here we're specifically going to look at functions that are the sum of a bunch of FIS where each FI could be a loss function for a single item of data.",
                    "label": 1
                },
                {
                    "sent": "Or it could be a loss function from mini batch of data, and as I've already pointed out, this sort of structure is very common.",
                    "label": 0
                },
                {
                    "sent": "So one thing to note about this sort of objective is that it's very, very difficult to compute a function value.",
                    "label": 0
                },
                {
                    "sent": "You basically have to scan the entire data set to get a function value, so that makes any algorithm that needs to compute function values completely impractical.",
                    "label": 1
                },
                {
                    "sent": "However, you can get an unbiased estimate of the gradient very cheaply if I just select one indexi at random and evaluate the gradient of FI.",
                    "label": 1
                },
                {
                    "sent": "I've got an unbiased estimate of the gradient of the whole function F, and so I can take a step in that direction and hope to make some progress.",
                    "label": 0
                },
                {
                    "sent": "So this idea actually goes back to Robbins and Monro from 1951.",
                    "label": 0
                },
                {
                    "sent": "So it's a classical paper.",
                    "label": 0
                },
                {
                    "sent": "It was worked on a lot in the Russian literature.",
                    "label": 0
                },
                {
                    "sent": "It was worked on a lot in the machine learning literature, going back 20 or 25 years.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And again, the analysis of the fundamental method is very, very simple, but there's a beautiful paper insheim optimization by Nemerofsky ET al that I think appears in their reference list for this talk, where they summarize the relevant analysis on just a few pages at the start of the paper.",
                    "label": 0
                },
                {
                    "sent": "And here is the result.",
                    "label": 0
                },
                {
                    "sent": "Here's the basic result for the basic method.",
                    "label": 1
                },
                {
                    "sent": "First of all, if I assume that the gradients of the FIS are in some sense uniformly bounded or their average is bounded by this quantity M. If I use a K. To be the expected value of the error or the squared error, Notice I have to use expected values because this is a random algorithm.",
                    "label": 0
                },
                {
                    "sent": "Every time I run it, I'm going to get a different result because I'm going to make a different set of choices of indices.",
                    "label": 0
                },
                {
                    "sent": "So in any, so I cannot, but I can still analyze the expectation OK, and you can show with a few lines of analysis that the expected error K plus one is less than or equal to this multiple of the expected error K plus this extra term.",
                    "label": 0
                },
                {
                    "sent": "And this choice is step length.",
                    "label": 0
                },
                {
                    "sent": "Alpha K is critical here.",
                    "label": 0
                },
                {
                    "sent": "You can show that by choosing Alpha K to be 1 / K times, mew mew is a lower bound on the eigenvalues of of the Hessian of F. Then you can apply a very simple argument to show that you get a sub linear convergence rate.",
                    "label": 1
                },
                {
                    "sent": "AKA goes down like 1 / K, so it's not the sort of geometric linear rate that we saw for steepest descent accelerated gradient, but at least it's going to zero at sort of a recognizable rate.",
                    "label": 0
                },
                {
                    "sent": "You wouldn't expect a blockbuster convergence rate because you're using this very typically very crude estimate of the gradient at each step, so you wouldn't expect to get something that sort of matched steepest descent.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So there are many, many variants of this basic approach.",
                    "label": 0
                },
                {
                    "sent": "There's a variant where you sort of set a target for how low you want the expected error to do, and then try to find a constant step length that gets you there in a number of iterations.",
                    "label": 1
                },
                {
                    "sent": "There's this idea of averaging where you don't just take the latest it as your guess of the solution, but you form a weighted average of all the iterative seen so far that tends to behave more stable.",
                    "label": 1
                },
                {
                    "sent": "It tends to be less sensitive to choice of step length.",
                    "label": 0
                },
                {
                    "sent": "And there's a dual averaging idea, which is very simple way that you use the search direction to be the average of all the approximate gradients you've seen so far, not just one random gradient.",
                    "label": 0
                },
                {
                    "sent": "Again, that tends to be more stable.",
                    "label": 0
                },
                {
                    "sent": "And I just want to make the comment here that a lot of people call this method STD for stochastic gradient descent, but I actually don't like that terminology because it's not a dissent method.",
                    "label": 0
                },
                {
                    "sent": "The descent method is where F is going downhill at every iteration, and that's not happening almost never have happening here, so I just like to call it SG for stochastic grade.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, third topic.",
                    "label": 0
                },
                {
                    "sent": "Coordinate descent.",
                    "label": 0
                },
                {
                    "sent": "So again here we're just going to going to consider initially just an unconstrained minimization of a function F. The idea of coordinate descent is that, again, you pick one coordinate of X at random, or can be at random.",
                    "label": 1
                },
                {
                    "sent": "Or it could be according to some schedule.",
                    "label": 0
                },
                {
                    "sent": "But in any case, the single coordinate and you take a move just in that coordinate.",
                    "label": 1
                },
                {
                    "sent": "OK, so you could have, for example evaluate that element of the gradient vector.",
                    "label": 0
                },
                {
                    "sent": "You could do some sort of more exhaustive minimization along that component.",
                    "label": 0
                },
                {
                    "sent": "But any case you only change one component.",
                    "label": 1
                },
                {
                    "sent": "So there are deterministic variants where you go through the components of X in some fixed order, like a cyclic order through stochastic variance where you choose them at random, maybe uniformly, maybe according to some weighted ski.",
                    "label": 0
                },
                {
                    "sent": "So this is a reasonable thing to do.",
                    "label": 0
                },
                {
                    "sent": "For example, if you're able to get individual gradients cheaply, or if you're able to do the minimization over an individ.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Gradient cheaply.",
                    "label": 0
                },
                {
                    "sent": "So here's a schematic picture of coordinate descent applied to a very simple two variable function.",
                    "label": 1
                },
                {
                    "sent": "In fact, there's two functions here and you can see that the steps indicated by the red path are moving either horizontally or vertically according to the axis direction.",
                    "label": 0
                },
                {
                    "sent": "So you typically see this sort of zig zag.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "King behavior.",
                    "label": 0
                },
                {
                    "sent": "Now there are many extensions of this basic idea.",
                    "label": 0
                },
                {
                    "sent": "You can instead of looking at single components, you can look at blocks of variables, and in fact there are many interesting methods in this community where you just break the variables into two blocks and take steps alternately between the two blocks.",
                    "label": 0
                },
                {
                    "sent": "You can also apply these methods when there are some sort of constraints on the variable.",
                    "label": 1
                },
                {
                    "sent": "So for example, for example if you got bounds on X, or if you got constraints that are separable with respect to the blocks, you can do that.",
                    "label": 1
                },
                {
                    "sent": "You can do these these things.",
                    "label": 0
                },
                {
                    "sent": "So convergence for these methods, actually the convergence analysis is surprisingly recent as far as I can tell, linear convergence rates for these methods have only been proved in the last few years, both for deterministic and stochastic variance, but I could be wrong about that.",
                    "label": 0
                },
                {
                    "sent": "There could be some old papers are hiding in the literature that prove linear convergence rates, but the ones I could find were only from the last couple of years.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So OK, first topic or maybe fifth.",
                    "label": 0
                },
                {
                    "sent": "I've lost count, but regularization, so I've already talked a lot about regularization about adding on this function that induces some sparsity in the solution, and I've already mentioned most of these examples.",
                    "label": 0
                },
                {
                    "sent": "I'll mention one more and that's group sparsity, so this is the case where the if you got an unknown X the components of X are not independent, they could represent, for example, the coefficients in a wavelet expansion.",
                    "label": 1
                },
                {
                    "sent": "So they could sort of have some sort of hierarchical.",
                    "label": 1
                },
                {
                    "sent": "Relationship that's defined by a tree.",
                    "label": 1
                },
                {
                    "sent": "And so when you're looking for structure in that solution, you're not necessarily looking just for sparsity, but you're looking for some sort of subset of X of the components of X to be non zero at a time.",
                    "label": 1
                },
                {
                    "sent": "OK, so for example, in the wavelet ICS expansion you might be looking for the non zeros and X to correspond to a subtree in the tree that describes the relationships between the coefficients.",
                    "label": 1
                },
                {
                    "sent": "So all of these sorts of structures that I've talked about.",
                    "label": 0
                },
                {
                    "sent": "If you formulate them in a naive way, you typically get an intractable optimization formulation.",
                    "label": 0
                },
                {
                    "sent": "So if you explicitly try to put a bound on the number of nonzeros, you'll typically get an intractable problem.",
                    "label": 1
                },
                {
                    "sent": "But as we've already noticed, there are ways to add functions to the formulation.",
                    "label": 0
                },
                {
                    "sent": "That sort of end.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Giving you a tractable problem that often has this sort of structure that you're looking for.",
                    "label": 0
                },
                {
                    "sent": "So of course, very famously, as already mentioned, the L1 norm has been used to recover sparsity, and I've got some more comments about this here, and in fact it was rigorously proved in the Candace Romberg Tao paper that in fact this convex reformulation under these strong assumptions on the Matrix A of the least squares problem actually gives you.",
                    "label": 0
                },
                {
                    "sent": "The probably gives you the same solution as the intractable formulation.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And these other structures have already discussed, so the use of nuclear norm to capture low rank matrices, the use of elementwise L1 norm.",
                    "label": 1
                },
                {
                    "sent": "To get sparse matrices and maybe combinations of that this is the discrete version of the total variation norm, which tends to give you sort of naturalness and images and then groups past norms.",
                    "label": 1
                },
                {
                    "sent": "You often can get regularizers that give you group sparse solutions by forming two norms of the sub vectors of X that correspond to a group of variables and then just summing all those up across all the groups.",
                    "label": 0
                },
                {
                    "sent": "Very similar to the one norm.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so what's the point of talking about that?",
                    "label": 0
                },
                {
                    "sent": "Again, the point is that these algorithms that I mentioned a moment ago for minimizing smooth functions there can be extended to this formulation where you've got a smooth function plus a regularization term.",
                    "label": 0
                },
                {
                    "sent": "By this very simple device of a shrink operate.",
                    "label": 0
                },
                {
                    "sent": "OK, so if you've got a method that takes a step in X for example, it steps in the negative gradient direction.",
                    "label": 0
                },
                {
                    "sent": "You can modify that method to work for this regularizer function by the following device.",
                    "label": 0
                },
                {
                    "sent": "First of all, you notice that if you have just dealing with F, you can express the step X minus Alpha G as the minimizer of this quadratic.",
                    "label": 0
                },
                {
                    "sent": "OK, so X plus is.",
                    "label": 0
                },
                {
                    "sent": "The is the value of Z that minimizes this very simple unconstrained quadratic.",
                    "label": 0
                },
                {
                    "sent": "Now, if you now you want to take account of the regularizer size so all you do is take this min problem, this subproblem that gives you the next iterate and add on site multiplied by Lambda, which is the regularization constant and also multiplied by Alpha, which is the which is the step length you want to take.",
                    "label": 0
                },
                {
                    "sent": "So now instead of just minimizing a quadratic, you minimize a quadratic plus the regularizer.",
                    "label": 0
                },
                {
                    "sent": "Now, if that's a tractable problem, if that's a simple problem, this gives you a very simple way of extending your favorite algorithm, accelerated gradient, stochastic gradient, whatever.",
                    "label": 0
                },
                {
                    "sent": "From the smooth case to this regularize case.",
                    "label": 0
                },
                {
                    "sent": "And all you have to do is solve this problem at each iteration for many of the regularizers that I talked about, particularly L1 norm, it's very easy to solve this subproblem.",
                    "label": 0
                },
                {
                    "sent": "It's it's sort of an order N operation.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And so this is a practical way of extending.",
                    "label": 0
                },
                {
                    "sent": "You know, projected gradient ideas to this to this setting.",
                    "label": 0
                },
                {
                    "sent": "So this sort of setting can be used to enforce constraints.",
                    "label": 0
                },
                {
                    "sent": "You can simply define site to be the indicator function of a constraint, set Omega, and in this case the shrink already just becomes a projection underwear mega.",
                    "label": 1
                },
                {
                    "sent": "So you recover projected gradient is a special case of this.",
                    "label": 1
                },
                {
                    "sent": "Of this technique, and as I just mentioned, this whole collection of interesting methods for smooth problems can be extended to regularize.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Problems using this device OK. Newton's method alright.",
                    "label": 0
                },
                {
                    "sent": "This is the fifth of the six tools I wanted to talk about.",
                    "label": 0
                },
                {
                    "sent": "Newton's method is the sort of Canonical higher order method for minimization.",
                    "label": 1
                },
                {
                    "sent": "So again, if we go back to thinking about a smooth function F, if you write down a second order expansion of F, the 1st three terms from the Taylor series, that gives you an approximation in the vicinity of the current iterate X.",
                    "label": 0
                },
                {
                    "sent": "If you minimize that approximation, and if the Hessian is positive definite, you can actually explicitly figure out what the step D is, and you can do it.",
                    "label": 1
                },
                {
                    "sent": "You can just take the.",
                    "label": 0
                },
                {
                    "sent": "Write down the optimality conditions for this quadratic and set them to zero OK and you get a set of linear equations that you can solve to find the Newton step.",
                    "label": 0
                },
                {
                    "sent": "So the difficulty with with applying this usually is that the Hessian is often hard to calculate, soften, expensive and it can be expensive to solve this system, but.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Of course, this is just a launching point for a whole family of methods that don't require you to compute the gradient exactly, or to solve the system.",
                    "label": 0
                },
                {
                    "sent": "For example, quasi Newton methods the technique LBF GS is probably known to many of you.",
                    "label": 0
                },
                {
                    "sent": "It doesn't ever explicitly calculate the hash and but it uses grading information to sort of build up knowledge of the hashing, and it uses an approximate Hessian to take modifications of the gradient step.",
                    "label": 0
                },
                {
                    "sent": "There are inexact Newton methods where you maybe do compute the Hessian, but you only solve that system in exactly.",
                    "label": 1
                },
                {
                    "sent": "In fact, you can implement these methods without ever having to compute a hash and just using finite difference of gradients to approximate Hessian vector multiplies their approximate methods where you maybe do a sample approximation to the Hessian.",
                    "label": 1
                },
                {
                    "sent": "And the other thing which is important in this setting is that very often in data analysis problems, the solution that we're looking for lies on a very low dimensional manifold of a high dimensional space.",
                    "label": 0
                },
                {
                    "sent": "And so.",
                    "label": 0
                },
                {
                    "sent": "Rather than applying a second order method on the full space, you can wait until your first order algorithm has identified in sort of the interesting part of this space, interesting subspace, and then start taking higher order steps on that reduce space, and that might be much more practical.",
                    "label": 0
                },
                {
                    "sent": "It might be much cheaper to get higher order information on a subspace, and it is on the full space, and so there are sort of a lot of interesting to phase.",
                    "label": 1
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Methods basically use that strategy.",
                    "label": 0
                },
                {
                    "sent": "Then the last of the topics I wanted to mention was augmented Lagrangian, which is the launching point for the method of multi for Adm app.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "There's a very nice derivation of augmented Lagrangian, which I unfortunately don't have time to tell you about it.",
                    "label": 0
                },
                {
                    "sent": "I'm just going to write down the formulas, so if you've got minimization of a smooth function subject to the set of linear constraints, you can write down this Lagrangian function which combines the objective and the constraints in this linear relationship here, and brings in elies LaGrange multiplier vector Lambda also includes a penalty term which penalizes violations of the constraints, and then you go into this loop where you fixed Lambda.",
                    "label": 0
                },
                {
                    "sent": "You fix row the penalty parameter.",
                    "label": 0
                },
                {
                    "sent": "You minimize with respect to X OK and then having done that you then update the lambdas.",
                    "label": 0
                },
                {
                    "sent": "You update your estimate of LaGrange multipliers and continue.",
                    "label": 0
                },
                {
                    "sent": "And maybe you adjust the penalty parameter row depending on how much progress you make.",
                    "label": 0
                },
                {
                    "sent": "So very simple approach.",
                    "label": 0
                },
                {
                    "sent": "This extends in a straightforward way to inequality constraints to nonlinear constraints.",
                    "label": 1
                },
                {
                    "sent": "The idea seems to go back to 1969 and these are some people that have worked a lot on that in this area.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So HMM, basically applies this method, but it tweaks it for for problems and constraints with certain special structure and the structure that we're looking for in a DMM is the situation where the variables in the objective and or the constraints almost can be separated out.",
                    "label": 0
                },
                {
                    "sent": "You can almost tear the problem apart into a bunch of independent problems, but not quite.",
                    "label": 0
                },
                {
                    "sent": "There's something that sort of couples them together and so here is an illustration of that.",
                    "label": 0
                },
                {
                    "sent": "Suppose you have a problem.",
                    "label": 0
                },
                {
                    "sent": "Where the sort of two groups of variables, X&Z and the objective function is completely separable in X&Z, you can break it out into an F of X plus in each of Z, but the X&Z appear together in the constraints that they are coupled through the constraints.",
                    "label": 0
                },
                {
                    "sent": "OK, now if you write down that augmented Lagrangian from the previous slide for this problem, you get this picture.",
                    "label": 0
                },
                {
                    "sent": "You get this formula here and now if you apply the standard metal Lagrangian method at every iteration, what you have to do is to minimize L jointly with respect to X&Z.",
                    "label": 0
                },
                {
                    "sent": "OK, but in a DMM you don't do that.",
                    "label": 0
                },
                {
                    "sent": "You minimize just with respect to X, fixing all the other variables, and then you fix X and then minimize with respect to Z OK, and that's where the alternating comes from.",
                    "label": 0
                },
                {
                    "sent": "You alternate between X&Z, Minimizations and then you update Lambda as before.",
                    "label": 0
                },
                {
                    "sent": "So this approach is useful when it's easy to minimize with respect to X&Z separately this Lagrangian, but hard to do it jointly.",
                    "label": 0
                },
                {
                    "sent": "And there are a lot of applications.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Have that flavor.",
                    "label": 0
                },
                {
                    "sent": "So hmm, it actually traces its roots way back into the 50s, but there was this important paper in 1992 by you came from John Eksteins thesis with Dimitri Bertsekas and they published a paper and I remember seeing this paper in preprint form and it was.",
                    "label": 0
                },
                {
                    "sent": "Reasonably well known in the optimization community and you know, we all knew it, but it just sort of sat there for about 15 years and then suddenly when people in machine learning and compressed sensing and data analysis discovered this technique, you can see it.",
                    "label": 0
                },
                {
                    "sent": "Citation statistics have sort of skyrocketed in the last few years.",
                    "label": 0
                },
                {
                    "sent": "So it's.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It's become a very important method.",
                    "label": 0
                },
                {
                    "sent": "So here's one instance of applying a DMM.",
                    "label": 0
                },
                {
                    "sent": "If you've got a problem where you're trying to minimize an objective where X is, it has to belong to an intersection of a bunch of sets, convex sets, and it could be that minimizing over a single constraint set is easy, but minimizing over the intersection is hard.",
                    "label": 0
                },
                {
                    "sent": "So what you can do to apply a DMM is you can make a bunch of copies of the of the variable X.",
                    "label": 0
                },
                {
                    "sent": "You can copy it into M different copies and assign one copy to each constraint set.",
                    "label": 0
                },
                {
                    "sent": "And then you can just add this constraint to the formulation that basically said all the copies have to be the same.",
                    "label": 0
                },
                {
                    "sent": "OK, so this equality constraint formulation is identical to the original formulation.",
                    "label": 0
                },
                {
                    "sent": "So if you now go ahead and apply a DMM to this.",
                    "label": 0
                },
                {
                    "sent": "To this.",
                    "label": 0
                },
                {
                    "sent": "So this reformulation what you find is that the minimizations with respect to the XI to the copied variables can all be done independently in parallel, and they're all simply minimizations of a quadratic over a single constraint set.",
                    "label": 0
                },
                {
                    "sent": "And then when you have to minimize over X, you basically got an unconstrained minimum involving the function F. And so you can alternate between these.",
                    "label": 0
                },
                {
                    "sent": "You can adjust the LaGrange multipliers and ultimately if you set things correctly, you can get a convergent method where.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Subproblems are easy to solve.",
                    "label": 0
                },
                {
                    "sent": "OK, so let me say a few words about matching the tools that I've talked about to the applications I talked about at the start and I won't have time to go over these slides in detail, but I refer you to the slides if you're interested in chasing up the references.",
                    "label": 1
                },
                {
                    "sent": "The point I'm trying to make here is that the tools that I told you about can all be applied to those problems I mentioned at the start.",
                    "label": 0
                },
                {
                    "sent": "They can be combined in weird and imaginative ways, and there's a huge literature on this by now, and I've tried to cite in each case some sort of representative paper.",
                    "label": 0
                },
                {
                    "sent": "I'm sure it's not the best one, but.",
                    "label": 0
                },
                {
                    "sent": "It's what I could come up with based on a search, so of course the linear regression problem has been around forever, and in fact Rogers talk yesterday.",
                    "label": 0
                },
                {
                    "sent": "One of the examples he gave of Hadoop implementation of a data analysis problem was in fact the large least squares problem as sort of a stochastic gradient method.",
                    "label": 1
                },
                {
                    "sent": "Variable selection and compressed sensing.",
                    "label": 0
                },
                {
                    "sent": "That's really been a happy hunting ground in the last few years for all kinds of men.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That's support vector machines of course have been a lot of very imaginative applications of the techniques that are discussed in many different combinations to that area.",
                    "label": 0
                },
                {
                    "sent": "Similar for logistic regression, particularly in the last few years.",
                    "label": 0
                },
                {
                    "sent": "There's been a lot of literature on that.",
                    "label": 0
                },
                {
                    "sent": "Matrix completion hasn't been around very long, but again, many of the techniques I've mentioned have been applied in different combinations.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Inverse covariance again is only been around since about 2008, but people have proposed accelerated gradient techniques, coordinate descent, admn techniques, deep belief networks to casted gradient is extremely popular there.",
                    "label": 1
                },
                {
                    "sent": "More recently there's been some work on doing higher order methods on reduced subspace is particularly also I think of pre training and deep belief networks is a kind of coordinate descent method in pre training is your only letting the parameters for one layer of the network change.",
                    "label": 0
                },
                {
                    "sent": "And that's sort of like coordinate descent, where you're just letting one block of variables change.",
                    "label": 0
                },
                {
                    "sent": "Image processing again.",
                    "label": 0
                },
                {
                    "sent": "Many of these techniques have been applied, some citations there, and data assimilation.",
                    "label": 0
                },
                {
                    "sent": "As I said, a different community from this, but it's one that you know it might be worth getting involved in a little bit because there's a lot of interest there, and I said as I said.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Coming up with good coverage models.",
                    "label": 0
                },
                {
                    "sent": "So in the last 10 minutes or so 10 minutes.",
                    "label": 0
                },
                {
                    "sent": "Is that OK in digital?",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "I'll try to do it in 10.",
                    "label": 0
                },
                {
                    "sent": "OK, so I'll try to say something about some some recent stuff that we've been doing with the group at Madison on multicore asynchronous methods.",
                    "label": 1
                },
                {
                    "sent": "Alright, so these are methods that have been around in some form for a long time, and if you had gone to an optimizer five or six years ago and said, you know I'm going to work on coordinate descent, they'd sort of say, well, aren't these really old, slow, simple sort of boring methods?",
                    "label": 0
                },
                {
                    "sent": "In fact, the latest edition of my book with not So in 2006 we have some stuff about coordinate descent, but it's sort of.",
                    "label": 0
                },
                {
                    "sent": "Fairly dismissive in tone, I would say alright.",
                    "label": 0
                },
                {
                    "sent": "But in fact it's turned out that these methods have found a lot of interesting applications in this community.",
                    "label": 0
                },
                {
                    "sent": "Sure, they're slow if you do them on a serial processor, but often there are good fit for multicore clastic computers.",
                    "label": 1
                },
                {
                    "sent": "Simple, well, So what simple is good?",
                    "label": 0
                },
                {
                    "sent": "And it turns out a lot of the analysis is not so simple, particularly if you're trying to analyze the performance on on models of parallel computation.",
                    "label": 1
                },
                {
                    "sent": "And also if you make sort of different assumptions about the data, whether it's streaming or batch or whatever, and of course they are old, but now they're being retool for asynchronous implementation and there's a lot of new analysis and a lot of new heuristics have to go into making them work.",
                    "label": 1
                },
                {
                    "sent": "So I want to mention there's a quote my colleague Bill drop my former colleague from Argonne gave a plenary at the Siam Computational Science Meeting in February where he said Asynchronicity is the key to speed up on modern architecture.",
                    "label": 1
                },
                {
                    "sent": "So we've tried to emphasize that in.",
                    "label": 0
                },
                {
                    "sent": "In Al variance on these methods we tried to to devise them so that they can run asynchronously and we can still get so.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Sort of interesting analysis.",
                    "label": 0
                },
                {
                    "sent": "So firstly, some work that I did with Ben Recht and Chris Ray and other colleagues at at Argonne.",
                    "label": 0
                },
                {
                    "sent": "Uh, sorry at Wisconsin on the stochastic gradient methods.",
                    "label": 0
                },
                {
                    "sent": "So just reminding what stochastic gradient is.",
                    "label": 0
                },
                {
                    "sent": "This is where F is the sum of a bunch of functions FI and we estimate the gradient by selecting one eye at random and taking a step in that direction.",
                    "label": 0
                },
                {
                    "sent": "So there are many ways to parallelize this.",
                    "label": 0
                },
                {
                    "sent": "It looks very sequential as it's written, but there was a lot of interest in the last few years at paralyzing it.",
                    "label": 0
                },
                {
                    "sent": "This idea of letting if you've got a multicore architecture.",
                    "label": 0
                },
                {
                    "sent": "You let the cause take turns and updating X where X is stored in some central central iaccessible location.",
                    "label": 0
                },
                {
                    "sent": "This idea of averaging where you let each of the cores or each of the processes evaluate a bunch of gradients and then aggregate all that information and then take a step we came up with this asynchronous method where.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We just let each processor basically run independently, run a stochastic gradient process so each core is picking an element IK from from the range one to M. It's reading extra memory, it's evaluating the gradient of FIK.",
                    "label": 0
                },
                {
                    "sent": "And then it's updating those components of the gradient that it just calculated.",
                    "label": 0
                },
                {
                    "sent": "And they're they're not trying to coordinate.",
                    "label": 0
                },
                {
                    "sent": "They're all doing this independently.",
                    "label": 0
                },
                {
                    "sent": "So of course, when this happens, you're going to get different cores treading on each others toys, and by the time you get in the gap between you reading X and and and the time you update it, other cores would have had their turn it updating X, and so the information that you're using to update by the time you actually use it, it's it's all right.",
                    "label": 0
                },
                {
                    "sent": "It could be, say, up to tower cycles.",
                    "label": 0
                },
                {
                    "sent": "All we assume there's a bound and how old it can be.",
                    "label": 0
                },
                {
                    "sent": "However, a lot of these applications of stochastic gradient, the individual gradients are often quite sparse.",
                    "label": 0
                },
                {
                    "sent": "OK, if you look at the gradients of HFI in many applications, I've only got 2, three, you know five non zero elements, and so this problem of different cores overriding each others work usually is not.",
                    "label": 0
                },
                {
                    "sent": "For that reason it's often not very.",
                    "label": 0
                },
                {
                    "sent": "It's not a very serious problem and so we can still analyze the speed of convergence of these methods by assuming that is not too much overlap.",
                    "label": 0
                },
                {
                    "sent": "So we can introduce some quantities Ro I.",
                    "label": 0
                },
                {
                    "sent": "So RAW is the number of indices J such that FI&FJ have overlapping support and then roll bar is some sort of average of all the row wise.",
                    "label": 1
                },
                {
                    "sent": "It's some sort of rate average rate of overlap.",
                    "label": 0
                },
                {
                    "sent": "So if robot is close to one, you've got a situation where the different FIS are not don't have don't generally have common support.",
                    "label": 0
                },
                {
                    "sent": "If sorry for those close to zero, they don't have much common support.",
                    "label": 0
                },
                {
                    "sent": "If it's close to one and they do have a lot of support and that's easy, that's more diffic.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To parallelize, so we have pages of analysis.",
                    "label": 0
                },
                {
                    "sent": "It was recently simplified by Peter Richterich.",
                    "label": 0
                },
                {
                    "sent": "It's sort of ugly, but a lot of these constants have appeared earlier in the slides.",
                    "label": 0
                },
                {
                    "sent": "I've had mu, which is the lower bound on the basically the modulus of strong convexity.",
                    "label": 0
                },
                {
                    "sent": "M Big M is abound in the gradient.",
                    "label": 0
                },
                {
                    "sent": "The uniform gradient are bound little M as a number of gradient cell is a Lipschitz constant, and so on.",
                    "label": 0
                },
                {
                    "sent": "Towers of delay parameter.",
                    "label": 0
                },
                {
                    "sent": "So the moral here is that there is a constant choice of step link that you can take.",
                    "label": 0
                },
                {
                    "sent": "In this asynchronous process, and there's also about in the number of iterates you need to achieve a target a given target error.",
                    "label": 0
                },
                {
                    "sent": "OK, and you can actually analyze this using this model of computation.",
                    "label": 0
                },
                {
                    "sent": "Using these assumptions about the amount of overlap so you can see that Roo bar this quantity that quantifies how much overlap there is between the support, it appears in the iteratee down.",
                    "label": 0
                },
                {
                    "sent": "So if Roo Bar is close to one then you have to take more.",
                    "label": 0
                },
                {
                    "sent": "Iterative is close to zero, you don't actually pay a very big price for running this asynchronously, so you can still recover a kind of a 1 / K convergence rate which is the classical convergence rate for STD that can be preserved in the asynchronous implementation provided you have these.",
                    "label": 0
                },
                {
                    "sent": "Extra assumption satisfied.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we got some performance of this was from a NIPS paper from the end of 2011, and I should point out that these other methods doing round Robin taking turns doing averaging a gradient in different circumstances.",
                    "label": 0
                },
                {
                    "sent": "These work well, but we had problems from SVM from matrix completion from graph cuts where the individual FIS were very, very simple, and in that case the asynchronous approach is best.",
                    "label": 0
                },
                {
                    "sent": "In the case where the individual FIS are more complicated, these other techniques are much more competitive generally.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I've got we got speedups on a 10 core machine, sometimes up to up to.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Nine almost.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is some your work and asynchronous coordinate descent.",
                    "label": 0
                },
                {
                    "sent": "So again to remind you here, we're just trying to minimize the function F. We're picking a component of exit random and where evaluating the gradient with respect to that component.",
                    "label": 0
                },
                {
                    "sent": "And then we're just taking a step in that component using that gradient.",
                    "label": 0
                },
                {
                    "sent": "OK, so the big the big trick here is choosing gamma, the step length, gamma, and the game is to come up with a gamma such that when you run this asynchronously this is being run in just the way hog wild was, each processor is independently doing its thing.",
                    "label": 0
                },
                {
                    "sent": "But the game is to choose gamma so that you can still prove some sort of convergence rate.",
                    "label": 0
                },
                {
                    "sent": "And again, I'm going to use the same sort of model as I did in Hog Wild, where we're assuming that no more than tower cycles passed between when you read X and when you get to do the update, OK, Tau is typically related to the number of cores that you're dealing.",
                    "label": 1
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So again, to do the the analysis of this is again very technical and it depends on a lot of constants that characterize the properties of F. So here the key seems to be the what I call the diagonal ecity.",
                    "label": 0
                },
                {
                    "sent": "Actually my student Jilu came up with this term and I'm not sure if he meant to say this, but I sort of latched onto it as an interesting term.",
                    "label": 0
                },
                {
                    "sent": "Dying listening basically is a measure of the degree of diagonal dominance of the hashing.",
                    "label": 1
                },
                {
                    "sent": "So L Max is the maximum element on the diagonal of the Hessian, L raises the maximum Royal.",
                    "label": 1
                },
                {
                    "sent": "You want the ratio valras to all Max to be small, close to one OK, and if that's the case then you've got a hash and it's sort of diagonally dominant.",
                    "label": 0
                },
                {
                    "sent": "Its maximum is square root of N. If it's square root of N, then the whole thing is harder to parallelize.",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So in this picture here, this is the same picture I showed you earlier.",
                    "label": 0
                },
                {
                    "sent": "The image on the left has basically you want the.",
                    "label": 0
                },
                {
                    "sent": "The principle components of the contours of the ellipse ellipse oil contours to more or less line up with the coordinate axes OK, and if that's the case, you've got the parallelism is easier.",
                    "label": 0
                },
                {
                    "sent": "You can paralyze this to higher degree in the case on the right where they don't line up with the axes very well.",
                    "label": 0
                },
                {
                    "sent": "That tends to be slower.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So again, the analysis is very complicated, but it all boils down to a very simple requirement where trying to choose the step length so that the change in the expected size of the gradient.",
                    "label": 0
                },
                {
                    "sent": "Of course, the gradient hopefully is going to zero as either it's progresses.",
                    "label": 0
                },
                {
                    "sent": "We're approaching a solution, but we want the change in the expected gradient to not be very much from one iteration to the next.",
                    "label": 0
                },
                {
                    "sent": "OK, now that might be surprising.",
                    "label": 0
                },
                {
                    "sent": "You might say, well, I don't.",
                    "label": 0
                },
                {
                    "sent": "Wouldn't you be happy if you had a method that made a big change in the gradient that got much closer to 0 after one step.",
                    "label": 0
                },
                {
                    "sent": "Well, the answer is no, because if you're trying to run this asynchronously, if one step makes a big improvement of the gradient, then when the other cores come in and do their updates, they're all using this irrelevant information.",
                    "label": 0
                },
                {
                    "sent": "So you be using information from when the gradient is large, and they might actually make they might actually mess things up again, so we're looking to make sort of slow, steady progress in decreasing the gradient, so we want to pick this constant row, and we want to make sure that the change in the grading is within is between one over rho and rho, so that's the principle that guides the selection of the of the step gamma.",
                    "label": 0
                },
                {
                    "sent": "And in the end we can show that you can choose a gamma, that sort of threads the threads the.",
                    "label": 0
                },
                {
                    "sent": "Threads the needle between being too fast and too slow and you can end up getting.",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Sort of linear convergence rate in the expected error.",
                    "label": 0
                },
                {
                    "sent": "That sort of comparable to the right that you get from steepest descent when you allow for the fact that the cost of a stochastic coordinate descent update is about one over end of the cost of a steepest descent update, you get a sort of a consistent convergence rate.",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we work with our colleagues Chris Ray and students Victor Bit off and and Christmas reader and we got the we ran this on a 40 core machine recently and basically we see that for this little test problem when you run it up to 40 cores, the number of iterates you need to converge is basically doesn't change so that the graph on the left is very boring.",
                    "label": 0
                },
                {
                    "sent": "There's no.",
                    "label": 0
                },
                {
                    "sent": "Basically, you just need the same amount of work, but the speedup actually is not quite linear because there are sort of memory contention affect, so we get speedups of up to about 20.",
                    "label": 0
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "26 or so in a 40 core machine.",
                    "label": 0
                },
                {
                    "sent": "So if I have maybe two more minutes, is that alright?",
                    "label": 0
                },
                {
                    "sent": "OK, I just want to say something at the end about very large scale linear programming because this was something that I worked on way back in the late 80s and my colleagues in Madison.",
                    "label": 0
                },
                {
                    "sent": "All the mega Sarah and also worked on this.",
                    "label": 0
                },
                {
                    "sent": "We basically took the basic linear programming problem, an applied augmented LaGrange into it, and I've told you what elemental Lagrangian is already, so that gives you quadratic programming subproblems.",
                    "label": 0
                },
                {
                    "sent": "OK, that basically look like this.",
                    "label": 0
                },
                {
                    "sent": "We",
                    "label": 0
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That an extra term on the end here, which also is a term that penalizes how far you move from your latest estimate of the solution.",
                    "label": 0
                },
                {
                    "sent": "So basically we're taking LP and expressing it as a sequence of bound constrained convex quadratic programs, and when we did this back.",
                    "label": 0
                }
            ]
        },
        "clip_55": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In the 80s and we generated random LP's, it seemed to work OK.",
                    "label": 0
                },
                {
                    "sent": "It seems to be promising, but when we took real LP's from a real test set it was incredibly bad.",
                    "label": 0
                },
                {
                    "sent": "Not at all competitive with with simplex methods and then more recently interior point methods.",
                    "label": 0
                }
            ]
        },
        "clip_56": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "However.",
                    "label": 0
                },
                {
                    "sent": "Chris Ray sort of was convinced that if you took this approach and applied it to very large LP's that come from relaxations of very large combinatorial problems, it might be.",
                    "label": 0
                },
                {
                    "sent": "It.",
                    "label": 0
                },
                {
                    "sent": "Might have a place OK and and maybe this is a plausible scenario because often for these rounded LP approximations you don't need a highly accurate solution.",
                    "label": 0
                },
                {
                    "sent": "Accrued solution is perfectly OK. Also, this approach never needs to do matrix factorization so.",
                    "label": 0
                },
                {
                    "sent": "Potentially you can deal with much bigger problems and so for those reasons we thought at least it was worth trying.",
                    "label": 0
                },
                {
                    "sent": "So one example, we ran it on.",
                    "label": 0
                },
                {
                    "sent": "This is the easiest one to describe as vertex cover.",
                    "label": 0
                },
                {
                    "sent": "So if you got a very big graph bunch of vertices V bunch of edges E, you're trying to choose a subset of the vertices such that every edge is touched by at least one vertex in the subset.",
                    "label": 1
                },
                {
                    "sent": "So you can write this down as a binary program like this where the the Unknowns XV are constrained to be binary variables.",
                    "label": 1
                },
                {
                    "sent": "You can relax it to an LP, you can solve the LP and then sort of collapse it back to a feasible solution for the integer program.",
                    "label": 0
                },
                {
                    "sent": "So when we do that.",
                    "label": 0
                }
            ]
        },
        "clip_57": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We're able to take these graphs and solve this problem with the number of variables going up into the millions couple of million, and we're able to get this is, by the way, is after we've done a pre solve step, which is a which doesn't do any optimization but able to.",
                    "label": 0
                }
            ]
        },
        "clip_58": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I'm a lot of variables and we compare that with standard.",
                    "label": 0
                },
                {
                    "sent": "Simplex method from the seaplex solver.",
                    "label": 0
                },
                {
                    "sent": "Very well known commercial solver.",
                    "label": 0
                },
                {
                    "sent": "And we're able to get solutions about sort of 10 times faster.",
                    "label": 0
                },
                {
                    "sent": "But more importantly, for the large problem, we're able to get a solution where Seaplex wasn't able to solve it within an hour.",
                    "label": 0
                }
            ]
        },
        "clip_59": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So there is some promise in this application, so this is the end.",
                    "label": 0
                },
                {
                    "sent": "I've sort of I've given you.",
                    "label": 0
                },
                {
                    "sent": "I think a bit of a whirlwind tour of Canonical applications, fundamental optimization tools tells you a bit about how they match up.",
                    "label": 1
                },
                {
                    "sent": "I want to make the point that this is not at all an exhaustive summary, as many of you know, there are many other areas that are potential or current applications of optimization, But I hope I've demonstrated that the optimization toolkit is a very important resource in in addressing the problems that that you have in this Community.",
                    "label": 1
                },
                {
                    "sent": "Thank you very much for your attention.",
                    "label": 0
                }
            ]
        }
    }
}