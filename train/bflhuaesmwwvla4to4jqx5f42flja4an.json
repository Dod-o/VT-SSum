{
    "id": "bflhuaesmwwvla4to4jqx5f42flja4an",
    "title": "Efficient Top-k Queries for XML Information Retrieval",
    "info": {
        "author": [
            "Gerhard Weikum, Max Planck Institute for Informatics, Max Planck Institute"
        ],
        "published": "Feb. 25, 2007",
        "recorded": "May 2006",
        "category": [
            "Top->Computer Science->Information Retrieval"
        ]
    },
    "url": "http://videolectures.net/fws06_weikum_etqxi/",
    "segmentation": [
        [
            "So I realize I'm between you and lunch so, but I don't make any promises that I will be faster than the plant time.",
            "So the topic is XML IR.",
            "Why is this interesting?",
            "It's quite a shift now in terms of topics, so at first glance there is little connection to the web.",
            "It's much closer to databases, which is my home community and in databases we're interested in this as one potential key piece in information integration.",
            "Think of looking at 100 different databases, all of which might have structure and schema like XML databases, and now you want to query them simultaneously, but you don't want to wait like weeks or months for some experts to actually deeply integrate them and create the data so that they are form a seamless.",
            "Federated system.",
            "So then you need to make up for the lack of global schema.",
            "Each database has a schema where they differ, so altogether you don't easily have a schema and you need to cope with the inherent uncertainty that's introduced by that process so that from a database viewpoint from an IR viewpoint well adding structure and adding some kind of semantic annotations to the data, it should at least in principle give you a push towards more expressive search now that.",
            "More expressive search.",
            "Connecting to the previous talk might not be for an end user, certainly not for mass users on the web, so actually would be more at the level of application developers interfaces, so it would be hidden from end users, but nevertheless in the talk we will use concrete syntax for phrasing queries in X path and adding information retrieval semantics.",
            "So what could these?"
        ],
        [
            "There is the queries that I think can be easily expressed and satisfactorily answered on the web, so they're toy queries, killer queries that I collected, no business value, just serving to demonstrate certain observations.",
            "So the first one cannot be easily answered on the web because no single web page might qualify.",
            "My address is on my home page, but then that page doesn't mention anything about teaching or research, so you need to follow one or two links and look at the little craft pattern that's embedded in the web craft.",
            "So you need to do pattern matching plus the usual keyword search.",
            "Number two is difficult because keyword search may not find the obvious answer.",
            "Shakespeare's Macbeth, because the main clue, and if you look at the primary literature, not secondary literature, the main clue would be aligned.",
            "Saying something like third, which: all Hail Macbeth Thane of Cawdor associate become King.",
            "Now you need background knowledge.",
            "The human would have that.",
            "So which is?",
            "And the literature?",
            "Sorry all the ladies in the room are typically female.",
            "Maybe it's a male prejudice, but this is.",
            "How it goes?",
            "So for most humans, it's pretty clear that third, which implies there are three women in this game, and similarly thing of quarter.",
            "Some people might know it's the Scottish nobleman title, so you need to make these kind of semantic inferences in order to get a reasonable answer.",
            "And the third example combines the complexities of these previous tool.",
            "So here you can actually or you should put together bits and pieces from different sources like I could look up in my electronic calendar which PC's are you attended?",
            "Which PC meetings are attended?",
            "Then connect that to email in order to figure out on which of these are good.",
            "Was the PC chair?",
            "Then maybe go to a digital library in order to get a list of all the people on the PC and finally go to their web pages in order to check out.",
            "Who these people might be?",
            "The woman from Paris and this way I might come across a candidate like Sophie Clay in real contour.",
            "And again we need to infer that Sophie is most likely female and walk in cooler.",
            "Strictly not Paris, but close enough.",
            "And finally, the engine also needs to kind of infer that by Paris I probably meant Paris, France and not Paris, TX, so these are difficult queries and they are way out.",
            "So to get like the ideal answer on rank one.",
            "This will keep the community busy another few decades so but XML might be a step into this direction towards quote semantic search."
        ],
        [
            "So what if the semantic web existed anywhere in XML?",
            "How far would we get?",
            "So this is my first example.",
            "This is my graphical illustration of XML, so these are just labeled trees.",
            "Everything in red is tax element names and everything in black is content terms.",
            "We have three web pages connected by X links or H ref pointers, so we."
        ],
        [
            "Could express their query using X path written this way little twig query and what it does.",
            "It essentially does semantically pattern matching in these trees or in the connected trees.",
            "So this is the first condition and then we need to match this and that and that would be standard database evaluation.",
            "If we have only data of this kind, so there's no IR element involved.",
            "But suppose we don't have."
        ],
        [
            "Few results that exactly match this quick query, so then in order to get more results we are going for approximate matches and so here I've chancler colleague in the Institute would be such an approximate match, but his tag name is not.",
            "Professor is lecturer, his content address does not mention supporting explicitly, but again you could plug in background knowledge in order to infer this and so this would be a decent approximate match.",
            "And we are using like generalization relaxation of X path queries where we can approximately match tech names and also content terms.",
            "So we use this~ sign.",
            "Hopefully I also wanted to give an online demo first, but I was afraid of technical problems, so the~ sign on the keyboard would have killed me too.",
            "So and then this would be an approximate match.",
            "So bottom line here.",
            "As we need to combine database and information retrieval techniques and this is a field I've been working on for a number of years and others including Ricardo have been promoting this also for a long time.",
            "So."
        ],
        [
            "After this motivation, now the talk is 3 parts.",
            "So I will first elaborate a bit more on the functionality of XML, IR an how lightweight ontologies author I can be plugged in, and then the main point is actually an efficiency.",
            "How can we efficiently run these kinds of queries which obviously are a lot more complex than simple keyword queries?",
            "And for that purpose we will first look at a simpler model named the keyword queries and after that I will show at the in the last part how to carry this over into the XML world.",
            "So."
        ],
        [
            "This doesn't start from scratch.",
            "There's a long history of research to build on web query languages that never were applied on the web, but led to XML query languages in some form.",
            "There's IR unstructured documents, foundational work in the mid 90s or maybe even earlier, which then led to IR on XML, which has now become pretty mainstream.",
            "I know there is a bunch of you here in the room who are also working on this, but I don't think the XML IR subgroup in this nice workshop.",
            "Forms a majority so and there is commercial interest.",
            "Now there's an index benchmark being established and being successfully run for a number of years, so our engine or prototype engine top X hosts some of the tasks and is iaccessible.",
            "If you register for IMAX.",
            "And the World Wide Web Consortium is considering extensions to the X path and expert standards that would take care of full text search and scoring and ranking.",
            "So a."
        ],
        [
            "These queries have standard apart from the syntax.",
            "Maybe Standard X path one.",
            "Abstracts index so we have these elementary conditions on tag names and then content, often referring to the child or descendant access, and in this talk I will only refer to this the slash slash.",
            "And very in a real nutshell, the query results all.",
            "That's the semantic definition of such a query, is that the result would be a subcraft that's isomorphic to the query pattern.",
            "And of course that's a tall order, and then you need to have the right pre computations and indexing strategies in order to get this sufficient.",
            "Once we add the similarity conditions with the~ operator.",
            "Here we need relevance scoring and we have two aspects here.",
            "One is for the content terms.",
            "Like XML, so here we write to the XML.",
            "So even here we could add a scoring and ranking semantics.",
            "So we do this by using standard IR technology.",
            "In particular, our engine uses a variation of the Okapi BM 25 probabilistic IR model with one twist that all the ingredients like term, frequencies or IDF values and our tag term pair specific.",
            "So that's for the content conditions.",
            "For the tag conditions, the which forms the structural backbone like tell the research statistics.",
            "Frequency statistics doesn't make sense because these are single words in the place where they occur.",
            "So here we use some lightweight ontology where we exploit similarities between different concept names, like a similarity between professor and lecturer for example.",
            "So bottom line, here is a query.",
            "Now is a relaxable pattern and results are approximate matches.",
            "So this is the."
        ],
        [
            "On slide I have on Thorion contala.",
            "Geez, we're really not into semantic web.",
            "This is nothing about owl or things of that kind.",
            "So we build a graph representation of concepts and relations.",
            "Different typed relations like these.",
            "This is made up.",
            "This is not real, by the way.",
            "The sources for that would be word, Nat, geographic gazetteers, doing some mining on web forms and tables, extracting concepts, entities and relations from Wikipedia and so forth.",
            "So it's not my main sales pitch here.",
            "Adjust.",
            "This isn't encapsulated piece and then all edges.",
            "All the relationships are are statistically weighted, which I think is crucial in order to make a kind of inferences, we need to make for very few relations are hard facts like remember the woman from Paris and it was not Paris in a strict logical sense because she is in or conquer and there would have been ambiguity about which Paris are meant.",
            "But statistically, this works well, and so we actually estimate correlation measures such as dice coefficient.",
            "But there are other measures from large corpora.",
            "Now, once we have this and we have a query of this kind, either Justin keyword form or in some semi XML form or in full XML form, we map the words in the query and to this concept space comparing a context and the query world and the query side and the craft context here along with these weighted edges and this gives us a ristic's for word sense disambiguation and then we can expand the query using a thresholding mechanism.",
            "So all the related.",
            "Concepts and their synonyms with similarity above some threshold are added and it produces a bigger expanded query along with query term weights.",
            "And the key point which I'm going to get it in a few minutes is that we should execute this now, efficiently and no.",
            "Just the expansion process already incurs quite some complexity because of seemingly harmless query might be expanded into a 50 keyword query with weights.",
            "So the query expansion is a double edged sword, as all the knowledgeable people in iron.",
            "Oh, so it helps for some queries, but it's difficult to tune and in some queries it might lead to a topic drift if you over expand.",
            "So that tuning of the threshold is really a little nightmare.",
            "An in benchmarks.",
            "You can tune a lot, but in a real application setting you can't do this.",
            "So we also worked on a method which I'm going to present in awhile.",
            "That pretty much eliminates the need for having a threshold at all and makes the whole expansion process a lot more robust and more efficient.",
            "Now a little."
        ],
        [
            "Detour here.",
            "So where is the XML on the web?",
            "So there is no not much XML, it's but there's a lot of XML and companies that publish data on the web just at the very end they cast into HTML.",
            "But on the Surface Web exciting data is things like Wikipedia for example, which is good old text plus a bit off surface markup.",
            "But there is information extraction technology.",
            "I don't know how much this will be covered later in the workshop, so and that goes along way that has become a reasonably mature technology.",
            "So we can run named entity recognition tools and get person tagged post person names tag, get time periods, tag, publications and so forth.",
            "We might even infra relations between a publication and a topic of the publication weaken.",
            "Tagging is seamlessly goes into classification.",
            "So here we might infer that Newton is a scientist.",
            "Becausw the text mentions he is a physicist, mathematician astronomer.",
            "Here at two in the classification, you can leverage the Thore and lightweight ontologies.",
            "By the way, if we are deep into NLP and R&R Bolden good enough, we might be able to infer from this little sentence.",
            "Shares credit with Leibnitz that Leibnitz must have been a scientist too, and then this is probably something that no NLP guy can do today, so inferring that Nella was a painter.",
            "So the message here is information extraction with its suite of techniques, NLP pattern matching, lexicons, learning, statistical learning goes along way, and in principle we could cast this data into a database just either either tables or XML.",
            "It doesn't matter.",
            "It could also be RDF.",
            "These are only syntactic variations, but this is not a hard fact database, but the individual entries might have confidence less than one because they were.",
            "Inferred by some heuristics or some statistical learning process.",
            "Once you attach like confidence, well, yes to this.",
            "This is almost like term index weights in IR.",
            "So then you certainly have an inherent uncertainty in your data and as you combine this data with other data, so evaluating queries and making connections then ranked retrieval is a must.",
            "So I think this would be maybe not tomorrow, but in a few years from now we might be able to do things of that kind."
        ],
        [
            "No efficiency.",
            "So how?"
        ],
        [
            "How do we evaluate queries?",
            "And now we go back half a step and look at keyword queries so we all know we operate over inverted index lists where we have these document ID or web page ID score pairs.",
            "So scores would be pre computed using probabilistic IR statistical language models.",
            "Whatever at query runtime for a three keyword query like this.",
            "Essentially you perform score aggregation.",
            "So we try to find the same document in multiple lists like this one here and here and you sum up.",
            "This course could be summation weighted summation.",
            "More complicated things, as long as we perform a monotonic score aggregation.",
            "We are in the framework that I'm going to present now.",
            "The textbook algorithm simple textbook algorithms would be fetch the index list and then do some computation with them in memory.",
            "But this index list could be long so they could easily be a MB long.",
            "A MB is multiple disc tracks, so you're keeping your desk quite busy.",
            "Now this does not matter in a single user system, but on a server you're running hundreds of thousands of queries simultaneously, so you want to be stingy with resource consumption, otherwise your throughput and your multi user response time are really badly affected, so we want to avoid reading the entire index lists and instead ideally because in the end we want to precompute top K results like top ten, top 100, top 1000, but not top 1 million in a completely ranked order.",
            "So ideally we read only short prefixes of these lists and we should be done.",
            "And there's a nice.",
            "This does not work anyway, so there's a nice algorithmic paradigm for this that goes back a long time into IR, where it still stayed out of you Ristic level, and Ron Fagin and colleagues actually gas this into an elegant framework known as the family of threshold algorithms.",
            "I'm going to illustrate one particular variation of this, and so you don't need to read the pseudocode here.",
            "The point is, is a very elegant piece of work because it's such compact pseudocode.",
            "So you can almost implement it this way.",
            "There's the difference between pseudocode and code is not really big.",
            "The Fagan also characterized it in terms of nice theoretical properties.",
            "For example, this algorithm has is asymptotically instance optimal, so whatever your data looks like, it's always asymptotically optimal.",
            "Of course, asymptotically Heights all the constants and second, he assumes the number of less over which this runs as constant two.",
            "Now the illustration, the algorithm and that special specific variant performs only sequential accesses on these lists.",
            "So there's no like random look ups of interesting scores, becausw sequential accesses amortized are like factor of 22,000 faster than random accesses.",
            "20 would be.",
            "You look at a raw disk.",
            "Once you Add all the software and we measure this.",
            "Actually you get much bigger factor, so we measured it on database systems and we measured it on file systems.",
            "So we want to do sequential accesses mostly.",
            "So we scan this list round Robin and as we know this should have gone away in the animation doesn't matter is different PowerPoint version than mine.",
            "So we scan the first entries and we collect that information in a main memory data structure which takes the form of a priority queue.",
            "So that becomes interesting the first time when we have scanned the second entries, because now we've seen one document 78 twice.",
            "And what we do in this data structure, we keep track of an interval for the true final score of a document.",
            "So we have a lower bound for the score coin were score, which because we use just simple summation in this example, is the sum of the scores we've seen for that document, and there is an upper bound, namely the worst core plus the best possible score mass.",
            "That this document could get from any of the lists know from all the lists together in which we haven't seen the document so far.",
            "So in this case is only here and that best possible score we could get here is actually upper bounded by the last quarter that we have seen.",
            "We call this the high values, so this is the algorithmic principle, and at some point hopefully something good happens.",
            "So at the point when the worst score of the current rank K document now, for simplicity this is K = 1.",
            "Is at least as high as the best core of all the other candidates and we can stop safely terminate the algorithm and that should happen after scanning the like 10% of the list.",
            "In some cases only 1% or 2%."
        ],
        [
            "Now the can this algorithm be improved in our own work kicks in, so where we actually improve on that?",
            "Well, first of all, let's say Fagan is a top notch theoretician, but when we first implemented it, it didn't perform.",
            "So create an it took some additional implementation tricks.",
            "How do you maintain priority queue and little details that in the end, matter a lot?",
            "So just our right implementation compared to the first implementation already caused the difference of one to two orders of magnitude in measured performance.",
            "Now, but here's an algorithmic element that further improves and gives us another order of magnitude, and that's a probabilistic consideration.",
            "So the algorithm is based on that invariant were score is the score summation in the list where we've seen the document.",
            "This is a lower bound and upper bound is at worst core plus the.",
            "Upper bounds these high values for the unknown scores in all the lists where we've seen haven't seen a document now that leads us into like a little illustration for the behavior of 1 candidate document in its lifetime.",
            "As we scan the list as we go deeper and deeper and what happens is that these core intervals gradually get converged towards a point, but it may take a long time to get this to a point for all.",
            "Candidates so we would like to avoid running that long and we can compare the intervals to the main K threshold.",
            "That's the worst core of the current rank document.",
            "This is what drives the door has given the algorithm.",
            "The family of algorithms, its name threshold algorithms.",
            "So when the.",
            "Disco interval gets completely above the red line.",
            "We know we have a top K result for the time being when it drops completely below the red line.",
            "We know this can never ever qualify for the result and at this point we can throw this away as a candidate.",
            "Now this garbage collection or pruning candidates is also important.",
            "It's not just important that the algorithm terminates fast, but also that we get rid of candidates quickly.",
            "Becausw the this.",
            "Priority queue data structure micro in a nontrivial manner.",
            "Again, it will not grow to gigabytes, but megabytes and running on a server.",
            "This is needs to be done for every one out of, let's say, thousand concurrent queries.",
            "So we want to be stingy again with the memory consumption.",
            "I want to be able to throw away candidates as early as possible.",
            "Now, in this conservative approach, we can drop this from the priority queue only at this point, not here, but that figure already suggests a probabilistic interpretation.",
            "If simple minded, there were a uniform probability of for every point on this segment to be the true score.",
            "Then you see this small ratio compared to that big thing suggests we can prune this document and we make a small probabilistic error.",
            "Now things are a bit more complicated.",
            "And this leads to this consideration.",
            "So what we actually do, we estimate the probability that this candidate document D in the end.",
            "If we add the unknown scores here.",
            "Gets a final score that is above this MNK threshold so this Delta which should be instantiated by men.",
            "Kate and the trick for doing this is we replace the conservative high bounds, just conservative upper bounds by random variables.",
            "SI which of course need to be estimated from information about the distribution of scores in the different index lists.",
            "But that's something we can precompute and keep along with the index fact it's much smaller than the actual index, so we would keep that information in memory of.",
            "Bring it into memory when the query is started and then at query runtime we do the right calculations.",
            "If we do this right then we would discard a candidate from the queue if that toepke qualification probability drops below some journable epsilon, say 10% one percent just a second.",
            "And that translates into an actual guarantee for the expected relative precision where relative this is, I think, Alessandro colleague competitiveness recall, so that we assume the conservative top care algorithm is ground truth and relative to that we making some probabilistic error, which leads to relative precision or relative recall.",
            "This is the same here and then this is 1 minus epsilon, so let's say 90% or 99 question.",
            "Independent, yes, yes yeah.",
            "I'll come to that I come to that.",
            "So how do we actually estimate this?",
            "Because we're not only looking at expectations here, we need to compute the convolution of distributions.",
            "There's a number of ways actually, the next slide goes through this.",
            "So one is we."
        ],
        [
            "After late distributions.",
            "And this might not be text only in the XML world we're interested in combining text with other data, so that might be categorical attribute distributions and might be an scores derived from that.",
            "There might be numerical distributions and scores derived from that, so different attributes, different dimensions might have different distributions.",
            "So in principle we could make educated guesses or analysis to postulate some parameter form and then compute convolutions analytically using Laplace transforms.",
            "And then using large deviation bounds, there is some work on taking correlations into account in a very limited extent.",
            "Practically this did not work that well.",
            "The bounds get way too conservative.",
            "If we wanted to take correlation into account in, uh, in ways other than this, we would have to look at 2 dimensional distributions, right?",
            "Would have to characterize identify good candidates where correlation is very prominent, important to capture and then do something special in the pre computation principle.",
            "The framework would work as well.",
            "Now an alternative would be to make specific assumptions about the parametric form like fossil mixtures because their convolution leads to fossil mixtures again and then the parameters would be fit by.",
            "Precomputation, or we don't make any assumptions and just use histograms precomputed per dimension.",
            "But here again if you tell us so this small fraction of.",
            "Pairs of dimensions is interesting in terms of their correlation.",
            "We could of course, plug in 2 dimensional or multidimensional histograms and then a query runtime.",
            "We compute the convolution dynamically so it turns out this works best by far.",
            "So."
        ],
        [
            "Also, this is on an old benchmark.",
            "So with standard queries with comparing or optimized implementation of the sorted access version of TA or N, also known as NRA against our probabilistic techniques, we win a factor of four in terms of abstract cost, measure and a factor of 10 in terms of runtime, which has to do with the better memory management.",
            "And we also compare like quality.",
            "So because here we employ additional heuristic tricks in addition to this probabilistic approximation.",
            "This should actually have been 0.9 because we use epsilon 10% and it didn't hold.",
            "But then you can use other measures as well.",
            "Rank distances, foot rule, candle store score errors and also here this data comes with relevance assessments from track.",
            "So you can look at precision at K or at map and in the latter regards actually the results were almost indistinguishable.",
            "So this bottom line is we speed up these queries by a factor of 10 in some cases even more.",
            "Depending on the nature of the queries and the result quality is by and large acceptable, there's a little bit.",
            "At some point it will be great, but it goes along way.",
            "Now."
        ],
        [
            "So the same thing can be done with expansions like.",
            "This is probably in the USA.",
            "Politically incorrect query expansion, but in Europe I should be safe.",
            "So here again just here you see the abstract cost saving is no longer that impressive because we're now talking at 20 dimensional keyword query, but the runtime gain is still significant and I come to these expansions also on the next slide.",
            "So expect."
        ],
        [
            "Actions I mentioned before.",
            "This is a double edged sword so they can work well, but sometimes they fail miserably, so we have two things to offer here.",
            "One is a different score aggregation function, so instead of justice aggregating the score contributions from all the expansion terms we take for one given originally keyword in the query only the best expansion contribution.",
            "So if we expand Professor into these possible candidates, they come with a with a weight with the similarity wait between this original.",
            "Term and the possible expansions and the contribution of a document that matches lecturer times that, as the contribution and only the best for candidate documents, only the best contributions out of these possible ones is counted so that changes the aggregation Frank function into a summation over original query terms and then this is done over a maximum over the possible expansions.",
            "So nice thing is it stays monotonic.",
            "All the work about the threshold algorithms apply, and even the the score prediction machinery can be adapted to take this into consideration.",
            "The second thing probably even more important, is that we do this expansions dynamically on the fly.",
            "As we move down in the lists and this is best explained by animation.",
            "So we start scanning.",
            "In the usual way, and at some point we realized so we had a score of 0.6.",
            "Now the best possible expansion would have a similarity weight of 0.7, but then if it had the document that contains this had a perfect score of say 1.0.",
            "This would be better than the following matches for the original term, and this is the first time that it's worthwhile doing this, and so at this point, and only at this point we start scanning here and we scan.",
            "And of course, the same effect occurs another time.",
            "So at some point I think it was here something 0.8 * 0.6.",
            "Sorry, Zero point 6 * 1 Perfect score gets better than 0.8 * 0.7, So this is the way we apply this method.",
            "You can think of this as a dynamic merging of the index lists.",
            "And the scheduling becomes a bit more tricky here.",
            "It's no longer round Robin obviously, so rather it has a query flavor.",
            "So by and large this gives very good quality.",
            "So we participated in the TB benchmark with decent results or expansions which driven by word net, so that alone you can't win the benchmark.",
            "But we had decent results, and we our technique improve the performance by a factor of four, and in some cases even higher.",
            "No."
        ],
        [
            "How am I doing in time?",
            "How much more time do I have?",
            "OK so a few words about scheduling because this is very recent.",
            "Even unpublished work, so the scheduling could be another boost factor in improving performance.",
            "So Fagan already did some less observed or appreciate it.",
            "Work on that, which nevertheless is very inspiring and valuable, so he said, well, a small amount of random accesses seems worthwhile, so we want to scan primarily and sequential.",
            "Order but once in awhile we should do some random accesses to look up missing score information about the most worthy candidates, and this algorithm would be driven by a cost ratio between one random access and one sequential access.",
            "Let's say 100 or so, and then every so many rounds of the sequential access, can't he would incur around of random lockups using some greedy strategy for picking which candidates are chosen to get more score information.",
            "Now he has a nice theoretical analysis.",
            "This is four M + K competitive.",
            "So compared to a fictitious optimal schedule, so that's actually kind of a lower bound for an optimal schedule that may not be feasible by an online algorithm, but nevertheless it can compare to this.",
            "Now this looks really good on paper, but when you think it through no, M is the number of index lists, so we do expansion.",
            "So we quickly have like 20 or so here, so we quickly have a factor of 100.",
            "Question factor of 100 is quite a lot on a multi user server.",
            "So we looked at this.",
            "And we came up with."
        ],
        [
            "Two strategies, one as on the essay scheduling for sequential accesses.",
            "There's no the round Robin.",
            "Discipline is not God given, so instead we could say well, because we have histogram information.",
            "In some sense we have precomputed look ahead information in a very compact form.",
            "So we might say, well, the score distributions matter too, and also the information that we have accumulated already.",
            "So we might say, well, let's perform now 1000 steps on this index lists overall, but let's divide them up in an uneven manner.",
            "And that leads actually to a combinatorial optimization problem which is NP hard, but again, a little engineering trick you don't want to do this with the individual index step.",
            "These index list sits in disk blocks and a desk Clock should be a disc track, so it's something like 100K.",
            "So we actually do this over batches of disk block accesses and then the size of the knapsack related NP hard problem becomes a lot lower, and we can actually solve that at runtime optimally.",
            "The other consideration is about random accesses.",
            "So there's a bunch of considerations.",
            "1 interesting is that we should not interleave sequential accesses and random accesses, but should save the random access is for the for the end.",
            "In fact, our and there's some theoretical arguments for this or best methods proceed by sequential access only up to some point when we estimate that the total cost of remaining random accesses is equal to what we have invested up to this point.",
            "There is some theoretical justification for this, and then we switch.",
            "The strategy and then we perform only random accesses and will use cost prediction models in order to determine a good order for this, so some."
        ],
        [
            "Solves very recent on terabytes data.",
            "Here we re implemented everything from a database system based engine.",
            "We used to be on top of a database system so our index scan steps were actually JDBC calls.",
            "Now we went for a file system implementation and got all the numbers down to things like a few milliseconds per query and this is as K increases for top K. This is the abstract cost measure.",
            "Weighted sum of sequential and random accesses.",
            "See for example in green is the sequential access only algorithm and blue is this combined algorithm by Fagan, with periodic random accesses.",
            "And this is our best technique and this is a lower bound for the optimal schedule, so we're very this is the most striking thing.",
            "We're very close to the lower bound anyway.",
            "We win roughly a factor of four or five in terms of abstract costs and also in terms of runtimes.",
            "So."
        ],
        [
            "Last part."
        ],
        [
            "And I hope I have 10 minutes left.",
            "So now coming to XML, how do these techniques apply to XML?",
            "So recall again, the queries are now a lot more complicated.",
            "They have these content conditions in combination with tax and there's also structural conditions.",
            "For example, affiliation an element with that tag name should be a descendant of an element with the tag name book in the same document.",
            "So, but we were driven by taking the TA style top K algorithms and applying them to the setting and adopting them as needed.",
            "And in doing this we encountered a bunch of problems and this is the vote I view of of how we solve them.",
            "So the first one is maybe not a problem, but more an opportunity.",
            "So disk space is cheap.",
            "Disk IO is not, so we were generous about using disk space for some sense, redundant indexing.",
            "So in particular when we precompute and store scores, we do this for entire subtrees rooted at some element of interest, not just so for the element alone.",
            "And then when we need the score for the entire subtree.",
            "We computed at query time, but this is precomputed.",
            "There's some redundancy here, but it's fine because disk space is indeed cheap.",
            "Now contact conditions are no longer on terms, only about ontact turn pairs, so we're interested in the content terms page rank, but only in combination with attack reference.",
            "So we just index the pairs.",
            "Might think there's a combinatorial explosion quit writing explosion, but there should be a lot less tax than terms.",
            "So we have an apples and oranges comparison problem when we aggregate scores because we actually see in this index list cause for subtrees and in the end the unit that we want to score and rank is entire documents.",
            "So and we use some engineering tricks in order to get the elements course for subtrees in the right order.",
            "So and we prefetch a little bit so that we see one interesting element.",
            "We get all the elements.",
            "For the same document in the same query condition and that helps pass conditions need to be checked to like book is an ancestor of affiliation.",
            "An ancestor of reference reference has Descendance publisher and publishers count Country.",
            "How to some extent random accesses may be unavoidable and we use our scheduling strategies for scheduling them in the right way, and the other implementation consideration here is that as we have some information in memory, we actually enhance the index structures to include also structural information in the form of these pre post order codings that once we have some building blocks in memory, we can actually test these path conditions sufficiently in memory without additional.",
            "Disk access is now these pre and post order encodings.",
            "Maybe this is in the XML database.",
            "World is a standard melt, but for you maybe it's not so well known.",
            "So what you do at document Analysis an indexing time, you traverse the nodes in the tree and you keep the preorder traversal and in a post order traversal conceptually twice, but can be implemented in one traversal and you remember the Rankin at foreseeing the element.",
            "In the two traversals and, this information gives you efficient tests for all the X path access.",
            "So from this information, given two elements, you can quickly tell whether this one element is a descendant of that other or not, so this is very efficient.",
            "And finally pass conditions, maybe relaxable, maybe a good approximate result of this does not have a publisher tack or a country tag.",
            "Or instead of the affiliation tag, we have something else.",
            "So we associate some score mass also with the structural considerations.",
            "This is a bit at Hawk and if they are not matched actually they don't get that score mass.",
            "So there is a penalty for being a perfect match in terms of content but sacrificing not.",
            "Satisfying some of the structural conditions."
        ],
        [
            "No, I think this is the for the for the take home message.",
            "This was good enough.",
            "I have a few more slides including like an elaborated example.",
            "Oh, I show you the example an."
        ],
        [
            "Fast forward mode.",
            "OK."
        ],
        [
            "So one pre conclusion and then the real conclusion.",
            "Oh no, I should have shown you sorry.",
            "Experimental results are always interesting, so this runs on on the next data bibliographic data with good performance results quality."
        ],
        [
            "Here we are again.",
            "We are like in the top third, but we were not driven by getting like the best quality also runs on the new iMacs data in XML version of Wikipedia and it has good performance.",
            "So we had competitors like the algorithm and this one is worthwhile mentioning.",
            "This came out of Ragu Rama Krishnan's group from Wisconsin, which uses a database style structural indexer, data guide index and actually gives preference to structural conditions.",
            "So it kind of tends to primarily evaluate structural conditions, and then the score scoring part for the top K query processing is like a second stage, so you see that we beat this significantly by factor.",
            "Actually, here in acts of more than 20.",
            "To be fair, we also evaluate this on data that has weather structure is more important, for example because it's a lot cleaner.",
            "Index has about 1000 different tags because this is converted SGML data and it's really messy.",
            "Whereas IMDb has a very clear schema and XML schema and here actually we still gain a factor of two to three, but these techniques are not bad in the sense that they would never work well."
        ],
        [
            "Now pre conclusion.",
            "So this was all on trees.",
            "So in my original motivation had brought up crafts.",
            "Now crafts incur a jump, a quantum leap in complexity.",
            "So think again the query from the motivation and now assume we might even have waited actors like we could we add connections between documents.",
            "Here we could say, well intra document actually have different weights than Inter document edges.",
            "As this might be symbolic links that got in Ferd from some text mining process and then they have weights too.",
            "So and as we add more documents that are just interlinked.",
            "So think Wikipedia every page has like links to 50 other pages.",
            "You really have a craft that's not at all like a tree.",
            "Now when we could still run our techniques, they're just getting slower and slower on this, so this might be a candidate match.",
            "This one and this one.",
            "And now in the scoring.",
            "We want particular here.",
            "You see that some of the conditions are matched in notes that are pretty far from this one here in the in the in the craft.",
            "And so we would like to take this into account.",
            "In addition to the aggregation over the local scores that you get from matching these conditions, you want to take into account the compactness of the results up craft that you see here.",
            "Unfortunately, this leads to NP hard problems like those who have an iPhone algorithmics immediately seized Inatori problem, so and even though in our approaches we approximate this by using maximum spanning trees on the connection graph, again, we're playing precomputation tricks because this space is cheap and indexing time is a lot less critical than query time, but this is very initial work, so this is a long way to go.",
            "Getting XML IR work well.",
            "In terms of quality and efficiency on arbitrary graphs and Wikipedia in XML will be one is a wonderful test study."
        ],
        [
            "So conclusion so."
        ],
        [
            "So I think XML IR is of is a strategic direction for enterprise search.",
            "Definitely yes.",
            "For digital libraries it will play a role in database integration and I think on the web and could play a big role in combination with information extraction.",
            "Now this may not be for the full web.",
            "It may not be for like masses of users but think just off the web that is of interest to scientists.",
            "So all the pages from all universities, all scientists, all students in the world, all related projects.",
            "So this is a site very big.",
            "Portion of the of the weapon is of great interest, and information extraction could really add a lot of extra value to that.",
            "And then once you have that, once you have family, fight it XML.",
            "IR plays a role and probabilistic approximations and statistical techniques play a big role in getting this sufficient.",
            "Now open issues.",
            "So some more technical, I pointed you to some very recent work on scheduling, but I can imagine there's more things one could do.",
            "I get the question about correlations across dimension, so there's more things to be done here.",
            "Once we add information extraction on a larger scale.",
            "The the tax come with confidence values.",
            "What's a principled model for getting this into the scoring model?",
            "Is there an ocean like a statistical language model that would then kind of generate this new kind of XML data?",
            "And how do we handle this?",
            "Generalizing all that to crafts?",
            "Not just our approach to packs, but I know some other people here in the room are working on this in this direction from a database viewpoint, we would like to combine these things with other database operators, so we're doing this over combinations of structured data and text data and information extraction and rich data and so on.",
            "Think of applications like customer support or E health and you really have complex queries not post by end users, But my application developers.",
            "And then you need certainly need a way of adding this preferable manner to what database people called physical operator algebra and how to do query optimization with this and many years further down the road.",
            "The background is a database system.",
            "Nobody in database is locked up together and hardly anybody last text query, so redoing this in a cleaner manner and as we do it adding probabilistic semantics to all of that would be a really great charge.",
            "Thank you.",
            "Question.",
            "Athena one of the implications if the same information in the XML schema occurs at play, A tag level at one point at at at St level and another point in the background.",
            "Of course, is the ontologist asking you.",
            "The question was do we deal with elements differently from attributes, so tag names and as equally with the Contacts on our approach, we treat this all the same.",
            "In fact we all model is not real XML, but this more this labeled tree approach.",
            "There's lots of.",
            "Additional intricacies in the real XML.",
            "Some of them are actually idiosyncrasy's that we overlooked.",
            "I have mixed feelings, whether it makes sense to be so sophisticated in the long run, because then you get into the problem.",
            "How do we model data in XML?",
            "And what's the philosophical difference between saying this deserves to be an element name?",
            "And this deserves to be an attribute name, but I could imagine approaches that actually take them apart and treat them separately.",
            "Fact syntactically and.",
            "Our approach could handle this, just we didn't do it because I don't believe in it.",
            "So you just matching element names and attribute names and things like that into the ontology and gets the goodies waiting.",
            "Painters in some way.",
            "I can't follow this jump so far.",
            "No in the query language that may actually be different in what I next US, and certainly what experts full text us.",
            "But in our approach we treat element names and attribute names both as nodes in the tree.",
            "So on every node in a tree has a label and as a content.",
            "So you can view the attribute as a child of the element to which it belongs.",
            "This is much simpler.",
            "I don't even application programmers are not so super sophisticated.",
            "They don't want to think about all these little details all the time.",
            "Google.",
            "Question.",
            "Repent.",
            "There is 1.",
            "This is fun.",
            "Sequel or insane relations.",
            "You have this notion of joints that are very kind of into.",
            "So many things in a programmatic model, every almost every combination is different.",
            "It depends when they're combined, so things are correlated around correlated there generated by particular process and so thinking of some kind of syntax in which we would agree that would somehow allow us to just exist really hard.",
            "Do you have ideas of how that?",
            "So I think the question was understandable in the room, so This is why I said this is a long term challenge, so joins would be approximate joints to write, so join results have a probability of being in the result.",
            "Estimating this probability could be based on independent switches.",
            "The state of the art right?",
            "Or it could take into account crucial pieces of correlation information.",
            "So this field is widely open, so it was a big field.",
            "I'm back in like mid 90s with even ground work like helper and worked on probabilistic logics and then there was also in the IR field.",
            "There was quite a lot of good work going on but it didn't reach a breakthrough.",
            "So then it dawned for 15 years and now in the database world is gains attention again and I think it is just the I think it's the right way to go even though it may take 30 years to get his right to get it expressive enough.",
            "But at the same time efficiently efficient enough to be.",
            "Practical we shouldn't give up too quickly.",
            "We should keep going.",
            "I was wondering so the permission instructions and it's very important.",
            "If you're feeling for our complicated needs to do it robustly and with enough courage so that.",
            "Nude picture so this is I'm in this regards this is I'm not an expert here.",
            "I'm sure there are some more knowledgeable people in the room, but I recommend you.",
            "For example, trying out to the open source tool Gate and its notation to a component.",
            "Any.",
            "This is from the University of Sheffield, so you can actually have a web demo so you can put piece of text and let it tag personals locations, time intervals and so on.",
            "And it does a pretty good job and I'm sure there's commercial tools to IBM.",
            "Must have something they did all the big players should all have something I don't know whether this is an issue for the search engine.",
            "Companies like Yahoo, Google and MSN.",
            "But the companies that are in enterprise search have a story.",
            "So this goes along way for the simple things.",
            "As I said, person names, organization names are harder but still go along way, time and locations.",
            "With the tools like it.",
            "They're not very robust, especially if you main gets more.",
            "Place and reach.",
            "So I don't, yeah, I see your point.",
            "But I don't agree.",
            "Try out gate person names.",
            "Almost no errors.",
            "Location names is easy.",
            "Location names is mostly lexicons.",
            "Look us right so there's not a whole lot of learning.",
            "There's not a whole lot of NLP or statistics involved.",
            "A little bit of preprocessing, then you are right, there's my examples with like never being a painter and so on.",
            "This is sci-fi.",
            "This is where this is beyond what can be done now, but there's a low hanging food which goes along way.",
            "Now this may not be worthwhile or noisy.",
            "Web pages so arbitrary web pages or blocks, but you apply this to a page like Wikipedia with well formed natural language sentences with a clear structure which you can even add as an additional leverage for doing the tagging, and it goes a very long way, and so you certainly have accuracy above 90% for this an issue for tomorrow, OK?",
            "Johnson"
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So I realize I'm between you and lunch so, but I don't make any promises that I will be faster than the plant time.",
                    "label": 0
                },
                {
                    "sent": "So the topic is XML IR.",
                    "label": 0
                },
                {
                    "sent": "Why is this interesting?",
                    "label": 0
                },
                {
                    "sent": "It's quite a shift now in terms of topics, so at first glance there is little connection to the web.",
                    "label": 0
                },
                {
                    "sent": "It's much closer to databases, which is my home community and in databases we're interested in this as one potential key piece in information integration.",
                    "label": 0
                },
                {
                    "sent": "Think of looking at 100 different databases, all of which might have structure and schema like XML databases, and now you want to query them simultaneously, but you don't want to wait like weeks or months for some experts to actually deeply integrate them and create the data so that they are form a seamless.",
                    "label": 0
                },
                {
                    "sent": "Federated system.",
                    "label": 0
                },
                {
                    "sent": "So then you need to make up for the lack of global schema.",
                    "label": 0
                },
                {
                    "sent": "Each database has a schema where they differ, so altogether you don't easily have a schema and you need to cope with the inherent uncertainty that's introduced by that process so that from a database viewpoint from an IR viewpoint well adding structure and adding some kind of semantic annotations to the data, it should at least in principle give you a push towards more expressive search now that.",
                    "label": 0
                },
                {
                    "sent": "More expressive search.",
                    "label": 0
                },
                {
                    "sent": "Connecting to the previous talk might not be for an end user, certainly not for mass users on the web, so actually would be more at the level of application developers interfaces, so it would be hidden from end users, but nevertheless in the talk we will use concrete syntax for phrasing queries in X path and adding information retrieval semantics.",
                    "label": 0
                },
                {
                    "sent": "So what could these?",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "There is the queries that I think can be easily expressed and satisfactorily answered on the web, so they're toy queries, killer queries that I collected, no business value, just serving to demonstrate certain observations.",
                    "label": 0
                },
                {
                    "sent": "So the first one cannot be easily answered on the web because no single web page might qualify.",
                    "label": 0
                },
                {
                    "sent": "My address is on my home page, but then that page doesn't mention anything about teaching or research, so you need to follow one or two links and look at the little craft pattern that's embedded in the web craft.",
                    "label": 0
                },
                {
                    "sent": "So you need to do pattern matching plus the usual keyword search.",
                    "label": 0
                },
                {
                    "sent": "Number two is difficult because keyword search may not find the obvious answer.",
                    "label": 0
                },
                {
                    "sent": "Shakespeare's Macbeth, because the main clue, and if you look at the primary literature, not secondary literature, the main clue would be aligned.",
                    "label": 0
                },
                {
                    "sent": "Saying something like third, which: all Hail Macbeth Thane of Cawdor associate become King.",
                    "label": 0
                },
                {
                    "sent": "Now you need background knowledge.",
                    "label": 0
                },
                {
                    "sent": "The human would have that.",
                    "label": 0
                },
                {
                    "sent": "So which is?",
                    "label": 0
                },
                {
                    "sent": "And the literature?",
                    "label": 0
                },
                {
                    "sent": "Sorry all the ladies in the room are typically female.",
                    "label": 0
                },
                {
                    "sent": "Maybe it's a male prejudice, but this is.",
                    "label": 0
                },
                {
                    "sent": "How it goes?",
                    "label": 0
                },
                {
                    "sent": "So for most humans, it's pretty clear that third, which implies there are three women in this game, and similarly thing of quarter.",
                    "label": 0
                },
                {
                    "sent": "Some people might know it's the Scottish nobleman title, so you need to make these kind of semantic inferences in order to get a reasonable answer.",
                    "label": 0
                },
                {
                    "sent": "And the third example combines the complexities of these previous tool.",
                    "label": 0
                },
                {
                    "sent": "So here you can actually or you should put together bits and pieces from different sources like I could look up in my electronic calendar which PC's are you attended?",
                    "label": 0
                },
                {
                    "sent": "Which PC meetings are attended?",
                    "label": 0
                },
                {
                    "sent": "Then connect that to email in order to figure out on which of these are good.",
                    "label": 0
                },
                {
                    "sent": "Was the PC chair?",
                    "label": 0
                },
                {
                    "sent": "Then maybe go to a digital library in order to get a list of all the people on the PC and finally go to their web pages in order to check out.",
                    "label": 0
                },
                {
                    "sent": "Who these people might be?",
                    "label": 0
                },
                {
                    "sent": "The woman from Paris and this way I might come across a candidate like Sophie Clay in real contour.",
                    "label": 1
                },
                {
                    "sent": "And again we need to infer that Sophie is most likely female and walk in cooler.",
                    "label": 0
                },
                {
                    "sent": "Strictly not Paris, but close enough.",
                    "label": 0
                },
                {
                    "sent": "And finally, the engine also needs to kind of infer that by Paris I probably meant Paris, France and not Paris, TX, so these are difficult queries and they are way out.",
                    "label": 0
                },
                {
                    "sent": "So to get like the ideal answer on rank one.",
                    "label": 0
                },
                {
                    "sent": "This will keep the community busy another few decades so but XML might be a step into this direction towards quote semantic search.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So what if the semantic web existed anywhere in XML?",
                    "label": 0
                },
                {
                    "sent": "How far would we get?",
                    "label": 0
                },
                {
                    "sent": "So this is my first example.",
                    "label": 0
                },
                {
                    "sent": "This is my graphical illustration of XML, so these are just labeled trees.",
                    "label": 0
                },
                {
                    "sent": "Everything in red is tax element names and everything in black is content terms.",
                    "label": 0
                },
                {
                    "sent": "We have three web pages connected by X links or H ref pointers, so we.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Could express their query using X path written this way little twig query and what it does.",
                    "label": 0
                },
                {
                    "sent": "It essentially does semantically pattern matching in these trees or in the connected trees.",
                    "label": 0
                },
                {
                    "sent": "So this is the first condition and then we need to match this and that and that would be standard database evaluation.",
                    "label": 0
                },
                {
                    "sent": "If we have only data of this kind, so there's no IR element involved.",
                    "label": 0
                },
                {
                    "sent": "But suppose we don't have.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Few results that exactly match this quick query, so then in order to get more results we are going for approximate matches and so here I've chancler colleague in the Institute would be such an approximate match, but his tag name is not.",
                    "label": 0
                },
                {
                    "sent": "Professor is lecturer, his content address does not mention supporting explicitly, but again you could plug in background knowledge in order to infer this and so this would be a decent approximate match.",
                    "label": 0
                },
                {
                    "sent": "And we are using like generalization relaxation of X path queries where we can approximately match tech names and also content terms.",
                    "label": 0
                },
                {
                    "sent": "So we use this~ sign.",
                    "label": 0
                },
                {
                    "sent": "Hopefully I also wanted to give an online demo first, but I was afraid of technical problems, so the~ sign on the keyboard would have killed me too.",
                    "label": 0
                },
                {
                    "sent": "So and then this would be an approximate match.",
                    "label": 0
                },
                {
                    "sent": "So bottom line here.",
                    "label": 0
                },
                {
                    "sent": "As we need to combine database and information retrieval techniques and this is a field I've been working on for a number of years and others including Ricardo have been promoting this also for a long time.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "After this motivation, now the talk is 3 parts.",
                    "label": 0
                },
                {
                    "sent": "So I will first elaborate a bit more on the functionality of XML, IR an how lightweight ontologies author I can be plugged in, and then the main point is actually an efficiency.",
                    "label": 0
                },
                {
                    "sent": "How can we efficiently run these kinds of queries which obviously are a lot more complex than simple keyword queries?",
                    "label": 0
                },
                {
                    "sent": "And for that purpose we will first look at a simpler model named the keyword queries and after that I will show at the in the last part how to carry this over into the XML world.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This doesn't start from scratch.",
                    "label": 0
                },
                {
                    "sent": "There's a long history of research to build on web query languages that never were applied on the web, but led to XML query languages in some form.",
                    "label": 1
                },
                {
                    "sent": "There's IR unstructured documents, foundational work in the mid 90s or maybe even earlier, which then led to IR on XML, which has now become pretty mainstream.",
                    "label": 0
                },
                {
                    "sent": "I know there is a bunch of you here in the room who are also working on this, but I don't think the XML IR subgroup in this nice workshop.",
                    "label": 0
                },
                {
                    "sent": "Forms a majority so and there is commercial interest.",
                    "label": 0
                },
                {
                    "sent": "Now there's an index benchmark being established and being successfully run for a number of years, so our engine or prototype engine top X hosts some of the tasks and is iaccessible.",
                    "label": 0
                },
                {
                    "sent": "If you register for IMAX.",
                    "label": 0
                },
                {
                    "sent": "And the World Wide Web Consortium is considering extensions to the X path and expert standards that would take care of full text search and scoring and ranking.",
                    "label": 0
                },
                {
                    "sent": "So a.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "These queries have standard apart from the syntax.",
                    "label": 0
                },
                {
                    "sent": "Maybe Standard X path one.",
                    "label": 0
                },
                {
                    "sent": "Abstracts index so we have these elementary conditions on tag names and then content, often referring to the child or descendant access, and in this talk I will only refer to this the slash slash.",
                    "label": 1
                },
                {
                    "sent": "And very in a real nutshell, the query results all.",
                    "label": 0
                },
                {
                    "sent": "That's the semantic definition of such a query, is that the result would be a subcraft that's isomorphic to the query pattern.",
                    "label": 0
                },
                {
                    "sent": "And of course that's a tall order, and then you need to have the right pre computations and indexing strategies in order to get this sufficient.",
                    "label": 1
                },
                {
                    "sent": "Once we add the similarity conditions with the~ operator.",
                    "label": 0
                },
                {
                    "sent": "Here we need relevance scoring and we have two aspects here.",
                    "label": 0
                },
                {
                    "sent": "One is for the content terms.",
                    "label": 0
                },
                {
                    "sent": "Like XML, so here we write to the XML.",
                    "label": 0
                },
                {
                    "sent": "So even here we could add a scoring and ranking semantics.",
                    "label": 0
                },
                {
                    "sent": "So we do this by using standard IR technology.",
                    "label": 0
                },
                {
                    "sent": "In particular, our engine uses a variation of the Okapi BM 25 probabilistic IR model with one twist that all the ingredients like term, frequencies or IDF values and our tag term pair specific.",
                    "label": 0
                },
                {
                    "sent": "So that's for the content conditions.",
                    "label": 0
                },
                {
                    "sent": "For the tag conditions, the which forms the structural backbone like tell the research statistics.",
                    "label": 0
                },
                {
                    "sent": "Frequency statistics doesn't make sense because these are single words in the place where they occur.",
                    "label": 0
                },
                {
                    "sent": "So here we use some lightweight ontology where we exploit similarities between different concept names, like a similarity between professor and lecturer for example.",
                    "label": 1
                },
                {
                    "sent": "So bottom line, here is a query.",
                    "label": 0
                },
                {
                    "sent": "Now is a relaxable pattern and results are approximate matches.",
                    "label": 1
                },
                {
                    "sent": "So this is the.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "On slide I have on Thorion contala.",
                    "label": 0
                },
                {
                    "sent": "Geez, we're really not into semantic web.",
                    "label": 0
                },
                {
                    "sent": "This is nothing about owl or things of that kind.",
                    "label": 0
                },
                {
                    "sent": "So we build a graph representation of concepts and relations.",
                    "label": 0
                },
                {
                    "sent": "Different typed relations like these.",
                    "label": 0
                },
                {
                    "sent": "This is made up.",
                    "label": 0
                },
                {
                    "sent": "This is not real, by the way.",
                    "label": 0
                },
                {
                    "sent": "The sources for that would be word, Nat, geographic gazetteers, doing some mining on web forms and tables, extracting concepts, entities and relations from Wikipedia and so forth.",
                    "label": 1
                },
                {
                    "sent": "So it's not my main sales pitch here.",
                    "label": 0
                },
                {
                    "sent": "Adjust.",
                    "label": 0
                },
                {
                    "sent": "This isn't encapsulated piece and then all edges.",
                    "label": 0
                },
                {
                    "sent": "All the relationships are are statistically weighted, which I think is crucial in order to make a kind of inferences, we need to make for very few relations are hard facts like remember the woman from Paris and it was not Paris in a strict logical sense because she is in or conquer and there would have been ambiguity about which Paris are meant.",
                    "label": 0
                },
                {
                    "sent": "But statistically, this works well, and so we actually estimate correlation measures such as dice coefficient.",
                    "label": 1
                },
                {
                    "sent": "But there are other measures from large corpora.",
                    "label": 0
                },
                {
                    "sent": "Now, once we have this and we have a query of this kind, either Justin keyword form or in some semi XML form or in full XML form, we map the words in the query and to this concept space comparing a context and the query world and the query side and the craft context here along with these weighted edges and this gives us a ristic's for word sense disambiguation and then we can expand the query using a thresholding mechanism.",
                    "label": 0
                },
                {
                    "sent": "So all the related.",
                    "label": 1
                },
                {
                    "sent": "Concepts and their synonyms with similarity above some threshold are added and it produces a bigger expanded query along with query term weights.",
                    "label": 0
                },
                {
                    "sent": "And the key point which I'm going to get it in a few minutes is that we should execute this now, efficiently and no.",
                    "label": 0
                },
                {
                    "sent": "Just the expansion process already incurs quite some complexity because of seemingly harmless query might be expanded into a 50 keyword query with weights.",
                    "label": 1
                },
                {
                    "sent": "So the query expansion is a double edged sword, as all the knowledgeable people in iron.",
                    "label": 0
                },
                {
                    "sent": "Oh, so it helps for some queries, but it's difficult to tune and in some queries it might lead to a topic drift if you over expand.",
                    "label": 0
                },
                {
                    "sent": "So that tuning of the threshold is really a little nightmare.",
                    "label": 1
                },
                {
                    "sent": "An in benchmarks.",
                    "label": 0
                },
                {
                    "sent": "You can tune a lot, but in a real application setting you can't do this.",
                    "label": 0
                },
                {
                    "sent": "So we also worked on a method which I'm going to present in awhile.",
                    "label": 0
                },
                {
                    "sent": "That pretty much eliminates the need for having a threshold at all and makes the whole expansion process a lot more robust and more efficient.",
                    "label": 0
                },
                {
                    "sent": "Now a little.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Detour here.",
                    "label": 0
                },
                {
                    "sent": "So where is the XML on the web?",
                    "label": 0
                },
                {
                    "sent": "So there is no not much XML, it's but there's a lot of XML and companies that publish data on the web just at the very end they cast into HTML.",
                    "label": 0
                },
                {
                    "sent": "But on the Surface Web exciting data is things like Wikipedia for example, which is good old text plus a bit off surface markup.",
                    "label": 0
                },
                {
                    "sent": "But there is information extraction technology.",
                    "label": 0
                },
                {
                    "sent": "I don't know how much this will be covered later in the workshop, so and that goes along way that has become a reasonably mature technology.",
                    "label": 0
                },
                {
                    "sent": "So we can run named entity recognition tools and get person tagged post person names tag, get time periods, tag, publications and so forth.",
                    "label": 0
                },
                {
                    "sent": "We might even infra relations between a publication and a topic of the publication weaken.",
                    "label": 0
                },
                {
                    "sent": "Tagging is seamlessly goes into classification.",
                    "label": 0
                },
                {
                    "sent": "So here we might infer that Newton is a scientist.",
                    "label": 0
                },
                {
                    "sent": "Becausw the text mentions he is a physicist, mathematician astronomer.",
                    "label": 0
                },
                {
                    "sent": "Here at two in the classification, you can leverage the Thore and lightweight ontologies.",
                    "label": 0
                },
                {
                    "sent": "By the way, if we are deep into NLP and R&R Bolden good enough, we might be able to infer from this little sentence.",
                    "label": 0
                },
                {
                    "sent": "Shares credit with Leibnitz that Leibnitz must have been a scientist too, and then this is probably something that no NLP guy can do today, so inferring that Nella was a painter.",
                    "label": 0
                },
                {
                    "sent": "So the message here is information extraction with its suite of techniques, NLP pattern matching, lexicons, learning, statistical learning goes along way, and in principle we could cast this data into a database just either either tables or XML.",
                    "label": 1
                },
                {
                    "sent": "It doesn't matter.",
                    "label": 0
                },
                {
                    "sent": "It could also be RDF.",
                    "label": 0
                },
                {
                    "sent": "These are only syntactic variations, but this is not a hard fact database, but the individual entries might have confidence less than one because they were.",
                    "label": 0
                },
                {
                    "sent": "Inferred by some heuristics or some statistical learning process.",
                    "label": 0
                },
                {
                    "sent": "Once you attach like confidence, well, yes to this.",
                    "label": 0
                },
                {
                    "sent": "This is almost like term index weights in IR.",
                    "label": 0
                },
                {
                    "sent": "So then you certainly have an inherent uncertainty in your data and as you combine this data with other data, so evaluating queries and making connections then ranked retrieval is a must.",
                    "label": 0
                },
                {
                    "sent": "So I think this would be maybe not tomorrow, but in a few years from now we might be able to do things of that kind.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "No efficiency.",
                    "label": 0
                },
                {
                    "sent": "So how?",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "How do we evaluate queries?",
                    "label": 0
                },
                {
                    "sent": "And now we go back half a step and look at keyword queries so we all know we operate over inverted index lists where we have these document ID or web page ID score pairs.",
                    "label": 0
                },
                {
                    "sent": "So scores would be pre computed using probabilistic IR statistical language models.",
                    "label": 0
                },
                {
                    "sent": "Whatever at query runtime for a three keyword query like this.",
                    "label": 0
                },
                {
                    "sent": "Essentially you perform score aggregation.",
                    "label": 0
                },
                {
                    "sent": "So we try to find the same document in multiple lists like this one here and here and you sum up.",
                    "label": 0
                },
                {
                    "sent": "This course could be summation weighted summation.",
                    "label": 0
                },
                {
                    "sent": "More complicated things, as long as we perform a monotonic score aggregation.",
                    "label": 0
                },
                {
                    "sent": "We are in the framework that I'm going to present now.",
                    "label": 0
                },
                {
                    "sent": "The textbook algorithm simple textbook algorithms would be fetch the index list and then do some computation with them in memory.",
                    "label": 0
                },
                {
                    "sent": "But this index list could be long so they could easily be a MB long.",
                    "label": 0
                },
                {
                    "sent": "A MB is multiple disc tracks, so you're keeping your desk quite busy.",
                    "label": 0
                },
                {
                    "sent": "Now this does not matter in a single user system, but on a server you're running hundreds of thousands of queries simultaneously, so you want to be stingy with resource consumption, otherwise your throughput and your multi user response time are really badly affected, so we want to avoid reading the entire index lists and instead ideally because in the end we want to precompute top K results like top ten, top 100, top 1000, but not top 1 million in a completely ranked order.",
                    "label": 0
                },
                {
                    "sent": "So ideally we read only short prefixes of these lists and we should be done.",
                    "label": 0
                },
                {
                    "sent": "And there's a nice.",
                    "label": 0
                },
                {
                    "sent": "This does not work anyway, so there's a nice algorithmic paradigm for this that goes back a long time into IR, where it still stayed out of you Ristic level, and Ron Fagin and colleagues actually gas this into an elegant framework known as the family of threshold algorithms.",
                    "label": 0
                },
                {
                    "sent": "I'm going to illustrate one particular variation of this, and so you don't need to read the pseudocode here.",
                    "label": 0
                },
                {
                    "sent": "The point is, is a very elegant piece of work because it's such compact pseudocode.",
                    "label": 0
                },
                {
                    "sent": "So you can almost implement it this way.",
                    "label": 0
                },
                {
                    "sent": "There's the difference between pseudocode and code is not really big.",
                    "label": 0
                },
                {
                    "sent": "The Fagan also characterized it in terms of nice theoretical properties.",
                    "label": 0
                },
                {
                    "sent": "For example, this algorithm has is asymptotically instance optimal, so whatever your data looks like, it's always asymptotically optimal.",
                    "label": 0
                },
                {
                    "sent": "Of course, asymptotically Heights all the constants and second, he assumes the number of less over which this runs as constant two.",
                    "label": 0
                },
                {
                    "sent": "Now the illustration, the algorithm and that special specific variant performs only sequential accesses on these lists.",
                    "label": 0
                },
                {
                    "sent": "So there's no like random look ups of interesting scores, becausw sequential accesses amortized are like factor of 22,000 faster than random accesses.",
                    "label": 0
                },
                {
                    "sent": "20 would be.",
                    "label": 0
                },
                {
                    "sent": "You look at a raw disk.",
                    "label": 0
                },
                {
                    "sent": "Once you Add all the software and we measure this.",
                    "label": 0
                },
                {
                    "sent": "Actually you get much bigger factor, so we measured it on database systems and we measured it on file systems.",
                    "label": 0
                },
                {
                    "sent": "So we want to do sequential accesses mostly.",
                    "label": 0
                },
                {
                    "sent": "So we scan this list round Robin and as we know this should have gone away in the animation doesn't matter is different PowerPoint version than mine.",
                    "label": 0
                },
                {
                    "sent": "So we scan the first entries and we collect that information in a main memory data structure which takes the form of a priority queue.",
                    "label": 0
                },
                {
                    "sent": "So that becomes interesting the first time when we have scanned the second entries, because now we've seen one document 78 twice.",
                    "label": 0
                },
                {
                    "sent": "And what we do in this data structure, we keep track of an interval for the true final score of a document.",
                    "label": 0
                },
                {
                    "sent": "So we have a lower bound for the score coin were score, which because we use just simple summation in this example, is the sum of the scores we've seen for that document, and there is an upper bound, namely the worst core plus the best possible score mass.",
                    "label": 0
                },
                {
                    "sent": "That this document could get from any of the lists know from all the lists together in which we haven't seen the document so far.",
                    "label": 0
                },
                {
                    "sent": "So in this case is only here and that best possible score we could get here is actually upper bounded by the last quarter that we have seen.",
                    "label": 0
                },
                {
                    "sent": "We call this the high values, so this is the algorithmic principle, and at some point hopefully something good happens.",
                    "label": 0
                },
                {
                    "sent": "So at the point when the worst score of the current rank K document now, for simplicity this is K = 1.",
                    "label": 0
                },
                {
                    "sent": "Is at least as high as the best core of all the other candidates and we can stop safely terminate the algorithm and that should happen after scanning the like 10% of the list.",
                    "label": 0
                },
                {
                    "sent": "In some cases only 1% or 2%.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now the can this algorithm be improved in our own work kicks in, so where we actually improve on that?",
                    "label": 0
                },
                {
                    "sent": "Well, first of all, let's say Fagan is a top notch theoretician, but when we first implemented it, it didn't perform.",
                    "label": 0
                },
                {
                    "sent": "So create an it took some additional implementation tricks.",
                    "label": 0
                },
                {
                    "sent": "How do you maintain priority queue and little details that in the end, matter a lot?",
                    "label": 0
                },
                {
                    "sent": "So just our right implementation compared to the first implementation already caused the difference of one to two orders of magnitude in measured performance.",
                    "label": 0
                },
                {
                    "sent": "Now, but here's an algorithmic element that further improves and gives us another order of magnitude, and that's a probabilistic consideration.",
                    "label": 0
                },
                {
                    "sent": "So the algorithm is based on that invariant were score is the score summation in the list where we've seen the document.",
                    "label": 0
                },
                {
                    "sent": "This is a lower bound and upper bound is at worst core plus the.",
                    "label": 0
                },
                {
                    "sent": "Upper bounds these high values for the unknown scores in all the lists where we've seen haven't seen a document now that leads us into like a little illustration for the behavior of 1 candidate document in its lifetime.",
                    "label": 0
                },
                {
                    "sent": "As we scan the list as we go deeper and deeper and what happens is that these core intervals gradually get converged towards a point, but it may take a long time to get this to a point for all.",
                    "label": 0
                },
                {
                    "sent": "Candidates so we would like to avoid running that long and we can compare the intervals to the main K threshold.",
                    "label": 0
                },
                {
                    "sent": "That's the worst core of the current rank document.",
                    "label": 0
                },
                {
                    "sent": "This is what drives the door has given the algorithm.",
                    "label": 0
                },
                {
                    "sent": "The family of algorithms, its name threshold algorithms.",
                    "label": 0
                },
                {
                    "sent": "So when the.",
                    "label": 0
                },
                {
                    "sent": "Disco interval gets completely above the red line.",
                    "label": 0
                },
                {
                    "sent": "We know we have a top K result for the time being when it drops completely below the red line.",
                    "label": 0
                },
                {
                    "sent": "We know this can never ever qualify for the result and at this point we can throw this away as a candidate.",
                    "label": 0
                },
                {
                    "sent": "Now this garbage collection or pruning candidates is also important.",
                    "label": 0
                },
                {
                    "sent": "It's not just important that the algorithm terminates fast, but also that we get rid of candidates quickly.",
                    "label": 0
                },
                {
                    "sent": "Becausw the this.",
                    "label": 0
                },
                {
                    "sent": "Priority queue data structure micro in a nontrivial manner.",
                    "label": 0
                },
                {
                    "sent": "Again, it will not grow to gigabytes, but megabytes and running on a server.",
                    "label": 0
                },
                {
                    "sent": "This is needs to be done for every one out of, let's say, thousand concurrent queries.",
                    "label": 0
                },
                {
                    "sent": "So we want to be stingy again with the memory consumption.",
                    "label": 0
                },
                {
                    "sent": "I want to be able to throw away candidates as early as possible.",
                    "label": 0
                },
                {
                    "sent": "Now, in this conservative approach, we can drop this from the priority queue only at this point, not here, but that figure already suggests a probabilistic interpretation.",
                    "label": 0
                },
                {
                    "sent": "If simple minded, there were a uniform probability of for every point on this segment to be the true score.",
                    "label": 0
                },
                {
                    "sent": "Then you see this small ratio compared to that big thing suggests we can prune this document and we make a small probabilistic error.",
                    "label": 0
                },
                {
                    "sent": "Now things are a bit more complicated.",
                    "label": 0
                },
                {
                    "sent": "And this leads to this consideration.",
                    "label": 0
                },
                {
                    "sent": "So what we actually do, we estimate the probability that this candidate document D in the end.",
                    "label": 0
                },
                {
                    "sent": "If we add the unknown scores here.",
                    "label": 0
                },
                {
                    "sent": "Gets a final score that is above this MNK threshold so this Delta which should be instantiated by men.",
                    "label": 0
                },
                {
                    "sent": "Kate and the trick for doing this is we replace the conservative high bounds, just conservative upper bounds by random variables.",
                    "label": 0
                },
                {
                    "sent": "SI which of course need to be estimated from information about the distribution of scores in the different index lists.",
                    "label": 0
                },
                {
                    "sent": "But that's something we can precompute and keep along with the index fact it's much smaller than the actual index, so we would keep that information in memory of.",
                    "label": 0
                },
                {
                    "sent": "Bring it into memory when the query is started and then at query runtime we do the right calculations.",
                    "label": 0
                },
                {
                    "sent": "If we do this right then we would discard a candidate from the queue if that toepke qualification probability drops below some journable epsilon, say 10% one percent just a second.",
                    "label": 0
                },
                {
                    "sent": "And that translates into an actual guarantee for the expected relative precision where relative this is, I think, Alessandro colleague competitiveness recall, so that we assume the conservative top care algorithm is ground truth and relative to that we making some probabilistic error, which leads to relative precision or relative recall.",
                    "label": 0
                },
                {
                    "sent": "This is the same here and then this is 1 minus epsilon, so let's say 90% or 99 question.",
                    "label": 0
                },
                {
                    "sent": "Independent, yes, yes yeah.",
                    "label": 0
                },
                {
                    "sent": "I'll come to that I come to that.",
                    "label": 0
                },
                {
                    "sent": "So how do we actually estimate this?",
                    "label": 0
                },
                {
                    "sent": "Because we're not only looking at expectations here, we need to compute the convolution of distributions.",
                    "label": 0
                },
                {
                    "sent": "There's a number of ways actually, the next slide goes through this.",
                    "label": 0
                },
                {
                    "sent": "So one is we.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "After late distributions.",
                    "label": 0
                },
                {
                    "sent": "And this might not be text only in the XML world we're interested in combining text with other data, so that might be categorical attribute distributions and might be an scores derived from that.",
                    "label": 0
                },
                {
                    "sent": "There might be numerical distributions and scores derived from that, so different attributes, different dimensions might have different distributions.",
                    "label": 0
                },
                {
                    "sent": "So in principle we could make educated guesses or analysis to postulate some parameter form and then compute convolutions analytically using Laplace transforms.",
                    "label": 0
                },
                {
                    "sent": "And then using large deviation bounds, there is some work on taking correlations into account in a very limited extent.",
                    "label": 0
                },
                {
                    "sent": "Practically this did not work that well.",
                    "label": 0
                },
                {
                    "sent": "The bounds get way too conservative.",
                    "label": 0
                },
                {
                    "sent": "If we wanted to take correlation into account in, uh, in ways other than this, we would have to look at 2 dimensional distributions, right?",
                    "label": 0
                },
                {
                    "sent": "Would have to characterize identify good candidates where correlation is very prominent, important to capture and then do something special in the pre computation principle.",
                    "label": 0
                },
                {
                    "sent": "The framework would work as well.",
                    "label": 0
                },
                {
                    "sent": "Now an alternative would be to make specific assumptions about the parametric form like fossil mixtures because their convolution leads to fossil mixtures again and then the parameters would be fit by.",
                    "label": 0
                },
                {
                    "sent": "Precomputation, or we don't make any assumptions and just use histograms precomputed per dimension.",
                    "label": 0
                },
                {
                    "sent": "But here again if you tell us so this small fraction of.",
                    "label": 0
                },
                {
                    "sent": "Pairs of dimensions is interesting in terms of their correlation.",
                    "label": 0
                },
                {
                    "sent": "We could of course, plug in 2 dimensional or multidimensional histograms and then a query runtime.",
                    "label": 0
                },
                {
                    "sent": "We compute the convolution dynamically so it turns out this works best by far.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Also, this is on an old benchmark.",
                    "label": 0
                },
                {
                    "sent": "So with standard queries with comparing or optimized implementation of the sorted access version of TA or N, also known as NRA against our probabilistic techniques, we win a factor of four in terms of abstract cost, measure and a factor of 10 in terms of runtime, which has to do with the better memory management.",
                    "label": 0
                },
                {
                    "sent": "And we also compare like quality.",
                    "label": 0
                },
                {
                    "sent": "So because here we employ additional heuristic tricks in addition to this probabilistic approximation.",
                    "label": 0
                },
                {
                    "sent": "This should actually have been 0.9 because we use epsilon 10% and it didn't hold.",
                    "label": 0
                },
                {
                    "sent": "But then you can use other measures as well.",
                    "label": 0
                },
                {
                    "sent": "Rank distances, foot rule, candle store score errors and also here this data comes with relevance assessments from track.",
                    "label": 0
                },
                {
                    "sent": "So you can look at precision at K or at map and in the latter regards actually the results were almost indistinguishable.",
                    "label": 0
                },
                {
                    "sent": "So this bottom line is we speed up these queries by a factor of 10 in some cases even more.",
                    "label": 0
                },
                {
                    "sent": "Depending on the nature of the queries and the result quality is by and large acceptable, there's a little bit.",
                    "label": 0
                },
                {
                    "sent": "At some point it will be great, but it goes along way.",
                    "label": 0
                },
                {
                    "sent": "Now.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the same thing can be done with expansions like.",
                    "label": 0
                },
                {
                    "sent": "This is probably in the USA.",
                    "label": 0
                },
                {
                    "sent": "Politically incorrect query expansion, but in Europe I should be safe.",
                    "label": 0
                },
                {
                    "sent": "So here again just here you see the abstract cost saving is no longer that impressive because we're now talking at 20 dimensional keyword query, but the runtime gain is still significant and I come to these expansions also on the next slide.",
                    "label": 0
                },
                {
                    "sent": "So expect.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Actions I mentioned before.",
                    "label": 0
                },
                {
                    "sent": "This is a double edged sword so they can work well, but sometimes they fail miserably, so we have two things to offer here.",
                    "label": 0
                },
                {
                    "sent": "One is a different score aggregation function, so instead of justice aggregating the score contributions from all the expansion terms we take for one given originally keyword in the query only the best expansion contribution.",
                    "label": 0
                },
                {
                    "sent": "So if we expand Professor into these possible candidates, they come with a with a weight with the similarity wait between this original.",
                    "label": 0
                },
                {
                    "sent": "Term and the possible expansions and the contribution of a document that matches lecturer times that, as the contribution and only the best for candidate documents, only the best contributions out of these possible ones is counted so that changes the aggregation Frank function into a summation over original query terms and then this is done over a maximum over the possible expansions.",
                    "label": 0
                },
                {
                    "sent": "So nice thing is it stays monotonic.",
                    "label": 0
                },
                {
                    "sent": "All the work about the threshold algorithms apply, and even the the score prediction machinery can be adapted to take this into consideration.",
                    "label": 0
                },
                {
                    "sent": "The second thing probably even more important, is that we do this expansions dynamically on the fly.",
                    "label": 0
                },
                {
                    "sent": "As we move down in the lists and this is best explained by animation.",
                    "label": 0
                },
                {
                    "sent": "So we start scanning.",
                    "label": 0
                },
                {
                    "sent": "In the usual way, and at some point we realized so we had a score of 0.6.",
                    "label": 0
                },
                {
                    "sent": "Now the best possible expansion would have a similarity weight of 0.7, but then if it had the document that contains this had a perfect score of say 1.0.",
                    "label": 0
                },
                {
                    "sent": "This would be better than the following matches for the original term, and this is the first time that it's worthwhile doing this, and so at this point, and only at this point we start scanning here and we scan.",
                    "label": 0
                },
                {
                    "sent": "And of course, the same effect occurs another time.",
                    "label": 0
                },
                {
                    "sent": "So at some point I think it was here something 0.8 * 0.6.",
                    "label": 0
                },
                {
                    "sent": "Sorry, Zero point 6 * 1 Perfect score gets better than 0.8 * 0.7, So this is the way we apply this method.",
                    "label": 0
                },
                {
                    "sent": "You can think of this as a dynamic merging of the index lists.",
                    "label": 0
                },
                {
                    "sent": "And the scheduling becomes a bit more tricky here.",
                    "label": 0
                },
                {
                    "sent": "It's no longer round Robin obviously, so rather it has a query flavor.",
                    "label": 0
                },
                {
                    "sent": "So by and large this gives very good quality.",
                    "label": 0
                },
                {
                    "sent": "So we participated in the TB benchmark with decent results or expansions which driven by word net, so that alone you can't win the benchmark.",
                    "label": 0
                },
                {
                    "sent": "But we had decent results, and we our technique improve the performance by a factor of four, and in some cases even higher.",
                    "label": 0
                },
                {
                    "sent": "No.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "How am I doing in time?",
                    "label": 0
                },
                {
                    "sent": "How much more time do I have?",
                    "label": 0
                },
                {
                    "sent": "OK so a few words about scheduling because this is very recent.",
                    "label": 0
                },
                {
                    "sent": "Even unpublished work, so the scheduling could be another boost factor in improving performance.",
                    "label": 0
                },
                {
                    "sent": "So Fagan already did some less observed or appreciate it.",
                    "label": 0
                },
                {
                    "sent": "Work on that, which nevertheless is very inspiring and valuable, so he said, well, a small amount of random accesses seems worthwhile, so we want to scan primarily and sequential.",
                    "label": 0
                },
                {
                    "sent": "Order but once in awhile we should do some random accesses to look up missing score information about the most worthy candidates, and this algorithm would be driven by a cost ratio between one random access and one sequential access.",
                    "label": 0
                },
                {
                    "sent": "Let's say 100 or so, and then every so many rounds of the sequential access, can't he would incur around of random lockups using some greedy strategy for picking which candidates are chosen to get more score information.",
                    "label": 0
                },
                {
                    "sent": "Now he has a nice theoretical analysis.",
                    "label": 0
                },
                {
                    "sent": "This is four M + K competitive.",
                    "label": 0
                },
                {
                    "sent": "So compared to a fictitious optimal schedule, so that's actually kind of a lower bound for an optimal schedule that may not be feasible by an online algorithm, but nevertheless it can compare to this.",
                    "label": 0
                },
                {
                    "sent": "Now this looks really good on paper, but when you think it through no, M is the number of index lists, so we do expansion.",
                    "label": 0
                },
                {
                    "sent": "So we quickly have like 20 or so here, so we quickly have a factor of 100.",
                    "label": 0
                },
                {
                    "sent": "Question factor of 100 is quite a lot on a multi user server.",
                    "label": 0
                },
                {
                    "sent": "So we looked at this.",
                    "label": 0
                },
                {
                    "sent": "And we came up with.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Two strategies, one as on the essay scheduling for sequential accesses.",
                    "label": 0
                },
                {
                    "sent": "There's no the round Robin.",
                    "label": 0
                },
                {
                    "sent": "Discipline is not God given, so instead we could say well, because we have histogram information.",
                    "label": 0
                },
                {
                    "sent": "In some sense we have precomputed look ahead information in a very compact form.",
                    "label": 0
                },
                {
                    "sent": "So we might say, well, the score distributions matter too, and also the information that we have accumulated already.",
                    "label": 0
                },
                {
                    "sent": "So we might say, well, let's perform now 1000 steps on this index lists overall, but let's divide them up in an uneven manner.",
                    "label": 0
                },
                {
                    "sent": "And that leads actually to a combinatorial optimization problem which is NP hard, but again, a little engineering trick you don't want to do this with the individual index step.",
                    "label": 0
                },
                {
                    "sent": "These index list sits in disk blocks and a desk Clock should be a disc track, so it's something like 100K.",
                    "label": 0
                },
                {
                    "sent": "So we actually do this over batches of disk block accesses and then the size of the knapsack related NP hard problem becomes a lot lower, and we can actually solve that at runtime optimally.",
                    "label": 0
                },
                {
                    "sent": "The other consideration is about random accesses.",
                    "label": 0
                },
                {
                    "sent": "So there's a bunch of considerations.",
                    "label": 0
                },
                {
                    "sent": "1 interesting is that we should not interleave sequential accesses and random accesses, but should save the random access is for the for the end.",
                    "label": 0
                },
                {
                    "sent": "In fact, our and there's some theoretical arguments for this or best methods proceed by sequential access only up to some point when we estimate that the total cost of remaining random accesses is equal to what we have invested up to this point.",
                    "label": 0
                },
                {
                    "sent": "There is some theoretical justification for this, and then we switch.",
                    "label": 0
                },
                {
                    "sent": "The strategy and then we perform only random accesses and will use cost prediction models in order to determine a good order for this, so some.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Solves very recent on terabytes data.",
                    "label": 0
                },
                {
                    "sent": "Here we re implemented everything from a database system based engine.",
                    "label": 0
                },
                {
                    "sent": "We used to be on top of a database system so our index scan steps were actually JDBC calls.",
                    "label": 0
                },
                {
                    "sent": "Now we went for a file system implementation and got all the numbers down to things like a few milliseconds per query and this is as K increases for top K. This is the abstract cost measure.",
                    "label": 0
                },
                {
                    "sent": "Weighted sum of sequential and random accesses.",
                    "label": 0
                },
                {
                    "sent": "See for example in green is the sequential access only algorithm and blue is this combined algorithm by Fagan, with periodic random accesses.",
                    "label": 0
                },
                {
                    "sent": "And this is our best technique and this is a lower bound for the optimal schedule, so we're very this is the most striking thing.",
                    "label": 0
                },
                {
                    "sent": "We're very close to the lower bound anyway.",
                    "label": 0
                },
                {
                    "sent": "We win roughly a factor of four or five in terms of abstract costs and also in terms of runtimes.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Last part.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And I hope I have 10 minutes left.",
                    "label": 0
                },
                {
                    "sent": "So now coming to XML, how do these techniques apply to XML?",
                    "label": 0
                },
                {
                    "sent": "So recall again, the queries are now a lot more complicated.",
                    "label": 0
                },
                {
                    "sent": "They have these content conditions in combination with tax and there's also structural conditions.",
                    "label": 0
                },
                {
                    "sent": "For example, affiliation an element with that tag name should be a descendant of an element with the tag name book in the same document.",
                    "label": 0
                },
                {
                    "sent": "So, but we were driven by taking the TA style top K algorithms and applying them to the setting and adopting them as needed.",
                    "label": 0
                },
                {
                    "sent": "And in doing this we encountered a bunch of problems and this is the vote I view of of how we solve them.",
                    "label": 0
                },
                {
                    "sent": "So the first one is maybe not a problem, but more an opportunity.",
                    "label": 0
                },
                {
                    "sent": "So disk space is cheap.",
                    "label": 0
                },
                {
                    "sent": "Disk IO is not, so we were generous about using disk space for some sense, redundant indexing.",
                    "label": 0
                },
                {
                    "sent": "So in particular when we precompute and store scores, we do this for entire subtrees rooted at some element of interest, not just so for the element alone.",
                    "label": 0
                },
                {
                    "sent": "And then when we need the score for the entire subtree.",
                    "label": 0
                },
                {
                    "sent": "We computed at query time, but this is precomputed.",
                    "label": 0
                },
                {
                    "sent": "There's some redundancy here, but it's fine because disk space is indeed cheap.",
                    "label": 0
                },
                {
                    "sent": "Now contact conditions are no longer on terms, only about ontact turn pairs, so we're interested in the content terms page rank, but only in combination with attack reference.",
                    "label": 0
                },
                {
                    "sent": "So we just index the pairs.",
                    "label": 0
                },
                {
                    "sent": "Might think there's a combinatorial explosion quit writing explosion, but there should be a lot less tax than terms.",
                    "label": 0
                },
                {
                    "sent": "So we have an apples and oranges comparison problem when we aggregate scores because we actually see in this index list cause for subtrees and in the end the unit that we want to score and rank is entire documents.",
                    "label": 0
                },
                {
                    "sent": "So and we use some engineering tricks in order to get the elements course for subtrees in the right order.",
                    "label": 0
                },
                {
                    "sent": "So and we prefetch a little bit so that we see one interesting element.",
                    "label": 0
                },
                {
                    "sent": "We get all the elements.",
                    "label": 0
                },
                {
                    "sent": "For the same document in the same query condition and that helps pass conditions need to be checked to like book is an ancestor of affiliation.",
                    "label": 0
                },
                {
                    "sent": "An ancestor of reference reference has Descendance publisher and publishers count Country.",
                    "label": 0
                },
                {
                    "sent": "How to some extent random accesses may be unavoidable and we use our scheduling strategies for scheduling them in the right way, and the other implementation consideration here is that as we have some information in memory, we actually enhance the index structures to include also structural information in the form of these pre post order codings that once we have some building blocks in memory, we can actually test these path conditions sufficiently in memory without additional.",
                    "label": 0
                },
                {
                    "sent": "Disk access is now these pre and post order encodings.",
                    "label": 0
                },
                {
                    "sent": "Maybe this is in the XML database.",
                    "label": 0
                },
                {
                    "sent": "World is a standard melt, but for you maybe it's not so well known.",
                    "label": 0
                },
                {
                    "sent": "So what you do at document Analysis an indexing time, you traverse the nodes in the tree and you keep the preorder traversal and in a post order traversal conceptually twice, but can be implemented in one traversal and you remember the Rankin at foreseeing the element.",
                    "label": 0
                },
                {
                    "sent": "In the two traversals and, this information gives you efficient tests for all the X path access.",
                    "label": 0
                },
                {
                    "sent": "So from this information, given two elements, you can quickly tell whether this one element is a descendant of that other or not, so this is very efficient.",
                    "label": 0
                },
                {
                    "sent": "And finally pass conditions, maybe relaxable, maybe a good approximate result of this does not have a publisher tack or a country tag.",
                    "label": 0
                },
                {
                    "sent": "Or instead of the affiliation tag, we have something else.",
                    "label": 0
                },
                {
                    "sent": "So we associate some score mass also with the structural considerations.",
                    "label": 0
                },
                {
                    "sent": "This is a bit at Hawk and if they are not matched actually they don't get that score mass.",
                    "label": 0
                },
                {
                    "sent": "So there is a penalty for being a perfect match in terms of content but sacrificing not.",
                    "label": 0
                },
                {
                    "sent": "Satisfying some of the structural conditions.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "No, I think this is the for the for the take home message.",
                    "label": 0
                },
                {
                    "sent": "This was good enough.",
                    "label": 0
                },
                {
                    "sent": "I have a few more slides including like an elaborated example.",
                    "label": 0
                },
                {
                    "sent": "Oh, I show you the example an.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Fast forward mode.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So one pre conclusion and then the real conclusion.",
                    "label": 0
                },
                {
                    "sent": "Oh no, I should have shown you sorry.",
                    "label": 0
                },
                {
                    "sent": "Experimental results are always interesting, so this runs on on the next data bibliographic data with good performance results quality.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here we are again.",
                    "label": 0
                },
                {
                    "sent": "We are like in the top third, but we were not driven by getting like the best quality also runs on the new iMacs data in XML version of Wikipedia and it has good performance.",
                    "label": 0
                },
                {
                    "sent": "So we had competitors like the algorithm and this one is worthwhile mentioning.",
                    "label": 0
                },
                {
                    "sent": "This came out of Ragu Rama Krishnan's group from Wisconsin, which uses a database style structural indexer, data guide index and actually gives preference to structural conditions.",
                    "label": 0
                },
                {
                    "sent": "So it kind of tends to primarily evaluate structural conditions, and then the score scoring part for the top K query processing is like a second stage, so you see that we beat this significantly by factor.",
                    "label": 0
                },
                {
                    "sent": "Actually, here in acts of more than 20.",
                    "label": 0
                },
                {
                    "sent": "To be fair, we also evaluate this on data that has weather structure is more important, for example because it's a lot cleaner.",
                    "label": 0
                },
                {
                    "sent": "Index has about 1000 different tags because this is converted SGML data and it's really messy.",
                    "label": 0
                },
                {
                    "sent": "Whereas IMDb has a very clear schema and XML schema and here actually we still gain a factor of two to three, but these techniques are not bad in the sense that they would never work well.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now pre conclusion.",
                    "label": 0
                },
                {
                    "sent": "So this was all on trees.",
                    "label": 0
                },
                {
                    "sent": "So in my original motivation had brought up crafts.",
                    "label": 0
                },
                {
                    "sent": "Now crafts incur a jump, a quantum leap in complexity.",
                    "label": 0
                },
                {
                    "sent": "So think again the query from the motivation and now assume we might even have waited actors like we could we add connections between documents.",
                    "label": 0
                },
                {
                    "sent": "Here we could say, well intra document actually have different weights than Inter document edges.",
                    "label": 0
                },
                {
                    "sent": "As this might be symbolic links that got in Ferd from some text mining process and then they have weights too.",
                    "label": 0
                },
                {
                    "sent": "So and as we add more documents that are just interlinked.",
                    "label": 0
                },
                {
                    "sent": "So think Wikipedia every page has like links to 50 other pages.",
                    "label": 0
                },
                {
                    "sent": "You really have a craft that's not at all like a tree.",
                    "label": 0
                },
                {
                    "sent": "Now when we could still run our techniques, they're just getting slower and slower on this, so this might be a candidate match.",
                    "label": 0
                },
                {
                    "sent": "This one and this one.",
                    "label": 0
                },
                {
                    "sent": "And now in the scoring.",
                    "label": 0
                },
                {
                    "sent": "We want particular here.",
                    "label": 0
                },
                {
                    "sent": "You see that some of the conditions are matched in notes that are pretty far from this one here in the in the in the craft.",
                    "label": 0
                },
                {
                    "sent": "And so we would like to take this into account.",
                    "label": 0
                },
                {
                    "sent": "In addition to the aggregation over the local scores that you get from matching these conditions, you want to take into account the compactness of the results up craft that you see here.",
                    "label": 0
                },
                {
                    "sent": "Unfortunately, this leads to NP hard problems like those who have an iPhone algorithmics immediately seized Inatori problem, so and even though in our approaches we approximate this by using maximum spanning trees on the connection graph, again, we're playing precomputation tricks because this space is cheap and indexing time is a lot less critical than query time, but this is very initial work, so this is a long way to go.",
                    "label": 0
                },
                {
                    "sent": "Getting XML IR work well.",
                    "label": 0
                },
                {
                    "sent": "In terms of quality and efficiency on arbitrary graphs and Wikipedia in XML will be one is a wonderful test study.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So conclusion so.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So I think XML IR is of is a strategic direction for enterprise search.",
                    "label": 0
                },
                {
                    "sent": "Definitely yes.",
                    "label": 0
                },
                {
                    "sent": "For digital libraries it will play a role in database integration and I think on the web and could play a big role in combination with information extraction.",
                    "label": 0
                },
                {
                    "sent": "Now this may not be for the full web.",
                    "label": 0
                },
                {
                    "sent": "It may not be for like masses of users but think just off the web that is of interest to scientists.",
                    "label": 0
                },
                {
                    "sent": "So all the pages from all universities, all scientists, all students in the world, all related projects.",
                    "label": 0
                },
                {
                    "sent": "So this is a site very big.",
                    "label": 0
                },
                {
                    "sent": "Portion of the of the weapon is of great interest, and information extraction could really add a lot of extra value to that.",
                    "label": 0
                },
                {
                    "sent": "And then once you have that, once you have family, fight it XML.",
                    "label": 0
                },
                {
                    "sent": "IR plays a role and probabilistic approximations and statistical techniques play a big role in getting this sufficient.",
                    "label": 0
                },
                {
                    "sent": "Now open issues.",
                    "label": 0
                },
                {
                    "sent": "So some more technical, I pointed you to some very recent work on scheduling, but I can imagine there's more things one could do.",
                    "label": 0
                },
                {
                    "sent": "I get the question about correlations across dimension, so there's more things to be done here.",
                    "label": 0
                },
                {
                    "sent": "Once we add information extraction on a larger scale.",
                    "label": 0
                },
                {
                    "sent": "The the tax come with confidence values.",
                    "label": 0
                },
                {
                    "sent": "What's a principled model for getting this into the scoring model?",
                    "label": 0
                },
                {
                    "sent": "Is there an ocean like a statistical language model that would then kind of generate this new kind of XML data?",
                    "label": 0
                },
                {
                    "sent": "And how do we handle this?",
                    "label": 0
                },
                {
                    "sent": "Generalizing all that to crafts?",
                    "label": 0
                },
                {
                    "sent": "Not just our approach to packs, but I know some other people here in the room are working on this in this direction from a database viewpoint, we would like to combine these things with other database operators, so we're doing this over combinations of structured data and text data and information extraction and rich data and so on.",
                    "label": 0
                },
                {
                    "sent": "Think of applications like customer support or E health and you really have complex queries not post by end users, But my application developers.",
                    "label": 0
                },
                {
                    "sent": "And then you need certainly need a way of adding this preferable manner to what database people called physical operator algebra and how to do query optimization with this and many years further down the road.",
                    "label": 0
                },
                {
                    "sent": "The background is a database system.",
                    "label": 0
                },
                {
                    "sent": "Nobody in database is locked up together and hardly anybody last text query, so redoing this in a cleaner manner and as we do it adding probabilistic semantics to all of that would be a really great charge.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                },
                {
                    "sent": "Question.",
                    "label": 0
                },
                {
                    "sent": "Athena one of the implications if the same information in the XML schema occurs at play, A tag level at one point at at at St level and another point in the background.",
                    "label": 0
                },
                {
                    "sent": "Of course, is the ontologist asking you.",
                    "label": 0
                },
                {
                    "sent": "The question was do we deal with elements differently from attributes, so tag names and as equally with the Contacts on our approach, we treat this all the same.",
                    "label": 0
                },
                {
                    "sent": "In fact we all model is not real XML, but this more this labeled tree approach.",
                    "label": 0
                },
                {
                    "sent": "There's lots of.",
                    "label": 0
                },
                {
                    "sent": "Additional intricacies in the real XML.",
                    "label": 0
                },
                {
                    "sent": "Some of them are actually idiosyncrasy's that we overlooked.",
                    "label": 0
                },
                {
                    "sent": "I have mixed feelings, whether it makes sense to be so sophisticated in the long run, because then you get into the problem.",
                    "label": 0
                },
                {
                    "sent": "How do we model data in XML?",
                    "label": 0
                },
                {
                    "sent": "And what's the philosophical difference between saying this deserves to be an element name?",
                    "label": 0
                },
                {
                    "sent": "And this deserves to be an attribute name, but I could imagine approaches that actually take them apart and treat them separately.",
                    "label": 0
                },
                {
                    "sent": "Fact syntactically and.",
                    "label": 0
                },
                {
                    "sent": "Our approach could handle this, just we didn't do it because I don't believe in it.",
                    "label": 0
                },
                {
                    "sent": "So you just matching element names and attribute names and things like that into the ontology and gets the goodies waiting.",
                    "label": 0
                },
                {
                    "sent": "Painters in some way.",
                    "label": 0
                },
                {
                    "sent": "I can't follow this jump so far.",
                    "label": 0
                },
                {
                    "sent": "No in the query language that may actually be different in what I next US, and certainly what experts full text us.",
                    "label": 0
                },
                {
                    "sent": "But in our approach we treat element names and attribute names both as nodes in the tree.",
                    "label": 0
                },
                {
                    "sent": "So on every node in a tree has a label and as a content.",
                    "label": 0
                },
                {
                    "sent": "So you can view the attribute as a child of the element to which it belongs.",
                    "label": 0
                },
                {
                    "sent": "This is much simpler.",
                    "label": 0
                },
                {
                    "sent": "I don't even application programmers are not so super sophisticated.",
                    "label": 0
                },
                {
                    "sent": "They don't want to think about all these little details all the time.",
                    "label": 0
                },
                {
                    "sent": "Google.",
                    "label": 0
                },
                {
                    "sent": "Question.",
                    "label": 0
                },
                {
                    "sent": "Repent.",
                    "label": 0
                },
                {
                    "sent": "There is 1.",
                    "label": 0
                },
                {
                    "sent": "This is fun.",
                    "label": 0
                },
                {
                    "sent": "Sequel or insane relations.",
                    "label": 0
                },
                {
                    "sent": "You have this notion of joints that are very kind of into.",
                    "label": 0
                },
                {
                    "sent": "So many things in a programmatic model, every almost every combination is different.",
                    "label": 0
                },
                {
                    "sent": "It depends when they're combined, so things are correlated around correlated there generated by particular process and so thinking of some kind of syntax in which we would agree that would somehow allow us to just exist really hard.",
                    "label": 0
                },
                {
                    "sent": "Do you have ideas of how that?",
                    "label": 0
                },
                {
                    "sent": "So I think the question was understandable in the room, so This is why I said this is a long term challenge, so joins would be approximate joints to write, so join results have a probability of being in the result.",
                    "label": 0
                },
                {
                    "sent": "Estimating this probability could be based on independent switches.",
                    "label": 0
                },
                {
                    "sent": "The state of the art right?",
                    "label": 0
                },
                {
                    "sent": "Or it could take into account crucial pieces of correlation information.",
                    "label": 0
                },
                {
                    "sent": "So this field is widely open, so it was a big field.",
                    "label": 0
                },
                {
                    "sent": "I'm back in like mid 90s with even ground work like helper and worked on probabilistic logics and then there was also in the IR field.",
                    "label": 0
                },
                {
                    "sent": "There was quite a lot of good work going on but it didn't reach a breakthrough.",
                    "label": 0
                },
                {
                    "sent": "So then it dawned for 15 years and now in the database world is gains attention again and I think it is just the I think it's the right way to go even though it may take 30 years to get his right to get it expressive enough.",
                    "label": 0
                },
                {
                    "sent": "But at the same time efficiently efficient enough to be.",
                    "label": 0
                },
                {
                    "sent": "Practical we shouldn't give up too quickly.",
                    "label": 0
                },
                {
                    "sent": "We should keep going.",
                    "label": 0
                },
                {
                    "sent": "I was wondering so the permission instructions and it's very important.",
                    "label": 0
                },
                {
                    "sent": "If you're feeling for our complicated needs to do it robustly and with enough courage so that.",
                    "label": 0
                },
                {
                    "sent": "Nude picture so this is I'm in this regards this is I'm not an expert here.",
                    "label": 0
                },
                {
                    "sent": "I'm sure there are some more knowledgeable people in the room, but I recommend you.",
                    "label": 0
                },
                {
                    "sent": "For example, trying out to the open source tool Gate and its notation to a component.",
                    "label": 0
                },
                {
                    "sent": "Any.",
                    "label": 0
                },
                {
                    "sent": "This is from the University of Sheffield, so you can actually have a web demo so you can put piece of text and let it tag personals locations, time intervals and so on.",
                    "label": 0
                },
                {
                    "sent": "And it does a pretty good job and I'm sure there's commercial tools to IBM.",
                    "label": 0
                },
                {
                    "sent": "Must have something they did all the big players should all have something I don't know whether this is an issue for the search engine.",
                    "label": 0
                },
                {
                    "sent": "Companies like Yahoo, Google and MSN.",
                    "label": 0
                },
                {
                    "sent": "But the companies that are in enterprise search have a story.",
                    "label": 0
                },
                {
                    "sent": "So this goes along way for the simple things.",
                    "label": 0
                },
                {
                    "sent": "As I said, person names, organization names are harder but still go along way, time and locations.",
                    "label": 0
                },
                {
                    "sent": "With the tools like it.",
                    "label": 0
                },
                {
                    "sent": "They're not very robust, especially if you main gets more.",
                    "label": 0
                },
                {
                    "sent": "Place and reach.",
                    "label": 0
                },
                {
                    "sent": "So I don't, yeah, I see your point.",
                    "label": 0
                },
                {
                    "sent": "But I don't agree.",
                    "label": 0
                },
                {
                    "sent": "Try out gate person names.",
                    "label": 0
                },
                {
                    "sent": "Almost no errors.",
                    "label": 0
                },
                {
                    "sent": "Location names is easy.",
                    "label": 0
                },
                {
                    "sent": "Location names is mostly lexicons.",
                    "label": 0
                },
                {
                    "sent": "Look us right so there's not a whole lot of learning.",
                    "label": 0
                },
                {
                    "sent": "There's not a whole lot of NLP or statistics involved.",
                    "label": 0
                },
                {
                    "sent": "A little bit of preprocessing, then you are right, there's my examples with like never being a painter and so on.",
                    "label": 0
                },
                {
                    "sent": "This is sci-fi.",
                    "label": 0
                },
                {
                    "sent": "This is where this is beyond what can be done now, but there's a low hanging food which goes along way.",
                    "label": 0
                },
                {
                    "sent": "Now this may not be worthwhile or noisy.",
                    "label": 0
                },
                {
                    "sent": "Web pages so arbitrary web pages or blocks, but you apply this to a page like Wikipedia with well formed natural language sentences with a clear structure which you can even add as an additional leverage for doing the tagging, and it goes a very long way, and so you certainly have accuracy above 90% for this an issue for tomorrow, OK?",
                    "label": 0
                },
                {
                    "sent": "Johnson",
                    "label": 0
                }
            ]
        }
    }
}