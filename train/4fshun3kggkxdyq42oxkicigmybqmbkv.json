{
    "id": "4fshun3kggkxdyq42oxkicigmybqmbkv",
    "title": "Partially Observed Maximum Entropy Discrimination Markov Networks",
    "info": {
        "author": [
            "Jun Zhu, Machine Learning Department, School of Computer Science, Carnegie Mellon University"
        ],
        "published": "Jan. 15, 2009",
        "recorded": "November 2008",
        "category": [
            "Top->Computer Science->Machine Learning->Markov Processes"
        ]
    },
    "url": "http://videolectures.net/cmulls08_zhu_pome/",
    "segmentation": [
        [
            "OK, so this talk is hard to learn.",
            "Graph model with hidden variables.",
            "So learning a car model is useful because you can discount cymatic insights about complex data and also give you a setting structure predictor.",
            "So also maximum likelihood method could be tensive studies.",
            "So by the margin little work had been done in next margin learning method.",
            "So this talk is presented.",
            "Partial observed in exchange of discrete market network and it will show you how to do Max margin learning with getting variables, instruction, product model.",
            "So here here.",
            "So I don't know how to articulate this work.",
            "If you cannot.",
            "I don't know how to dance.",
            "Yeah.",
            "Oh, here we go.",
            "It's just slow I think OK. Now you should just be able to hit the arrows.",
            "So.",
            "Just a second technical difficulties.",
            "Reverse the lighting.",
            "Yeah.",
            "Think this is too many copies of PowerPoint open right now.",
            "Oh OK, here we go, no.",
            "Weird.",
            "Alright, well close this one.",
            "This is this one.",
            "So here we."
        ],
        [
            "OK.",
            "So, so the first part is perfect action to start pretty.",
            "I guess most of you are familiar with this part, so the second is is a newer framework for the fully fully observed cast, it's.",
            "It's a.",
            "And or framework code make central discriminant mark network.",
            "I will show you some better results and then focus on the partial observe."
        ],
        [
            "Case.",
            "So this is a crafting problem, so we have.",
            "We have a set of IID training set.",
            "Each sample is a pair of feature worked and the true level.",
            "So the output is classifier.",
            "So you have a double star and for tax free sample you want you want to assign set a good product.",
            "So for the linear case, the two popular methods is one is logistic regression and the other is the powered machine.",
            "So they take two different learning approach.",
            "Support machine is based on margin personalities.",
            "It's directly optimizing margin with some constraint to make sure the model can predict correctly on the data.",
            "But logical regression takes another project to do like best estimation.",
            "So it define log linear.",
            "Model.",
            "So for Star prediction is relax the strict strict IID assumption."
        ],
        [
            "Madeline Clark, model so real Castle.",
            "The samples are prediction of different samples can correlate it.",
            "For example, for peer to peer taking.",
            "The input is sequence, so the output is is also a sequence of popular tags, so the grammar grammar says that there's some correlation between different price tag.",
            "I'm sorry, maybe this doesn't work, I don't know.",
            "OK, so so another example is a 3 dimensional image segmentation.",
            "Is it OK?",
            "OK, so so your input is 2 dimensional metric of pixels and the output is level of each pixel.",
            "So in this case also the library and level tend to be similar because your image is smooth.",
            "So the strike prediction model.",
            "The correlation to different outputs into consideration and jointly.",
            "Learn a classifier to predict of all the samples.",
            "So again, it learn optimal.",
            "Optimal model and for test example.",
            "To use this particular route to assign, to assign a good prediction.",
            "So so in literature is alliteration.",
            "There are two popular methods when it's convenient fields, another user, Max Marky Mark Network, so back it is.",
            "CR if we take the similar protests, logistic regression, you do maximum likelihood activation.",
            "So you define a log linear like model.",
            "On next Monday, Michael Network takes the approach of SRAM.",
            "It optimizing margin with the with the subset of constraint to make sure the the model can predict correctly on the other data.",
            "So this data model can be very complicated because for each instance you have for a potential number of possible predictions.",
            "So to make."
        ],
        [
            "This model computationally efficient.",
            "You always make some Markov assumption for them.",
            "For this chain graph.",
            "Micro.",
            "Some say that giving one verbal.",
            "For example, why 2?",
            "Then the two neighbors to number?",
            "Will be continuing independent."
        ],
        [
            "So OK, so we have.",
            "We have a talk about.",
            "The different models for cloud cache under strict prediction.",
            "So basically they take two different different learning approach.",
            "Logistic regression is CRF.",
            "It takes the like old best estimation, and I swam and makes party.",
            "Market Network takes makes margin learning approach.",
            "So let's compare these two different learning paradigms.",
            "So first, basically like would best estimation is probabilistic it has.",
            "Implicit joint or conditional like old model.",
            "So in this framework it's easy to do Bayesian learning and concealed prior knowledge of some missing data, but Max margin learning.",
            "Take another approach.",
            "It directly optimize margin so it's a focus on the.",
            "Focus on the input output mapping so it's not obvious how to do Beijing based style learning and how to consider prior or missing information information.",
            "But he has another nice properties that there are a lot of theoretical arguments about the performance guarantee when you have a limited number of samples.",
            "So.",
            "There is a nice nice from work.",
            "We extend it between these two 2 methods is called Max entropy discrimination, so it takes a big fashion style.",
            "Learning is learning a posterior distribution over the model and do prediction takes the average over all the models.",
            "So the optimization problem is minimized character averages with the prior and the constraint.",
            "This is just a general generalized of.",
            "Officers the constraint as swam this year.",
            "Binary classification problem.",
            "So me it has a lot of nice properties when I want to mention is that it can be shows at SMU spare case of this framework."
        ],
        [
            "So the first part of our work is to attend the MD from over to struggle protein case.",
            "So this is so proposed.",
            "Maxim Max entropy discrimination market networks.",
            "I.",
            "Or next Internet for short.",
            "So so basically we learn a positive distribution result with prior the optimization problem is minimized.",
            "Regularised care diversions.",
            "So mu function is assumed to be convinced.",
            "So here the subspace, the physical subspace defined with the with the consideration of the margin.",
            "So you take the average over.",
            "If you ignore them, the position is just the margin constraints in the standard makes maximum market network.",
            "So for prediction you take the.",
            "The patient style predicting technology over all the models.",
            "So to show the basic ideas.",
            "So before I see any data you subject to the selector prior of the model.",
            "So when some data coming so you want to add some constraint.",
            "To enforce their model to predict correctly on this this data.",
            "So one more and more data.",
            "Given you add more and more constraints, so the intersection of this hard plans will give you.",
            "It defines the feasible subspace.",
            "So Max Interpersonal says that you should choose.",
            "Choose one TSP that has a little more care divergent to the prior.",
            "So this is the basic idea.",
            "So, so this problem is nice because the objective function is convex also.",
            "The physical subspace is quite fed, so so you can.",
            "It's a convex program you can.",
            "Formal leveraging function and text.",
            "Solve the dual problem."
        ],
        [
            "So here is the general solution of this problem.",
            "So the posterior of this form.",
            "So the first part is prior and the second part is so natural.",
            "So it can be seen as like old model because it is related to the data.",
            "So the two parameters are solved by.",
            "Achieved by solving this dual problem.",
            "So Milstein is correct conjugated immune function.",
            "So this is the definition definition of convex conjugate and some some use for examples.",
            "So for example, care directions will have to do is log party function and for right now you have a set of box constraints, so so it's not surprising we have a log Z here, so it's just a command.",
            "Can you get?",
            "So another interesting result is that if you make some assumption.",
            "Actually, you can reduce it reduced to the spare case of mixed market market network.",
            "So you assume the model your linear and you function is just a random and the priors than normal, so you can get the results.",
            "The party is also a normal normal with shifted me and the dual problem problem is the same as that of the standard makes Mark Mark Network.",
            "So if we use the posterior to do prediction you get the same prediction rules that makes money, money, network.",
            "So we can say so we show that next Monday my network is staircase.",
            "So basically this argument in the two form.",
            "So we can equivalent to the.",
            "It should show this reduction in the primal form.",
            "So in addition, maximum that can offer.",
            "At least three advantages.",
            "So here's the 1st, it's."
        ],
        [
            "It's a fashion style, learning with consideration of margin so you can have a passion prediction error guarantee.",
            "So for any prior you can cover this.",
            "This guarantee and the follow circuits of normal you can you can reduce these two to the guarantee of standard next Mark Mark Network.",
            "Just take the advantage you can achieve is that it has a prior so the product can be designed to introduce some.",
            "Some sparsity bias.",
            "For example, you used last prior.",
            "You can show some posterior chilling effect.",
            "So this is the code should basic idea.",
            "So suppose this axis is the right amount of the standard next market network.",
            "Change the positive meaning of loveless loveless prior have some huge around 0, so you can.",
            "You can see these two curves have some.",
            "So much respect here.",
            "So the second one here is, which also I want to present in the rest of talk.",
            "Its maximum.",
            "Let's offer elegant approach to incorporating variables so it can be used to learn to learn structure prediction model with.",
            "So I want to motivate this problem with one example, so this is.",
            "Web data extraction is the target to identify the attributes of product info products from web pages.",
            "For example, in this case, you want to identify the name of."
        ],
        [
            "Product and image and some discussion of this image is this product.",
            "So to do this task, if the direct order given, we can we can put the HTML elements into for example a sequence to do static prediction.",
            "So this model is simple, you can you can perform efficient training and inference.",
            "However, it will lose a lot of useful dependence.",
            "For example, the first element.",
            "Also, interact with with this settlement and this one, this One South, in order to capture their dependence you want to add some additional constraints, additional edges, But this this model will be argued, so the maximum click click will be of larger size, so the inference and training will not be efficient.",
            "So another way is to do hierarchical model so.",
            "So for this webpage we can construct a hierarchical structure like this."
        ],
        [
            "The leaf nodes lymph nodes are the HTML elements and the nodes.",
            "Each node represent a record.",
            "A blog on the web page.",
            "So now your task is to label the leaf nodes and the nodes to detect that Roseanne also detect the data record.",
            "So which node represent the record?",
            "So you pass on this structure.",
            "You can construct a hierarchical model, for example.",
            "Who makes money market network?",
            "So to learn this, you may need some fully leveraging data, so you need to level the inner nodes.",
            "So this is this model in Nice because it's so computationally efficient because the click is small.",
            "You can perform efficient training and inference and also you can consider long range dependencies because in this model you can add some edges to make the.",
            "The inner nodes interact with each other so we can perform George traction to do direct detection the actual level.",
            "So, but the problem is that we need some full level."
        ],
        [
            "Turn data to learn this model.",
            "So maybe we want to ask can we learn hierarchical model from partial level data?",
            "For example, only the leave nodes are labeled.",
            "So the answer is yes, at least we can do this in the next month.",
            "Maximum likelihood activation, so here 2 examples for object recognition or with destruction program.",
            "So the second question I want to ask is, can we learn this in the Max margin learning setting?",
            "So I can say yes, so actually it turned out to be easy with our proposed Max Internet.",
            "So let me show you how to do this.",
            "So."
        ],
        [
            "Impartial observer cancel out data has observed level and hidden variables.",
            "So for example in this case is the case the leaf nodes and direction nodes are observed and all other nodes are hidden.",
            "So.",
            "So remember, this is fully observed maximum net use.",
            "Learn posterity tree of the model and to consider the hidden variables.",
            "We define the piles of.",
            "Accenture discriminate marker network so so actually that's where you want to join this version of the model and variable without prior prior.",
            "Also on the joint distribution of the two parts.",
            "So so you better you.",
            "You add some introduce came back here and also you had to redefine the feasible subspace.",
            "To consider variables.",
            "So for prediction, you need to marginalized over the hidden variable.",
            "So so how to solve this problem?",
            "So in those that it's also a convex program because object function is still convex and.",
            "The physical subset is also common, said.",
            "So, but if you apply the general form solution, it would.",
            "It would be intractable because.",
            "Now you have a continuous variable and discourage criminals.",
            "It would.",
            "It would involve hardware, high dimensional integration, summation, so it's in practice intractable.",
            "So we've developed our net minimize."
        ],
        [
            "By method by make some factorization assumption.",
            "So here, here in both prior and posterior, assumes that the credible are independent of the model parameter and also in different different samples the hidden dependants.",
            "So with this assumption, the method is like this, so it's actually 2 steps.",
            "First step is keeps the.",
            "So that is reallocated variable, fixed, and the optimize over the model distribution.",
            "And the second step is to fix the model, distribute fixed and optimized over PPC.",
            "So for the first step, it's easy because it reduced to the.",
            "The problem the problem of fully observed Max Internet, so windows that.",
            "For non price it's equivalent to.",
            "Emissary and optimizing problem.",
            "It's quadratic program, and if you want to use the Loblaws prior it.",
            "Is also can be done with version of Asian learning method.",
            "So for the six step with.",
            "The optimization problem is this cause we make this factorization assumption.",
            "You can turn this step for each each sample independent.",
            "So you get you introduce some of.",
            "LaGrange multipliers and you get this general solution and this better parameter can be solved achieved by solving this problem.",
            "So this is a non linear program.",
            "So this is a set of constraints, so here it's constraint can be potentially cause because you observe the observer level Y.",
            "Or the possible observer?",
            "Why compute people nature so.",
            "But the good news is you can reduce this problem to to equivalent form with polynomial number of constraints.",
            "So I."
        ],
        [
            "It could go into the details.",
            "So.",
            "So let me show you something permanent results.",
            "So here we consider the web data extraction.",
            "We want to identify for attributes, name, image, price and description.",
            "The method we want to compare the fully observed hierarchical content fields model and fully observed hierarchical Lexmark network and also their partial observed case.",
            "The test set of from.",
            "As from the web page is generated by suggested templates.",
            "Different temperatures means the webpage have different design style or some.",
            "Maybe have a different layout?",
            "So.",
            "So here is the training set.",
            "These are templates we use.",
            "We collect 5 pages for training and team for testing.",
            "So we consider two different level of inputs in the evaluation.",
            "So for record level relation with just text text the record as inputs.",
            "And for page level evaluation we take the whole web page as inputs.",
            "So for for the record level evaluation for the partially observed model, we just provide the level of leaf nodes or other wearables are hidden.",
            "So for parallelization we consider two different strategies to provide the supervision information.",
            "The first strategy is just provide the leaf nodes and direct downloads.",
            "With the true level before the 2nd segment strategy, we provide additional information.",
            "For example, the nodes about with that record."
        ],
        [
            "So here's the here's the results of record level evaluation, so.",
            "All this is overall performance of average F1 block in 10 cycles.",
            "Every job for one just algia value overall or 4H builds.",
            "Blog intense accuracies.",
            "Percent percent of records whose name, image and price are correct.",
            "So we can see.",
            "This is the partial observed next parking.",
            "It's part of the next model network.",
            "Or sorry maybe.",
            "This notation is wrong, so it's a PM, not M3.",
            "So.",
            "So we can see with a reasonable and motion that actually the partial observed me and can perform compared with the fully observed.",
            "Next, multimarket network.",
            "But partial observed harajly counter and fields model perform.",
            "Perform much worse so it also have a larger larger variance.",
            "So this is a detailed performance of different attributes.",
            "So.",
            "So for the.",
            "For the page revelation so this."
        ],
        [
            "So for the first strategy to provide supervision information, so again, we can see that the partial observed me and can perform.",
            "Much better than the partial result considering the field.",
            "So for this technique, for the second strategy, provide mode supervision information so we can see the performance of the partial observed HCR change change very much.",
            "So, but it's still still have our larger variance.",
            "OK. QHCIF is it bias?",
            "No, it's not bad, and it's not.",
            "It's discriminative because it's optimized.",
            "It optimizes the conditional like hold.",
            "You have some hidden variable.",
            "But not the margin.",
            "Yeah, not a margin.",
            "So that's a different from an approach or from the market.",
            "I. I guess I think from the market because we use it.",
            "All these cases we just use the normal prior, so it's equivalent to the Max Mark Mark Network.",
            "How many games do you expect you get from B as in approach?",
            "Yeah, we have another work to show.",
            "If we use different prior so you can have different performance.",
            "We also also issue that for user bashing learning most stable and if we use our norm, for example, our normal will give you unstable results so.",
            "Yeah, we have another work to choose that."
        ],
        [
            "Yeah, to summarize so so we proposed Max Max entropy, screaming Michael Network and basically we choose three advantages can offer so it's has activation problems guarantee it also can be designed to introduce sparsity.",
            "And also it's easy to tend to be correlated variables.",
            "So we also show some of your primary results.",
            "OK, so the last slide the two to show where we are now.",
            "So basically we have four different margin based learning method so as well.",
            "Among network immunity and Nexon net.",
            "So they optimized their to find different optimization problem and two different have different prediction rule.",
            "So to see how the connected, let's start from SM which will also propose the 1st.",
            "So from me, for you tend to strike protein, you get 3 and if you do, Beijing style learning will go to me D. So from me, if you want to attend to start putting together and we make the Internet so also you can start from M3.",
            "You perform patient Start learning.",
            "You also get the next Internet so that is maximum at its end of both paths, so OK.",
            "Thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so this talk is hard to learn.",
                    "label": 0
                },
                {
                    "sent": "Graph model with hidden variables.",
                    "label": 0
                },
                {
                    "sent": "So learning a car model is useful because you can discount cymatic insights about complex data and also give you a setting structure predictor.",
                    "label": 0
                },
                {
                    "sent": "So also maximum likelihood method could be tensive studies.",
                    "label": 0
                },
                {
                    "sent": "So by the margin little work had been done in next margin learning method.",
                    "label": 0
                },
                {
                    "sent": "So this talk is presented.",
                    "label": 0
                },
                {
                    "sent": "Partial observed in exchange of discrete market network and it will show you how to do Max margin learning with getting variables, instruction, product model.",
                    "label": 0
                },
                {
                    "sent": "So here here.",
                    "label": 0
                },
                {
                    "sent": "So I don't know how to articulate this work.",
                    "label": 0
                },
                {
                    "sent": "If you cannot.",
                    "label": 0
                },
                {
                    "sent": "I don't know how to dance.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Oh, here we go.",
                    "label": 0
                },
                {
                    "sent": "It's just slow I think OK. Now you should just be able to hit the arrows.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Just a second technical difficulties.",
                    "label": 0
                },
                {
                    "sent": "Reverse the lighting.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Think this is too many copies of PowerPoint open right now.",
                    "label": 0
                },
                {
                    "sent": "Oh OK, here we go, no.",
                    "label": 0
                },
                {
                    "sent": "Weird.",
                    "label": 0
                },
                {
                    "sent": "Alright, well close this one.",
                    "label": 0
                },
                {
                    "sent": "This is this one.",
                    "label": 0
                },
                {
                    "sent": "So here we.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So, so the first part is perfect action to start pretty.",
                    "label": 0
                },
                {
                    "sent": "I guess most of you are familiar with this part, so the second is is a newer framework for the fully fully observed cast, it's.",
                    "label": 0
                },
                {
                    "sent": "It's a.",
                    "label": 0
                },
                {
                    "sent": "And or framework code make central discriminant mark network.",
                    "label": 0
                },
                {
                    "sent": "I will show you some better results and then focus on the partial observe.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Case.",
                    "label": 0
                },
                {
                    "sent": "So this is a crafting problem, so we have.",
                    "label": 0
                },
                {
                    "sent": "We have a set of IID training set.",
                    "label": 1
                },
                {
                    "sent": "Each sample is a pair of feature worked and the true level.",
                    "label": 0
                },
                {
                    "sent": "So the output is classifier.",
                    "label": 0
                },
                {
                    "sent": "So you have a double star and for tax free sample you want you want to assign set a good product.",
                    "label": 0
                },
                {
                    "sent": "So for the linear case, the two popular methods is one is logistic regression and the other is the powered machine.",
                    "label": 0
                },
                {
                    "sent": "So they take two different learning approach.",
                    "label": 0
                },
                {
                    "sent": "Support machine is based on margin personalities.",
                    "label": 0
                },
                {
                    "sent": "It's directly optimizing margin with some constraint to make sure the model can predict correctly on the data.",
                    "label": 0
                },
                {
                    "sent": "But logical regression takes another project to do like best estimation.",
                    "label": 0
                },
                {
                    "sent": "So it define log linear.",
                    "label": 0
                },
                {
                    "sent": "Model.",
                    "label": 0
                },
                {
                    "sent": "So for Star prediction is relax the strict strict IID assumption.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Madeline Clark, model so real Castle.",
                    "label": 0
                },
                {
                    "sent": "The samples are prediction of different samples can correlate it.",
                    "label": 0
                },
                {
                    "sent": "For example, for peer to peer taking.",
                    "label": 0
                },
                {
                    "sent": "The input is sequence, so the output is is also a sequence of popular tags, so the grammar grammar says that there's some correlation between different price tag.",
                    "label": 0
                },
                {
                    "sent": "I'm sorry, maybe this doesn't work, I don't know.",
                    "label": 0
                },
                {
                    "sent": "OK, so so another example is a 3 dimensional image segmentation.",
                    "label": 1
                },
                {
                    "sent": "Is it OK?",
                    "label": 0
                },
                {
                    "sent": "OK, so so your input is 2 dimensional metric of pixels and the output is level of each pixel.",
                    "label": 0
                },
                {
                    "sent": "So in this case also the library and level tend to be similar because your image is smooth.",
                    "label": 0
                },
                {
                    "sent": "So the strike prediction model.",
                    "label": 0
                },
                {
                    "sent": "The correlation to different outputs into consideration and jointly.",
                    "label": 0
                },
                {
                    "sent": "Learn a classifier to predict of all the samples.",
                    "label": 0
                },
                {
                    "sent": "So again, it learn optimal.",
                    "label": 0
                },
                {
                    "sent": "Optimal model and for test example.",
                    "label": 0
                },
                {
                    "sent": "To use this particular route to assign, to assign a good prediction.",
                    "label": 0
                },
                {
                    "sent": "So so in literature is alliteration.",
                    "label": 0
                },
                {
                    "sent": "There are two popular methods when it's convenient fields, another user, Max Marky Mark Network, so back it is.",
                    "label": 0
                },
                {
                    "sent": "CR if we take the similar protests, logistic regression, you do maximum likelihood activation.",
                    "label": 0
                },
                {
                    "sent": "So you define a log linear like model.",
                    "label": 0
                },
                {
                    "sent": "On next Monday, Michael Network takes the approach of SRAM.",
                    "label": 0
                },
                {
                    "sent": "It optimizing margin with the with the subset of constraint to make sure the the model can predict correctly on the other data.",
                    "label": 0
                },
                {
                    "sent": "So this data model can be very complicated because for each instance you have for a potential number of possible predictions.",
                    "label": 0
                },
                {
                    "sent": "So to make.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This model computationally efficient.",
                    "label": 0
                },
                {
                    "sent": "You always make some Markov assumption for them.",
                    "label": 0
                },
                {
                    "sent": "For this chain graph.",
                    "label": 0
                },
                {
                    "sent": "Micro.",
                    "label": 0
                },
                {
                    "sent": "Some say that giving one verbal.",
                    "label": 0
                },
                {
                    "sent": "For example, why 2?",
                    "label": 0
                },
                {
                    "sent": "Then the two neighbors to number?",
                    "label": 0
                },
                {
                    "sent": "Will be continuing independent.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So OK, so we have.",
                    "label": 0
                },
                {
                    "sent": "We have a talk about.",
                    "label": 0
                },
                {
                    "sent": "The different models for cloud cache under strict prediction.",
                    "label": 1
                },
                {
                    "sent": "So basically they take two different different learning approach.",
                    "label": 0
                },
                {
                    "sent": "Logistic regression is CRF.",
                    "label": 0
                },
                {
                    "sent": "It takes the like old best estimation, and I swam and makes party.",
                    "label": 0
                },
                {
                    "sent": "Market Network takes makes margin learning approach.",
                    "label": 1
                },
                {
                    "sent": "So let's compare these two different learning paradigms.",
                    "label": 0
                },
                {
                    "sent": "So first, basically like would best estimation is probabilistic it has.",
                    "label": 0
                },
                {
                    "sent": "Implicit joint or conditional like old model.",
                    "label": 0
                },
                {
                    "sent": "So in this framework it's easy to do Bayesian learning and concealed prior knowledge of some missing data, but Max margin learning.",
                    "label": 1
                },
                {
                    "sent": "Take another approach.",
                    "label": 0
                },
                {
                    "sent": "It directly optimize margin so it's a focus on the.",
                    "label": 0
                },
                {
                    "sent": "Focus on the input output mapping so it's not obvious how to do Beijing based style learning and how to consider prior or missing information information.",
                    "label": 1
                },
                {
                    "sent": "But he has another nice properties that there are a lot of theoretical arguments about the performance guarantee when you have a limited number of samples.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "There is a nice nice from work.",
                    "label": 0
                },
                {
                    "sent": "We extend it between these two 2 methods is called Max entropy discrimination, so it takes a big fashion style.",
                    "label": 1
                },
                {
                    "sent": "Learning is learning a posterior distribution over the model and do prediction takes the average over all the models.",
                    "label": 0
                },
                {
                    "sent": "So the optimization problem is minimized character averages with the prior and the constraint.",
                    "label": 0
                },
                {
                    "sent": "This is just a general generalized of.",
                    "label": 0
                },
                {
                    "sent": "Officers the constraint as swam this year.",
                    "label": 0
                },
                {
                    "sent": "Binary classification problem.",
                    "label": 0
                },
                {
                    "sent": "So me it has a lot of nice properties when I want to mention is that it can be shows at SMU spare case of this framework.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the first part of our work is to attend the MD from over to struggle protein case.",
                    "label": 0
                },
                {
                    "sent": "So this is so proposed.",
                    "label": 0
                },
                {
                    "sent": "Maxim Max entropy discrimination market networks.",
                    "label": 0
                },
                {
                    "sent": "I.",
                    "label": 0
                },
                {
                    "sent": "Or next Internet for short.",
                    "label": 0
                },
                {
                    "sent": "So so basically we learn a positive distribution result with prior the optimization problem is minimized.",
                    "label": 0
                },
                {
                    "sent": "Regularised care diversions.",
                    "label": 0
                },
                {
                    "sent": "So mu function is assumed to be convinced.",
                    "label": 0
                },
                {
                    "sent": "So here the subspace, the physical subspace defined with the with the consideration of the margin.",
                    "label": 1
                },
                {
                    "sent": "So you take the average over.",
                    "label": 1
                },
                {
                    "sent": "If you ignore them, the position is just the margin constraints in the standard makes maximum market network.",
                    "label": 0
                },
                {
                    "sent": "So for prediction you take the.",
                    "label": 0
                },
                {
                    "sent": "The patient style predicting technology over all the models.",
                    "label": 0
                },
                {
                    "sent": "So to show the basic ideas.",
                    "label": 0
                },
                {
                    "sent": "So before I see any data you subject to the selector prior of the model.",
                    "label": 0
                },
                {
                    "sent": "So when some data coming so you want to add some constraint.",
                    "label": 0
                },
                {
                    "sent": "To enforce their model to predict correctly on this this data.",
                    "label": 0
                },
                {
                    "sent": "So one more and more data.",
                    "label": 0
                },
                {
                    "sent": "Given you add more and more constraints, so the intersection of this hard plans will give you.",
                    "label": 0
                },
                {
                    "sent": "It defines the feasible subspace.",
                    "label": 0
                },
                {
                    "sent": "So Max Interpersonal says that you should choose.",
                    "label": 0
                },
                {
                    "sent": "Choose one TSP that has a little more care divergent to the prior.",
                    "label": 0
                },
                {
                    "sent": "So this is the basic idea.",
                    "label": 0
                },
                {
                    "sent": "So, so this problem is nice because the objective function is convex also.",
                    "label": 0
                },
                {
                    "sent": "The physical subspace is quite fed, so so you can.",
                    "label": 0
                },
                {
                    "sent": "It's a convex program you can.",
                    "label": 0
                },
                {
                    "sent": "Formal leveraging function and text.",
                    "label": 0
                },
                {
                    "sent": "Solve the dual problem.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So here is the general solution of this problem.",
                    "label": 0
                },
                {
                    "sent": "So the posterior of this form.",
                    "label": 0
                },
                {
                    "sent": "So the first part is prior and the second part is so natural.",
                    "label": 0
                },
                {
                    "sent": "So it can be seen as like old model because it is related to the data.",
                    "label": 0
                },
                {
                    "sent": "So the two parameters are solved by.",
                    "label": 0
                },
                {
                    "sent": "Achieved by solving this dual problem.",
                    "label": 0
                },
                {
                    "sent": "So Milstein is correct conjugated immune function.",
                    "label": 0
                },
                {
                    "sent": "So this is the definition definition of convex conjugate and some some use for examples.",
                    "label": 1
                },
                {
                    "sent": "So for example, care directions will have to do is log party function and for right now you have a set of box constraints, so so it's not surprising we have a log Z here, so it's just a command.",
                    "label": 0
                },
                {
                    "sent": "Can you get?",
                    "label": 0
                },
                {
                    "sent": "So another interesting result is that if you make some assumption.",
                    "label": 0
                },
                {
                    "sent": "Actually, you can reduce it reduced to the spare case of mixed market market network.",
                    "label": 0
                },
                {
                    "sent": "So you assume the model your linear and you function is just a random and the priors than normal, so you can get the results.",
                    "label": 0
                },
                {
                    "sent": "The party is also a normal normal with shifted me and the dual problem problem is the same as that of the standard makes Mark Mark Network.",
                    "label": 0
                },
                {
                    "sent": "So if we use the posterior to do prediction you get the same prediction rules that makes money, money, network.",
                    "label": 0
                },
                {
                    "sent": "So we can say so we show that next Monday my network is staircase.",
                    "label": 0
                },
                {
                    "sent": "So basically this argument in the two form.",
                    "label": 0
                },
                {
                    "sent": "So we can equivalent to the.",
                    "label": 0
                },
                {
                    "sent": "It should show this reduction in the primal form.",
                    "label": 0
                },
                {
                    "sent": "So in addition, maximum that can offer.",
                    "label": 0
                },
                {
                    "sent": "At least three advantages.",
                    "label": 0
                },
                {
                    "sent": "So here's the 1st, it's.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It's a fashion style, learning with consideration of margin so you can have a passion prediction error guarantee.",
                    "label": 0
                },
                {
                    "sent": "So for any prior you can cover this.",
                    "label": 0
                },
                {
                    "sent": "This guarantee and the follow circuits of normal you can you can reduce these two to the guarantee of standard next Mark Mark Network.",
                    "label": 0
                },
                {
                    "sent": "Just take the advantage you can achieve is that it has a prior so the product can be designed to introduce some.",
                    "label": 0
                },
                {
                    "sent": "Some sparsity bias.",
                    "label": 0
                },
                {
                    "sent": "For example, you used last prior.",
                    "label": 0
                },
                {
                    "sent": "You can show some posterior chilling effect.",
                    "label": 0
                },
                {
                    "sent": "So this is the code should basic idea.",
                    "label": 0
                },
                {
                    "sent": "So suppose this axis is the right amount of the standard next market network.",
                    "label": 0
                },
                {
                    "sent": "Change the positive meaning of loveless loveless prior have some huge around 0, so you can.",
                    "label": 0
                },
                {
                    "sent": "You can see these two curves have some.",
                    "label": 0
                },
                {
                    "sent": "So much respect here.",
                    "label": 0
                },
                {
                    "sent": "So the second one here is, which also I want to present in the rest of talk.",
                    "label": 0
                },
                {
                    "sent": "Its maximum.",
                    "label": 0
                },
                {
                    "sent": "Let's offer elegant approach to incorporating variables so it can be used to learn to learn structure prediction model with.",
                    "label": 0
                },
                {
                    "sent": "So I want to motivate this problem with one example, so this is.",
                    "label": 0
                },
                {
                    "sent": "Web data extraction is the target to identify the attributes of product info products from web pages.",
                    "label": 0
                },
                {
                    "sent": "For example, in this case, you want to identify the name of.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Product and image and some discussion of this image is this product.",
                    "label": 0
                },
                {
                    "sent": "So to do this task, if the direct order given, we can we can put the HTML elements into for example a sequence to do static prediction.",
                    "label": 0
                },
                {
                    "sent": "So this model is simple, you can you can perform efficient training and inference.",
                    "label": 0
                },
                {
                    "sent": "However, it will lose a lot of useful dependence.",
                    "label": 0
                },
                {
                    "sent": "For example, the first element.",
                    "label": 0
                },
                {
                    "sent": "Also, interact with with this settlement and this one, this One South, in order to capture their dependence you want to add some additional constraints, additional edges, But this this model will be argued, so the maximum click click will be of larger size, so the inference and training will not be efficient.",
                    "label": 0
                },
                {
                    "sent": "So another way is to do hierarchical model so.",
                    "label": 0
                },
                {
                    "sent": "So for this webpage we can construct a hierarchical structure like this.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The leaf nodes lymph nodes are the HTML elements and the nodes.",
                    "label": 0
                },
                {
                    "sent": "Each node represent a record.",
                    "label": 0
                },
                {
                    "sent": "A blog on the web page.",
                    "label": 0
                },
                {
                    "sent": "So now your task is to label the leaf nodes and the nodes to detect that Roseanne also detect the data record.",
                    "label": 1
                },
                {
                    "sent": "So which node represent the record?",
                    "label": 0
                },
                {
                    "sent": "So you pass on this structure.",
                    "label": 0
                },
                {
                    "sent": "You can construct a hierarchical model, for example.",
                    "label": 1
                },
                {
                    "sent": "Who makes money market network?",
                    "label": 0
                },
                {
                    "sent": "So to learn this, you may need some fully leveraging data, so you need to level the inner nodes.",
                    "label": 0
                },
                {
                    "sent": "So this is this model in Nice because it's so computationally efficient because the click is small.",
                    "label": 0
                },
                {
                    "sent": "You can perform efficient training and inference and also you can consider long range dependencies because in this model you can add some edges to make the.",
                    "label": 0
                },
                {
                    "sent": "The inner nodes interact with each other so we can perform George traction to do direct detection the actual level.",
                    "label": 0
                },
                {
                    "sent": "So, but the problem is that we need some full level.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Turn data to learn this model.",
                    "label": 0
                },
                {
                    "sent": "So maybe we want to ask can we learn hierarchical model from partial level data?",
                    "label": 1
                },
                {
                    "sent": "For example, only the leave nodes are labeled.",
                    "label": 0
                },
                {
                    "sent": "So the answer is yes, at least we can do this in the next month.",
                    "label": 1
                },
                {
                    "sent": "Maximum likelihood activation, so here 2 examples for object recognition or with destruction program.",
                    "label": 0
                },
                {
                    "sent": "So the second question I want to ask is, can we learn this in the Max margin learning setting?",
                    "label": 0
                },
                {
                    "sent": "So I can say yes, so actually it turned out to be easy with our proposed Max Internet.",
                    "label": 0
                },
                {
                    "sent": "So let me show you how to do this.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Impartial observer cancel out data has observed level and hidden variables.",
                    "label": 1
                },
                {
                    "sent": "So for example in this case is the case the leaf nodes and direction nodes are observed and all other nodes are hidden.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "So remember, this is fully observed maximum net use.",
                    "label": 0
                },
                {
                    "sent": "Learn posterity tree of the model and to consider the hidden variables.",
                    "label": 0
                },
                {
                    "sent": "We define the piles of.",
                    "label": 0
                },
                {
                    "sent": "Accenture discriminate marker network so so actually that's where you want to join this version of the model and variable without prior prior.",
                    "label": 0
                },
                {
                    "sent": "Also on the joint distribution of the two parts.",
                    "label": 0
                },
                {
                    "sent": "So so you better you.",
                    "label": 0
                },
                {
                    "sent": "You add some introduce came back here and also you had to redefine the feasible subspace.",
                    "label": 0
                },
                {
                    "sent": "To consider variables.",
                    "label": 0
                },
                {
                    "sent": "So for prediction, you need to marginalized over the hidden variable.",
                    "label": 0
                },
                {
                    "sent": "So so how to solve this problem?",
                    "label": 0
                },
                {
                    "sent": "So in those that it's also a convex program because object function is still convex and.",
                    "label": 0
                },
                {
                    "sent": "The physical subset is also common, said.",
                    "label": 0
                },
                {
                    "sent": "So, but if you apply the general form solution, it would.",
                    "label": 0
                },
                {
                    "sent": "It would be intractable because.",
                    "label": 0
                },
                {
                    "sent": "Now you have a continuous variable and discourage criminals.",
                    "label": 0
                },
                {
                    "sent": "It would.",
                    "label": 0
                },
                {
                    "sent": "It would involve hardware, high dimensional integration, summation, so it's in practice intractable.",
                    "label": 0
                },
                {
                    "sent": "So we've developed our net minimize.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "By method by make some factorization assumption.",
                    "label": 1
                },
                {
                    "sent": "So here, here in both prior and posterior, assumes that the credible are independent of the model parameter and also in different different samples the hidden dependants.",
                    "label": 0
                },
                {
                    "sent": "So with this assumption, the method is like this, so it's actually 2 steps.",
                    "label": 0
                },
                {
                    "sent": "First step is keeps the.",
                    "label": 1
                },
                {
                    "sent": "So that is reallocated variable, fixed, and the optimize over the model distribution.",
                    "label": 0
                },
                {
                    "sent": "And the second step is to fix the model, distribute fixed and optimized over PPC.",
                    "label": 1
                },
                {
                    "sent": "So for the first step, it's easy because it reduced to the.",
                    "label": 0
                },
                {
                    "sent": "The problem the problem of fully observed Max Internet, so windows that.",
                    "label": 0
                },
                {
                    "sent": "For non price it's equivalent to.",
                    "label": 0
                },
                {
                    "sent": "Emissary and optimizing problem.",
                    "label": 0
                },
                {
                    "sent": "It's quadratic program, and if you want to use the Loblaws prior it.",
                    "label": 0
                },
                {
                    "sent": "Is also can be done with version of Asian learning method.",
                    "label": 0
                },
                {
                    "sent": "So for the six step with.",
                    "label": 0
                },
                {
                    "sent": "The optimization problem is this cause we make this factorization assumption.",
                    "label": 0
                },
                {
                    "sent": "You can turn this step for each each sample independent.",
                    "label": 0
                },
                {
                    "sent": "So you get you introduce some of.",
                    "label": 0
                },
                {
                    "sent": "LaGrange multipliers and you get this general solution and this better parameter can be solved achieved by solving this problem.",
                    "label": 0
                },
                {
                    "sent": "So this is a non linear program.",
                    "label": 0
                },
                {
                    "sent": "So this is a set of constraints, so here it's constraint can be potentially cause because you observe the observer level Y.",
                    "label": 0
                },
                {
                    "sent": "Or the possible observer?",
                    "label": 0
                },
                {
                    "sent": "Why compute people nature so.",
                    "label": 0
                },
                {
                    "sent": "But the good news is you can reduce this problem to to equivalent form with polynomial number of constraints.",
                    "label": 1
                },
                {
                    "sent": "So I.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "It could go into the details.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "So let me show you something permanent results.",
                    "label": 0
                },
                {
                    "sent": "So here we consider the web data extraction.",
                    "label": 1
                },
                {
                    "sent": "We want to identify for attributes, name, image, price and description.",
                    "label": 0
                },
                {
                    "sent": "The method we want to compare the fully observed hierarchical content fields model and fully observed hierarchical Lexmark network and also their partial observed case.",
                    "label": 0
                },
                {
                    "sent": "The test set of from.",
                    "label": 0
                },
                {
                    "sent": "As from the web page is generated by suggested templates.",
                    "label": 0
                },
                {
                    "sent": "Different temperatures means the webpage have different design style or some.",
                    "label": 0
                },
                {
                    "sent": "Maybe have a different layout?",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "So here is the training set.",
                    "label": 0
                },
                {
                    "sent": "These are templates we use.",
                    "label": 0
                },
                {
                    "sent": "We collect 5 pages for training and team for testing.",
                    "label": 0
                },
                {
                    "sent": "So we consider two different level of inputs in the evaluation.",
                    "label": 0
                },
                {
                    "sent": "So for record level relation with just text text the record as inputs.",
                    "label": 1
                },
                {
                    "sent": "And for page level evaluation we take the whole web page as inputs.",
                    "label": 0
                },
                {
                    "sent": "So for for the record level evaluation for the partially observed model, we just provide the level of leaf nodes or other wearables are hidden.",
                    "label": 1
                },
                {
                    "sent": "So for parallelization we consider two different strategies to provide the supervision information.",
                    "label": 1
                },
                {
                    "sent": "The first strategy is just provide the leaf nodes and direct downloads.",
                    "label": 0
                },
                {
                    "sent": "With the true level before the 2nd segment strategy, we provide additional information.",
                    "label": 0
                },
                {
                    "sent": "For example, the nodes about with that record.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So here's the here's the results of record level evaluation, so.",
                    "label": 0
                },
                {
                    "sent": "All this is overall performance of average F1 block in 10 cycles.",
                    "label": 0
                },
                {
                    "sent": "Every job for one just algia value overall or 4H builds.",
                    "label": 0
                },
                {
                    "sent": "Blog intense accuracies.",
                    "label": 0
                },
                {
                    "sent": "Percent percent of records whose name, image and price are correct.",
                    "label": 1
                },
                {
                    "sent": "So we can see.",
                    "label": 0
                },
                {
                    "sent": "This is the partial observed next parking.",
                    "label": 0
                },
                {
                    "sent": "It's part of the next model network.",
                    "label": 0
                },
                {
                    "sent": "Or sorry maybe.",
                    "label": 0
                },
                {
                    "sent": "This notation is wrong, so it's a PM, not M3.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "So we can see with a reasonable and motion that actually the partial observed me and can perform compared with the fully observed.",
                    "label": 0
                },
                {
                    "sent": "Next, multimarket network.",
                    "label": 0
                },
                {
                    "sent": "But partial observed harajly counter and fields model perform.",
                    "label": 0
                },
                {
                    "sent": "Perform much worse so it also have a larger larger variance.",
                    "label": 0
                },
                {
                    "sent": "So this is a detailed performance of different attributes.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "So for the.",
                    "label": 0
                },
                {
                    "sent": "For the page revelation so this.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So for the first strategy to provide supervision information, so again, we can see that the partial observed me and can perform.",
                    "label": 0
                },
                {
                    "sent": "Much better than the partial result considering the field.",
                    "label": 0
                },
                {
                    "sent": "So for this technique, for the second strategy, provide mode supervision information so we can see the performance of the partial observed HCR change change very much.",
                    "label": 0
                },
                {
                    "sent": "So, but it's still still have our larger variance.",
                    "label": 0
                },
                {
                    "sent": "OK. QHCIF is it bias?",
                    "label": 0
                },
                {
                    "sent": "No, it's not bad, and it's not.",
                    "label": 0
                },
                {
                    "sent": "It's discriminative because it's optimized.",
                    "label": 0
                },
                {
                    "sent": "It optimizes the conditional like hold.",
                    "label": 0
                },
                {
                    "sent": "You have some hidden variable.",
                    "label": 0
                },
                {
                    "sent": "But not the margin.",
                    "label": 0
                },
                {
                    "sent": "Yeah, not a margin.",
                    "label": 0
                },
                {
                    "sent": "So that's a different from an approach or from the market.",
                    "label": 0
                },
                {
                    "sent": "I. I guess I think from the market because we use it.",
                    "label": 0
                },
                {
                    "sent": "All these cases we just use the normal prior, so it's equivalent to the Max Mark Mark Network.",
                    "label": 0
                },
                {
                    "sent": "How many games do you expect you get from B as in approach?",
                    "label": 0
                },
                {
                    "sent": "Yeah, we have another work to show.",
                    "label": 0
                },
                {
                    "sent": "If we use different prior so you can have different performance.",
                    "label": 0
                },
                {
                    "sent": "We also also issue that for user bashing learning most stable and if we use our norm, for example, our normal will give you unstable results so.",
                    "label": 0
                },
                {
                    "sent": "Yeah, we have another work to choose that.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Yeah, to summarize so so we proposed Max Max entropy, screaming Michael Network and basically we choose three advantages can offer so it's has activation problems guarantee it also can be designed to introduce sparsity.",
                    "label": 0
                },
                {
                    "sent": "And also it's easy to tend to be correlated variables.",
                    "label": 0
                },
                {
                    "sent": "So we also show some of your primary results.",
                    "label": 0
                },
                {
                    "sent": "OK, so the last slide the two to show where we are now.",
                    "label": 0
                },
                {
                    "sent": "So basically we have four different margin based learning method so as well.",
                    "label": 0
                },
                {
                    "sent": "Among network immunity and Nexon net.",
                    "label": 0
                },
                {
                    "sent": "So they optimized their to find different optimization problem and two different have different prediction rule.",
                    "label": 0
                },
                {
                    "sent": "So to see how the connected, let's start from SM which will also propose the 1st.",
                    "label": 0
                },
                {
                    "sent": "So from me, for you tend to strike protein, you get 3 and if you do, Beijing style learning will go to me D. So from me, if you want to attend to start putting together and we make the Internet so also you can start from M3.",
                    "label": 0
                },
                {
                    "sent": "You perform patient Start learning.",
                    "label": 0
                },
                {
                    "sent": "You also get the next Internet so that is maximum at its end of both paths, so OK.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": []
        }
    }
}