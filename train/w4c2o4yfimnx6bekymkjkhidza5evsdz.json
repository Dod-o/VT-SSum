{
    "id": "w4c2o4yfimnx6bekymkjkhidza5evsdz",
    "title": "Multitask Learning Using Nonparametrically Learned Predictor Subspaces",
    "info": {
        "author": [
            "Piyush Rai, University of Utah"
        ],
        "published": "Jan. 19, 2010",
        "recorded": "December 2009",
        "category": [
            "Top->Computer Science->Machine Learning->Multi-Task Learning"
        ]
    },
    "url": "http://videolectures.net/nipsworkshops09_rai_mlun/",
    "segmentation": [
        [
            "So hello everyone and you try and I'm going to be talking about this stuff that I've been doing for awhile now.",
            "It's multi task learning using nonparametric liloan predictor subspaces and this is joint work with my advisor.",
            "Hold on actually."
        ],
        [
            "So the problem setting that we are interested in is when we are given a set of related learning tasks and I think Chris does away with this data.",
            "Very nice job at motivating this problem, but I'll again like briefly try to motivate again for this thought.",
            "So what we wish is to we wish to basically exploit dependently in structure between learning problems.",
            "So you have you are given a set of learning problems and you expect them to be related in some way and so we used to.",
            "We wish to basically exploit that relatedness in order to be better.",
            "Better solve these problems and the reason why we want to do this is because that because we're trying to learn multiple models and each Model S certain statics strength and we somehow want to share the static static strength across all the tasks.",
            "And our hope is that it will lead to overall generalize overall generalization improvement.",
            "I do hold back into the baby.",
            "Will try to solve this problem is that we will try to learn all these tasks together."
        ],
        [
            "So I was not defined the setting that we assuming for this particular problem.",
            "So what we're given with M task they are defined by task parameters.",
            "He 22 tee time or planning to GDB.",
            "So you can think of these tasks parameters as weight vectors, for example for logistic regression model or your SPM.",
            "So these are like these.",
            "You can think of.",
            "These features will wait vectors.",
            "So what the standard Bayesian approaches try to do in these sort of problems is that we assume some sort of notion of relatedness, and that notion of relatedness can be incorporated into the problem by using the hierarchical prior.",
            "So you can assume that all the tasks parameters share a common Gaussian prior for example, or also like another assumption could be what Chris was talking in the previous thought that you could have something like a Coke reading model which can actually capture the covariance structure of all the cars.",
            "In this talk, I will assume that I am going to have a somewhat complementary but a different assumption is that all the task parameters these Peter likely doesn't agree, then they all share a linear subspace.",
            "And we see this stuff.",
            "Subspace will be bought.",
            "Will actually determine how the tasks are related.",
            "And the way we will learn this subspace."
        ],
        [
            "Is that we will learn this subspace nonparametrically, so we will not assume anything about its complicity, or so we will not assume anything about the complexity complexity of this subspace, and we will let only the data determine how complex that subspace is going to be.",
            "So by complexity I mean that we will not assume anything about the intrinsic dimensionality of this subspace and we will discover that number automatically, so that one notion, and if you know what's a basis, so you can think of a subspace as using some sort of.",
            "Some kind of projection matrix, so we will also control the sparsity of that prediction metrics.",
            "So we will.",
            "We will basically deal with those these two notions of complexity automatically.",
            "Now you can think of that.",
            "You can think you can argue that."
        ],
        [
            "Subspace could be a somewhat restrictive assumption, so we I will also talk about a generalization of our basic model in which your this subspace would be some some smooth linear manifold nonlinear medical also.",
            "OK, so I'll define the problem more formally now."
        ],
        [
            "We have how many cars defined by these unknown parameters determined to see the end and the generative story that I'm going to assume here is that each time is generated as a product of a metric Z.",
            "Thanks, a task specific coefficient vector PM plus some task specific noise asylum and this story is true for all the tasks from L212M.",
            "And that makes these as you can see, Big Matrix Z is shared by all the task parameters.",
            "OK so I can write the same thing in a matrix notation, So what I?"
        ],
        [
            "So I can just check all the way all these sites for amateurs in the metrics form and I can write this thing a big matrix rotation like big data as Z times another matrix nearly done.",
            "Plus this metrics E. So this is just a matrix way of representing the earlier generating story.",
            "So we do we have is that all these task parameters in this big matrix feeder and so the remains the same.",
            "And this metric spaces that consists of the task specific provisions like able to AM.",
            "And then we have this noise or static.",
            "Noise error metrics with it, but we celebrate.",
            "It really is the noise corresponding to the that particular time.",
            "So again, so this email.",
            "It is basically the differential shared some space and it has four K column vectors, so you can just think of it in terms of how you're appreciate to each column is attached basis vector basis vector and you can think of each task as being composed of a linear combination of those basis vectors, task basis vectors.",
            "So if you just squint a little, it just looks like the sender factor analysis, or probabilistically setting, but the difference is that we don't have observed data, because if you do PC or factor analysis what you do you deal with selling on observed data.",
            "But in all cases we also wish to learn Peter, so he does not observed in our setting.",
            "So it is still a little late latent variable in our setting.",
            "OK, So what will we do?",
            "We're going to take an unfair."
        ],
        [
            "Activision approach of solving this problem.",
            "So again, regarding our setup is like this, metric data is easy times 80.",
            "WE and all these starts Cherokee subspace defined by the time schematics Z.",
            "But now the question is that what the true case?",
            "So what's the true dimensionality of my slated subspace in which these task parameters live?",
            "So how do we select that number?",
            "How do we?",
            "How do we know what that number is?",
            "OK, so the solution."
        ],
        [
            "We will be taking taking up would be that we will model metric Z using something called the Indian buffet process and it's a nonparametric Bayesian model which is used to which is used in the prior distribution on infinite.",
            "About infinite size binary matrices.",
            "But The thing is that this Indian buffet process priority is defined on infinite binary valued matrices, whereas this the matrix is real value.",
            "It has real valued entries.",
            "So to deal with that case, what we will do, we'll just simply express busy metrics as a product."
        ],
        [
            "We think it's a hardware product with religious symbols and the times we be the binary metrics.",
            "Really, the real value metrics and they both have size is equal to 10 scale.",
            "So now what we will do?",
            "Since Norwegian biometric business mails I depend on the metrics and that will help us determine that these two number the number of columns indeed and we will.",
            "The the real valued metrics will play versus viral nothing.",
            "So this is the basic setup in our problem.",
            "OK, I'll quickly describe what."
        ],
        [
            "So really, how the Indian buffet process was so intimate process works?",
            "Imprecise binary matrices.",
            "And it's primarily used to model the little feature structure of a set of observed data points.",
            "So it is because it's a number because it is a very nice analogy in terms of a set of customers coming to an Indian buffet and choosing dishes for themselves.",
            "So in this analogy can be understood by, you can think of the observation and a customer and then each lady teacher can be thought of as a dish.",
            "And so I mean this is the general story.",
            "How this this lady feature of the meeting people to observe?",
            "Because I'm in heaven.",
            "So what happens is that you can think of this verse throughout the 1st generation.",
            "So the first thing you want.",
            "The 1st order she can pick up as a customer who comes to an end of it and you select a number of digits or itself for the first district number of vision and what happens when the next customer comes in.",
            "It selects a number of dishes from the already simple dishes, then goes on to select the number of users and the process continues for all the customers.",
            "And what happens after awhile that each new customer start selecting the already sampled dishes and then selecting a few dishes?",
            "Season of the other point and that will you know that.",
            "This metric is completed that will you know that will work with the right set of little feature to express your data.",
            "So educated if you follow the same process then."
        ],
        [
            "The number of columns in this matrix into binary matrix is determined automatically.",
            "It only depends on the data in.",
            "So you didn't.",
            "You didn't make any very assumption on the number of columns.",
            "So basically this metrics.",
            "This indicate processes parameterized by a parameter Alpha, which can automatically control the network problems and help with this particular business metrics.",
            "No, in other thing what we have we have this attachment events so we will reboot Aspergers as the customers who come into this Indian buffet and those tasks businesses vectors which each task is composed by and composed of these.",
            "If you define the setup missions that you have.",
            "OK, so coming to the full model.",
            "So what we have here?"
        ],
        [
            "M Plus and 40 stuff.",
            "You have dealer so if you can just write the all the data that you that you were given as big budget action, right?",
            "So it consists of actual Bible that large data for task one and so on for the Amazons you have accept while handle we will assume a probabilistic, a linear models for either a service model can be applied to division problems or perceptions of them.",
            "If you have a regression task then you can just think of required rerun former from abortion within mean CFX.",
            "Put up with some noise if you have a classification task then you can assume that your labels are being run from the logistic regression model, so this is like.",
            "Or the third time, so you have you defeated the actress as we tend to be tense.",
            "Erica versus the line and what we did as I said earlier, we model this binary magically using dental work across is we learn which handles hyperparameter Alpha and Richard.",
            "The random variables with the metrics.",
            "It's basically drawn from abortion.",
            "Same is true for this metric.",
            "Easier and possible.",
            "So noise is also zero in Goshen.",
            "OK, So what?",
            "So no I am.",
            "We also have an augmented."
        ],
        [
            "Because if you think of the Asian model, what you have there is that you have.",
            "So learning of this metric space defined by this geometric, it basically involves only feed up.",
            "OK, which is again a random variable.",
            "Now if you don't have a large number of tasks will you will not have enough data to learn that message?",
            "The reliability.",
            "So what you can you can do.",
            "You can actually augment the original model by including the inputs X.",
            "Also in learning of this metric, and if it turns out that the assumption this model has is that these tasks as well as your input, they share the same living substrate.",
            "It is true actually, because if you think of the represented here then you can express each bit vector as a linear combination of the observed data, right?",
            "And if the observed data has some basic vector, then you can also write each letter as the other email combination of the soul, same basis vectors.",
            "So this essentially is true when we are assuming that action because they would like to share the same subspace.",
            "Then I think about this thing is that once you include the data X or learning reason, you have more data.",
            "So we can do this for learning more elaborate.",
            "And so everything would be product is done by using uncertainty.",
            "OK, so coming to experiment.",
            "So we apply."
        ],
        [
            "This model onto multi label because it's so each predicting each label becomes a task.",
            "So and we applied this 2 two datasets from the UCI repository, so persistent degenerative the second is the same data set so and we had baselines we applied this model.",
            "We compare this model against a Bayesian logic conditions which was independently trained for each.",
            "Each label.",
            "We also did the pulling her, pulling things.",
            "We just combine all the data together and learn a single model for taller.",
            "We also compared our model against the task testing frameworks, which is based on the DPS traditional process based clustering and then these two other computers in the last movement grows through our models.",
            "The first model which only used it.",
            "I'm learning the negative space metric Z and the second model use the input data as well.",
            "So as you can see, like both our models performed recently better than either cooling or the task, missing approaches, and in particular it also shows active in politics that's better.",
            "Anymore what it shows that including the input data and learning that task basis metrics does improve performance.",
            "But we also investigated the effect of wearing the training data site.",
            "So we compared this our models against vision local before listing tradition, and we saw that even with a very small amount of data, as you can see here, our model is close to optimal and as birth and also you can see that our second mortgage is slightly better than the first model and both these models are definitely better than the vision making a logical reason.",
            "Difference between accuracy of each model and so this is basically the equity and we also compared the TV series called so.",
            "Basically this is for the senior, does it?",
            "Then these are called?",
            "OK, so as I said in the beginning, assuming a linear."
        ],
        [
            "Space can be somewhat restrictive, So what you can do, actually you can actually compose a set of linear subspaces to model a nonlinear manifold.",
            "OK, so.",
            "You can see, or you can think of a non linear subspaces consisting of a mixture of linear subspaces.",
            "So as you and then you can think also in this year.",
            "Do you have any linear subspaces and your actual nonlinear manifold?",
            "It basically it can be modeled as a collection updated picture of the linear subspaces, and this is just like the mixture of.",
            "For example, if you think of questing you have mixture of Gaussian will similarly to model nonlinear manifold for data, you can actually use something like mixture of vector analyzers or mixture of probabilistic easier.",
            "But again so we are following the similar scene.",
            "But in our case we are doing this on late late interview.",
            "So this kind of a mixture setting can actually help us in.",
            "As I said to discover my folder structure underlying the task parameters and also in the original model that I described earlier, we had a single linear subspace, so all the large parameters were sharing the same subspace.",
            "Now if there are some outliers, ask then you are also encouraging them to share the same the same subspace.",
            "OK, so in that case you might have heard about negative transfer in multi task learning.",
            "So if you want to avoid that work, I mean this model it will be.",
            "Very effectively segregate starts into different subspaces, so if there are there are outlier tasks they can be made to have their own subspace so they will not affect the learning of the.",
            "That subspace?",
            "OK so but in this model can also be done in a non parametric way.",
            "So again there are two models that can problems in this kind of setting.",
            "So you have to 1st select how many number of major components that you want to have.",
            "And again the interested dimensionality of each subspace.",
            "So it turns out that you can actually learn both these parameters in a nonparametric.",
            "Basically just impose the."
        ],
        [
            "He tried his deposit right on his music up again.",
            "Then you can model the number of.",
            "We will automatically infer, infer the number of Mr Components and also, just like I just said, I dislike the idea.",
            "Featuring you can actually infiltrating the majority of these.",
            "Each of these are basic basic basic subscription by using an identifier.",
            "So also this is work in progress, so I love her very much unlike any.",
            "Any feedback that you guys have.",
            "OK, so we can do so.",
            "We have presented a nonparametric version framework for multi task."
        ],
        [
            "That might be the building and basically our approach is based on share having a shared many folders secure underlying the task parameters and we don't have to assume anything a priori about the structure of the manifold.",
            "Basically, our model as I showed, so we started with a linear subspace model, but we could actually extend it to to model nonparametric medical, non non linear inputs as well.",
            "Thanks."
        ],
        [
            "Never.",
            "My birthday please question."
        ],
        [
            "Yeah.",
            "Something like.",
            "Since the perspectives and binary matches.",
            "Nothing.",
            "I only did such things so it is not an artificially tell the hyperparameter it.",
            "It will be learned based on the data that we have for all the tasks.",
            "So I don't see why it isn't artificial.",
            "So when we get better today, thank you.",
            "I could send you saying you know The thing is that you don't have to do everything.",
            "The number of latent subscription so that number will be automatically discovered.",
            "I don't do this or that.",
            "I'm not aware of nickel now.",
            "Yes, it is different than the sum of its value.",
            "Yeah, on the basically.",
            "Yeah, so yeah.",
            "So that's wonderful.",
            "That's like that.",
            "How people used to do like easier.",
            "For example, they expect the single values and then based on that do something different question.",
            "But I mean the basically the non metric Bayesian models you don't have to do this kind of adult education.",
            "So I mean this is mostly I see it as a more principled way of like.",
            "Controlling the model complexity.",
            "Yeah, it's kind of ultimately, but I mean, I think this is a more sensible approach.",
            "Like if you want to control the communication model, is only the data can design design, how complex your model can grow so.",
            "Something like what you mentioned.",
            "One quick question, so no.",
            "You're basically doing rather happy model in the latent space, yet compare the model that you have from the actual parameter space to do the predictions.",
            "Yes, so.",
            "I guess that he does that in order to really learn this latent space formally, you need to have a will to learn.",
            "Willing to have a large number of different tasks, yes, so do you have any OK so.",
            "Mention about my second model in it, so if you don't have enough number it because in the first model if you go back to this.",
            "So is this the first case?",
            "It's officially work."
        ],
        [
            "He defeated the curve.",
            "You don't have enough number of tasks.",
            "Then you can actually automate your model with the input data also.",
            "So in this case, this is this shared subspace exactly like ending is making up information from your inputs as well.",
            "How many passed you, by the way?",
            "These datasets have really small number of labels, likely elect 14 tasks, you know, so these are not really so you can actually.",
            "I mean this is ongoing work, so you can actually if you have lots of tasks that you can leverage this information even more.",
            "OK, let's speak for me."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So hello everyone and you try and I'm going to be talking about this stuff that I've been doing for awhile now.",
                    "label": 0
                },
                {
                    "sent": "It's multi task learning using nonparametric liloan predictor subspaces and this is joint work with my advisor.",
                    "label": 1
                },
                {
                    "sent": "Hold on actually.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the problem setting that we are interested in is when we are given a set of related learning tasks and I think Chris does away with this data.",
                    "label": 0
                },
                {
                    "sent": "Very nice job at motivating this problem, but I'll again like briefly try to motivate again for this thought.",
                    "label": 0
                },
                {
                    "sent": "So what we wish is to we wish to basically exploit dependently in structure between learning problems.",
                    "label": 1
                },
                {
                    "sent": "So you have you are given a set of learning problems and you expect them to be related in some way and so we used to.",
                    "label": 0
                },
                {
                    "sent": "We wish to basically exploit that relatedness in order to be better.",
                    "label": 0
                },
                {
                    "sent": "Better solve these problems and the reason why we want to do this is because that because we're trying to learn multiple models and each Model S certain statics strength and we somehow want to share the static static strength across all the tasks.",
                    "label": 0
                },
                {
                    "sent": "And our hope is that it will lead to overall generalize overall generalization improvement.",
                    "label": 0
                },
                {
                    "sent": "I do hold back into the baby.",
                    "label": 0
                },
                {
                    "sent": "Will try to solve this problem is that we will try to learn all these tasks together.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So I was not defined the setting that we assuming for this particular problem.",
                    "label": 0
                },
                {
                    "sent": "So what we're given with M task they are defined by task parameters.",
                    "label": 1
                },
                {
                    "sent": "He 22 tee time or planning to GDB.",
                    "label": 0
                },
                {
                    "sent": "So you can think of these tasks parameters as weight vectors, for example for logistic regression model or your SPM.",
                    "label": 0
                },
                {
                    "sent": "So these are like these.",
                    "label": 0
                },
                {
                    "sent": "You can think of.",
                    "label": 0
                },
                {
                    "sent": "These features will wait vectors.",
                    "label": 0
                },
                {
                    "sent": "So what the standard Bayesian approaches try to do in these sort of problems is that we assume some sort of notion of relatedness, and that notion of relatedness can be incorporated into the problem by using the hierarchical prior.",
                    "label": 0
                },
                {
                    "sent": "So you can assume that all the tasks parameters share a common Gaussian prior for example, or also like another assumption could be what Chris was talking in the previous thought that you could have something like a Coke reading model which can actually capture the covariance structure of all the cars.",
                    "label": 1
                },
                {
                    "sent": "In this talk, I will assume that I am going to have a somewhat complementary but a different assumption is that all the task parameters these Peter likely doesn't agree, then they all share a linear subspace.",
                    "label": 0
                },
                {
                    "sent": "And we see this stuff.",
                    "label": 0
                },
                {
                    "sent": "Subspace will be bought.",
                    "label": 0
                },
                {
                    "sent": "Will actually determine how the tasks are related.",
                    "label": 0
                },
                {
                    "sent": "And the way we will learn this subspace.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Is that we will learn this subspace nonparametrically, so we will not assume anything about its complicity, or so we will not assume anything about the complexity complexity of this subspace, and we will let only the data determine how complex that subspace is going to be.",
                    "label": 0
                },
                {
                    "sent": "So by complexity I mean that we will not assume anything about the intrinsic dimensionality of this subspace and we will discover that number automatically, so that one notion, and if you know what's a basis, so you can think of a subspace as using some sort of.",
                    "label": 1
                },
                {
                    "sent": "Some kind of projection matrix, so we will also control the sparsity of that prediction metrics.",
                    "label": 0
                },
                {
                    "sent": "So we will.",
                    "label": 0
                },
                {
                    "sent": "We will basically deal with those these two notions of complexity automatically.",
                    "label": 0
                },
                {
                    "sent": "Now you can think of that.",
                    "label": 0
                },
                {
                    "sent": "You can think you can argue that.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Subspace could be a somewhat restrictive assumption, so we I will also talk about a generalization of our basic model in which your this subspace would be some some smooth linear manifold nonlinear medical also.",
                    "label": 0
                },
                {
                    "sent": "OK, so I'll define the problem more formally now.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We have how many cars defined by these unknown parameters determined to see the end and the generative story that I'm going to assume here is that each time is generated as a product of a metric Z.",
                    "label": 1
                },
                {
                    "sent": "Thanks, a task specific coefficient vector PM plus some task specific noise asylum and this story is true for all the tasks from L212M.",
                    "label": 0
                },
                {
                    "sent": "And that makes these as you can see, Big Matrix Z is shared by all the task parameters.",
                    "label": 0
                },
                {
                    "sent": "OK so I can write the same thing in a matrix notation, So what I?",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So I can just check all the way all these sites for amateurs in the metrics form and I can write this thing a big matrix rotation like big data as Z times another matrix nearly done.",
                    "label": 0
                },
                {
                    "sent": "Plus this metrics E. So this is just a matrix way of representing the earlier generating story.",
                    "label": 0
                },
                {
                    "sent": "So we do we have is that all these task parameters in this big matrix feeder and so the remains the same.",
                    "label": 0
                },
                {
                    "sent": "And this metric spaces that consists of the task specific provisions like able to AM.",
                    "label": 0
                },
                {
                    "sent": "And then we have this noise or static.",
                    "label": 0
                },
                {
                    "sent": "Noise error metrics with it, but we celebrate.",
                    "label": 0
                },
                {
                    "sent": "It really is the noise corresponding to the that particular time.",
                    "label": 0
                },
                {
                    "sent": "So again, so this email.",
                    "label": 0
                },
                {
                    "sent": "It is basically the differential shared some space and it has four K column vectors, so you can just think of it in terms of how you're appreciate to each column is attached basis vector basis vector and you can think of each task as being composed of a linear combination of those basis vectors, task basis vectors.",
                    "label": 0
                },
                {
                    "sent": "So if you just squint a little, it just looks like the sender factor analysis, or probabilistically setting, but the difference is that we don't have observed data, because if you do PC or factor analysis what you do you deal with selling on observed data.",
                    "label": 0
                },
                {
                    "sent": "But in all cases we also wish to learn Peter, so he does not observed in our setting.",
                    "label": 0
                },
                {
                    "sent": "So it is still a little late latent variable in our setting.",
                    "label": 0
                },
                {
                    "sent": "OK, So what will we do?",
                    "label": 0
                },
                {
                    "sent": "We're going to take an unfair.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Activision approach of solving this problem.",
                    "label": 0
                },
                {
                    "sent": "So again, regarding our setup is like this, metric data is easy times 80.",
                    "label": 1
                },
                {
                    "sent": "WE and all these starts Cherokee subspace defined by the time schematics Z.",
                    "label": 1
                },
                {
                    "sent": "But now the question is that what the true case?",
                    "label": 0
                },
                {
                    "sent": "So what's the true dimensionality of my slated subspace in which these task parameters live?",
                    "label": 0
                },
                {
                    "sent": "So how do we select that number?",
                    "label": 0
                },
                {
                    "sent": "How do we?",
                    "label": 0
                },
                {
                    "sent": "How do we know what that number is?",
                    "label": 0
                },
                {
                    "sent": "OK, so the solution.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We will be taking taking up would be that we will model metric Z using something called the Indian buffet process and it's a nonparametric Bayesian model which is used to which is used in the prior distribution on infinite.",
                    "label": 1
                },
                {
                    "sent": "About infinite size binary matrices.",
                    "label": 0
                },
                {
                    "sent": "But The thing is that this Indian buffet process priority is defined on infinite binary valued matrices, whereas this the matrix is real value.",
                    "label": 0
                },
                {
                    "sent": "It has real valued entries.",
                    "label": 0
                },
                {
                    "sent": "So to deal with that case, what we will do, we'll just simply express busy metrics as a product.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We think it's a hardware product with religious symbols and the times we be the binary metrics.",
                    "label": 0
                },
                {
                    "sent": "Really, the real value metrics and they both have size is equal to 10 scale.",
                    "label": 0
                },
                {
                    "sent": "So now what we will do?",
                    "label": 0
                },
                {
                    "sent": "Since Norwegian biometric business mails I depend on the metrics and that will help us determine that these two number the number of columns indeed and we will.",
                    "label": 1
                },
                {
                    "sent": "The the real valued metrics will play versus viral nothing.",
                    "label": 0
                },
                {
                    "sent": "So this is the basic setup in our problem.",
                    "label": 0
                },
                {
                    "sent": "OK, I'll quickly describe what.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So really, how the Indian buffet process was so intimate process works?",
                    "label": 1
                },
                {
                    "sent": "Imprecise binary matrices.",
                    "label": 0
                },
                {
                    "sent": "And it's primarily used to model the little feature structure of a set of observed data points.",
                    "label": 0
                },
                {
                    "sent": "So it is because it's a number because it is a very nice analogy in terms of a set of customers coming to an Indian buffet and choosing dishes for themselves.",
                    "label": 0
                },
                {
                    "sent": "So in this analogy can be understood by, you can think of the observation and a customer and then each lady teacher can be thought of as a dish.",
                    "label": 0
                },
                {
                    "sent": "And so I mean this is the general story.",
                    "label": 0
                },
                {
                    "sent": "How this this lady feature of the meeting people to observe?",
                    "label": 0
                },
                {
                    "sent": "Because I'm in heaven.",
                    "label": 0
                },
                {
                    "sent": "So what happens is that you can think of this verse throughout the 1st generation.",
                    "label": 0
                },
                {
                    "sent": "So the first thing you want.",
                    "label": 0
                },
                {
                    "sent": "The 1st order she can pick up as a customer who comes to an end of it and you select a number of digits or itself for the first district number of vision and what happens when the next customer comes in.",
                    "label": 0
                },
                {
                    "sent": "It selects a number of dishes from the already simple dishes, then goes on to select the number of users and the process continues for all the customers.",
                    "label": 0
                },
                {
                    "sent": "And what happens after awhile that each new customer start selecting the already sampled dishes and then selecting a few dishes?",
                    "label": 0
                },
                {
                    "sent": "Season of the other point and that will you know that.",
                    "label": 0
                },
                {
                    "sent": "This metric is completed that will you know that will work with the right set of little feature to express your data.",
                    "label": 0
                },
                {
                    "sent": "So educated if you follow the same process then.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The number of columns in this matrix into binary matrix is determined automatically.",
                    "label": 1
                },
                {
                    "sent": "It only depends on the data in.",
                    "label": 0
                },
                {
                    "sent": "So you didn't.",
                    "label": 0
                },
                {
                    "sent": "You didn't make any very assumption on the number of columns.",
                    "label": 0
                },
                {
                    "sent": "So basically this metrics.",
                    "label": 0
                },
                {
                    "sent": "This indicate processes parameterized by a parameter Alpha, which can automatically control the network problems and help with this particular business metrics.",
                    "label": 1
                },
                {
                    "sent": "No, in other thing what we have we have this attachment events so we will reboot Aspergers as the customers who come into this Indian buffet and those tasks businesses vectors which each task is composed by and composed of these.",
                    "label": 0
                },
                {
                    "sent": "If you define the setup missions that you have.",
                    "label": 0
                },
                {
                    "sent": "OK, so coming to the full model.",
                    "label": 0
                },
                {
                    "sent": "So what we have here?",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "M Plus and 40 stuff.",
                    "label": 0
                },
                {
                    "sent": "You have dealer so if you can just write the all the data that you that you were given as big budget action, right?",
                    "label": 0
                },
                {
                    "sent": "So it consists of actual Bible that large data for task one and so on for the Amazons you have accept while handle we will assume a probabilistic, a linear models for either a service model can be applied to division problems or perceptions of them.",
                    "label": 0
                },
                {
                    "sent": "If you have a regression task then you can just think of required rerun former from abortion within mean CFX.",
                    "label": 0
                },
                {
                    "sent": "Put up with some noise if you have a classification task then you can assume that your labels are being run from the logistic regression model, so this is like.",
                    "label": 0
                },
                {
                    "sent": "Or the third time, so you have you defeated the actress as we tend to be tense.",
                    "label": 0
                },
                {
                    "sent": "Erica versus the line and what we did as I said earlier, we model this binary magically using dental work across is we learn which handles hyperparameter Alpha and Richard.",
                    "label": 0
                },
                {
                    "sent": "The random variables with the metrics.",
                    "label": 0
                },
                {
                    "sent": "It's basically drawn from abortion.",
                    "label": 0
                },
                {
                    "sent": "Same is true for this metric.",
                    "label": 0
                },
                {
                    "sent": "Easier and possible.",
                    "label": 0
                },
                {
                    "sent": "So noise is also zero in Goshen.",
                    "label": 0
                },
                {
                    "sent": "OK, So what?",
                    "label": 0
                },
                {
                    "sent": "So no I am.",
                    "label": 0
                },
                {
                    "sent": "We also have an augmented.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Because if you think of the Asian model, what you have there is that you have.",
                    "label": 0
                },
                {
                    "sent": "So learning of this metric space defined by this geometric, it basically involves only feed up.",
                    "label": 0
                },
                {
                    "sent": "OK, which is again a random variable.",
                    "label": 0
                },
                {
                    "sent": "Now if you don't have a large number of tasks will you will not have enough data to learn that message?",
                    "label": 0
                },
                {
                    "sent": "The reliability.",
                    "label": 0
                },
                {
                    "sent": "So what you can you can do.",
                    "label": 0
                },
                {
                    "sent": "You can actually augment the original model by including the inputs X.",
                    "label": 1
                },
                {
                    "sent": "Also in learning of this metric, and if it turns out that the assumption this model has is that these tasks as well as your input, they share the same living substrate.",
                    "label": 1
                },
                {
                    "sent": "It is true actually, because if you think of the represented here then you can express each bit vector as a linear combination of the observed data, right?",
                    "label": 0
                },
                {
                    "sent": "And if the observed data has some basic vector, then you can also write each letter as the other email combination of the soul, same basis vectors.",
                    "label": 0
                },
                {
                    "sent": "So this essentially is true when we are assuming that action because they would like to share the same subspace.",
                    "label": 0
                },
                {
                    "sent": "Then I think about this thing is that once you include the data X or learning reason, you have more data.",
                    "label": 1
                },
                {
                    "sent": "So we can do this for learning more elaborate.",
                    "label": 0
                },
                {
                    "sent": "And so everything would be product is done by using uncertainty.",
                    "label": 0
                },
                {
                    "sent": "OK, so coming to experiment.",
                    "label": 0
                },
                {
                    "sent": "So we apply.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This model onto multi label because it's so each predicting each label becomes a task.",
                    "label": 0
                },
                {
                    "sent": "So and we applied this 2 two datasets from the UCI repository, so persistent degenerative the second is the same data set so and we had baselines we applied this model.",
                    "label": 0
                },
                {
                    "sent": "We compare this model against a Bayesian logic conditions which was independently trained for each.",
                    "label": 0
                },
                {
                    "sent": "Each label.",
                    "label": 0
                },
                {
                    "sent": "We also did the pulling her, pulling things.",
                    "label": 0
                },
                {
                    "sent": "We just combine all the data together and learn a single model for taller.",
                    "label": 0
                },
                {
                    "sent": "We also compared our model against the task testing frameworks, which is based on the DPS traditional process based clustering and then these two other computers in the last movement grows through our models.",
                    "label": 0
                },
                {
                    "sent": "The first model which only used it.",
                    "label": 0
                },
                {
                    "sent": "I'm learning the negative space metric Z and the second model use the input data as well.",
                    "label": 0
                },
                {
                    "sent": "So as you can see, like both our models performed recently better than either cooling or the task, missing approaches, and in particular it also shows active in politics that's better.",
                    "label": 0
                },
                {
                    "sent": "Anymore what it shows that including the input data and learning that task basis metrics does improve performance.",
                    "label": 0
                },
                {
                    "sent": "But we also investigated the effect of wearing the training data site.",
                    "label": 0
                },
                {
                    "sent": "So we compared this our models against vision local before listing tradition, and we saw that even with a very small amount of data, as you can see here, our model is close to optimal and as birth and also you can see that our second mortgage is slightly better than the first model and both these models are definitely better than the vision making a logical reason.",
                    "label": 0
                },
                {
                    "sent": "Difference between accuracy of each model and so this is basically the equity and we also compared the TV series called so.",
                    "label": 0
                },
                {
                    "sent": "Basically this is for the senior, does it?",
                    "label": 0
                },
                {
                    "sent": "Then these are called?",
                    "label": 0
                },
                {
                    "sent": "OK, so as I said in the beginning, assuming a linear.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Space can be somewhat restrictive, So what you can do, actually you can actually compose a set of linear subspaces to model a nonlinear manifold.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "You can see, or you can think of a non linear subspaces consisting of a mixture of linear subspaces.",
                    "label": 1
                },
                {
                    "sent": "So as you and then you can think also in this year.",
                    "label": 0
                },
                {
                    "sent": "Do you have any linear subspaces and your actual nonlinear manifold?",
                    "label": 1
                },
                {
                    "sent": "It basically it can be modeled as a collection updated picture of the linear subspaces, and this is just like the mixture of.",
                    "label": 0
                },
                {
                    "sent": "For example, if you think of questing you have mixture of Gaussian will similarly to model nonlinear manifold for data, you can actually use something like mixture of vector analyzers or mixture of probabilistic easier.",
                    "label": 0
                },
                {
                    "sent": "But again so we are following the similar scene.",
                    "label": 0
                },
                {
                    "sent": "But in our case we are doing this on late late interview.",
                    "label": 0
                },
                {
                    "sent": "So this kind of a mixture setting can actually help us in.",
                    "label": 1
                },
                {
                    "sent": "As I said to discover my folder structure underlying the task parameters and also in the original model that I described earlier, we had a single linear subspace, so all the large parameters were sharing the same subspace.",
                    "label": 0
                },
                {
                    "sent": "Now if there are some outliers, ask then you are also encouraging them to share the same the same subspace.",
                    "label": 0
                },
                {
                    "sent": "OK, so in that case you might have heard about negative transfer in multi task learning.",
                    "label": 0
                },
                {
                    "sent": "So if you want to avoid that work, I mean this model it will be.",
                    "label": 0
                },
                {
                    "sent": "Very effectively segregate starts into different subspaces, so if there are there are outlier tasks they can be made to have their own subspace so they will not affect the learning of the.",
                    "label": 0
                },
                {
                    "sent": "That subspace?",
                    "label": 0
                },
                {
                    "sent": "OK so but in this model can also be done in a non parametric way.",
                    "label": 0
                },
                {
                    "sent": "So again there are two models that can problems in this kind of setting.",
                    "label": 0
                },
                {
                    "sent": "So you have to 1st select how many number of major components that you want to have.",
                    "label": 0
                },
                {
                    "sent": "And again the interested dimensionality of each subspace.",
                    "label": 0
                },
                {
                    "sent": "So it turns out that you can actually learn both these parameters in a nonparametric.",
                    "label": 0
                },
                {
                    "sent": "Basically just impose the.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "He tried his deposit right on his music up again.",
                    "label": 0
                },
                {
                    "sent": "Then you can model the number of.",
                    "label": 1
                },
                {
                    "sent": "We will automatically infer, infer the number of Mr Components and also, just like I just said, I dislike the idea.",
                    "label": 0
                },
                {
                    "sent": "Featuring you can actually infiltrating the majority of these.",
                    "label": 1
                },
                {
                    "sent": "Each of these are basic basic basic subscription by using an identifier.",
                    "label": 0
                },
                {
                    "sent": "So also this is work in progress, so I love her very much unlike any.",
                    "label": 0
                },
                {
                    "sent": "Any feedback that you guys have.",
                    "label": 0
                },
                {
                    "sent": "OK, so we can do so.",
                    "label": 0
                },
                {
                    "sent": "We have presented a nonparametric version framework for multi task.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "That might be the building and basically our approach is based on share having a shared many folders secure underlying the task parameters and we don't have to assume anything a priori about the structure of the manifold.",
                    "label": 1
                },
                {
                    "sent": "Basically, our model as I showed, so we started with a linear subspace model, but we could actually extend it to to model nonparametric medical, non non linear inputs as well.",
                    "label": 0
                },
                {
                    "sent": "Thanks.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Never.",
                    "label": 0
                },
                {
                    "sent": "My birthday please question.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Something like.",
                    "label": 0
                },
                {
                    "sent": "Since the perspectives and binary matches.",
                    "label": 0
                },
                {
                    "sent": "Nothing.",
                    "label": 0
                },
                {
                    "sent": "I only did such things so it is not an artificially tell the hyperparameter it.",
                    "label": 0
                },
                {
                    "sent": "It will be learned based on the data that we have for all the tasks.",
                    "label": 0
                },
                {
                    "sent": "So I don't see why it isn't artificial.",
                    "label": 0
                },
                {
                    "sent": "So when we get better today, thank you.",
                    "label": 0
                },
                {
                    "sent": "I could send you saying you know The thing is that you don't have to do everything.",
                    "label": 0
                },
                {
                    "sent": "The number of latent subscription so that number will be automatically discovered.",
                    "label": 0
                },
                {
                    "sent": "I don't do this or that.",
                    "label": 0
                },
                {
                    "sent": "I'm not aware of nickel now.",
                    "label": 0
                },
                {
                    "sent": "Yes, it is different than the sum of its value.",
                    "label": 0
                },
                {
                    "sent": "Yeah, on the basically.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so yeah.",
                    "label": 0
                },
                {
                    "sent": "So that's wonderful.",
                    "label": 0
                },
                {
                    "sent": "That's like that.",
                    "label": 0
                },
                {
                    "sent": "How people used to do like easier.",
                    "label": 0
                },
                {
                    "sent": "For example, they expect the single values and then based on that do something different question.",
                    "label": 0
                },
                {
                    "sent": "But I mean the basically the non metric Bayesian models you don't have to do this kind of adult education.",
                    "label": 0
                },
                {
                    "sent": "So I mean this is mostly I see it as a more principled way of like.",
                    "label": 0
                },
                {
                    "sent": "Controlling the model complexity.",
                    "label": 0
                },
                {
                    "sent": "Yeah, it's kind of ultimately, but I mean, I think this is a more sensible approach.",
                    "label": 0
                },
                {
                    "sent": "Like if you want to control the communication model, is only the data can design design, how complex your model can grow so.",
                    "label": 0
                },
                {
                    "sent": "Something like what you mentioned.",
                    "label": 0
                },
                {
                    "sent": "One quick question, so no.",
                    "label": 0
                },
                {
                    "sent": "You're basically doing rather happy model in the latent space, yet compare the model that you have from the actual parameter space to do the predictions.",
                    "label": 0
                },
                {
                    "sent": "Yes, so.",
                    "label": 0
                },
                {
                    "sent": "I guess that he does that in order to really learn this latent space formally, you need to have a will to learn.",
                    "label": 0
                },
                {
                    "sent": "Willing to have a large number of different tasks, yes, so do you have any OK so.",
                    "label": 0
                },
                {
                    "sent": "Mention about my second model in it, so if you don't have enough number it because in the first model if you go back to this.",
                    "label": 0
                },
                {
                    "sent": "So is this the first case?",
                    "label": 0
                },
                {
                    "sent": "It's officially work.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "He defeated the curve.",
                    "label": 0
                },
                {
                    "sent": "You don't have enough number of tasks.",
                    "label": 0
                },
                {
                    "sent": "Then you can actually automate your model with the input data also.",
                    "label": 0
                },
                {
                    "sent": "So in this case, this is this shared subspace exactly like ending is making up information from your inputs as well.",
                    "label": 0
                },
                {
                    "sent": "How many passed you, by the way?",
                    "label": 0
                },
                {
                    "sent": "These datasets have really small number of labels, likely elect 14 tasks, you know, so these are not really so you can actually.",
                    "label": 0
                },
                {
                    "sent": "I mean this is ongoing work, so you can actually if you have lots of tasks that you can leverage this information even more.",
                    "label": 0
                },
                {
                    "sent": "OK, let's speak for me.",
                    "label": 0
                }
            ]
        }
    }
}