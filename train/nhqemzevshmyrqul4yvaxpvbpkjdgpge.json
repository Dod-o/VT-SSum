{
    "id": "nhqemzevshmyrqul4yvaxpvbpkjdgpge",
    "title": "Learning Inadmissible Heuristics during Search",
    "info": {
        "author": [
            "Jordan T. Thayer, Department of Computer Science, University of New Hampshire"
        ],
        "published": "July 21, 2011",
        "recorded": "June 2011",
        "category": [
            "Top->Computer Science->Artificial Intelligence->Planning and Scheduling"
        ]
    },
    "url": "http://videolectures.net/icaps2011_thayer_inadmissible/",
    "segmentation": [
        [
            "I'm driving there from the University of New Hampshire.",
            "I'll be presenting work on learning heuristics during search that I did together with Austin Dion and our advisor Wheeler Romo."
        ],
        [
            "Here we see a gridworld navigation problem.",
            "The red S in the center of the left hand side is the starting position and the goal of this problem is to move from that red S to the red G in the center of the right hand."
        ],
        [
            "Side of the screen by traversing the white cells using moves in the Cardinal directions.",
            "The Black Cells Act as obstacles that we can't move through.",
            "So what's happening here?",
            "So what we see?"
        ],
        [
            "Here is the solution.",
            "The nodes expanded by greedy best first search and greedy best first search finds the solution that marches through this sort of ladder like structure to the goal.",
            "So the reason that it does that is unlike a star which combines both heuristic estimates and the cost of arriving at a node.",
            "Greedy best first search is totally focused on the heuristic alone.",
            "So what happens is it enters this heuristic depression and it says, oh, wow, all of these nodes are like one step closer to the goal.",
            "Then all of the nodes that I examined previously.",
            "It gets down here and it takes a step in the right direction.",
            "It says great, I'm on the right path.",
            "I'm still going towards where I want to go and it moves up and the heuristic keeps decreasing and decreasing.",
            "It gets to here it says I gotta make a step in the wrong direction, but that's fine.",
            "These nodes still look better than the other nodes that I considered earlier, and then it makes a step in the wrong direction again and again and again.",
            "So it's not noticing the fact that the heuristic is lying to it consistently.",
            "And the question is whether or not we can.",
            "We can we notice that the heuristic is often misleading?",
            "And can we take advantage of that?"
        ],
        [
            "The answer is yes.",
            "In fact, we can do that.",
            "So this is the same greedy best first search algorithm.",
            "But now when it expands and odane, the heuristic value doesn't behave the way we thought it should.",
            "It pays attention to that.",
            "An uses that to correct the heuristic going forward, so that's what we're going to.",
            "What I'm going to talk about for the next couple of minutes is how we can make observations of heuristic error during search to improve the heuristic online."
        ],
        [
            "So just to sort of finish up the motivation for the approach we want to do things in the most general manner we can, which means that we don't want to have to rely on offline training, and we don't want to have to rely on information that's specific to any particular domain.",
            "What we're going to try to do is only rely on the relationship between a parent and its child nodes, and the behavior of the heuristic in the search space and what we're going to do.",
            "Use that to do is to construct inadmissible heuristic estimates so heuristics which may not necessarily underestimate the cost to go.",
            "So unfortunately there are no longer necessarily appropriate for optimal search, but they work quite well in sub optimal searches we see."
        ],
        [
            "So the outline of the talk is as follows.",
            "I just covered the motivation.",
            "The next thing I'm going to talk about is how the technique actually works.",
            "Once I'm done describing the technique itself, then we'll talk a little bit about the performance of it in sub optimal search algorithms and also bounded sub optimal search algorithms.",
            "So algorithms that return solutions within some fixed factor of the optimal cost."
        ],
        [
            "So unreachable."
        ],
        [
            "Let's say that we have this very simple caricature of a search space here, right?",
            "So we have the parent node P. It has some child, has a couple of children, and there's a goal state down here and this child on the left is the best child.",
            "And what that means is that it is the child which is the next step on an optimal solution from the parent to a goal.",
            "If you'll notice that I've also labeled this arc here, so this arc is the action that takes us from the parent to the best child, and this label here is saying that the cost of this arc is so.",
            "The cost from going from the parent P to the best child BC.",
            "So there's some weight on that arc, so the technique works."
        ],
        [
            "By observing by paying attention to this fact so F of PF of a node is simply the estimate of what the cost of a solution passing through this node should be so.",
            "What we're saying here is that the F of the parent ought to be equal to the F of the best child since the best child is the next step on the optimal path, they should have the same value."
        ],
        [
            "If we had perfect heuristic values, they definitely would, so that's what we see here in this set of equations.",
            "So F star is just if we had perfect knowledge.",
            "This would be the cost of an optimal solution through node P. That would be equal to the cost of an optimal solution through its best child BC.",
            "Here we've just rewritten the equation so F of a node is Jeevan owed.",
            "The cost of arriving at it plus H. The cost of completion from there.",
            "An if we do a little more algebra, we can state the heuristic value of the parent in terms of the heuristic of the best child plus the cost of the arc.",
            "Now we never have perfect heuristics.",
            "If we did, we wouldn't need search."
        ],
        [
            "So when we get estimates, the equations change just slightly, so again we have the heuristic value of the parent, but now there's no star there, so it's just some estimate.",
            "And again, the heuristic value.",
            "The best child plus the cost of transition, but whenever they're not equal and frequently, they won't be.",
            "Then what's happened is we've observed some error in the single transition epsilon sub H. So we rewrite this equation again to say that the the error in a single transition epsilon said H is just the heuristic of the best child plus the cost of transition minus the heuristic of the parent.",
            "If the right thing happened, that will be 0 and every time it's not zero, then we've observed the air in the heuristic."
        ],
        [
            "So what we're going to do to construct a better heuristic is we're going to take the base heuristic H. Aven, and we're going to add to it the average single step error.",
            "So epsilon bar sub H times the estimated number of steps in our solution.",
            "So we think we'll have this much air in every step we think will take this many steps, and that's the new heuristic value.",
            "If you have a unit cost domain where all of the actions have the same cost, HN is equal to D event, which is just our estimate.",
            "The number of actions if you don't have a domain with unit cost actions, you can estimate the length pretty simply.",
            "You may already be computing most of the information you need.",
            "For example, if you're using the relax plan to compute your cost, then the number of actions in the relax plan is then your estimate of the length of that solution, so.",
            "To sort of quote the old saying what's sauce for the goose is also sauce for the gander.",
            "So not only do we correct the cost to go estimates with this kind of technique, we can also correct those distance estimates as well.",
            "In that case we don't have to pay attention to the cost of the arc because all art should be length one."
        ],
        [
            "So there are a couple of problems.",
            "You note that I switched from Epsilon sub H. The single step error to bar epsilon sub HD sort of average single step error, but I didn't tell you how to compute that.",
            "So there are a couple of ways to do that.",
            "First, and probably most obvious way is that we just keep a global average of all of the single step errors that we've ever observed, right?",
            "That works alright."
        ],
        [
            "But what we could do is we could pay attention to the single step error along a path through the search space.",
            "So let's imagine that we have this space right here the left.",
            "So it's a unit cost problem.",
            "The left child of a node is always the best child.",
            "The right child is some child.",
            "That's not necessarily the best one, right?",
            "So here at the route we have H of 10, the best child of the root has age of nine, and experienced no error because the heuristic decreased by one across that transition, which is exactly what we expected it would do.",
            "Now this node does experience some error because it's best child.",
            "Also has a heuristic value of nine.",
            "We thought that the heuristic value should drop by one because we made the transition, but the heuristic made a mistake and so it didn't.",
            "So what we're going to do is we're going to aggregate the single step errors along a path and then to get the single step estimate, we just divide by the depth of the node."
        ],
        [
            "So that's what we get here.",
            "So 4H.",
            "Nine experienced, no error at depth one.",
            "0 / 1 is 0 for this node down here.",
            "Experienced one error across two transitions.",
            "So 1 / 2 is 1/2.",
            "Now that leads us to.",
            "So what do we do with these two nodes?",
            "They aren't the best child really, so what's their error like?"
        ],
        [
            "Well, they are the best child, or at least they're the best child.",
            "When the search visits them.",
            "So when the search gets back to expanding these two states over here, what's happened is it's expanded the tree beneath the nodes it thought was best before and said, you know the heuristic was wrong and I was.",
            "I made a mistake.",
            "I didn't think you were very good, but now I do think you are the best child.",
            "So the problem that we had here with the global model, that of needing to estimate which node was best sort of, goes away when we use these path dependent corrections.",
            "So we rely on the search to tell us which note is best.",
            "And then we just calculate the one step errors before aggregated along the path and divide by depth."
        ],
        [
            "So that's very briefly, the way the heuristic corrections work.",
            "We rely on the fact that there should be the special relationship between apparent no Dan, it's children, specifically the parent and its best child should have the same F every time they don't.",
            "That's an error.",
            "An heuristic search.",
            "Unfortunately we do a lot of expansions, so every time you do an expansion you are learning something about the performance of your heuristics in the space, and that's information you should really be using.",
            "And the nice thing about this particular information is that it can be measured during the search itself and used during the same exact search.",
            "So that's very nice.",
            "Basically, what that lets us do is it lets us run a correction online and improve the performance of the search, while it's while it's still going."
        ],
        [
            "So that was the correction technique.",
            "Now I'm going to talk about the performance of these corrected heuristics in a couple of different."
        ],
        [
            "Which algorithms I'm going to start with discussing the performance of the algorithms in greedy best first search which is just a best per search on estimated costs to go.",
            "After I'm done talking about greedy best first search, I'll talk about the performance of the algorithms in a new search algorithm called Sceptical Search.",
            "It's abundance of optimal algorithm that can use inadmissable sources of heuristic guidance but still provide you with solutions that are within some fixed factor W of the optimal solution."
        ],
        [
            "So the first domain we're going to talk about is the venerable sliding tiles domain.",
            "It's the 15 puzzle.",
            "Here on the X axis we have the time needed to solve the problem on the Y axis we have the actual costs of the solutions Ann.",
            "The four different crosses that are on the plot represent four different heuristics in greedy best first search.",
            "So the first one up here, this red one is the Manhattan distance heuristic, which is a very standard heuristic for the sliding tiles problem.",
            "It's just the displacement of each tile summed for all the tiles.",
            "This Blue Cross down here is the performance of the online learning, specifically the path based single step corrections on top of the Manhattan distance heuristic.",
            "So what you're seeing is that there's this big gap here, which means that the corrections are producing solutions of a much higher quality, and there's also a small shift to the left, which means that the greedy search guide on the corrected heuristic is also solving problems a little bit faster.",
            "Now the Manhattan distance heuristic is, relatively speaking, quite a weak heuristic for the sliding tile puzzle, so we also consider pattern databases, which are very popular approach to that problem.",
            "So here in green we have the 78 pattern database.",
            "If you don't know what that is, it doesn't particularly matter, it's just really really powerful and you can see that the single step corrections on top of the Manhattan distance are substantially faster than the pattern database which took us, you know.",
            "Several hours to compute and produce solutions on about the same, about the same cost or quality.",
            "But of course we can add these.",
            "We can add the single step correction to the pattern database as well, which is the Gray which is the grey cross down here so you can see that the corrected the corrections work even for very well informed heuristics, and we still get speedup, and we still get improvements in terms of solution quality now."
        ],
        [
            "It isn't only the case in the sliding tile puzzle.",
            "It also happens in other domains.",
            "Here we see Gridworld navigation, so just like the first problem, but instead of a structured set of obstacles here we have random obstacle distribution of about 35% of the cells being blocked.",
            "There's a problems get quite hard around there, or not quite hard, but it becomes difficult to solve anything after 35% of obstacles.",
            "So and again, we have the base heuristics, sort of the Manhattan distance heuristic down here time again on the X axis instead of solution cost on the Y axis.",
            "Now we have the IPC satisficing quality metrics, so the cost of the best solution divided by the cost of the solution returned by the algorithm and you can see that perhaps you can't because the green is a little light.",
            "But here is the base heuristic with learning producing better solutions in shorter amounts of time.",
            "And here is the base heuristic alone.",
            "Producing substantially worse solutions in longer amounts of time."
        ],
        [
            "Um?",
            "Here is another variant of the sliding tiles puzzle.",
            "It differs from the original problem in that moves now have interesting cost, so in the original sliding tile puzzle, moving any of the tiles is exactly the same cost.",
            "But in this variant the cost of moving a tile is one over the face value of that tile, so New Hampshire is the Granite State, so we like to imagine that we have a sliding tile puzzle made out of granite, and the act of chiseling out the numbers has reduced the weight of the tiles, so different tiles have different weights.",
            "Cost different amounts to move and you could see here again.",
            "Here's the base heuristic for that problem in greedy best.",
            "First search it takes, you know, over 100 seconds more or less to solve the problem and produces solutions of very low quality compared to just adding these single step corrections on top of the heuristic, not even changing the search algorithm where we find solutions of very high quality in I think about two orders of magnitude less time, so that's a huge huge speedup."
        ],
        [
            "So those were the results for greedy best first search where you don't have to prove anything about the quality of the solution while you're doing this solving.",
            "So now we're going to look at boundaries of optimal search, an wonder about it.",
            "Can we get the same kinds of improvements in terms of time if we have to show that the solutions we return are within some fixed quality boundary?"
        ],
        [
            "So just to remind everyone who doesn't think about bounded, suboptimal search all the time, the real goal of bounded, suboptimal searches the user gives you some suboptimality bounds W, let's call it and within W you want to find a.",
            "So you want to find a solution with a cost within a bounded factor W of optimal as quickly as you possibly can.",
            "So the way we're going to do this here, we're going to.",
            "We're going to do this with a skeptical search algorithm.",
            "And the."
        ],
        [
            "Way the sceptical search algorithm is works is it relies on the optimistic framework that we introduced a couple of years ago in Sydney.",
            "So basically what we're going to do is we're going to run, waited a star, but we're going to run it with this.",
            "Thanks.",
            "We're going to run it with this inadmissible heuristic that we're learning.",
            "So G of N + W * H hat called, that's the correct touristic event.",
            "So now we have we no longer have those nice guarantees that way.",
            "Today Star provided us with that.",
            "All solutions returned are within a bounded factor W optimal, so when we get a solution with this search, we're going to have to do a little more work.",
            "We're going to have to expand some nodes.",
            "In the order that a star would have expanded them actually, and what that's going to do is it's going to so they know that a star would expand to anytime we call him best F. He's the node with the smallest value among all other nodes.",
            "And what that does is it also acts as a lower bound on the cost of an optimal solution.",
            "So by expanding him we raise that value and we can raise that value up to the point where we find that the solution we found at first that we didn't know was bounded.",
            "Now we do know it's bounded, so there's some slightly complicated things that can happen when the initial search fails to find something within the bound, but.",
            "You'll have to read the paper to figure out how that works.",
            "The nice thing about skeptical search when compared to optimistic search is that it doesn't have this ad hoc optimism parameter.",
            "That optimistic search had, so you don't have to do any tuning before you run the thing, you just give it the bound, and then you find solutions with."
        ],
        [
            "The band.",
            "Of course, removing the parameter isn't the only nice thing.",
            "We also get remarkable speedups, so this shows the performance of three bounded sub optimal search algorithms.",
            "Again on these inverse tiles puzzles from before on the X axis.",
            "Now we have the suboptimality bounds, so the guaranteed solution quality and on the Y axis we have the CPU time required to solve the problem on a log scale you can see that as the bound is loose and waited, a star and optimistic search do not do particularly well.",
            "In fact, they get slightly worse for various reasons.",
            "And as the bound is relaxed for first sceptical search, we go much faster.",
            "In fact, over 2 orders of magnitude, when you get to large relaxations and mind you that it's actually using the same basic cost heuristic as these other two algorithms.",
            "So the only sort of special sauce we have here is that learning."
        ],
        [
            "It's not just the tiles puzzle that it works on.",
            "Fortunately it also works on this dockyard robot domain, which is the running example from the planning textbook, again on the X axis suboptimality bound on the Y axis, CPU time on a log scale.",
            "The Green Line is sceptical.",
            "Search.",
            "The blue line is optimistic, the red line is standard, waited a star and you can see that there's quite a large performance gap between the algorithms an as that bound is relaxed, the gap widens, and in fact again in this domain, as the bound is loose and eventually waited, a certain optimistic search begin to perform poorly.",
            "And sceptical search does not have."
        ],
        [
            "Problem.",
            "We also have another domain.",
            "We're quite fond of the vacuum problem, so you have a little Roomba.",
            "He wants to go around the room and suck up some dirt, but every time he picks up dirt, thank you, he gets heavier.",
            "And you can see again we have huge speedups here.",
            "As the bound, as the boundless."
        ],
        [
            "So there are a couple of things that are in the paper that I don't have time to cover in any detail in the talk, but that you should be aware of.",
            "Nonetheless.",
            "The first is that we find accuracy is, generally speaking, less important than the relative ordering of the nodes, so the corrections we learn are not necessarily great in terms of comparison to H star, but in terms of ranking the nodes, they work quite well, which is how we're getting all of these speedups.",
            "The learning that's happening on a per instance basis is very beneficial, so we're actually getting some improvement versus trying to learn a general concept similar to this on a set of instances.",
            "The distance estimates that we use are very helpful.",
            "You could manipulate this technique to work just in terms of cost deltas, but you want the distance estimates that improves performance.",
            "And I'm not going to talk about it, but sceptical does actually provide solutions within the quality bound."
        ],
        [
            "So, just to summarize, we can learn in admissible heuristics and these these learn heuristics tend to improve search guidance, which makes our algorithms go quite fast.",
            "The nice thing is that we can learn them online during search, so we don't have to depend on domain specific information.",
            "We don't have to depend on offline training, although both of these things might be able to improve the performance of the technique and we can learn instance specific corrections, which is hard to do with other approaches to learning heuristics.",
            "And then we also introduced this new algorithm called Sceptical Search, which removes a parameter from optimistic search and you can use it to search on inadmissible heuristics while still maintaining bounded suboptimality.",
            "So I'll take any questions you have now."
        ],
        [
            "So.",
            "So the heuristic error you learn.",
            "You don't use the absolute error, right?",
            "The absolute value of the error, no.",
            "Now we learn it directionally.",
            "So this correction technique will work with both admissible and inadmissible things.",
            "So if you're always overestimate, also look learn to reduce your values, yes, so The thing is, if you Ristic errors on both sides, you might get an average error of zero.",
            "Yes, that's true.",
            "So you might want to try to use a classifier, for example, OK. Yeah.",
            "OK, OK.",
            "I, if I understand correctly, so the algorithm basic computer is a epsilons, that is what people sometimes call Bellman residuals.",
            "OK, they're very related or people using dynamic programming, so is it and you take like a sort of an average residual.",
            "So two quick questions, one sort of about the mechanics of the algorithms.",
            "So every time that you do an expansion, so the evaluation function of all the notes in open changes, not with the path based corrections, which is the other nice thing about it.",
            "So for the path based corrections.",
            "All of the evaluation functions remain the same from the time the node was generated, if it's regenerated by another path and they do change, but then you've regenerated by another path anyway.",
            "If you use the global error model, that is a problem in practice, in the evaluation paper we ignore that problem, and that may be part of the explanation for his poor performance.",
            "OK, and the second question is why these average errors so give assiduous why?",
            "Any idea why they work?",
            "I mean, I mean from the point of view of of.",
            "Typical dynamic programming analysis that seems a bit weird, right?",
            "Well, I mean so at least conceptually, the idea is very straightforward, right?",
            "We observe a certain amount of error in every step, and then we say, OK, we have how many steps to go.",
            "So we're going to observe this error throughout the rest of the search and then add it back in.",
            "You generalize it of it all day.",
            "Other notes that you have not seen.",
            "That is true, so very specific type of generalization is very strong, yeah?",
            "So I. I don't have any particular insights as to why it works so well, but it does appear to work on a wide variety of domains and quite well.",
            "Great.",
            "And so actually that will be my question.",
            "So what happens with the other domains?",
            "So if the answer is in the paper, just tell me yes.",
            "So we are able to characterize the kinds of domains that it finds problematic.",
            "Specifically where there is very high in one part of the domain and then simplify the question.",
            "So have you run the experiment on a bunch of, you know, by cops benchmarks.",
            "So I'm getting ready to do that in the very near future.",
            "So not yet but soon."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I'm driving there from the University of New Hampshire.",
                    "label": 0
                },
                {
                    "sent": "I'll be presenting work on learning heuristics during search that I did together with Austin Dion and our advisor Wheeler Romo.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here we see a gridworld navigation problem.",
                    "label": 0
                },
                {
                    "sent": "The red S in the center of the left hand side is the starting position and the goal of this problem is to move from that red S to the red G in the center of the right hand.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Side of the screen by traversing the white cells using moves in the Cardinal directions.",
                    "label": 0
                },
                {
                    "sent": "The Black Cells Act as obstacles that we can't move through.",
                    "label": 0
                },
                {
                    "sent": "So what's happening here?",
                    "label": 0
                },
                {
                    "sent": "So what we see?",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here is the solution.",
                    "label": 0
                },
                {
                    "sent": "The nodes expanded by greedy best first search and greedy best first search finds the solution that marches through this sort of ladder like structure to the goal.",
                    "label": 0
                },
                {
                    "sent": "So the reason that it does that is unlike a star which combines both heuristic estimates and the cost of arriving at a node.",
                    "label": 0
                },
                {
                    "sent": "Greedy best first search is totally focused on the heuristic alone.",
                    "label": 0
                },
                {
                    "sent": "So what happens is it enters this heuristic depression and it says, oh, wow, all of these nodes are like one step closer to the goal.",
                    "label": 0
                },
                {
                    "sent": "Then all of the nodes that I examined previously.",
                    "label": 0
                },
                {
                    "sent": "It gets down here and it takes a step in the right direction.",
                    "label": 0
                },
                {
                    "sent": "It says great, I'm on the right path.",
                    "label": 0
                },
                {
                    "sent": "I'm still going towards where I want to go and it moves up and the heuristic keeps decreasing and decreasing.",
                    "label": 0
                },
                {
                    "sent": "It gets to here it says I gotta make a step in the wrong direction, but that's fine.",
                    "label": 0
                },
                {
                    "sent": "These nodes still look better than the other nodes that I considered earlier, and then it makes a step in the wrong direction again and again and again.",
                    "label": 0
                },
                {
                    "sent": "So it's not noticing the fact that the heuristic is lying to it consistently.",
                    "label": 0
                },
                {
                    "sent": "And the question is whether or not we can.",
                    "label": 0
                },
                {
                    "sent": "We can we notice that the heuristic is often misleading?",
                    "label": 0
                },
                {
                    "sent": "And can we take advantage of that?",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The answer is yes.",
                    "label": 0
                },
                {
                    "sent": "In fact, we can do that.",
                    "label": 0
                },
                {
                    "sent": "So this is the same greedy best first search algorithm.",
                    "label": 0
                },
                {
                    "sent": "But now when it expands and odane, the heuristic value doesn't behave the way we thought it should.",
                    "label": 0
                },
                {
                    "sent": "It pays attention to that.",
                    "label": 0
                },
                {
                    "sent": "An uses that to correct the heuristic going forward, so that's what we're going to.",
                    "label": 0
                },
                {
                    "sent": "What I'm going to talk about for the next couple of minutes is how we can make observations of heuristic error during search to improve the heuristic online.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So just to sort of finish up the motivation for the approach we want to do things in the most general manner we can, which means that we don't want to have to rely on offline training, and we don't want to have to rely on information that's specific to any particular domain.",
                    "label": 1
                },
                {
                    "sent": "What we're going to try to do is only rely on the relationship between a parent and its child nodes, and the behavior of the heuristic in the search space and what we're going to do.",
                    "label": 0
                },
                {
                    "sent": "Use that to do is to construct inadmissible heuristic estimates so heuristics which may not necessarily underestimate the cost to go.",
                    "label": 0
                },
                {
                    "sent": "So unfortunately there are no longer necessarily appropriate for optimal search, but they work quite well in sub optimal searches we see.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the outline of the talk is as follows.",
                    "label": 0
                },
                {
                    "sent": "I just covered the motivation.",
                    "label": 0
                },
                {
                    "sent": "The next thing I'm going to talk about is how the technique actually works.",
                    "label": 0
                },
                {
                    "sent": "Once I'm done describing the technique itself, then we'll talk a little bit about the performance of it in sub optimal search algorithms and also bounded sub optimal search algorithms.",
                    "label": 0
                },
                {
                    "sent": "So algorithms that return solutions within some fixed factor of the optimal cost.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So unreachable.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Let's say that we have this very simple caricature of a search space here, right?",
                    "label": 0
                },
                {
                    "sent": "So we have the parent node P. It has some child, has a couple of children, and there's a goal state down here and this child on the left is the best child.",
                    "label": 0
                },
                {
                    "sent": "And what that means is that it is the child which is the next step on an optimal solution from the parent to a goal.",
                    "label": 0
                },
                {
                    "sent": "If you'll notice that I've also labeled this arc here, so this arc is the action that takes us from the parent to the best child, and this label here is saying that the cost of this arc is so.",
                    "label": 0
                },
                {
                    "sent": "The cost from going from the parent P to the best child BC.",
                    "label": 0
                },
                {
                    "sent": "So there's some weight on that arc, so the technique works.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "By observing by paying attention to this fact so F of PF of a node is simply the estimate of what the cost of a solution passing through this node should be so.",
                    "label": 0
                },
                {
                    "sent": "What we're saying here is that the F of the parent ought to be equal to the F of the best child since the best child is the next step on the optimal path, they should have the same value.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "If we had perfect heuristic values, they definitely would, so that's what we see here in this set of equations.",
                    "label": 0
                },
                {
                    "sent": "So F star is just if we had perfect knowledge.",
                    "label": 0
                },
                {
                    "sent": "This would be the cost of an optimal solution through node P. That would be equal to the cost of an optimal solution through its best child BC.",
                    "label": 0
                },
                {
                    "sent": "Here we've just rewritten the equation so F of a node is Jeevan owed.",
                    "label": 0
                },
                {
                    "sent": "The cost of arriving at it plus H. The cost of completion from there.",
                    "label": 0
                },
                {
                    "sent": "An if we do a little more algebra, we can state the heuristic value of the parent in terms of the heuristic of the best child plus the cost of the arc.",
                    "label": 0
                },
                {
                    "sent": "Now we never have perfect heuristics.",
                    "label": 0
                },
                {
                    "sent": "If we did, we wouldn't need search.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So when we get estimates, the equations change just slightly, so again we have the heuristic value of the parent, but now there's no star there, so it's just some estimate.",
                    "label": 0
                },
                {
                    "sent": "And again, the heuristic value.",
                    "label": 0
                },
                {
                    "sent": "The best child plus the cost of transition, but whenever they're not equal and frequently, they won't be.",
                    "label": 0
                },
                {
                    "sent": "Then what's happened is we've observed some error in the single transition epsilon sub H. So we rewrite this equation again to say that the the error in a single transition epsilon said H is just the heuristic of the best child plus the cost of transition minus the heuristic of the parent.",
                    "label": 0
                },
                {
                    "sent": "If the right thing happened, that will be 0 and every time it's not zero, then we've observed the air in the heuristic.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So what we're going to do to construct a better heuristic is we're going to take the base heuristic H. Aven, and we're going to add to it the average single step error.",
                    "label": 0
                },
                {
                    "sent": "So epsilon bar sub H times the estimated number of steps in our solution.",
                    "label": 0
                },
                {
                    "sent": "So we think we'll have this much air in every step we think will take this many steps, and that's the new heuristic value.",
                    "label": 0
                },
                {
                    "sent": "If you have a unit cost domain where all of the actions have the same cost, HN is equal to D event, which is just our estimate.",
                    "label": 0
                },
                {
                    "sent": "The number of actions if you don't have a domain with unit cost actions, you can estimate the length pretty simply.",
                    "label": 0
                },
                {
                    "sent": "You may already be computing most of the information you need.",
                    "label": 0
                },
                {
                    "sent": "For example, if you're using the relax plan to compute your cost, then the number of actions in the relax plan is then your estimate of the length of that solution, so.",
                    "label": 0
                },
                {
                    "sent": "To sort of quote the old saying what's sauce for the goose is also sauce for the gander.",
                    "label": 0
                },
                {
                    "sent": "So not only do we correct the cost to go estimates with this kind of technique, we can also correct those distance estimates as well.",
                    "label": 0
                },
                {
                    "sent": "In that case we don't have to pay attention to the cost of the arc because all art should be length one.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So there are a couple of problems.",
                    "label": 0
                },
                {
                    "sent": "You note that I switched from Epsilon sub H. The single step error to bar epsilon sub HD sort of average single step error, but I didn't tell you how to compute that.",
                    "label": 0
                },
                {
                    "sent": "So there are a couple of ways to do that.",
                    "label": 0
                },
                {
                    "sent": "First, and probably most obvious way is that we just keep a global average of all of the single step errors that we've ever observed, right?",
                    "label": 0
                },
                {
                    "sent": "That works alright.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But what we could do is we could pay attention to the single step error along a path through the search space.",
                    "label": 0
                },
                {
                    "sent": "So let's imagine that we have this space right here the left.",
                    "label": 0
                },
                {
                    "sent": "So it's a unit cost problem.",
                    "label": 0
                },
                {
                    "sent": "The left child of a node is always the best child.",
                    "label": 0
                },
                {
                    "sent": "The right child is some child.",
                    "label": 0
                },
                {
                    "sent": "That's not necessarily the best one, right?",
                    "label": 0
                },
                {
                    "sent": "So here at the route we have H of 10, the best child of the root has age of nine, and experienced no error because the heuristic decreased by one across that transition, which is exactly what we expected it would do.",
                    "label": 0
                },
                {
                    "sent": "Now this node does experience some error because it's best child.",
                    "label": 0
                },
                {
                    "sent": "Also has a heuristic value of nine.",
                    "label": 0
                },
                {
                    "sent": "We thought that the heuristic value should drop by one because we made the transition, but the heuristic made a mistake and so it didn't.",
                    "label": 0
                },
                {
                    "sent": "So what we're going to do is we're going to aggregate the single step errors along a path and then to get the single step estimate, we just divide by the depth of the node.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So that's what we get here.",
                    "label": 0
                },
                {
                    "sent": "So 4H.",
                    "label": 0
                },
                {
                    "sent": "Nine experienced, no error at depth one.",
                    "label": 0
                },
                {
                    "sent": "0 / 1 is 0 for this node down here.",
                    "label": 0
                },
                {
                    "sent": "Experienced one error across two transitions.",
                    "label": 0
                },
                {
                    "sent": "So 1 / 2 is 1/2.",
                    "label": 0
                },
                {
                    "sent": "Now that leads us to.",
                    "label": 0
                },
                {
                    "sent": "So what do we do with these two nodes?",
                    "label": 0
                },
                {
                    "sent": "They aren't the best child really, so what's their error like?",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Well, they are the best child, or at least they're the best child.",
                    "label": 0
                },
                {
                    "sent": "When the search visits them.",
                    "label": 0
                },
                {
                    "sent": "So when the search gets back to expanding these two states over here, what's happened is it's expanded the tree beneath the nodes it thought was best before and said, you know the heuristic was wrong and I was.",
                    "label": 0
                },
                {
                    "sent": "I made a mistake.",
                    "label": 0
                },
                {
                    "sent": "I didn't think you were very good, but now I do think you are the best child.",
                    "label": 0
                },
                {
                    "sent": "So the problem that we had here with the global model, that of needing to estimate which node was best sort of, goes away when we use these path dependent corrections.",
                    "label": 0
                },
                {
                    "sent": "So we rely on the search to tell us which note is best.",
                    "label": 0
                },
                {
                    "sent": "And then we just calculate the one step errors before aggregated along the path and divide by depth.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So that's very briefly, the way the heuristic corrections work.",
                    "label": 0
                },
                {
                    "sent": "We rely on the fact that there should be the special relationship between apparent no Dan, it's children, specifically the parent and its best child should have the same F every time they don't.",
                    "label": 0
                },
                {
                    "sent": "That's an error.",
                    "label": 0
                },
                {
                    "sent": "An heuristic search.",
                    "label": 0
                },
                {
                    "sent": "Unfortunately we do a lot of expansions, so every time you do an expansion you are learning something about the performance of your heuristics in the space, and that's information you should really be using.",
                    "label": 0
                },
                {
                    "sent": "And the nice thing about this particular information is that it can be measured during the search itself and used during the same exact search.",
                    "label": 0
                },
                {
                    "sent": "So that's very nice.",
                    "label": 0
                },
                {
                    "sent": "Basically, what that lets us do is it lets us run a correction online and improve the performance of the search, while it's while it's still going.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So that was the correction technique.",
                    "label": 0
                },
                {
                    "sent": "Now I'm going to talk about the performance of these corrected heuristics in a couple of different.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Which algorithms I'm going to start with discussing the performance of the algorithms in greedy best first search which is just a best per search on estimated costs to go.",
                    "label": 0
                },
                {
                    "sent": "After I'm done talking about greedy best first search, I'll talk about the performance of the algorithms in a new search algorithm called Sceptical Search.",
                    "label": 0
                },
                {
                    "sent": "It's abundance of optimal algorithm that can use inadmissable sources of heuristic guidance but still provide you with solutions that are within some fixed factor W of the optimal solution.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the first domain we're going to talk about is the venerable sliding tiles domain.",
                    "label": 0
                },
                {
                    "sent": "It's the 15 puzzle.",
                    "label": 0
                },
                {
                    "sent": "Here on the X axis we have the time needed to solve the problem on the Y axis we have the actual costs of the solutions Ann.",
                    "label": 0
                },
                {
                    "sent": "The four different crosses that are on the plot represent four different heuristics in greedy best first search.",
                    "label": 1
                },
                {
                    "sent": "So the first one up here, this red one is the Manhattan distance heuristic, which is a very standard heuristic for the sliding tiles problem.",
                    "label": 0
                },
                {
                    "sent": "It's just the displacement of each tile summed for all the tiles.",
                    "label": 1
                },
                {
                    "sent": "This Blue Cross down here is the performance of the online learning, specifically the path based single step corrections on top of the Manhattan distance heuristic.",
                    "label": 0
                },
                {
                    "sent": "So what you're seeing is that there's this big gap here, which means that the corrections are producing solutions of a much higher quality, and there's also a small shift to the left, which means that the greedy search guide on the corrected heuristic is also solving problems a little bit faster.",
                    "label": 0
                },
                {
                    "sent": "Now the Manhattan distance heuristic is, relatively speaking, quite a weak heuristic for the sliding tile puzzle, so we also consider pattern databases, which are very popular approach to that problem.",
                    "label": 0
                },
                {
                    "sent": "So here in green we have the 78 pattern database.",
                    "label": 0
                },
                {
                    "sent": "If you don't know what that is, it doesn't particularly matter, it's just really really powerful and you can see that the single step corrections on top of the Manhattan distance are substantially faster than the pattern database which took us, you know.",
                    "label": 0
                },
                {
                    "sent": "Several hours to compute and produce solutions on about the same, about the same cost or quality.",
                    "label": 0
                },
                {
                    "sent": "But of course we can add these.",
                    "label": 0
                },
                {
                    "sent": "We can add the single step correction to the pattern database as well, which is the Gray which is the grey cross down here so you can see that the corrected the corrections work even for very well informed heuristics, and we still get speedup, and we still get improvements in terms of solution quality now.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It isn't only the case in the sliding tile puzzle.",
                    "label": 0
                },
                {
                    "sent": "It also happens in other domains.",
                    "label": 0
                },
                {
                    "sent": "Here we see Gridworld navigation, so just like the first problem, but instead of a structured set of obstacles here we have random obstacle distribution of about 35% of the cells being blocked.",
                    "label": 0
                },
                {
                    "sent": "There's a problems get quite hard around there, or not quite hard, but it becomes difficult to solve anything after 35% of obstacles.",
                    "label": 0
                },
                {
                    "sent": "So and again, we have the base heuristics, sort of the Manhattan distance heuristic down here time again on the X axis instead of solution cost on the Y axis.",
                    "label": 0
                },
                {
                    "sent": "Now we have the IPC satisficing quality metrics, so the cost of the best solution divided by the cost of the solution returned by the algorithm and you can see that perhaps you can't because the green is a little light.",
                    "label": 0
                },
                {
                    "sent": "But here is the base heuristic with learning producing better solutions in shorter amounts of time.",
                    "label": 0
                },
                {
                    "sent": "And here is the base heuristic alone.",
                    "label": 0
                },
                {
                    "sent": "Producing substantially worse solutions in longer amounts of time.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Here is another variant of the sliding tiles puzzle.",
                    "label": 0
                },
                {
                    "sent": "It differs from the original problem in that moves now have interesting cost, so in the original sliding tile puzzle, moving any of the tiles is exactly the same cost.",
                    "label": 0
                },
                {
                    "sent": "But in this variant the cost of moving a tile is one over the face value of that tile, so New Hampshire is the Granite State, so we like to imagine that we have a sliding tile puzzle made out of granite, and the act of chiseling out the numbers has reduced the weight of the tiles, so different tiles have different weights.",
                    "label": 0
                },
                {
                    "sent": "Cost different amounts to move and you could see here again.",
                    "label": 0
                },
                {
                    "sent": "Here's the base heuristic for that problem in greedy best.",
                    "label": 1
                },
                {
                    "sent": "First search it takes, you know, over 100 seconds more or less to solve the problem and produces solutions of very low quality compared to just adding these single step corrections on top of the heuristic, not even changing the search algorithm where we find solutions of very high quality in I think about two orders of magnitude less time, so that's a huge huge speedup.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So those were the results for greedy best first search where you don't have to prove anything about the quality of the solution while you're doing this solving.",
                    "label": 0
                },
                {
                    "sent": "So now we're going to look at boundaries of optimal search, an wonder about it.",
                    "label": 0
                },
                {
                    "sent": "Can we get the same kinds of improvements in terms of time if we have to show that the solutions we return are within some fixed quality boundary?",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So just to remind everyone who doesn't think about bounded, suboptimal search all the time, the real goal of bounded, suboptimal searches the user gives you some suboptimality bounds W, let's call it and within W you want to find a.",
                    "label": 0
                },
                {
                    "sent": "So you want to find a solution with a cost within a bounded factor W of optimal as quickly as you possibly can.",
                    "label": 1
                },
                {
                    "sent": "So the way we're going to do this here, we're going to.",
                    "label": 1
                },
                {
                    "sent": "We're going to do this with a skeptical search algorithm.",
                    "label": 0
                },
                {
                    "sent": "And the.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Way the sceptical search algorithm is works is it relies on the optimistic framework that we introduced a couple of years ago in Sydney.",
                    "label": 0
                },
                {
                    "sent": "So basically what we're going to do is we're going to run, waited a star, but we're going to run it with this.",
                    "label": 0
                },
                {
                    "sent": "Thanks.",
                    "label": 0
                },
                {
                    "sent": "We're going to run it with this inadmissible heuristic that we're learning.",
                    "label": 1
                },
                {
                    "sent": "So G of N + W * H hat called, that's the correct touristic event.",
                    "label": 0
                },
                {
                    "sent": "So now we have we no longer have those nice guarantees that way.",
                    "label": 0
                },
                {
                    "sent": "Today Star provided us with that.",
                    "label": 0
                },
                {
                    "sent": "All solutions returned are within a bounded factor W optimal, so when we get a solution with this search, we're going to have to do a little more work.",
                    "label": 0
                },
                {
                    "sent": "We're going to have to expand some nodes.",
                    "label": 0
                },
                {
                    "sent": "In the order that a star would have expanded them actually, and what that's going to do is it's going to so they know that a star would expand to anytime we call him best F. He's the node with the smallest value among all other nodes.",
                    "label": 0
                },
                {
                    "sent": "And what that does is it also acts as a lower bound on the cost of an optimal solution.",
                    "label": 0
                },
                {
                    "sent": "So by expanding him we raise that value and we can raise that value up to the point where we find that the solution we found at first that we didn't know was bounded.",
                    "label": 0
                },
                {
                    "sent": "Now we do know it's bounded, so there's some slightly complicated things that can happen when the initial search fails to find something within the bound, but.",
                    "label": 1
                },
                {
                    "sent": "You'll have to read the paper to figure out how that works.",
                    "label": 0
                },
                {
                    "sent": "The nice thing about skeptical search when compared to optimistic search is that it doesn't have this ad hoc optimism parameter.",
                    "label": 1
                },
                {
                    "sent": "That optimistic search had, so you don't have to do any tuning before you run the thing, you just give it the bound, and then you find solutions with.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The band.",
                    "label": 0
                },
                {
                    "sent": "Of course, removing the parameter isn't the only nice thing.",
                    "label": 0
                },
                {
                    "sent": "We also get remarkable speedups, so this shows the performance of three bounded sub optimal search algorithms.",
                    "label": 0
                },
                {
                    "sent": "Again on these inverse tiles puzzles from before on the X axis.",
                    "label": 0
                },
                {
                    "sent": "Now we have the suboptimality bounds, so the guaranteed solution quality and on the Y axis we have the CPU time required to solve the problem on a log scale you can see that as the bound is loose and waited, a star and optimistic search do not do particularly well.",
                    "label": 0
                },
                {
                    "sent": "In fact, they get slightly worse for various reasons.",
                    "label": 0
                },
                {
                    "sent": "And as the bound is relaxed for first sceptical search, we go much faster.",
                    "label": 0
                },
                {
                    "sent": "In fact, over 2 orders of magnitude, when you get to large relaxations and mind you that it's actually using the same basic cost heuristic as these other two algorithms.",
                    "label": 0
                },
                {
                    "sent": "So the only sort of special sauce we have here is that learning.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It's not just the tiles puzzle that it works on.",
                    "label": 0
                },
                {
                    "sent": "Fortunately it also works on this dockyard robot domain, which is the running example from the planning textbook, again on the X axis suboptimality bound on the Y axis, CPU time on a log scale.",
                    "label": 0
                },
                {
                    "sent": "The Green Line is sceptical.",
                    "label": 0
                },
                {
                    "sent": "Search.",
                    "label": 0
                },
                {
                    "sent": "The blue line is optimistic, the red line is standard, waited a star and you can see that there's quite a large performance gap between the algorithms an as that bound is relaxed, the gap widens, and in fact again in this domain, as the bound is loose and eventually waited, a certain optimistic search begin to perform poorly.",
                    "label": 0
                },
                {
                    "sent": "And sceptical search does not have.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Problem.",
                    "label": 0
                },
                {
                    "sent": "We also have another domain.",
                    "label": 0
                },
                {
                    "sent": "We're quite fond of the vacuum problem, so you have a little Roomba.",
                    "label": 0
                },
                {
                    "sent": "He wants to go around the room and suck up some dirt, but every time he picks up dirt, thank you, he gets heavier.",
                    "label": 0
                },
                {
                    "sent": "And you can see again we have huge speedups here.",
                    "label": 0
                },
                {
                    "sent": "As the bound, as the boundless.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So there are a couple of things that are in the paper that I don't have time to cover in any detail in the talk, but that you should be aware of.",
                    "label": 1
                },
                {
                    "sent": "Nonetheless.",
                    "label": 0
                },
                {
                    "sent": "The first is that we find accuracy is, generally speaking, less important than the relative ordering of the nodes, so the corrections we learn are not necessarily great in terms of comparison to H star, but in terms of ranking the nodes, they work quite well, which is how we're getting all of these speedups.",
                    "label": 0
                },
                {
                    "sent": "The learning that's happening on a per instance basis is very beneficial, so we're actually getting some improvement versus trying to learn a general concept similar to this on a set of instances.",
                    "label": 1
                },
                {
                    "sent": "The distance estimates that we use are very helpful.",
                    "label": 0
                },
                {
                    "sent": "You could manipulate this technique to work just in terms of cost deltas, but you want the distance estimates that improves performance.",
                    "label": 0
                },
                {
                    "sent": "And I'm not going to talk about it, but sceptical does actually provide solutions within the quality bound.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So, just to summarize, we can learn in admissible heuristics and these these learn heuristics tend to improve search guidance, which makes our algorithms go quite fast.",
                    "label": 0
                },
                {
                    "sent": "The nice thing is that we can learn them online during search, so we don't have to depend on domain specific information.",
                    "label": 1
                },
                {
                    "sent": "We don't have to depend on offline training, although both of these things might be able to improve the performance of the technique and we can learn instance specific corrections, which is hard to do with other approaches to learning heuristics.",
                    "label": 0
                },
                {
                    "sent": "And then we also introduced this new algorithm called Sceptical Search, which removes a parameter from optimistic search and you can use it to search on inadmissible heuristics while still maintaining bounded suboptimality.",
                    "label": 0
                },
                {
                    "sent": "So I'll take any questions you have now.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "So the heuristic error you learn.",
                    "label": 0
                },
                {
                    "sent": "You don't use the absolute error, right?",
                    "label": 0
                },
                {
                    "sent": "The absolute value of the error, no.",
                    "label": 0
                },
                {
                    "sent": "Now we learn it directionally.",
                    "label": 0
                },
                {
                    "sent": "So this correction technique will work with both admissible and inadmissible things.",
                    "label": 0
                },
                {
                    "sent": "So if you're always overestimate, also look learn to reduce your values, yes, so The thing is, if you Ristic errors on both sides, you might get an average error of zero.",
                    "label": 0
                },
                {
                    "sent": "Yes, that's true.",
                    "label": 0
                },
                {
                    "sent": "So you might want to try to use a classifier, for example, OK. Yeah.",
                    "label": 0
                },
                {
                    "sent": "OK, OK.",
                    "label": 0
                },
                {
                    "sent": "I, if I understand correctly, so the algorithm basic computer is a epsilons, that is what people sometimes call Bellman residuals.",
                    "label": 0
                },
                {
                    "sent": "OK, they're very related or people using dynamic programming, so is it and you take like a sort of an average residual.",
                    "label": 0
                },
                {
                    "sent": "So two quick questions, one sort of about the mechanics of the algorithms.",
                    "label": 0
                },
                {
                    "sent": "So every time that you do an expansion, so the evaluation function of all the notes in open changes, not with the path based corrections, which is the other nice thing about it.",
                    "label": 0
                },
                {
                    "sent": "So for the path based corrections.",
                    "label": 0
                },
                {
                    "sent": "All of the evaluation functions remain the same from the time the node was generated, if it's regenerated by another path and they do change, but then you've regenerated by another path anyway.",
                    "label": 0
                },
                {
                    "sent": "If you use the global error model, that is a problem in practice, in the evaluation paper we ignore that problem, and that may be part of the explanation for his poor performance.",
                    "label": 0
                },
                {
                    "sent": "OK, and the second question is why these average errors so give assiduous why?",
                    "label": 0
                },
                {
                    "sent": "Any idea why they work?",
                    "label": 0
                },
                {
                    "sent": "I mean, I mean from the point of view of of.",
                    "label": 0
                },
                {
                    "sent": "Typical dynamic programming analysis that seems a bit weird, right?",
                    "label": 0
                },
                {
                    "sent": "Well, I mean so at least conceptually, the idea is very straightforward, right?",
                    "label": 0
                },
                {
                    "sent": "We observe a certain amount of error in every step, and then we say, OK, we have how many steps to go.",
                    "label": 0
                },
                {
                    "sent": "So we're going to observe this error throughout the rest of the search and then add it back in.",
                    "label": 0
                },
                {
                    "sent": "You generalize it of it all day.",
                    "label": 0
                },
                {
                    "sent": "Other notes that you have not seen.",
                    "label": 0
                },
                {
                    "sent": "That is true, so very specific type of generalization is very strong, yeah?",
                    "label": 0
                },
                {
                    "sent": "So I. I don't have any particular insights as to why it works so well, but it does appear to work on a wide variety of domains and quite well.",
                    "label": 0
                },
                {
                    "sent": "Great.",
                    "label": 0
                },
                {
                    "sent": "And so actually that will be my question.",
                    "label": 0
                },
                {
                    "sent": "So what happens with the other domains?",
                    "label": 0
                },
                {
                    "sent": "So if the answer is in the paper, just tell me yes.",
                    "label": 1
                },
                {
                    "sent": "So we are able to characterize the kinds of domains that it finds problematic.",
                    "label": 0
                },
                {
                    "sent": "Specifically where there is very high in one part of the domain and then simplify the question.",
                    "label": 0
                },
                {
                    "sent": "So have you run the experiment on a bunch of, you know, by cops benchmarks.",
                    "label": 0
                },
                {
                    "sent": "So I'm getting ready to do that in the very near future.",
                    "label": 0
                },
                {
                    "sent": "So not yet but soon.",
                    "label": 0
                }
            ]
        }
    }
}