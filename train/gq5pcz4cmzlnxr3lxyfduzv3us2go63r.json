{
    "id": "gq5pcz4cmzlnxr3lxyfduzv3us2go63r",
    "title": "Event detection in twitter with an event knowledge base",
    "info": {
        "author": [
            "Luis Rei, Artificial Intelligence Laboratory, Jo\u017eef Stefan Institute"
        ],
        "published": "Oct. 21, 2015",
        "recorded": "October 2015",
        "category": [
            "Top->Computer Science->Data Mining",
            "Top->Computer Science->Artificial Intelligence"
        ]
    },
    "url": "http://videolectures.net/sikdd2015_rei_event_detection/",
    "segmentation": [
        [
            "My name is Luis.",
            "I work here at the AI lab and together with Marco Grobelny, can professor Doctor Dominic.",
            "We were researching event detection and Twitter with an event knowledge base, so I'm going."
        ],
        [
            "Begin by sort of giving you an introduction.",
            "What event detection means why we did it the way we did it.",
            "Which approaches we took and then some final remarks."
        ],
        [
            "So what is an event, an event in the literature is defined as a real world occurrence over a specific period of time in a specific location.",
            "So, but this is very broad and generally in the literature.",
            "Another small point is added, which is an event is significant and significance is normally determined whether it is discussed in traditional media or not.",
            "So if you consider at JFK over heard the cell convo.",
            "I went to the bathroom and when I got back my flight had taken off and my girlfriend was on it.",
            "So this is an event.",
            "But is it a significant event?",
            "Not really because well, this didn't show up in the news.",
            "I guess you know, as this person was really important."
        ],
        [
            "Motivation so event detection answers one important question or questions what is happening or what happened right in social media.",
            "It adds an extra social dimension, right?",
            "You want to know what the people are discussing rather than what the journalists are discussing.",
            "Then the motivation for matching it to a knowledge base is that if we match it to some kind of knowledge base, we needed to event a lot, get a lot more context for this event, then we would get from a single tweet, right?"
        ],
        [
            "So tweets and social media in January are very high volume, so 500 million a month for just Twitter.",
            "They have very reduced context in terms of text.",
            "They only have at most 140 characters.",
            "They have a high degree of irrelevant message by our definition of relevant which we showed before and they are multi language."
        ],
        [
            "So next we got an event knowledge base which was event registry we've heard before, which consists of automatically created events from news article retrieved from News Feed.",
            "It collects content from a lot of new sources worldwide, so they all have different languages out of different points, and each event consists of a multilingual cluster of news articles.",
            "This is a traditional approach to event detection in mainstream media.",
            "Which is stream clustering, an information extracted from them an most and we know that most topics discussed on Twitter are also mainstream news, and this also corresponds to our definition of significant annetts modeling.",
            "OK, so it really seemed like an ideal knowledge base to go."
        ],
        [
            "So to recap, our objective is to get from a series of events on Event registry which are structured and come from news an are multi language and match them to our stream of social media messages.",
            "Which is also multi lingual.",
            "I."
        ],
        [
            "The first sort of approach we can think of thinking, and the easiest one is URL matching, so it's very common in a tweet to have a URL to a news story.",
            "Event registry we have a series of news stories which their associated URLs, so if you consider this tweet why I think India's negotiation tactics have not advanced its case for reform.",
            "We might not know exactly what we're talking about.",
            "We don't have a lot of context, but if we look at that URL and will look at Event registry where it's actually discussing an event called Double World Trade Organization failure on trade facilitation so that information that's the person is talking about.",
            "His comments are not necessarily mirrored in the news story, but because of the URL we can still associated and get extra con."
        ],
        [
            "So there are some issues with URL matching.",
            "It's not just like string matching because the relationship between an article and the URL is one too many, so an article will have many URLs, for example URL shorteners, other re directions.",
            "When the sites changes structure trailing slashes.",
            "These are some of the most common.",
            "Sort of problems finding the correct URL we can extract from the web page often metadata which is embedded in the HTML of many publishers which include the Canonical URL.",
            "Sort of an open standard and the open graph, which is another standard promoted by Facebook.",
            "We can also follow redirects and we can ignore trailing slashes, so for most problems we can kind of find a solution, right?",
            "But of course this is."
        ],
        [
            "Just very basic because not all tweets will have URLs.",
            "So now we need to consider the context.",
            "So in terms of content, if we look at the traditional news, story has usually has a title, a date and author and a body.",
            "What does?",
            "Tweet have well it has an author.",
            "It has a date and it has a very short content.",
            "And here we have a URL, but we don't want to use it.",
            "Insert in this case and content matching we want to instead take."
        ],
        [
            "Approach based on text similarity and usually from decades of research on text similarity we can sort of take some kind of common assumptions.",
            "The title is usually more important in the body, longer N grams are more important than shorter and grams when it comes to matching text.",
            "Keywords are more important than normal words.",
            "Multiple similarity measures exist and we can train a classifier based on this text similarity.",
            "Anhana corpus generated from URL matching."
        ],
        [
            "Just one more second.",
            "We have also pre processing which is common in text.",
            "So in our case we did we converted everything to lowercase.",
            "All URLs are removed so we don't sort of cheat all non alphanumeric characters are removed.",
            "All characters are converted to their Unicode normal form.",
            "The text is tokenized based on white spaces and stop words or remove."
        ],
        [
            "Left so too are the classifier we're trying to build to match content between an event and tweet.",
            "We take the features, the Jaccard similarity between the title of the article in the tweet, the number of common terms between the tweets and the body of the article multiplied by the logarithm of the number of terms in the tweet.",
            "The Jaccard similarity between the body of the title in the article of the tweet and tweet and the cosine similarity between the body of the.",
            "Article in the tweet."
        ],
        [
            "We need to consider that there are some language dependencies in this approach.",
            "Whitespace based organization only works on languages which use whitespace based separation, such as European languages, but they are not possible in Asian languages.",
            "Unicode normalization works better in cases where the language on tweets matches the way Unicode normalization works.",
            "So for instance, if you normalize Portuguese text, you have this little C here and it converts it to that C and that matches how people write on social media.",
            "However, if you do Unicode normalization on German text, this A with an omelete gets converted to.",
            "Hey Anthony and this does not match the way that Germans write on Twitter.",
            "Of course, stop words.",
            "I think yeah, I got the word from Mike.",
            "For instance, they I think they use a single A or they use AA.",
            "With the SI know it, yes it's double S, but with the I think because they don't do this kind of thing, or at least that's what sort of my German consultant told me."
        ],
        [
            "Project OK, so now to train a classifier to do content matching between tweets and an article.",
            "We need to sort of create a data set, supervised data set.",
            "So we use the previous method of URL matching each entry, sort of each row on our data is an event tweet pair.",
            "An event is represented by the Central News article in Event Registry.",
            "So each event has a central newsarticle defined.",
            "An article we tweet, fares.",
            "Tweet article.",
            "Tweet pairs with zero similarity vectors or discarded except for a single negative example, we balance the data set so the number of negatives examples equals to negative positive examples and we get about 32,000 tweet event pairs."
        ],
        [
            "Then we train our classifier.",
            "We use standard support vector machine.",
            "It's a binary classifier that tells us whether there is a match or not match.",
            "We split the data set 5050 into a train and test, and we do a grid search hyperparameter tuning on the train set and we get these parameters standard parameters."
        ],
        [
            "That's the results.",
            "So we get an area under the curve result of zero point 91 or 91%.",
            "And we plot the precision recall curve, which shows us that actually get pretty nice precision up to very well recall up to a very high recall.",
            "So."
        ],
        [
            "Next report the precision.",
            "Sorry, typo there.",
            "I made the slides just before you don't have time to fix it.",
            "Precision recall versus threshold.",
            "So if we kind of change our threshold in decision making, what can we expect?",
            "So what we did threshold of approximately 1 right far edge there.",
            "We can get a precision of approximately 100% so close enough and the recall of 55%.",
            "So it's."
        ],
        [
            "Discuss a bit the results.",
            "So the way we generated our data set introduces a huge bias because we can expect a real recall to be much lower.",
            "Um, the reason is that.",
            "If a false if a true positive does have has a zero similarity factor, this case is not covered by our data set, but it's happens a lot in reality, right?",
            "This can be sort of partially offset.",
            "If we get a lot of tweets 'cause we heard it's 500 million a day.",
            "So if you lose in our use case, do we store in our perceived loose case.",
            "There is a redundancy that we can sort of hope will make up for our word recall an it's important to keep in mind that in our work there is this emphasis on precision versus recall.",
            "This is of course a decision we made.",
            "Other people can serve, take our approach and make different."
        ],
        [
            "Decisions.",
            "So final remarks.",
            "One of the problems is that feature extraction for supervised classification is well, so you should be careful with which candidates you use.",
            "Usually since we can ignore zero similarity, article tweet pairs, we can use and because we're using text similarity, we can use a lot of approaches from information retrieval that are like for instance ngram searching that are fast and removing a lot of bad candidates.",
            "Um, there's an obvious time delay on event detection, so our emphasis here was not on real time work.",
            "So the the article, the news article event needs to exist already formed in our event database, so if something is happening and we still don't have news about it, we will not detect it.",
            "Obviously we consider serve the biggest contributions of this work to be the use of an event knowledge base for event detection, social media, and the introduction of.",
            "Fully automated techniques for generalizing supervised event detection data set.",
            "That's it, thank you, thank you.",
            "Yes, so how much string can be?",
            "I mean, how many weeks per second or so?",
            "The question is that this works on tweets, article pairs, right?",
            "So the number of tweets you can process.",
            "So the problem is if feature extraction right, the classifier itself is very fast, so the feature extraction extracting N grams and comparing text similarity, which is still very fast.",
            "And if you reduce the number of candidates that you send into the classifier.",
            "It's very fast, so at the present we haven't.",
            "We're not doing it, measuring it on my laptop or anything like it, but I expect this to be relatively fast."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "My name is Luis.",
                    "label": 0
                },
                {
                    "sent": "I work here at the AI lab and together with Marco Grobelny, can professor Doctor Dominic.",
                    "label": 0
                },
                {
                    "sent": "We were researching event detection and Twitter with an event knowledge base, so I'm going.",
                    "label": 1
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Begin by sort of giving you an introduction.",
                    "label": 0
                },
                {
                    "sent": "What event detection means why we did it the way we did it.",
                    "label": 0
                },
                {
                    "sent": "Which approaches we took and then some final remarks.",
                    "label": 1
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So what is an event, an event in the literature is defined as a real world occurrence over a specific period of time in a specific location.",
                    "label": 1
                },
                {
                    "sent": "So, but this is very broad and generally in the literature.",
                    "label": 0
                },
                {
                    "sent": "Another small point is added, which is an event is significant and significance is normally determined whether it is discussed in traditional media or not.",
                    "label": 0
                },
                {
                    "sent": "So if you consider at JFK over heard the cell convo.",
                    "label": 0
                },
                {
                    "sent": "I went to the bathroom and when I got back my flight had taken off and my girlfriend was on it.",
                    "label": 0
                },
                {
                    "sent": "So this is an event.",
                    "label": 0
                },
                {
                    "sent": "But is it a significant event?",
                    "label": 0
                },
                {
                    "sent": "Not really because well, this didn't show up in the news.",
                    "label": 0
                },
                {
                    "sent": "I guess you know, as this person was really important.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Motivation so event detection answers one important question or questions what is happening or what happened right in social media.",
                    "label": 1
                },
                {
                    "sent": "It adds an extra social dimension, right?",
                    "label": 0
                },
                {
                    "sent": "You want to know what the people are discussing rather than what the journalists are discussing.",
                    "label": 0
                },
                {
                    "sent": "Then the motivation for matching it to a knowledge base is that if we match it to some kind of knowledge base, we needed to event a lot, get a lot more context for this event, then we would get from a single tweet, right?",
                    "label": 1
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So tweets and social media in January are very high volume, so 500 million a month for just Twitter.",
                    "label": 1
                },
                {
                    "sent": "They have very reduced context in terms of text.",
                    "label": 1
                },
                {
                    "sent": "They only have at most 140 characters.",
                    "label": 1
                },
                {
                    "sent": "They have a high degree of irrelevant message by our definition of relevant which we showed before and they are multi language.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So next we got an event knowledge base which was event registry we've heard before, which consists of automatically created events from news article retrieved from News Feed.",
                    "label": 1
                },
                {
                    "sent": "It collects content from a lot of new sources worldwide, so they all have different languages out of different points, and each event consists of a multilingual cluster of news articles.",
                    "label": 1
                },
                {
                    "sent": "This is a traditional approach to event detection in mainstream media.",
                    "label": 0
                },
                {
                    "sent": "Which is stream clustering, an information extracted from them an most and we know that most topics discussed on Twitter are also mainstream news, and this also corresponds to our definition of significant annetts modeling.",
                    "label": 1
                },
                {
                    "sent": "OK, so it really seemed like an ideal knowledge base to go.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So to recap, our objective is to get from a series of events on Event registry which are structured and come from news an are multi language and match them to our stream of social media messages.",
                    "label": 1
                },
                {
                    "sent": "Which is also multi lingual.",
                    "label": 0
                },
                {
                    "sent": "I.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The first sort of approach we can think of thinking, and the easiest one is URL matching, so it's very common in a tweet to have a URL to a news story.",
                    "label": 0
                },
                {
                    "sent": "Event registry we have a series of news stories which their associated URLs, so if you consider this tweet why I think India's negotiation tactics have not advanced its case for reform.",
                    "label": 0
                },
                {
                    "sent": "We might not know exactly what we're talking about.",
                    "label": 0
                },
                {
                    "sent": "We don't have a lot of context, but if we look at that URL and will look at Event registry where it's actually discussing an event called Double World Trade Organization failure on trade facilitation so that information that's the person is talking about.",
                    "label": 0
                },
                {
                    "sent": "His comments are not necessarily mirrored in the news story, but because of the URL we can still associated and get extra con.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So there are some issues with URL matching.",
                    "label": 0
                },
                {
                    "sent": "It's not just like string matching because the relationship between an article and the URL is one too many, so an article will have many URLs, for example URL shorteners, other re directions.",
                    "label": 1
                },
                {
                    "sent": "When the sites changes structure trailing slashes.",
                    "label": 0
                },
                {
                    "sent": "These are some of the most common.",
                    "label": 0
                },
                {
                    "sent": "Sort of problems finding the correct URL we can extract from the web page often metadata which is embedded in the HTML of many publishers which include the Canonical URL.",
                    "label": 0
                },
                {
                    "sent": "Sort of an open standard and the open graph, which is another standard promoted by Facebook.",
                    "label": 0
                },
                {
                    "sent": "We can also follow redirects and we can ignore trailing slashes, so for most problems we can kind of find a solution, right?",
                    "label": 0
                },
                {
                    "sent": "But of course this is.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Just very basic because not all tweets will have URLs.",
                    "label": 0
                },
                {
                    "sent": "So now we need to consider the context.",
                    "label": 0
                },
                {
                    "sent": "So in terms of content, if we look at the traditional news, story has usually has a title, a date and author and a body.",
                    "label": 0
                },
                {
                    "sent": "What does?",
                    "label": 0
                },
                {
                    "sent": "Tweet have well it has an author.",
                    "label": 0
                },
                {
                    "sent": "It has a date and it has a very short content.",
                    "label": 0
                },
                {
                    "sent": "And here we have a URL, but we don't want to use it.",
                    "label": 0
                },
                {
                    "sent": "Insert in this case and content matching we want to instead take.",
                    "label": 1
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Approach based on text similarity and usually from decades of research on text similarity we can sort of take some kind of common assumptions.",
                    "label": 0
                },
                {
                    "sent": "The title is usually more important in the body, longer N grams are more important than shorter and grams when it comes to matching text.",
                    "label": 1
                },
                {
                    "sent": "Keywords are more important than normal words.",
                    "label": 0
                },
                {
                    "sent": "Multiple similarity measures exist and we can train a classifier based on this text similarity.",
                    "label": 0
                },
                {
                    "sent": "Anhana corpus generated from URL matching.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Just one more second.",
                    "label": 0
                },
                {
                    "sent": "We have also pre processing which is common in text.",
                    "label": 0
                },
                {
                    "sent": "So in our case we did we converted everything to lowercase.",
                    "label": 0
                },
                {
                    "sent": "All URLs are removed so we don't sort of cheat all non alphanumeric characters are removed.",
                    "label": 1
                },
                {
                    "sent": "All characters are converted to their Unicode normal form.",
                    "label": 1
                },
                {
                    "sent": "The text is tokenized based on white spaces and stop words or remove.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Left so too are the classifier we're trying to build to match content between an event and tweet.",
                    "label": 0
                },
                {
                    "sent": "We take the features, the Jaccard similarity between the title of the article in the tweet, the number of common terms between the tweets and the body of the article multiplied by the logarithm of the number of terms in the tweet.",
                    "label": 1
                },
                {
                    "sent": "The Jaccard similarity between the body of the title in the article of the tweet and tweet and the cosine similarity between the body of the.",
                    "label": 0
                },
                {
                    "sent": "Article in the tweet.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We need to consider that there are some language dependencies in this approach.",
                    "label": 0
                },
                {
                    "sent": "Whitespace based organization only works on languages which use whitespace based separation, such as European languages, but they are not possible in Asian languages.",
                    "label": 0
                },
                {
                    "sent": "Unicode normalization works better in cases where the language on tweets matches the way Unicode normalization works.",
                    "label": 1
                },
                {
                    "sent": "So for instance, if you normalize Portuguese text, you have this little C here and it converts it to that C and that matches how people write on social media.",
                    "label": 0
                },
                {
                    "sent": "However, if you do Unicode normalization on German text, this A with an omelete gets converted to.",
                    "label": 0
                },
                {
                    "sent": "Hey Anthony and this does not match the way that Germans write on Twitter.",
                    "label": 0
                },
                {
                    "sent": "Of course, stop words.",
                    "label": 0
                },
                {
                    "sent": "I think yeah, I got the word from Mike.",
                    "label": 0
                },
                {
                    "sent": "For instance, they I think they use a single A or they use AA.",
                    "label": 0
                },
                {
                    "sent": "With the SI know it, yes it's double S, but with the I think because they don't do this kind of thing, or at least that's what sort of my German consultant told me.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Project OK, so now to train a classifier to do content matching between tweets and an article.",
                    "label": 0
                },
                {
                    "sent": "We need to sort of create a data set, supervised data set.",
                    "label": 0
                },
                {
                    "sent": "So we use the previous method of URL matching each entry, sort of each row on our data is an event tweet pair.",
                    "label": 0
                },
                {
                    "sent": "An event is represented by the Central News article in Event Registry.",
                    "label": 1
                },
                {
                    "sent": "So each event has a central newsarticle defined.",
                    "label": 0
                },
                {
                    "sent": "An article we tweet, fares.",
                    "label": 0
                },
                {
                    "sent": "Tweet article.",
                    "label": 0
                },
                {
                    "sent": "Tweet pairs with zero similarity vectors or discarded except for a single negative example, we balance the data set so the number of negatives examples equals to negative positive examples and we get about 32,000 tweet event pairs.",
                    "label": 1
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Then we train our classifier.",
                    "label": 0
                },
                {
                    "sent": "We use standard support vector machine.",
                    "label": 1
                },
                {
                    "sent": "It's a binary classifier that tells us whether there is a match or not match.",
                    "label": 0
                },
                {
                    "sent": "We split the data set 5050 into a train and test, and we do a grid search hyperparameter tuning on the train set and we get these parameters standard parameters.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That's the results.",
                    "label": 0
                },
                {
                    "sent": "So we get an area under the curve result of zero point 91 or 91%.",
                    "label": 0
                },
                {
                    "sent": "And we plot the precision recall curve, which shows us that actually get pretty nice precision up to very well recall up to a very high recall.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Next report the precision.",
                    "label": 0
                },
                {
                    "sent": "Sorry, typo there.",
                    "label": 0
                },
                {
                    "sent": "I made the slides just before you don't have time to fix it.",
                    "label": 0
                },
                {
                    "sent": "Precision recall versus threshold.",
                    "label": 0
                },
                {
                    "sent": "So if we kind of change our threshold in decision making, what can we expect?",
                    "label": 0
                },
                {
                    "sent": "So what we did threshold of approximately 1 right far edge there.",
                    "label": 0
                },
                {
                    "sent": "We can get a precision of approximately 100% so close enough and the recall of 55%.",
                    "label": 0
                },
                {
                    "sent": "So it's.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Discuss a bit the results.",
                    "label": 0
                },
                {
                    "sent": "So the way we generated our data set introduces a huge bias because we can expect a real recall to be much lower.",
                    "label": 1
                },
                {
                    "sent": "Um, the reason is that.",
                    "label": 0
                },
                {
                    "sent": "If a false if a true positive does have has a zero similarity factor, this case is not covered by our data set, but it's happens a lot in reality, right?",
                    "label": 1
                },
                {
                    "sent": "This can be sort of partially offset.",
                    "label": 0
                },
                {
                    "sent": "If we get a lot of tweets 'cause we heard it's 500 million a day.",
                    "label": 0
                },
                {
                    "sent": "So if you lose in our use case, do we store in our perceived loose case.",
                    "label": 0
                },
                {
                    "sent": "There is a redundancy that we can sort of hope will make up for our word recall an it's important to keep in mind that in our work there is this emphasis on precision versus recall.",
                    "label": 1
                },
                {
                    "sent": "This is of course a decision we made.",
                    "label": 0
                },
                {
                    "sent": "Other people can serve, take our approach and make different.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Decisions.",
                    "label": 0
                },
                {
                    "sent": "So final remarks.",
                    "label": 0
                },
                {
                    "sent": "One of the problems is that feature extraction for supervised classification is well, so you should be careful with which candidates you use.",
                    "label": 1
                },
                {
                    "sent": "Usually since we can ignore zero similarity, article tweet pairs, we can use and because we're using text similarity, we can use a lot of approaches from information retrieval that are like for instance ngram searching that are fast and removing a lot of bad candidates.",
                    "label": 1
                },
                {
                    "sent": "Um, there's an obvious time delay on event detection, so our emphasis here was not on real time work.",
                    "label": 1
                },
                {
                    "sent": "So the the article, the news article event needs to exist already formed in our event database, so if something is happening and we still don't have news about it, we will not detect it.",
                    "label": 0
                },
                {
                    "sent": "Obviously we consider serve the biggest contributions of this work to be the use of an event knowledge base for event detection, social media, and the introduction of.",
                    "label": 1
                },
                {
                    "sent": "Fully automated techniques for generalizing supervised event detection data set.",
                    "label": 0
                },
                {
                    "sent": "That's it, thank you, thank you.",
                    "label": 0
                },
                {
                    "sent": "Yes, so how much string can be?",
                    "label": 0
                },
                {
                    "sent": "I mean, how many weeks per second or so?",
                    "label": 0
                },
                {
                    "sent": "The question is that this works on tweets, article pairs, right?",
                    "label": 0
                },
                {
                    "sent": "So the number of tweets you can process.",
                    "label": 0
                },
                {
                    "sent": "So the problem is if feature extraction right, the classifier itself is very fast, so the feature extraction extracting N grams and comparing text similarity, which is still very fast.",
                    "label": 0
                },
                {
                    "sent": "And if you reduce the number of candidates that you send into the classifier.",
                    "label": 0
                },
                {
                    "sent": "It's very fast, so at the present we haven't.",
                    "label": 0
                },
                {
                    "sent": "We're not doing it, measuring it on my laptop or anything like it, but I expect this to be relatively fast.",
                    "label": 0
                }
            ]
        }
    }
}