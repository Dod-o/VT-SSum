{
    "id": "tfg3l623nkl2fouct6b7ryzxw7djoxxn",
    "title": "Regression Canonical Correlation Analysis",
    "info": {
        "author": [
            "Jan Rupnik, Artificial Intelligence Laboratory, Jo\u017eef Stefan Institute"
        ],
        "published": "Dec. 20, 2008",
        "recorded": "December 2008",
        "category": [
            "Top->Computer Science->Machine Learning->Principal Component Analysis"
        ]
    },
    "url": "http://videolectures.net/lms08_rupnik_rcca/",
    "segmentation": [
        [
            "And rupnick from your ship, Steven Institute and this is joint work with blush from Fortuna.",
            "And the it's the title.",
            "Is regression Canonical correlation analysis and this work is based on the observation that if you use Canonical correlation analysis for information retrieval like this, is this is the diagram.",
            "So we have two views, a query in one view, the target corpus in second view and there's some aligned corpus that we use to try to find the projections the CCA mappings into the common semantic space.",
            "And once we have those mappings, we then map query and the target target corpus and then we do the monolingual search in the common semantic space.",
            "And the observation is that sometimes those concepts that you find with CCA there can be 2, two general and the query is not represented very well along those concepts that you discovered.",
            "So our idea is to optimize directly for each query separately and given a query find, find this mapping into directly into the language too, and then do the.",
            "This information retrieval in the second second view.",
            "So."
        ],
        [
            "So.",
            "Then this is the optimization problem.",
            "We have two D aligned corpus X&X matrix and Y matrix.",
            "Then we have a query and the goal is to find the Alpha so that QXY Alpha is.",
            "Is maximally correlated, so this is the.",
            "This is exactly like in the Canonical correlation analysis optimization, except for the fact that we fixed Q.",
            "So we're not optimizing over Q, but only over Alpha.",
            "So and this this so in this problem, using the Lagrangian techniques then reduces to a system of linear equations as opposed to eigenvalue eigen problem in CCA.",
            "So and we solve this system for each query separately and we can use.",
            "We can take sparsity into account and use conjugate gradient descent to efficiently solve this system.",
            "So this can be done in query time.",
            "And.",
            "That's it."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And rupnick from your ship, Steven Institute and this is joint work with blush from Fortuna.",
                    "label": 0
                },
                {
                    "sent": "And the it's the title.",
                    "label": 0
                },
                {
                    "sent": "Is regression Canonical correlation analysis and this work is based on the observation that if you use Canonical correlation analysis for information retrieval like this, is this is the diagram.",
                    "label": 0
                },
                {
                    "sent": "So we have two views, a query in one view, the target corpus in second view and there's some aligned corpus that we use to try to find the projections the CCA mappings into the common semantic space.",
                    "label": 1
                },
                {
                    "sent": "And once we have those mappings, we then map query and the target target corpus and then we do the monolingual search in the common semantic space.",
                    "label": 0
                },
                {
                    "sent": "And the observation is that sometimes those concepts that you find with CCA there can be 2, two general and the query is not represented very well along those concepts that you discovered.",
                    "label": 0
                },
                {
                    "sent": "So our idea is to optimize directly for each query separately and given a query find, find this mapping into directly into the language too, and then do the.",
                    "label": 0
                },
                {
                    "sent": "This information retrieval in the second second view.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Then this is the optimization problem.",
                    "label": 1
                },
                {
                    "sent": "We have two D aligned corpus X&X matrix and Y matrix.",
                    "label": 0
                },
                {
                    "sent": "Then we have a query and the goal is to find the Alpha so that QXY Alpha is.",
                    "label": 0
                },
                {
                    "sent": "Is maximally correlated, so this is the.",
                    "label": 0
                },
                {
                    "sent": "This is exactly like in the Canonical correlation analysis optimization, except for the fact that we fixed Q.",
                    "label": 0
                },
                {
                    "sent": "So we're not optimizing over Q, but only over Alpha.",
                    "label": 0
                },
                {
                    "sent": "So and this this so in this problem, using the Lagrangian techniques then reduces to a system of linear equations as opposed to eigenvalue eigen problem in CCA.",
                    "label": 1
                },
                {
                    "sent": "So and we solve this system for each query separately and we can use.",
                    "label": 0
                },
                {
                    "sent": "We can take sparsity into account and use conjugate gradient descent to efficiently solve this system.",
                    "label": 0
                },
                {
                    "sent": "So this can be done in query time.",
                    "label": 1
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "That's it.",
                    "label": 0
                }
            ]
        }
    }
}