{
    "id": "ld46qpv7ggggaqtsyr3pv23vq3socpik",
    "title": "Transfer learning in social recommendations",
    "info": {
        "author": [
            "Qiang Yang, The Hong Kong University of Science and Technology"
        ],
        "published": "Aug. 4, 2011",
        "recorded": "July 2011",
        "category": [
            "Top->Computer Science->Data Mining->Social Content"
        ]
    },
    "url": "http://videolectures.net/socialweb2011_yang_transfer/",
    "segmentation": [
        [
            "Hola everybody, I just learned this Spanish word."
        ],
        [
            "OK, so to start with let me give you a brief review of the traditional machine learning paradigm so we know that machine learning can be considered as generally two phase process training and testing in the training process.",
            "We have a collection of training data with a number of features and with outcome.",
            "OK the class attribute.",
            "So then based on this you train a classifier model.",
            "Which can more or less correctly classify those training examples.",
            "So being from Hong Kong, I used this analogy where a customer goes to see a fortune teller and the fortune teller can.",
            "Based on your story, an features can give you a judgment can give you a decision whether you will have good fortune or not, and we can consider that as a.",
            "A model OK and the training can be all the previous customers you have seen."
        ],
        [
            "Then we can apply this to a new data.",
            "But the problem is, what if the future customer that comes is a different entity from what you have seen before instead of a human, it's a dog.",
            "Then the traditional machine learning models will be."
        ],
        [
            "Rock You will not know what to do.",
            "OK, so evaluating this scenario we found out that a major assumption made in the previous learning systems is that you know training and the future data, including the test data, must follow a number of restrictions.",
            "OK, number one, they must follow the same distribution more or less and #2 they must be from the same feature space and there may be others but.",
            "These are the major assumptions.",
            "So what so the question is, what if these assumptions break?",
            "OK, what if you know we face a new data with a different distribution different?"
        ],
        [
            "Your space.",
            "OK, in fact we see many such examples in real life, particularly when we apply learning methods to new application areas.",
            "OK, so for example, if we use a lot of newspaper articles as the training data to train a text classifier, but then we apply to a very specific domain in medical domain, we may find that many of the natural language processing tasks will get very low performance."
        ],
        [
            "OK, similarly when we have different feature spaces, say if you have the text as training data but we use images image features as the test data, then again the classifier will not work OK, so we have many such situations.",
            "Now these are not contrived examples because in real life when we deal with a new domain, often we find we don't have enough labeled data or high quality labeled data.",
            "OK, because to label these data in order to build the training data, we need to spend a lot of effort, money, effort, people, human power and so on in order to label them OK and all."
        ],
        [
            "We don't have the luxury.",
            "So we try to use a different paradigm from the traditional paradigm, in which instead of having just the learning system based on the training data as usual, we supply a number of other or what we call source domains.",
            "Auxiliary domains which more or less have some similarity with the target domain, but they are different.",
            "OK, the trick is.",
            "We want to find out what's similar between the source domain and the target domain in order to improve learning performance in the target domain.",
            "OK, and so we have a paradigm as illustrated in this matrix where we have, you know, as usual, the training and test data, but instead of just focusing on the target domain, we now have a new dimension which is the source domain and where the data can be either labeled or unlabeled.",
            "So this.",
            "Process of learning, including other information sources.",
            "Is known as transfer learning, and it's a.",
            "It's a very active research area in many different areas.",
            "If you go to each client you can see you know, including this year.",
            "You can see many papers if you go to computer vision conference you can see many papers if you go to a natural language processing and so on and so forth.",
            "OK, now because of this sudden surge in interest, my student Sinope and I single panel is sitting over there.",
            "We did a survey and we try to look at."
        ],
        [
            "At transfer learning the overall.",
            "Picture of the landscape and try to make some sense of it.",
            "And in order to help us determine you know what's been done and what what's still open.",
            "OK, so we look at the Mini Mini.",
            "Works in transfer learning and we figured out that one dimension in which we can partition the work is to look at the target data and see if the target data are labeled or not OK, so if the label data are available.",
            "Then we go this branch and we look at inductive transfer learning, including inductive transfer learning when the source data OK, which is the next.",
            "Dimension we locate the source data, include some labeled data or not, labeled data.",
            "And likewise, when we don't have the label data then.",
            "We go this direction and when the label data are available only in a source domain, we have the transductive transfer learning and so on.",
            "So we have those yellow boxes at the bottom of the tree in the classification.",
            "Each one is a body of."
        ],
        [
            "Work OK so we have this survey posted online."
        ],
        [
            "And people can also get this from signal Signal Path homepage.",
            "You can just go and type transfer learning survey and get to this page and download this for free and we also have a collection of source code and data that we posted here so people can get these after the talk.",
            "I can give you the links.",
            "OK so that's a very very brief overview of."
        ],
        [
            "A survey in this topic so.",
            "In this talk I'm going to divide my talk into several stages, but all the stages will focus on one thing, which is social media.",
            "OK, so how social media can help recommendation systems?",
            "How recommendation systems can benefit from other social behavior?",
            "So the first topic I'm going to look at is how social media can serve as a bridge.",
            "OK, to help in transfer learning.",
            "OK, here we have a bridge in Spain."
        ],
        [
            "OK, so let's consider the problem I posted before.",
            "Suppose I give you a lot of data.",
            "OK, suppose you as a human intelligent human reader.",
            "You have read much about fruits, OK, apples versus bananas.",
            "Now can this knowledge which you read from text help you recognize pictures OK, when you're presented in the future data, some images of apples and bananas OK, you can say.",
            "Well, obviously right.",
            "The more you read, the more knowledgeable you are, and so the quicker you can learn to recognize pictures.",
            "But after all, we don't know if that's true.",
            "OK.",
            "If it's true, then so much the better because we have so much more labeled data in terms of text as compared to images.",
            "OK, so so we have this as the auxiliary data and we have these as target data.",
            "So since 2009 paper."
        ],
        [
            "Dish in ACL, which is computational linguistics.",
            "There's a serious works, including my own group and other groups working in this direction, and a theme here is using social web for transfer learning.",
            "So let me give you one example for using social web for clustering.",
            "OK, now suppose I have bunch of images I wish to cluster.",
            "Now the images may be about apples and bananas.",
            "And in clustering we don't have labeled data right?",
            "So we can only work with the very very low level pixel image features.",
            "And likewise, if you just use that those low level features.",
            "It's likely that we don't get very good clustering results.",
            "OK, now suppose we call V as the image features and F sorry V as images an F as image features.",
            "Then we can build this relationship between images and their features, and if you can have a good probability understanding of the probability distribution.",
            "Of those low level features such as safety features, then we can build a good cluster.",
            "Now.",
            "On the other hand, a good cluster actually corresponds to a good topic model of the images.",
            "So the question is if we have, in addition of a bunch of text documents, can they help us?",
            "Eating better topic model.",
            "OK, so the trick here then is how to link a topic model we build for the text and the Top Model we can build for images by linking them together.",
            "And here's where the bridge comes in and the bridge is social media.",
            "OK, so we have so for example on Flickr we have many images which are tagged with text labels.",
            "These are code tags.",
            "Now these tags somehow is a collection of small documents which are text to description of the image we are looking at.",
            "OK, so if you have lots and lots of loads and we have lots and lots of tags, then we can.",
            "Relat these two OK in terms of our task, it is aligning using.",
            "Using this to align the topics that we build for the documents and the topics that we have for the images.",
            "Then it is the same set of topic which can boost the performance of the model.",
            "OK so."
        ],
        [
            "The result in this experiment there was a improvement in clustering performance."
        ],
        [
            "Now encouraged by this success, we went on to ask next question.",
            "So suppose you have read a lot of text documents, say about Lions and apples and bananas.",
            "Can you then help with the classification?",
            "OK, and this involves supervised."
        ],
        [
            "So here is an example.",
            "OK, so let's say we have a few labeled images and they are so feel that they are not sufficient for building a good image classifier.",
            "OK, so the test data consists of the.",
            "Just the unlabeled images.",
            "And in addition, suppose I give you 2 resources.",
            "One is just like what we had just now.",
            "Is the tag images say from Flickr or from other some other resources.",
            "And on the other hand we have a large collection of auxiliary text data documents that are unlabeled, OK, these are unlabeled.",
            "So then by putting this together we can still see some relationship between them.",
            "OK, so for example as illustr."
        ],
        [
            "Dated.",
            "In this next image we can for the images we try to build a relation between images and tags and those are from the social web right and the documents which are unlabelled even though they are unlabeled, we still have a relation between documents and words, and on each we can use matrix decomposition to build their relevant latent semantic model.",
            "OK, so for example for the images.",
            "We have these models image times the latent.",
            "Clusters and then and then their semantic model times the tags.",
            "And here we have the documents.",
            "Likewise in the same way now.",
            "The only difficulty we have here, which is a major difficulty, is that these semantic latent models are not aligned, and we can try to impose a constraint to align them.",
            "OK, the latent factors can be aligned.",
            "So what the result is if we have these images which which are seemingly unrelated, we don't know how similar they are after this alignment, then we can have a better.",
            "Relationship between them like they are all about exercising and exercising machine."
        ],
        [
            "And so on.",
            "So that's the intuition.",
            "The mathematical model behind this is a matrix model where we simultaneously decompose the collection of images and the collection of documents and in the same time making sure that the latent Model V is the same.",
            "OK, the latent semantic models are the same.",
            "Then in the end we can accomplish this."
        ],
        [
            "So then you know, because there are many unknowns, we can we have to use some trick to make sure the model is convex and can converge.",
            "So the details will be omitted."
        ],
        [
            "Now, in the end we did a number of experiments to see if our intuition conform to the experiments.",
            "OK, the first thing is if we increase the number of auxiliary documents, that is, you know, is it true if?",
            "The more we read, the more knowledgeable we are.",
            "OK, so here on this horizontal axis is the number of unlabeled documents that the system reads, and we can see that the performance, which is the accuracy increases sharply for the 1st 200 documents, and then it flattens out after that.",
            "OK, so this tells us that yes, the more you read, the smarter you are.",
            "But it's not true if you continue reading OK.",
            "So after you reach 200, you can graduate.",
            "That's why we graduate.",
            "And then you flatten out and in fact it drops a little bit because there's more noise that are introduced, so you may get a little bit more stupid."
        ],
        [
            "OK, and if you introduce some more tag images again, the performance increases after a certain point.",
            "That is, the translator itself has to be of good."
        ],
        [
            "Pretty good, enough quality, and likewise the more noise you introduce in the non relevant tag images the performance will drop."
        ],
        [
            "OK, so these are some preliminar."
        ],
        [
            "Ray experiments, which are quite encouraging at 1st and again here we are trying to use the unlabeled text as the auxiliary data.",
            "Use the social web as the bridge and we try to improve image classification, which is a very difficult task."
        ],
        [
            "The second work I tried to introduce is.",
            "In recent work done by my students on using social recommendations themselves as the source data in transfer learning.",
            "OK, so the targets here are people and the relation between people and people and people and items and products in red."
        ],
        [
            "Foundation systems.",
            "OK, so because this workshop is about social media, social recommendation, so I don't need to give you much introduction here, but we are.",
            "We should be all familiar with recommendation, right?",
            "So if you type a query, you come in and there are a number of recommendations."
        ],
        [
            "Can be given to you the familiar.",
            "Workflow of Amazon.",
            "If you write if you buy this book, these books are recommended to you.",
            "And we all know the advantage of recommendation system is as opposed to a search based system is it's active.",
            "It gives you recommendation.",
            "Knowing something about you it can personalize."
        ],
        [
            "It can be up and close.",
            "OK, now in order to model a social recommendation systems, we can consider it as mathematically as a bipartite graph where one side we have a bunch of products, on the other we have people and we have the links indicating whether some users prefer some products and to what."
        ],
        [
            "Agree.",
            "OK, so if we consider them in matrix form, usually horizontally we consider users and vertically we consider items or products and the ratings here represents how much a user prefers a product.",
            "And often we have many missing links and the missing ratings here are represented as question marks.",
            "OK, so algorithm wise we have initially you know in the history of recommendation systems we have user based which is to consider similarity between users and to group the similar users together and symmetrically we can use item based and more recently people adopt model based.",
            "It turns out model based methods are more formally R factor factorization methods.",
            "Matrix factorization methods."
        ],
        [
            "OK, now So what I try to focus on here is that in recommendation systems we often have the problem of data sparsity.",
            "OK, which is when we don't have much ratings to start with and we want to train the model.",
            "And apply to the test data.",
            "The performance can be dramatically reduced if we have a very sparse matrix to start with.",
            "OK, so cold start problem data sparsity problem.",
            "These terms refer to this drop in performance and this is exactly the thing we tried to try to address."
        ],
        [
            "So how we can address that from a transfer learning perspective is to consider this.",
            "Suppose we have some new product line for selling books where we want to recommend books to people, but we don't have much data about books because maybe it's a new domain.",
            "Maybe they are about new users.",
            "OK, so then where we can look at is some similar domains, maybe on different products maybe?",
            "Movies and because of the similarity or inherent similarity between either the product or the users.",
            "Now, is it possible for us to transfer some knowledge to into the target domain to help alleviate the data sparsity problem?",
            "OK, that's the question, OK."
        ],
        [
            "Is it possible so?",
            "With this in mind, we did a number of experiments, try to there's ways in which an auxiliary domain can help.",
            "OK, so this first work is codebook transfer and Billy sitting there in the yellow shirt he's.",
            "The first author here."
        ],
        [
            "Now let me let me give you a brief description of this and being can answer questions thereafter.",
            "OK, so if you look at.",
            "If you look at a matrix representation of the rating record of a domain, we can often consider it as.",
            "You know, because the user group and the item group are very large, we can use.",
            "Usually consider it as consisting of a group of users that have similar tastes and a group of atoms that have similar features.",
            "OK, so if we can group them together then we can compose a compressed version of the rating matrix, which can be more compactly be used to represent the original matrix.",
            "OK, which is inside each cell is a smooth version of the rating and we can code that code book.",
            "Now suppose we have a dense enough matrix.",
            "Then we can build a very good code book.",
            "The question is, can this codebook help solve the cold start problem for some other matrix?"
        ],
        [
            "This OK so if you have a matrix, say in movies where we have many more ratings missing as compared to a books domain, then perhaps if we align their groups in a correct way.",
            "OK the item group and the user group then we can because of their inherent similarity and relatedness.",
            "We can use the dense version to help the sparse version.",
            "OK, so that's the intuition behind this work.",
            "So then the research questions remain OK.",
            "So first of all, how do we relate the code books that we build for either domains?",
            "OK, so that's the first question.",
            "The second question is that you know how sparse does the either the target domain has to be in order for this improvement to be pronounced to be large enough, OK, and likewise, how much do we require the auxiliary domain?",
            "To be dense?",
            "OK, how much dense it must be in order to be helpful for transferring into the target domain.",
            "So this question."
        ],
        [
            "These are preliminary answered.",
            "In this, each paper a couple of years ago.",
            "So to answer the first question, how to build the codebook we can first build a codebook in the source domain, assuming it's dense enough."
        ],
        [
            "Then we take this into the target domain.",
            "Here is the target domain in order to.",
            "So this is the data for the target domain, which is very sparse now by itself, it doesn't allow us to build a good decomposition into a user latent feature space, and item latent feature space, but using the codebook that's transferred from the source domain, we can do a better job.",
            "OK, so this is what this formula is trying to.",
            "Represent."
        ],
        [
            "And indeed, in some small scale experiments involving a subset of users and subset of movies and allow the movies and books to transfer between each other."
        ],
        [
            "We can see that the performance does help, especially one right.",
            "So in each of these settings the CBT is the codebook transfer performs better, especially when the target domain is very, very sparse."
        ],
        [
            "Now following this work, we notice a number of limitations in this style of transfer.",
            "So first of all, the original transfer work required that the readings be of the same range and that in reality we don't have to have this.",
            "This assumption may not be always true, for example the source domain, maybe 01.",
            "Maybe it's a link or not, rather than a rating.",
            "OK, so we must allow this kind of heterogeneous rating to be transferred.",
            "Furthermore, the scale is a limitation.",
            "The scale that was in that experiment was was particularly small and also another limitation we try to break is it allowed only one, a single one auxiliary domain as the source.",
            "And here we try to look at whether it's possible to transfer from a variety of different things.",
            "Some are related, some are unrelated, and we don't know.",
            "Ahead of time and whether we can decide how much to transfer at."
        ],
        [
            "Actively OK, so this is the result of subsequent work.",
            "So for example, in last year's triple AI, my students we could plan at all proposed a system called Cordon."
        ],
        [
            "8 system transfer and here they have to impose a number of restrictions such as you know the users or the items must correspond.",
            "But even under this under this, so the advantage of imposing this constraint is to allow different content.",
            "OK, so here the ratings are 01 and here the ratings are integers.",
            "Allow this kind of transfer to happen."
        ],
        [
            "And indeed it was allowed.",
            "It performed much better and a follow up of that work is work.",
            "Tomorrow OK, so here I'm allowed to do some advertisement.",
            "Which is at 10:30.",
            "My student will talk about a further work where.",
            "He has"
        ],
        [
            "He allows him to genius.",
            "Multiple domains to transfer to a target domain where one the there's partial overlap between the items and users.",
            "He can do much better and can scale up to a much higher degree.",
            "And here is a latent semantic model of his matrix factorization model, which is which is shown here, so I won't say much about this, but."
        ],
        [
            "Welcome to attend that session.",
            "OK, and Furthermore, as I just mentioned, there's even with the CST and CDT, the two previous systems there are still limitations and one limitation is that the transferring has to specify a source domain.",
            "OK, what if the source domain is not a good source domain kind?",
            "The system automatically detect that and in fact."
        ],
        [
            "Wooden bins how?",
            "Who is sitting at the corner?",
            "There he tried to answer this using a method called adaptive transfer learning and in this work he used."
        ],
        [
            "Gaussian process model to build a adaptation in the following sense.",
            "OK, where we have a distance measure between a source domain and the target domain so that when this distance is small you do the transferring and when the distance is over a certain threshold you stop transferring.",
            "So in the end here we have the we have the curve.",
            "This is the error for transfer learning.",
            "And here is the curve, which is a horizontal line for not transferring anything, and we wish to get the best of the two worlds in different settings.",
            "OK, based on the distance between the two domains and using Gaussian process he was successful in demonstrating this."
        ],
        [
            "A number of domains.",
            "And the last part of this talk.",
            "Is related to this collaborative filtering in transferring, but here we try to use a different source data instead of using the same collaborative filtering domain rating or binary data.",
            "Let's try to use Wikipedia, for example as the source domain and the target domain is.",
            "The same is still the region domain, and we asked whether it's possible to transfer some knowledge.",
            "Again, to help with the data sparsity problem.",
            "OK, and this is the work done together with my student change.",
            "Now."
        ],
        [
            "So let's look at some details of this.",
            "And this paper is also included in the workshop proceedings, so everybody can already get that from the web."
        ],
        [
            "OK, so the motivation of this is the following.",
            "OK, suppose we are interested in helping with recommendation, doing better recommendation.",
            "Even one hour reading data is very very sparse.",
            "OK, but suppose we don't have another rating domain to help us with, so let's turn to something that everybody has OK, which is the Wikipedia.",
            "Now on the Wikipedia we have a lot of data which we can model.",
            "As a bipartite graph of users and products, the products can be anything, can be a document, can be a event, and in this particular work we focus on Movies OK because then we can.",
            "We can look at movies so we have movies here in the target domain and we look at the subset of Wikipedia web pages that are about movies.",
            "And each of these pages have a number of editors.",
            "And these editors are people who have spent their time and effort in describing this movie in commenting on this movie.",
            "So in a way, they have given some readings on this movie and in another way we can look at whether the same user commented on two different movies and use this knowledge to link similar movies together.",
            "OK, so then the intuition becomes this, even though we have a very sparse user movie rating matrix Now, it's almost like using Wikipedia.",
            "We can relat some movies together and we can relate some users together.",
            "OK, so symmetrically the movies link different users together now.",
            "However, we cannot guarantee that these users and these users are the same, but we can guarantee that these movies and these movies together.",
            "So let's just focus on.",
            "Using the relationship between movies so it's so, think of it as a consisting of a taxonomy or ontology that relate the movies.",
            "So as a result maybe we can do better recommendation even though the data is very sparse."
        ],
        [
            "OK, so this is the intuition behind our work.",
            "Now if you look at Wikipedia pages about movies, we can see many."
        ],
        [
            "Any of these examples like Kung Fu Panda?",
            "There's already a page there, this is."
        ],
        [
            "A popular movie and some less popular, and I don't know, but maybe so there are there other."
        ],
        [
            "Things OK, there are other mix alright, so we can represent as I said, users and editing information as a 01.",
            "So one means this.",
            "This editor edited something about this movie and we have this matrix here.",
            "So the experiment we have here is really focused on a simple question.",
            "So we call this system Co. Edit OK, cool, edit.",
            "That name is rather long, so you can read the paper about it, but generally it means if we have the extra information about the Wikipedia, so X is the original data, then we can append a part of this matrix to this so you can see that the users are different, But the movies are.",
            "Align because they have the same name and so on.",
            "So when we do this matrix factorization, hopefully this is better than not using this additional information.",
            "OK, so this is the question.",
            "So even though the model looks rather simple, the focus here is to see whether we can actually scale it up.",
            "To consider minimum users, many many movies and do this in a practical setting and so as a result we want to introduce some distributed processing techniques such as map, reduce and scale it up and so this can be considered as one of the 1st works in the effort to scale up transfer learning."
        ],
        [
            "OK, so the model is a matrix factorization model where the loss function is defined based on both the wiki data and the target domain data where we want to reduce the difference between the.",
            "The predicted rating and the observed rating at the same time keep the model complexity in control."
        ],
        [
            "All.",
            "OK, so.",
            "'cause our focus here is on scale up.",
            "We really look at a very large data set.",
            "For example, the Netflix data set, the MOVIELENS data set, and the Wikipedia data set consisting of 11,000 movie articles.",
            "Typically is typically done.",
            "We have a 7030 split and consider a variety of density ratings in terms of you know how much.",
            "Of the whole matrix have an unknown value.",
            "OK, and because matrix factorization requires us to specify the number of latent factors here, we also work with a number of latent factors.",
            "I."
        ],
        [
            "Right so.",
            "So in the paper we have many many results.",
            "But to summarize the results in the high level overview, here we have the average feeling which is just to look at, you know, clustering, different movie groups and user groups and try to use their average as a filler to.",
            "So that gives a very high AE, which is very high error.",
            "Now there are other systems that we use, so this is the.",
            "Latent factor matrix factorization and this is to look at instead of looking at the social information we look at using the content information as a link between different movies.",
            "For example, whether two movie pages use the same word.",
            "And similarly we also used hyperlinks inherent in those movie pages and whether those links can provide relationship similarity.",
            "Between different movie pages and compare that to the social link.",
            "So overall we find that the social link actually has the strongest constraint which can push the error downward.",
            "OK, so it gives the lowest lowest error rate here."
        ],
        [
            "And this is true for a variety of target domain data density.",
            "OK, so as we as we see as the density increases in the target domain data, the error also drops."
        ],
        [
            "Four different."
        ],
        [
            "Different domains."
        ],
        [
            "And also, as I mentioned, you know added advantages that we can.",
            "We can do this in a very large scaled up manner.",
            "So in one setting we can achieve a almost linear speed."
        ],
        [
            "App."
        ],
        [
            "OK, so.",
            "So to summarize this work, so this work tries to use the Wikipedia editing information as the social.",
            "I a social knowledge which serve.",
            "As the source data for transfer learning and the target is is the collaborative filtering data OK, so simulate they are very different.",
            "So in a way they are heterogeneous in nature and we found that the social information actually is the most helpful as compared to other information such as pure information retrieval or or no source data.",
            "OK, so."
        ],
        [
            "Let me conclude my talk, so so far I have looked at a number of ways in which social media can help with transfer learning and the reason why we need transfer learning is because in the domain we are interested in, which is the target domain.",
            "We may not have so much supervision we may not have enough labels.",
            "We may not have enough ratings and so we have the so called data sparsity cold start problem.",
            "OK, which is a typical problem in practice, and so we have looked at using social media as a translator, and this is like the flicker and using another collaborative filtering reading data as the source data, or using Wikipedia as the source data.",
            "And in all of these we have some very positive experience.",
            "We also face a number of challenges, for example here we tried reading data.",
            "We tried social media.",
            "And Wikipedia are there other social knowledge that can be used for knowledge transfer?",
            "OK, like for example in this workshop we heard many talks about Twitter and so can Twitter be helpful for such information?",
            "Can the social relations in Facebook be helpful in in terms of knowledge transfer?",
            "OK, and also the way domain differences can play a role is also very very important.",
            "Now some theoretical work are under way to characterize the different domain differences so that when we choose a source domain we can make sure that the domain is indeed useful for the target domain data.",
            "And if you push that to the extreme.",
            "OK, we want to ask whether it's possible to ignore the consideration of source domain so everything can be a source domain and let the system decide in learning which one to use as the auxiliary data, which one cannot.",
            "OK, this is another talk at each chi.",
            "It's either tomorrow or day after tomorrow is called source selection.",
            "Free transfer learning.",
            "OK, so thank you very much."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Hola everybody, I just learned this Spanish word.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so to start with let me give you a brief review of the traditional machine learning paradigm so we know that machine learning can be considered as generally two phase process training and testing in the training process.",
                    "label": 1
                },
                {
                    "sent": "We have a collection of training data with a number of features and with outcome.",
                    "label": 0
                },
                {
                    "sent": "OK the class attribute.",
                    "label": 0
                },
                {
                    "sent": "So then based on this you train a classifier model.",
                    "label": 0
                },
                {
                    "sent": "Which can more or less correctly classify those training examples.",
                    "label": 0
                },
                {
                    "sent": "So being from Hong Kong, I used this analogy where a customer goes to see a fortune teller and the fortune teller can.",
                    "label": 0
                },
                {
                    "sent": "Based on your story, an features can give you a judgment can give you a decision whether you will have good fortune or not, and we can consider that as a.",
                    "label": 0
                },
                {
                    "sent": "A model OK and the training can be all the previous customers you have seen.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Then we can apply this to a new data.",
                    "label": 0
                },
                {
                    "sent": "But the problem is, what if the future customer that comes is a different entity from what you have seen before instead of a human, it's a dog.",
                    "label": 0
                },
                {
                    "sent": "Then the traditional machine learning models will be.",
                    "label": 1
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Rock You will not know what to do.",
                    "label": 0
                },
                {
                    "sent": "OK, so evaluating this scenario we found out that a major assumption made in the previous learning systems is that you know training and the future data, including the test data, must follow a number of restrictions.",
                    "label": 0
                },
                {
                    "sent": "OK, number one, they must follow the same distribution more or less and #2 they must be from the same feature space and there may be others but.",
                    "label": 1
                },
                {
                    "sent": "These are the major assumptions.",
                    "label": 0
                },
                {
                    "sent": "So what so the question is, what if these assumptions break?",
                    "label": 0
                },
                {
                    "sent": "OK, what if you know we face a new data with a different distribution different?",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Your space.",
                    "label": 0
                },
                {
                    "sent": "OK, in fact we see many such examples in real life, particularly when we apply learning methods to new application areas.",
                    "label": 0
                },
                {
                    "sent": "OK, so for example, if we use a lot of newspaper articles as the training data to train a text classifier, but then we apply to a very specific domain in medical domain, we may find that many of the natural language processing tasks will get very low performance.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, similarly when we have different feature spaces, say if you have the text as training data but we use images image features as the test data, then again the classifier will not work OK, so we have many such situations.",
                    "label": 0
                },
                {
                    "sent": "Now these are not contrived examples because in real life when we deal with a new domain, often we find we don't have enough labeled data or high quality labeled data.",
                    "label": 0
                },
                {
                    "sent": "OK, because to label these data in order to build the training data, we need to spend a lot of effort, money, effort, people, human power and so on in order to label them OK and all.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We don't have the luxury.",
                    "label": 0
                },
                {
                    "sent": "So we try to use a different paradigm from the traditional paradigm, in which instead of having just the learning system based on the training data as usual, we supply a number of other or what we call source domains.",
                    "label": 0
                },
                {
                    "sent": "Auxiliary domains which more or less have some similarity with the target domain, but they are different.",
                    "label": 0
                },
                {
                    "sent": "OK, the trick is.",
                    "label": 0
                },
                {
                    "sent": "We want to find out what's similar between the source domain and the target domain in order to improve learning performance in the target domain.",
                    "label": 1
                },
                {
                    "sent": "OK, and so we have a paradigm as illustrated in this matrix where we have, you know, as usual, the training and test data, but instead of just focusing on the target domain, we now have a new dimension which is the source domain and where the data can be either labeled or unlabeled.",
                    "label": 0
                },
                {
                    "sent": "So this.",
                    "label": 0
                },
                {
                    "sent": "Process of learning, including other information sources.",
                    "label": 1
                },
                {
                    "sent": "Is known as transfer learning, and it's a.",
                    "label": 0
                },
                {
                    "sent": "It's a very active research area in many different areas.",
                    "label": 0
                },
                {
                    "sent": "If you go to each client you can see you know, including this year.",
                    "label": 0
                },
                {
                    "sent": "You can see many papers if you go to computer vision conference you can see many papers if you go to a natural language processing and so on and so forth.",
                    "label": 0
                },
                {
                    "sent": "OK, now because of this sudden surge in interest, my student Sinope and I single panel is sitting over there.",
                    "label": 0
                },
                {
                    "sent": "We did a survey and we try to look at.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "At transfer learning the overall.",
                    "label": 1
                },
                {
                    "sent": "Picture of the landscape and try to make some sense of it.",
                    "label": 0
                },
                {
                    "sent": "And in order to help us determine you know what's been done and what what's still open.",
                    "label": 0
                },
                {
                    "sent": "OK, so we look at the Mini Mini.",
                    "label": 1
                },
                {
                    "sent": "Works in transfer learning and we figured out that one dimension in which we can partition the work is to look at the target data and see if the target data are labeled or not OK, so if the label data are available.",
                    "label": 0
                },
                {
                    "sent": "Then we go this branch and we look at inductive transfer learning, including inductive transfer learning when the source data OK, which is the next.",
                    "label": 1
                },
                {
                    "sent": "Dimension we locate the source data, include some labeled data or not, labeled data.",
                    "label": 0
                },
                {
                    "sent": "And likewise, when we don't have the label data then.",
                    "label": 0
                },
                {
                    "sent": "We go this direction and when the label data are available only in a source domain, we have the transductive transfer learning and so on.",
                    "label": 1
                },
                {
                    "sent": "So we have those yellow boxes at the bottom of the tree in the classification.",
                    "label": 0
                },
                {
                    "sent": "Each one is a body of.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Work OK so we have this survey posted online.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And people can also get this from signal Signal Path homepage.",
                    "label": 0
                },
                {
                    "sent": "You can just go and type transfer learning survey and get to this page and download this for free and we also have a collection of source code and data that we posted here so people can get these after the talk.",
                    "label": 0
                },
                {
                    "sent": "I can give you the links.",
                    "label": 0
                },
                {
                    "sent": "OK so that's a very very brief overview of.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "A survey in this topic so.",
                    "label": 0
                },
                {
                    "sent": "In this talk I'm going to divide my talk into several stages, but all the stages will focus on one thing, which is social media.",
                    "label": 0
                },
                {
                    "sent": "OK, so how social media can help recommendation systems?",
                    "label": 1
                },
                {
                    "sent": "How recommendation systems can benefit from other social behavior?",
                    "label": 0
                },
                {
                    "sent": "So the first topic I'm going to look at is how social media can serve as a bridge.",
                    "label": 0
                },
                {
                    "sent": "OK, to help in transfer learning.",
                    "label": 1
                },
                {
                    "sent": "OK, here we have a bridge in Spain.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so let's consider the problem I posted before.",
                    "label": 0
                },
                {
                    "sent": "Suppose I give you a lot of data.",
                    "label": 0
                },
                {
                    "sent": "OK, suppose you as a human intelligent human reader.",
                    "label": 0
                },
                {
                    "sent": "You have read much about fruits, OK, apples versus bananas.",
                    "label": 0
                },
                {
                    "sent": "Now can this knowledge which you read from text help you recognize pictures OK, when you're presented in the future data, some images of apples and bananas OK, you can say.",
                    "label": 0
                },
                {
                    "sent": "Well, obviously right.",
                    "label": 0
                },
                {
                    "sent": "The more you read, the more knowledgeable you are, and so the quicker you can learn to recognize pictures.",
                    "label": 0
                },
                {
                    "sent": "But after all, we don't know if that's true.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "If it's true, then so much the better because we have so much more labeled data in terms of text as compared to images.",
                    "label": 0
                },
                {
                    "sent": "OK, so so we have this as the auxiliary data and we have these as target data.",
                    "label": 0
                },
                {
                    "sent": "So since 2009 paper.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Dish in ACL, which is computational linguistics.",
                    "label": 0
                },
                {
                    "sent": "There's a serious works, including my own group and other groups working in this direction, and a theme here is using social web for transfer learning.",
                    "label": 0
                },
                {
                    "sent": "So let me give you one example for using social web for clustering.",
                    "label": 1
                },
                {
                    "sent": "OK, now suppose I have bunch of images I wish to cluster.",
                    "label": 0
                },
                {
                    "sent": "Now the images may be about apples and bananas.",
                    "label": 0
                },
                {
                    "sent": "And in clustering we don't have labeled data right?",
                    "label": 1
                },
                {
                    "sent": "So we can only work with the very very low level pixel image features.",
                    "label": 0
                },
                {
                    "sent": "And likewise, if you just use that those low level features.",
                    "label": 0
                },
                {
                    "sent": "It's likely that we don't get very good clustering results.",
                    "label": 0
                },
                {
                    "sent": "OK, now suppose we call V as the image features and F sorry V as images an F as image features.",
                    "label": 0
                },
                {
                    "sent": "Then we can build this relationship between images and their features, and if you can have a good probability understanding of the probability distribution.",
                    "label": 0
                },
                {
                    "sent": "Of those low level features such as safety features, then we can build a good cluster.",
                    "label": 0
                },
                {
                    "sent": "Now.",
                    "label": 0
                },
                {
                    "sent": "On the other hand, a good cluster actually corresponds to a good topic model of the images.",
                    "label": 0
                },
                {
                    "sent": "So the question is if we have, in addition of a bunch of text documents, can they help us?",
                    "label": 0
                },
                {
                    "sent": "Eating better topic model.",
                    "label": 0
                },
                {
                    "sent": "OK, so the trick here then is how to link a topic model we build for the text and the Top Model we can build for images by linking them together.",
                    "label": 0
                },
                {
                    "sent": "And here's where the bridge comes in and the bridge is social media.",
                    "label": 0
                },
                {
                    "sent": "OK, so we have so for example on Flickr we have many images which are tagged with text labels.",
                    "label": 0
                },
                {
                    "sent": "These are code tags.",
                    "label": 0
                },
                {
                    "sent": "Now these tags somehow is a collection of small documents which are text to description of the image we are looking at.",
                    "label": 0
                },
                {
                    "sent": "OK, so if you have lots and lots of loads and we have lots and lots of tags, then we can.",
                    "label": 0
                },
                {
                    "sent": "Relat these two OK in terms of our task, it is aligning using.",
                    "label": 0
                },
                {
                    "sent": "Using this to align the topics that we build for the documents and the topics that we have for the images.",
                    "label": 0
                },
                {
                    "sent": "Then it is the same set of topic which can boost the performance of the model.",
                    "label": 0
                },
                {
                    "sent": "OK so.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The result in this experiment there was a improvement in clustering performance.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now encouraged by this success, we went on to ask next question.",
                    "label": 0
                },
                {
                    "sent": "So suppose you have read a lot of text documents, say about Lions and apples and bananas.",
                    "label": 0
                },
                {
                    "sent": "Can you then help with the classification?",
                    "label": 0
                },
                {
                    "sent": "OK, and this involves supervised.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So here is an example.",
                    "label": 0
                },
                {
                    "sent": "OK, so let's say we have a few labeled images and they are so feel that they are not sufficient for building a good image classifier.",
                    "label": 1
                },
                {
                    "sent": "OK, so the test data consists of the.",
                    "label": 0
                },
                {
                    "sent": "Just the unlabeled images.",
                    "label": 0
                },
                {
                    "sent": "And in addition, suppose I give you 2 resources.",
                    "label": 0
                },
                {
                    "sent": "One is just like what we had just now.",
                    "label": 0
                },
                {
                    "sent": "Is the tag images say from Flickr or from other some other resources.",
                    "label": 0
                },
                {
                    "sent": "And on the other hand we have a large collection of auxiliary text data documents that are unlabeled, OK, these are unlabeled.",
                    "label": 0
                },
                {
                    "sent": "So then by putting this together we can still see some relationship between them.",
                    "label": 0
                },
                {
                    "sent": "OK, so for example as illustr.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Dated.",
                    "label": 0
                },
                {
                    "sent": "In this next image we can for the images we try to build a relation between images and tags and those are from the social web right and the documents which are unlabelled even though they are unlabeled, we still have a relation between documents and words, and on each we can use matrix decomposition to build their relevant latent semantic model.",
                    "label": 0
                },
                {
                    "sent": "OK, so for example for the images.",
                    "label": 0
                },
                {
                    "sent": "We have these models image times the latent.",
                    "label": 0
                },
                {
                    "sent": "Clusters and then and then their semantic model times the tags.",
                    "label": 0
                },
                {
                    "sent": "And here we have the documents.",
                    "label": 0
                },
                {
                    "sent": "Likewise in the same way now.",
                    "label": 1
                },
                {
                    "sent": "The only difficulty we have here, which is a major difficulty, is that these semantic latent models are not aligned, and we can try to impose a constraint to align them.",
                    "label": 0
                },
                {
                    "sent": "OK, the latent factors can be aligned.",
                    "label": 1
                },
                {
                    "sent": "So what the result is if we have these images which which are seemingly unrelated, we don't know how similar they are after this alignment, then we can have a better.",
                    "label": 0
                },
                {
                    "sent": "Relationship between them like they are all about exercising and exercising machine.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And so on.",
                    "label": 0
                },
                {
                    "sent": "So that's the intuition.",
                    "label": 0
                },
                {
                    "sent": "The mathematical model behind this is a matrix model where we simultaneously decompose the collection of images and the collection of documents and in the same time making sure that the latent Model V is the same.",
                    "label": 1
                },
                {
                    "sent": "OK, the latent semantic models are the same.",
                    "label": 1
                },
                {
                    "sent": "Then in the end we can accomplish this.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So then you know, because there are many unknowns, we can we have to use some trick to make sure the model is convex and can converge.",
                    "label": 0
                },
                {
                    "sent": "So the details will be omitted.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now, in the end we did a number of experiments to see if our intuition conform to the experiments.",
                    "label": 0
                },
                {
                    "sent": "OK, the first thing is if we increase the number of auxiliary documents, that is, you know, is it true if?",
                    "label": 0
                },
                {
                    "sent": "The more we read, the more knowledgeable we are.",
                    "label": 0
                },
                {
                    "sent": "OK, so here on this horizontal axis is the number of unlabeled documents that the system reads, and we can see that the performance, which is the accuracy increases sharply for the 1st 200 documents, and then it flattens out after that.",
                    "label": 1
                },
                {
                    "sent": "OK, so this tells us that yes, the more you read, the smarter you are.",
                    "label": 0
                },
                {
                    "sent": "But it's not true if you continue reading OK.",
                    "label": 0
                },
                {
                    "sent": "So after you reach 200, you can graduate.",
                    "label": 0
                },
                {
                    "sent": "That's why we graduate.",
                    "label": 0
                },
                {
                    "sent": "And then you flatten out and in fact it drops a little bit because there's more noise that are introduced, so you may get a little bit more stupid.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, and if you introduce some more tag images again, the performance increases after a certain point.",
                    "label": 0
                },
                {
                    "sent": "That is, the translator itself has to be of good.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Pretty good, enough quality, and likewise the more noise you introduce in the non relevant tag images the performance will drop.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so these are some preliminar.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Ray experiments, which are quite encouraging at 1st and again here we are trying to use the unlabeled text as the auxiliary data.",
                    "label": 0
                },
                {
                    "sent": "Use the social web as the bridge and we try to improve image classification, which is a very difficult task.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The second work I tried to introduce is.",
                    "label": 0
                },
                {
                    "sent": "In recent work done by my students on using social recommendations themselves as the source data in transfer learning.",
                    "label": 1
                },
                {
                    "sent": "OK, so the targets here are people and the relation between people and people and people and items and products in red.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Foundation systems.",
                    "label": 0
                },
                {
                    "sent": "OK, so because this workshop is about social media, social recommendation, so I don't need to give you much introduction here, but we are.",
                    "label": 0
                },
                {
                    "sent": "We should be all familiar with recommendation, right?",
                    "label": 0
                },
                {
                    "sent": "So if you type a query, you come in and there are a number of recommendations.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Can be given to you the familiar.",
                    "label": 0
                },
                {
                    "sent": "Workflow of Amazon.",
                    "label": 0
                },
                {
                    "sent": "If you write if you buy this book, these books are recommended to you.",
                    "label": 0
                },
                {
                    "sent": "And we all know the advantage of recommendation system is as opposed to a search based system is it's active.",
                    "label": 0
                },
                {
                    "sent": "It gives you recommendation.",
                    "label": 0
                },
                {
                    "sent": "Knowing something about you it can personalize.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It can be up and close.",
                    "label": 0
                },
                {
                    "sent": "OK, now in order to model a social recommendation systems, we can consider it as mathematically as a bipartite graph where one side we have a bunch of products, on the other we have people and we have the links indicating whether some users prefer some products and to what.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Agree.",
                    "label": 0
                },
                {
                    "sent": "OK, so if we consider them in matrix form, usually horizontally we consider users and vertically we consider items or products and the ratings here represents how much a user prefers a product.",
                    "label": 0
                },
                {
                    "sent": "And often we have many missing links and the missing ratings here are represented as question marks.",
                    "label": 0
                },
                {
                    "sent": "OK, so algorithm wise we have initially you know in the history of recommendation systems we have user based which is to consider similarity between users and to group the similar users together and symmetrically we can use item based and more recently people adopt model based.",
                    "label": 0
                },
                {
                    "sent": "It turns out model based methods are more formally R factor factorization methods.",
                    "label": 0
                },
                {
                    "sent": "Matrix factorization methods.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, now So what I try to focus on here is that in recommendation systems we often have the problem of data sparsity.",
                    "label": 0
                },
                {
                    "sent": "OK, which is when we don't have much ratings to start with and we want to train the model.",
                    "label": 0
                },
                {
                    "sent": "And apply to the test data.",
                    "label": 1
                },
                {
                    "sent": "The performance can be dramatically reduced if we have a very sparse matrix to start with.",
                    "label": 1
                },
                {
                    "sent": "OK, so cold start problem data sparsity problem.",
                    "label": 0
                },
                {
                    "sent": "These terms refer to this drop in performance and this is exactly the thing we tried to try to address.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So how we can address that from a transfer learning perspective is to consider this.",
                    "label": 0
                },
                {
                    "sent": "Suppose we have some new product line for selling books where we want to recommend books to people, but we don't have much data about books because maybe it's a new domain.",
                    "label": 0
                },
                {
                    "sent": "Maybe they are about new users.",
                    "label": 0
                },
                {
                    "sent": "OK, so then where we can look at is some similar domains, maybe on different products maybe?",
                    "label": 0
                },
                {
                    "sent": "Movies and because of the similarity or inherent similarity between either the product or the users.",
                    "label": 0
                },
                {
                    "sent": "Now, is it possible for us to transfer some knowledge to into the target domain to help alleviate the data sparsity problem?",
                    "label": 0
                },
                {
                    "sent": "OK, that's the question, OK.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is it possible so?",
                    "label": 0
                },
                {
                    "sent": "With this in mind, we did a number of experiments, try to there's ways in which an auxiliary domain can help.",
                    "label": 0
                },
                {
                    "sent": "OK, so this first work is codebook transfer and Billy sitting there in the yellow shirt he's.",
                    "label": 0
                },
                {
                    "sent": "The first author here.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now let me let me give you a brief description of this and being can answer questions thereafter.",
                    "label": 0
                },
                {
                    "sent": "OK, so if you look at.",
                    "label": 0
                },
                {
                    "sent": "If you look at a matrix representation of the rating record of a domain, we can often consider it as.",
                    "label": 0
                },
                {
                    "sent": "You know, because the user group and the item group are very large, we can use.",
                    "label": 0
                },
                {
                    "sent": "Usually consider it as consisting of a group of users that have similar tastes and a group of atoms that have similar features.",
                    "label": 0
                },
                {
                    "sent": "OK, so if we can group them together then we can compose a compressed version of the rating matrix, which can be more compactly be used to represent the original matrix.",
                    "label": 0
                },
                {
                    "sent": "OK, which is inside each cell is a smooth version of the rating and we can code that code book.",
                    "label": 0
                },
                {
                    "sent": "Now suppose we have a dense enough matrix.",
                    "label": 0
                },
                {
                    "sent": "Then we can build a very good code book.",
                    "label": 0
                },
                {
                    "sent": "The question is, can this codebook help solve the cold start problem for some other matrix?",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This OK so if you have a matrix, say in movies where we have many more ratings missing as compared to a books domain, then perhaps if we align their groups in a correct way.",
                    "label": 0
                },
                {
                    "sent": "OK the item group and the user group then we can because of their inherent similarity and relatedness.",
                    "label": 0
                },
                {
                    "sent": "We can use the dense version to help the sparse version.",
                    "label": 0
                },
                {
                    "sent": "OK, so that's the intuition behind this work.",
                    "label": 0
                },
                {
                    "sent": "So then the research questions remain OK.",
                    "label": 0
                },
                {
                    "sent": "So first of all, how do we relate the code books that we build for either domains?",
                    "label": 0
                },
                {
                    "sent": "OK, so that's the first question.",
                    "label": 0
                },
                {
                    "sent": "The second question is that you know how sparse does the either the target domain has to be in order for this improvement to be pronounced to be large enough, OK, and likewise, how much do we require the auxiliary domain?",
                    "label": 0
                },
                {
                    "sent": "To be dense?",
                    "label": 0
                },
                {
                    "sent": "OK, how much dense it must be in order to be helpful for transferring into the target domain.",
                    "label": 0
                },
                {
                    "sent": "So this question.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "These are preliminary answered.",
                    "label": 0
                },
                {
                    "sent": "In this, each paper a couple of years ago.",
                    "label": 0
                },
                {
                    "sent": "So to answer the first question, how to build the codebook we can first build a codebook in the source domain, assuming it's dense enough.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Then we take this into the target domain.",
                    "label": 0
                },
                {
                    "sent": "Here is the target domain in order to.",
                    "label": 0
                },
                {
                    "sent": "So this is the data for the target domain, which is very sparse now by itself, it doesn't allow us to build a good decomposition into a user latent feature space, and item latent feature space, but using the codebook that's transferred from the source domain, we can do a better job.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is what this formula is trying to.",
                    "label": 0
                },
                {
                    "sent": "Represent.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And indeed, in some small scale experiments involving a subset of users and subset of movies and allow the movies and books to transfer between each other.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We can see that the performance does help, especially one right.",
                    "label": 0
                },
                {
                    "sent": "So in each of these settings the CBT is the codebook transfer performs better, especially when the target domain is very, very sparse.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now following this work, we notice a number of limitations in this style of transfer.",
                    "label": 0
                },
                {
                    "sent": "So first of all, the original transfer work required that the readings be of the same range and that in reality we don't have to have this.",
                    "label": 1
                },
                {
                    "sent": "This assumption may not be always true, for example the source domain, maybe 01.",
                    "label": 0
                },
                {
                    "sent": "Maybe it's a link or not, rather than a rating.",
                    "label": 0
                },
                {
                    "sent": "OK, so we must allow this kind of heterogeneous rating to be transferred.",
                    "label": 0
                },
                {
                    "sent": "Furthermore, the scale is a limitation.",
                    "label": 0
                },
                {
                    "sent": "The scale that was in that experiment was was particularly small and also another limitation we try to break is it allowed only one, a single one auxiliary domain as the source.",
                    "label": 0
                },
                {
                    "sent": "And here we try to look at whether it's possible to transfer from a variety of different things.",
                    "label": 0
                },
                {
                    "sent": "Some are related, some are unrelated, and we don't know.",
                    "label": 0
                },
                {
                    "sent": "Ahead of time and whether we can decide how much to transfer at.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Actively OK, so this is the result of subsequent work.",
                    "label": 0
                },
                {
                    "sent": "So for example, in last year's triple AI, my students we could plan at all proposed a system called Cordon.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "8 system transfer and here they have to impose a number of restrictions such as you know the users or the items must correspond.",
                    "label": 0
                },
                {
                    "sent": "But even under this under this, so the advantage of imposing this constraint is to allow different content.",
                    "label": 0
                },
                {
                    "sent": "OK, so here the ratings are 01 and here the ratings are integers.",
                    "label": 0
                },
                {
                    "sent": "Allow this kind of transfer to happen.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And indeed it was allowed.",
                    "label": 0
                },
                {
                    "sent": "It performed much better and a follow up of that work is work.",
                    "label": 0
                },
                {
                    "sent": "Tomorrow OK, so here I'm allowed to do some advertisement.",
                    "label": 0
                },
                {
                    "sent": "Which is at 10:30.",
                    "label": 0
                },
                {
                    "sent": "My student will talk about a further work where.",
                    "label": 0
                },
                {
                    "sent": "He has",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "He allows him to genius.",
                    "label": 0
                },
                {
                    "sent": "Multiple domains to transfer to a target domain where one the there's partial overlap between the items and users.",
                    "label": 0
                },
                {
                    "sent": "He can do much better and can scale up to a much higher degree.",
                    "label": 0
                },
                {
                    "sent": "And here is a latent semantic model of his matrix factorization model, which is which is shown here, so I won't say much about this, but.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Welcome to attend that session.",
                    "label": 0
                },
                {
                    "sent": "OK, and Furthermore, as I just mentioned, there's even with the CST and CDT, the two previous systems there are still limitations and one limitation is that the transferring has to specify a source domain.",
                    "label": 0
                },
                {
                    "sent": "OK, what if the source domain is not a good source domain kind?",
                    "label": 0
                },
                {
                    "sent": "The system automatically detect that and in fact.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Wooden bins how?",
                    "label": 0
                },
                {
                    "sent": "Who is sitting at the corner?",
                    "label": 0
                },
                {
                    "sent": "There he tried to answer this using a method called adaptive transfer learning and in this work he used.",
                    "label": 1
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Gaussian process model to build a adaptation in the following sense.",
                    "label": 0
                },
                {
                    "sent": "OK, where we have a distance measure between a source domain and the target domain so that when this distance is small you do the transferring and when the distance is over a certain threshold you stop transferring.",
                    "label": 0
                },
                {
                    "sent": "So in the end here we have the we have the curve.",
                    "label": 0
                },
                {
                    "sent": "This is the error for transfer learning.",
                    "label": 0
                },
                {
                    "sent": "And here is the curve, which is a horizontal line for not transferring anything, and we wish to get the best of the two worlds in different settings.",
                    "label": 0
                },
                {
                    "sent": "OK, based on the distance between the two domains and using Gaussian process he was successful in demonstrating this.",
                    "label": 1
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "A number of domains.",
                    "label": 0
                },
                {
                    "sent": "And the last part of this talk.",
                    "label": 0
                },
                {
                    "sent": "Is related to this collaborative filtering in transferring, but here we try to use a different source data instead of using the same collaborative filtering domain rating or binary data.",
                    "label": 1
                },
                {
                    "sent": "Let's try to use Wikipedia, for example as the source domain and the target domain is.",
                    "label": 0
                },
                {
                    "sent": "The same is still the region domain, and we asked whether it's possible to transfer some knowledge.",
                    "label": 0
                },
                {
                    "sent": "Again, to help with the data sparsity problem.",
                    "label": 0
                },
                {
                    "sent": "OK, and this is the work done together with my student change.",
                    "label": 0
                },
                {
                    "sent": "Now.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So let's look at some details of this.",
                    "label": 0
                },
                {
                    "sent": "And this paper is also included in the workshop proceedings, so everybody can already get that from the web.",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so the motivation of this is the following.",
                    "label": 0
                },
                {
                    "sent": "OK, suppose we are interested in helping with recommendation, doing better recommendation.",
                    "label": 0
                },
                {
                    "sent": "Even one hour reading data is very very sparse.",
                    "label": 0
                },
                {
                    "sent": "OK, but suppose we don't have another rating domain to help us with, so let's turn to something that everybody has OK, which is the Wikipedia.",
                    "label": 0
                },
                {
                    "sent": "Now on the Wikipedia we have a lot of data which we can model.",
                    "label": 0
                },
                {
                    "sent": "As a bipartite graph of users and products, the products can be anything, can be a document, can be a event, and in this particular work we focus on Movies OK because then we can.",
                    "label": 0
                },
                {
                    "sent": "We can look at movies so we have movies here in the target domain and we look at the subset of Wikipedia web pages that are about movies.",
                    "label": 0
                },
                {
                    "sent": "And each of these pages have a number of editors.",
                    "label": 0
                },
                {
                    "sent": "And these editors are people who have spent their time and effort in describing this movie in commenting on this movie.",
                    "label": 0
                },
                {
                    "sent": "So in a way, they have given some readings on this movie and in another way we can look at whether the same user commented on two different movies and use this knowledge to link similar movies together.",
                    "label": 0
                },
                {
                    "sent": "OK, so then the intuition becomes this, even though we have a very sparse user movie rating matrix Now, it's almost like using Wikipedia.",
                    "label": 0
                },
                {
                    "sent": "We can relat some movies together and we can relate some users together.",
                    "label": 0
                },
                {
                    "sent": "OK, so symmetrically the movies link different users together now.",
                    "label": 0
                },
                {
                    "sent": "However, we cannot guarantee that these users and these users are the same, but we can guarantee that these movies and these movies together.",
                    "label": 0
                },
                {
                    "sent": "So let's just focus on.",
                    "label": 0
                },
                {
                    "sent": "Using the relationship between movies so it's so, think of it as a consisting of a taxonomy or ontology that relate the movies.",
                    "label": 0
                },
                {
                    "sent": "So as a result maybe we can do better recommendation even though the data is very sparse.",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so this is the intuition behind our work.",
                    "label": 0
                },
                {
                    "sent": "Now if you look at Wikipedia pages about movies, we can see many.",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Any of these examples like Kung Fu Panda?",
                    "label": 0
                },
                {
                    "sent": "There's already a page there, this is.",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "A popular movie and some less popular, and I don't know, but maybe so there are there other.",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Things OK, there are other mix alright, so we can represent as I said, users and editing information as a 01.",
                    "label": 0
                },
                {
                    "sent": "So one means this.",
                    "label": 0
                },
                {
                    "sent": "This editor edited something about this movie and we have this matrix here.",
                    "label": 0
                },
                {
                    "sent": "So the experiment we have here is really focused on a simple question.",
                    "label": 0
                },
                {
                    "sent": "So we call this system Co. Edit OK, cool, edit.",
                    "label": 0
                },
                {
                    "sent": "That name is rather long, so you can read the paper about it, but generally it means if we have the extra information about the Wikipedia, so X is the original data, then we can append a part of this matrix to this so you can see that the users are different, But the movies are.",
                    "label": 0
                },
                {
                    "sent": "Align because they have the same name and so on.",
                    "label": 0
                },
                {
                    "sent": "So when we do this matrix factorization, hopefully this is better than not using this additional information.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is the question.",
                    "label": 0
                },
                {
                    "sent": "So even though the model looks rather simple, the focus here is to see whether we can actually scale it up.",
                    "label": 0
                },
                {
                    "sent": "To consider minimum users, many many movies and do this in a practical setting and so as a result we want to introduce some distributed processing techniques such as map, reduce and scale it up and so this can be considered as one of the 1st works in the effort to scale up transfer learning.",
                    "label": 0
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so the model is a matrix factorization model where the loss function is defined based on both the wiki data and the target domain data where we want to reduce the difference between the.",
                    "label": 0
                },
                {
                    "sent": "The predicted rating and the observed rating at the same time keep the model complexity in control.",
                    "label": 0
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "All.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "'cause our focus here is on scale up.",
                    "label": 0
                },
                {
                    "sent": "We really look at a very large data set.",
                    "label": 0
                },
                {
                    "sent": "For example, the Netflix data set, the MOVIELENS data set, and the Wikipedia data set consisting of 11,000 movie articles.",
                    "label": 0
                },
                {
                    "sent": "Typically is typically done.",
                    "label": 0
                },
                {
                    "sent": "We have a 7030 split and consider a variety of density ratings in terms of you know how much.",
                    "label": 0
                },
                {
                    "sent": "Of the whole matrix have an unknown value.",
                    "label": 0
                },
                {
                    "sent": "OK, and because matrix factorization requires us to specify the number of latent factors here, we also work with a number of latent factors.",
                    "label": 0
                },
                {
                    "sent": "I.",
                    "label": 0
                }
            ]
        },
        "clip_55": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Right so.",
                    "label": 0
                },
                {
                    "sent": "So in the paper we have many many results.",
                    "label": 0
                },
                {
                    "sent": "But to summarize the results in the high level overview, here we have the average feeling which is just to look at, you know, clustering, different movie groups and user groups and try to use their average as a filler to.",
                    "label": 0
                },
                {
                    "sent": "So that gives a very high AE, which is very high error.",
                    "label": 0
                },
                {
                    "sent": "Now there are other systems that we use, so this is the.",
                    "label": 0
                },
                {
                    "sent": "Latent factor matrix factorization and this is to look at instead of looking at the social information we look at using the content information as a link between different movies.",
                    "label": 0
                },
                {
                    "sent": "For example, whether two movie pages use the same word.",
                    "label": 0
                },
                {
                    "sent": "And similarly we also used hyperlinks inherent in those movie pages and whether those links can provide relationship similarity.",
                    "label": 0
                },
                {
                    "sent": "Between different movie pages and compare that to the social link.",
                    "label": 0
                },
                {
                    "sent": "So overall we find that the social link actually has the strongest constraint which can push the error downward.",
                    "label": 0
                },
                {
                    "sent": "OK, so it gives the lowest lowest error rate here.",
                    "label": 0
                }
            ]
        },
        "clip_56": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And this is true for a variety of target domain data density.",
                    "label": 0
                },
                {
                    "sent": "OK, so as we as we see as the density increases in the target domain data, the error also drops.",
                    "label": 0
                }
            ]
        },
        "clip_57": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Four different.",
                    "label": 0
                }
            ]
        },
        "clip_58": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Different domains.",
                    "label": 0
                }
            ]
        },
        "clip_59": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And also, as I mentioned, you know added advantages that we can.",
                    "label": 0
                },
                {
                    "sent": "We can do this in a very large scaled up manner.",
                    "label": 0
                },
                {
                    "sent": "So in one setting we can achieve a almost linear speed.",
                    "label": 0
                }
            ]
        },
        "clip_60": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "App.",
                    "label": 0
                }
            ]
        },
        "clip_61": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "So to summarize this work, so this work tries to use the Wikipedia editing information as the social.",
                    "label": 0
                },
                {
                    "sent": "I a social knowledge which serve.",
                    "label": 0
                },
                {
                    "sent": "As the source data for transfer learning and the target is is the collaborative filtering data OK, so simulate they are very different.",
                    "label": 1
                },
                {
                    "sent": "So in a way they are heterogeneous in nature and we found that the social information actually is the most helpful as compared to other information such as pure information retrieval or or no source data.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                }
            ]
        },
        "clip_62": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Let me conclude my talk, so so far I have looked at a number of ways in which social media can help with transfer learning and the reason why we need transfer learning is because in the domain we are interested in, which is the target domain.",
                    "label": 1
                },
                {
                    "sent": "We may not have so much supervision we may not have enough labels.",
                    "label": 0
                },
                {
                    "sent": "We may not have enough ratings and so we have the so called data sparsity cold start problem.",
                    "label": 0
                },
                {
                    "sent": "OK, which is a typical problem in practice, and so we have looked at using social media as a translator, and this is like the flicker and using another collaborative filtering reading data as the source data, or using Wikipedia as the source data.",
                    "label": 0
                },
                {
                    "sent": "And in all of these we have some very positive experience.",
                    "label": 0
                },
                {
                    "sent": "We also face a number of challenges, for example here we tried reading data.",
                    "label": 0
                },
                {
                    "sent": "We tried social media.",
                    "label": 0
                },
                {
                    "sent": "And Wikipedia are there other social knowledge that can be used for knowledge transfer?",
                    "label": 1
                },
                {
                    "sent": "OK, like for example in this workshop we heard many talks about Twitter and so can Twitter be helpful for such information?",
                    "label": 0
                },
                {
                    "sent": "Can the social relations in Facebook be helpful in in terms of knowledge transfer?",
                    "label": 0
                },
                {
                    "sent": "OK, and also the way domain differences can play a role is also very very important.",
                    "label": 0
                },
                {
                    "sent": "Now some theoretical work are under way to characterize the different domain differences so that when we choose a source domain we can make sure that the domain is indeed useful for the target domain data.",
                    "label": 0
                },
                {
                    "sent": "And if you push that to the extreme.",
                    "label": 0
                },
                {
                    "sent": "OK, we want to ask whether it's possible to ignore the consideration of source domain so everything can be a source domain and let the system decide in learning which one to use as the auxiliary data, which one cannot.",
                    "label": 0
                },
                {
                    "sent": "OK, this is another talk at each chi.",
                    "label": 0
                },
                {
                    "sent": "It's either tomorrow or day after tomorrow is called source selection.",
                    "label": 0
                },
                {
                    "sent": "Free transfer learning.",
                    "label": 0
                },
                {
                    "sent": "OK, so thank you very much.",
                    "label": 0
                }
            ]
        }
    }
}