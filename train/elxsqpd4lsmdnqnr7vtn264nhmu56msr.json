{
    "id": "elxsqpd4lsmdnqnr7vtn264nhmu56msr",
    "title": "The Development of the AMI System for the Transcription of Speech in Meetings",
    "info": {
        "author": [
            "Thomas Hain, Speech and Hearing Group, Department of Computer Science, University of Sheffield"
        ],
        "published": "Feb. 25, 2007",
        "recorded": "June 2005",
        "category": [
            "Top->Computer Science->Speech Analysis"
        ]
    },
    "url": "http://videolectures.net/mlmi04uk_hain_dasts/",
    "segmentation": [
        [
            "Yeah.",
            "OK, so let's make starting this afternoon session and this session is about speech recognition, speech to text transcription.",
            "And there's two talks in the session and the first talk."
        ],
        [
            "Will be by Thomas Hanging from the University of Sheffield, but the leader of the party millions and will be talking about the Army speech recognition system.",
            "Thanks so hold on to this table now.",
            "So.",
            "It looks like I should be doing capitalization other than speech recognition.",
            "If I look at the title anyway, so this is about the system that we submitted for participation in these evaluations.",
            "And yes, it's it's.",
            "It's of course not by far not only me, but people from Bruno at Edinburgh.",
            "University of 2010.",
            "And video of course.",
            "Who has participated and built the system.",
            "And so if you have specific questions on specific parts, I might."
        ],
        [
            "Correct those questions too to the people actually done the work.",
            "Oh yeah, I have to.",
            "OK, so briefly when I tried to do is basically run you through through basically the system architecture which we came up with in the end and the various components.",
            "So this is the language modeling side the linguistic side, the front end side acoustic modeling side and of course lots of results.",
            "A graveyard of numbers at the end.",
            "This is about conference room data where."
        ],
        [
            "Mostly targeted the system on and be able to actually have submitted to the seminar task, and so you basically have results in the end, so the starting point of for us in terms of developing that system was essentially a lots of toolkits which are publicly or are publicly available services.",
            "HDK this is Brian SDK Toolkit which is in development and of course the srim two.",
            "Could we also had access to?",
            "Cambridge University decoder.",
            "HD code, which is supposed to be released at some point in the future.",
            "Publicly available we have.",
            "We had some additional training segmentations and transcripts for CTS which were supposed to be clean units.",
            "Indexing your format and lots of data.",
            "Of course lots of data, unprocessed, unnormalized, all of that, and that's basically the starting point.",
            "What we ended up with was that so this is the final system.",
            "Our architecture as we submit it and that is a system that operates essentially in six passes.",
            "So you basically go down here and then down here.",
            "So if I briefly talk you through this system architecture has been used both for contributions to the item task and the MDM task.",
            "So in both cases essentially what differs is the acoustic models that are inside some of these blue boxes or represented by these blue boxes.",
            "And of course the front end processing itself.",
            "But the rest of the structure."
        ],
        [
            "Remains the same, so from the processing I'll talk about that in a second lender is a first pass, which is essentially the task to get a first guess of what of the person actually set over the people actually said in the meetings, and that is used for two purposes, one on the one side.",
            "It is used for re segmenting the input.",
            "So basically trying to adjust the boundaries to fit the appropriate silence colors and then do we deal with.",
            "Estimation vocal tract length normalization for speaker adaptation, which we then use in the second pass and then we do another decoding pass and we use a bit more sophisticated acoustic link path.",
            "So here we used.",
            "We use maximum likelihood trained models.",
            "Here we actually used discriminatively trained triphone models.",
            "We used of course vocal tract length normalization.",
            "We used an LDA matrix.",
            "I'll talk about that as a front end feature transform.",
            "But again also in terms of the language model side we use trigram.",
            "Language models so that so you will see later on that the performance difference between this pass and this pass is huge.",
            "But I mean there is only the information, we only goes from here goes only into the retail estimation.",
            "There's nothing more to that, so after that we do MLLR dictation and the whole aim is to generate up this passes to generate lattices and lattices which are big, so that we can also apply later on higher order language models.",
            "This is especially for Gram language models, so so.",
            "We do decoding here with the bigram language model because we."
        ],
        [
            "I'm interested in the actual performance here, but only in the lattices, so they are generated, and then those lattices go into internal lattice expansion stage.",
            "This is past four and outcome a set of four gram lattices.",
            "For the for the.",
            "For their conference room meeting.",
            "So we have actually built meeting resource specific language model, so we have a language model tuned for any data.",
            "We have a language model to inform this data and so on, and refused those in order to generate these lattices in the next step we basically use those lattices and do another re scoring pass where we do another set of adaptation using amela and essentially the same.",
            "The same model says as we had it before.",
            "We also use pronunciation probabilities in that step and produce another set of lattices which going to the last step, which is the compact, these lattices into confusion networks, and from these new confusion networks we do minimum moderate decoding and essentially do an alignment of the output of that and get the final result.",
            "So that's essentially how the system works in terms of complexity of the models.",
            "There's a slight difference.",
            "For system development reasons, between which model sets?"
        ],
        [
            "Price of model sets we used here between HRM and MDM for the item system.",
            "We had had the models as they are written here for the MDM system.",
            "We actually didn't have the discriminatively trained models yet at that point in time, so at this point in time there were only ML trained.",
            "VTL end models are used in that stage and the only discriminatively trained models came in later on.",
            "So that's the only difference.",
            "Right, so I'm not going to talk about a lot about dictionary and vocabulary selection.",
            "I've done for those of you who have been here yesterday, I've done that.",
            "The take home message.",
            "We are dictionary is based on on.",
            "The units industry in which we augmented and quite a lot by using another.",
            "It is here.",
            "12 Eleven 1600 words, and we've done that with with using something that gave us a prediction of what the pronunciation was, so that the manual checking of the pronunciation was actually very straightforward and the system was actually performing very well.",
            "In that respect, we have a weird situation that we have a dictionary.",
            "We using the dictionary if you ask."
        ],
        [
            "Pronunciations and British spellings.",
            "That is sort of the trade off between between doing this task and doing the army task, but we also have mappings between between different spellings, so that's OK and recovery selected by essentially doing taking the words from the meetings domains and putting it to make a 50K dictionary using broadcast news data.",
            "Language modeling data.",
            "While we used try to use everything we could get our hands on and you can see that there's a lot of the usual suspects there.",
            "CTS Resources There is Fisher data.",
            "There's a lot of web data.",
            "There's the block of broadcast news data.",
            "BBC data have four data.",
            "Newswire data also enter on the email data, even though it didn't help a lot and.",
            "Those fight Bible so and of course meeting data meeting.",
            "Of course, the training data since either the amount is really small and also then web data.",
            "Like the meeting data that is officially available from the University of Washington, but also we collected our own websites for the for the Army data set and we followed essentially the same routines.",
            "We use the tools that were provided by the University of Washington.",
            "The only difference we we did was essentially we tried.",
            "We did a collection as they suggest as the original protocol suggests, but we didn't get a lot of improvement from that.",
            "So what we did is we."
        ],
        [
            "Set of looking for all the possible programs or combinations of programs.",
            "We looked at specifically at 4 grams that were not in any of the other language models we had before and that made actually quite a lot of difference in terms of the rating for this data.",
            "When we interpolate all these language models, but so the weight length from 3% to 20% and especially important, this wasn't chill.",
            "did I get so?",
            "This is the seminar data I'll get back to that later.",
            "Right, so again, for people who have been yesterday, this is, there are not very new in terms of complexity is what you can expect is consider the perplexities of language models which we have tuned for this specific resources and you can see the perplexities in the main diagonal.",
            "That yes, you get mostly the lowest complexity for data that is specifically tuned to that particular task.",
            "I mean it is very important for the Army data, but there also the ISL data seems to have.",
            "Show a strong difference to all the other datasets, so basically that's the language models we used in decoding, so we did it on a per meeting meeting.",
            "Resource Base is now in terms of the language modeling gain we got in the development was we got like half a percent, going from trigram to program language models and we got another half a percent using the meeting resource specific language models, but there seems to be very well.",
            "There's no game, I think on the HM.",
            "Data at all."
        ],
        [
            "So, so we might have been over tuning a bit on the update.",
            "We get like half a percent, so it's it's a mixed picture we see on the eval from that.",
            "Right, so the the only box that was left out was where the front ends from before and so.",
            "So we have of course different different front ends for the independent headset microphone data and then for the MDM type of data.",
            "The approach on the item data.",
            "While there is quite a lot of difference in terms of what actually comes here in there in terms of quality of microphones as well, some of them are really only captured the some of those microphone seems to really only capture that speaker.",
            "Then I agree it's it's, it's.",
            "Very much like a CTS task, but other microphones seem to well record half the room in equal loudness, so there's quite a lot of variability in those as well.",
            "So we first do the echo cancellation, which on the multi channel basis and then we do an MLP based.",
            "Uh, segmentation.",
            "I'll talk about that in a second and after that we actually also do some smoothing of the boundaries of the relatively roles of the raw segments we get out of out of that."
        ],
        [
            "Mentation to again fit our silence padding needs.",
            "For the MDM stuff it is that is the following.",
            "Essentially the approach that exceed has used last year.",
            "We do delay some delay Baxter estimation and delete some beamforming.",
            "Also what we should have done is users do speaker segmentation and clustering, but we haven't done so.",
            "So very grateful for EXE for providing us with that information.",
            "So so basically for that part of the MDM front end we have our input from the Sri system.",
            "So having all those two systems in both cases what we do is we compute features standard.",
            "HTK style features MFP S plus the C0."
        ],
        [
            "And then the 1st and 2nd order derivative.",
            "So we arrive at the 39 dimensional feature vector and we do capture mean variance normalization on a personal basis.",
            "Question 4.",
            "You did not take into account the topology of the microphone array when you knew it.",
            "Nobody.",
            "We did some experiment, preliminary experiments on any data about didn't get very far run out of time.",
            "So for the item processing.",
            "We so so the first part was the adaptive echo cancellation suggested by message made in 89 and but the difference to that is we use of course multiple reference channels and we some of these channels actually have quite as Q in terms of their not perfectly time aligned.",
            "So we have an automatic calculation of the time alignment before we actually do it.",
            "And then we also modified the system to do a sample rather than a per block update.",
            "So once we've done that, and.",
            "Then we take that echo Council.",
            "Output and we do normal feature extraction services.",
            "14 MF PLP coefficients, and then additional features for following a paper by Wrigley, which is basically including features on that basis.",
            "So this is essentially the ratio of energy between the main channel and all the other channels.",
            "Kurtosis oev the signal and and a measurement that gives you a measurement of voicing us of the signal in that place.",
            "So we use those additional.",
            "Features as well.",
            "And all of that was basically used in two class multilayer perception which took in 31 input frames at a time and five hidden units.",
            "Of course you have to output classes and all of this was trained on 20 hours of speech originally I think we had a wider wider window in mind, but we couldn't get the system finished to train.",
            "Right, so and then the output of the MLP is essentially used in every style.",
            "Decoding using scale likelihoods with minimum duration constraints Hoffer."
        ],
        [
            "Second insertion penalties tutein false alarm false rejects So what you see here is false alarm false rejects rates on the RTO five data and.",
            "See also the associated word error rates of automatic versus manual segmentation, and you can see that for those systems where we have large for these situations where we have large false reject."
        ],
        [
            "We also clearly have a large difference between between in terms of word error rate between automatic and manual segmentation, so this place is like here.",
            "Where else do we have a large difference?",
            "Well, relatively large difference on the XY data and then where this number is is relatively low.",
            "The difference is actually relatively small, so in this raw sense it seems to correlate well with further a performance the frame accuracies.",
            "And the M4 steps.",
            "First step gain calibration followed by noise filtering."
        ],
        [
            "This is again very very intent.",
            "Very similar to what?",
            "We have been talking about so this is to compensate for the different audio levels, audio recording levels, noise filtering is using Wiener filtering, so you get the noise estimate from the trend of minimum energy frames on the whole channel, and they do it on a per channel basis and then you do the delay estimation which is on the basis of 1 second frames.",
            "But we use like the overlapping so we have like a half a second frameshift.",
            "But the scale factors we use, so we use scale factors for the various contributions and these scale factors are essentially energy ratios of 1 channel versus or versus one reference channel, which we essentially arbitrarily pick and delay estimation is by peak picking, so there's no additional filtering going on, and then we do the beamforming.",
            "This is essentially."
        ],
        [
            "Multiplying we doing this in the frequency domain, multiplying the spectrum input from each channel with a matrix which is represented by this.",
            "This is the same short time for you transform that you used is the priority orchestral coefficient calculation.",
            "So essentially puts no.",
            "It's actually cooked out in audio again, so we generate audio essentially and do it in order and do another stage C analysis do the beamforming, then you go back to a time signal.",
            "Yes, OK.",
            "Right, so OK on four for MDM be also trained on MDM data.",
            "So we basically generated audio files in the way I just described and the question of course is how do you select data for training and because you don't want to overlap speech because that is going to destroy the performance.",
            "So we essentially did an alignment on the HM.",
            "Channel recordings and trying to remove all the overlaps, and it's quite interesting.",
            "Sort of how much you lose if you go down that route.",
            "If we go to two."
        ],
        [
            "I think the.",
            "Nearest town responder, but relatively far away from that, has a certain size that is your already lose like 40 hours of the data you get down to 62 hours.",
            "If you do, it's just on word boundaries without requiring the word boundaries tax.",
            "They have silences between words.",
            "You get, you retain a bit more of the data.",
            "What is also interesting that you still retain a lot of the proportion of the silence in the data, so that doesn't go away.",
            "So we did another step on that basis and basically trying to cut off too much silence."
        ],
        [
            "I haven't dated because I mean if you look at those ratios this is.",
            "This is actually not very very very good for for variety of reasons and capture mean normalization and so on.",
            "So that is essentially the setup we used.",
            "We only essentially train on 63 hours of data on MDM.",
            "Right, so just just some issues that came up specific with that data.",
            "We do vocal tract length normalization and no specifics and that the only thing that we found interesting was that there was seemed to have been an issue with with cut off frequency.",
            "Normally we have this linear piecewise.",
            "We're using the HTK style linear piecewise approach.",
            "Which she uses."
        ],
        [
            "The frequency for for for smoothing out at upper frequencies and it seemed to be the case that basically if we use the cutoff frequency versus first closer to the to the to the sampling rate dictated bandwidth, we get it actually got poorer performance then we when we used like a narrowband type cut off frequency and that's what we use continuously out.",
            "So it seems to tell us that we should concentrate on lower frequencies and essentially flatten out whatever happens in the higher frequencies so that was.",
            "The only interesting effect on vocal tract, otherwise it it seems to work like well, similar to similar performance gains too.",
            "Work on CTS data now.",
            "Front end feature transform.",
            "I'm front end feature transform is used in H LDA matrix.",
            "Again this is following the standard approach.",
            "Tested by kuma.",
            "The only difference here is that we use a smooth is SH LDA which essentially tries to smooth the covariance estimates with a global within class covariance.",
            "So this is moving and HRD approach we found with an LDA approach and that gave that worked reasonably well.",
            "Actually, that approach wasn't even used.",
            "Instead of this type of interpolation it was a map style which again improved things a bit further.",
            "See so so.",
            "The alphas are dependent essentially on the occupation counts rather than being globally tuned factors.",
            "So typically we get from that 1/2% word error rate improvement.",
            "The major HLD matrix reduces a 52 dimensional feature space down to 39 dimensional feature space.",
            "Again, if you want to know more about it, Lucas can tell you a lot about this and then also there's code available in the SDK toolkit.",
            "One thing we got relatively late, but Luckily into our system was minimum phone error training for the following.",
            "Paper from or the thesis from Dan Povey.",
            "And so we used at both large and MDM data.",
            "Implementational details.",
            "Of course, it is lattice based and and the way it is implemented, it is first producing phone or model lattices doing a minimization process and then in the in the forward backward pass.",
            "It actually does it to forward because it does a full search of the lattice, but it uses the time constraints from which are in which.",
            "Put into the lattices on individual phone boundaries so it is a full forward backward, but using time constraints.",
            "All of these things like acoustic acoustic scaling, unigram language models are standard to this technique.",
            "Also, the updates include ice moving with a factor of 2 of 25, and we found that we needed to do about 10 iterations of MP training to basically finally converge.",
            "Right, so again, I'm running a bit late so, but let's quickly look at what these techniques are.",
            "Just talked about, give in terms of performance improvements.",
            "If you start off with an L train system CTS adapted 32.2%, you get used with the line.",
            "You get another 2%.",
            "It turns out that it doesn't really matter if you actually use CTS adaptation on the eval data or if you just train on meeting data in our system.",
            "If you search LDA we get another 1 1/2%.",
            "And from especially in this case we didn't get any again.",
            "But if you look at the fine detail here, you can see that the picture is actually mixed and from MP we get a massive 3% improvement.",
            "Right confusion network decoding that is the last part of our system where we just taking lattices and create this confusion.",
            "Networks using the Sri Toolkit implementation and we found later on that we get quite a nice gain from that.",
            "But if you look closely, it was actually a gain we got from doing the alignment and correcting the word times that come out of our recognized in the 1st place rather than rather than the confusion networks alone.",
            "So if you compare the numbers with and without alignment here.",
            "You see that effectively you get a .6 game percent gain from from confusion, network decoding, HRM in our case, and only .2 from from doing this on on MDM.",
            "So maybe there is room for improvement.",
            "Overall system results.",
            "Yeah, this is the great world of numbers.",
            "This is numbers for all the passes, both IG M&MDM and of course you have substitution, deletion insertions.",
            "You have male female results and you have the results here for all the individual meeting sources.",
            "So if you just concentrate on this column here, you can see that going from the first pass which I already said down to the LastPass you have like.",
            "And 11% difference, but only only this step here which includes VTL N which includes SH LDA which includes MP trained models already.",
            "You get quite a long way and and off the whole distance, so following this path along you basically get the degradation here because I mean you do adaptation, but then on the other side here there is a bigram language model used, which is much weaker.",
            "So if you go back to 4 gram language model, you basically improve on the.",
            "On the previous number, this past that didn't seem to work very well at all, and then you get this gain from doing the alignment and the confusion network in the end.",
            "Interesting to also see that the deletion rates and in this case the difference between between male and female speech.",
            "If you look at MDM story in terms of the progression through the pass is very similar.",
            "I mean also do you have an 11% absolute difference here?",
            "And if you look at the differences?",
            "The whole picture is very similar, but the only thing that is in a way interesting that here you have a huge difference between male and females, because here you don't.",
            "But I don't know what the reason for that is.",
            "We clearly seem to have a problem with mediator in this particular case, and there are probably many reasons we already heard someone from the exit of traffic.",
            "We can make up our minds on that, right?",
            "So I'm not going to talk about the segmentation and.",
            "And we can take the questions to that offline.",
            "We compared our system to reference segmentation, but essentially only show you the results.",
            "We also get an electron data.",
            "So speciality here.",
            "I ran the system as described for the conference meeting room data exactly the same way.",
            "We didn't do any special is.",
            "The only thing that is different.",
            "We used in a language model we which we collected in the style I just described.",
            "So this is another 1717 million words and we found that this language will reduce the complexity of the chill DEF data from 100 and 79212.",
            "So this was quite a dramatic reduction in complexity, and that obviously seems to have worked reasonably well because.",
            "The performance gains you see from the individual steps are quite good adaptation.",
            "I mean, you see a huge difference between pass one and pass two and I am not so much on the MDM case.",
            "So, so we're quite pleased that our system is relatively generic to that.",
            "To complete.",
            "It's.",
            "I think we've done a relatively decent first system, which also works is reasonable general to generalize to lecture in data.",
            "Um, of course there's lots of room for improvement and and front end is certainly the first part we should look at.",
            "Using more data like not using 63 hours for in the case of MDM for example, but also in an HM case you making real users of other data would be really beneficial.",
            "We haven't actually spent a lot of time tuning our system, so this is this is a way to go and dictionary and lots of other things I think, but they definitely need ultimately faster system because basically this system I described at the moment seems to run at 150 times real time.",
            "So questions.",
            "I have a theory about your agenda result.",
            "So of course there is about only 1/3 of the training data is being arrested, male, so there's a big gender balance.",
            "But then in the end the end training set throughout all of that because they talk over each other, so we can.",
            "You have to be careful.",
            "Because it's.",
            "But it's.",
            "The camping right because you're squashing separately.",
            "But but but would you segments get removed?",
            "The fact that it's in the training data rather than in the in the actual scoring.",
            "OK.",
            "They will.",
            "Yes.",
            "How did you train your FDM models to determine training on their distant data without any normal throat rainbow match?",
            "I mean the original models are.",
            "Trained using standard forward maximum likelihood Commonwealth training on trusty MDM data data so you have parallel recordings for five channels at the same time, so that would make even throw away some of the data that we played more than 60 hours of data.",
            "Or do you cite 60 hours with five channels each?",
            "No no no no no no.",
            "This is MDM process data with the MDM front end.",
            "So you basically all this stuff is an enhancement type approach.",
            "Generally take five channels or whatever channels in the generated one channel and that's your training data.",
            "OK, thanks very much."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "OK, so let's make starting this afternoon session and this session is about speech recognition, speech to text transcription.",
                    "label": 0
                },
                {
                    "sent": "And there's two talks in the session and the first talk.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Will be by Thomas Hanging from the University of Sheffield, but the leader of the party millions and will be talking about the Army speech recognition system.",
                    "label": 0
                },
                {
                    "sent": "Thanks so hold on to this table now.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "It looks like I should be doing capitalization other than speech recognition.",
                    "label": 0
                },
                {
                    "sent": "If I look at the title anyway, so this is about the system that we submitted for participation in these evaluations.",
                    "label": 0
                },
                {
                    "sent": "And yes, it's it's.",
                    "label": 0
                },
                {
                    "sent": "It's of course not by far not only me, but people from Bruno at Edinburgh.",
                    "label": 0
                },
                {
                    "sent": "University of 2010.",
                    "label": 0
                },
                {
                    "sent": "And video of course.",
                    "label": 0
                },
                {
                    "sent": "Who has participated and built the system.",
                    "label": 0
                },
                {
                    "sent": "And so if you have specific questions on specific parts, I might.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Correct those questions too to the people actually done the work.",
                    "label": 0
                },
                {
                    "sent": "Oh yeah, I have to.",
                    "label": 0
                },
                {
                    "sent": "OK, so briefly when I tried to do is basically run you through through basically the system architecture which we came up with in the end and the various components.",
                    "label": 0
                },
                {
                    "sent": "So this is the language modeling side the linguistic side, the front end side acoustic modeling side and of course lots of results.",
                    "label": 0
                },
                {
                    "sent": "A graveyard of numbers at the end.",
                    "label": 0
                },
                {
                    "sent": "This is about conference room data where.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Mostly targeted the system on and be able to actually have submitted to the seminar task, and so you basically have results in the end, so the starting point of for us in terms of developing that system was essentially a lots of toolkits which are publicly or are publicly available services.",
                    "label": 0
                },
                {
                    "sent": "HDK this is Brian SDK Toolkit which is in development and of course the srim two.",
                    "label": 0
                },
                {
                    "sent": "Could we also had access to?",
                    "label": 0
                },
                {
                    "sent": "Cambridge University decoder.",
                    "label": 0
                },
                {
                    "sent": "HD code, which is supposed to be released at some point in the future.",
                    "label": 0
                },
                {
                    "sent": "Publicly available we have.",
                    "label": 0
                },
                {
                    "sent": "We had some additional training segmentations and transcripts for CTS which were supposed to be clean units.",
                    "label": 0
                },
                {
                    "sent": "Indexing your format and lots of data.",
                    "label": 0
                },
                {
                    "sent": "Of course lots of data, unprocessed, unnormalized, all of that, and that's basically the starting point.",
                    "label": 0
                },
                {
                    "sent": "What we ended up with was that so this is the final system.",
                    "label": 0
                },
                {
                    "sent": "Our architecture as we submit it and that is a system that operates essentially in six passes.",
                    "label": 0
                },
                {
                    "sent": "So you basically go down here and then down here.",
                    "label": 0
                },
                {
                    "sent": "So if I briefly talk you through this system architecture has been used both for contributions to the item task and the MDM task.",
                    "label": 0
                },
                {
                    "sent": "So in both cases essentially what differs is the acoustic models that are inside some of these blue boxes or represented by these blue boxes.",
                    "label": 0
                },
                {
                    "sent": "And of course the front end processing itself.",
                    "label": 0
                },
                {
                    "sent": "But the rest of the structure.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Remains the same, so from the processing I'll talk about that in a second lender is a first pass, which is essentially the task to get a first guess of what of the person actually set over the people actually said in the meetings, and that is used for two purposes, one on the one side.",
                    "label": 0
                },
                {
                    "sent": "It is used for re segmenting the input.",
                    "label": 0
                },
                {
                    "sent": "So basically trying to adjust the boundaries to fit the appropriate silence colors and then do we deal with.",
                    "label": 0
                },
                {
                    "sent": "Estimation vocal tract length normalization for speaker adaptation, which we then use in the second pass and then we do another decoding pass and we use a bit more sophisticated acoustic link path.",
                    "label": 0
                },
                {
                    "sent": "So here we used.",
                    "label": 0
                },
                {
                    "sent": "We use maximum likelihood trained models.",
                    "label": 0
                },
                {
                    "sent": "Here we actually used discriminatively trained triphone models.",
                    "label": 0
                },
                {
                    "sent": "We used of course vocal tract length normalization.",
                    "label": 0
                },
                {
                    "sent": "We used an LDA matrix.",
                    "label": 0
                },
                {
                    "sent": "I'll talk about that as a front end feature transform.",
                    "label": 0
                },
                {
                    "sent": "But again also in terms of the language model side we use trigram.",
                    "label": 0
                },
                {
                    "sent": "Language models so that so you will see later on that the performance difference between this pass and this pass is huge.",
                    "label": 0
                },
                {
                    "sent": "But I mean there is only the information, we only goes from here goes only into the retail estimation.",
                    "label": 0
                },
                {
                    "sent": "There's nothing more to that, so after that we do MLLR dictation and the whole aim is to generate up this passes to generate lattices and lattices which are big, so that we can also apply later on higher order language models.",
                    "label": 0
                },
                {
                    "sent": "This is especially for Gram language models, so so.",
                    "label": 0
                },
                {
                    "sent": "We do decoding here with the bigram language model because we.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I'm interested in the actual performance here, but only in the lattices, so they are generated, and then those lattices go into internal lattice expansion stage.",
                    "label": 0
                },
                {
                    "sent": "This is past four and outcome a set of four gram lattices.",
                    "label": 0
                },
                {
                    "sent": "For the for the.",
                    "label": 0
                },
                {
                    "sent": "For their conference room meeting.",
                    "label": 0
                },
                {
                    "sent": "So we have actually built meeting resource specific language model, so we have a language model tuned for any data.",
                    "label": 0
                },
                {
                    "sent": "We have a language model to inform this data and so on, and refused those in order to generate these lattices in the next step we basically use those lattices and do another re scoring pass where we do another set of adaptation using amela and essentially the same.",
                    "label": 0
                },
                {
                    "sent": "The same model says as we had it before.",
                    "label": 0
                },
                {
                    "sent": "We also use pronunciation probabilities in that step and produce another set of lattices which going to the last step, which is the compact, these lattices into confusion networks, and from these new confusion networks we do minimum moderate decoding and essentially do an alignment of the output of that and get the final result.",
                    "label": 0
                },
                {
                    "sent": "So that's essentially how the system works in terms of complexity of the models.",
                    "label": 0
                },
                {
                    "sent": "There's a slight difference.",
                    "label": 0
                },
                {
                    "sent": "For system development reasons, between which model sets?",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Price of model sets we used here between HRM and MDM for the item system.",
                    "label": 0
                },
                {
                    "sent": "We had had the models as they are written here for the MDM system.",
                    "label": 0
                },
                {
                    "sent": "We actually didn't have the discriminatively trained models yet at that point in time, so at this point in time there were only ML trained.",
                    "label": 0
                },
                {
                    "sent": "VTL end models are used in that stage and the only discriminatively trained models came in later on.",
                    "label": 0
                },
                {
                    "sent": "So that's the only difference.",
                    "label": 0
                },
                {
                    "sent": "Right, so I'm not going to talk about a lot about dictionary and vocabulary selection.",
                    "label": 0
                },
                {
                    "sent": "I've done for those of you who have been here yesterday, I've done that.",
                    "label": 0
                },
                {
                    "sent": "The take home message.",
                    "label": 0
                },
                {
                    "sent": "We are dictionary is based on on.",
                    "label": 0
                },
                {
                    "sent": "The units industry in which we augmented and quite a lot by using another.",
                    "label": 0
                },
                {
                    "sent": "It is here.",
                    "label": 0
                },
                {
                    "sent": "12 Eleven 1600 words, and we've done that with with using something that gave us a prediction of what the pronunciation was, so that the manual checking of the pronunciation was actually very straightforward and the system was actually performing very well.",
                    "label": 0
                },
                {
                    "sent": "In that respect, we have a weird situation that we have a dictionary.",
                    "label": 0
                },
                {
                    "sent": "We using the dictionary if you ask.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Pronunciations and British spellings.",
                    "label": 0
                },
                {
                    "sent": "That is sort of the trade off between between doing this task and doing the army task, but we also have mappings between between different spellings, so that's OK and recovery selected by essentially doing taking the words from the meetings domains and putting it to make a 50K dictionary using broadcast news data.",
                    "label": 0
                },
                {
                    "sent": "Language modeling data.",
                    "label": 0
                },
                {
                    "sent": "While we used try to use everything we could get our hands on and you can see that there's a lot of the usual suspects there.",
                    "label": 0
                },
                {
                    "sent": "CTS Resources There is Fisher data.",
                    "label": 0
                },
                {
                    "sent": "There's a lot of web data.",
                    "label": 0
                },
                {
                    "sent": "There's the block of broadcast news data.",
                    "label": 1
                },
                {
                    "sent": "BBC data have four data.",
                    "label": 0
                },
                {
                    "sent": "Newswire data also enter on the email data, even though it didn't help a lot and.",
                    "label": 0
                },
                {
                    "sent": "Those fight Bible so and of course meeting data meeting.",
                    "label": 0
                },
                {
                    "sent": "Of course, the training data since either the amount is really small and also then web data.",
                    "label": 0
                },
                {
                    "sent": "Like the meeting data that is officially available from the University of Washington, but also we collected our own websites for the for the Army data set and we followed essentially the same routines.",
                    "label": 0
                },
                {
                    "sent": "We use the tools that were provided by the University of Washington.",
                    "label": 0
                },
                {
                    "sent": "The only difference we we did was essentially we tried.",
                    "label": 0
                },
                {
                    "sent": "We did a collection as they suggest as the original protocol suggests, but we didn't get a lot of improvement from that.",
                    "label": 0
                },
                {
                    "sent": "So what we did is we.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Set of looking for all the possible programs or combinations of programs.",
                    "label": 0
                },
                {
                    "sent": "We looked at specifically at 4 grams that were not in any of the other language models we had before and that made actually quite a lot of difference in terms of the rating for this data.",
                    "label": 0
                },
                {
                    "sent": "When we interpolate all these language models, but so the weight length from 3% to 20% and especially important, this wasn't chill.",
                    "label": 0
                },
                {
                    "sent": "did I get so?",
                    "label": 0
                },
                {
                    "sent": "This is the seminar data I'll get back to that later.",
                    "label": 0
                },
                {
                    "sent": "Right, so again, for people who have been yesterday, this is, there are not very new in terms of complexity is what you can expect is consider the perplexities of language models which we have tuned for this specific resources and you can see the perplexities in the main diagonal.",
                    "label": 0
                },
                {
                    "sent": "That yes, you get mostly the lowest complexity for data that is specifically tuned to that particular task.",
                    "label": 0
                },
                {
                    "sent": "I mean it is very important for the Army data, but there also the ISL data seems to have.",
                    "label": 0
                },
                {
                    "sent": "Show a strong difference to all the other datasets, so basically that's the language models we used in decoding, so we did it on a per meeting meeting.",
                    "label": 0
                },
                {
                    "sent": "Resource Base is now in terms of the language modeling gain we got in the development was we got like half a percent, going from trigram to program language models and we got another half a percent using the meeting resource specific language models, but there seems to be very well.",
                    "label": 0
                },
                {
                    "sent": "There's no game, I think on the HM.",
                    "label": 0
                },
                {
                    "sent": "Data at all.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So, so we might have been over tuning a bit on the update.",
                    "label": 0
                },
                {
                    "sent": "We get like half a percent, so it's it's a mixed picture we see on the eval from that.",
                    "label": 0
                },
                {
                    "sent": "Right, so the the only box that was left out was where the front ends from before and so.",
                    "label": 0
                },
                {
                    "sent": "So we have of course different different front ends for the independent headset microphone data and then for the MDM type of data.",
                    "label": 0
                },
                {
                    "sent": "The approach on the item data.",
                    "label": 0
                },
                {
                    "sent": "While there is quite a lot of difference in terms of what actually comes here in there in terms of quality of microphones as well, some of them are really only captured the some of those microphone seems to really only capture that speaker.",
                    "label": 0
                },
                {
                    "sent": "Then I agree it's it's, it's.",
                    "label": 0
                },
                {
                    "sent": "Very much like a CTS task, but other microphones seem to well record half the room in equal loudness, so there's quite a lot of variability in those as well.",
                    "label": 0
                },
                {
                    "sent": "So we first do the echo cancellation, which on the multi channel basis and then we do an MLP based.",
                    "label": 0
                },
                {
                    "sent": "Uh, segmentation.",
                    "label": 0
                },
                {
                    "sent": "I'll talk about that in a second and after that we actually also do some smoothing of the boundaries of the relatively roles of the raw segments we get out of out of that.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Mentation to again fit our silence padding needs.",
                    "label": 0
                },
                {
                    "sent": "For the MDM stuff it is that is the following.",
                    "label": 0
                },
                {
                    "sent": "Essentially the approach that exceed has used last year.",
                    "label": 0
                },
                {
                    "sent": "We do delay some delay Baxter estimation and delete some beamforming.",
                    "label": 0
                },
                {
                    "sent": "Also what we should have done is users do speaker segmentation and clustering, but we haven't done so.",
                    "label": 0
                },
                {
                    "sent": "So very grateful for EXE for providing us with that information.",
                    "label": 0
                },
                {
                    "sent": "So so basically for that part of the MDM front end we have our input from the Sri system.",
                    "label": 0
                },
                {
                    "sent": "So having all those two systems in both cases what we do is we compute features standard.",
                    "label": 0
                },
                {
                    "sent": "HTK style features MFP S plus the C0.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then the 1st and 2nd order derivative.",
                    "label": 0
                },
                {
                    "sent": "So we arrive at the 39 dimensional feature vector and we do capture mean variance normalization on a personal basis.",
                    "label": 0
                },
                {
                    "sent": "Question 4.",
                    "label": 0
                },
                {
                    "sent": "You did not take into account the topology of the microphone array when you knew it.",
                    "label": 0
                },
                {
                    "sent": "Nobody.",
                    "label": 0
                },
                {
                    "sent": "We did some experiment, preliminary experiments on any data about didn't get very far run out of time.",
                    "label": 0
                },
                {
                    "sent": "So for the item processing.",
                    "label": 0
                },
                {
                    "sent": "We so so the first part was the adaptive echo cancellation suggested by message made in 89 and but the difference to that is we use of course multiple reference channels and we some of these channels actually have quite as Q in terms of their not perfectly time aligned.",
                    "label": 0
                },
                {
                    "sent": "So we have an automatic calculation of the time alignment before we actually do it.",
                    "label": 0
                },
                {
                    "sent": "And then we also modified the system to do a sample rather than a per block update.",
                    "label": 0
                },
                {
                    "sent": "So once we've done that, and.",
                    "label": 0
                },
                {
                    "sent": "Then we take that echo Council.",
                    "label": 0
                },
                {
                    "sent": "Output and we do normal feature extraction services.",
                    "label": 0
                },
                {
                    "sent": "14 MF PLP coefficients, and then additional features for following a paper by Wrigley, which is basically including features on that basis.",
                    "label": 0
                },
                {
                    "sent": "So this is essentially the ratio of energy between the main channel and all the other channels.",
                    "label": 0
                },
                {
                    "sent": "Kurtosis oev the signal and and a measurement that gives you a measurement of voicing us of the signal in that place.",
                    "label": 0
                },
                {
                    "sent": "So we use those additional.",
                    "label": 0
                },
                {
                    "sent": "Features as well.",
                    "label": 0
                },
                {
                    "sent": "And all of that was basically used in two class multilayer perception which took in 31 input frames at a time and five hidden units.",
                    "label": 0
                },
                {
                    "sent": "Of course you have to output classes and all of this was trained on 20 hours of speech originally I think we had a wider wider window in mind, but we couldn't get the system finished to train.",
                    "label": 0
                },
                {
                    "sent": "Right, so and then the output of the MLP is essentially used in every style.",
                    "label": 0
                },
                {
                    "sent": "Decoding using scale likelihoods with minimum duration constraints Hoffer.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Second insertion penalties tutein false alarm false rejects So what you see here is false alarm false rejects rates on the RTO five data and.",
                    "label": 0
                },
                {
                    "sent": "See also the associated word error rates of automatic versus manual segmentation, and you can see that for those systems where we have large for these situations where we have large false reject.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We also clearly have a large difference between between in terms of word error rate between automatic and manual segmentation, so this place is like here.",
                    "label": 0
                },
                {
                    "sent": "Where else do we have a large difference?",
                    "label": 0
                },
                {
                    "sent": "Well, relatively large difference on the XY data and then where this number is is relatively low.",
                    "label": 0
                },
                {
                    "sent": "The difference is actually relatively small, so in this raw sense it seems to correlate well with further a performance the frame accuracies.",
                    "label": 0
                },
                {
                    "sent": "And the M4 steps.",
                    "label": 0
                },
                {
                    "sent": "First step gain calibration followed by noise filtering.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is again very very intent.",
                    "label": 0
                },
                {
                    "sent": "Very similar to what?",
                    "label": 0
                },
                {
                    "sent": "We have been talking about so this is to compensate for the different audio levels, audio recording levels, noise filtering is using Wiener filtering, so you get the noise estimate from the trend of minimum energy frames on the whole channel, and they do it on a per channel basis and then you do the delay estimation which is on the basis of 1 second frames.",
                    "label": 0
                },
                {
                    "sent": "But we use like the overlapping so we have like a half a second frameshift.",
                    "label": 0
                },
                {
                    "sent": "But the scale factors we use, so we use scale factors for the various contributions and these scale factors are essentially energy ratios of 1 channel versus or versus one reference channel, which we essentially arbitrarily pick and delay estimation is by peak picking, so there's no additional filtering going on, and then we do the beamforming.",
                    "label": 0
                },
                {
                    "sent": "This is essentially.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Multiplying we doing this in the frequency domain, multiplying the spectrum input from each channel with a matrix which is represented by this.",
                    "label": 0
                },
                {
                    "sent": "This is the same short time for you transform that you used is the priority orchestral coefficient calculation.",
                    "label": 0
                },
                {
                    "sent": "So essentially puts no.",
                    "label": 0
                },
                {
                    "sent": "It's actually cooked out in audio again, so we generate audio essentially and do it in order and do another stage C analysis do the beamforming, then you go back to a time signal.",
                    "label": 0
                },
                {
                    "sent": "Yes, OK.",
                    "label": 0
                },
                {
                    "sent": "Right, so OK on four for MDM be also trained on MDM data.",
                    "label": 0
                },
                {
                    "sent": "So we basically generated audio files in the way I just described and the question of course is how do you select data for training and because you don't want to overlap speech because that is going to destroy the performance.",
                    "label": 0
                },
                {
                    "sent": "So we essentially did an alignment on the HM.",
                    "label": 0
                },
                {
                    "sent": "Channel recordings and trying to remove all the overlaps, and it's quite interesting.",
                    "label": 0
                },
                {
                    "sent": "Sort of how much you lose if you go down that route.",
                    "label": 0
                },
                {
                    "sent": "If we go to two.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I think the.",
                    "label": 0
                },
                {
                    "sent": "Nearest town responder, but relatively far away from that, has a certain size that is your already lose like 40 hours of the data you get down to 62 hours.",
                    "label": 0
                },
                {
                    "sent": "If you do, it's just on word boundaries without requiring the word boundaries tax.",
                    "label": 0
                },
                {
                    "sent": "They have silences between words.",
                    "label": 0
                },
                {
                    "sent": "You get, you retain a bit more of the data.",
                    "label": 0
                },
                {
                    "sent": "What is also interesting that you still retain a lot of the proportion of the silence in the data, so that doesn't go away.",
                    "label": 0
                },
                {
                    "sent": "So we did another step on that basis and basically trying to cut off too much silence.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I haven't dated because I mean if you look at those ratios this is.",
                    "label": 0
                },
                {
                    "sent": "This is actually not very very very good for for variety of reasons and capture mean normalization and so on.",
                    "label": 0
                },
                {
                    "sent": "So that is essentially the setup we used.",
                    "label": 0
                },
                {
                    "sent": "We only essentially train on 63 hours of data on MDM.",
                    "label": 0
                },
                {
                    "sent": "Right, so just just some issues that came up specific with that data.",
                    "label": 0
                },
                {
                    "sent": "We do vocal tract length normalization and no specifics and that the only thing that we found interesting was that there was seemed to have been an issue with with cut off frequency.",
                    "label": 0
                },
                {
                    "sent": "Normally we have this linear piecewise.",
                    "label": 0
                },
                {
                    "sent": "We're using the HTK style linear piecewise approach.",
                    "label": 0
                },
                {
                    "sent": "Which she uses.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The frequency for for for smoothing out at upper frequencies and it seemed to be the case that basically if we use the cutoff frequency versus first closer to the to the to the sampling rate dictated bandwidth, we get it actually got poorer performance then we when we used like a narrowband type cut off frequency and that's what we use continuously out.",
                    "label": 0
                },
                {
                    "sent": "So it seems to tell us that we should concentrate on lower frequencies and essentially flatten out whatever happens in the higher frequencies so that was.",
                    "label": 0
                },
                {
                    "sent": "The only interesting effect on vocal tract, otherwise it it seems to work like well, similar to similar performance gains too.",
                    "label": 0
                },
                {
                    "sent": "Work on CTS data now.",
                    "label": 0
                },
                {
                    "sent": "Front end feature transform.",
                    "label": 0
                },
                {
                    "sent": "I'm front end feature transform is used in H LDA matrix.",
                    "label": 0
                },
                {
                    "sent": "Again this is following the standard approach.",
                    "label": 0
                },
                {
                    "sent": "Tested by kuma.",
                    "label": 0
                },
                {
                    "sent": "The only difference here is that we use a smooth is SH LDA which essentially tries to smooth the covariance estimates with a global within class covariance.",
                    "label": 0
                },
                {
                    "sent": "So this is moving and HRD approach we found with an LDA approach and that gave that worked reasonably well.",
                    "label": 0
                },
                {
                    "sent": "Actually, that approach wasn't even used.",
                    "label": 0
                },
                {
                    "sent": "Instead of this type of interpolation it was a map style which again improved things a bit further.",
                    "label": 0
                },
                {
                    "sent": "See so so.",
                    "label": 0
                },
                {
                    "sent": "The alphas are dependent essentially on the occupation counts rather than being globally tuned factors.",
                    "label": 0
                },
                {
                    "sent": "So typically we get from that 1/2% word error rate improvement.",
                    "label": 0
                },
                {
                    "sent": "The major HLD matrix reduces a 52 dimensional feature space down to 39 dimensional feature space.",
                    "label": 0
                },
                {
                    "sent": "Again, if you want to know more about it, Lucas can tell you a lot about this and then also there's code available in the SDK toolkit.",
                    "label": 0
                },
                {
                    "sent": "One thing we got relatively late, but Luckily into our system was minimum phone error training for the following.",
                    "label": 0
                },
                {
                    "sent": "Paper from or the thesis from Dan Povey.",
                    "label": 0
                },
                {
                    "sent": "And so we used at both large and MDM data.",
                    "label": 0
                },
                {
                    "sent": "Implementational details.",
                    "label": 0
                },
                {
                    "sent": "Of course, it is lattice based and and the way it is implemented, it is first producing phone or model lattices doing a minimization process and then in the in the forward backward pass.",
                    "label": 0
                },
                {
                    "sent": "It actually does it to forward because it does a full search of the lattice, but it uses the time constraints from which are in which.",
                    "label": 0
                },
                {
                    "sent": "Put into the lattices on individual phone boundaries so it is a full forward backward, but using time constraints.",
                    "label": 0
                },
                {
                    "sent": "All of these things like acoustic acoustic scaling, unigram language models are standard to this technique.",
                    "label": 0
                },
                {
                    "sent": "Also, the updates include ice moving with a factor of 2 of 25, and we found that we needed to do about 10 iterations of MP training to basically finally converge.",
                    "label": 0
                },
                {
                    "sent": "Right, so again, I'm running a bit late so, but let's quickly look at what these techniques are.",
                    "label": 0
                },
                {
                    "sent": "Just talked about, give in terms of performance improvements.",
                    "label": 0
                },
                {
                    "sent": "If you start off with an L train system CTS adapted 32.2%, you get used with the line.",
                    "label": 0
                },
                {
                    "sent": "You get another 2%.",
                    "label": 0
                },
                {
                    "sent": "It turns out that it doesn't really matter if you actually use CTS adaptation on the eval data or if you just train on meeting data in our system.",
                    "label": 0
                },
                {
                    "sent": "If you search LDA we get another 1 1/2%.",
                    "label": 0
                },
                {
                    "sent": "And from especially in this case we didn't get any again.",
                    "label": 0
                },
                {
                    "sent": "But if you look at the fine detail here, you can see that the picture is actually mixed and from MP we get a massive 3% improvement.",
                    "label": 0
                },
                {
                    "sent": "Right confusion network decoding that is the last part of our system where we just taking lattices and create this confusion.",
                    "label": 0
                },
                {
                    "sent": "Networks using the Sri Toolkit implementation and we found later on that we get quite a nice gain from that.",
                    "label": 0
                },
                {
                    "sent": "But if you look closely, it was actually a gain we got from doing the alignment and correcting the word times that come out of our recognized in the 1st place rather than rather than the confusion networks alone.",
                    "label": 0
                },
                {
                    "sent": "So if you compare the numbers with and without alignment here.",
                    "label": 0
                },
                {
                    "sent": "You see that effectively you get a .6 game percent gain from from confusion, network decoding, HRM in our case, and only .2 from from doing this on on MDM.",
                    "label": 0
                },
                {
                    "sent": "So maybe there is room for improvement.",
                    "label": 0
                },
                {
                    "sent": "Overall system results.",
                    "label": 0
                },
                {
                    "sent": "Yeah, this is the great world of numbers.",
                    "label": 0
                },
                {
                    "sent": "This is numbers for all the passes, both IG M&MDM and of course you have substitution, deletion insertions.",
                    "label": 0
                },
                {
                    "sent": "You have male female results and you have the results here for all the individual meeting sources.",
                    "label": 0
                },
                {
                    "sent": "So if you just concentrate on this column here, you can see that going from the first pass which I already said down to the LastPass you have like.",
                    "label": 0
                },
                {
                    "sent": "And 11% difference, but only only this step here which includes VTL N which includes SH LDA which includes MP trained models already.",
                    "label": 0
                },
                {
                    "sent": "You get quite a long way and and off the whole distance, so following this path along you basically get the degradation here because I mean you do adaptation, but then on the other side here there is a bigram language model used, which is much weaker.",
                    "label": 0
                },
                {
                    "sent": "So if you go back to 4 gram language model, you basically improve on the.",
                    "label": 0
                },
                {
                    "sent": "On the previous number, this past that didn't seem to work very well at all, and then you get this gain from doing the alignment and the confusion network in the end.",
                    "label": 0
                },
                {
                    "sent": "Interesting to also see that the deletion rates and in this case the difference between between male and female speech.",
                    "label": 0
                },
                {
                    "sent": "If you look at MDM story in terms of the progression through the pass is very similar.",
                    "label": 0
                },
                {
                    "sent": "I mean also do you have an 11% absolute difference here?",
                    "label": 0
                },
                {
                    "sent": "And if you look at the differences?",
                    "label": 0
                },
                {
                    "sent": "The whole picture is very similar, but the only thing that is in a way interesting that here you have a huge difference between male and females, because here you don't.",
                    "label": 0
                },
                {
                    "sent": "But I don't know what the reason for that is.",
                    "label": 0
                },
                {
                    "sent": "We clearly seem to have a problem with mediator in this particular case, and there are probably many reasons we already heard someone from the exit of traffic.",
                    "label": 0
                },
                {
                    "sent": "We can make up our minds on that, right?",
                    "label": 0
                },
                {
                    "sent": "So I'm not going to talk about the segmentation and.",
                    "label": 0
                },
                {
                    "sent": "And we can take the questions to that offline.",
                    "label": 0
                },
                {
                    "sent": "We compared our system to reference segmentation, but essentially only show you the results.",
                    "label": 0
                },
                {
                    "sent": "We also get an electron data.",
                    "label": 0
                },
                {
                    "sent": "So speciality here.",
                    "label": 0
                },
                {
                    "sent": "I ran the system as described for the conference meeting room data exactly the same way.",
                    "label": 0
                },
                {
                    "sent": "We didn't do any special is.",
                    "label": 0
                },
                {
                    "sent": "The only thing that is different.",
                    "label": 0
                },
                {
                    "sent": "We used in a language model we which we collected in the style I just described.",
                    "label": 0
                },
                {
                    "sent": "So this is another 1717 million words and we found that this language will reduce the complexity of the chill DEF data from 100 and 79212.",
                    "label": 0
                },
                {
                    "sent": "So this was quite a dramatic reduction in complexity, and that obviously seems to have worked reasonably well because.",
                    "label": 0
                },
                {
                    "sent": "The performance gains you see from the individual steps are quite good adaptation.",
                    "label": 0
                },
                {
                    "sent": "I mean, you see a huge difference between pass one and pass two and I am not so much on the MDM case.",
                    "label": 0
                },
                {
                    "sent": "So, so we're quite pleased that our system is relatively generic to that.",
                    "label": 0
                },
                {
                    "sent": "To complete.",
                    "label": 0
                },
                {
                    "sent": "It's.",
                    "label": 0
                },
                {
                    "sent": "I think we've done a relatively decent first system, which also works is reasonable general to generalize to lecture in data.",
                    "label": 0
                },
                {
                    "sent": "Um, of course there's lots of room for improvement and and front end is certainly the first part we should look at.",
                    "label": 0
                },
                {
                    "sent": "Using more data like not using 63 hours for in the case of MDM for example, but also in an HM case you making real users of other data would be really beneficial.",
                    "label": 0
                },
                {
                    "sent": "We haven't actually spent a lot of time tuning our system, so this is this is a way to go and dictionary and lots of other things I think, but they definitely need ultimately faster system because basically this system I described at the moment seems to run at 150 times real time.",
                    "label": 0
                },
                {
                    "sent": "So questions.",
                    "label": 0
                },
                {
                    "sent": "I have a theory about your agenda result.",
                    "label": 0
                },
                {
                    "sent": "So of course there is about only 1/3 of the training data is being arrested, male, so there's a big gender balance.",
                    "label": 0
                },
                {
                    "sent": "But then in the end the end training set throughout all of that because they talk over each other, so we can.",
                    "label": 0
                },
                {
                    "sent": "You have to be careful.",
                    "label": 0
                },
                {
                    "sent": "Because it's.",
                    "label": 0
                },
                {
                    "sent": "But it's.",
                    "label": 0
                },
                {
                    "sent": "The camping right because you're squashing separately.",
                    "label": 0
                },
                {
                    "sent": "But but but would you segments get removed?",
                    "label": 0
                },
                {
                    "sent": "The fact that it's in the training data rather than in the in the actual scoring.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "They will.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "How did you train your FDM models to determine training on their distant data without any normal throat rainbow match?",
                    "label": 0
                },
                {
                    "sent": "I mean the original models are.",
                    "label": 0
                },
                {
                    "sent": "Trained using standard forward maximum likelihood Commonwealth training on trusty MDM data data so you have parallel recordings for five channels at the same time, so that would make even throw away some of the data that we played more than 60 hours of data.",
                    "label": 0
                },
                {
                    "sent": "Or do you cite 60 hours with five channels each?",
                    "label": 0
                },
                {
                    "sent": "No no no no no no.",
                    "label": 0
                },
                {
                    "sent": "This is MDM process data with the MDM front end.",
                    "label": 0
                },
                {
                    "sent": "So you basically all this stuff is an enhancement type approach.",
                    "label": 0
                },
                {
                    "sent": "Generally take five channels or whatever channels in the generated one channel and that's your training data.",
                    "label": 0
                },
                {
                    "sent": "OK, thanks very much.",
                    "label": 0
                }
            ]
        }
    }
}