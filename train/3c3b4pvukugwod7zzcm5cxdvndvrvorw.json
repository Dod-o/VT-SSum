{
    "id": "3c3b4pvukugwod7zzcm5cxdvndvrvorw",
    "title": "DeFacto - Temporal and multilingual Deep Fact Validation",
    "info": {
        "author": [
            "Axel-Cyrille Ngonga Ngomo, University of Leipzig"
        ],
        "published": "Nov. 10, 2016",
        "recorded": "October 2016",
        "category": [
            "Top->Computer Science->Semantic Web"
        ]
    },
    "url": "http://videolectures.net/iswc2016_ngonga_ngomo_defacto/",
    "segmentation": [
        [
            "My greetings to you all for those who don't know me, my name is Axel from the University of Leipzig in Germany and from the Institute for Applied Informatics.",
            "And this is work that was mainly done by my PhD student, Daniel Gerber, together with Diego estivation, Sleeman, Norman Spearman, Ricardo Uzbek and rainy spec."
        ],
        [
            "So, did you know that Lily Aldridge is married?"
        ],
        [
            "To the whole band, the Kings of Leon.",
            "Or"
        ],
        [
            "Or that Arthur Shrewsbury death place was the English cricket team and you have plenty."
        ],
        [
            "Facts like that on the linked open data web, for example, Michelle Obama is married to Barack Obama, but also to his presidency, which by the way started when he was born.",
            "And yeah, you can be born in a sport called lacrosse.",
            "There's also situated called that name and so on and so forth.",
            "So there's plenty of information in on the link data web that does not reflect the reality that we see in the real world, so that this information that will call false throughout."
        ],
        [
            "To talk, you have created this huge compendium of data like more than 130 billion trip billion facts really.",
            "And a lot of that data is generated automatically by extracting information from other sources.",
            "The major problem is, given the mere sized amount of information that we have, it is impossible to check it manually.",
            "So basically to go through each triple and check whether what we see in reality is reflected in that triple, and that's the whole problem that the factor tries to tackle what we pay."
        ],
        [
            "Pose is a framework that recalled a deep fat validation framework deep because we basically tried to analyze to basically go into the text into text that provides support for the fax or does not provide support.",
            "So what we do?",
            "Is we use verbalization, which was the topic of the keynote this morning.",
            "So that came out really helped and machine learning to find evidence that support facts for being true.",
            "It is important to state here that we do not check for facts being forced becausw it is very tricky to find evidence for something being false, but we're working on it.",
            "That's basically upcoming work.",
            "The second thing is that we consider the fact that facts are true for a certain period of time.",
            "Some cases, hence we also want to provide temporal scoping.",
            "We want to see this particular fact was valid within a certain period of time.",
            "What I'm not going to try to do during this talk is give you all the details pertaining to how we do it.",
            "I'm trying, I'll try to give you a flavor of how we went about doing this.",
            "I will not, for example, go through all the features that we used in the."
        ],
        [
            "Machine learning, but this was it.",
            "You see, a good overview of how defacto works.",
            "We start with a fact, for example, Albert Einstein Award Noble price.",
            "Our goal is to 1st transform this fact into some natural language representation.",
            "Once we've done that, we basically use a search engine to find pages that contain what we hope will be evidence for this fact being being true out of this index.",
            "We then extract a bunch of features that belong to two categories, category number.",
            "One tries to check whether what we found is actually a proof for the fact being correct and the second category of features actually asks, can we really trust the source out of which we got?",
            "Disproof we then have these two sets of features that we combine using different machine learning approaches and based on that we basically give a score to the fact saying it is mostly true, or we don't really have any evidence.",
            "Any evidence for it being true."
        ],
        [
            "I'm going to do in the next minutes is basically go through that pipeline."
        ],
        [
            "So let's start here.",
            "The first thing we need to do is verbalize the fact for that we used to bore pattern library."
        ],
        [
            "The block framework.",
            "Goes from the assumption that we have billions of triples that are available through us, and given that we have so much text, so many triples an so much text, we can actually apply distance learning to learn how relations are represented in natural language.",
            "So for example, we have triple such as Barack Obama born in Honolulu.",
            "Party is a Democratic Party on his bosses, Michelle."
        ],
        [
            "Obama, that's basically the same.",
            "We also find verbalize versions of these facts in sources such as Wikipedia.",
            "Basically all across the web.",
            "So if you are able to recognize the entities, we can basically figure out that was born in.",
            "For example, is a pattern for the relation birthplace."
        ],
        [
            "Main advantage of having such patterns is obviously that we can extract more knowledge so we can find sentences where we find facts that we did not know before."
        ],
        [
            "Are these options?",
            "So we can gather even more RDF out of the web."
        ],
        [
            "But even more importantly.",
            "We can."
        ],
        [
            "Do."
        ],
        [
            "Do this.",
            "We can't take.",
            "The text basically relations that we have the triple that we have used these patterns and generate text in other in several languages to represent the triples that we had in those languages and then start a search query.",
            "The reason why we do this in several languages is simply that if we look at the distribution of languages across the web, we basically see that approximately half of the web is not written in English, which basically means that by supporting several languages.",
            "Our aim was to actually show that we can achieve better score by finding more evidence.",
            "So if you have a fact such as a particular book, Momo was written by Michelle Ender, would basically be able to generate triples, but another text such as Enders book, Momo, or End in, sign in book Modesta, German of it or ended also Homer Moe Moe.",
            "In French we have a bunch of queries we can then send them."
        ],
        [
            "To the web.",
            "This is just another example for Alfred Hitchcock directed Jamaica in we can send its corresponding search query and will find text IE web pages for example form examiner.com that point to that fact hopefully."
        ],
        [
            "OK, so we have our triple.",
            "We've generated text out of it using these different patterns in different languages.",
            "What we then do is we take all these patterns and we send them to a search engine.",
            "In our experiments we use Google, but that is obviously one of the bottlenecks of the approaches.",
            "You basically need to pay to send those queries.",
            "We are looking into how to use a local corpus really to do that kind of search.",
            "If anybody is an expert on focus crawling, that is basically one of the key questions here, how do you create a small corpus that can give you the evidence you need for the web of data?",
            "But we get these queries we send him to.",
            "A search engine will collect a bunch of web pages.",
            "Those are the web pages where we hope to find evidence for the triple that was given."
        ],
        [
            "Tools.",
            "So now that we have the web pages we need to ask ourselves number one.",
            "Do I have any evidence for my triple in those web pages #2 can I trust these web pages so as to extract information from them and say this is actually reliable information?",
            "This thing?"
        ],
        [
            "Might be true.",
            "So how do we do?"
        ],
        [
            "Scoring.",
            "The basic idea is simple we have.",
            "For each of the subjects and objects of the triples, a bunch of surface forms which are basically string representations of the resources as anti so that Lambda function actually just gives you a set of labels for a particular resource."
        ],
        [
            "The first thing that we do is to check whether the distance between these labels so even starts for the labels of S E2 sensor labels of oh, whether the distance between these labels on the web page is less than a certain threshold Theta.",
            "So if these labels are too far apart within the paper, basically say that there's more story.",
            "No proof, no evidence for these two things being related within the page, and we don't consider the page any further if they are within the same.",
            "Basically within that distance.",
            "We say, OK, we might have some proof here.",
            "Example, we might have.",
            "Albert Einstein asked the label for our subject Noble price as the label for object and was awarded basically as a verbalization for our predicate.",
            "OK, we then compute a bunch of features.",
            "So once we found a web page where we think there might be some proof here, we compute a bunch of features we ask ourselves.",
            "Did we find any pattern between the busy anymore pattern?",
            "The patterns I talked about before between the label of the source and the label, the subject and label of the object?",
            "We also include the score that we give to that pattern while we were learning the patterns for the relations.",
            "We consider things such as to word net similarity of the sentence that we're looking into with different strings that we had the frequency of the patterns and so on and so forth.",
            "One feature that is actually quite important is looking to the title of the web page to basically see whether the webpage that we're looking into as in the title, any of the source any of the subjects or objects that were interested in.",
            "Because we know that the subject matter in the web page then is the particular.",
            "Entity."
        ],
        [
            "So we compile a bunch of features values for the proof.",
            "The second thing that we do is we basically ask ourselves, can we trust this particular web page.",
            "So we compute a bunch of trust."
        ],
        [
            "Worthless features.",
            "What we rely on is a work by now, radar from 2007, which basically assume that by looking at the distribution of topics on the web, we can actually see whether a website is reliable or not."
        ],
        [
            "We rely on distributional features of the website in particular.",
            "We basically compute the topic majority in the search result within that paper.",
            "Atopic was simply a string that was such that its frequency was beyond a certain threshold or its frequency was significantly higher.",
            "Respect to a reference corpus.",
            "We basically said these are typical strings for this particular web pages."
        ],
        [
            "So we compute the number is a Christian, but basically compute the number of pages in the search results that have similar topics to particular web page.",
            "We are looking into at the moment we compute the topic majority on the World Wide Web, but we also look at the page rank of the website that we are interested in there bunch of other features such as the number of proofs found on the website, the total number of queries and so on and so forth.",
            "I've not delve into the details.",
            "Yes, thank you very much."
        ],
        [
            "OK, I'm not completely done yet.",
            "I was just acknowledging that I have 5 minutes left.",
            "OK, so we have these features.",
            "One thing that we also consider is the fact that is the fact that facts are not always true.",
            "For example, Tom Cruise was married to Katie Holmes, but only for a certain period of time or Frank Beckenbauer Huntsman bore only played in the New York Cosmos for a certain period of time, so."
        ],
        [
            "What we do is in addition we add.",
            "Temporal information we have computed the distribution of years on the web.",
            "The Plotless approximately as down there and based on this distribution we can actually normalize to frequency of appearance of years in web pages.",
            "So basically if we find something a web page where we have a lot of 2010, it is not necessarily evidence for 2010 being very important for their web page simply because there are priority probability of finding 2010 is pretty high."
        ],
        [
            "What we've done here is we have looked for Ye literals within a certain contact windows, and we try to learn patterns that basically express intervals within web pages, and these are the kind of patterns that one can learn across the web.",
            "Things like between the years, a certain year, another year or a year.",
            "This actually slips that German another year, and we found patterns in French and other languages as."
        ],
        [
            "Well, so now you have an overview of the kinds of features that we're interested in.",
            "We then took all these features and threw them into a machine learning approach to figure out whether we can actually.",
            "Check weather fact Parker."
        ],
        [
            "Or not, the main proper challenge that we faced here is that there were no benchmarks for actually measuring how accurate such a thing is.",
            "So we created a benchmark.",
            "We basically annotated 1500 facts manually and had two people doing that to make sure that it was correct.",
            "And we compared a bunch of different machine learning approaches.",
            "J48 knife, base, support vector machines and so on."
        ],
        [
            "And so forth.",
            "Just basically just gives you an overview of fact bench important.",
            "It is limited to 10 relations where we're sure that we understood the semantics of the relations.",
            "There are some relations where the semantic is not unique."
        ],
        [
            "This just gives you an overview of the kind of distributions that you can expect with in fact bent.",
            "So basically, the kinds of time intervals that you will find in there."
        ],
        [
            "We also generated negative examples automatically out of the positive examples simply by using different permutations, such as replacing the subject, the object, subject and object, and so on and."
        ],
        [
            "So forth.",
            "Now to some results, but we were able to show is that we actually have actually a pretty good F measure in most cases somewhere between.",
            "In the worst case it was zero point 7 in the best case it was around 0.9.",
            "On G4, cheat is definitely the best algorithm when you're doing fact checking from all the algorithms that we tested."
        ],
        [
            "One effect that was very interesting is that using multiple languages definitely does help, and he was able to push the accuracy in the English.",
            "For example, on the award relation from 96% to actually 100%."
        ],
        [
            "We also checked how good we were at finding the validity span.",
            "For fact we had to extend the definition of precision and recall as well as F measure for this particular case."
        ],
        [
            "So if our algorithm found a certain interval and we had a correct interval, we basically simply computed the intersection of correct, found divided by phone for precision.",
            "Divided by quick for recall.",
            "So in this particular case would have a precision of the have every call of 1/3 yes and then F measure of two 5th."
        ],
        [
            "But we could show you that again by using several languages, we could push algorithm to get up to basically the good in the good 80s for F measure on this part."
        ],
        [
            "Killer task.",
            "And algorithm generates obviously proof aware output, basically telling you why it thinks the fact is true and basic await found evidence for this fact being true.",
            "Basically supporting people to cure it."
        ],
        [
            "Knowledge base."
        ],
        [
            "This is cool.",
            "That was it already from my side, presented defacto performs with best BJ 48 achieves between 80% and 100% precision on the fact bench relations and we obviously need to extend fact bench on more relations were considered 10 so far.",
            "One thing that we're really interested in is combining it with deep learning and integrating more languages."
        ],
        [
            "Thank you very much.",
            "Thanks excellent, you showed these examples in the beginning and they have a very entertaining but at the same time they were just simple schema violations, right?",
            "So how does consistency checking against the schema work?",
            "As a baseline?",
            "How much accuracy do get with that?",
            "So we've basically not checked out what we're interested in knowing really.",
            "I mean, these are.",
            "These are examples that are obvious there.",
            "A lot of examples where this is not obvious.",
            "For example, people being married to the wrong person that also does occur in the data.",
            "Or basically people in the cases, especially of things that have the same name when it disambiguation fails, your basic average and the generation of a lot of facts that do abide by the schema but are still wrong.",
            "What we did check is basically when we did the generation of negative facts, we basically make make sure that we are that the generation followed the schema, and even then there we could basically see that even if the schema is not violated, we can still perform pretty well.",
            "Hi, I'm on the time stuff.",
            "How do you know the difference between when there can be multiple values of a relation like children?",
            "If you see a new fact about someone's child, it doesn't mean the old one is no longer a child versus even win multiple Nobel Prizes.",
            "For example in different years versus spouse and whatever.",
            "The other examples you gave him so.",
            "So basically, if we find, let's say Albert Einstein want, let's assume no.",
            "Madam Curie, let's take one.",
            "Carry one.",
            "Several Nobel Prizes were basically would give the one of your see lower score.",
            "So basically in that particular case.",
            "This second Nobel Prize, for which we have less evidence, basically with the time distribution, would most probably get the lower score is also, we never say that in fact is wrong with simply have less evidence for his point being true.",
            "So negation is not yet considered.",
            "That's something we definitely want to look into.",
            "Hi I was wondering have you do you have a an example or a use case where going through generation would work but simply tracking extracted facts against each other wouldn't.",
            "So what's the added value by comparison to just extracting triples out of this other texts than on Wikipedia?",
            "Texts that were using and then looking for inconsistencies?",
            "So I'm not sure.",
            "We got the question right.",
            "So basically you're saying what is the other value respect in comparison to?",
            "I take the text extract triples right and look for your system.",
            "So for inconsistencies in many cases you don't.",
            "You don't really have inconsistencies, so there are let me think for let me think for a second.",
            "For example Arthur Shrewsbury's death place.",
            "You can have several strings that are his death place or several resources.",
            "He can be dead in.",
            "I mean, he could have died in London in a particular house, and so on and so forth.",
            "So there is actually.",
            "Let's difficult to detect inconsistencies, alright, but you basically get support values that point instances them, but.",
            "Looking for supporting triples, say looking for the same triple in other texts without going through generation, but by extracting triples again from this new texts.",
            "Basically you'd have to extract a lot of triples with all the triples from the corpus.",
            "That job at hand, which in this case is.",
            "The web is simply doesn't work, so practically want to go the other direction because you can limit the amount of information out of which you need to extract basically your features as well as the evidence that you're looking for so.",
            "This allows you to take advantage of Google's index.",
            "Yeah, but basically one yeah, one thing that we definitely want to look into is creating a corresponding corpus that is basically small so that you can actually do the indexing locally.",
            "Will make the tool scale way better.",
            "OK, thanks, thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "My greetings to you all for those who don't know me, my name is Axel from the University of Leipzig in Germany and from the Institute for Applied Informatics.",
                    "label": 0
                },
                {
                    "sent": "And this is work that was mainly done by my PhD student, Daniel Gerber, together with Diego estivation, Sleeman, Norman Spearman, Ricardo Uzbek and rainy spec.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So, did you know that Lily Aldridge is married?",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To the whole band, the Kings of Leon.",
                    "label": 0
                },
                {
                    "sent": "Or",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Or that Arthur Shrewsbury death place was the English cricket team and you have plenty.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Facts like that on the linked open data web, for example, Michelle Obama is married to Barack Obama, but also to his presidency, which by the way started when he was born.",
                    "label": 1
                },
                {
                    "sent": "And yeah, you can be born in a sport called lacrosse.",
                    "label": 0
                },
                {
                    "sent": "There's also situated called that name and so on and so forth.",
                    "label": 0
                },
                {
                    "sent": "So there's plenty of information in on the link data web that does not reflect the reality that we see in the real world, so that this information that will call false throughout.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "To talk, you have created this huge compendium of data like more than 130 billion trip billion facts really.",
                    "label": 1
                },
                {
                    "sent": "And a lot of that data is generated automatically by extracting information from other sources.",
                    "label": 0
                },
                {
                    "sent": "The major problem is, given the mere sized amount of information that we have, it is impossible to check it manually.",
                    "label": 0
                },
                {
                    "sent": "So basically to go through each triple and check whether what we see in reality is reflected in that triple, and that's the whole problem that the factor tries to tackle what we pay.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Pose is a framework that recalled a deep fat validation framework deep because we basically tried to analyze to basically go into the text into text that provides support for the fax or does not provide support.",
                    "label": 0
                },
                {
                    "sent": "So what we do?",
                    "label": 0
                },
                {
                    "sent": "Is we use verbalization, which was the topic of the keynote this morning.",
                    "label": 1
                },
                {
                    "sent": "So that came out really helped and machine learning to find evidence that support facts for being true.",
                    "label": 0
                },
                {
                    "sent": "It is important to state here that we do not check for facts being forced becausw it is very tricky to find evidence for something being false, but we're working on it.",
                    "label": 1
                },
                {
                    "sent": "That's basically upcoming work.",
                    "label": 0
                },
                {
                    "sent": "The second thing is that we consider the fact that facts are true for a certain period of time.",
                    "label": 1
                },
                {
                    "sent": "Some cases, hence we also want to provide temporal scoping.",
                    "label": 0
                },
                {
                    "sent": "We want to see this particular fact was valid within a certain period of time.",
                    "label": 0
                },
                {
                    "sent": "What I'm not going to try to do during this talk is give you all the details pertaining to how we do it.",
                    "label": 0
                },
                {
                    "sent": "I'm trying, I'll try to give you a flavor of how we went about doing this.",
                    "label": 0
                },
                {
                    "sent": "I will not, for example, go through all the features that we used in the.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Machine learning, but this was it.",
                    "label": 0
                },
                {
                    "sent": "You see, a good overview of how defacto works.",
                    "label": 0
                },
                {
                    "sent": "We start with a fact, for example, Albert Einstein Award Noble price.",
                    "label": 1
                },
                {
                    "sent": "Our goal is to 1st transform this fact into some natural language representation.",
                    "label": 0
                },
                {
                    "sent": "Once we've done that, we basically use a search engine to find pages that contain what we hope will be evidence for this fact being being true out of this index.",
                    "label": 0
                },
                {
                    "sent": "We then extract a bunch of features that belong to two categories, category number.",
                    "label": 0
                },
                {
                    "sent": "One tries to check whether what we found is actually a proof for the fact being correct and the second category of features actually asks, can we really trust the source out of which we got?",
                    "label": 0
                },
                {
                    "sent": "Disproof we then have these two sets of features that we combine using different machine learning approaches and based on that we basically give a score to the fact saying it is mostly true, or we don't really have any evidence.",
                    "label": 0
                },
                {
                    "sent": "Any evidence for it being true.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I'm going to do in the next minutes is basically go through that pipeline.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So let's start here.",
                    "label": 0
                },
                {
                    "sent": "The first thing we need to do is verbalize the fact for that we used to bore pattern library.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The block framework.",
                    "label": 0
                },
                {
                    "sent": "Goes from the assumption that we have billions of triples that are available through us, and given that we have so much text, so many triples an so much text, we can actually apply distance learning to learn how relations are represented in natural language.",
                    "label": 1
                },
                {
                    "sent": "So for example, we have triple such as Barack Obama born in Honolulu.",
                    "label": 0
                },
                {
                    "sent": "Party is a Democratic Party on his bosses, Michelle.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Obama, that's basically the same.",
                    "label": 0
                },
                {
                    "sent": "We also find verbalize versions of these facts in sources such as Wikipedia.",
                    "label": 0
                },
                {
                    "sent": "Basically all across the web.",
                    "label": 0
                },
                {
                    "sent": "So if you are able to recognize the entities, we can basically figure out that was born in.",
                    "label": 1
                },
                {
                    "sent": "For example, is a pattern for the relation birthplace.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Main advantage of having such patterns is obviously that we can extract more knowledge so we can find sentences where we find facts that we did not know before.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Are these options?",
                    "label": 0
                },
                {
                    "sent": "So we can gather even more RDF out of the web.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But even more importantly.",
                    "label": 0
                },
                {
                    "sent": "We can.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Do.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Do this.",
                    "label": 0
                },
                {
                    "sent": "We can't take.",
                    "label": 0
                },
                {
                    "sent": "The text basically relations that we have the triple that we have used these patterns and generate text in other in several languages to represent the triples that we had in those languages and then start a search query.",
                    "label": 0
                },
                {
                    "sent": "The reason why we do this in several languages is simply that if we look at the distribution of languages across the web, we basically see that approximately half of the web is not written in English, which basically means that by supporting several languages.",
                    "label": 0
                },
                {
                    "sent": "Our aim was to actually show that we can achieve better score by finding more evidence.",
                    "label": 0
                },
                {
                    "sent": "So if you have a fact such as a particular book, Momo was written by Michelle Ender, would basically be able to generate triples, but another text such as Enders book, Momo, or End in, sign in book Modesta, German of it or ended also Homer Moe Moe.",
                    "label": 0
                },
                {
                    "sent": "In French we have a bunch of queries we can then send them.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To the web.",
                    "label": 0
                },
                {
                    "sent": "This is just another example for Alfred Hitchcock directed Jamaica in we can send its corresponding search query and will find text IE web pages for example form examiner.com that point to that fact hopefully.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so we have our triple.",
                    "label": 0
                },
                {
                    "sent": "We've generated text out of it using these different patterns in different languages.",
                    "label": 0
                },
                {
                    "sent": "What we then do is we take all these patterns and we send them to a search engine.",
                    "label": 0
                },
                {
                    "sent": "In our experiments we use Google, but that is obviously one of the bottlenecks of the approaches.",
                    "label": 0
                },
                {
                    "sent": "You basically need to pay to send those queries.",
                    "label": 0
                },
                {
                    "sent": "We are looking into how to use a local corpus really to do that kind of search.",
                    "label": 0
                },
                {
                    "sent": "If anybody is an expert on focus crawling, that is basically one of the key questions here, how do you create a small corpus that can give you the evidence you need for the web of data?",
                    "label": 0
                },
                {
                    "sent": "But we get these queries we send him to.",
                    "label": 0
                },
                {
                    "sent": "A search engine will collect a bunch of web pages.",
                    "label": 0
                },
                {
                    "sent": "Those are the web pages where we hope to find evidence for the triple that was given.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Tools.",
                    "label": 0
                },
                {
                    "sent": "So now that we have the web pages we need to ask ourselves number one.",
                    "label": 0
                },
                {
                    "sent": "Do I have any evidence for my triple in those web pages #2 can I trust these web pages so as to extract information from them and say this is actually reliable information?",
                    "label": 0
                },
                {
                    "sent": "This thing?",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Might be true.",
                    "label": 0
                },
                {
                    "sent": "So how do we do?",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Scoring.",
                    "label": 0
                },
                {
                    "sent": "The basic idea is simple we have.",
                    "label": 0
                },
                {
                    "sent": "For each of the subjects and objects of the triples, a bunch of surface forms which are basically string representations of the resources as anti so that Lambda function actually just gives you a set of labels for a particular resource.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The first thing that we do is to check whether the distance between these labels so even starts for the labels of S E2 sensor labels of oh, whether the distance between these labels on the web page is less than a certain threshold Theta.",
                    "label": 0
                },
                {
                    "sent": "So if these labels are too far apart within the paper, basically say that there's more story.",
                    "label": 0
                },
                {
                    "sent": "No proof, no evidence for these two things being related within the page, and we don't consider the page any further if they are within the same.",
                    "label": 0
                },
                {
                    "sent": "Basically within that distance.",
                    "label": 0
                },
                {
                    "sent": "We say, OK, we might have some proof here.",
                    "label": 0
                },
                {
                    "sent": "Example, we might have.",
                    "label": 0
                },
                {
                    "sent": "Albert Einstein asked the label for our subject Noble price as the label for object and was awarded basically as a verbalization for our predicate.",
                    "label": 1
                },
                {
                    "sent": "OK, we then compute a bunch of features.",
                    "label": 0
                },
                {
                    "sent": "So once we found a web page where we think there might be some proof here, we compute a bunch of features we ask ourselves.",
                    "label": 0
                },
                {
                    "sent": "Did we find any pattern between the busy anymore pattern?",
                    "label": 0
                },
                {
                    "sent": "The patterns I talked about before between the label of the source and the label, the subject and label of the object?",
                    "label": 0
                },
                {
                    "sent": "We also include the score that we give to that pattern while we were learning the patterns for the relations.",
                    "label": 0
                },
                {
                    "sent": "We consider things such as to word net similarity of the sentence that we're looking into with different strings that we had the frequency of the patterns and so on and so forth.",
                    "label": 0
                },
                {
                    "sent": "One feature that is actually quite important is looking to the title of the web page to basically see whether the webpage that we're looking into as in the title, any of the source any of the subjects or objects that were interested in.",
                    "label": 0
                },
                {
                    "sent": "Because we know that the subject matter in the web page then is the particular.",
                    "label": 0
                },
                {
                    "sent": "Entity.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we compile a bunch of features values for the proof.",
                    "label": 0
                },
                {
                    "sent": "The second thing that we do is we basically ask ourselves, can we trust this particular web page.",
                    "label": 0
                },
                {
                    "sent": "So we compute a bunch of trust.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Worthless features.",
                    "label": 0
                },
                {
                    "sent": "What we rely on is a work by now, radar from 2007, which basically assume that by looking at the distribution of topics on the web, we can actually see whether a website is reliable or not.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We rely on distributional features of the website in particular.",
                    "label": 1
                },
                {
                    "sent": "We basically compute the topic majority in the search result within that paper.",
                    "label": 0
                },
                {
                    "sent": "Atopic was simply a string that was such that its frequency was beyond a certain threshold or its frequency was significantly higher.",
                    "label": 0
                },
                {
                    "sent": "Respect to a reference corpus.",
                    "label": 0
                },
                {
                    "sent": "We basically said these are typical strings for this particular web pages.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we compute the number is a Christian, but basically compute the number of pages in the search results that have similar topics to particular web page.",
                    "label": 1
                },
                {
                    "sent": "We are looking into at the moment we compute the topic majority on the World Wide Web, but we also look at the page rank of the website that we are interested in there bunch of other features such as the number of proofs found on the website, the total number of queries and so on and so forth.",
                    "label": 0
                },
                {
                    "sent": "I've not delve into the details.",
                    "label": 0
                },
                {
                    "sent": "Yes, thank you very much.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, I'm not completely done yet.",
                    "label": 0
                },
                {
                    "sent": "I was just acknowledging that I have 5 minutes left.",
                    "label": 0
                },
                {
                    "sent": "OK, so we have these features.",
                    "label": 0
                },
                {
                    "sent": "One thing that we also consider is the fact that is the fact that facts are not always true.",
                    "label": 0
                },
                {
                    "sent": "For example, Tom Cruise was married to Katie Holmes, but only for a certain period of time or Frank Beckenbauer Huntsman bore only played in the New York Cosmos for a certain period of time, so.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "What we do is in addition we add.",
                    "label": 0
                },
                {
                    "sent": "Temporal information we have computed the distribution of years on the web.",
                    "label": 0
                },
                {
                    "sent": "The Plotless approximately as down there and based on this distribution we can actually normalize to frequency of appearance of years in web pages.",
                    "label": 0
                },
                {
                    "sent": "So basically if we find something a web page where we have a lot of 2010, it is not necessarily evidence for 2010 being very important for their web page simply because there are priority probability of finding 2010 is pretty high.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "What we've done here is we have looked for Ye literals within a certain contact windows, and we try to learn patterns that basically express intervals within web pages, and these are the kind of patterns that one can learn across the web.",
                    "label": 0
                },
                {
                    "sent": "Things like between the years, a certain year, another year or a year.",
                    "label": 0
                },
                {
                    "sent": "This actually slips that German another year, and we found patterns in French and other languages as.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Well, so now you have an overview of the kinds of features that we're interested in.",
                    "label": 0
                },
                {
                    "sent": "We then took all these features and threw them into a machine learning approach to figure out whether we can actually.",
                    "label": 0
                },
                {
                    "sent": "Check weather fact Parker.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Or not, the main proper challenge that we faced here is that there were no benchmarks for actually measuring how accurate such a thing is.",
                    "label": 0
                },
                {
                    "sent": "So we created a benchmark.",
                    "label": 0
                },
                {
                    "sent": "We basically annotated 1500 facts manually and had two people doing that to make sure that it was correct.",
                    "label": 0
                },
                {
                    "sent": "And we compared a bunch of different machine learning approaches.",
                    "label": 0
                },
                {
                    "sent": "J48 knife, base, support vector machines and so on.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And so forth.",
                    "label": 0
                },
                {
                    "sent": "Just basically just gives you an overview of fact bench important.",
                    "label": 0
                },
                {
                    "sent": "It is limited to 10 relations where we're sure that we understood the semantics of the relations.",
                    "label": 0
                },
                {
                    "sent": "There are some relations where the semantic is not unique.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This just gives you an overview of the kind of distributions that you can expect with in fact bent.",
                    "label": 0
                },
                {
                    "sent": "So basically, the kinds of time intervals that you will find in there.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We also generated negative examples automatically out of the positive examples simply by using different permutations, such as replacing the subject, the object, subject and object, and so on and.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So forth.",
                    "label": 0
                },
                {
                    "sent": "Now to some results, but we were able to show is that we actually have actually a pretty good F measure in most cases somewhere between.",
                    "label": 0
                },
                {
                    "sent": "In the worst case it was zero point 7 in the best case it was around 0.9.",
                    "label": 0
                },
                {
                    "sent": "On G4, cheat is definitely the best algorithm when you're doing fact checking from all the algorithms that we tested.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "One effect that was very interesting is that using multiple languages definitely does help, and he was able to push the accuracy in the English.",
                    "label": 0
                },
                {
                    "sent": "For example, on the award relation from 96% to actually 100%.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We also checked how good we were at finding the validity span.",
                    "label": 0
                },
                {
                    "sent": "For fact we had to extend the definition of precision and recall as well as F measure for this particular case.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So if our algorithm found a certain interval and we had a correct interval, we basically simply computed the intersection of correct, found divided by phone for precision.",
                    "label": 0
                },
                {
                    "sent": "Divided by quick for recall.",
                    "label": 0
                },
                {
                    "sent": "So in this particular case would have a precision of the have every call of 1/3 yes and then F measure of two 5th.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But we could show you that again by using several languages, we could push algorithm to get up to basically the good in the good 80s for F measure on this part.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Killer task.",
                    "label": 0
                },
                {
                    "sent": "And algorithm generates obviously proof aware output, basically telling you why it thinks the fact is true and basic await found evidence for this fact being true.",
                    "label": 0
                },
                {
                    "sent": "Basically supporting people to cure it.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Knowledge base.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This is cool.",
                    "label": 0
                },
                {
                    "sent": "That was it already from my side, presented defacto performs with best BJ 48 achieves between 80% and 100% precision on the fact bench relations and we obviously need to extend fact bench on more relations were considered 10 so far.",
                    "label": 1
                },
                {
                    "sent": "One thing that we're really interested in is combining it with deep learning and integrating more languages.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Thank you very much.",
                    "label": 0
                },
                {
                    "sent": "Thanks excellent, you showed these examples in the beginning and they have a very entertaining but at the same time they were just simple schema violations, right?",
                    "label": 0
                },
                {
                    "sent": "So how does consistency checking against the schema work?",
                    "label": 0
                },
                {
                    "sent": "As a baseline?",
                    "label": 0
                },
                {
                    "sent": "How much accuracy do get with that?",
                    "label": 0
                },
                {
                    "sent": "So we've basically not checked out what we're interested in knowing really.",
                    "label": 0
                },
                {
                    "sent": "I mean, these are.",
                    "label": 0
                },
                {
                    "sent": "These are examples that are obvious there.",
                    "label": 0
                },
                {
                    "sent": "A lot of examples where this is not obvious.",
                    "label": 0
                },
                {
                    "sent": "For example, people being married to the wrong person that also does occur in the data.",
                    "label": 0
                },
                {
                    "sent": "Or basically people in the cases, especially of things that have the same name when it disambiguation fails, your basic average and the generation of a lot of facts that do abide by the schema but are still wrong.",
                    "label": 0
                },
                {
                    "sent": "What we did check is basically when we did the generation of negative facts, we basically make make sure that we are that the generation followed the schema, and even then there we could basically see that even if the schema is not violated, we can still perform pretty well.",
                    "label": 0
                },
                {
                    "sent": "Hi, I'm on the time stuff.",
                    "label": 0
                },
                {
                    "sent": "How do you know the difference between when there can be multiple values of a relation like children?",
                    "label": 0
                },
                {
                    "sent": "If you see a new fact about someone's child, it doesn't mean the old one is no longer a child versus even win multiple Nobel Prizes.",
                    "label": 0
                },
                {
                    "sent": "For example in different years versus spouse and whatever.",
                    "label": 0
                },
                {
                    "sent": "The other examples you gave him so.",
                    "label": 0
                },
                {
                    "sent": "So basically, if we find, let's say Albert Einstein want, let's assume no.",
                    "label": 0
                },
                {
                    "sent": "Madam Curie, let's take one.",
                    "label": 0
                },
                {
                    "sent": "Carry one.",
                    "label": 0
                },
                {
                    "sent": "Several Nobel Prizes were basically would give the one of your see lower score.",
                    "label": 0
                },
                {
                    "sent": "So basically in that particular case.",
                    "label": 0
                },
                {
                    "sent": "This second Nobel Prize, for which we have less evidence, basically with the time distribution, would most probably get the lower score is also, we never say that in fact is wrong with simply have less evidence for his point being true.",
                    "label": 0
                },
                {
                    "sent": "So negation is not yet considered.",
                    "label": 0
                },
                {
                    "sent": "That's something we definitely want to look into.",
                    "label": 0
                },
                {
                    "sent": "Hi I was wondering have you do you have a an example or a use case where going through generation would work but simply tracking extracted facts against each other wouldn't.",
                    "label": 0
                },
                {
                    "sent": "So what's the added value by comparison to just extracting triples out of this other texts than on Wikipedia?",
                    "label": 0
                },
                {
                    "sent": "Texts that were using and then looking for inconsistencies?",
                    "label": 0
                },
                {
                    "sent": "So I'm not sure.",
                    "label": 0
                },
                {
                    "sent": "We got the question right.",
                    "label": 0
                },
                {
                    "sent": "So basically you're saying what is the other value respect in comparison to?",
                    "label": 0
                },
                {
                    "sent": "I take the text extract triples right and look for your system.",
                    "label": 0
                },
                {
                    "sent": "So for inconsistencies in many cases you don't.",
                    "label": 0
                },
                {
                    "sent": "You don't really have inconsistencies, so there are let me think for let me think for a second.",
                    "label": 0
                },
                {
                    "sent": "For example Arthur Shrewsbury's death place.",
                    "label": 0
                },
                {
                    "sent": "You can have several strings that are his death place or several resources.",
                    "label": 0
                },
                {
                    "sent": "He can be dead in.",
                    "label": 0
                },
                {
                    "sent": "I mean, he could have died in London in a particular house, and so on and so forth.",
                    "label": 0
                },
                {
                    "sent": "So there is actually.",
                    "label": 0
                },
                {
                    "sent": "Let's difficult to detect inconsistencies, alright, but you basically get support values that point instances them, but.",
                    "label": 0
                },
                {
                    "sent": "Looking for supporting triples, say looking for the same triple in other texts without going through generation, but by extracting triples again from this new texts.",
                    "label": 0
                },
                {
                    "sent": "Basically you'd have to extract a lot of triples with all the triples from the corpus.",
                    "label": 0
                },
                {
                    "sent": "That job at hand, which in this case is.",
                    "label": 0
                },
                {
                    "sent": "The web is simply doesn't work, so practically want to go the other direction because you can limit the amount of information out of which you need to extract basically your features as well as the evidence that you're looking for so.",
                    "label": 0
                },
                {
                    "sent": "This allows you to take advantage of Google's index.",
                    "label": 0
                },
                {
                    "sent": "Yeah, but basically one yeah, one thing that we definitely want to look into is creating a corresponding corpus that is basically small so that you can actually do the indexing locally.",
                    "label": 0
                },
                {
                    "sent": "Will make the tool scale way better.",
                    "label": 0
                },
                {
                    "sent": "OK, thanks, thank you.",
                    "label": 0
                }
            ]
        }
    }
}