{
    "id": "npvt6xkk2ancrnanxmufgtvcvakricbo",
    "title": "Identifying Topical Authorities in Microblogs",
    "info": {
        "author": [
            "Aditya Pal, Department of Computer Science and Engineering, University of Minnesota"
        ],
        "published": "Aug. 9, 2011",
        "recorded": "February 2011",
        "category": [
            "Top->Computer Science->Information Retrieval"
        ]
    },
    "url": "http://videolectures.net/wsdm2011_pal_ita/",
    "segmentation": [
        [
            "Yeah hi everyone, my name is Adam Paul and I am a student at University of Minnesota.",
            "Ann.",
            "I'm here to present my work on identifying topical authorities in microblogs.",
            "This work has been done along with Scott counts from Microsoft Research and the."
        ],
        [
            "Item that we focused on is given a topic.",
            "How do you find the most interesting top users and the data substantial benefits in finding these users, such as they can be used for improving search engine quality and they can be used for while marketing and getting a perspective about the topic and several other things."
        ],
        [
            "Moreover, the challenges in microblogs are many found.",
            "For example, the scale of data that microblog site gets is quite a lot and at the same time the shortliffe time span of a topic makes gives us very interesting scenarios such as author might not even exist on a topic before the topic actually started.",
            "For example, Haiti Relief Fund or maybe World Cup news.",
            "These authors didn't even exist before that event actually happened.",
            "So in these scenarios we would like to avoid recommending general authorities who are posting on large set of topics or celebrities.",
            "For example, should here as a celebrity for World Cup, which some yeah, so we would like to avoid."
        ],
        [
            "All those people.",
            "So much work has been done in expert identification and identifying authorities in several online domains in microblogs Wing.",
            "It all addressed this problem, last year's wisdom, and in their approach what they do is that they compute topical distribution of users using latent digital allocation, and then the user weighted Pagerank algorithm to find out who are the topical influencers over a given topic.",
            "Then they used a data set from Singapore.",
            "They had a sample of a data set and they showed that their algorithm was doing better than a page rank based model and the only problem with this kind of approach is that can we do this in real time because it just doesn't look like it can be done in real time.",
            "This actually motivates us to explore an alternate approach which we implemented in a near real time manner."
        ],
        [
            "OK, so our approach can be understood with this simple pipeline.",
            "What we have over here is that the first phase of the pipeline is the feature selection, so we estimate that these features are important for an author to have a top authority to have an based on these feature.",
            "Then we do a probabilistic clustering.",
            "The idea behind clustering is that it gives us a sense of how authorities are behaving in this particular topic.",
            "It could very well happen that authorities might behave very differently on one topic from a different topic.",
            "And avoid us from making a very general statement about authorities like they should have this quality or that quality.",
            "And once we do the clustering and then we propose a ranking method which we use to find out the top authorities on that given topic.",
            "Alright, so the attractive features of our algorithm is that it can be implemented in near real time, and it can be implemented using a distributed framework."
        ],
        [
            "Alright, so some of the terms that I've used over here as basically original tweets which other tweets proposed by the Author RT represents a retweets which we all know procede with.",
            "Artie keyword and City are the conversation to eat which other tweets directed towards another user.",
            "So these are the kind of tweet that an author can post in a microblogging site and."
        ],
        [
            "Next we have some features based on these tweets and also the graph features that we actually take into account to propose some of the basic features.",
            "One of the notable features is a self similarity score in which we actually try to see how many words are person is borrowing from his or her previous tweets.",
            "So the idea here is that if a person borrows a lot of words, then the person could be a spammer.",
            "If a person is boring, very few words, then a person might not be topically relevant, so.",
            "Now using."
        ],
        [
            "These basic features.",
            "We then compute some more refined features.",
            "So for example, the number one features topic signal where we try to estimate how much this user is actually posting within the topic and how much he's posting outside the topic.",
            "The second feature in that case is that signal strength.",
            "OK, this person is posting within the topic.",
            "What is a signal of this person?",
            "So for example, a cnn.com might have a low topic signal, but will have a very high signal strength.",
            "So several of these features are intuitive and then one of them is a mentioned impact.",
            "I'm not sure if it's visible, but.",
            "What we try to estimate over here is that how much this topic is about the person.",
            "And we try to see that how other people mentioning this person over this given topic."
        ],
        [
            "Well.",
            "We use all these features an once we get these features then we use a probabilistic clustering method.",
            "So we use Gaussian mixture model to find out all the mixtures, all the clusters.",
            "So the idea here is that instead of saying that a point belongs to this cluster, we said at a point belongs to this cluster with a probability .9 and that cluster with probability .1 and.",
            "This is done using expectation maximization algorithm, and once we actually find out the probabilistic clusters, we actually then the problem comes that we have to find out the right cluster and to find out the right cluster.",
            "We then compute.",
            "We use several heuristics such as topic, signal, redo it impact to find out which cluster contains the maximum authorities and that cluster becomes a target cluster."
        ],
        [
            "OK, so.",
            "So once we get the clusters, the next step is we have to rank these people so within the clusters.",
            "So in order to rank we explore two methods.",
            "When is Elizabeth ranking, which is very commonly used in the second?",
            "Is aggression based method in Elizabeth method we call the features independently, rank users on individual features and take an aggregate rank in the Gaussian based feature we try to estimate how good is this person over this given feature.",
            "So we compute a Gaussian CDF to get a score for this person over this feature.",
            "And then we actually compute the product of their scores to get the final rank of this person.",
            "So.",
            "This is actually actually the algorithm and the three states."
        ],
        [
            "So the algorithm and the data set we used was all public tweets for five days from 6 June 10 June.",
            "It counted 290 million tweets, which is quite a substantial amount of data for five days and.",
            "The topics we use for like iPhone or else will in World Cup and we use keyword extraction to find all the topical tweets.",
            "Along with that we did our once you've got all these tweets then we did a data set expansion by taking into account what are the common hashtags shared?",
            "What are the common URL shared and then try to expand the data set so this actually amounted to the statistics over there and.",
            "We can see that iPhone is slightly bigger than oil spill in World Cup because at the time iPhone 4 was about to launch and people were talking about it a lot."
        ],
        [
            "Alright, do now.",
            "Validate our algorithm.",
            "We just selected some baseline methods.",
            "One of the baseline method was a method based on the graph properties that we selected and we added page rank over dimension graph to it and second was a text property based model and third was a random selection outside the cluster.",
            "So these models will help us in estimating how good is our model and how well it is performing.",
            "And then we use the same clustering and ranking algorithm that I proposed previously to build the rank list per model."
        ],
        [
            "OK, so now we get the top 10 users per model.",
            "We see that the key observation in this table is that the number of the average number of followers for the B1 model is more than average number of followers for our model.",
            "So in some sense we can say that our model is likely sweet spot between your graph based model and a pure text based model.",
            "That is, it is not recommending users which have high number of followers but also not low number of followers somewhere in between."
        ],
        [
            "OK, so the top 10 users of our model look like this.",
            "I haven't.",
            "I have highlighted some of them.",
            "For example, NWF is National Wildlife Foundation and it doesn't have that high follower count.",
            "But still it's very topically relevant an actually yeah and several others of them are reserved.",
            "They don't have very high number of follower count, but still they are very topically relevant.",
            "OK."
        ],
        [
            "Alright, so in order to validate our algorithm with other baseline models, we then did a human evaluation so.",
            "In order to evaluate different models, we selected authors top ten authors from baseline models and 20 from our model that I've read gave us 40 authors, but open due to some overlaps and then we selected 4 original tweets posted by each author for a survey and we had participants from Microsoft who rated so they were assigned one topic randomly and within the topic they did half of the authors anonymously.",
            "Half of the auto synonymously."
        ],
        [
            "And anonymous screen actually looked like this, where we showed four tweets per author and we didn't show the author name and participant had to rate how interesting they find this author and how authoritative they find this author to be in the."
        ],
        [
            "On another screen, we actually showed the username, so this difference.",
            "The idea behind this difference was that we would like to capture if there is a rating bias between the participants and also how good the content stands on its own and how good the content stands with the source."
        ],
        [
            "Name?",
            "Alright, so OK.",
            "So then this is an average rating comparison.",
            "These are the results and we see that our model is performing much better than the baseline.",
            "B1 and B1 is performing better than B2B1 is a graph based model and beta was a text based and it actually significantly better.",
            "It has a significance T test with a 95% confidence interval.",
            "It is performing better than the baseline models in all the conditions except for one Topic World Cup.",
            "And."
        ],
        [
            "OK, so next we did a best rating comparison.",
            "In this comparison what we did is that we imagine that like in a web search, what happens is that if we return end results an N minus one of them are bad.",
            "But when is good and the user actually finds that result, user is happy with the search.",
            "Then the same thing we do that.",
            "Who is the best rated author by a participant for model and then we did a comparison of that.",
            "We now see that our model is doing significantly better than all the baseline models.",
            "Which actually tells us that the best person of her model is much better than the best person of Beaven, Heartbeat or B3."
        ],
        [
            "OK then the next thing we do, we try to compute the.",
            "Precision of the models dissuaded by taking the human rating, sorting on the basis of the human ratings, and then pick the top 10 from them and see how many of our models surface in the top 10 list.",
            "So what we see over here is that the precision is as high as pointed for some of the.",
            "Topics and we see that our model is doing much better than the baseline.",
            "B will not be too as a matter of fact."
        ],
        [
            "OK, then we had like several components in the algorithm, such as we had a clustering component.",
            "We had a list with ranking component and we just wanted to see which one of them is better.",
            "For example, in the clustering we could have gone for a hard clustering methods such as K means or we could have done no clustering at all.",
            "So we just try to measure how good these clustering methods in comparison to the humanity, how much they agree with the human ratings, and we saw that the GMM method was doing much better than the key means.",
            "Anano clustering in fact was very bad.",
            "And so the intuitive reason why no casting didn't perform that well is that because there are so many outliers and outliers, make the ranking so sensitive that we would like to avoid those outliers.",
            "So it is better to do a clustering, remove the outliers and then do a ranking on top of it in terms of ranking algorithms, we saw that the Gaussian ranking was better than the list based ranking and."
        ],
        [
            "Last but not the least, then we we use the Gaussian ranking and then there is a component called WF here which is a weight function which can be used to assign different weights for different features and we try to estimate what are the best possible weights that could be assigned to features.",
            "I won't go into details of the algorithm that we use here, but.",
            "And we saw that the best correlation for the best possible that we could achieve with the human raters is like .56 for oil spill and .61 four .56 for iPhone and .61 for oil spill and our correlation was like .5 for iPhone and .400 oil spill.",
            "So overall which is a significant agreement I guess.",
            "But overall we learn from this is that mention impact and the topical signal should have slightly higher weights in the rest of the features.",
            "Though how high those words should be depends on the actual domain, depends on the actual problem that we're trying to solve and."
        ],
        [
            "Overall, to conclude, we propose a new real time algorithm which can be done which can be implemented using a distributed framework such as Hadoop or Map.",
            "Reduce an Armada, use author of greater interest and authoritativeness and the baseline models and last.",
            "But the most important, we said that microblogging is a very dynamic environment in which what can happen is that.",
            "So here we saw that the graph based algorithm is better than attack space anagrafe plus text based algorithm is better than a graph base.",
            "So there is a likely sweet spot between how much you actually put your weights on a graph stuff and how much you put your weight on the text based properties.",
            "And this can depend on the timing of the topic.",
            "This can depend on several."
        ],
        [
            "Other things, for example, if their topic is extremely important and it's raging topic or a trending topic, then it could very well be the case that the graph properties might be more important.",
            "So this is a future work that we would like to estimate.",
            "The second thing.",
            "We found here is that there can be ways to filter human beings like males, females, organizations and topical names.",
            "Given how they actually participate, and this is also we would like to see how this effects a ranking of the people and how this effects overall system."
        ],
        [
            "So that's what I have.",
            "Thanks a lot."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Yeah hi everyone, my name is Adam Paul and I am a student at University of Minnesota.",
                    "label": 0
                },
                {
                    "sent": "Ann.",
                    "label": 0
                },
                {
                    "sent": "I'm here to present my work on identifying topical authorities in microblogs.",
                    "label": 1
                },
                {
                    "sent": "This work has been done along with Scott counts from Microsoft Research and the.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Item that we focused on is given a topic.",
                    "label": 0
                },
                {
                    "sent": "How do you find the most interesting top users and the data substantial benefits in finding these users, such as they can be used for improving search engine quality and they can be used for while marketing and getting a perspective about the topic and several other things.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Moreover, the challenges in microblogs are many found.",
                    "label": 0
                },
                {
                    "sent": "For example, the scale of data that microblog site gets is quite a lot and at the same time the shortliffe time span of a topic makes gives us very interesting scenarios such as author might not even exist on a topic before the topic actually started.",
                    "label": 1
                },
                {
                    "sent": "For example, Haiti Relief Fund or maybe World Cup news.",
                    "label": 0
                },
                {
                    "sent": "These authors didn't even exist before that event actually happened.",
                    "label": 1
                },
                {
                    "sent": "So in these scenarios we would like to avoid recommending general authorities who are posting on large set of topics or celebrities.",
                    "label": 0
                },
                {
                    "sent": "For example, should here as a celebrity for World Cup, which some yeah, so we would like to avoid.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "All those people.",
                    "label": 0
                },
                {
                    "sent": "So much work has been done in expert identification and identifying authorities in several online domains in microblogs Wing.",
                    "label": 0
                },
                {
                    "sent": "It all addressed this problem, last year's wisdom, and in their approach what they do is that they compute topical distribution of users using latent digital allocation, and then the user weighted Pagerank algorithm to find out who are the topical influencers over a given topic.",
                    "label": 1
                },
                {
                    "sent": "Then they used a data set from Singapore.",
                    "label": 0
                },
                {
                    "sent": "They had a sample of a data set and they showed that their algorithm was doing better than a page rank based model and the only problem with this kind of approach is that can we do this in real time because it just doesn't look like it can be done in real time.",
                    "label": 0
                },
                {
                    "sent": "This actually motivates us to explore an alternate approach which we implemented in a near real time manner.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so our approach can be understood with this simple pipeline.",
                    "label": 0
                },
                {
                    "sent": "What we have over here is that the first phase of the pipeline is the feature selection, so we estimate that these features are important for an author to have a top authority to have an based on these feature.",
                    "label": 0
                },
                {
                    "sent": "Then we do a probabilistic clustering.",
                    "label": 1
                },
                {
                    "sent": "The idea behind clustering is that it gives us a sense of how authorities are behaving in this particular topic.",
                    "label": 0
                },
                {
                    "sent": "It could very well happen that authorities might behave very differently on one topic from a different topic.",
                    "label": 0
                },
                {
                    "sent": "And avoid us from making a very general statement about authorities like they should have this quality or that quality.",
                    "label": 0
                },
                {
                    "sent": "And once we do the clustering and then we propose a ranking method which we use to find out the top authorities on that given topic.",
                    "label": 0
                },
                {
                    "sent": "Alright, so the attractive features of our algorithm is that it can be implemented in near real time, and it can be implemented using a distributed framework.",
                    "label": 1
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Alright, so some of the terms that I've used over here as basically original tweets which other tweets proposed by the Author RT represents a retweets which we all know procede with.",
                    "label": 1
                },
                {
                    "sent": "Artie keyword and City are the conversation to eat which other tweets directed towards another user.",
                    "label": 1
                },
                {
                    "sent": "So these are the kind of tweet that an author can post in a microblogging site and.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Next we have some features based on these tweets and also the graph features that we actually take into account to propose some of the basic features.",
                    "label": 0
                },
                {
                    "sent": "One of the notable features is a self similarity score in which we actually try to see how many words are person is borrowing from his or her previous tweets.",
                    "label": 0
                },
                {
                    "sent": "So the idea here is that if a person borrows a lot of words, then the person could be a spammer.",
                    "label": 0
                },
                {
                    "sent": "If a person is boring, very few words, then a person might not be topically relevant, so.",
                    "label": 0
                },
                {
                    "sent": "Now using.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "These basic features.",
                    "label": 0
                },
                {
                    "sent": "We then compute some more refined features.",
                    "label": 0
                },
                {
                    "sent": "So for example, the number one features topic signal where we try to estimate how much this user is actually posting within the topic and how much he's posting outside the topic.",
                    "label": 1
                },
                {
                    "sent": "The second feature in that case is that signal strength.",
                    "label": 0
                },
                {
                    "sent": "OK, this person is posting within the topic.",
                    "label": 0
                },
                {
                    "sent": "What is a signal of this person?",
                    "label": 0
                },
                {
                    "sent": "So for example, a cnn.com might have a low topic signal, but will have a very high signal strength.",
                    "label": 0
                },
                {
                    "sent": "So several of these features are intuitive and then one of them is a mentioned impact.",
                    "label": 0
                },
                {
                    "sent": "I'm not sure if it's visible, but.",
                    "label": 0
                },
                {
                    "sent": "What we try to estimate over here is that how much this topic is about the person.",
                    "label": 1
                },
                {
                    "sent": "And we try to see that how other people mentioning this person over this given topic.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Well.",
                    "label": 0
                },
                {
                    "sent": "We use all these features an once we get these features then we use a probabilistic clustering method.",
                    "label": 0
                },
                {
                    "sent": "So we use Gaussian mixture model to find out all the mixtures, all the clusters.",
                    "label": 1
                },
                {
                    "sent": "So the idea here is that instead of saying that a point belongs to this cluster, we said at a point belongs to this cluster with a probability .9 and that cluster with probability .1 and.",
                    "label": 0
                },
                {
                    "sent": "This is done using expectation maximization algorithm, and once we actually find out the probabilistic clusters, we actually then the problem comes that we have to find out the right cluster and to find out the right cluster.",
                    "label": 0
                },
                {
                    "sent": "We then compute.",
                    "label": 0
                },
                {
                    "sent": "We use several heuristics such as topic, signal, redo it impact to find out which cluster contains the maximum authorities and that cluster becomes a target cluster.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "So once we get the clusters, the next step is we have to rank these people so within the clusters.",
                    "label": 0
                },
                {
                    "sent": "So in order to rank we explore two methods.",
                    "label": 0
                },
                {
                    "sent": "When is Elizabeth ranking, which is very commonly used in the second?",
                    "label": 0
                },
                {
                    "sent": "Is aggression based method in Elizabeth method we call the features independently, rank users on individual features and take an aggregate rank in the Gaussian based feature we try to estimate how good is this person over this given feature.",
                    "label": 1
                },
                {
                    "sent": "So we compute a Gaussian CDF to get a score for this person over this feature.",
                    "label": 0
                },
                {
                    "sent": "And then we actually compute the product of their scores to get the final rank of this person.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "This is actually actually the algorithm and the three states.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the algorithm and the data set we used was all public tweets for five days from 6 June 10 June.",
                    "label": 0
                },
                {
                    "sent": "It counted 290 million tweets, which is quite a substantial amount of data for five days and.",
                    "label": 0
                },
                {
                    "sent": "The topics we use for like iPhone or else will in World Cup and we use keyword extraction to find all the topical tweets.",
                    "label": 1
                },
                {
                    "sent": "Along with that we did our once you've got all these tweets then we did a data set expansion by taking into account what are the common hashtags shared?",
                    "label": 0
                },
                {
                    "sent": "What are the common URL shared and then try to expand the data set so this actually amounted to the statistics over there and.",
                    "label": 0
                },
                {
                    "sent": "We can see that iPhone is slightly bigger than oil spill in World Cup because at the time iPhone 4 was about to launch and people were talking about it a lot.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Alright, do now.",
                    "label": 0
                },
                {
                    "sent": "Validate our algorithm.",
                    "label": 0
                },
                {
                    "sent": "We just selected some baseline methods.",
                    "label": 0
                },
                {
                    "sent": "One of the baseline method was a method based on the graph properties that we selected and we added page rank over dimension graph to it and second was a text property based model and third was a random selection outside the cluster.",
                    "label": 1
                },
                {
                    "sent": "So these models will help us in estimating how good is our model and how well it is performing.",
                    "label": 0
                },
                {
                    "sent": "And then we use the same clustering and ranking algorithm that I proposed previously to build the rank list per model.",
                    "label": 1
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so now we get the top 10 users per model.",
                    "label": 1
                },
                {
                    "sent": "We see that the key observation in this table is that the number of the average number of followers for the B1 model is more than average number of followers for our model.",
                    "label": 0
                },
                {
                    "sent": "So in some sense we can say that our model is likely sweet spot between your graph based model and a pure text based model.",
                    "label": 0
                },
                {
                    "sent": "That is, it is not recommending users which have high number of followers but also not low number of followers somewhere in between.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so the top 10 users of our model look like this.",
                    "label": 1
                },
                {
                    "sent": "I haven't.",
                    "label": 0
                },
                {
                    "sent": "I have highlighted some of them.",
                    "label": 0
                },
                {
                    "sent": "For example, NWF is National Wildlife Foundation and it doesn't have that high follower count.",
                    "label": 0
                },
                {
                    "sent": "But still it's very topically relevant an actually yeah and several others of them are reserved.",
                    "label": 0
                },
                {
                    "sent": "They don't have very high number of follower count, but still they are very topically relevant.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Alright, so in order to validate our algorithm with other baseline models, we then did a human evaluation so.",
                    "label": 1
                },
                {
                    "sent": "In order to evaluate different models, we selected authors top ten authors from baseline models and 20 from our model that I've read gave us 40 authors, but open due to some overlaps and then we selected 4 original tweets posted by each author for a survey and we had participants from Microsoft who rated so they were assigned one topic randomly and within the topic they did half of the authors anonymously.",
                    "label": 1
                },
                {
                    "sent": "Half of the auto synonymously.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And anonymous screen actually looked like this, where we showed four tweets per author and we didn't show the author name and participant had to rate how interesting they find this author and how authoritative they find this author to be in the.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "On another screen, we actually showed the username, so this difference.",
                    "label": 0
                },
                {
                    "sent": "The idea behind this difference was that we would like to capture if there is a rating bias between the participants and also how good the content stands on its own and how good the content stands with the source.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Name?",
                    "label": 0
                },
                {
                    "sent": "Alright, so OK.",
                    "label": 0
                },
                {
                    "sent": "So then this is an average rating comparison.",
                    "label": 1
                },
                {
                    "sent": "These are the results and we see that our model is performing much better than the baseline.",
                    "label": 0
                },
                {
                    "sent": "B1 and B1 is performing better than B2B1 is a graph based model and beta was a text based and it actually significantly better.",
                    "label": 0
                },
                {
                    "sent": "It has a significance T test with a 95% confidence interval.",
                    "label": 1
                },
                {
                    "sent": "It is performing better than the baseline models in all the conditions except for one Topic World Cup.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so next we did a best rating comparison.",
                    "label": 1
                },
                {
                    "sent": "In this comparison what we did is that we imagine that like in a web search, what happens is that if we return end results an N minus one of them are bad.",
                    "label": 1
                },
                {
                    "sent": "But when is good and the user actually finds that result, user is happy with the search.",
                    "label": 0
                },
                {
                    "sent": "Then the same thing we do that.",
                    "label": 0
                },
                {
                    "sent": "Who is the best rated author by a participant for model and then we did a comparison of that.",
                    "label": 0
                },
                {
                    "sent": "We now see that our model is doing significantly better than all the baseline models.",
                    "label": 0
                },
                {
                    "sent": "Which actually tells us that the best person of her model is much better than the best person of Beaven, Heartbeat or B3.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK then the next thing we do, we try to compute the.",
                    "label": 0
                },
                {
                    "sent": "Precision of the models dissuaded by taking the human rating, sorting on the basis of the human ratings, and then pick the top 10 from them and see how many of our models surface in the top 10 list.",
                    "label": 0
                },
                {
                    "sent": "So what we see over here is that the precision is as high as pointed for some of the.",
                    "label": 0
                },
                {
                    "sent": "Topics and we see that our model is doing much better than the baseline.",
                    "label": 0
                },
                {
                    "sent": "B will not be too as a matter of fact.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, then we had like several components in the algorithm, such as we had a clustering component.",
                    "label": 0
                },
                {
                    "sent": "We had a list with ranking component and we just wanted to see which one of them is better.",
                    "label": 0
                },
                {
                    "sent": "For example, in the clustering we could have gone for a hard clustering methods such as K means or we could have done no clustering at all.",
                    "label": 0
                },
                {
                    "sent": "So we just try to measure how good these clustering methods in comparison to the humanity, how much they agree with the human ratings, and we saw that the GMM method was doing much better than the key means.",
                    "label": 0
                },
                {
                    "sent": "Anano clustering in fact was very bad.",
                    "label": 0
                },
                {
                    "sent": "And so the intuitive reason why no casting didn't perform that well is that because there are so many outliers and outliers, make the ranking so sensitive that we would like to avoid those outliers.",
                    "label": 0
                },
                {
                    "sent": "So it is better to do a clustering, remove the outliers and then do a ranking on top of it in terms of ranking algorithms, we saw that the Gaussian ranking was better than the list based ranking and.",
                    "label": 1
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Last but not the least, then we we use the Gaussian ranking and then there is a component called WF here which is a weight function which can be used to assign different weights for different features and we try to estimate what are the best possible weights that could be assigned to features.",
                    "label": 0
                },
                {
                    "sent": "I won't go into details of the algorithm that we use here, but.",
                    "label": 0
                },
                {
                    "sent": "And we saw that the best correlation for the best possible that we could achieve with the human raters is like .56 for oil spill and .61 four .56 for iPhone and .61 for oil spill and our correlation was like .5 for iPhone and .400 oil spill.",
                    "label": 1
                },
                {
                    "sent": "So overall which is a significant agreement I guess.",
                    "label": 0
                },
                {
                    "sent": "But overall we learn from this is that mention impact and the topical signal should have slightly higher weights in the rest of the features.",
                    "label": 1
                },
                {
                    "sent": "Though how high those words should be depends on the actual domain, depends on the actual problem that we're trying to solve and.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Overall, to conclude, we propose a new real time algorithm which can be done which can be implemented using a distributed framework such as Hadoop or Map.",
                    "label": 0
                },
                {
                    "sent": "Reduce an Armada, use author of greater interest and authoritativeness and the baseline models and last.",
                    "label": 1
                },
                {
                    "sent": "But the most important, we said that microblogging is a very dynamic environment in which what can happen is that.",
                    "label": 1
                },
                {
                    "sent": "So here we saw that the graph based algorithm is better than attack space anagrafe plus text based algorithm is better than a graph base.",
                    "label": 0
                },
                {
                    "sent": "So there is a likely sweet spot between how much you actually put your weights on a graph stuff and how much you put your weight on the text based properties.",
                    "label": 0
                },
                {
                    "sent": "And this can depend on the timing of the topic.",
                    "label": 0
                },
                {
                    "sent": "This can depend on several.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Other things, for example, if their topic is extremely important and it's raging topic or a trending topic, then it could very well be the case that the graph properties might be more important.",
                    "label": 0
                },
                {
                    "sent": "So this is a future work that we would like to estimate.",
                    "label": 1
                },
                {
                    "sent": "The second thing.",
                    "label": 0
                },
                {
                    "sent": "We found here is that there can be ways to filter human beings like males, females, organizations and topical names.",
                    "label": 1
                },
                {
                    "sent": "Given how they actually participate, and this is also we would like to see how this effects a ranking of the people and how this effects overall system.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So that's what I have.",
                    "label": 0
                },
                {
                    "sent": "Thanks a lot.",
                    "label": 0
                }
            ]
        }
    }
}