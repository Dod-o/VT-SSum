{
    "id": "pn3apbowym4afqx6zf3yokkphooasncz",
    "title": "Multilinear relaxation: a tool for maximization of submodular functions",
    "info": {
        "author": [
            "Jan Vondrak, IBM Almaden Research Center, IBM Research"
        ],
        "published": "Jan. 13, 2011",
        "recorded": "December 2010",
        "category": [
            "Top->Computer Science->Discrete Optimization"
        ]
    },
    "url": "http://videolectures.net/nipsworkshops2010_vondrak_mlr/",
    "segmentation": [
        [
            "Thank you very much.",
            "You're too kind, very happy to be here.",
            "So.",
            "I will give a sort of survey talk about some recent progress on maximization of submodular functions, so this talk will be in some sense complementary to the previous one.",
            "An I will cover bunch of different works with various people.",
            "I will try to attribute each of them to their respective people, but these are the main actors here.",
            "Grew a colonist could Chandra Chekuri, Martin Paul, or if I get involved in Rachni, Shaneice Garden and Ricos inclusive.",
            "So I don't want to assume that everybody was here for Satoru's talk, but still, I'm happy that he covered a lot of the basics already, so that would be helpful."
        ],
        [
            "You have been here.",
            "But still let me introduce submodular functions again and let me let me explain the property of submodularity from slightly different angles.",
            "So we will talk about set functions.",
            "So function assigns some value to each subset of a certain finite ground set, and this will be one way that such a function can arise and sort of running example that's good."
        ],
        [
            "Keep in mind for this stock, so this would be a function which tells me how much I value a certain set of items.",
            "So there are certain items here and the function tells me maybe plane ticket to Hawaii is worth 500.",
            "So this is my internal valuation for this item this is."
        ],
        [
            "How much it's useful to me?",
            "Jamaica maybe 4?"
        ],
        [
            "100 so now if I get both, it's not so valuable to me anymore because I'm tired of the whole thing.",
            "So it's like I'm willing to pay 600, let's say."
        ],
        [
            "Now there can be a different kind of dependency which arises as follows, which is something like left to right shoe.",
            "So one shoe alone is worth maybe $1 to me."
        ],
        [
            "But if I have both, then I'm willing to pay much more.",
            "Maybe 50 OK?",
            "So."
        ],
        [
            "Alright, so that's another kind of dependency and OK, maybe some items are sort of independence.",
            "If I get a left shoe and it's John Mica, then I'm willing to pay $401.00 'cause there's really no correlation between these two items."
        ],
        [
            "Right, So what is submodularity?",
            "One way to look at submodularity is to say that it forbids the kind of left to right shoe kind of dependency.",
            "So.",
            "For valuation function which is submodular, you don't want something like this to happen.",
            "The two items would reinforce each others value.",
            "So that's the idea here."
        ],
        [
            "Now, formally, let me let me repeat the definition that we saw in the previous talk.",
            "So set function is submodular if for any two sets the value of the Union plus the value of the intersection is at most the sum of the two values of the two sets."
        ],
        [
            "Or equivalently.",
            "If we look at marginal values of elements and this relates nicely to the previous example, what is the marginal value that's the amount of money that I'm willing to pay for item J, given that I already have asks what is the added value of J when I add it to S, so the property says and this is equivalent to the property above that if I'm adding some element to larger set, it will not add more value to the larger set then it added to the smaller set.",
            "So this is exactly what it means to be submodular for set function.",
            "Alright."
        ],
        [
            "And you can see that this is violated for the two shoes.",
            "This is exactly what should not happen, all right.",
            "So."
        ],
        [
            "I hope that's clear, so let me give you 2 examples which are sort of Canonical.",
            "The first example is something that we call coverage function.",
            "So here we have some system of sets.",
            "And I'm defining a function on.",
            "Subsets of indices of these sets.",
            "So what I'm saying is let me take some subcollection of these sets and the function measures.",
            "How large is the union of these sets?",
            "In other words, how much do these sets cover together so the blue area would be the value of two and four?",
            "That's what these two sets cover together, and it's pretty easy to see that this type of function is always submodular.",
            "The second example.",
            "Is the one which was very important in Satori stalk and this is the cut function in a graph.",
            "So in in a graph.",
            "Defining a function on the vertices of the graph.",
            "And for a set of vertices I define the value of this set as the number of edges.",
            "That cross the boundary of this green set.",
            "That's what we call the cut induced by this set.",
            "And this function is also known to be submodular.",
            "So just one more remark here, just one difference between these two functions.",
            "The first function is monotone in the sense that adding more elements can only increase the value of the function.",
            "This is not true in this example, naturally becausw.",
            "The value of the empty set is 0.",
            "Now if you keep adding vertices, presumably the cut will increase, but at the end when you include all the vertices, the values again 0, so it goes up and down.",
            "It's not monotone, so these are actually the two Canonical examples.",
            "I would say of monotone submodular function and a non monotone submodular function.",
            "But there are many other examples as well, and Satoru mentioned quite a few."
        ],
        [
            "So in this talk I want to talk about problems that involve maximising such functions.",
            "And just to put it in contrast with Satori stalk.",
            "Minimizing submodular functions is in some sense of very nice problem, because you can solve it optimally.",
            "Now.",
            "Maximization you can consider under various constraints, but even the basic problem of maximizing submodular function without any constraints captures the maximum cut problem in graphs, which is an NP hard problem, and there are other NP hard problems which arise as special cases in this framework.",
            "So we cannot expect in general to maximize submodular functions exactly optimally."
        ],
        [
            "In fact, in some sense it's even worse, because the natural model for working with set functions is that we have some Oracle that provides values of this function, so we don't have the input given explicitly as a graph or some other explicitly written structure.",
            "But we have a black box that we can ask what is the value of this set?",
            "What is the value of that?",
            "And that's the model we would like to work in.",
            "In this model, you can actually prove unconditional hardness results, so you can say that maximizing submodular function requires unconditionally an exponential number of queries.",
            "It's not related to the question of P versus NP, so just information theoretically it's very hard to find what the optimum is.",
            "Alright, but"
        ],
        [
            "We don't want to give up so easily.",
            "The structure of submodular functions is quite interesting in this sense.",
            "That it allows you to have some positive results even for maximization, and this is actually related to the question are submodular functions more like convex functions or are they more like concave functions?",
            "And I think this question doesn't have a very clear answer an in some sense I would say that the answer is that submodular functions exhibit some aspects of both convexity and concavity.",
            "Anne.",
            "In problems where you want to maximize, you would like to exploit the concave aspect of submodular functions, so that would be the theme of this talk.",
            "How can we exploit this concave aspect?",
            "Formally, what we are looking for is some sort of approximation algorithm, so we would like to have an algorithm which returns a solution which is always at least a certain fraction Alpha.",
            "Of the optimal solution.",
            "And.",
            "In all cases that I will mention here, we will work with functions which are always non negative, so this makes sense.",
            "We will not think about negative values."
        ],
        [
            "OK, so first of all, approximation algorithms with pretty nice approximation factors are known for many of the problems.",
            "Classical problems which are actually special cases of.",
            "Maximizing a submodular functions.",
            "So some of these problems are maximum K cover.",
            "What is that?",
            "It's just given a bunch of sets.",
            "Choose K sets in order to maximize the Union.",
            "The size of the union of these sets.",
            "So for this problem, 1 -- 1 / E approximation has been known for a long time.",
            "And this number will appear multiple times.",
            "In this talk, something like 0.63.",
            "And somehow it turns out to be an important number here.",
            "OK?",
            "Max cuts.",
            "It's known that you can achieve this kind of approximation by the celebrated goldmans Williamson algorithm, which introduced some definite programming to approximation algorithms, and I just wanted to mention that even in hypergraphs where you have hyper edges of larger size.",
            "You can consider the maximum cut problem an it's actually still a submodular maximization problem.",
            "In fact, the larger the hyperedges get K is the size of these hyperedges, the easier the problem becomes.",
            "So in the limit, you can actually get closer and closer to the optimal solution.",
            "Alright, so so these are some special cases and.",
            "This is just some evidence that we might hope for good approximation results in general for such problems."
        ],
        [
            "So the main questions here are.",
            "1st just from a theoretical point of view, can we extend these results to arbitrary submodular functions?",
            "Maybe more Interestingly, is there some unifying framework, some algorithmic framework that would explain why these problems are nice and why they are tractable, at least in the approximate sense?"
        ],
        [
            "But there's another motivation, which sort of popularized these problems recently, and this comes from.",
            "Algorithmic game theory or computational economics, where the submodular functions that arise are not given by specific combinatorial settings like the coverage setting or cut functions in graphs, but the notion of submodularity comes from the economic interpretation that a certain valuation function has the property of diminishing returns, so that's another way that such functions could arise without being given a specific combinatorial structure.",
            "Anne.",
            "There are two properties here that I actually mentioned already monotonicity.",
            "So what does monotonicity mean in this setting?",
            "It means that you can discard items for free.",
            "It never hurts if you get more items.",
            "So you don't have to recycle or something like that.",
            "Parity means that the more you have, the less you're willing to pay for the next item.",
            "So.",
            "So these are.",
            "Interpretations which.",
            "Which allow you to say that maybe in this setting it's reasonable to assume that the valuation function satisfies these properties without saying explicitly what the function is.",
            "So that's another direction where this came from and sort of revived interest in submodular functions actually, so that's one of my motivations here."
        ],
        [
            "And let me mention now more specific problem which comes exactly from this angle.",
            "So this problem is called a submodular welfare problem, and it arises in combinatorial auctions.",
            "Now what we have here is a set of M items and then we have N players who have valuation functions on these items.",
            "So let's assume for now that these valuation functions are monotone and submodular.",
            "And the problem here is to allocate these items."
        ],
        [
            "To the players.",
            "In a way that maximizes what is called the social welfare.",
            "Which is the sum of the utilities that all the players together derive from this allocation.",
            "OK, so in combinatorial auctions there's one other issue which is the issue of truthfulness.",
            "Can you actually trust the players when you ask them what is the value of this set?",
            "What is the value of that?",
            "So I'm not going to deal with this issue here, I'm talking about the optimization problem.",
            "So this is the core optimization problem which you need to deal with, but in an actual auction there are other serious issues as well.",
            "But OK, this is an optimization problem.",
            "And.",
            "Let's see what we can do about it."
        ],
        [
            "Now before I before I go to what's known about this problem.",
            "Let me say that this was actually stated as an example of a more general framework, so now this framework will seem a little bit abstract, maybe, but it's a very useful way of looking at things so in.",
            "In this paper by Fisher, Nemhauser, and Wolsey, which introduced the first ideas in submodular maximization, they actually formulated.",
            "The following problem.",
            "So in this problem we have just one monotone submodular function F and then we have a matroid M defined on the ground set.",
            "So I will get to the definition of a matroid in a minute.",
            "And the problem is.",
            "Maximize F of X overall sets independent in the matroid.",
            "Alright."
        ],
        [
            "So how is this related to the allocation problem that I described in the previous slide?"
        ],
        [
            "Alright, so in matroid is simply a system of sets that we call independent.",
            "Now you call it a matroid if it satisfies certain axioms, and let me not dwell on these axioms too much, but let me just say that these are the natural properties that linear independence between vectors satisfies, so it's a combinatorial abstraction of a property similar to linear independence between vectors.",
            "These axioms simply say that a subset of an independent set is always independent, and if you have a larger independent set, then you can always extend the smaller one by adding something from the larger independent set.",
            "In fact."
        ],
        [
            "In this talk.",
            "What will be important is a very simple special type of matroid, so let me explain what this matroid is.",
            "This is called the partition matroid.",
            "And it's defined as follows.",
            "You have a ground set and it's partitioned into a bunch of.",
            "Let's call them blocks.",
            "Columns.",
            "So now I have to say, when is a set independent, so I just say that the set is independent if it contains at most one element from each column.",
            "It's very simple.",
            "So I call all such sets independent.",
            "There's also a notion of basis, which is similar to bases in vector spaces.",
            "Basis would be a maximal independent set, so that would be a set like this which contains exactly one guy from each column.",
            "Um?",
            "Alright, so these are Metro."
        ],
        [
            "Right?",
            "And now I want to show this reduction because it's pretty simple and.",
            "It's quite useful, so we have this allocation problem.",
            "The submodular welfare problem where we have N different.",
            "Submodular functions each player might have a different valuation function.",
            "And I would like to transform that into an optimization problem which has only one objective function, yes?",
            "I I see I didn't say monotone on this slide, but yes, I still assume that their monotone thanks."
        ],
        [
            "So in fact the reduction does not depend on that.",
            "The objective function that you would get in the new problem would be either monotone or non monotone depending on what you start from.",
            "But yes, I still want to assume that their model.",
            "So what is the reduction here?",
            "Well, let's do the following.",
            "Let's just take each item.",
            "So now each column corresponds to one item of the original ground set.",
            "And I will create N copies.",
            "Of each item, one copy for each player.",
            "So the new ground set is a Cartesian product of the set of players and a set of items.",
            "OK, so now I will define a new function on the new ground set, which is very natural.",
            "Is the function F which for any set here.",
            "Well, simply add up.",
            "The contributions that their respective players get from the items which are allocated to them in that set.",
            "You can interpret each set here as a certain allocation where the red players will get whatever copies you took from the top row.",
            "And now in this definition you can take any set, even the entire Cartesian product would be would be assigned some value, but it's not an actual set that you can allocate right?",
            "Because you have only one copy of each item.",
            "So the constraint here is that from each column you can only take one element.",
            "So this is just a simple reformulation of the problem.",
            "Nothing mysterious is happening here.",
            "The problem the submodular welfare problem is equivalent to saying.",
            "That I want to maximize this new objective function F subject to a partition matroid.",
            "Where from each column I'm allowed to take at most one item.",
            "OK, so maybe at this point it looks like needless gain to reduce the problem to this framework."
        ],
        [
            "Actually, it's quite useful to think about it this way, so let me say what is known about these problems and this starts really with the Seminole work of Nemhauser, Wolsey and Fisher in the 70s.",
            "So the first message here is that very simple greedy algorithms or local search type algorithms work very well for these problems already in many cases.",
            "So for example, the problem where you want to maximize a monotone submodular function subject to selecting at most K elements.",
            "For this problem, the greedy algorithm already gives you a 1 -- 1 / E approximation, and this is actually known to be optimal.",
            "If you generalize this problem slightly, if you replace the condition that I'm selecting at most K elements by selecting an independent set in a matroid.",
            "Then the problem gets slightly more difficult.",
            "The greedy algorithm actually gives a 1/2 approximation.",
            "And it's not known it wasn't known if this is optimal or not.",
            "Now you can also ask what can you do if you maximize a non monotone submodular function.",
            "That's like the problem, generalizing maximum cut.",
            "In graphs, so for this problem local search also gives a pretty nice approximation 1/3, and we proved with verify again that you cannot do better than 1/2.",
            "So the answer is somewhere between 1/3 and 1/2.",
            "But then there's some other problems for which actually these simple algorithms don't work that well.",
            "Let me mention 11 problem which is quite natural.",
            "It's called maxmin.",
            "Allocation sometimes this problem is called the Santa Claus problem.",
            "In this problem you also want to allocate items, but you want to maximize what the least happy Agent gets.",
            "So it's like distributing presents to kids to maximize for the least.",
            "Happy Child receives.",
            "Actually, this problem is much more difficult from an approximation point of view.",
            "Is very difficult even if the utility functions are just additive.",
            "If you just add up some values over items, it's already very hard.",
            "OK, so for these problems and then I'm mentioning here a problem where you maximize a submodular function subject to general linear constraints.",
            "Let's say constant number of general linear constraints.",
            "So such problems have been also studied for these problems.",
            "This simple algorithms don't work really, blow doesn't they don't give any constant factor for sure.",
            "So that's the landscape."
        ],
        [
            "But the question here is really, what can we do except some sort of combinatorial search algorithm like what is the tool that we could possibly apply here?",
            "So I would like to put that in perspective with problems with."
        ],
        [
            "There.",
            "Where the objective function is linear.",
            "In those cases, natural tool that's been used over and over is linear programming, so you can replace a discrete problem by continuous problem, which in many cases turns out to be a linear program which you can solve exactly.",
            "And then maybe you can go back to your original discrete problem and use that fractional solution somehow.",
            "So I would like to do a similar thing for these problems, where the objective function is.",
            "Not linear, it's a submodular function.",
            "So the question is, there are two things that we have to replace here.",
            "The objective function and the set of feasible solutions.",
            "So you replace the objective function by some continuous function and you replace the feasible region by some convex."
        ],
        [
            "Yep.",
            "So the second part we just do what is standard.",
            "We take the set of feasible sets.",
            "And we interpret them as 01 vectors and we replace that by the convex Hull of these characteristic vectors.",
            "So that would be the polytope which corresponds to the set system F. And that's very natural.",
            "Well, sometimes this is already too complicated, but let's say.",
            "Let's say we can do that for some special subsystems."
        ],
        [
            "But the more interesting question is what form of continuous function do you choose for replacing the objective function F?",
            "Anne.",
            "And I want to promote the following type of extension which seems to be working well for maximization problems.",
            "So what do we do here?",
            "We take a fractional solution just a point in the cube.",
            "01 to the end.",
            "And I want to define a value for this point.",
            "OK, so how is this value defined?",
            "Let's define it by a random experiment.",
            "Where I interpret the coordinates of this vector Y as probabilities and I pick each element I with probability corresponding to YJ.",
            "So I pick it with probability YJ and I don't pick it with probability 1 -- y G. So I do that independently for each element of the ground set.",
            "This will give me some.",
            "Random 01 vector which can be interpreted as a random set.",
            "And I know what the value of such set is is given by the function F. So let me take the expectation over this random experiment.",
            "OK, so this is what we call the multilinear extension of F, and we call it multilinear becausw.",
            "This actually turns out to be a multilinear function of these variables, Y one through YN, and it's quite easy to see.",
            "It's actually the unique multilinear polynomial on the hypercube, which coincides with your values on the vertices values are given on the vertices, and you want to interpolate inside the cube, and this is the unique multilinear polynomial which achieves that.",
            "Doesn't make sense.",
            "Hey.",
            "Haha.",
            "So.",
            "So far it's not clear how we can actually evaluate this, and we cannot evaluate it exactly.",
            "So we will only evaluate it approximately right?",
            "So we will.",
            "We will get some error bounds that we have to deal with, and that's actually somehow in terms of running time.",
            "This will be the most.",
            "Most serious issue.",
            "But in principle.",
            "OK, so now there's this gap between theory and practice, right?",
            "So theoretically speaking there is no big issue here, because you can estimate it, let's say by taking N squared samples within additive error 1 / 1 over North.",
            "So if you take em to the four samples, you get additive error, one over and squared, and that would be actually enough for the analysis.",
            "But in practice, you have to think about this a little bit more.",
            "How you can speed it up, but for now, let's actually assume that we can evaluate this function.",
            "OK, I will cheat and I will assume that this is an efficiently computable function."
        ],
        [
            "So you might ask, why do we choose this particular extension?",
            "There are actually several choices that we have several Nat."
        ],
        [
            "The choices that we have, so one is that Satoru mentioned in his talk the Lovasz extension is the most famous way of extending a submodular function to a continuous function on the cube.",
            "And.",
            "It can be viewed in this way which.",
            "Which is equivalent to what subtotal described.",
            "I want to put in this framework because I'm thinking of all the extensions as some sort of expectation.",
            "So this is one way to define the Lovasz extension.",
            "You take a random threshold Lambda which is uniformly chosen between zero and one.",
            "And you take all the elements whose coordinate is at least Lambda or strict.",
            "Doesn't matter, at least Lambda.",
            "So in expectation this is exactly the Lovasz extension.",
            "So what is the problem with this last extension?",
            "Well, it's a convex function for submodular functions, so it's actually great for minimum minimization problems.",
            "But we cannot use it for maximization problems."
        ],
        [
            "Now, if you want something that looks good for maximization, what is it?",
            "It's a concave function.",
            "So what if we take the concave extension of this function, which you can define for any function defined on the vertices of a cube, you can take essentially the convex combination which maximizes.",
            "Which maximizes this value.",
            "You can do this for any set function.",
            "And this will give you a convex concave function.",
            "I'm sorry this will be a concave function, but there's another problem with that.",
            "It actually we cannot evaluate this function and we cannot do that even approximately.",
            "So that's not useful either."
        ],
        [
            "And the multilinear extension is some sort of compromise between these two.",
            "It's sitting somewhere between the convex and concave.",
            "Extensions of F. And actually it's not convex and it's not concave either.",
            "But it can be evaluated up to these sampling issues.",
            "So what is the property that the multilinear extension satisfies that we can use?",
            "It's not convex, not concave.",
            "What can we use about it?",
            "There's one nice condition that it satisfies which, which is a sort of strange condition from continuous optimization point of view.",
            "This is the condition that you get.",
            "This is exactly equivalent to being submodular.",
            "It's the condition that all second partial derivatives are non positive.",
            "Any question?",
            "OK, this is the condition that you get.",
            "In some sense, it's pretty natural because it means that the first partial derivatives which correspond to marginal values when you move them up, they can only decrease.",
            "That's that's the second partial.",
            "That's what the second partial derivative means, and this is true for all pairs IJ, including I equal to J, so.",
            "If you differentiate the same variable twice, you also get.",
            "The concept of multilinear.",
            "While this comes so it comes out of some earlier work by a given three Danko.",
            "And then and then we used it with Gruyere cleaner school and gender, chicory, Ann Martin Paul.",
            "For for submodular functions, this is the sort of new idea here.",
            "But OK, this is the nice condition that we have.",
            "And how do we use it?",
            "How much time do I mean?",
            "Not so much?",
            "15 minutes OK thanks.",
            "Anne."
        ],
        [
            "Alright, so there are two questions here.",
            "Can we even solve the continuous problem because it's not convex and it's not concave either.",
            "And then even if we can solve it, what can we do with a fraction solution?",
            "So these are both non obvious.",
            "So first let me deal with the question of solving the continuous problem."
        ],
        [
            "So what do we have?",
            "We have some polytope and we would like to optimize a function over this polytope and all we know is that the function is the multilinear extension of monotone submodular function, an.",
            "Essentially, we have this condition on the second partial derivatives.",
            "That's all we have.",
            "So here is an algorithm which.",
            "A widget does something.",
            "It doesn't solve the problem optimally, but it will do something useful."
        ],
        [
            "So let's try the following.",
            "Let me define for each point.",
            "Something that I want to call a greedy direction.",
            "So this is for each point Y sum.",
            "Vector which is obtained by maximising V dot gradient of F over the polytope.",
            "So.",
            "OK, so people ask about this a lot.",
            "Is it like gradient descent or is it not well?",
            "It's not.",
            "It's not, the algorithm is not going to be gradient descent and you can see that there's something something interesting happening here.",
            "The direction does not depend only on the behavior of the function at that point.",
            "It also depends on the structure of the polytope.",
            "Because I take this linear form which is given by the gradient.",
            "So that's where the function comes in.",
            "But I maximize that over the polytope.",
            "So some directions might actually be more profitable because the polytope extends further in those directions, right?",
            "So this vector field.",
            "It doesn't depend only on the function.",
            "It also depends on the polytope somehow combines these two together."
        ],
        [
            "And once we have these greedy directions, we just run a very simple algorithm.",
            "Which can be phrased as follows.",
            "You start from the origin Ann you.",
            "You drop a particle here and you let it flow along these arrows for unit amount of time.",
            "Ann, wherever you end up after unit amount of time that will be your solution.",
            "So you don't try to go.",
            "As long as there is some improvement possible, you just do this for a unit amount of time and you stop and that's it.",
            "You get something like conjugate gradient descent, huh?",
            "So I would be very interested if you can put it in some framework like that.",
            "So it will be conjugate.",
            "So how does the polytope come in?",
            "Because if you if you want to minimize along rubbing, you want to go along.",
            "So you think that you take the global structure of the metric into account for minimalization looks like and.",
            "So let's yeah, let's discuss.",
            "I still think that conjugate gradient only looks at the function of the polytope, but.",
            "Projection.",
            "Predicted.",
            "Proceed along creating nothing and then project along onto the polytopes.",
            "Are you referring to that question or it's independent?",
            "OK, OK, so you're asking what this means in some sense.",
            "Oh, I see I see.",
            "OK, so let's yeah, let's leave that for offline.",
            "That's interesting, because maybe this is the right community actually to ask this question.",
            "What is really happening here?",
            "So OK, so I'm not claiming that this algorithm solves the problem optimally, but."
        ],
        [
            "But I want to claim that it solves it within a factor of 1 -- 1 / E. And in fact, it is known that this is the optimal factor that you can achieve for this problem so.",
            "For worst case analysis, there's no point trying to improve the solution by some further tricks.",
            "This is the best factor you can achieve.",
            "In general, OK, in practice, maybe you want to do some more tweaks, but this is it.",
            "So the first claim.",
            "The first claim is that the final point is actually in the polytope, and it's pretty easy to see because at each point we are moving along the direction which is given by vector, which is in the polytope.",
            "So it's like an integral from zero to 1.",
            "Of vectors which are in the polytope, like a convex combination.",
            "So you're still in the polytope, so this is easy to see.",
            "So this claim is.",
            "The interesting part of it.",
            "And the."
        ],
        [
            "Life is actually quite simple, so.",
            "So now how do we use the property that the second partial derivatives are non positive?",
            "So another way to say that is that if you move along a direction which is given by non negative vector, the function is actually concave.",
            "Right, so there's some special directions.",
            "The positive orthant where the function is actually concave.",
            "So we can prove this lemma.",
            "Which says that for any point when you look at the greedy direction that I defined.",
            "You take the dot product with the gradient.",
            "This will be at least the optimal value minus my current value.",
            "What I have at that point."
        ],
        [
            "And why is this true?",
            "Well, I'm not going to prove it here, but it's sort of intuitive given the fact that the function is concave along any direction that's only increasing in all coordinates.",
            "So you can essentially say.",
            "Some technicalities that if you move from the current points towards the actual optimum.",
            "Then this kind of inequality is satisfied by the concavity argument.",
            "But I'm not moving towards the the actual optimum moving in some other direction.",
            "Which dominates that.",
            "So the inequality.",
            "Certainly satisfied.",
            "OK, I just hand waved it but.",
            "This is the idea.",
            "So at any point.",
            "My current rate of increase.",
            "Is at least the difference between the optimal value and the value that I have right now?",
            "So this is the kind of dynamic which leads to."
        ],
        [
            "The factor of 1 -- 1 / E. Just solve this differential equation.",
            "You get that at time T. My values at least 1 -- E to the minus T times the optimal, so it's time 1 you get 1 -- 1 ovary.",
            "It's a very simple dynamic process.",
            "OK."
        ],
        [
            "Alright, so let me summarize this part.",
            "I showed you how we can solve the continuous problem up to some technicalities, sampling and so on.",
            "There's another point here, which I should have mentioned is that what we really need in the algorithm is being able to maximize linear functions over the polytope, so you can implement this for any polytope such that you can optimize linear functions, and you can do that for any nice polytope, let's say given by a separation Oracle or something like that.",
            "So in this generality, you can always achieve this factor of 1 -- 1 / E."
        ],
        [
            "Now I will not say much about how to deal with non monotone submodular functions, but quite recently we developed techniques which allow you to achieve constant factors.",
            "Also, if the objective function is non monotone submodular, this actually uses some quite interesting approach, motivate, motivated by simulated annealing.",
            "It's more complicated and achieve some.",
            "Factors which are not so nice.",
            "But here are the numbers if you just optimize over the pure hypercube then you get a factor of 0.41 an for any down closed polytope you get 0.325.",
            "So we sort of know how to optimize this multilinear extension even for non monotone submodular function."
        ],
        [
            "So now let me go to the second part.",
            "How do we around the fractional solution?",
            "Well, the first case, if the polytope is the hypercube itself, then it's very easy.",
            "We just use the definition of the multilinear extension itself.",
            "You take your point, you around, in dependently the coordinates based on these probabilities and by definition the expectation of what you get is exactly the value of this extension, so that's.",
            "Trivial, so immediately you get.",
            "0.41 for maximizing non monotone submodular function.",
            "Without any constraints."
        ],
        [
            "Now, in the case of the submodular welfare problem, we have some constraints, but they are pretty simple and they're very natural.",
            "So when you look at the reduction.",
            "The interpretation of the fractional solution.",
            "Is that the value of the fractional solution?",
            "Is the expected value of a certain random assignment where you just give each item to each player with a probability corresponding to the variable YIJ so the variables really correspond to probabilities that you give the item to that player, and that's exactly the objective function.",
            "So what are the constraints here?",
            "Well, the constraints say that for each item the probability is summed up over players.",
            "Some of the at most one.",
            "So that's great.",
            "That means that this is a probability distribution.",
            "I can just take."
        ],
        [
            "The item and allocated to player I with probably YIJ.",
            "And in expectation I get exactly this value, which I know to be at least 1 -- 1 / E times opt.",
            "So that achieves.",
            "The optimal factor for this problem.",
            "That's one application."
        ],
        [
            "But in fact you can extend it to this more general setting of a matroid constraint, and I'm not going to say how, but you can do for any matroid.",
            "The following you can start from some point in the matroid polytope, which is why I think you called the marginal polytope in this community, right?",
            "So any point which is given by marginals of some convex combination of independent sets?",
            "You can move from that point."
        ],
        [
            "An actual independent set in a matroid in such a way that you don't lose in terms of the objective function.",
            "So here's the summary.",
            "The algorithm has two parts, the blue part is the continuous greedy algorithm which finds a fractional solution of value at least 1 -- 1 / E. And in the second part, you move from that point again along certain special directions, and those directions are actually chosen such that the function is convex along these arrows.",
            "So.",
            "So this picture is somehow exploits.",
            "At both aspects of submodularity, it exploits the concave aspect in the blue portion.",
            "And the convex aspect in the red part in the rounding procedure.",
            "And that leads to this.",
            "The result which sort of unifies bunch of different scenarios where the factor was either known or obtained recently.",
            "So somehow this is the right framework for all these 1 -- 1 / E result.",
            "Right?",
            "So.",
            "I'm almost OK."
        ],
        [
            "Thank you so.",
            "Oh haha, so there are actually a bunch of other applications where this framework gives constant factor where no constant factor was known.",
            "Well so far I only talked about basically improving constant factors, But some recent work this has been extended to a bunch of problems where it really gives a new result.",
            "In terms of.",
            "Whether there is a constant at all or not."
        ],
        [
            "And finally, very quickly I want to say that this framework also serves.",
            "As a tool to derive hardness results, so that's a little bit surprising, but you can actually take this framework of multilinear relaxation, and you can derive impossibility results.",
            "Using something called the symmetric gap so.",
            "So very briefly.",
            "The way this works is that you start from some instance which has certain symmetric properties and you compare."
        ],
        [
            "Put a certain number."
        ],
        [
            "Which is called the symmetry gap, and what is the symmetry gap?",
            "Intuitively it's just looking at the multilinear relaxation of the problem, and you compute the gap between the best solution and the best symmetric solution.",
            "So this will be some number, it's just a number for fixed instance.",
            "And then we have a procedure which will take this instance in some sense, blow it up to a class of instances.",
            "Such that on this class you will get a certain hardness result.",
            "Well X bar.",
            "Yeah, I didn't quite define it formally, but given an instance which has certain symmetric properties, there's some group of permutations which keeps it invariant.",
            "So this will.",
            "This would be all the solutions.",
            "Which are invariant under these permutations?"
        ],
        [
            "So I have an example here, but I think I'm running out of time, so probably."
        ],
        [
            "I'll skip that the way this works is you take some very simple instance and you compare the best solution.",
            "This would be just Max cut on one edge.",
            "What is the best solution?",
            "It's just cutting the edge value one.",
            "What is the best symmetric solution while the instant is symmetric under flipping these two vertices and the best symmetric solution is.",
            "One half 1/2.",
            "In terms of the multilinear relaxation.",
            "And the value of that is 1/2.",
            "So the gap."
        ],
        [
            "Here is 1/2 or factor 2."
        ],
        [
            "So the general."
        ],
        [
            "I'm here is that.",
            "From any instance which looks like that it has some gap, you can actually blow it up and you will get a hardness result, which is based somehow on the fact that you can fool any algorithm and force it to only find symmetric solutions.",
            "So basically you can prove that no algorithm will be able to.",
            "Beat the gap between the best solution and the best symmetric solution.",
            "So for example, this will prove that for maximizing submodular functions without any constraints.",
            "Non monotone submodular functions, which is a generalization of Max cut.",
            "You cannot beat the factor of 1/2.",
            "But there's a lot of."
        ],
        [
            "Machinery hidden here, which I'm skipping, so let me let me just summarize with what is known.",
            "This is the landscape now.",
            "Any question about I really went over it very far."
        ],
        [
            "Sorry so I didn't explain how.",
            "How to prove?"
        ],
        [
            "Works, but basically from a gap in a single instance.",
            "You get automatically a hardness result.",
            "That's how it works.",
            "An IT unifies some earlier known hardness results and it gives some new harness results.",
            "So basically this is what we know at the moment for monotone submodular functions we sort of know what's going on, so for a broad range of constraints you can achieve this.",
            "Factor 1 -- 1 over East.",
            "For more complicated constraints, you cannot achieve it, but I'm not listing all the known results here.",
            "For non monotone submodular functions the numbers are not so nice, but the gaps are sort of getting closer, so we have some rough picture of what's going on.",
            "I think I'll just stop here.",
            "Yes, so why am I listing?",
            "OK, this is sorry.",
            "This is a cardinality equality constraint, so this is the problem where you maximize F of S subject to cardinality of as being equal to K. And that's actually.",
            "It's not clear.",
            "It seems more difficult than these cases.",
            "Which are the constraints are down closed, but in terms of hardness results we have the same hardness result for these two so.",
            "We don't quite understand what's going on.",
            "Any other questions?",
            "Simulated annealing algorithm.",
            "Use the extension, but that works on set yes, so it's another way to solve this multilinear relaxation of a problem where the objective is non monotone submodular an it's essentially the following algorithm you, so it's a local search algorithm under certain noise which is controlled by some parameter which can be called temperature, and you start from essentially uniformly random solution, which is like infinite temperature an.",
            "You gradually decrease the temperature while performing local search about temperature, so it's not exactly simulated annealing, but I think there's some analogy there and it can be proved that it gives these factors which are best known currently, so it works nicely somehow.",
            "So it seems like.",
            "Seems like the kind of constraints that you were talking about here for the so much longer function maximization problem are very different than the kinds of constraints that support was talking about this so much about humanization.",
            "Yes, running?",
            "Why are they types of constraints?",
            "Sort of different employers.",
            "Yeah, good question.",
            "Yeah, so so for maximization problem, it's natural to consider packing type constraint where something is at most something you maximize overset South such that.",
            "The size of South is at most something or some linear function is at most something.",
            "For minimization problems it's more natural to consider covering constraints.",
            "And there are some intersections, yes, and I didn't list all the known results here.",
            "In fact, for non monotone submodular functions.",
            "I think the most natural constraints are those which are sort of sitting in the middle, like these problems, like minimum by section in graph or maximum by section, where you say that you want to cut such that both sides are equal or approximately equal.",
            "So that kind of constraint is maybe the most natural one here.",
            "Um?",
            "Yeah.",
            "Thanks."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Thank you very much.",
                    "label": 0
                },
                {
                    "sent": "You're too kind, very happy to be here.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "I will give a sort of survey talk about some recent progress on maximization of submodular functions, so this talk will be in some sense complementary to the previous one.",
                    "label": 0
                },
                {
                    "sent": "An I will cover bunch of different works with various people.",
                    "label": 0
                },
                {
                    "sent": "I will try to attribute each of them to their respective people, but these are the main actors here.",
                    "label": 0
                },
                {
                    "sent": "Grew a colonist could Chandra Chekuri, Martin Paul, or if I get involved in Rachni, Shaneice Garden and Ricos inclusive.",
                    "label": 0
                },
                {
                    "sent": "So I don't want to assume that everybody was here for Satoru's talk, but still, I'm happy that he covered a lot of the basics already, so that would be helpful.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You have been here.",
                    "label": 0
                },
                {
                    "sent": "But still let me introduce submodular functions again and let me let me explain the property of submodularity from slightly different angles.",
                    "label": 0
                },
                {
                    "sent": "So we will talk about set functions.",
                    "label": 0
                },
                {
                    "sent": "So function assigns some value to each subset of a certain finite ground set, and this will be one way that such a function can arise and sort of running example that's good.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Keep in mind for this stock, so this would be a function which tells me how much I value a certain set of items.",
                    "label": 0
                },
                {
                    "sent": "So there are certain items here and the function tells me maybe plane ticket to Hawaii is worth 500.",
                    "label": 1
                },
                {
                    "sent": "So this is my internal valuation for this item this is.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "How much it's useful to me?",
                    "label": 0
                },
                {
                    "sent": "Jamaica maybe 4?",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "100 so now if I get both, it's not so valuable to me anymore because I'm tired of the whole thing.",
                    "label": 0
                },
                {
                    "sent": "So it's like I'm willing to pay 600, let's say.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now there can be a different kind of dependency which arises as follows, which is something like left to right shoe.",
                    "label": 0
                },
                {
                    "sent": "So one shoe alone is worth maybe $1 to me.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But if I have both, then I'm willing to pay much more.",
                    "label": 0
                },
                {
                    "sent": "Maybe 50 OK?",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Alright, so that's another kind of dependency and OK, maybe some items are sort of independence.",
                    "label": 0
                },
                {
                    "sent": "If I get a left shoe and it's John Mica, then I'm willing to pay $401.00 'cause there's really no correlation between these two items.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Right, So what is submodularity?",
                    "label": 0
                },
                {
                    "sent": "One way to look at submodularity is to say that it forbids the kind of left to right shoe kind of dependency.",
                    "label": 1
                },
                {
                    "sent": "So.",
                    "label": 1
                },
                {
                    "sent": "For valuation function which is submodular, you don't want something like this to happen.",
                    "label": 0
                },
                {
                    "sent": "The two items would reinforce each others value.",
                    "label": 0
                },
                {
                    "sent": "So that's the idea here.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now, formally, let me let me repeat the definition that we saw in the previous talk.",
                    "label": 0
                },
                {
                    "sent": "So set function is submodular if for any two sets the value of the Union plus the value of the intersection is at most the sum of the two values of the two sets.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Or equivalently.",
                    "label": 0
                },
                {
                    "sent": "If we look at marginal values of elements and this relates nicely to the previous example, what is the marginal value that's the amount of money that I'm willing to pay for item J, given that I already have asks what is the added value of J when I add it to S, so the property says and this is equivalent to the property above that if I'm adding some element to larger set, it will not add more value to the larger set then it added to the smaller set.",
                    "label": 0
                },
                {
                    "sent": "So this is exactly what it means to be submodular for set function.",
                    "label": 0
                },
                {
                    "sent": "Alright.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And you can see that this is violated for the two shoes.",
                    "label": 0
                },
                {
                    "sent": "This is exactly what should not happen, all right.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I hope that's clear, so let me give you 2 examples which are sort of Canonical.",
                    "label": 0
                },
                {
                    "sent": "The first example is something that we call coverage function.",
                    "label": 1
                },
                {
                    "sent": "So here we have some system of sets.",
                    "label": 0
                },
                {
                    "sent": "And I'm defining a function on.",
                    "label": 0
                },
                {
                    "sent": "Subsets of indices of these sets.",
                    "label": 0
                },
                {
                    "sent": "So what I'm saying is let me take some subcollection of these sets and the function measures.",
                    "label": 0
                },
                {
                    "sent": "How large is the union of these sets?",
                    "label": 0
                },
                {
                    "sent": "In other words, how much do these sets cover together so the blue area would be the value of two and four?",
                    "label": 0
                },
                {
                    "sent": "That's what these two sets cover together, and it's pretty easy to see that this type of function is always submodular.",
                    "label": 0
                },
                {
                    "sent": "The second example.",
                    "label": 1
                },
                {
                    "sent": "Is the one which was very important in Satori stalk and this is the cut function in a graph.",
                    "label": 0
                },
                {
                    "sent": "So in in a graph.",
                    "label": 0
                },
                {
                    "sent": "Defining a function on the vertices of the graph.",
                    "label": 0
                },
                {
                    "sent": "And for a set of vertices I define the value of this set as the number of edges.",
                    "label": 0
                },
                {
                    "sent": "That cross the boundary of this green set.",
                    "label": 0
                },
                {
                    "sent": "That's what we call the cut induced by this set.",
                    "label": 0
                },
                {
                    "sent": "And this function is also known to be submodular.",
                    "label": 0
                },
                {
                    "sent": "So just one more remark here, just one difference between these two functions.",
                    "label": 0
                },
                {
                    "sent": "The first function is monotone in the sense that adding more elements can only increase the value of the function.",
                    "label": 0
                },
                {
                    "sent": "This is not true in this example, naturally becausw.",
                    "label": 0
                },
                {
                    "sent": "The value of the empty set is 0.",
                    "label": 0
                },
                {
                    "sent": "Now if you keep adding vertices, presumably the cut will increase, but at the end when you include all the vertices, the values again 0, so it goes up and down.",
                    "label": 0
                },
                {
                    "sent": "It's not monotone, so these are actually the two Canonical examples.",
                    "label": 0
                },
                {
                    "sent": "I would say of monotone submodular function and a non monotone submodular function.",
                    "label": 0
                },
                {
                    "sent": "But there are many other examples as well, and Satoru mentioned quite a few.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So in this talk I want to talk about problems that involve maximising such functions.",
                    "label": 0
                },
                {
                    "sent": "And just to put it in contrast with Satori stalk.",
                    "label": 0
                },
                {
                    "sent": "Minimizing submodular functions is in some sense of very nice problem, because you can solve it optimally.",
                    "label": 0
                },
                {
                    "sent": "Now.",
                    "label": 0
                },
                {
                    "sent": "Maximization you can consider under various constraints, but even the basic problem of maximizing submodular function without any constraints captures the maximum cut problem in graphs, which is an NP hard problem, and there are other NP hard problems which arise as special cases in this framework.",
                    "label": 1
                },
                {
                    "sent": "So we cannot expect in general to maximize submodular functions exactly optimally.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In fact, in some sense it's even worse, because the natural model for working with set functions is that we have some Oracle that provides values of this function, so we don't have the input given explicitly as a graph or some other explicitly written structure.",
                    "label": 0
                },
                {
                    "sent": "But we have a black box that we can ask what is the value of this set?",
                    "label": 0
                },
                {
                    "sent": "What is the value of that?",
                    "label": 1
                },
                {
                    "sent": "And that's the model we would like to work in.",
                    "label": 0
                },
                {
                    "sent": "In this model, you can actually prove unconditional hardness results, so you can say that maximizing submodular function requires unconditionally an exponential number of queries.",
                    "label": 1
                },
                {
                    "sent": "It's not related to the question of P versus NP, so just information theoretically it's very hard to find what the optimum is.",
                    "label": 0
                },
                {
                    "sent": "Alright, but",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We don't want to give up so easily.",
                    "label": 0
                },
                {
                    "sent": "The structure of submodular functions is quite interesting in this sense.",
                    "label": 0
                },
                {
                    "sent": "That it allows you to have some positive results even for maximization, and this is actually related to the question are submodular functions more like convex functions or are they more like concave functions?",
                    "label": 0
                },
                {
                    "sent": "And I think this question doesn't have a very clear answer an in some sense I would say that the answer is that submodular functions exhibit some aspects of both convexity and concavity.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "In problems where you want to maximize, you would like to exploit the concave aspect of submodular functions, so that would be the theme of this talk.",
                    "label": 0
                },
                {
                    "sent": "How can we exploit this concave aspect?",
                    "label": 0
                },
                {
                    "sent": "Formally, what we are looking for is some sort of approximation algorithm, so we would like to have an algorithm which returns a solution which is always at least a certain fraction Alpha.",
                    "label": 1
                },
                {
                    "sent": "Of the optimal solution.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "In all cases that I will mention here, we will work with functions which are always non negative, so this makes sense.",
                    "label": 0
                },
                {
                    "sent": "We will not think about negative values.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so first of all, approximation algorithms with pretty nice approximation factors are known for many of the problems.",
                    "label": 1
                },
                {
                    "sent": "Classical problems which are actually special cases of.",
                    "label": 0
                },
                {
                    "sent": "Maximizing a submodular functions.",
                    "label": 0
                },
                {
                    "sent": "So some of these problems are maximum K cover.",
                    "label": 0
                },
                {
                    "sent": "What is that?",
                    "label": 0
                },
                {
                    "sent": "It's just given a bunch of sets.",
                    "label": 0
                },
                {
                    "sent": "Choose K sets in order to maximize the Union.",
                    "label": 0
                },
                {
                    "sent": "The size of the union of these sets.",
                    "label": 0
                },
                {
                    "sent": "So for this problem, 1 -- 1 / E approximation has been known for a long time.",
                    "label": 0
                },
                {
                    "sent": "And this number will appear multiple times.",
                    "label": 0
                },
                {
                    "sent": "In this talk, something like 0.63.",
                    "label": 0
                },
                {
                    "sent": "And somehow it turns out to be an important number here.",
                    "label": 0
                },
                {
                    "sent": "OK?",
                    "label": 0
                },
                {
                    "sent": "Max cuts.",
                    "label": 0
                },
                {
                    "sent": "It's known that you can achieve this kind of approximation by the celebrated goldmans Williamson algorithm, which introduced some definite programming to approximation algorithms, and I just wanted to mention that even in hypergraphs where you have hyper edges of larger size.",
                    "label": 1
                },
                {
                    "sent": "You can consider the maximum cut problem an it's actually still a submodular maximization problem.",
                    "label": 0
                },
                {
                    "sent": "In fact, the larger the hyperedges get K is the size of these hyperedges, the easier the problem becomes.",
                    "label": 0
                },
                {
                    "sent": "So in the limit, you can actually get closer and closer to the optimal solution.",
                    "label": 0
                },
                {
                    "sent": "Alright, so so these are some special cases and.",
                    "label": 0
                },
                {
                    "sent": "This is just some evidence that we might hope for good approximation results in general for such problems.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the main questions here are.",
                    "label": 1
                },
                {
                    "sent": "1st just from a theoretical point of view, can we extend these results to arbitrary submodular functions?",
                    "label": 0
                },
                {
                    "sent": "Maybe more Interestingly, is there some unifying framework, some algorithmic framework that would explain why these problems are nice and why they are tractable, at least in the approximate sense?",
                    "label": 1
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "But there's another motivation, which sort of popularized these problems recently, and this comes from.",
                    "label": 0
                },
                {
                    "sent": "Algorithmic game theory or computational economics, where the submodular functions that arise are not given by specific combinatorial settings like the coverage setting or cut functions in graphs, but the notion of submodularity comes from the economic interpretation that a certain valuation function has the property of diminishing returns, so that's another way that such functions could arise without being given a specific combinatorial structure.",
                    "label": 1
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "There are two properties here that I actually mentioned already monotonicity.",
                    "label": 0
                },
                {
                    "sent": "So what does monotonicity mean in this setting?",
                    "label": 1
                },
                {
                    "sent": "It means that you can discard items for free.",
                    "label": 0
                },
                {
                    "sent": "It never hurts if you get more items.",
                    "label": 0
                },
                {
                    "sent": "So you don't have to recycle or something like that.",
                    "label": 0
                },
                {
                    "sent": "Parity means that the more you have, the less you're willing to pay for the next item.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "So these are.",
                    "label": 0
                },
                {
                    "sent": "Interpretations which.",
                    "label": 0
                },
                {
                    "sent": "Which allow you to say that maybe in this setting it's reasonable to assume that the valuation function satisfies these properties without saying explicitly what the function is.",
                    "label": 0
                },
                {
                    "sent": "So that's another direction where this came from and sort of revived interest in submodular functions actually, so that's one of my motivations here.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And let me mention now more specific problem which comes exactly from this angle.",
                    "label": 0
                },
                {
                    "sent": "So this problem is called a submodular welfare problem, and it arises in combinatorial auctions.",
                    "label": 1
                },
                {
                    "sent": "Now what we have here is a set of M items and then we have N players who have valuation functions on these items.",
                    "label": 0
                },
                {
                    "sent": "So let's assume for now that these valuation functions are monotone and submodular.",
                    "label": 0
                },
                {
                    "sent": "And the problem here is to allocate these items.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To the players.",
                    "label": 0
                },
                {
                    "sent": "In a way that maximizes what is called the social welfare.",
                    "label": 0
                },
                {
                    "sent": "Which is the sum of the utilities that all the players together derive from this allocation.",
                    "label": 0
                },
                {
                    "sent": "OK, so in combinatorial auctions there's one other issue which is the issue of truthfulness.",
                    "label": 0
                },
                {
                    "sent": "Can you actually trust the players when you ask them what is the value of this set?",
                    "label": 0
                },
                {
                    "sent": "What is the value of that?",
                    "label": 0
                },
                {
                    "sent": "So I'm not going to deal with this issue here, I'm talking about the optimization problem.",
                    "label": 0
                },
                {
                    "sent": "So this is the core optimization problem which you need to deal with, but in an actual auction there are other serious issues as well.",
                    "label": 0
                },
                {
                    "sent": "But OK, this is an optimization problem.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "Let's see what we can do about it.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now before I before I go to what's known about this problem.",
                    "label": 0
                },
                {
                    "sent": "Let me say that this was actually stated as an example of a more general framework, so now this framework will seem a little bit abstract, maybe, but it's a very useful way of looking at things so in.",
                    "label": 1
                },
                {
                    "sent": "In this paper by Fisher, Nemhauser, and Wolsey, which introduced the first ideas in submodular maximization, they actually formulated.",
                    "label": 0
                },
                {
                    "sent": "The following problem.",
                    "label": 1
                },
                {
                    "sent": "So in this problem we have just one monotone submodular function F and then we have a matroid M defined on the ground set.",
                    "label": 0
                },
                {
                    "sent": "So I will get to the definition of a matroid in a minute.",
                    "label": 0
                },
                {
                    "sent": "And the problem is.",
                    "label": 0
                },
                {
                    "sent": "Maximize F of X overall sets independent in the matroid.",
                    "label": 0
                },
                {
                    "sent": "Alright.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So how is this related to the allocation problem that I described in the previous slide?",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Alright, so in matroid is simply a system of sets that we call independent.",
                    "label": 1
                },
                {
                    "sent": "Now you call it a matroid if it satisfies certain axioms, and let me not dwell on these axioms too much, but let me just say that these are the natural properties that linear independence between vectors satisfies, so it's a combinatorial abstraction of a property similar to linear independence between vectors.",
                    "label": 0
                },
                {
                    "sent": "These axioms simply say that a subset of an independent set is always independent, and if you have a larger independent set, then you can always extend the smaller one by adding something from the larger independent set.",
                    "label": 0
                },
                {
                    "sent": "In fact.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In this talk.",
                    "label": 0
                },
                {
                    "sent": "What will be important is a very simple special type of matroid, so let me explain what this matroid is.",
                    "label": 0
                },
                {
                    "sent": "This is called the partition matroid.",
                    "label": 1
                },
                {
                    "sent": "And it's defined as follows.",
                    "label": 0
                },
                {
                    "sent": "You have a ground set and it's partitioned into a bunch of.",
                    "label": 0
                },
                {
                    "sent": "Let's call them blocks.",
                    "label": 0
                },
                {
                    "sent": "Columns.",
                    "label": 0
                },
                {
                    "sent": "So now I have to say, when is a set independent, so I just say that the set is independent if it contains at most one element from each column.",
                    "label": 1
                },
                {
                    "sent": "It's very simple.",
                    "label": 0
                },
                {
                    "sent": "So I call all such sets independent.",
                    "label": 0
                },
                {
                    "sent": "There's also a notion of basis, which is similar to bases in vector spaces.",
                    "label": 0
                },
                {
                    "sent": "Basis would be a maximal independent set, so that would be a set like this which contains exactly one guy from each column.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Alright, so these are Metro.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Right?",
                    "label": 0
                },
                {
                    "sent": "And now I want to show this reduction because it's pretty simple and.",
                    "label": 0
                },
                {
                    "sent": "It's quite useful, so we have this allocation problem.",
                    "label": 0
                },
                {
                    "sent": "The submodular welfare problem where we have N different.",
                    "label": 0
                },
                {
                    "sent": "Submodular functions each player might have a different valuation function.",
                    "label": 0
                },
                {
                    "sent": "And I would like to transform that into an optimization problem which has only one objective function, yes?",
                    "label": 0
                },
                {
                    "sent": "I I see I didn't say monotone on this slide, but yes, I still assume that their monotone thanks.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So in fact the reduction does not depend on that.",
                    "label": 0
                },
                {
                    "sent": "The objective function that you would get in the new problem would be either monotone or non monotone depending on what you start from.",
                    "label": 0
                },
                {
                    "sent": "But yes, I still want to assume that their model.",
                    "label": 0
                },
                {
                    "sent": "So what is the reduction here?",
                    "label": 0
                },
                {
                    "sent": "Well, let's do the following.",
                    "label": 0
                },
                {
                    "sent": "Let's just take each item.",
                    "label": 0
                },
                {
                    "sent": "So now each column corresponds to one item of the original ground set.",
                    "label": 0
                },
                {
                    "sent": "And I will create N copies.",
                    "label": 0
                },
                {
                    "sent": "Of each item, one copy for each player.",
                    "label": 1
                },
                {
                    "sent": "So the new ground set is a Cartesian product of the set of players and a set of items.",
                    "label": 0
                },
                {
                    "sent": "OK, so now I will define a new function on the new ground set, which is very natural.",
                    "label": 0
                },
                {
                    "sent": "Is the function F which for any set here.",
                    "label": 0
                },
                {
                    "sent": "Well, simply add up.",
                    "label": 0
                },
                {
                    "sent": "The contributions that their respective players get from the items which are allocated to them in that set.",
                    "label": 0
                },
                {
                    "sent": "You can interpret each set here as a certain allocation where the red players will get whatever copies you took from the top row.",
                    "label": 0
                },
                {
                    "sent": "And now in this definition you can take any set, even the entire Cartesian product would be would be assigned some value, but it's not an actual set that you can allocate right?",
                    "label": 0
                },
                {
                    "sent": "Because you have only one copy of each item.",
                    "label": 0
                },
                {
                    "sent": "So the constraint here is that from each column you can only take one element.",
                    "label": 0
                },
                {
                    "sent": "So this is just a simple reformulation of the problem.",
                    "label": 0
                },
                {
                    "sent": "Nothing mysterious is happening here.",
                    "label": 0
                },
                {
                    "sent": "The problem the submodular welfare problem is equivalent to saying.",
                    "label": 1
                },
                {
                    "sent": "That I want to maximize this new objective function F subject to a partition matroid.",
                    "label": 0
                },
                {
                    "sent": "Where from each column I'm allowed to take at most one item.",
                    "label": 0
                },
                {
                    "sent": "OK, so maybe at this point it looks like needless gain to reduce the problem to this framework.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Actually, it's quite useful to think about it this way, so let me say what is known about these problems and this starts really with the Seminole work of Nemhauser, Wolsey and Fisher in the 70s.",
                    "label": 0
                },
                {
                    "sent": "So the first message here is that very simple greedy algorithms or local search type algorithms work very well for these problems already in many cases.",
                    "label": 0
                },
                {
                    "sent": "So for example, the problem where you want to maximize a monotone submodular function subject to selecting at most K elements.",
                    "label": 0
                },
                {
                    "sent": "For this problem, the greedy algorithm already gives you a 1 -- 1 / E approximation, and this is actually known to be optimal.",
                    "label": 1
                },
                {
                    "sent": "If you generalize this problem slightly, if you replace the condition that I'm selecting at most K elements by selecting an independent set in a matroid.",
                    "label": 0
                },
                {
                    "sent": "Then the problem gets slightly more difficult.",
                    "label": 1
                },
                {
                    "sent": "The greedy algorithm actually gives a 1/2 approximation.",
                    "label": 0
                },
                {
                    "sent": "And it's not known it wasn't known if this is optimal or not.",
                    "label": 0
                },
                {
                    "sent": "Now you can also ask what can you do if you maximize a non monotone submodular function.",
                    "label": 0
                },
                {
                    "sent": "That's like the problem, generalizing maximum cut.",
                    "label": 1
                },
                {
                    "sent": "In graphs, so for this problem local search also gives a pretty nice approximation 1/3, and we proved with verify again that you cannot do better than 1/2.",
                    "label": 0
                },
                {
                    "sent": "So the answer is somewhere between 1/3 and 1/2.",
                    "label": 0
                },
                {
                    "sent": "But then there's some other problems for which actually these simple algorithms don't work that well.",
                    "label": 0
                },
                {
                    "sent": "Let me mention 11 problem which is quite natural.",
                    "label": 0
                },
                {
                    "sent": "It's called maxmin.",
                    "label": 0
                },
                {
                    "sent": "Allocation sometimes this problem is called the Santa Claus problem.",
                    "label": 0
                },
                {
                    "sent": "In this problem you also want to allocate items, but you want to maximize what the least happy Agent gets.",
                    "label": 0
                },
                {
                    "sent": "So it's like distributing presents to kids to maximize for the least.",
                    "label": 0
                },
                {
                    "sent": "Happy Child receives.",
                    "label": 0
                },
                {
                    "sent": "Actually, this problem is much more difficult from an approximation point of view.",
                    "label": 1
                },
                {
                    "sent": "Is very difficult even if the utility functions are just additive.",
                    "label": 0
                },
                {
                    "sent": "If you just add up some values over items, it's already very hard.",
                    "label": 0
                },
                {
                    "sent": "OK, so for these problems and then I'm mentioning here a problem where you maximize a submodular function subject to general linear constraints.",
                    "label": 1
                },
                {
                    "sent": "Let's say constant number of general linear constraints.",
                    "label": 0
                },
                {
                    "sent": "So such problems have been also studied for these problems.",
                    "label": 0
                },
                {
                    "sent": "This simple algorithms don't work really, blow doesn't they don't give any constant factor for sure.",
                    "label": 0
                },
                {
                    "sent": "So that's the landscape.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But the question here is really, what can we do except some sort of combinatorial search algorithm like what is the tool that we could possibly apply here?",
                    "label": 0
                },
                {
                    "sent": "So I would like to put that in perspective with problems with.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "There.",
                    "label": 0
                },
                {
                    "sent": "Where the objective function is linear.",
                    "label": 0
                },
                {
                    "sent": "In those cases, natural tool that's been used over and over is linear programming, so you can replace a discrete problem by continuous problem, which in many cases turns out to be a linear program which you can solve exactly.",
                    "label": 1
                },
                {
                    "sent": "And then maybe you can go back to your original discrete problem and use that fractional solution somehow.",
                    "label": 0
                },
                {
                    "sent": "So I would like to do a similar thing for these problems, where the objective function is.",
                    "label": 0
                },
                {
                    "sent": "Not linear, it's a submodular function.",
                    "label": 0
                },
                {
                    "sent": "So the question is, there are two things that we have to replace here.",
                    "label": 0
                },
                {
                    "sent": "The objective function and the set of feasible solutions.",
                    "label": 0
                },
                {
                    "sent": "So you replace the objective function by some continuous function and you replace the feasible region by some convex.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Yep.",
                    "label": 0
                },
                {
                    "sent": "So the second part we just do what is standard.",
                    "label": 0
                },
                {
                    "sent": "We take the set of feasible sets.",
                    "label": 0
                },
                {
                    "sent": "And we interpret them as 01 vectors and we replace that by the convex Hull of these characteristic vectors.",
                    "label": 0
                },
                {
                    "sent": "So that would be the polytope which corresponds to the set system F. And that's very natural.",
                    "label": 0
                },
                {
                    "sent": "Well, sometimes this is already too complicated, but let's say.",
                    "label": 0
                },
                {
                    "sent": "Let's say we can do that for some special subsystems.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "But the more interesting question is what form of continuous function do you choose for replacing the objective function F?",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "And I want to promote the following type of extension which seems to be working well for maximization problems.",
                    "label": 0
                },
                {
                    "sent": "So what do we do here?",
                    "label": 0
                },
                {
                    "sent": "We take a fractional solution just a point in the cube.",
                    "label": 0
                },
                {
                    "sent": "01 to the end.",
                    "label": 0
                },
                {
                    "sent": "And I want to define a value for this point.",
                    "label": 0
                },
                {
                    "sent": "OK, so how is this value defined?",
                    "label": 0
                },
                {
                    "sent": "Let's define it by a random experiment.",
                    "label": 0
                },
                {
                    "sent": "Where I interpret the coordinates of this vector Y as probabilities and I pick each element I with probability corresponding to YJ.",
                    "label": 0
                },
                {
                    "sent": "So I pick it with probability YJ and I don't pick it with probability 1 -- y G. So I do that independently for each element of the ground set.",
                    "label": 0
                },
                {
                    "sent": "This will give me some.",
                    "label": 0
                },
                {
                    "sent": "Random 01 vector which can be interpreted as a random set.",
                    "label": 0
                },
                {
                    "sent": "And I know what the value of such set is is given by the function F. So let me take the expectation over this random experiment.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is what we call the multilinear extension of F, and we call it multilinear becausw.",
                    "label": 1
                },
                {
                    "sent": "This actually turns out to be a multilinear function of these variables, Y one through YN, and it's quite easy to see.",
                    "label": 0
                },
                {
                    "sent": "It's actually the unique multilinear polynomial on the hypercube, which coincides with your values on the vertices values are given on the vertices, and you want to interpolate inside the cube, and this is the unique multilinear polynomial which achieves that.",
                    "label": 0
                },
                {
                    "sent": "Doesn't make sense.",
                    "label": 0
                },
                {
                    "sent": "Hey.",
                    "label": 0
                },
                {
                    "sent": "Haha.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "So far it's not clear how we can actually evaluate this, and we cannot evaluate it exactly.",
                    "label": 0
                },
                {
                    "sent": "So we will only evaluate it approximately right?",
                    "label": 0
                },
                {
                    "sent": "So we will.",
                    "label": 0
                },
                {
                    "sent": "We will get some error bounds that we have to deal with, and that's actually somehow in terms of running time.",
                    "label": 0
                },
                {
                    "sent": "This will be the most.",
                    "label": 0
                },
                {
                    "sent": "Most serious issue.",
                    "label": 0
                },
                {
                    "sent": "But in principle.",
                    "label": 0
                },
                {
                    "sent": "OK, so now there's this gap between theory and practice, right?",
                    "label": 0
                },
                {
                    "sent": "So theoretically speaking there is no big issue here, because you can estimate it, let's say by taking N squared samples within additive error 1 / 1 over North.",
                    "label": 0
                },
                {
                    "sent": "So if you take em to the four samples, you get additive error, one over and squared, and that would be actually enough for the analysis.",
                    "label": 0
                },
                {
                    "sent": "But in practice, you have to think about this a little bit more.",
                    "label": 0
                },
                {
                    "sent": "How you can speed it up, but for now, let's actually assume that we can evaluate this function.",
                    "label": 0
                },
                {
                    "sent": "OK, I will cheat and I will assume that this is an efficiently computable function.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So you might ask, why do we choose this particular extension?",
                    "label": 0
                },
                {
                    "sent": "There are actually several choices that we have several Nat.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The choices that we have, so one is that Satoru mentioned in his talk the Lovasz extension is the most famous way of extending a submodular function to a continuous function on the cube.",
                    "label": 1
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "It can be viewed in this way which.",
                    "label": 0
                },
                {
                    "sent": "Which is equivalent to what subtotal described.",
                    "label": 0
                },
                {
                    "sent": "I want to put in this framework because I'm thinking of all the extensions as some sort of expectation.",
                    "label": 0
                },
                {
                    "sent": "So this is one way to define the Lovasz extension.",
                    "label": 0
                },
                {
                    "sent": "You take a random threshold Lambda which is uniformly chosen between zero and one.",
                    "label": 0
                },
                {
                    "sent": "And you take all the elements whose coordinate is at least Lambda or strict.",
                    "label": 0
                },
                {
                    "sent": "Doesn't matter, at least Lambda.",
                    "label": 0
                },
                {
                    "sent": "So in expectation this is exactly the Lovasz extension.",
                    "label": 0
                },
                {
                    "sent": "So what is the problem with this last extension?",
                    "label": 0
                },
                {
                    "sent": "Well, it's a convex function for submodular functions, so it's actually great for minimum minimization problems.",
                    "label": 0
                },
                {
                    "sent": "But we cannot use it for maximization problems.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now, if you want something that looks good for maximization, what is it?",
                    "label": 0
                },
                {
                    "sent": "It's a concave function.",
                    "label": 0
                },
                {
                    "sent": "So what if we take the concave extension of this function, which you can define for any function defined on the vertices of a cube, you can take essentially the convex combination which maximizes.",
                    "label": 1
                },
                {
                    "sent": "Which maximizes this value.",
                    "label": 0
                },
                {
                    "sent": "You can do this for any set function.",
                    "label": 0
                },
                {
                    "sent": "And this will give you a convex concave function.",
                    "label": 1
                },
                {
                    "sent": "I'm sorry this will be a concave function, but there's another problem with that.",
                    "label": 1
                },
                {
                    "sent": "It actually we cannot evaluate this function and we cannot do that even approximately.",
                    "label": 0
                },
                {
                    "sent": "So that's not useful either.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And the multilinear extension is some sort of compromise between these two.",
                    "label": 1
                },
                {
                    "sent": "It's sitting somewhere between the convex and concave.",
                    "label": 0
                },
                {
                    "sent": "Extensions of F. And actually it's not convex and it's not concave either.",
                    "label": 1
                },
                {
                    "sent": "But it can be evaluated up to these sampling issues.",
                    "label": 1
                },
                {
                    "sent": "So what is the property that the multilinear extension satisfies that we can use?",
                    "label": 0
                },
                {
                    "sent": "It's not convex, not concave.",
                    "label": 0
                },
                {
                    "sent": "What can we use about it?",
                    "label": 0
                },
                {
                    "sent": "There's one nice condition that it satisfies which, which is a sort of strange condition from continuous optimization point of view.",
                    "label": 0
                },
                {
                    "sent": "This is the condition that you get.",
                    "label": 0
                },
                {
                    "sent": "This is exactly equivalent to being submodular.",
                    "label": 0
                },
                {
                    "sent": "It's the condition that all second partial derivatives are non positive.",
                    "label": 0
                },
                {
                    "sent": "Any question?",
                    "label": 0
                },
                {
                    "sent": "OK, this is the condition that you get.",
                    "label": 0
                },
                {
                    "sent": "In some sense, it's pretty natural because it means that the first partial derivatives which correspond to marginal values when you move them up, they can only decrease.",
                    "label": 0
                },
                {
                    "sent": "That's that's the second partial.",
                    "label": 0
                },
                {
                    "sent": "That's what the second partial derivative means, and this is true for all pairs IJ, including I equal to J, so.",
                    "label": 0
                },
                {
                    "sent": "If you differentiate the same variable twice, you also get.",
                    "label": 0
                },
                {
                    "sent": "The concept of multilinear.",
                    "label": 0
                },
                {
                    "sent": "While this comes so it comes out of some earlier work by a given three Danko.",
                    "label": 0
                },
                {
                    "sent": "And then and then we used it with Gruyere cleaner school and gender, chicory, Ann Martin Paul.",
                    "label": 0
                },
                {
                    "sent": "For for submodular functions, this is the sort of new idea here.",
                    "label": 0
                },
                {
                    "sent": "But OK, this is the nice condition that we have.",
                    "label": 0
                },
                {
                    "sent": "And how do we use it?",
                    "label": 0
                },
                {
                    "sent": "How much time do I mean?",
                    "label": 0
                },
                {
                    "sent": "Not so much?",
                    "label": 0
                },
                {
                    "sent": "15 minutes OK thanks.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Alright, so there are two questions here.",
                    "label": 1
                },
                {
                    "sent": "Can we even solve the continuous problem because it's not convex and it's not concave either.",
                    "label": 1
                },
                {
                    "sent": "And then even if we can solve it, what can we do with a fraction solution?",
                    "label": 0
                },
                {
                    "sent": "So these are both non obvious.",
                    "label": 0
                },
                {
                    "sent": "So first let me deal with the question of solving the continuous problem.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So what do we have?",
                    "label": 0
                },
                {
                    "sent": "We have some polytope and we would like to optimize a function over this polytope and all we know is that the function is the multilinear extension of monotone submodular function, an.",
                    "label": 1
                },
                {
                    "sent": "Essentially, we have this condition on the second partial derivatives.",
                    "label": 0
                },
                {
                    "sent": "That's all we have.",
                    "label": 0
                },
                {
                    "sent": "So here is an algorithm which.",
                    "label": 0
                },
                {
                    "sent": "A widget does something.",
                    "label": 0
                },
                {
                    "sent": "It doesn't solve the problem optimally, but it will do something useful.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So let's try the following.",
                    "label": 0
                },
                {
                    "sent": "Let me define for each point.",
                    "label": 0
                },
                {
                    "sent": "Something that I want to call a greedy direction.",
                    "label": 1
                },
                {
                    "sent": "So this is for each point Y sum.",
                    "label": 0
                },
                {
                    "sent": "Vector which is obtained by maximising V dot gradient of F over the polytope.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "OK, so people ask about this a lot.",
                    "label": 0
                },
                {
                    "sent": "Is it like gradient descent or is it not well?",
                    "label": 0
                },
                {
                    "sent": "It's not.",
                    "label": 0
                },
                {
                    "sent": "It's not, the algorithm is not going to be gradient descent and you can see that there's something something interesting happening here.",
                    "label": 0
                },
                {
                    "sent": "The direction does not depend only on the behavior of the function at that point.",
                    "label": 0
                },
                {
                    "sent": "It also depends on the structure of the polytope.",
                    "label": 0
                },
                {
                    "sent": "Because I take this linear form which is given by the gradient.",
                    "label": 0
                },
                {
                    "sent": "So that's where the function comes in.",
                    "label": 0
                },
                {
                    "sent": "But I maximize that over the polytope.",
                    "label": 0
                },
                {
                    "sent": "So some directions might actually be more profitable because the polytope extends further in those directions, right?",
                    "label": 0
                },
                {
                    "sent": "So this vector field.",
                    "label": 0
                },
                {
                    "sent": "It doesn't depend only on the function.",
                    "label": 0
                },
                {
                    "sent": "It also depends on the polytope somehow combines these two together.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And once we have these greedy directions, we just run a very simple algorithm.",
                    "label": 0
                },
                {
                    "sent": "Which can be phrased as follows.",
                    "label": 0
                },
                {
                    "sent": "You start from the origin Ann you.",
                    "label": 0
                },
                {
                    "sent": "You drop a particle here and you let it flow along these arrows for unit amount of time.",
                    "label": 0
                },
                {
                    "sent": "Ann, wherever you end up after unit amount of time that will be your solution.",
                    "label": 0
                },
                {
                    "sent": "So you don't try to go.",
                    "label": 0
                },
                {
                    "sent": "As long as there is some improvement possible, you just do this for a unit amount of time and you stop and that's it.",
                    "label": 0
                },
                {
                    "sent": "You get something like conjugate gradient descent, huh?",
                    "label": 0
                },
                {
                    "sent": "So I would be very interested if you can put it in some framework like that.",
                    "label": 0
                },
                {
                    "sent": "So it will be conjugate.",
                    "label": 0
                },
                {
                    "sent": "So how does the polytope come in?",
                    "label": 0
                },
                {
                    "sent": "Because if you if you want to minimize along rubbing, you want to go along.",
                    "label": 0
                },
                {
                    "sent": "So you think that you take the global structure of the metric into account for minimalization looks like and.",
                    "label": 0
                },
                {
                    "sent": "So let's yeah, let's discuss.",
                    "label": 0
                },
                {
                    "sent": "I still think that conjugate gradient only looks at the function of the polytope, but.",
                    "label": 0
                },
                {
                    "sent": "Projection.",
                    "label": 0
                },
                {
                    "sent": "Predicted.",
                    "label": 0
                },
                {
                    "sent": "Proceed along creating nothing and then project along onto the polytopes.",
                    "label": 0
                },
                {
                    "sent": "Are you referring to that question or it's independent?",
                    "label": 0
                },
                {
                    "sent": "OK, OK, so you're asking what this means in some sense.",
                    "label": 0
                },
                {
                    "sent": "Oh, I see I see.",
                    "label": 0
                },
                {
                    "sent": "OK, so let's yeah, let's leave that for offline.",
                    "label": 0
                },
                {
                    "sent": "That's interesting, because maybe this is the right community actually to ask this question.",
                    "label": 0
                },
                {
                    "sent": "What is really happening here?",
                    "label": 0
                },
                {
                    "sent": "So OK, so I'm not claiming that this algorithm solves the problem optimally, but.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But I want to claim that it solves it within a factor of 1 -- 1 / E. And in fact, it is known that this is the optimal factor that you can achieve for this problem so.",
                    "label": 0
                },
                {
                    "sent": "For worst case analysis, there's no point trying to improve the solution by some further tricks.",
                    "label": 0
                },
                {
                    "sent": "This is the best factor you can achieve.",
                    "label": 0
                },
                {
                    "sent": "In general, OK, in practice, maybe you want to do some more tweaks, but this is it.",
                    "label": 0
                },
                {
                    "sent": "So the first claim.",
                    "label": 0
                },
                {
                    "sent": "The first claim is that the final point is actually in the polytope, and it's pretty easy to see because at each point we are moving along the direction which is given by vector, which is in the polytope.",
                    "label": 0
                },
                {
                    "sent": "So it's like an integral from zero to 1.",
                    "label": 0
                },
                {
                    "sent": "Of vectors which are in the polytope, like a convex combination.",
                    "label": 0
                },
                {
                    "sent": "So you're still in the polytope, so this is easy to see.",
                    "label": 0
                },
                {
                    "sent": "So this claim is.",
                    "label": 0
                },
                {
                    "sent": "The interesting part of it.",
                    "label": 0
                },
                {
                    "sent": "And the.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Life is actually quite simple, so.",
                    "label": 0
                },
                {
                    "sent": "So now how do we use the property that the second partial derivatives are non positive?",
                    "label": 0
                },
                {
                    "sent": "So another way to say that is that if you move along a direction which is given by non negative vector, the function is actually concave.",
                    "label": 0
                },
                {
                    "sent": "Right, so there's some special directions.",
                    "label": 0
                },
                {
                    "sent": "The positive orthant where the function is actually concave.",
                    "label": 0
                },
                {
                    "sent": "So we can prove this lemma.",
                    "label": 0
                },
                {
                    "sent": "Which says that for any point when you look at the greedy direction that I defined.",
                    "label": 1
                },
                {
                    "sent": "You take the dot product with the gradient.",
                    "label": 0
                },
                {
                    "sent": "This will be at least the optimal value minus my current value.",
                    "label": 0
                },
                {
                    "sent": "What I have at that point.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And why is this true?",
                    "label": 0
                },
                {
                    "sent": "Well, I'm not going to prove it here, but it's sort of intuitive given the fact that the function is concave along any direction that's only increasing in all coordinates.",
                    "label": 1
                },
                {
                    "sent": "So you can essentially say.",
                    "label": 0
                },
                {
                    "sent": "Some technicalities that if you move from the current points towards the actual optimum.",
                    "label": 0
                },
                {
                    "sent": "Then this kind of inequality is satisfied by the concavity argument.",
                    "label": 0
                },
                {
                    "sent": "But I'm not moving towards the the actual optimum moving in some other direction.",
                    "label": 0
                },
                {
                    "sent": "Which dominates that.",
                    "label": 0
                },
                {
                    "sent": "So the inequality.",
                    "label": 0
                },
                {
                    "sent": "Certainly satisfied.",
                    "label": 0
                },
                {
                    "sent": "OK, I just hand waved it but.",
                    "label": 0
                },
                {
                    "sent": "This is the idea.",
                    "label": 0
                },
                {
                    "sent": "So at any point.",
                    "label": 0
                },
                {
                    "sent": "My current rate of increase.",
                    "label": 0
                },
                {
                    "sent": "Is at least the difference between the optimal value and the value that I have right now?",
                    "label": 1
                },
                {
                    "sent": "So this is the kind of dynamic which leads to.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The factor of 1 -- 1 / E. Just solve this differential equation.",
                    "label": 0
                },
                {
                    "sent": "You get that at time T. My values at least 1 -- E to the minus T times the optimal, so it's time 1 you get 1 -- 1 ovary.",
                    "label": 0
                },
                {
                    "sent": "It's a very simple dynamic process.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Alright, so let me summarize this part.",
                    "label": 0
                },
                {
                    "sent": "I showed you how we can solve the continuous problem up to some technicalities, sampling and so on.",
                    "label": 1
                },
                {
                    "sent": "There's another point here, which I should have mentioned is that what we really need in the algorithm is being able to maximize linear functions over the polytope, so you can implement this for any polytope such that you can optimize linear functions, and you can do that for any nice polytope, let's say given by a separation Oracle or something like that.",
                    "label": 0
                },
                {
                    "sent": "So in this generality, you can always achieve this factor of 1 -- 1 / E.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now I will not say much about how to deal with non monotone submodular functions, but quite recently we developed techniques which allow you to achieve constant factors.",
                    "label": 1
                },
                {
                    "sent": "Also, if the objective function is non monotone submodular, this actually uses some quite interesting approach, motivate, motivated by simulated annealing.",
                    "label": 1
                },
                {
                    "sent": "It's more complicated and achieve some.",
                    "label": 0
                },
                {
                    "sent": "Factors which are not so nice.",
                    "label": 0
                },
                {
                    "sent": "But here are the numbers if you just optimize over the pure hypercube then you get a factor of 0.41 an for any down closed polytope you get 0.325.",
                    "label": 0
                },
                {
                    "sent": "So we sort of know how to optimize this multilinear extension even for non monotone submodular function.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So now let me go to the second part.",
                    "label": 0
                },
                {
                    "sent": "How do we around the fractional solution?",
                    "label": 0
                },
                {
                    "sent": "Well, the first case, if the polytope is the hypercube itself, then it's very easy.",
                    "label": 0
                },
                {
                    "sent": "We just use the definition of the multilinear extension itself.",
                    "label": 0
                },
                {
                    "sent": "You take your point, you around, in dependently the coordinates based on these probabilities and by definition the expectation of what you get is exactly the value of this extension, so that's.",
                    "label": 0
                },
                {
                    "sent": "Trivial, so immediately you get.",
                    "label": 0
                },
                {
                    "sent": "0.41 for maximizing non monotone submodular function.",
                    "label": 1
                },
                {
                    "sent": "Without any constraints.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now, in the case of the submodular welfare problem, we have some constraints, but they are pretty simple and they're very natural.",
                    "label": 0
                },
                {
                    "sent": "So when you look at the reduction.",
                    "label": 0
                },
                {
                    "sent": "The interpretation of the fractional solution.",
                    "label": 1
                },
                {
                    "sent": "Is that the value of the fractional solution?",
                    "label": 0
                },
                {
                    "sent": "Is the expected value of a certain random assignment where you just give each item to each player with a probability corresponding to the variable YIJ so the variables really correspond to probabilities that you give the item to that player, and that's exactly the objective function.",
                    "label": 0
                },
                {
                    "sent": "So what are the constraints here?",
                    "label": 1
                },
                {
                    "sent": "Well, the constraints say that for each item the probability is summed up over players.",
                    "label": 0
                },
                {
                    "sent": "Some of the at most one.",
                    "label": 0
                },
                {
                    "sent": "So that's great.",
                    "label": 0
                },
                {
                    "sent": "That means that this is a probability distribution.",
                    "label": 0
                },
                {
                    "sent": "I can just take.",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The item and allocated to player I with probably YIJ.",
                    "label": 1
                },
                {
                    "sent": "And in expectation I get exactly this value, which I know to be at least 1 -- 1 / E times opt.",
                    "label": 0
                },
                {
                    "sent": "So that achieves.",
                    "label": 0
                },
                {
                    "sent": "The optimal factor for this problem.",
                    "label": 0
                },
                {
                    "sent": "That's one application.",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "But in fact you can extend it to this more general setting of a matroid constraint, and I'm not going to say how, but you can do for any matroid.",
                    "label": 1
                },
                {
                    "sent": "The following you can start from some point in the matroid polytope, which is why I think you called the marginal polytope in this community, right?",
                    "label": 0
                },
                {
                    "sent": "So any point which is given by marginals of some convex combination of independent sets?",
                    "label": 0
                },
                {
                    "sent": "You can move from that point.",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "An actual independent set in a matroid in such a way that you don't lose in terms of the objective function.",
                    "label": 0
                },
                {
                    "sent": "So here's the summary.",
                    "label": 0
                },
                {
                    "sent": "The algorithm has two parts, the blue part is the continuous greedy algorithm which finds a fractional solution of value at least 1 -- 1 / E. And in the second part, you move from that point again along certain special directions, and those directions are actually chosen such that the function is convex along these arrows.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "So this picture is somehow exploits.",
                    "label": 0
                },
                {
                    "sent": "At both aspects of submodularity, it exploits the concave aspect in the blue portion.",
                    "label": 0
                },
                {
                    "sent": "And the convex aspect in the red part in the rounding procedure.",
                    "label": 0
                },
                {
                    "sent": "And that leads to this.",
                    "label": 0
                },
                {
                    "sent": "The result which sort of unifies bunch of different scenarios where the factor was either known or obtained recently.",
                    "label": 0
                },
                {
                    "sent": "So somehow this is the right framework for all these 1 -- 1 / E result.",
                    "label": 0
                },
                {
                    "sent": "Right?",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "I'm almost OK.",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Thank you so.",
                    "label": 0
                },
                {
                    "sent": "Oh haha, so there are actually a bunch of other applications where this framework gives constant factor where no constant factor was known.",
                    "label": 1
                },
                {
                    "sent": "Well so far I only talked about basically improving constant factors, But some recent work this has been extended to a bunch of problems where it really gives a new result.",
                    "label": 1
                },
                {
                    "sent": "In terms of.",
                    "label": 0
                },
                {
                    "sent": "Whether there is a constant at all or not.",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And finally, very quickly I want to say that this framework also serves.",
                    "label": 0
                },
                {
                    "sent": "As a tool to derive hardness results, so that's a little bit surprising, but you can actually take this framework of multilinear relaxation, and you can derive impossibility results.",
                    "label": 1
                },
                {
                    "sent": "Using something called the symmetric gap so.",
                    "label": 0
                },
                {
                    "sent": "So very briefly.",
                    "label": 0
                },
                {
                    "sent": "The way this works is that you start from some instance which has certain symmetric properties and you compare.",
                    "label": 0
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Put a certain number.",
                    "label": 0
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Which is called the symmetry gap, and what is the symmetry gap?",
                    "label": 1
                },
                {
                    "sent": "Intuitively it's just looking at the multilinear relaxation of the problem, and you compute the gap between the best solution and the best symmetric solution.",
                    "label": 0
                },
                {
                    "sent": "So this will be some number, it's just a number for fixed instance.",
                    "label": 0
                },
                {
                    "sent": "And then we have a procedure which will take this instance in some sense, blow it up to a class of instances.",
                    "label": 0
                },
                {
                    "sent": "Such that on this class you will get a certain hardness result.",
                    "label": 0
                },
                {
                    "sent": "Well X bar.",
                    "label": 0
                },
                {
                    "sent": "Yeah, I didn't quite define it formally, but given an instance which has certain symmetric properties, there's some group of permutations which keeps it invariant.",
                    "label": 1
                },
                {
                    "sent": "So this will.",
                    "label": 0
                },
                {
                    "sent": "This would be all the solutions.",
                    "label": 0
                },
                {
                    "sent": "Which are invariant under these permutations?",
                    "label": 0
                }
            ]
        },
        "clip_55": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So I have an example here, but I think I'm running out of time, so probably.",
                    "label": 0
                }
            ]
        },
        "clip_56": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I'll skip that the way this works is you take some very simple instance and you compare the best solution.",
                    "label": 0
                },
                {
                    "sent": "This would be just Max cut on one edge.",
                    "label": 1
                },
                {
                    "sent": "What is the best solution?",
                    "label": 0
                },
                {
                    "sent": "It's just cutting the edge value one.",
                    "label": 0
                },
                {
                    "sent": "What is the best symmetric solution while the instant is symmetric under flipping these two vertices and the best symmetric solution is.",
                    "label": 0
                },
                {
                    "sent": "One half 1/2.",
                    "label": 0
                },
                {
                    "sent": "In terms of the multilinear relaxation.",
                    "label": 0
                },
                {
                    "sent": "And the value of that is 1/2.",
                    "label": 0
                },
                {
                    "sent": "So the gap.",
                    "label": 0
                }
            ]
        },
        "clip_57": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here is 1/2 or factor 2.",
                    "label": 0
                }
            ]
        },
        "clip_58": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the general.",
                    "label": 0
                }
            ]
        },
        "clip_59": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I'm here is that.",
                    "label": 0
                },
                {
                    "sent": "From any instance which looks like that it has some gap, you can actually blow it up and you will get a hardness result, which is based somehow on the fact that you can fool any algorithm and force it to only find symmetric solutions.",
                    "label": 0
                },
                {
                    "sent": "So basically you can prove that no algorithm will be able to.",
                    "label": 1
                },
                {
                    "sent": "Beat the gap between the best solution and the best symmetric solution.",
                    "label": 0
                },
                {
                    "sent": "So for example, this will prove that for maximizing submodular functions without any constraints.",
                    "label": 0
                },
                {
                    "sent": "Non monotone submodular functions, which is a generalization of Max cut.",
                    "label": 0
                },
                {
                    "sent": "You cannot beat the factor of 1/2.",
                    "label": 1
                },
                {
                    "sent": "But there's a lot of.",
                    "label": 0
                }
            ]
        },
        "clip_60": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Machinery hidden here, which I'm skipping, so let me let me just summarize with what is known.",
                    "label": 0
                },
                {
                    "sent": "This is the landscape now.",
                    "label": 0
                },
                {
                    "sent": "Any question about I really went over it very far.",
                    "label": 0
                }
            ]
        },
        "clip_61": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Sorry so I didn't explain how.",
                    "label": 0
                },
                {
                    "sent": "How to prove?",
                    "label": 0
                }
            ]
        },
        "clip_62": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Works, but basically from a gap in a single instance.",
                    "label": 0
                },
                {
                    "sent": "You get automatically a hardness result.",
                    "label": 0
                },
                {
                    "sent": "That's how it works.",
                    "label": 0
                },
                {
                    "sent": "An IT unifies some earlier known hardness results and it gives some new harness results.",
                    "label": 0
                },
                {
                    "sent": "So basically this is what we know at the moment for monotone submodular functions we sort of know what's going on, so for a broad range of constraints you can achieve this.",
                    "label": 0
                },
                {
                    "sent": "Factor 1 -- 1 over East.",
                    "label": 0
                },
                {
                    "sent": "For more complicated constraints, you cannot achieve it, but I'm not listing all the known results here.",
                    "label": 0
                },
                {
                    "sent": "For non monotone submodular functions the numbers are not so nice, but the gaps are sort of getting closer, so we have some rough picture of what's going on.",
                    "label": 0
                },
                {
                    "sent": "I think I'll just stop here.",
                    "label": 0
                },
                {
                    "sent": "Yes, so why am I listing?",
                    "label": 0
                },
                {
                    "sent": "OK, this is sorry.",
                    "label": 0
                },
                {
                    "sent": "This is a cardinality equality constraint, so this is the problem where you maximize F of S subject to cardinality of as being equal to K. And that's actually.",
                    "label": 0
                },
                {
                    "sent": "It's not clear.",
                    "label": 0
                },
                {
                    "sent": "It seems more difficult than these cases.",
                    "label": 0
                },
                {
                    "sent": "Which are the constraints are down closed, but in terms of hardness results we have the same hardness result for these two so.",
                    "label": 0
                },
                {
                    "sent": "We don't quite understand what's going on.",
                    "label": 0
                },
                {
                    "sent": "Any other questions?",
                    "label": 0
                },
                {
                    "sent": "Simulated annealing algorithm.",
                    "label": 0
                },
                {
                    "sent": "Use the extension, but that works on set yes, so it's another way to solve this multilinear relaxation of a problem where the objective is non monotone submodular an it's essentially the following algorithm you, so it's a local search algorithm under certain noise which is controlled by some parameter which can be called temperature, and you start from essentially uniformly random solution, which is like infinite temperature an.",
                    "label": 0
                },
                {
                    "sent": "You gradually decrease the temperature while performing local search about temperature, so it's not exactly simulated annealing, but I think there's some analogy there and it can be proved that it gives these factors which are best known currently, so it works nicely somehow.",
                    "label": 0
                },
                {
                    "sent": "So it seems like.",
                    "label": 0
                },
                {
                    "sent": "Seems like the kind of constraints that you were talking about here for the so much longer function maximization problem are very different than the kinds of constraints that support was talking about this so much about humanization.",
                    "label": 0
                },
                {
                    "sent": "Yes, running?",
                    "label": 0
                },
                {
                    "sent": "Why are they types of constraints?",
                    "label": 0
                },
                {
                    "sent": "Sort of different employers.",
                    "label": 0
                },
                {
                    "sent": "Yeah, good question.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so so for maximization problem, it's natural to consider packing type constraint where something is at most something you maximize overset South such that.",
                    "label": 0
                },
                {
                    "sent": "The size of South is at most something or some linear function is at most something.",
                    "label": 0
                },
                {
                    "sent": "For minimization problems it's more natural to consider covering constraints.",
                    "label": 0
                },
                {
                    "sent": "And there are some intersections, yes, and I didn't list all the known results here.",
                    "label": 0
                },
                {
                    "sent": "In fact, for non monotone submodular functions.",
                    "label": 0
                },
                {
                    "sent": "I think the most natural constraints are those which are sort of sitting in the middle, like these problems, like minimum by section in graph or maximum by section, where you say that you want to cut such that both sides are equal or approximately equal.",
                    "label": 0
                },
                {
                    "sent": "So that kind of constraint is maybe the most natural one here.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Thanks.",
                    "label": 0
                }
            ]
        }
    }
}