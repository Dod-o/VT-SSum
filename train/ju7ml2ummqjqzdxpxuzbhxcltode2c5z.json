{
    "id": "ju7ml2ummqjqzdxpxuzbhxcltode2c5z",
    "title": "Partner presentation - KIT",
    "info": {
        "author": [
            "Andreas Thalhammer, F. Hoffmann-La Roche Ltd",
            "Lei Zhang, Institute of Applied Informatics and Formal Description Methods (AIFB), Karlsruhe Institute of Technology (KIT)",
            "Michael F\u00e4rber, Institute of Applied Informatics and Formal Description Methods (AIFB), Karlsruhe Institute of Technology (KIT)",
            "Achim Rettinger, Institute of Applied Informatics and Formal Description Methods (AIFB), Karlsruhe Institute of Technology (KIT)"
        ],
        "published": "July 15, 2014",
        "recorded": "November 2013",
        "category": [
            "Top->Computer Science->Knowledge Extraction"
        ]
    },
    "url": "http://videolectures.net/xlimekickoff2013_partner_presentation_kit/",
    "segmentation": [
        [
            "So we are."
        ],
        [
            "Said from Katie, the overview of this, like presentation for the next hour is.",
            "I will briefly talk about our Institute, then go into what technologies we have that might be helpful for the Exline project.",
            "So some, some are very very closely related.",
            "Others yeah, just maybe just 4.",
            "We could build on top of this and maybe develop new ideas.",
            "And then I will briefly talk about the deliverables of for the first year."
        ],
        [
            "So about us."
        ],
        [
            "So this is something we call semantic as well.",
            "Sometimes it's also called Rudy Verse which some person see you don't like at all.",
            "So this is basically what is related.",
            "Like all institutions that are related to professor student through the and have something to do with semantics.",
            "So we're on the research side.",
            "This is the AFP.",
            "We have a partner Institute that the Ksri in cards with service reach Research Institute which is sponsored by Bush and IBM sponsored.",
            "Is this correct is.",
            "Funded, funded, funded.",
            "OK, here are some of the topics that we are mainly doing then.",
            "Then we have the fortunes tentrem informatic which is more applied Research Institute which is actually just 200 meters from the University of maybe 400 or 500.",
            "And then we have some companies that we closely collaborate that either spinoffs of our Institute or after I.",
            "Or yeah, companies we know for a long time."
        ],
        [
            "Here just couple of names like the persons that are working at AFP in F said I.",
            "Also the topics.",
            "This is constantly changing, but just to give you an idea how many people are working at our Institute."
        ],
        [
            "OK, now coming to the so we're mostly funded by.",
            "Projects so the projects coming either from the EU or from national funding different ministries and also the torture for strings.",
            "Command shift above the line.",
            "There are the project logos, so here's a slime as X like.",
            "Not totally up to date vendor trust.",
            "Finished today's ago.",
            "Yeah, and then here are some selected project partners that we have.",
            "So so too is in there.",
            "And some other well known names.",
            "Chase I."
        ],
        [
            "OK, now about the team for Exline."
        ],
        [
            "That's mostly Andreas you sitting here.",
            "Then we will get a new colleague.",
            "He will start in January at Itea and of course we have people that are somehow close to the project like Michelle and Lay who's working on X like so yeah, and who is always a good backup for any task."
        ],
        [
            "OK, now I stop talking finally, hello."
        ],
        [
            "Name is Michelle.",
            "I'm from Katie.",
            "As I am already mentioned.",
            "Yeah, and I just start with some demos.",
            "First demo is about semantic search.",
            "It's called research Pro."
        ],
        [
            "Which is about the semantic search system.",
            "We use semantic relations for the document ranking step.",
            "The basic idea is that behavior hypothesis, which is that a document or an article is more relevant if it doesn't contain only the entity, the term itself, but also attributes which are related to this search term to search entity.",
            "In this example, if you have if you want to search focus on for the company next.",
            "The documents which contain, for example California or Steve Jobs are more interesting because we know there circulation key person or location of this company next, of course, we already must have this relations.",
            "This is our knowledge base.",
            "In this case, DB pedia.",
            "And this can enlarge our possibilities for semantic search.",
            "In this case, this means the user doesn't have to specify.",
            "For example, I'm looking for next.",
            "So here in his only next, but also you can say let's search about key persons of next not knowing the person itself.",
            "So it does not enter Steve Charles but only key person.",
            "How does this work?"
        ],
        [
            "First of all, we need a knowledge base and we need to annotate the documents we want to rank.",
            "In this case, there's a bunch of documents and we use for example, the Wikipedia minor.",
            "This is a tool where we can annotate the text documents, so in this case.",
            "Here for example Nokia as mentioned here, it's annotated to the PD entity.",
            "We have Windows, iPhone and also some disambiguation is done here like software company.",
            "This is in this case Microsoft for example.",
            "Then the actual search can begin.",
            "The user enters some keywords, only one keyword.",
            "Then he can refine his query.",
            "He can select first of all the class.",
            "This keyword should belong to.",
            "In this case, next can be the company next but also nextmedia.",
            "It mentioned it is mentioned in the TV show or in some work or whatever.",
            "So he can select the class and then the entity itself he's interested in."
        ],
        [
            "The last step stand the document ranking step.",
            "This is the most important one and the clues here that the user can specify the debates there where he's interested in.",
            "He gets the entity back.",
            "This is next company here.",
            "And if he's interested in the key person, for example, he gives this relation key person's special higher value.",
            "So if you have these documents, first we filled out all documents which are not relevant and these are the documents which do not contain the company.",
            "Next year, for example, here we have next media limited.",
            "This is not the company.",
            "Next is another company.",
            "But this is done by the annotation tool.",
            "And then the ranking is done and as we have fear, Steve Jobs and next, so we know here's a relation next to Steve Jobs is an attribute.",
            "You can rank this higher.",
            "So if documents three is highest person and highest position, and then the other one, there's only next software and so on.",
            "So just to give you an idea.",
            "We have exact search and fastest search.",
            "For example, I have already here tried this fast search, then we can select here the class or here the end it.",
            "If you're interested in whatever here.",
            "OK.",
            "So here can be the company or the organization.",
            "This is not the best.",
            "Connection.",
            "OK.",
            "Took some time.",
            "OK. Nope.",
            "I anyway yeah, so on the left you have here the relations and you can for example weights that you're whatever here for example.",
            "Key person can ever higher value.",
            "This should be fast normally.",
            "Maybe I'm not used to make whatever.",
            "And they normally we have can give her special weight like 9 or 99 and then these documents on the right hand side are ranked in a different manner.",
            "So.",
            "Yeah, that's all OK. OK, this was only an impression for semantic search and now continue with Lee."
        ],
        [
            "Now I will introduce some cross lingual techniques we developed mainly in X.",
            "Like project.",
            "First is the cross lingual document linking, namely how to link document documents in different languages based on the similarity between them as we know."
        ],
        [
            "So document we can represent documents as term vectors based on the bag of words model.",
            "For example, given this English 3 English documents and we assume the English vocabulary contain contains these terms, we can represent these documents as a term vector, X1X, 2X3."
        ],
        [
            "And then we can based on that, we can compute the similarity between this document based on some standard standard similarity measure.",
            "For example cosine similarity however."
        ],
        [
            "Over for cross lingual document similarity.",
            "Usually the the different language have different vocabularies, so given these two set of English and German documents, we cannot directly compare these vectors becausw each dimension.",
            "4 different languages represent a different term.",
            "So we call this vocabulary mismatch problem to solve."
        ],
        [
            "This vocabulary mismatch problem, we developed different approaches to.",
            "Of two cross lingual document linking X like Project, Katie developed the cross lingual explicit semantic analysis and Jess I developed the Director Cross lingual latent semantic indexing and Canonical correlation analysis."
        ],
        [
            "Yeah, I will briefly introduce the cross lingual explicit semantic analysis.",
            "Also called series are for either.",
            "We assume there are some external defined concepts.",
            "Each concept has its texture, description, Forcier.",
            "Either the concept has the text texture description in several languages as concepts.",
            "We can use the comperable Wikipedia articles or anything.",
            "Parallel documents.",
            "For example.",
            "Here we can extract the come parable.",
            "We keep it articles from Wikipedia here for the English One English, one computational linguistic and for German article computer linguistic, so we can use this tool.",
            "Wikipedia article as a texture description of the concept, computing computational, linguistic and similarly we can extract more comperable articles in other language.",
            "Through their cross language links in Wikipedia.",
            "So here we have the.",
            "Concept representation, which is independent of the of the languages.",
            "And."
        ],
        [
            "Based on that, we we construct the interlingual concept space.",
            "For example, here, here each dimension represents which represent concept and the concept has the texture description in different languages.",
            "And then we can map the documents of arbitrary language into this interlingual concept space.",
            "For example, here the blue points represent the English documents and the red points represent represent the German documents.",
            "Actually here we use a function mapping function which transforms the term vector of documents to their concept vectors.",
            "This is the mapping function.",
            "Here we can observe that the concept vector has N dimensions because we have end concepts here.",
            "And each entry here represents the Association strength between the concept and the documents.",
            "Here this function can be like in the product, so so it represents the the Association strengths between the concept and and document X.",
            "So after we.",
            "We map the document given two documents.",
            "After we map these two documents in different language into this Inter lingual concept space, we can compare these two vector using standard similarity measure such as cosine similarity here.",
            "So in this way we can compute the similarity similarity between documents in different languages OK."
        ],
        [
            "An we paired the cross lingual document linking service.",
            "Here is some information about the service so we have some parimeter the document, the first document and this language and the second document as this language.",
            "So the output is a similarity score between the document between the documents.",
            "So I will show you the demo."
        ],
        [
            "So this is the web service we built, so the input is the is 2 documents in different language and then you will get the.",
            "Similarities score between them and we also build the.",
            "User interface on top of the service.",
            "Here you can select the language of the first document and select one.",
            "Document here I select the second language as German and.",
            "Select documents.",
            "So here I select some some parallel documents as example.",
            "So if the.",
            "If the number is the same.",
            "That means there are parallel documents, for example of one and one.",
            "So if I select the.",
            "Another document and compute the similarity.",
            "You can see the similarity is the much smaller or I for example for the second one.",
            "Yeah, these are two.",
            "Parallel documents and scores the higher.",
            "OK, and also in excellent project JS I build the.",
            "Also appeared there.",
            "Crosslinker.",
            "Molarity service this is a GI side gsis service that has a similar function but based on different techniques is based on the CL LSI."
        ],
        [
            "OK. Next I will introduce the cross lingual semantic annotation techniques we developed in X like project."
        ],
        [
            "First, the what is the problem of cross lingual semantic annotation on the one side we have the documents containing a set of entity mentions in source language in a source language and on the other side we have semantic knowledge base containing a set of entities and relations between between them.",
            "Here the the.",
            "These entities are described in the target language, so usually the source language and target language might be different.",
            "And cross lingual semantic annotation is to link or annotate this entity mentions in the documents with their reference entities in the knowledge base."
        ],
        [
            "There are some challenges here.",
            "First is the resourcing.",
            "The launch base can be mentioned in different ways, such as a common name or some other illnesses.",
            "For example, for the US State New York, it can be mentioned in different ways in different languages.",
            "For example, here NY New York in English and starts the 11th bond start in German.",
            "So the challenge is the how to how to know all this?",
            "These measures which can.",
            "Refer to this entity.",
            "So we call this variation problem.",
            "Yeah, there are a lot of I just list like yeah yes yeah for New York actually there are like 30 different names so.",
            "So the second problem is mentioned may refer to different resources in the knowledge base given the different given different contexts for example."
        ],
        [
            "Here starts might refer to the general entity Usdata or the Special one New York and the Spanish New York.",
            "I don't know how to pronounce.",
            "It can refer to New York State or New York City and English.",
            "New York can refer to New York, NY City or New York magazine.",
            "So here the challenge is how to disambiguate these entities.",
            "We call it this.",
            "Great problem, so the.",
            "So in our system we try, we try to solve this two problem."
        ],
        [
            "I will first briefly introduce the system architecture.",
            "We use the linked open data and Wikipedia on debate basis.",
            "We first performed.",
            "Steps the linked open data exploit exploitation and Wikipedia mining to extract the graphic structure of the data and cross lingual groundings.",
            "This is offline process and based on that we build build.",
            "We store this graphic graph structures and crossing cross lingual groundings into different indexes.",
            "And then we build their cross lingual semantic annotation service which is performed performed by two components.",
            "First is the local mention entity similarity computation and 2nd is the disambiguation based on the global coherence.",
            "I will talk talk about these two later.",
            "And this part is the online process."
        ],
        [
            "So first I will briefly introduce the cross lingual groundings extraction.",
            "We start with the we start with English Wikipedia articles for example here for this English Wikipedia article New York.",
            "We extract surface forms of the resource from Wikipedia.",
            "So first form means means the words or phrases that can be used to represent a resource.",
            "Basically, basically we use the following sources.",
            "The title of the page.",
            "Provides the most common name for the resource, and redirect and disambiguation pages provide the synonyms and as a elasis and the most important one is the anchor text, which provides the sooner names and other variations for for resources.",
            "For example, here we can derive the surface form for New York, so here's 3 New York, NY State an NY.",
            "And then we derived the cross.",
            "Lingual grounding is based on the cross language links in Wikipedia.",
            "For example here throws across language links.",
            "In Wikipedia we find the German Wikipedia article and then we can similarly recap based on this.",
            "This sources we derive the German surface form for new New York.",
            "And also.",
            "Through DB Pedia and Wikipedia mapping, we can find the.",
            "The New York the Resource New York in the linked open data and we can use the this surface forms.",
            "We extract it As for the for resource in the linked open data.",
            "And we also exploit some statistics of this cross lingual groundings, which can be used to, for example, measure the.",
            "How strong is the surface form associated with the with the resource and we transfer all this in this information into RDF and store them in triple store and then we can use sparkle query to to get this information.",
            "Here I will show you the demo."
        ],
        [
            "Of the sparkle endpoint.",
            "Focus them.",
            "For example, the first example is the.",
            "I want to find.",
            "Resources with the label.",
            "The 11th bond start.",
            "So I find the New York and.",
            "So maybe I can try other, for example an, why?",
            "Let's see English.",
            "So I will find the NYU Ken can be used to represent New York or New York City.",
            "OK, this is the.",
            "And any others we can try.",
            "What does only return one result of physical condition?",
            "This is like.",
            "Big big 'cause this is only used to represent the New York, NY in the.",
            "Is the for example under start?",
            "Oh, let's just use.",
            "Start torch.",
            "So you will find a sum.",
            "This is a very general one.",
            "You will also find the New York.",
            "But the score is somehow.",
            "Low.",
            "OK, this is how to given a surface form how to find resource?",
            "And.",
            "The second example.",
            "The second example is given a resource.",
            "Such as New York.",
            "I want to find other labels.",
            "In German.",
            "So here you can see.",
            "Yeah, we can find surface forms in German.",
            "There are some is not in German but this.",
            "Big Apple.",
            "OK. Yeah, this is New York State and maybe I'll try.",
            "There.",
            "I don't know if you are correct.",
            "Yeah, pick up pick up.",
            "Yeah.",
            "So this.",
            "So here yeah, given their resource find order, surface forms and last one is the.",
            "The last one is the.",
            "Given the surface form Finder probability that this surface form is used as anchor text.",
            "So for example, for this New York.",
            "Yeah, the probability is there.",
            "0.25 So if I use the general.",
            "Like Journal like start.",
            "Starts.",
            "Then the probabilities is much lower becausw it's too general, so usually not used as the links, but just that appear in the plaintext.",
            "So if I maybe I try the stop words.",
            "Cause even for the stop words you can find a Wikipedia article.",
            "So here is very low.",
            "The probability that means it always used as text, not as links.",
            "OK.",
            "So this is the.",
            "Cross lingual groundings we rebuilt."
        ],
        [
            "And based on that we.",
            "We develop some of the two components I mentioned before.",
            "The 1st is a local mesh local measure, entity similarity computation.",
            "It captures the first is captures the most likely entity behind dimension based on the cross lingual groundings I just show.",
            "And it also captures the entities that best fits their context based on cross lingual document linking techniques I present previously here the context of.",
            "Of a mention is the surrounding sentences and texts of context of entity.",
            "Is the attribute values of this content of this entity?",
            "Then the second component is a disambiguation based on global coherence.",
            "So obviously entities that appear together in one document usually tend to tend to related to each other.",
            "Yeah, so based on this observation.",
            "This component collectively disambiguates the annotations based on the relatedness among entities using the graph structure of the knowledge base, so.",
            "That means the.",
            "So entities in appear appearing in one document might be connected in the knowledge base.",
            "So the first component together with the cross lingual grounding, grounding extraction, addressed the variation problem and 2nd component together with the graph structure extraction address.",
            "The problem of ambiguity.",
            "OK."
        ],
        [
            "And also we built the cross lingual semantic annotation service based on what I should hear.",
            "This is some input parameter.",
            "Source can be the URL of web page or row text and then one is the language of the input source and land tour is the language of the output knowledge based resource NKB we can select.",
            "DBPR, Wikipedia and output can be XML output.",
            "One source is the raw text or the web page with inserted annotations.",
            "When the source is the URL of a web page."
        ],
        [
            "So I will show you.",
            "Demo 1st.",
            "First, I wear shoes are service for.",
            "For annotating the raw text.",
            "So here I the input is some.",
            "Some sentence sentence is in in German and you will get the order.",
            "DB Pedia resources, which are mentioned in the in the text.",
            "So I can change the.",
            "Like if I change change there.",
            "Output language, for example, I change to Spanish, then you will get there.",
            "Deeper resources, Spanish and also I can change the DB pedia to Vicky Pedia.",
            "So.",
            "Stronic OK then you will get the resource Wikipedia resource.",
            "2nd is to use it to annotate webpage.",
            "OK.",
            "Here this is the.",
            "Should be faster.",
            "Exchange yeah.",
            "OK so this is the URL.",
            "Of the web page I want help.",
            "I get the Internet is temporarily unavailable.",
            "OK, here maybe I can show you the original webpage first.",
            "Guess.",
            "So this is the original.",
            "Web page and after annotation so this.",
            "These entities are annotated with the.",
            "For example, if I.",
            "Open the Obama.",
            "So it's.",
            "You were linked to the DB Pedia page.",
            "Yeah.",
            "And here you can also change the.",
            "Change the knowledge base.",
            "Wikipedia.",
            "So then you can link to the.",
            "To the Wikipedia article of about Barack Obama.",
            "Yeah, any language here.",
            "We can also change the output language so you can link to, so if I change the language to Spanish then you will link to Spanish Wikipedia articles or DB pedia resource.",
            "And also based on that we be at the the.",
            "Graphic interface, so select one document here.",
            "OK, I select output is German.",
            "Yeah, and I.",
            "Here's the other annotations and mentions and score.",
            "And this pot pie charge show how many.",
            "Annotations for each language we find.",
            "OK."
        ],
        [
            "Alright, my name is Andrea, so just just starting at KIT before I've been working closely with Katie and at UFC side in the render project and there we have developed an extension to Drupal module.",
            "Drupal is a content management system is called diversity of their Drupal."
        ],
        [
            "Attention.",
            "Right, what does this trooper module do?",
            "For example, if you're writing A blog post, you and you have a couple of related blog posts you would like to have which covered the same topic you would like to be directed to them, like somehow guided to them.",
            "This is like it's basically.",
            "Expert or exploratory search module so and this setting we cover different dimensions in particular topics in sentiment.",
            "And the buyer, as we understand topics topic can also be a named entity in our case and or automatically generated topic.",
            "And the content discovery is.",
            "Basically, through the cover topics.",
            "Right, give."
        ],
        [
            "Do a short demo on this.",
            "So I set this up.",
            "With empty data, which is actually like, I just used few random examples from Discovery Channel, so don't be surprised.",
            "So for example, like there's this kind of Fable, which goes around like the people are into searching for gold.",
            "Let's have a look at this short.",
            "Text on mining and so it's basically describes show which is coming up the next days on Discovery Channel.",
            "So is the locations of TV shows electronic program guide EPG.",
            "So if you you have you have a button on your TV remote control, so sort of just clicked EPG data and then you get a detailed description of what the show is about and here is about like.",
            "So how this guys?",
            "Find toy flakes of code and so for example, and now we extracted a couple of topics in here.",
            "So for example, mining just quite relevant to searching for gold, and now we find actually some show we just had, and this is a related show which also covers.",
            "Gold rush and so we have the topic Alaska here.",
            "So just like we are interested now in Alaska for some reason and we navigate to Alaska.",
            "Now we get shows which cover Alaska, just Alaska, the last Frontier and we select, for example, North America's next topic.",
            "So he can basically switch through the topics which could be easily done via remote control and you don't have to type any text.",
            "And for example, like here, we ended up with American Chopper.",
            "If we just like.",
            "Click on this and see what kind of topics are extracted.",
            "Is neutral.",
            "That's the sentiment extraction.",
            "I maybe we can ask our colleagues from Chase Ivy, but there is.",
            "There's a one show which is negative, which we will get to know, which is.",
            "So this is about American chopper and how they tune the models, and so we're getting interested in motor sports.",
            "And here we actually get Street outlaws, which is actually has a negative sentiment.",
            "Which is.",
            "And this is actually like also in this case, because it's just a few articles.",
            "This is actually kind of a dead end.",
            "The only show where we can navigate back to his American chopper.",
            "But it's just demo.",
            "We also have extracted tax here and usually you through a topic extraction.",
            "You can also get like related, positive, negative and neutral articles.",
            "Right, that's about it.",
            "If you have any questions.",
            "Yeah, the last 15."
        ],
        [
            "That are less than that last minutes, just on what we plan for the first year.",
            "The deliverables."
        ],
        [
            "We have, so as I said before, we are mostly involved in work package one and four.",
            "But this doesn't mean that."
        ],
        [
            "We have a lot of deliverables and other work packages, so those are deliverables for actually that are due in three days.",
            "So so at the end of the first month.",
            "Yeah, but it's it's not that bad, but maybe maybe this deliverable, something that Sophie, like the former project of the She insisted to put this there and we're not very happy with that.",
            "So if you have some, if you think you know some risks, what could go wrong in the project?",
            "Let us know very soon, because then we can put it in this deliverable an But anyway, so we thought we covered this pretty well in the proposal, but apparently not.",
            "Anyway, so those are the important deliverables.",
            "The first one, so I will go through them and."
        ],
        [
            "The first step, the first one is this prototype of meta data model.",
            "I think the most important thing is here to see what we already have, like from the exact project, how we their structure, our data and of course from Vista TV.",
            "What meta data we can get from there and how it's represented and how we can integrate both of that.",
            "And then of course extend this considering the requirements of our use cases in slime.",
            "And yeah, we already listed a couple of candidates for standards.",
            "We of course we want to reuse standards as much as possible, but.",
            "Yeah we have to see this so we don't have a plan for this at all."
        ],
        [
            "Then deliver rebel three point 3.1.",
            "So this is something that.",
            "Related to this, what was just presented the cross lingual semantic annotation?",
            "So what you just saw with the website that could annotate entities on this website.",
            "Here the goal is not only annotate text from websites, but also text that comes from different modalities like speech and images, and we don't have experience with that.",
            "We don't know if it works, if it's different, how the performance will be and so on.",
            "So this is something we want to do in this deliverable.",
            "To do this, of course, we also need the links between the modalities and between the languages like we already have this in the X like case for the different languages, yeah.",
            "Yeah, probably this would is always our first guest, but of course we could think about other knowledge bases that are more suitable for the use cases.",
            "So so.",
            "But I guess we're always linking to DB Pedia plus something.",
            "I've called for his OSD pedia.",
            "Kind of data we have and what kind of yes, yeah yeah.",
            "It's it's very much use case driven.",
            "Media there are.",
            "Music yeah yeah maybe yeah.",
            "They are maybe companies or I don't know.",
            "OK."
        ],
        [
            "And then this is, I think this is the most interesting one.",
            "This is the statistical content linking that we also just showed with the text.",
            "So the text similarity with the cross lingual USA or Canonical correlation analysis.",
            "So the ideas you basically input like what we want to have in the end is a function where you input one.",
            "So far we input one text in any language and another text in any language.",
            "And we get some number out of it, telling you how similar the content of those two texts are in now what we need here is something where you put in any.",
            "The multimedia item like video, whatever, audio, anything put in it and another one and you could be text, the other one and you get a similarity score.",
            "Even across languages.",
            "This is something that is probably very the hardest task in the most interesting as well, and how we want to do this is basically the same approach as we did this for text.",
            "So what you need to do is collect a parallel corpus, but so far the parallel corpus was just a list of.",
            "Text documents that were aligned.",
            "That means translated, for example.",
            "So we had the English and the German text for example.",
            "Now we need this.",
            "We need such a multimedia aligned corpus and this is of course something different.",
            "I mean, there are some out there, but we don't have a lot of experience.",
            "And then there's of course the big question.",
            "How to represent this?",
            "I mean, so far we've always like a big vector.",
            "Is this enough?",
            "Does this work?",
            "Let's see so.",
            "And what should be in this vector like?",
            "Having the.",
            "A million sway ways of representing video as a vector, I guess.",
            "So this is, I think this is the most interesting and deliverable that we have in the first year."
        ],
        [
            "I'm.",
            "And then this is the final deliverable, which builds very much on top of this functionality of the deliverable before that means.",
            "We are.",
            "We have some kind of query which could be any multilingual multimedia item.",
            "I still don't have a good word for this multilingual multimedia item, so could be text video in any languages, whatever.",
            "We have this as a search query and we want to get something similar that could be text.",
            "Could be a video appear, anything other so and the search could be explicit like someone typing a keyword or in putting a text, but it could also be implicit like in the so two case where someone is watching a TV show and we just take this as a query to show him related articles from Wikipedia or from maybe even tweets or whatever.",
            "Yeah.",
            "So yeah, and it's probably built on top of this.",
            "On this functionality and then of course, once we have something like semantic search, we can also do stuff that we just saw in this in the first semantic search prototype or in this Drupal extension where we can then browse and.",
            "Find related topics and so on."
        ],
        [
            "OK, so that's it from the khits side."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we are.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Said from Katie, the overview of this, like presentation for the next hour is.",
                    "label": 0
                },
                {
                    "sent": "I will briefly talk about our Institute, then go into what technologies we have that might be helpful for the Exline project.",
                    "label": 0
                },
                {
                    "sent": "So some, some are very very closely related.",
                    "label": 0
                },
                {
                    "sent": "Others yeah, just maybe just 4.",
                    "label": 0
                },
                {
                    "sent": "We could build on top of this and maybe develop new ideas.",
                    "label": 0
                },
                {
                    "sent": "And then I will briefly talk about the deliverables of for the first year.",
                    "label": 1
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So about us.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is something we call semantic as well.",
                    "label": 0
                },
                {
                    "sent": "Sometimes it's also called Rudy Verse which some person see you don't like at all.",
                    "label": 0
                },
                {
                    "sent": "So this is basically what is related.",
                    "label": 0
                },
                {
                    "sent": "Like all institutions that are related to professor student through the and have something to do with semantics.",
                    "label": 0
                },
                {
                    "sent": "So we're on the research side.",
                    "label": 0
                },
                {
                    "sent": "This is the AFP.",
                    "label": 0
                },
                {
                    "sent": "We have a partner Institute that the Ksri in cards with service reach Research Institute which is sponsored by Bush and IBM sponsored.",
                    "label": 0
                },
                {
                    "sent": "Is this correct is.",
                    "label": 0
                },
                {
                    "sent": "Funded, funded, funded.",
                    "label": 0
                },
                {
                    "sent": "OK, here are some of the topics that we are mainly doing then.",
                    "label": 0
                },
                {
                    "sent": "Then we have the fortunes tentrem informatic which is more applied Research Institute which is actually just 200 meters from the University of maybe 400 or 500.",
                    "label": 0
                },
                {
                    "sent": "And then we have some companies that we closely collaborate that either spinoffs of our Institute or after I.",
                    "label": 0
                },
                {
                    "sent": "Or yeah, companies we know for a long time.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here just couple of names like the persons that are working at AFP in F said I.",
                    "label": 0
                },
                {
                    "sent": "Also the topics.",
                    "label": 0
                },
                {
                    "sent": "This is constantly changing, but just to give you an idea how many people are working at our Institute.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, now coming to the so we're mostly funded by.",
                    "label": 0
                },
                {
                    "sent": "Projects so the projects coming either from the EU or from national funding different ministries and also the torture for strings.",
                    "label": 0
                },
                {
                    "sent": "Command shift above the line.",
                    "label": 0
                },
                {
                    "sent": "There are the project logos, so here's a slime as X like.",
                    "label": 0
                },
                {
                    "sent": "Not totally up to date vendor trust.",
                    "label": 0
                },
                {
                    "sent": "Finished today's ago.",
                    "label": 0
                },
                {
                    "sent": "Yeah, and then here are some selected project partners that we have.",
                    "label": 0
                },
                {
                    "sent": "So so too is in there.",
                    "label": 0
                },
                {
                    "sent": "And some other well known names.",
                    "label": 0
                },
                {
                    "sent": "Chase I.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, now about the team for Exline.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That's mostly Andreas you sitting here.",
                    "label": 0
                },
                {
                    "sent": "Then we will get a new colleague.",
                    "label": 0
                },
                {
                    "sent": "He will start in January at Itea and of course we have people that are somehow close to the project like Michelle and Lay who's working on X like so yeah, and who is always a good backup for any task.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, now I stop talking finally, hello.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Name is Michelle.",
                    "label": 0
                },
                {
                    "sent": "I'm from Katie.",
                    "label": 0
                },
                {
                    "sent": "As I am already mentioned.",
                    "label": 0
                },
                {
                    "sent": "Yeah, and I just start with some demos.",
                    "label": 0
                },
                {
                    "sent": "First demo is about semantic search.",
                    "label": 1
                },
                {
                    "sent": "It's called research Pro.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Which is about the semantic search system.",
                    "label": 1
                },
                {
                    "sent": "We use semantic relations for the document ranking step.",
                    "label": 1
                },
                {
                    "sent": "The basic idea is that behavior hypothesis, which is that a document or an article is more relevant if it doesn't contain only the entity, the term itself, but also attributes which are related to this search term to search entity.",
                    "label": 1
                },
                {
                    "sent": "In this example, if you have if you want to search focus on for the company next.",
                    "label": 0
                },
                {
                    "sent": "The documents which contain, for example California or Steve Jobs are more interesting because we know there circulation key person or location of this company next, of course, we already must have this relations.",
                    "label": 0
                },
                {
                    "sent": "This is our knowledge base.",
                    "label": 0
                },
                {
                    "sent": "In this case, DB pedia.",
                    "label": 0
                },
                {
                    "sent": "And this can enlarge our possibilities for semantic search.",
                    "label": 0
                },
                {
                    "sent": "In this case, this means the user doesn't have to specify.",
                    "label": 0
                },
                {
                    "sent": "For example, I'm looking for next.",
                    "label": 0
                },
                {
                    "sent": "So here in his only next, but also you can say let's search about key persons of next not knowing the person itself.",
                    "label": 1
                },
                {
                    "sent": "So it does not enter Steve Charles but only key person.",
                    "label": 0
                },
                {
                    "sent": "How does this work?",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "First of all, we need a knowledge base and we need to annotate the documents we want to rank.",
                    "label": 0
                },
                {
                    "sent": "In this case, there's a bunch of documents and we use for example, the Wikipedia minor.",
                    "label": 0
                },
                {
                    "sent": "This is a tool where we can annotate the text documents, so in this case.",
                    "label": 0
                },
                {
                    "sent": "Here for example Nokia as mentioned here, it's annotated to the PD entity.",
                    "label": 0
                },
                {
                    "sent": "We have Windows, iPhone and also some disambiguation is done here like software company.",
                    "label": 0
                },
                {
                    "sent": "This is in this case Microsoft for example.",
                    "label": 0
                },
                {
                    "sent": "Then the actual search can begin.",
                    "label": 0
                },
                {
                    "sent": "The user enters some keywords, only one keyword.",
                    "label": 0
                },
                {
                    "sent": "Then he can refine his query.",
                    "label": 0
                },
                {
                    "sent": "He can select first of all the class.",
                    "label": 0
                },
                {
                    "sent": "This keyword should belong to.",
                    "label": 0
                },
                {
                    "sent": "In this case, next can be the company next but also nextmedia.",
                    "label": 0
                },
                {
                    "sent": "It mentioned it is mentioned in the TV show or in some work or whatever.",
                    "label": 0
                },
                {
                    "sent": "So he can select the class and then the entity itself he's interested in.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The last step stand the document ranking step.",
                    "label": 0
                },
                {
                    "sent": "This is the most important one and the clues here that the user can specify the debates there where he's interested in.",
                    "label": 0
                },
                {
                    "sent": "He gets the entity back.",
                    "label": 0
                },
                {
                    "sent": "This is next company here.",
                    "label": 0
                },
                {
                    "sent": "And if he's interested in the key person, for example, he gives this relation key person's special higher value.",
                    "label": 0
                },
                {
                    "sent": "So if you have these documents, first we filled out all documents which are not relevant and these are the documents which do not contain the company.",
                    "label": 0
                },
                {
                    "sent": "Next year, for example, here we have next media limited.",
                    "label": 0
                },
                {
                    "sent": "This is not the company.",
                    "label": 0
                },
                {
                    "sent": "Next is another company.",
                    "label": 0
                },
                {
                    "sent": "But this is done by the annotation tool.",
                    "label": 0
                },
                {
                    "sent": "And then the ranking is done and as we have fear, Steve Jobs and next, so we know here's a relation next to Steve Jobs is an attribute.",
                    "label": 0
                },
                {
                    "sent": "You can rank this higher.",
                    "label": 0
                },
                {
                    "sent": "So if documents three is highest person and highest position, and then the other one, there's only next software and so on.",
                    "label": 0
                },
                {
                    "sent": "So just to give you an idea.",
                    "label": 0
                },
                {
                    "sent": "We have exact search and fastest search.",
                    "label": 0
                },
                {
                    "sent": "For example, I have already here tried this fast search, then we can select here the class or here the end it.",
                    "label": 0
                },
                {
                    "sent": "If you're interested in whatever here.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So here can be the company or the organization.",
                    "label": 0
                },
                {
                    "sent": "This is not the best.",
                    "label": 0
                },
                {
                    "sent": "Connection.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "Took some time.",
                    "label": 0
                },
                {
                    "sent": "OK. Nope.",
                    "label": 0
                },
                {
                    "sent": "I anyway yeah, so on the left you have here the relations and you can for example weights that you're whatever here for example.",
                    "label": 0
                },
                {
                    "sent": "Key person can ever higher value.",
                    "label": 0
                },
                {
                    "sent": "This should be fast normally.",
                    "label": 0
                },
                {
                    "sent": "Maybe I'm not used to make whatever.",
                    "label": 0
                },
                {
                    "sent": "And they normally we have can give her special weight like 9 or 99 and then these documents on the right hand side are ranked in a different manner.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Yeah, that's all OK. OK, this was only an impression for semantic search and now continue with Lee.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now I will introduce some cross lingual techniques we developed mainly in X.",
                    "label": 0
                },
                {
                    "sent": "Like project.",
                    "label": 0
                },
                {
                    "sent": "First is the cross lingual document linking, namely how to link document documents in different languages based on the similarity between them as we know.",
                    "label": 1
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So document we can represent documents as term vectors based on the bag of words model.",
                    "label": 0
                },
                {
                    "sent": "For example, given this English 3 English documents and we assume the English vocabulary contain contains these terms, we can represent these documents as a term vector, X1X, 2X3.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then we can based on that, we can compute the similarity between this document based on some standard standard similarity measure.",
                    "label": 0
                },
                {
                    "sent": "For example cosine similarity however.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Over for cross lingual document similarity.",
                    "label": 0
                },
                {
                    "sent": "Usually the the different language have different vocabularies, so given these two set of English and German documents, we cannot directly compare these vectors becausw each dimension.",
                    "label": 0
                },
                {
                    "sent": "4 different languages represent a different term.",
                    "label": 0
                },
                {
                    "sent": "So we call this vocabulary mismatch problem to solve.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This vocabulary mismatch problem, we developed different approaches to.",
                    "label": 0
                },
                {
                    "sent": "Of two cross lingual document linking X like Project, Katie developed the cross lingual explicit semantic analysis and Jess I developed the Director Cross lingual latent semantic indexing and Canonical correlation analysis.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Yeah, I will briefly introduce the cross lingual explicit semantic analysis.",
                    "label": 1
                },
                {
                    "sent": "Also called series are for either.",
                    "label": 1
                },
                {
                    "sent": "We assume there are some external defined concepts.",
                    "label": 1
                },
                {
                    "sent": "Each concept has its texture, description, Forcier.",
                    "label": 1
                },
                {
                    "sent": "Either the concept has the text texture description in several languages as concepts.",
                    "label": 1
                },
                {
                    "sent": "We can use the comperable Wikipedia articles or anything.",
                    "label": 0
                },
                {
                    "sent": "Parallel documents.",
                    "label": 0
                },
                {
                    "sent": "For example.",
                    "label": 0
                },
                {
                    "sent": "Here we can extract the come parable.",
                    "label": 0
                },
                {
                    "sent": "We keep it articles from Wikipedia here for the English One English, one computational linguistic and for German article computer linguistic, so we can use this tool.",
                    "label": 0
                },
                {
                    "sent": "Wikipedia article as a texture description of the concept, computing computational, linguistic and similarly we can extract more comperable articles in other language.",
                    "label": 0
                },
                {
                    "sent": "Through their cross language links in Wikipedia.",
                    "label": 1
                },
                {
                    "sent": "So here we have the.",
                    "label": 0
                },
                {
                    "sent": "Concept representation, which is independent of the of the languages.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Based on that, we we construct the interlingual concept space.",
                    "label": 0
                },
                {
                    "sent": "For example, here, here each dimension represents which represent concept and the concept has the texture description in different languages.",
                    "label": 0
                },
                {
                    "sent": "And then we can map the documents of arbitrary language into this interlingual concept space.",
                    "label": 1
                },
                {
                    "sent": "For example, here the blue points represent the English documents and the red points represent represent the German documents.",
                    "label": 0
                },
                {
                    "sent": "Actually here we use a function mapping function which transforms the term vector of documents to their concept vectors.",
                    "label": 1
                },
                {
                    "sent": "This is the mapping function.",
                    "label": 0
                },
                {
                    "sent": "Here we can observe that the concept vector has N dimensions because we have end concepts here.",
                    "label": 0
                },
                {
                    "sent": "And each entry here represents the Association strength between the concept and the documents.",
                    "label": 0
                },
                {
                    "sent": "Here this function can be like in the product, so so it represents the the Association strengths between the concept and and document X.",
                    "label": 0
                },
                {
                    "sent": "So after we.",
                    "label": 0
                },
                {
                    "sent": "We map the document given two documents.",
                    "label": 0
                },
                {
                    "sent": "After we map these two documents in different language into this Inter lingual concept space, we can compare these two vector using standard similarity measure such as cosine similarity here.",
                    "label": 0
                },
                {
                    "sent": "So in this way we can compute the similarity similarity between documents in different languages OK.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "An we paired the cross lingual document linking service.",
                    "label": 1
                },
                {
                    "sent": "Here is some information about the service so we have some parimeter the document, the first document and this language and the second document as this language.",
                    "label": 1
                },
                {
                    "sent": "So the output is a similarity score between the document between the documents.",
                    "label": 0
                },
                {
                    "sent": "So I will show you the demo.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is the web service we built, so the input is the is 2 documents in different language and then you will get the.",
                    "label": 0
                },
                {
                    "sent": "Similarities score between them and we also build the.",
                    "label": 0
                },
                {
                    "sent": "User interface on top of the service.",
                    "label": 0
                },
                {
                    "sent": "Here you can select the language of the first document and select one.",
                    "label": 0
                },
                {
                    "sent": "Document here I select the second language as German and.",
                    "label": 0
                },
                {
                    "sent": "Select documents.",
                    "label": 0
                },
                {
                    "sent": "So here I select some some parallel documents as example.",
                    "label": 0
                },
                {
                    "sent": "So if the.",
                    "label": 0
                },
                {
                    "sent": "If the number is the same.",
                    "label": 0
                },
                {
                    "sent": "That means there are parallel documents, for example of one and one.",
                    "label": 0
                },
                {
                    "sent": "So if I select the.",
                    "label": 0
                },
                {
                    "sent": "Another document and compute the similarity.",
                    "label": 0
                },
                {
                    "sent": "You can see the similarity is the much smaller or I for example for the second one.",
                    "label": 0
                },
                {
                    "sent": "Yeah, these are two.",
                    "label": 0
                },
                {
                    "sent": "Parallel documents and scores the higher.",
                    "label": 0
                },
                {
                    "sent": "OK, and also in excellent project JS I build the.",
                    "label": 0
                },
                {
                    "sent": "Also appeared there.",
                    "label": 0
                },
                {
                    "sent": "Crosslinker.",
                    "label": 0
                },
                {
                    "sent": "Molarity service this is a GI side gsis service that has a similar function but based on different techniques is based on the CL LSI.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK. Next I will introduce the cross lingual semantic annotation techniques we developed in X like project.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "First, the what is the problem of cross lingual semantic annotation on the one side we have the documents containing a set of entity mentions in source language in a source language and on the other side we have semantic knowledge base containing a set of entities and relations between between them.",
                    "label": 1
                },
                {
                    "sent": "Here the the.",
                    "label": 1
                },
                {
                    "sent": "These entities are described in the target language, so usually the source language and target language might be different.",
                    "label": 1
                },
                {
                    "sent": "And cross lingual semantic annotation is to link or annotate this entity mentions in the documents with their reference entities in the knowledge base.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "There are some challenges here.",
                    "label": 0
                },
                {
                    "sent": "First is the resourcing.",
                    "label": 0
                },
                {
                    "sent": "The launch base can be mentioned in different ways, such as a common name or some other illnesses.",
                    "label": 1
                },
                {
                    "sent": "For example, for the US State New York, it can be mentioned in different ways in different languages.",
                    "label": 0
                },
                {
                    "sent": "For example, here NY New York in English and starts the 11th bond start in German.",
                    "label": 0
                },
                {
                    "sent": "So the challenge is the how to how to know all this?",
                    "label": 0
                },
                {
                    "sent": "These measures which can.",
                    "label": 0
                },
                {
                    "sent": "Refer to this entity.",
                    "label": 0
                },
                {
                    "sent": "So we call this variation problem.",
                    "label": 0
                },
                {
                    "sent": "Yeah, there are a lot of I just list like yeah yes yeah for New York actually there are like 30 different names so.",
                    "label": 0
                },
                {
                    "sent": "So the second problem is mentioned may refer to different resources in the knowledge base given the different given different contexts for example.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Here starts might refer to the general entity Usdata or the Special one New York and the Spanish New York.",
                    "label": 0
                },
                {
                    "sent": "I don't know how to pronounce.",
                    "label": 0
                },
                {
                    "sent": "It can refer to New York State or New York City and English.",
                    "label": 0
                },
                {
                    "sent": "New York can refer to New York, NY City or New York magazine.",
                    "label": 1
                },
                {
                    "sent": "So here the challenge is how to disambiguate these entities.",
                    "label": 0
                },
                {
                    "sent": "We call it this.",
                    "label": 0
                },
                {
                    "sent": "Great problem, so the.",
                    "label": 0
                },
                {
                    "sent": "So in our system we try, we try to solve this two problem.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I will first briefly introduce the system architecture.",
                    "label": 1
                },
                {
                    "sent": "We use the linked open data and Wikipedia on debate basis.",
                    "label": 0
                },
                {
                    "sent": "We first performed.",
                    "label": 0
                },
                {
                    "sent": "Steps the linked open data exploit exploitation and Wikipedia mining to extract the graphic structure of the data and cross lingual groundings.",
                    "label": 1
                },
                {
                    "sent": "This is offline process and based on that we build build.",
                    "label": 1
                },
                {
                    "sent": "We store this graphic graph structures and crossing cross lingual groundings into different indexes.",
                    "label": 1
                },
                {
                    "sent": "And then we build their cross lingual semantic annotation service which is performed performed by two components.",
                    "label": 0
                },
                {
                    "sent": "First is the local mention entity similarity computation and 2nd is the disambiguation based on the global coherence.",
                    "label": 0
                },
                {
                    "sent": "I will talk talk about these two later.",
                    "label": 0
                },
                {
                    "sent": "And this part is the online process.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So first I will briefly introduce the cross lingual groundings extraction.",
                    "label": 0
                },
                {
                    "sent": "We start with the we start with English Wikipedia articles for example here for this English Wikipedia article New York.",
                    "label": 0
                },
                {
                    "sent": "We extract surface forms of the resource from Wikipedia.",
                    "label": 1
                },
                {
                    "sent": "So first form means means the words or phrases that can be used to represent a resource.",
                    "label": 0
                },
                {
                    "sent": "Basically, basically we use the following sources.",
                    "label": 0
                },
                {
                    "sent": "The title of the page.",
                    "label": 1
                },
                {
                    "sent": "Provides the most common name for the resource, and redirect and disambiguation pages provide the synonyms and as a elasis and the most important one is the anchor text, which provides the sooner names and other variations for for resources.",
                    "label": 1
                },
                {
                    "sent": "For example, here we can derive the surface form for New York, so here's 3 New York, NY State an NY.",
                    "label": 0
                },
                {
                    "sent": "And then we derived the cross.",
                    "label": 0
                },
                {
                    "sent": "Lingual grounding is based on the cross language links in Wikipedia.",
                    "label": 0
                },
                {
                    "sent": "For example here throws across language links.",
                    "label": 0
                },
                {
                    "sent": "In Wikipedia we find the German Wikipedia article and then we can similarly recap based on this.",
                    "label": 0
                },
                {
                    "sent": "This sources we derive the German surface form for new New York.",
                    "label": 0
                },
                {
                    "sent": "And also.",
                    "label": 0
                },
                {
                    "sent": "Through DB Pedia and Wikipedia mapping, we can find the.",
                    "label": 0
                },
                {
                    "sent": "The New York the Resource New York in the linked open data and we can use the this surface forms.",
                    "label": 0
                },
                {
                    "sent": "We extract it As for the for resource in the linked open data.",
                    "label": 0
                },
                {
                    "sent": "And we also exploit some statistics of this cross lingual groundings, which can be used to, for example, measure the.",
                    "label": 0
                },
                {
                    "sent": "How strong is the surface form associated with the with the resource and we transfer all this in this information into RDF and store them in triple store and then we can use sparkle query to to get this information.",
                    "label": 0
                },
                {
                    "sent": "Here I will show you the demo.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Of the sparkle endpoint.",
                    "label": 0
                },
                {
                    "sent": "Focus them.",
                    "label": 0
                },
                {
                    "sent": "For example, the first example is the.",
                    "label": 0
                },
                {
                    "sent": "I want to find.",
                    "label": 0
                },
                {
                    "sent": "Resources with the label.",
                    "label": 0
                },
                {
                    "sent": "The 11th bond start.",
                    "label": 0
                },
                {
                    "sent": "So I find the New York and.",
                    "label": 1
                },
                {
                    "sent": "So maybe I can try other, for example an, why?",
                    "label": 0
                },
                {
                    "sent": "Let's see English.",
                    "label": 0
                },
                {
                    "sent": "So I will find the NYU Ken can be used to represent New York or New York City.",
                    "label": 0
                },
                {
                    "sent": "OK, this is the.",
                    "label": 0
                },
                {
                    "sent": "And any others we can try.",
                    "label": 0
                },
                {
                    "sent": "What does only return one result of physical condition?",
                    "label": 0
                },
                {
                    "sent": "This is like.",
                    "label": 0
                },
                {
                    "sent": "Big big 'cause this is only used to represent the New York, NY in the.",
                    "label": 0
                },
                {
                    "sent": "Is the for example under start?",
                    "label": 0
                },
                {
                    "sent": "Oh, let's just use.",
                    "label": 0
                },
                {
                    "sent": "Start torch.",
                    "label": 0
                },
                {
                    "sent": "So you will find a sum.",
                    "label": 0
                },
                {
                    "sent": "This is a very general one.",
                    "label": 0
                },
                {
                    "sent": "You will also find the New York.",
                    "label": 0
                },
                {
                    "sent": "But the score is somehow.",
                    "label": 0
                },
                {
                    "sent": "Low.",
                    "label": 0
                },
                {
                    "sent": "OK, this is how to given a surface form how to find resource?",
                    "label": 1
                },
                {
                    "sent": "And.",
                    "label": 1
                },
                {
                    "sent": "The second example.",
                    "label": 0
                },
                {
                    "sent": "The second example is given a resource.",
                    "label": 0
                },
                {
                    "sent": "Such as New York.",
                    "label": 0
                },
                {
                    "sent": "I want to find other labels.",
                    "label": 1
                },
                {
                    "sent": "In German.",
                    "label": 0
                },
                {
                    "sent": "So here you can see.",
                    "label": 0
                },
                {
                    "sent": "Yeah, we can find surface forms in German.",
                    "label": 0
                },
                {
                    "sent": "There are some is not in German but this.",
                    "label": 0
                },
                {
                    "sent": "Big Apple.",
                    "label": 0
                },
                {
                    "sent": "OK. Yeah, this is New York State and maybe I'll try.",
                    "label": 0
                },
                {
                    "sent": "There.",
                    "label": 0
                },
                {
                    "sent": "I don't know if you are correct.",
                    "label": 0
                },
                {
                    "sent": "Yeah, pick up pick up.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 1
                },
                {
                    "sent": "So this.",
                    "label": 0
                },
                {
                    "sent": "So here yeah, given their resource find order, surface forms and last one is the.",
                    "label": 0
                },
                {
                    "sent": "The last one is the.",
                    "label": 0
                },
                {
                    "sent": "Given the surface form Finder probability that this surface form is used as anchor text.",
                    "label": 0
                },
                {
                    "sent": "So for example, for this New York.",
                    "label": 0
                },
                {
                    "sent": "Yeah, the probability is there.",
                    "label": 0
                },
                {
                    "sent": "0.25 So if I use the general.",
                    "label": 0
                },
                {
                    "sent": "Like Journal like start.",
                    "label": 0
                },
                {
                    "sent": "Starts.",
                    "label": 0
                },
                {
                    "sent": "Then the probabilities is much lower becausw it's too general, so usually not used as the links, but just that appear in the plaintext.",
                    "label": 0
                },
                {
                    "sent": "So if I maybe I try the stop words.",
                    "label": 0
                },
                {
                    "sent": "Cause even for the stop words you can find a Wikipedia article.",
                    "label": 0
                },
                {
                    "sent": "So here is very low.",
                    "label": 0
                },
                {
                    "sent": "The probability that means it always used as text, not as links.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So this is the.",
                    "label": 0
                },
                {
                    "sent": "Cross lingual groundings we rebuilt.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And based on that we.",
                    "label": 0
                },
                {
                    "sent": "We develop some of the two components I mentioned before.",
                    "label": 0
                },
                {
                    "sent": "The 1st is a local mesh local measure, entity similarity computation.",
                    "label": 0
                },
                {
                    "sent": "It captures the first is captures the most likely entity behind dimension based on the cross lingual groundings I just show.",
                    "label": 1
                },
                {
                    "sent": "And it also captures the entities that best fits their context based on cross lingual document linking techniques I present previously here the context of.",
                    "label": 0
                },
                {
                    "sent": "Of a mention is the surrounding sentences and texts of context of entity.",
                    "label": 0
                },
                {
                    "sent": "Is the attribute values of this content of this entity?",
                    "label": 1
                },
                {
                    "sent": "Then the second component is a disambiguation based on global coherence.",
                    "label": 0
                },
                {
                    "sent": "So obviously entities that appear together in one document usually tend to tend to related to each other.",
                    "label": 1
                },
                {
                    "sent": "Yeah, so based on this observation.",
                    "label": 0
                },
                {
                    "sent": "This component collectively disambiguates the annotations based on the relatedness among entities using the graph structure of the knowledge base, so.",
                    "label": 1
                },
                {
                    "sent": "That means the.",
                    "label": 0
                },
                {
                    "sent": "So entities in appear appearing in one document might be connected in the knowledge base.",
                    "label": 0
                },
                {
                    "sent": "So the first component together with the cross lingual grounding, grounding extraction, addressed the variation problem and 2nd component together with the graph structure extraction address.",
                    "label": 0
                },
                {
                    "sent": "The problem of ambiguity.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And also we built the cross lingual semantic annotation service based on what I should hear.",
                    "label": 1
                },
                {
                    "sent": "This is some input parameter.",
                    "label": 1
                },
                {
                    "sent": "Source can be the URL of web page or row text and then one is the language of the input source and land tour is the language of the output knowledge based resource NKB we can select.",
                    "label": 1
                },
                {
                    "sent": "DBPR, Wikipedia and output can be XML output.",
                    "label": 1
                },
                {
                    "sent": "One source is the raw text or the web page with inserted annotations.",
                    "label": 1
                },
                {
                    "sent": "When the source is the URL of a web page.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So I will show you.",
                    "label": 0
                },
                {
                    "sent": "Demo 1st.",
                    "label": 0
                },
                {
                    "sent": "First, I wear shoes are service for.",
                    "label": 0
                },
                {
                    "sent": "For annotating the raw text.",
                    "label": 0
                },
                {
                    "sent": "So here I the input is some.",
                    "label": 0
                },
                {
                    "sent": "Some sentence sentence is in in German and you will get the order.",
                    "label": 0
                },
                {
                    "sent": "DB Pedia resources, which are mentioned in the in the text.",
                    "label": 0
                },
                {
                    "sent": "So I can change the.",
                    "label": 0
                },
                {
                    "sent": "Like if I change change there.",
                    "label": 0
                },
                {
                    "sent": "Output language, for example, I change to Spanish, then you will get there.",
                    "label": 0
                },
                {
                    "sent": "Deeper resources, Spanish and also I can change the DB pedia to Vicky Pedia.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Stronic OK then you will get the resource Wikipedia resource.",
                    "label": 0
                },
                {
                    "sent": "2nd is to use it to annotate webpage.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "Here this is the.",
                    "label": 0
                },
                {
                    "sent": "Should be faster.",
                    "label": 0
                },
                {
                    "sent": "Exchange yeah.",
                    "label": 0
                },
                {
                    "sent": "OK so this is the URL.",
                    "label": 0
                },
                {
                    "sent": "Of the web page I want help.",
                    "label": 0
                },
                {
                    "sent": "I get the Internet is temporarily unavailable.",
                    "label": 0
                },
                {
                    "sent": "OK, here maybe I can show you the original webpage first.",
                    "label": 0
                },
                {
                    "sent": "Guess.",
                    "label": 0
                },
                {
                    "sent": "So this is the original.",
                    "label": 0
                },
                {
                    "sent": "Web page and after annotation so this.",
                    "label": 0
                },
                {
                    "sent": "These entities are annotated with the.",
                    "label": 0
                },
                {
                    "sent": "For example, if I.",
                    "label": 0
                },
                {
                    "sent": "Open the Obama.",
                    "label": 0
                },
                {
                    "sent": "So it's.",
                    "label": 0
                },
                {
                    "sent": "You were linked to the DB Pedia page.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "And here you can also change the.",
                    "label": 0
                },
                {
                    "sent": "Change the knowledge base.",
                    "label": 0
                },
                {
                    "sent": "Wikipedia.",
                    "label": 0
                },
                {
                    "sent": "So then you can link to the.",
                    "label": 0
                },
                {
                    "sent": "To the Wikipedia article of about Barack Obama.",
                    "label": 0
                },
                {
                    "sent": "Yeah, any language here.",
                    "label": 0
                },
                {
                    "sent": "We can also change the output language so you can link to, so if I change the language to Spanish then you will link to Spanish Wikipedia articles or DB pedia resource.",
                    "label": 0
                },
                {
                    "sent": "And also based on that we be at the the.",
                    "label": 0
                },
                {
                    "sent": "Graphic interface, so select one document here.",
                    "label": 0
                },
                {
                    "sent": "OK, I select output is German.",
                    "label": 0
                },
                {
                    "sent": "Yeah, and I.",
                    "label": 0
                },
                {
                    "sent": "Here's the other annotations and mentions and score.",
                    "label": 0
                },
                {
                    "sent": "And this pot pie charge show how many.",
                    "label": 0
                },
                {
                    "sent": "Annotations for each language we find.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Alright, my name is Andrea, so just just starting at KIT before I've been working closely with Katie and at UFC side in the render project and there we have developed an extension to Drupal module.",
                    "label": 0
                },
                {
                    "sent": "Drupal is a content management system is called diversity of their Drupal.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Attention.",
                    "label": 0
                },
                {
                    "sent": "Right, what does this trooper module do?",
                    "label": 0
                },
                {
                    "sent": "For example, if you're writing A blog post, you and you have a couple of related blog posts you would like to have which covered the same topic you would like to be directed to them, like somehow guided to them.",
                    "label": 0
                },
                {
                    "sent": "This is like it's basically.",
                    "label": 0
                },
                {
                    "sent": "Expert or exploratory search module so and this setting we cover different dimensions in particular topics in sentiment.",
                    "label": 0
                },
                {
                    "sent": "And the buyer, as we understand topics topic can also be a named entity in our case and or automatically generated topic.",
                    "label": 0
                },
                {
                    "sent": "And the content discovery is.",
                    "label": 1
                },
                {
                    "sent": "Basically, through the cover topics.",
                    "label": 0
                },
                {
                    "sent": "Right, give.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Do a short demo on this.",
                    "label": 0
                },
                {
                    "sent": "So I set this up.",
                    "label": 0
                },
                {
                    "sent": "With empty data, which is actually like, I just used few random examples from Discovery Channel, so don't be surprised.",
                    "label": 0
                },
                {
                    "sent": "So for example, like there's this kind of Fable, which goes around like the people are into searching for gold.",
                    "label": 0
                },
                {
                    "sent": "Let's have a look at this short.",
                    "label": 0
                },
                {
                    "sent": "Text on mining and so it's basically describes show which is coming up the next days on Discovery Channel.",
                    "label": 0
                },
                {
                    "sent": "So is the locations of TV shows electronic program guide EPG.",
                    "label": 0
                },
                {
                    "sent": "So if you you have you have a button on your TV remote control, so sort of just clicked EPG data and then you get a detailed description of what the show is about and here is about like.",
                    "label": 0
                },
                {
                    "sent": "So how this guys?",
                    "label": 0
                },
                {
                    "sent": "Find toy flakes of code and so for example, and now we extracted a couple of topics in here.",
                    "label": 0
                },
                {
                    "sent": "So for example, mining just quite relevant to searching for gold, and now we find actually some show we just had, and this is a related show which also covers.",
                    "label": 0
                },
                {
                    "sent": "Gold rush and so we have the topic Alaska here.",
                    "label": 0
                },
                {
                    "sent": "So just like we are interested now in Alaska for some reason and we navigate to Alaska.",
                    "label": 0
                },
                {
                    "sent": "Now we get shows which cover Alaska, just Alaska, the last Frontier and we select, for example, North America's next topic.",
                    "label": 0
                },
                {
                    "sent": "So he can basically switch through the topics which could be easily done via remote control and you don't have to type any text.",
                    "label": 0
                },
                {
                    "sent": "And for example, like here, we ended up with American Chopper.",
                    "label": 0
                },
                {
                    "sent": "If we just like.",
                    "label": 0
                },
                {
                    "sent": "Click on this and see what kind of topics are extracted.",
                    "label": 0
                },
                {
                    "sent": "Is neutral.",
                    "label": 0
                },
                {
                    "sent": "That's the sentiment extraction.",
                    "label": 0
                },
                {
                    "sent": "I maybe we can ask our colleagues from Chase Ivy, but there is.",
                    "label": 0
                },
                {
                    "sent": "There's a one show which is negative, which we will get to know, which is.",
                    "label": 0
                },
                {
                    "sent": "So this is about American chopper and how they tune the models, and so we're getting interested in motor sports.",
                    "label": 0
                },
                {
                    "sent": "And here we actually get Street outlaws, which is actually has a negative sentiment.",
                    "label": 0
                },
                {
                    "sent": "Which is.",
                    "label": 0
                },
                {
                    "sent": "And this is actually like also in this case, because it's just a few articles.",
                    "label": 0
                },
                {
                    "sent": "This is actually kind of a dead end.",
                    "label": 0
                },
                {
                    "sent": "The only show where we can navigate back to his American chopper.",
                    "label": 0
                },
                {
                    "sent": "But it's just demo.",
                    "label": 0
                },
                {
                    "sent": "We also have extracted tax here and usually you through a topic extraction.",
                    "label": 0
                },
                {
                    "sent": "You can also get like related, positive, negative and neutral articles.",
                    "label": 0
                },
                {
                    "sent": "Right, that's about it.",
                    "label": 0
                },
                {
                    "sent": "If you have any questions.",
                    "label": 0
                },
                {
                    "sent": "Yeah, the last 15.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That are less than that last minutes, just on what we plan for the first year.",
                    "label": 0
                },
                {
                    "sent": "The deliverables.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We have, so as I said before, we are mostly involved in work package one and four.",
                    "label": 0
                },
                {
                    "sent": "But this doesn't mean that.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We have a lot of deliverables and other work packages, so those are deliverables for actually that are due in three days.",
                    "label": 0
                },
                {
                    "sent": "So so at the end of the first month.",
                    "label": 0
                },
                {
                    "sent": "Yeah, but it's it's not that bad, but maybe maybe this deliverable, something that Sophie, like the former project of the She insisted to put this there and we're not very happy with that.",
                    "label": 0
                },
                {
                    "sent": "So if you have some, if you think you know some risks, what could go wrong in the project?",
                    "label": 0
                },
                {
                    "sent": "Let us know very soon, because then we can put it in this deliverable an But anyway, so we thought we covered this pretty well in the proposal, but apparently not.",
                    "label": 0
                },
                {
                    "sent": "Anyway, so those are the important deliverables.",
                    "label": 0
                },
                {
                    "sent": "The first one, so I will go through them and.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The first step, the first one is this prototype of meta data model.",
                    "label": 0
                },
                {
                    "sent": "I think the most important thing is here to see what we already have, like from the exact project, how we their structure, our data and of course from Vista TV.",
                    "label": 0
                },
                {
                    "sent": "What meta data we can get from there and how it's represented and how we can integrate both of that.",
                    "label": 0
                },
                {
                    "sent": "And then of course extend this considering the requirements of our use cases in slime.",
                    "label": 1
                },
                {
                    "sent": "And yeah, we already listed a couple of candidates for standards.",
                    "label": 1
                },
                {
                    "sent": "We of course we want to reuse standards as much as possible, but.",
                    "label": 0
                },
                {
                    "sent": "Yeah we have to see this so we don't have a plan for this at all.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Then deliver rebel three point 3.1.",
                    "label": 0
                },
                {
                    "sent": "So this is something that.",
                    "label": 0
                },
                {
                    "sent": "Related to this, what was just presented the cross lingual semantic annotation?",
                    "label": 0
                },
                {
                    "sent": "So what you just saw with the website that could annotate entities on this website.",
                    "label": 0
                },
                {
                    "sent": "Here the goal is not only annotate text from websites, but also text that comes from different modalities like speech and images, and we don't have experience with that.",
                    "label": 1
                },
                {
                    "sent": "We don't know if it works, if it's different, how the performance will be and so on.",
                    "label": 0
                },
                {
                    "sent": "So this is something we want to do in this deliverable.",
                    "label": 0
                },
                {
                    "sent": "To do this, of course, we also need the links between the modalities and between the languages like we already have this in the X like case for the different languages, yeah.",
                    "label": 0
                },
                {
                    "sent": "Yeah, probably this would is always our first guest, but of course we could think about other knowledge bases that are more suitable for the use cases.",
                    "label": 0
                },
                {
                    "sent": "So so.",
                    "label": 0
                },
                {
                    "sent": "But I guess we're always linking to DB Pedia plus something.",
                    "label": 0
                },
                {
                    "sent": "I've called for his OSD pedia.",
                    "label": 0
                },
                {
                    "sent": "Kind of data we have and what kind of yes, yeah yeah.",
                    "label": 0
                },
                {
                    "sent": "It's it's very much use case driven.",
                    "label": 0
                },
                {
                    "sent": "Media there are.",
                    "label": 0
                },
                {
                    "sent": "Music yeah yeah maybe yeah.",
                    "label": 0
                },
                {
                    "sent": "They are maybe companies or I don't know.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then this is, I think this is the most interesting one.",
                    "label": 0
                },
                {
                    "sent": "This is the statistical content linking that we also just showed with the text.",
                    "label": 0
                },
                {
                    "sent": "So the text similarity with the cross lingual USA or Canonical correlation analysis.",
                    "label": 0
                },
                {
                    "sent": "So the ideas you basically input like what we want to have in the end is a function where you input one.",
                    "label": 0
                },
                {
                    "sent": "So far we input one text in any language and another text in any language.",
                    "label": 0
                },
                {
                    "sent": "And we get some number out of it, telling you how similar the content of those two texts are in now what we need here is something where you put in any.",
                    "label": 0
                },
                {
                    "sent": "The multimedia item like video, whatever, audio, anything put in it and another one and you could be text, the other one and you get a similarity score.",
                    "label": 0
                },
                {
                    "sent": "Even across languages.",
                    "label": 0
                },
                {
                    "sent": "This is something that is probably very the hardest task in the most interesting as well, and how we want to do this is basically the same approach as we did this for text.",
                    "label": 0
                },
                {
                    "sent": "So what you need to do is collect a parallel corpus, but so far the parallel corpus was just a list of.",
                    "label": 0
                },
                {
                    "sent": "Text documents that were aligned.",
                    "label": 0
                },
                {
                    "sent": "That means translated, for example.",
                    "label": 0
                },
                {
                    "sent": "So we had the English and the German text for example.",
                    "label": 0
                },
                {
                    "sent": "Now we need this.",
                    "label": 0
                },
                {
                    "sent": "We need such a multimedia aligned corpus and this is of course something different.",
                    "label": 0
                },
                {
                    "sent": "I mean, there are some out there, but we don't have a lot of experience.",
                    "label": 0
                },
                {
                    "sent": "And then there's of course the big question.",
                    "label": 0
                },
                {
                    "sent": "How to represent this?",
                    "label": 0
                },
                {
                    "sent": "I mean, so far we've always like a big vector.",
                    "label": 0
                },
                {
                    "sent": "Is this enough?",
                    "label": 0
                },
                {
                    "sent": "Does this work?",
                    "label": 0
                },
                {
                    "sent": "Let's see so.",
                    "label": 0
                },
                {
                    "sent": "And what should be in this vector like?",
                    "label": 0
                },
                {
                    "sent": "Having the.",
                    "label": 0
                },
                {
                    "sent": "A million sway ways of representing video as a vector, I guess.",
                    "label": 0
                },
                {
                    "sent": "So this is, I think this is the most interesting and deliverable that we have in the first year.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I'm.",
                    "label": 0
                },
                {
                    "sent": "And then this is the final deliverable, which builds very much on top of this functionality of the deliverable before that means.",
                    "label": 0
                },
                {
                    "sent": "We are.",
                    "label": 0
                },
                {
                    "sent": "We have some kind of query which could be any multilingual multimedia item.",
                    "label": 0
                },
                {
                    "sent": "I still don't have a good word for this multilingual multimedia item, so could be text video in any languages, whatever.",
                    "label": 0
                },
                {
                    "sent": "We have this as a search query and we want to get something similar that could be text.",
                    "label": 0
                },
                {
                    "sent": "Could be a video appear, anything other so and the search could be explicit like someone typing a keyword or in putting a text, but it could also be implicit like in the so two case where someone is watching a TV show and we just take this as a query to show him related articles from Wikipedia or from maybe even tweets or whatever.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "So yeah, and it's probably built on top of this.",
                    "label": 0
                },
                {
                    "sent": "On this functionality and then of course, once we have something like semantic search, we can also do stuff that we just saw in this in the first semantic search prototype or in this Drupal extension where we can then browse and.",
                    "label": 0
                },
                {
                    "sent": "Find related topics and so on.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so that's it from the khits side.",
                    "label": 0
                }
            ]
        }
    }
}