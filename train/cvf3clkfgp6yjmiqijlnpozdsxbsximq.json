{
    "id": "cvf3clkfgp6yjmiqijlnpozdsxbsximq",
    "title": "Approximate inference for continuous time Markov processes",
    "info": {
        "author": [
            "Manfred Opper, Department of Artificial Intelligence, TU Berlin"
        ],
        "published": "Sept. 17, 2008",
        "recorded": "May 2008",
        "category": [
            "Top->Computer Science->Machine Learning->Markov Processes"
        ]
    },
    "url": "http://videolectures.net/aispds08_opper_aict/",
    "segmentation": [
        [
            "Talk of today's morning session.",
            "She's by Manfred Opper.",
            "Let's go on approximate inference for continuous time.",
            "Markov process is also thank you very much, Neal.",
            "The organizers to the organizer for inviting me, but some of them are actually on as collaborators here so well, they can ask you.",
            "They can answer you a lot of questions, probably that you might have, which I can't answer, so this will be about approximate inference.",
            "For continuous time Markov processes in the type of things that we have in mind is."
        ],
        [
            "This is an example, so we have a time serious with actually a bivariate one and it comes from a simple.",
            "Prey predator models.",
            "So the observations would be integer valued quantities with a little bit of noise, and there's an underlying continuous time process, but we don't observe the process.",
            "Actually we see only these these observations as discrete time points, and the problem would be."
        ],
        [
            "Assuming specific model which is here so there's two species and they multiply.",
            "I don't want to go through the details depending on how many guys are already there.",
            "Some of them die, some of them eat each others and multiply, and things like that.",
            "So based on such such a type of model, we would like to infer what are these rate constants based on the measurements that we make.",
            "So this model has unknown rate constants.",
            "Can we predict them?",
            "And we would also like to understand maybe."
        ],
        [
            "What happened in between those observations where we haven't seen things, so we'd like to predict the state, and we would like to predict what are model parameters.",
            "So this is 1."
        ],
        [
            "Type of thing."
        ],
        [
            "The other type of well that actually was the underlying true.",
            "Sample path that generated those data.",
            "So you see this little jumps, so it's a Markov jump process in this case and."
        ],
        [
            "Another example would be something like that, so again we have here at time and we have some state and that state evolves again with some dynamics that we don't know.",
            "But we make only certain observations in these areas.",
            "We don't have observations, and in this case we try to make a prediction and give some uncertainty to that prediction.",
            "In this case we used a Gaussian process regression type.",
            "Of modeling, and this is actually a bad prediction if you know what the underlying model was.",
            "It predicts that if you far away from these measurements, you would have a huge uncertainty and your prediction should go to zero.",
            "But this type of prediction had actually completely ignored the underlying."
        ],
        [
            "Modeling the underlying model was something like that, so it was a emotion.",
            "In a double well potential.",
            "So you see what happened.",
            "There was a little particle that was sort of randomly kicked by white noise.",
            "Here.",
            "This is white noise and there's a drift term.",
            "The drift is the derivative of this potential, so it's kicked here.",
            "Then it make some measurements there, and at some time point it moves to the other side of the potential and then also kicked is kicked a bit and you observe it.",
            "And I think if you don't observe it for awhile it will still stay there for quite awhile.",
            "So the prediction that your uncertainty is getting bigger and bigger was.",
            "Not a good thing knowing that the underlying model was that, so we would like to use the fact that we know something like this, a model which is a stochastic differential equation to make a good prediction.",
            "So in this case, sort of the optimal prediction."
        ],
        [
            "Obtained.",
            "My Monte Carlo method was actually something like that, so this is the prediction of the expected state of the system overtime and that is the corresponding uncertainty about our about the measurement of the state.",
            "So you see anytime when we have a little bit of information by this by this data point you see there's a reduction in uncertainty and you see this thing.",
            "Is not blowing up the uncertainty, so this is the kind of thing that we want to achieve and the question is how?",
            "How can we do that?"
        ],
        [
            "So well, that was.",
            "A possible underlying sample path that might have generated the data.",
            "So in this case it is very rough function.",
            "It's not one of these little piecewise constant paths.",
            "In this case it is a salute.",
            "It's a sample path for stochastic differential equation."
        ],
        [
            "So what I would like to do in this talk is look at some of the approximations that we've been working on.",
            "So first of all, I'd like to define a little bit more mathematically.",
            "What I mean with these models that I've discussed this simple Markov jump process and and diffusion process.",
            "Then I would like to discuss a variational approach to Bayesian inference, inference and parameter estimation for that model.",
            "And if you do sort of a full variation, you might end up.",
            "With the exact inference and, but you might also get kind of approximations for that, and then there will be also if I have time to speak about a non variational type of approximation based on assuming small fluctuations.",
            "Right, so well he can ask me questions anytime and."
        ],
        [
            "Right, so the two types of models that we were looking at something is a continuous time Markov process.",
            "So we're thinking about here assistant with discrete states X and the probability of having a transition from one state X to another state X prime over a small time interval of size Delta T scales like scales in such a way that means with high probability.",
            "Nothing is happening, so this is a chronic Delta, so with probability almost one state, the new state is equal to the old state, but there is a rate function F of X prime.",
            "And X that tells you sort of with with which probability you're moving into another state.",
            "So you have this small Delta T scaling for these types of processes, discrete jump processes.",
            "So with a linear probability that grows linear with Delta T, you go somewhere else and the other type of models that we're interested in is diffusion processes.",
            "There are described by stochastic differential equations, so the state is now changing.",
            "Continuously, the change of the state is proportional to the time interval, Delta T and a drift term.",
            "So this is the deterministic part of the of the motion, and then there will be a diffusion part sort of driven by white noise.",
            "And in general it might be dependent on this state as well.",
            "And sort of my humble understanding of stochastic differential equations is sort of if I want to simulate them, I do it in the following way.",
            "I discretize this object in a very simple Euler type of way and say, well, the change of the state Delta X is proportional to something linearly in Delta T and something which goes with the with the square root of Delta T. White noise part, and then I get the correct scaling for small Delta T so you can understand it as a kind of limit of this very simple discrete time thing."
        ],
        [
            "OK, So what we want to do is the following.",
            "We want to solve the problem of having noisy observations of that state X so noisy observations at certain discrete time steps, T one to 10.",
            "So we don't observe the full trajectory.",
            "We observe it only at certain discrete times, and that's what we observe and we think we have a likelihood function given the state X at time T. I we know what's the probability of of the wise, what's the probability density of the observations.",
            "So this is given to us or it might contain parameters that we also want to estimate, and so the problem would be would like to estimate XT and give uncertainty of the prediction and we would like to also estimate unknown system parameters Theta that would be contained in the rate functions or in the drift or diffusion terms.",
            "So in an ideal world that would be.",
            "The type of stuff that we would like to do.",
            "The question is."
        ],
        [
            "Yeah, so well, the solution of course is.",
            "Yeah, not so complicated, at least in principle.",
            "So the optimal prediction of the path you would just just calculate the conditional distribution given the observation.",
            "What is the probability of it?",
            "The possible paths of the state?",
            "Now we're not interested in.",
            "Instead of saying what happened at time T, we're interested in the entire measure probability measure over paths so well, if we want to just make an optimal prediction.",
            "So we could probably do.",
            "Conditional expectation of the path MXT given the observations Y, and that should be based on the conditional or posterior distribution of the states X given the observations.",
            "And this is just strange way of writing down Bayes rule, so this is the prior distribution over paths.",
            "Coming from the underlying stochastic system, the stochastic differential equation of the jump process.",
            "This is the likelihood of the observations given the state.",
            "Zed is a normalizer and this is just posterior over prior is equal to likelihood within that constant.",
            "So this is what we should use for making optimal predictions.",
            "But of course this is a very sort of not so nice object this posterior and also the prior is not something that we can write down sort of explicitly because it's a prior overpass and it's a posterior over paths that we that we are discussing.",
            "Right, so this is a problem is just a thing over paths so we could use this guy for making if we could handle it we could make optimal predictions, but we can also do parameter estimations.",
            "For instance we would have this probability of the data given the parameters.",
            "We could do a maximum likelihood estimation over using.",
            "We could maximize this with respect to parameters if we could Q compute those this partition function and we could do a Bayesian estimation if we were using, for instance a prior over thetas.",
            "So slightly more complicated.",
            "So the problem is we should be able to deal with this guy as well.",
            "So again."
        ],
        [
            "Why's it not so see why is it not so easy?",
            "They might just argue you know people with the machine learning background so they have looked probably into graphical models with all kinds of loops and stuff like that and and well, this is a very very simple system.",
            "It doesn't have any loops, it's it's mark curve and you have some observation, so it's a hidden Markov model.",
            "So why?",
            "Why all this fuss about it?",
            "It's a very simple system that people have studied, probably for many years, and I think the only thing that makes it so.",
            "Well, a bit nastier is it's just a continuous time thing, and the things that we are used to like forward and backward algorithms to be well just partial differential equations that we have to solve.",
            "So it's a bit a bit more complex so conceptually simple, but it involves partial differential equations.",
            "Well, we could also resort to Monte Carlo techniques, and that's also something that we've done, but it requires sampling over sort of finely discretized paths, and that might also take.",
            "Take some time to get convergence and if we think about computing the Bayesian evidence or the free energy, as it's often called well, it's also a bit nontrivial.",
            "It might need many temperatures for the underlying Montecarlo process.",
            "And also a Gibbs sampler is non trivial, which we probably will learn about this today from Andrew and naive Gibbs.",
            "Sampling doesn't work and explain it much better than I could."
        ],
        [
            "Right, so one way of looking at this problem is, well, we know that the posterior when I say posterior, the posterior press process over paths is also a mark of process.",
            "And so we could think of sort of trying to find out how this Markov process looks like.",
            "For instance this jump process.",
            "It may, we might wish to compute the rate function.",
            "Having seen the data, what's the new rate function?",
            "Or if we look at a diffusion problem, we might wish to understand what this new drift term is.",
            "Actually, the diffusion is not changed, but the drift is changed.",
            "We can think of this new drift is adrift.",
            "That takes the data into account because you know the path is coming and there's a data point, and we know that's sort of the data point has to be.",
            "The path must be sort of generated in such a way that the the data point is.",
            "Rather likely so so there has to be a drift that guides the path of the diffusion process close to the data point, and so we would like to see what this G function is.",
            "And can we find out can we do at least an approximate computation of this underlying posterior drift function?",
            "So one idea is just to resort to."
        ],
        [
            "Well OK this is 1 example.",
            "Let's say there's a simple a simple a single observation of a vina process, so it's a process that doesn't have a drift.",
            "But now observe it, I observe it at some time T here and I make the observation it well, it has the value 0 at this end point.",
            "So this is my observation and I'm sure that the observation is noise free.",
            "So I'm exactly sure it went there.",
            "So how does the posterior look like based on this type of information?",
            "So the Wiener process starts at 0 and I observe it at zero.",
            "Also at this time T and then you can show.",
            "That the drift so of the posterior is given by this expression, and you see if I if I reach with time.",
            "If I reach this final time T then X has to be sure and has has to be has to go to zero to avoid this.",
            "To make this from diverging so this really attracts the this vina process towards 0 and it has to come back and so the posterior process with this type of thing is known as the Brownian Bridge.",
            "So you can yes.",
            "You say you posterior process.",
            "The diffusion is the same, the diffusion is the same.",
            "Yes, if you take the if you take one observation or finite number of observation, given that number one yes.",
            "Doesn't it seem?",
            "That that you sort of get in.",
            "Then the observations are completely guiding the dynamics.",
            "You would expect that there's a diffusion goes to 0 or no, no, no.",
            "These observations are really point observation, so they don't tell you anything about changes in time.",
            "They just say where was the process at time T, so it doesn't tell you anything about about a Fusion.",
            "So if you make the number of observations.",
            "It seems to be sort of observed.",
            "It doesn't change the diffusion to my to my knowledge.",
            "I don't know if this limit is going to be something nice, but at least for every finite set of observation, the diffusion is not is not changed."
        ],
        [
            "So.",
            "Our idea was to look at at to use a method that has been used in machine learning quite a lot and assist.",
            "It's known as the variational approximation so you have a posterior process that is or a posterior distribution that is not so easy to to handle to deal with and you like to introduce a family of simpler distributions, like Gaussians that we can sort of deal with and optimize them.",
            "So in such a way that they sort of resemble.",
            "The not so nice distribution in.",
            "The best way and measuring sort of the similarities between distributions.",
            "Yeah, we measured them using the cool Buck Libra divergent.",
            "So the kullback Leiber divergent, or the relative entropy, is a nonsymmetric dissimilarity measure between distributions.",
            "So we introduce.",
            "So this is the posterior process data.",
            "The State X and what I mean by that is really X is.",
            "The whole path over States and we tried to play with simpler probability measures Q and we make we try to make them as close as possible to P using this distance measure innocence between distributions and an equivalent formulation is because this posterior contains a nasty term which is the evidence of the data.",
            "The this P of Y given Theta.",
            "So if we subtract that from the kullback, Leiber divergent, then usually this is something this guy is called.",
            "The variational Free energy is something that we can usually compute.",
            "And so we wish to find distributions Q which minimize this variational free energy.",
            "So if we do a full variation in the space of all probability distributions.",
            "So the best Q would be the true posterior.",
            "And if we use a sort of simpler approximating family, we might get, well, a good approximation by minimizing this functional with respect to this family of approximating distributions.",
            "And if I write down the posterior as a product of prior and likelihood, I will find out that the free energy is becoming.",
            "There's a term which is the kullback Leiber divergent between Q and the prior distribution, and a term that comes from the data from the likelihood.",
            "And I also see by the fact that this guy is non negative.",
            "Let the free energy gives.",
            "An upper bound on the negative logarithm of the probability of the data given the parameters, so I can use this also as a proxy for, you know, minimizing this object with respect to parameters in a maximum likelihood way.",
            "So rather than minimizing this, which I cannot compute, I minimize this guy with respect to parameters, so that's that solves two things I can do sort of approximate inference about state paths, and I can do.",
            "Approximate inference also about parameters in this approach, so this has been used."
        ],
        [
            "Well, those are you with a statistical physics background.",
            "There's a different way, so if have Gibbs measures and was a Hamiltonian, H Another approximating Gibbs measure with the Hamiltonian function age nought.",
            "Then the free energy is you can actually show the free energy is becoming.",
            "Set of 1st order perturbation theory.",
            "This this variational free energy.",
            "If you believe that the difference between this and this is small and you do a first order perturbation theory in the difference, then you end up also with the variational free energy and.",
            "Open formulat"
        ],
        [
            "Chen I don't want."
        ],
        [
            "OK, so that you can use this variational formulation also to get sort of an approximate full Bayesian inference by.",
            "Sort of saying what is the best posterior approximate posterior over the parameters within this formulation, and then you can use also the free energy E to the minus free energy would be something like the probability of the data given the parameters.",
            "So if you multiply it by a prior and normalize it, that can serve also as an approximation to the posterior over parameters.",
            "So this is the program and that has been used.",
            "Extensively in the area of machine learning and sort of our interest was can we sort of carry the limit.",
            "Of Delta T of small times to zero anhava continuum time.",
            "Continuous time formulation of that so that."
        ],
        [
            "Was.",
            "One of the things that we wanted to do so we can try and make this rigorous, but I think it's it's much easier to sort of look at it as a limit of a discrete time modeling, so we have to compute cubuk Libra divergences between Markov processes and one way of doing it.",
            "If we discretize in time, then we would see of course.",
            "If we have the logs of probabilities, Overpass can always be written.",
            "These probability overpass using the Markov property as a product of the transition probabilities and at the end of the day, what you obtain is kind of an average of the kullback.",
            "Leiber divergent between transition probabilities, and so the only thing you have to do is you use your mark process and find out what is the short time behavior for these transition probabilities.",
            "And that's something that you can you can do for these Markov jump processes, and you can do for diffusions.",
            "So you plug this in and go to the limit where the time step Delta T is small, and then you find out that the sum over these different times is becoming an integral, and that is sort of a non rigorous heuristic type of derivation of something that you also can get in a more rigorous."
        ],
        [
            "Play.",
            "So you need the short time the kullback Leiber divergences between the transition probability of the Markov process for short terms."
        ],
        [
            "Show times, so here are the two classes of processes that we looked at.",
            "Sort of.",
            "This simple mark of John processes.",
            "We've already written down what these short time behavior is, and for Gaussian for diffusion processes, we know that for short times the probability the transition probability is locali a Gaussian, so we know the change in the state has a mean which is given by the drift.",
            "And there is also a covariance given by this diffusion term, so this is the short time behavior of that transition probability.",
            "And if we use it inside of this cool book library computation, then."
        ],
        [
            "For instance, you get the following thing.",
            "So the kullback Leiber divergance between one probability measure and another one that correspond to diffusion processes with the same diffusion is essentially given by the expected L2 distance in a sense between the drift corresponding to Q and the drift corresponding to P. So it's essentially how different are two 2 measures.",
            "Well, it's more or less the square between.",
            "The two drifts, averaged over the marginal distribution at time T of.",
            "Of the process queue, so that looks not so bad, right?",
            "I mean, the only thing you have to know what is the drift?",
            "What are the two drifts of the approximating processes?",
            "And you have to know what is the marginal distribution, and then you're able to compute this callback live.",
            "Learn it when you can compute it.",
            "You can use it in a variational method, so that's all I mean.",
            "OK, this formula is already known.",
            "It's been known before, and of course, completely independently."
        ],
        [
            "Rediscovered by asking?",
            "So you can do the same thing for Mark."
        ],
        [
            "Jump processes as well."
        ],
        [
            "So what do we have to do right?",
            "I mean, let's say just to re discover something that is also known in the literature for quite awhile, so we should be able to re discover what the exact inference is doing by doing the full variation, just to see that it's not so not so simple.",
            "So as I told you, you have to do the two drifts squared, averaged over the marginal distribution and plug this in so it's a functional.",
            "Now you do the variation with respect to G, which is the G is the posterior drift.",
            "That's the drift that has seen the data.",
            "So the only problem is that the drift G in the marginal distribution sort of there are connected because the marginal distribution and drift are related by the forward equation which is known in for diffusions as the Fokker Planck equation or the master equation for the jump processes.",
            "So you have to do the variation, but you have to know that.",
            "Q knows G and they're related.",
            "By the Fokker Planck equation.",
            "So you do the variation and you use as an extra constraint.",
            "This this Fokker Planck equation."
        ],
        [
            "And so if you do that, you can do it using a LaGrange multiplier.",
            "Plug in the dynamics.",
            "This Fokker Planck equation and I LaGrange function which is function of state in time.",
            "And then you do a full variation with respect to the posterior drift and with respect to this module distribution.",
            "So essentially this was all just taken from from from a derivation of.",
            "A belief propagation using beta free energy, so it's just a copy of the same method you do.",
            "You get your cool Mark Leiber divergent.",
            "You do a variation and introduce LaGrange multiplier for all the consistency conditions that you have.",
            "The only difference is just the continuous time continuous state.",
            "So you find out that the drift that has seen the data is equal to the drift that doesn't know that data.",
            "And something that is proportional to the gradient of this LaGrange function that's one part of it."
        ],
        [
            "And then you find also that the LaGrange function obeys.",
            "Suitably transformed a backward equation.",
            "So in some sense you discover something you might expect.",
            "There's a backward forward algorithm.",
            "The backward algorithm tells you how to compute the forward drift, and that's what you have to do.",
            "So essentially the task is you solve a backward equation backwards in time.",
            "That gives you the drift and where are the data.",
            "The data actually come into jump conditions for this backward equation.",
            "So anytime you see your data point makes a little jump and then you integrate it without jumps further and and so on.",
            "So this is just what you have to do.",
            "One backward sweep, but unfortunately you have to solve a PDE for doing that and that is sort of not so nice and these these equations are known as the the Kushner Stratonovich in part, do equations.",
            "So they're known for quite awhile.",
            "Times independently, I don't know exactly says.",
            "Is there a Cold War thing going on here?",
            "I don't know.",
            "Yeah, I don't know Ronnie, you know about the history.",
            "Discover 1958 first published this paper pardon.",
            "Paper on this matter was 98 OK, I see.",
            "In for diffusion processes.",
            "Model partition theory was OK, OK good, so I don't have to the best.",
            "Alright, so we are not independent OK?",
            "Go to the previous page.",
            "So."
        ],
        [
            "As an example, now this this this this."
        ],
        [
            "That noise for your observation case.",
            "So what you have to do is you have to solve a backward equation.",
            "The data point is at the end, so you just get one.",
            "So this is this Delta function and you solve it and you get the result that I showed you before, so it's not a big deal.",
            "So now we can use that different derivation using the variational method."
        ],
        [
            "Also to come up with approximations.",
            "So the idea is in the case of diffusion process you use simpler methods.",
            "So you would use Gaussian measures and Gaussians.",
            "Well we can do everything with Gaussians and people have also used them before, but not as extensively as factorizing variational distributions in the area of machine learning.",
            "So the idea is now using a Gaussian measure.",
            "So you can say this is induced by a linear posterior stochastic differential equations.",
            "So here is a linear.",
            "It's linear in the drift is linear in the state, and there is also a bias term here in these things are time dependent, so this we use this type of stochastic differential equation to approximate the true posterior process and the functions A&B would be the variational functions to be optimized.",
            "So that's the idea.",
            "Is these stochastic differential equations would induce a measure over path which is a Gaussian one, and we would calculate the global kleiber divergance between the true posterior and the measure introduced induced by this one and use this this as an approximation.",
            "So there's one important thing this can be done only if the diffusion term is independent of the state, so it would not be.",
            "Applicable to state dependent noise because the state dependent noise, I cannot get a Gaussian measure and the diffusions have to be the same in the kullback Leiber divergent because otherwise the kullback Leiber divergences becoming infinite.",
            "So that is a bit of a problem.",
            "So now the interesting thing is, since we have a Gaussian measure, linear stochastic differential equation with a linear drift and a Gaussian measure, so we know that now the marginal distribution is a Gaussian and we don't have to write down ifakara complicated Fokker Planck equation, which makes things worse.",
            "We only have to deal with the mean at time T and the covariance of the state at time T. So these are the only parameters they completely determine.",
            "The marginal distribution.",
            "So rather than having to deal with arbitrary marginal distributions, we have to deal with Gaussian ones which are completely determined by mean and covariance.",
            "Now, rather than having PD is we are, we end up with systems of ODS and that makes of course the treatment simpler.",
            "So we end up with systems of nonlinear ODS, and I'm not giving the details, but that is sort of the simplification.",
            "We don't have to solve the PDE's we have to solve ODS.",
            "Nonlinear.",
            "Let me see.",
            "Well, I think the nonlinearity comes in when we we have when we work we introduce LaGrange functions again communicate to this condition and we can eliminate.",
            "You know, we get a set of differential equations and we can eliminate certain quantities, and then the rest of it becomes nonlinear.",
            "So you're right, these ones are.",
            "Linear.",
            "Look for NVIDIA pardon yes, yes yes, the problem.",
            "So we get.",
            "Of course we have to.",
            "This is the dynamics of mean and covariance.",
            "Then we get LaGrange functions also for this and for that.",
            "And we have to do a variation with respect to 2A and B and that ends up becoming non."
        ],
        [
            "Near right, so as an example, is emotion in a double."
        ],
        [
            "The potential that I have mentioned and this is now a variational, the variational result solving these ordinary differential equations compared to a result from Monte Carlo sampling where we do a sampling of the posterior and you see so this the green one is the variational approximation, the blue one is sort of the exact yes.",
            "I mean is it while it looks very bars going back up for the possibility that it jumps back it one way, John, he isn't this possibility that that jumps back the opposite direction.",
            "Yes, yes, but not with the parameters that we've chosen and in this in this case, and so there's a typical thing here that happens in many variational approximation.",
            "So the variances on is under estimated, but the mean is.",
            "Assumed to be no, no pun.",
            "The drift in this case is known, yes, yes, but we can also do."
        ],
        [
            "Sort of estimations on parameters.",
            "So in this case we were doing estimation on the diffusion constant, introducing a prior over diffusions, and this is again the variational inference in comparison with Monte Carlo inference.",
            "So I mean it's not perfect, but you see it seems like the mean and roughly also the uncertainty are sort of preserved in in the approx."
        ],
        [
            "Timation and of course I mean it wouldn't be science if I wouldn't show you an example where it doesn't work so well.",
            "And of course you can easily understand why it doesn't work so well here.",
            "This is a case where really the posterior is very far from a Gaussian measure and so you see, this is a case where we have large observation noise, so the observations don't really tell you exactly where the state don't tell you much about whether state is.",
            "So if you look, for instance at the marginal at a certain time.",
            "It would be a Tri modal distribution and so we try to model it with essentially something that is unimodal marginally, and so we're not even getting the correct transition.",
            "And also, you know this is no no good approximation for the variance, and it's clear.",
            "So we try to approximate something which is non Gaussian, highly non Gaussian by by something which is much more concentrated."
        ],
        [
            "Yeah, so it has its limits of course, and so we can also go to.",
            "Well, of course we were planning to go to very high dimensionality at the moment.",
            "We do three dimension, so this is a this is designed for you this.",
            "So this is a noisy Lauren system, so I think the blue one is the true is the true underlying path and the red one is is the prediction so we don't make a comparison here with the exact model."
        ],
        [
            "Other results, but we show we show these are the three coordinates and we make comparison with other types of approximation.",
            "So that seems to be beyond unscented Kalman.",
            "Smoother result.",
            "Again, Blue is exact and so the dashed line is the prediction of."
        ],
        [
            "Yes, the prediction."
        ],
        [
            "This is a regression, and that's sort of that's what we got.",
            "It looks sort of more reasonable.",
            "For the prediction and also for the for the the error bar."
        ],
        [
            "Right, I haven't spoken about Markov jump processes.",
            "Just briefly.",
            "Of course, we can't approximate them with a Gaussian, but if we have a multivariate problem, we can still say, well, a reasonable approximation is to factorize the measure over paths into a product of measures where each you know where each measure is only.",
            "With a with a single coordinate, right?",
            "So we're not doing any factorization in time.",
            "Of course, we preserve temporal correlations, but we factorize the measure in the different components and use that as an approximation that is known as mean field or factorizing variational approximation and sort of what we gain is the exact system backward equation that we would have to solve is linear odies in South to the D variables, where X is the number of state D is.",
            "The dimensionality of the problem and we would get away with S * D. Is a complexity reduction, so we can do that.",
            "Yeah, I don't want to give any."
        ],
        [
            "I don't have enough time, so one of the problems of course that we're facing at the moment is.",
            "When we go back to stochastic differential equations, we can't deal with with state dependent diffusion terms, so D of X is not possible because the kullback Leiber divergent between a Gaussian and the true posterior would be infinite.",
            "In such a case.",
            "So we would have to do other types of things we might think for instance, and transforming the state variable, but that is usually not possible if you run if you.",
            "Deal with multivariate problems.",
            "Those usually don't exist.",
            "These transformations for any interesting case.",
            "So at the moment we help ourselves with."
        ],
        [
            "The types of approximations, so we go back to the exact solution and the exact solution.",
            "For instance, the backward equation.",
            "We go back to the PDE that we would have to solve, and in the case where we say that the diffusion term is relatively small.",
            "So what we do formally we go from a diffusion to epsilon time diffusion in work with small epsilons.",
            "Then you can get kind of a Gaussian shape scaling.",
            "Form of the solution to that key.",
            "KSP equation.",
            "What we do is just we solve this.",
            "We solve the PDE with this type of approximation backwards in one sweep, and then we get an approximation to the posterior drift that can also be computed for the case of multiplicative noise, but it's not a variational approximation, just using this type of unsers within within the.",
            "Pardon, this is a small that's a small noise kind of thing and and the application area would be something like that."
        ],
        [
            "For instance, it would be applicable to chemical kinetics or these type of prey predator system where sort of the average number of individuals or molecules involved in the problem is large compared sort of large, so that the usually the fluctuations are small and so you can treat well.",
            "This is originally a mark of jump process, but you can come up with a diffusion approximation for it in the limit where we have large number of.",
            "Species and so so jumps are relatively small compared to that, and if you look at at this problem just from far away, it looks more or less like a diffusion path, and so you can approximate it by a stochastic differential equation.",
            "And again you can make this weak noise assumption on top of it and you get something salute."
        ],
        [
            "Things that don't look so bad.",
            "So for instance, this is.",
            "We repeat this experiment with many new random realizations and you see so our approximation would be that there is a Gaussian, and so this is not a Bayesian type of thing.",
            "This is a frequentist type of, you know, we see is our mean prediction over the uncertainty that we get really reflecting the true true.",
            "So this is kind of a calibration experiment and.",
            "So let's say if you are."
        ],
        [
            "In this region, maybe the Gaussian assumption is not so bad.",
            "So what we get out of this sort of approximate weak noise inference seems to be reasonable.",
            "But of course, if you're here in the area where things die out, of course, sort of Gaussian assumptions are probably bad, but if you're in that area, then and it's OK. And on top of it, So what we do now is essentially we use this week noise approximation and it's if it's weak noise.",
            "Everything looks more or less Kelsey and you can also calculate free energies for that case and use."
        ],
        [
            "System for doing Peru."
        ],
        [
            "Meter estimation and they also look reasonably well, so you make a prediction error for OP.",
            "Four parameters in that process and sort of these are comparisons between estimates and and truth, so it seems like maximum likelihood is doing fairly well in that case.",
            "And also the sort of the curvature of the likelihood gives you more or less the uncertainty, so it calibrates well, at least in the week noise limit, but it's not a variational type of thing.",
            "And we have to work on that.",
            "I think this is a good point probably to stop.",
            "So we."
        ],
        [
            "Something that we're playing now with and hope to get something ready for NIPS.",
            "Of course, so less transparency is systems where we have a hybrid kind of structure.",
            "We have something which is continuous state, so it's like a Norristown Uhlenbeck process.",
            "But the noise is no longer white white noise, but the noise is is a flip is a random, is a Markov jump processes that flips between plus and minus one with a certain rate.",
            "So this is a.",
            "This is driven by a Markov process, and so we want to see if we can do inference on what's going on here.",
            "What's the posterior over these flip variables and.",
            "Yeah, so this problem is simple enough so you can solve the underlying stochastic the underlying partial differential equation and we compare it with a variational method so this zed is no longer Markovian.",
            "After I've seen the observation, so the posterior is no longer Markovian, but the whole system X end together with said is Markovian in the joint variables and you can play with that.",
            "And yeah, I think just.",
            "I'd rather stop now.",
            "Thank you very much.",
            "I guess in the spiritual sense of lady purses you could look at dynamics, which has both drift and diffusion as well as jump components.",
            "Yes?",
            "Well the question is we would have to write down kullback Leiber divergent for that case, and I would assume even that's probably known in the literature how they look like, and we would have to see if we could do something.",
            "But the question is what would be the underlying sort of more tractable processes?",
            "I'm not sure what.",
            "But if you need the callback library and you need an approximating process that you can handle, so that will be the question.",
            "If you could, you said that your condition Brownian motion to be at a specific point at a specific time.",
            "You get around in fridge.",
            "Yeah, that was a simple example.",
            "Gotta get out of here and which tells you what you want to sort of be, rather nikodym derivative when you compare the.",
            "Diffusion with a space dependent drift.",
            "Yes, Brownian motion.",
            "Yes, combine these two observations to come up with the distribution of the diffusion condition to be at a specific point in specific time.",
            "I'm not quite sure if I fully understand.",
            "I mean I cannot use a comparison with the with the Brownian motion that has a constant drift because these two processes would not be continued.",
            "How do you say absolutely continues?",
            "Yeah, they would not be equivalent.",
            "Is not as frequent, diffusion coefficient is the same.",
            "They are equivalent.",
            "Yes, yes you're right.",
            "Yeah yeah, but still it would leave me with processes that have state dependent diffusion and they are not so easy to handle.",
            "So I sort of.",
            "I mean I was forced to do Gaussians because Gaussians are the simplest things to deal with.",
            "As soon as I leave the family of Gaussians things there are not so many nice approximating rich classes of of distribution.",
            "That's the problem we need attract.",
            "Table class that we can nicely manipulate and do computations with and I think there are not too many that have state dependent.",
            "Noise.",
            "Sure, I would bet that diffusion time actually changes when you condition the measurements, but OK, that's not my question.",
            "How much is that various nonlinear optimization related to so-called statistical linearizations?",
            "This I to be honest, I don't know what it means statistically narration you would have to explain.",
            "It is a very common algorithm, but it's not related to extended, filter.",
            "Well, we described in alright.",
            "The question is, is what you propose?",
            "Is it a local type of sort of adjustment, a local approximation?",
            "This is sort of a global one.",
            "It looks at the entire path and it says OK, that here's a here's a functional.",
            "I mean, I think maybe this would explain it.",
            "The function of the kullback Leiber that we're using.",
            "It looks at the process two processes, so that along the entire path, so it's not a local type of things.",
            "Of course, we approximate something with Gaussian, so that means effectively we deal with the linear stochastic differential equation approximating the original one, but.",
            "The measure that we use for closeness takes into account the entire path, and I'm not sure if this would be done in stochastic linearization, but probably you have.",
            "Have you looked into the?",
            "Essentially it's very close.",
            "Speak Linearizations except where you have observations so you can rewrite it like statistically very limited.",
            "The standard way of doing the expectation of the ACE in the beast, but then here you have the direct motion to apply that come into play where you have, yeah.",
            "It depends on on the whole window, in fact.",
            "So it's yeah, yeah, so.",
            "So in the original.",
            "I mean we we started this we made we derive this callback library and then we try to minimize it.",
            "But we made them.",
            "We made a mistake and it looked everything looked very much like Council.",
            "But then we found out that if we do a variation then there is also approximate propagation of sort of information from the past in from the from the future into the path.",
            "So there's.",
            "This thing is nonlocal, this approximation.",
            "So this is really no system for small thing.",
            "Also yes yes OK, that is moving, so you would you would believe it's the same.",
            "I'm not sure, I don't know.",
            "I think mathematically so these LaGrange multipliers that really take you know the.",
            "The starting point of the idea is very different, but the equation look.",
            "The results were similar, so at least could be so in your case is it.",
            "Is it a one shot type of thing where you have to just solve some backward equation once?",
            "I mean in our case, we really you know, in order to get the solution we have to sort of iterate backward and forward many times to get this converge.",
            "I think that got in the statistical.",
            "Based on kind of discriptive functions so that you have to calculate.",
            "Something in closed form, but it's possible only for certain types of.",
            "I think one different.",
            "One different aspect might be that this opens up the possibility also to go for for further suboptimal types of approximation.",
            "So you could say I specify my solution but not by by an entire path of functions, but maybe something that I can do in a parametric way.",
            "Then it can plug it again and I haven't.",
            "Sort of.",
            "I have an optimization method, sort of to get the optimal.",
            "Wait, so This is why we hope in the future we can deal with the better parameterized approximations that have smaller number of parameters and then go to higher dimension.",
            "So maybe this is not.",
            "Doable in the other one.",
            "I'm not sure that's.",
            "This computer system has many problems 'cause you have to actually calculate something in closed form and this you don't have that data restriction so.",
            "There are reasons why this collaboration is not very commonly used 'cause it's not so flexible framework.",
            "OK, so maybe we should then really compare it.",
            "The mathematics if you want.",
            "OK."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Talk of today's morning session.",
                    "label": 0
                },
                {
                    "sent": "She's by Manfred Opper.",
                    "label": 0
                },
                {
                    "sent": "Let's go on approximate inference for continuous time.",
                    "label": 1
                },
                {
                    "sent": "Markov process is also thank you very much, Neal.",
                    "label": 0
                },
                {
                    "sent": "The organizers to the organizer for inviting me, but some of them are actually on as collaborators here so well, they can ask you.",
                    "label": 0
                },
                {
                    "sent": "They can answer you a lot of questions, probably that you might have, which I can't answer, so this will be about approximate inference.",
                    "label": 1
                },
                {
                    "sent": "For continuous time Markov processes in the type of things that we have in mind is.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This is an example, so we have a time serious with actually a bivariate one and it comes from a simple.",
                    "label": 1
                },
                {
                    "sent": "Prey predator models.",
                    "label": 0
                },
                {
                    "sent": "So the observations would be integer valued quantities with a little bit of noise, and there's an underlying continuous time process, but we don't observe the process.",
                    "label": 0
                },
                {
                    "sent": "Actually we see only these these observations as discrete time points, and the problem would be.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Assuming specific model which is here so there's two species and they multiply.",
                    "label": 0
                },
                {
                    "sent": "I don't want to go through the details depending on how many guys are already there.",
                    "label": 0
                },
                {
                    "sent": "Some of them die, some of them eat each others and multiply, and things like that.",
                    "label": 0
                },
                {
                    "sent": "So based on such such a type of model, we would like to infer what are these rate constants based on the measurements that we make.",
                    "label": 0
                },
                {
                    "sent": "So this model has unknown rate constants.",
                    "label": 0
                },
                {
                    "sent": "Can we predict them?",
                    "label": 0
                },
                {
                    "sent": "And we would also like to understand maybe.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "What happened in between those observations where we haven't seen things, so we'd like to predict the state, and we would like to predict what are model parameters.",
                    "label": 0
                },
                {
                    "sent": "So this is 1.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Type of thing.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The other type of well that actually was the underlying true.",
                    "label": 0
                },
                {
                    "sent": "Sample path that generated those data.",
                    "label": 0
                },
                {
                    "sent": "So you see this little jumps, so it's a Markov jump process in this case and.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Another example would be something like that, so again we have here at time and we have some state and that state evolves again with some dynamics that we don't know.",
                    "label": 0
                },
                {
                    "sent": "But we make only certain observations in these areas.",
                    "label": 0
                },
                {
                    "sent": "We don't have observations, and in this case we try to make a prediction and give some uncertainty to that prediction.",
                    "label": 0
                },
                {
                    "sent": "In this case we used a Gaussian process regression type.",
                    "label": 0
                },
                {
                    "sent": "Of modeling, and this is actually a bad prediction if you know what the underlying model was.",
                    "label": 0
                },
                {
                    "sent": "It predicts that if you far away from these measurements, you would have a huge uncertainty and your prediction should go to zero.",
                    "label": 0
                },
                {
                    "sent": "But this type of prediction had actually completely ignored the underlying.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Modeling the underlying model was something like that, so it was a emotion.",
                    "label": 0
                },
                {
                    "sent": "In a double well potential.",
                    "label": 1
                },
                {
                    "sent": "So you see what happened.",
                    "label": 0
                },
                {
                    "sent": "There was a little particle that was sort of randomly kicked by white noise.",
                    "label": 0
                },
                {
                    "sent": "Here.",
                    "label": 0
                },
                {
                    "sent": "This is white noise and there's a drift term.",
                    "label": 0
                },
                {
                    "sent": "The drift is the derivative of this potential, so it's kicked here.",
                    "label": 0
                },
                {
                    "sent": "Then it make some measurements there, and at some time point it moves to the other side of the potential and then also kicked is kicked a bit and you observe it.",
                    "label": 0
                },
                {
                    "sent": "And I think if you don't observe it for awhile it will still stay there for quite awhile.",
                    "label": 0
                },
                {
                    "sent": "So the prediction that your uncertainty is getting bigger and bigger was.",
                    "label": 0
                },
                {
                    "sent": "Not a good thing knowing that the underlying model was that, so we would like to use the fact that we know something like this, a model which is a stochastic differential equation to make a good prediction.",
                    "label": 0
                },
                {
                    "sent": "So in this case, sort of the optimal prediction.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Obtained.",
                    "label": 0
                },
                {
                    "sent": "My Monte Carlo method was actually something like that, so this is the prediction of the expected state of the system overtime and that is the corresponding uncertainty about our about the measurement of the state.",
                    "label": 0
                },
                {
                    "sent": "So you see anytime when we have a little bit of information by this by this data point you see there's a reduction in uncertainty and you see this thing.",
                    "label": 0
                },
                {
                    "sent": "Is not blowing up the uncertainty, so this is the kind of thing that we want to achieve and the question is how?",
                    "label": 0
                },
                {
                    "sent": "How can we do that?",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So well, that was.",
                    "label": 0
                },
                {
                    "sent": "A possible underlying sample path that might have generated the data.",
                    "label": 1
                },
                {
                    "sent": "So in this case it is very rough function.",
                    "label": 0
                },
                {
                    "sent": "It's not one of these little piecewise constant paths.",
                    "label": 0
                },
                {
                    "sent": "In this case it is a salute.",
                    "label": 0
                },
                {
                    "sent": "It's a sample path for stochastic differential equation.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So what I would like to do in this talk is look at some of the approximations that we've been working on.",
                    "label": 0
                },
                {
                    "sent": "So first of all, I'd like to define a little bit more mathematically.",
                    "label": 0
                },
                {
                    "sent": "What I mean with these models that I've discussed this simple Markov jump process and and diffusion process.",
                    "label": 1
                },
                {
                    "sent": "Then I would like to discuss a variational approach to Bayesian inference, inference and parameter estimation for that model.",
                    "label": 1
                },
                {
                    "sent": "And if you do sort of a full variation, you might end up.",
                    "label": 0
                },
                {
                    "sent": "With the exact inference and, but you might also get kind of approximations for that, and then there will be also if I have time to speak about a non variational type of approximation based on assuming small fluctuations.",
                    "label": 0
                },
                {
                    "sent": "Right, so well he can ask me questions anytime and.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Right, so the two types of models that we were looking at something is a continuous time Markov process.",
                    "label": 1
                },
                {
                    "sent": "So we're thinking about here assistant with discrete states X and the probability of having a transition from one state X to another state X prime over a small time interval of size Delta T scales like scales in such a way that means with high probability.",
                    "label": 1
                },
                {
                    "sent": "Nothing is happening, so this is a chronic Delta, so with probability almost one state, the new state is equal to the old state, but there is a rate function F of X prime.",
                    "label": 0
                },
                {
                    "sent": "And X that tells you sort of with with which probability you're moving into another state.",
                    "label": 1
                },
                {
                    "sent": "So you have this small Delta T scaling for these types of processes, discrete jump processes.",
                    "label": 0
                },
                {
                    "sent": "So with a linear probability that grows linear with Delta T, you go somewhere else and the other type of models that we're interested in is diffusion processes.",
                    "label": 0
                },
                {
                    "sent": "There are described by stochastic differential equations, so the state is now changing.",
                    "label": 0
                },
                {
                    "sent": "Continuously, the change of the state is proportional to the time interval, Delta T and a drift term.",
                    "label": 0
                },
                {
                    "sent": "So this is the deterministic part of the of the motion, and then there will be a diffusion part sort of driven by white noise.",
                    "label": 0
                },
                {
                    "sent": "And in general it might be dependent on this state as well.",
                    "label": 0
                },
                {
                    "sent": "And sort of my humble understanding of stochastic differential equations is sort of if I want to simulate them, I do it in the following way.",
                    "label": 0
                },
                {
                    "sent": "I discretize this object in a very simple Euler type of way and say, well, the change of the state Delta X is proportional to something linearly in Delta T and something which goes with the with the square root of Delta T. White noise part, and then I get the correct scaling for small Delta T so you can understand it as a kind of limit of this very simple discrete time thing.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, So what we want to do is the following.",
                    "label": 0
                },
                {
                    "sent": "We want to solve the problem of having noisy observations of that state X so noisy observations at certain discrete time steps, T one to 10.",
                    "label": 0
                },
                {
                    "sent": "So we don't observe the full trajectory.",
                    "label": 0
                },
                {
                    "sent": "We observe it only at certain discrete times, and that's what we observe and we think we have a likelihood function given the state X at time T. I we know what's the probability of of the wise, what's the probability density of the observations.",
                    "label": 0
                },
                {
                    "sent": "So this is given to us or it might contain parameters that we also want to estimate, and so the problem would be would like to estimate XT and give uncertainty of the prediction and we would like to also estimate unknown system parameters Theta that would be contained in the rate functions or in the drift or diffusion terms.",
                    "label": 1
                },
                {
                    "sent": "So in an ideal world that would be.",
                    "label": 0
                },
                {
                    "sent": "The type of stuff that we would like to do.",
                    "label": 0
                },
                {
                    "sent": "The question is.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Yeah, so well, the solution of course is.",
                    "label": 0
                },
                {
                    "sent": "Yeah, not so complicated, at least in principle.",
                    "label": 0
                },
                {
                    "sent": "So the optimal prediction of the path you would just just calculate the conditional distribution given the observation.",
                    "label": 1
                },
                {
                    "sent": "What is the probability of it?",
                    "label": 0
                },
                {
                    "sent": "The possible paths of the state?",
                    "label": 0
                },
                {
                    "sent": "Now we're not interested in.",
                    "label": 0
                },
                {
                    "sent": "Instead of saying what happened at time T, we're interested in the entire measure probability measure over paths so well, if we want to just make an optimal prediction.",
                    "label": 0
                },
                {
                    "sent": "So we could probably do.",
                    "label": 1
                },
                {
                    "sent": "Conditional expectation of the path MXT given the observations Y, and that should be based on the conditional or posterior distribution of the states X given the observations.",
                    "label": 1
                },
                {
                    "sent": "And this is just strange way of writing down Bayes rule, so this is the prior distribution over paths.",
                    "label": 0
                },
                {
                    "sent": "Coming from the underlying stochastic system, the stochastic differential equation of the jump process.",
                    "label": 0
                },
                {
                    "sent": "This is the likelihood of the observations given the state.",
                    "label": 0
                },
                {
                    "sent": "Zed is a normalizer and this is just posterior over prior is equal to likelihood within that constant.",
                    "label": 0
                },
                {
                    "sent": "So this is what we should use for making optimal predictions.",
                    "label": 0
                },
                {
                    "sent": "But of course this is a very sort of not so nice object this posterior and also the prior is not something that we can write down sort of explicitly because it's a prior overpass and it's a posterior over paths that we that we are discussing.",
                    "label": 0
                },
                {
                    "sent": "Right, so this is a problem is just a thing over paths so we could use this guy for making if we could handle it we could make optimal predictions, but we can also do parameter estimations.",
                    "label": 0
                },
                {
                    "sent": "For instance we would have this probability of the data given the parameters.",
                    "label": 0
                },
                {
                    "sent": "We could do a maximum likelihood estimation over using.",
                    "label": 0
                },
                {
                    "sent": "We could maximize this with respect to parameters if we could Q compute those this partition function and we could do a Bayesian estimation if we were using, for instance a prior over thetas.",
                    "label": 1
                },
                {
                    "sent": "So slightly more complicated.",
                    "label": 0
                },
                {
                    "sent": "So the problem is we should be able to deal with this guy as well.",
                    "label": 0
                },
                {
                    "sent": "So again.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Why's it not so see why is it not so easy?",
                    "label": 1
                },
                {
                    "sent": "They might just argue you know people with the machine learning background so they have looked probably into graphical models with all kinds of loops and stuff like that and and well, this is a very very simple system.",
                    "label": 0
                },
                {
                    "sent": "It doesn't have any loops, it's it's mark curve and you have some observation, so it's a hidden Markov model.",
                    "label": 0
                },
                {
                    "sent": "So why?",
                    "label": 0
                },
                {
                    "sent": "Why all this fuss about it?",
                    "label": 0
                },
                {
                    "sent": "It's a very simple system that people have studied, probably for many years, and I think the only thing that makes it so.",
                    "label": 0
                },
                {
                    "sent": "Well, a bit nastier is it's just a continuous time thing, and the things that we are used to like forward and backward algorithms to be well just partial differential equations that we have to solve.",
                    "label": 0
                },
                {
                    "sent": "So it's a bit a bit more complex so conceptually simple, but it involves partial differential equations.",
                    "label": 0
                },
                {
                    "sent": "Well, we could also resort to Monte Carlo techniques, and that's also something that we've done, but it requires sampling over sort of finely discretized paths, and that might also take.",
                    "label": 0
                },
                {
                    "sent": "Take some time to get convergence and if we think about computing the Bayesian evidence or the free energy, as it's often called well, it's also a bit nontrivial.",
                    "label": 1
                },
                {
                    "sent": "It might need many temperatures for the underlying Montecarlo process.",
                    "label": 0
                },
                {
                    "sent": "And also a Gibbs sampler is non trivial, which we probably will learn about this today from Andrew and naive Gibbs.",
                    "label": 0
                },
                {
                    "sent": "Sampling doesn't work and explain it much better than I could.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Right, so one way of looking at this problem is, well, we know that the posterior when I say posterior, the posterior press process over paths is also a mark of process.",
                    "label": 0
                },
                {
                    "sent": "And so we could think of sort of trying to find out how this Markov process looks like.",
                    "label": 0
                },
                {
                    "sent": "For instance this jump process.",
                    "label": 0
                },
                {
                    "sent": "It may, we might wish to compute the rate function.",
                    "label": 0
                },
                {
                    "sent": "Having seen the data, what's the new rate function?",
                    "label": 1
                },
                {
                    "sent": "Or if we look at a diffusion problem, we might wish to understand what this new drift term is.",
                    "label": 0
                },
                {
                    "sent": "Actually, the diffusion is not changed, but the drift is changed.",
                    "label": 0
                },
                {
                    "sent": "We can think of this new drift is adrift.",
                    "label": 0
                },
                {
                    "sent": "That takes the data into account because you know the path is coming and there's a data point, and we know that's sort of the data point has to be.",
                    "label": 0
                },
                {
                    "sent": "The path must be sort of generated in such a way that the the data point is.",
                    "label": 0
                },
                {
                    "sent": "Rather likely so so there has to be a drift that guides the path of the diffusion process close to the data point, and so we would like to see what this G function is.",
                    "label": 0
                },
                {
                    "sent": "And can we find out can we do at least an approximate computation of this underlying posterior drift function?",
                    "label": 0
                },
                {
                    "sent": "So one idea is just to resort to.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Well OK this is 1 example.",
                    "label": 0
                },
                {
                    "sent": "Let's say there's a simple a simple a single observation of a vina process, so it's a process that doesn't have a drift.",
                    "label": 0
                },
                {
                    "sent": "But now observe it, I observe it at some time T here and I make the observation it well, it has the value 0 at this end point.",
                    "label": 0
                },
                {
                    "sent": "So this is my observation and I'm sure that the observation is noise free.",
                    "label": 0
                },
                {
                    "sent": "So I'm exactly sure it went there.",
                    "label": 0
                },
                {
                    "sent": "So how does the posterior look like based on this type of information?",
                    "label": 0
                },
                {
                    "sent": "So the Wiener process starts at 0 and I observe it at zero.",
                    "label": 1
                },
                {
                    "sent": "Also at this time T and then you can show.",
                    "label": 0
                },
                {
                    "sent": "That the drift so of the posterior is given by this expression, and you see if I if I reach with time.",
                    "label": 0
                },
                {
                    "sent": "If I reach this final time T then X has to be sure and has has to be has to go to zero to avoid this.",
                    "label": 0
                },
                {
                    "sent": "To make this from diverging so this really attracts the this vina process towards 0 and it has to come back and so the posterior process with this type of thing is known as the Brownian Bridge.",
                    "label": 0
                },
                {
                    "sent": "So you can yes.",
                    "label": 0
                },
                {
                    "sent": "You say you posterior process.",
                    "label": 0
                },
                {
                    "sent": "The diffusion is the same, the diffusion is the same.",
                    "label": 0
                },
                {
                    "sent": "Yes, if you take the if you take one observation or finite number of observation, given that number one yes.",
                    "label": 0
                },
                {
                    "sent": "Doesn't it seem?",
                    "label": 0
                },
                {
                    "sent": "That that you sort of get in.",
                    "label": 0
                },
                {
                    "sent": "Then the observations are completely guiding the dynamics.",
                    "label": 0
                },
                {
                    "sent": "You would expect that there's a diffusion goes to 0 or no, no, no.",
                    "label": 0
                },
                {
                    "sent": "These observations are really point observation, so they don't tell you anything about changes in time.",
                    "label": 0
                },
                {
                    "sent": "They just say where was the process at time T, so it doesn't tell you anything about about a Fusion.",
                    "label": 0
                },
                {
                    "sent": "So if you make the number of observations.",
                    "label": 0
                },
                {
                    "sent": "It seems to be sort of observed.",
                    "label": 0
                },
                {
                    "sent": "It doesn't change the diffusion to my to my knowledge.",
                    "label": 0
                },
                {
                    "sent": "I don't know if this limit is going to be something nice, but at least for every finite set of observation, the diffusion is not is not changed.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Our idea was to look at at to use a method that has been used in machine learning quite a lot and assist.",
                    "label": 0
                },
                {
                    "sent": "It's known as the variational approximation so you have a posterior process that is or a posterior distribution that is not so easy to to handle to deal with and you like to introduce a family of simpler distributions, like Gaussians that we can sort of deal with and optimize them.",
                    "label": 0
                },
                {
                    "sent": "So in such a way that they sort of resemble.",
                    "label": 0
                },
                {
                    "sent": "The not so nice distribution in.",
                    "label": 0
                },
                {
                    "sent": "The best way and measuring sort of the similarities between distributions.",
                    "label": 0
                },
                {
                    "sent": "Yeah, we measured them using the cool Buck Libra divergent.",
                    "label": 0
                },
                {
                    "sent": "So the kullback Leiber divergent, or the relative entropy, is a nonsymmetric dissimilarity measure between distributions.",
                    "label": 0
                },
                {
                    "sent": "So we introduce.",
                    "label": 0
                },
                {
                    "sent": "So this is the posterior process data.",
                    "label": 1
                },
                {
                    "sent": "The State X and what I mean by that is really X is.",
                    "label": 0
                },
                {
                    "sent": "The whole path over States and we tried to play with simpler probability measures Q and we make we try to make them as close as possible to P using this distance measure innocence between distributions and an equivalent formulation is because this posterior contains a nasty term which is the evidence of the data.",
                    "label": 0
                },
                {
                    "sent": "The this P of Y given Theta.",
                    "label": 0
                },
                {
                    "sent": "So if we subtract that from the kullback, Leiber divergent, then usually this is something this guy is called.",
                    "label": 1
                },
                {
                    "sent": "The variational Free energy is something that we can usually compute.",
                    "label": 0
                },
                {
                    "sent": "And so we wish to find distributions Q which minimize this variational free energy.",
                    "label": 0
                },
                {
                    "sent": "So if we do a full variation in the space of all probability distributions.",
                    "label": 0
                },
                {
                    "sent": "So the best Q would be the true posterior.",
                    "label": 0
                },
                {
                    "sent": "And if we use a sort of simpler approximating family, we might get, well, a good approximation by minimizing this functional with respect to this family of approximating distributions.",
                    "label": 0
                },
                {
                    "sent": "And if I write down the posterior as a product of prior and likelihood, I will find out that the free energy is becoming.",
                    "label": 0
                },
                {
                    "sent": "There's a term which is the kullback Leiber divergent between Q and the prior distribution, and a term that comes from the data from the likelihood.",
                    "label": 0
                },
                {
                    "sent": "And I also see by the fact that this guy is non negative.",
                    "label": 0
                },
                {
                    "sent": "Let the free energy gives.",
                    "label": 0
                },
                {
                    "sent": "An upper bound on the negative logarithm of the probability of the data given the parameters, so I can use this also as a proxy for, you know, minimizing this object with respect to parameters in a maximum likelihood way.",
                    "label": 0
                },
                {
                    "sent": "So rather than minimizing this, which I cannot compute, I minimize this guy with respect to parameters, so that's that solves two things I can do sort of approximate inference about state paths, and I can do.",
                    "label": 0
                },
                {
                    "sent": "Approximate inference also about parameters in this approach, so this has been used.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Well, those are you with a statistical physics background.",
                    "label": 1
                },
                {
                    "sent": "There's a different way, so if have Gibbs measures and was a Hamiltonian, H Another approximating Gibbs measure with the Hamiltonian function age nought.",
                    "label": 0
                },
                {
                    "sent": "Then the free energy is you can actually show the free energy is becoming.",
                    "label": 0
                },
                {
                    "sent": "Set of 1st order perturbation theory.",
                    "label": 0
                },
                {
                    "sent": "This this variational free energy.",
                    "label": 1
                },
                {
                    "sent": "If you believe that the difference between this and this is small and you do a first order perturbation theory in the difference, then you end up also with the variational free energy and.",
                    "label": 0
                },
                {
                    "sent": "Open formulat",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Chen I don't want.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so that you can use this variational formulation also to get sort of an approximate full Bayesian inference by.",
                    "label": 1
                },
                {
                    "sent": "Sort of saying what is the best posterior approximate posterior over the parameters within this formulation, and then you can use also the free energy E to the minus free energy would be something like the probability of the data given the parameters.",
                    "label": 0
                },
                {
                    "sent": "So if you multiply it by a prior and normalize it, that can serve also as an approximation to the posterior over parameters.",
                    "label": 0
                },
                {
                    "sent": "So this is the program and that has been used.",
                    "label": 0
                },
                {
                    "sent": "Extensively in the area of machine learning and sort of our interest was can we sort of carry the limit.",
                    "label": 0
                },
                {
                    "sent": "Of Delta T of small times to zero anhava continuum time.",
                    "label": 0
                },
                {
                    "sent": "Continuous time formulation of that so that.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Was.",
                    "label": 0
                },
                {
                    "sent": "One of the things that we wanted to do so we can try and make this rigorous, but I think it's it's much easier to sort of look at it as a limit of a discrete time modeling, so we have to compute cubuk Libra divergences between Markov processes and one way of doing it.",
                    "label": 1
                },
                {
                    "sent": "If we discretize in time, then we would see of course.",
                    "label": 0
                },
                {
                    "sent": "If we have the logs of probabilities, Overpass can always be written.",
                    "label": 0
                },
                {
                    "sent": "These probability overpass using the Markov property as a product of the transition probabilities and at the end of the day, what you obtain is kind of an average of the kullback.",
                    "label": 0
                },
                {
                    "sent": "Leiber divergent between transition probabilities, and so the only thing you have to do is you use your mark process and find out what is the short time behavior for these transition probabilities.",
                    "label": 0
                },
                {
                    "sent": "And that's something that you can you can do for these Markov jump processes, and you can do for diffusions.",
                    "label": 0
                },
                {
                    "sent": "So you plug this in and go to the limit where the time step Delta T is small, and then you find out that the sum over these different times is becoming an integral, and that is sort of a non rigorous heuristic type of derivation of something that you also can get in a more rigorous.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Play.",
                    "label": 0
                },
                {
                    "sent": "So you need the short time the kullback Leiber divergences between the transition probability of the Markov process for short terms.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Show times, so here are the two classes of processes that we looked at.",
                    "label": 0
                },
                {
                    "sent": "Sort of.",
                    "label": 0
                },
                {
                    "sent": "This simple mark of John processes.",
                    "label": 0
                },
                {
                    "sent": "We've already written down what these short time behavior is, and for Gaussian for diffusion processes, we know that for short times the probability the transition probability is locali a Gaussian, so we know the change in the state has a mean which is given by the drift.",
                    "label": 0
                },
                {
                    "sent": "And there is also a covariance given by this diffusion term, so this is the short time behavior of that transition probability.",
                    "label": 1
                },
                {
                    "sent": "And if we use it inside of this cool book library computation, then.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "For instance, you get the following thing.",
                    "label": 0
                },
                {
                    "sent": "So the kullback Leiber divergance between one probability measure and another one that correspond to diffusion processes with the same diffusion is essentially given by the expected L2 distance in a sense between the drift corresponding to Q and the drift corresponding to P. So it's essentially how different are two 2 measures.",
                    "label": 1
                },
                {
                    "sent": "Well, it's more or less the square between.",
                    "label": 0
                },
                {
                    "sent": "The two drifts, averaged over the marginal distribution at time T of.",
                    "label": 0
                },
                {
                    "sent": "Of the process queue, so that looks not so bad, right?",
                    "label": 0
                },
                {
                    "sent": "I mean, the only thing you have to know what is the drift?",
                    "label": 0
                },
                {
                    "sent": "What are the two drifts of the approximating processes?",
                    "label": 0
                },
                {
                    "sent": "And you have to know what is the marginal distribution, and then you're able to compute this callback live.",
                    "label": 0
                },
                {
                    "sent": "Learn it when you can compute it.",
                    "label": 0
                },
                {
                    "sent": "You can use it in a variational method, so that's all I mean.",
                    "label": 0
                },
                {
                    "sent": "OK, this formula is already known.",
                    "label": 0
                },
                {
                    "sent": "It's been known before, and of course, completely independently.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Rediscovered by asking?",
                    "label": 0
                },
                {
                    "sent": "So you can do the same thing for Mark.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Jump processes as well.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So what do we have to do right?",
                    "label": 0
                },
                {
                    "sent": "I mean, let's say just to re discover something that is also known in the literature for quite awhile, so we should be able to re discover what the exact inference is doing by doing the full variation, just to see that it's not so not so simple.",
                    "label": 0
                },
                {
                    "sent": "So as I told you, you have to do the two drifts squared, averaged over the marginal distribution and plug this in so it's a functional.",
                    "label": 0
                },
                {
                    "sent": "Now you do the variation with respect to G, which is the G is the posterior drift.",
                    "label": 0
                },
                {
                    "sent": "That's the drift that has seen the data.",
                    "label": 0
                },
                {
                    "sent": "So the only problem is that the drift G in the marginal distribution sort of there are connected because the marginal distribution and drift are related by the forward equation which is known in for diffusions as the Fokker Planck equation or the master equation for the jump processes.",
                    "label": 0
                },
                {
                    "sent": "So you have to do the variation, but you have to know that.",
                    "label": 0
                },
                {
                    "sent": "Q knows G and they're related.",
                    "label": 0
                },
                {
                    "sent": "By the Fokker Planck equation.",
                    "label": 1
                },
                {
                    "sent": "So you do the variation and you use as an extra constraint.",
                    "label": 0
                },
                {
                    "sent": "This this Fokker Planck equation.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And so if you do that, you can do it using a LaGrange multiplier.",
                    "label": 0
                },
                {
                    "sent": "Plug in the dynamics.",
                    "label": 0
                },
                {
                    "sent": "This Fokker Planck equation and I LaGrange function which is function of state in time.",
                    "label": 1
                },
                {
                    "sent": "And then you do a full variation with respect to the posterior drift and with respect to this module distribution.",
                    "label": 1
                },
                {
                    "sent": "So essentially this was all just taken from from from a derivation of.",
                    "label": 0
                },
                {
                    "sent": "A belief propagation using beta free energy, so it's just a copy of the same method you do.",
                    "label": 0
                },
                {
                    "sent": "You get your cool Mark Leiber divergent.",
                    "label": 0
                },
                {
                    "sent": "You do a variation and introduce LaGrange multiplier for all the consistency conditions that you have.",
                    "label": 0
                },
                {
                    "sent": "The only difference is just the continuous time continuous state.",
                    "label": 0
                },
                {
                    "sent": "So you find out that the drift that has seen the data is equal to the drift that doesn't know that data.",
                    "label": 0
                },
                {
                    "sent": "And something that is proportional to the gradient of this LaGrange function that's one part of it.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And then you find also that the LaGrange function obeys.",
                    "label": 0
                },
                {
                    "sent": "Suitably transformed a backward equation.",
                    "label": 0
                },
                {
                    "sent": "So in some sense you discover something you might expect.",
                    "label": 0
                },
                {
                    "sent": "There's a backward forward algorithm.",
                    "label": 0
                },
                {
                    "sent": "The backward algorithm tells you how to compute the forward drift, and that's what you have to do.",
                    "label": 0
                },
                {
                    "sent": "So essentially the task is you solve a backward equation backwards in time.",
                    "label": 0
                },
                {
                    "sent": "That gives you the drift and where are the data.",
                    "label": 0
                },
                {
                    "sent": "The data actually come into jump conditions for this backward equation.",
                    "label": 1
                },
                {
                    "sent": "So anytime you see your data point makes a little jump and then you integrate it without jumps further and and so on.",
                    "label": 0
                },
                {
                    "sent": "So this is just what you have to do.",
                    "label": 0
                },
                {
                    "sent": "One backward sweep, but unfortunately you have to solve a PDE for doing that and that is sort of not so nice and these these equations are known as the the Kushner Stratonovich in part, do equations.",
                    "label": 0
                },
                {
                    "sent": "So they're known for quite awhile.",
                    "label": 0
                },
                {
                    "sent": "Times independently, I don't know exactly says.",
                    "label": 0
                },
                {
                    "sent": "Is there a Cold War thing going on here?",
                    "label": 0
                },
                {
                    "sent": "I don't know.",
                    "label": 0
                },
                {
                    "sent": "Yeah, I don't know Ronnie, you know about the history.",
                    "label": 0
                },
                {
                    "sent": "Discover 1958 first published this paper pardon.",
                    "label": 0
                },
                {
                    "sent": "Paper on this matter was 98 OK, I see.",
                    "label": 0
                },
                {
                    "sent": "In for diffusion processes.",
                    "label": 0
                },
                {
                    "sent": "Model partition theory was OK, OK good, so I don't have to the best.",
                    "label": 0
                },
                {
                    "sent": "Alright, so we are not independent OK?",
                    "label": 0
                },
                {
                    "sent": "Go to the previous page.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "As an example, now this this this this.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That noise for your observation case.",
                    "label": 0
                },
                {
                    "sent": "So what you have to do is you have to solve a backward equation.",
                    "label": 0
                },
                {
                    "sent": "The data point is at the end, so you just get one.",
                    "label": 0
                },
                {
                    "sent": "So this is this Delta function and you solve it and you get the result that I showed you before, so it's not a big deal.",
                    "label": 0
                },
                {
                    "sent": "So now we can use that different derivation using the variational method.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Also to come up with approximations.",
                    "label": 0
                },
                {
                    "sent": "So the idea is in the case of diffusion process you use simpler methods.",
                    "label": 0
                },
                {
                    "sent": "So you would use Gaussian measures and Gaussians.",
                    "label": 0
                },
                {
                    "sent": "Well we can do everything with Gaussians and people have also used them before, but not as extensively as factorizing variational distributions in the area of machine learning.",
                    "label": 1
                },
                {
                    "sent": "So the idea is now using a Gaussian measure.",
                    "label": 0
                },
                {
                    "sent": "So you can say this is induced by a linear posterior stochastic differential equations.",
                    "label": 0
                },
                {
                    "sent": "So here is a linear.",
                    "label": 0
                },
                {
                    "sent": "It's linear in the drift is linear in the state, and there is also a bias term here in these things are time dependent, so this we use this type of stochastic differential equation to approximate the true posterior process and the functions A&B would be the variational functions to be optimized.",
                    "label": 0
                },
                {
                    "sent": "So that's the idea.",
                    "label": 0
                },
                {
                    "sent": "Is these stochastic differential equations would induce a measure over path which is a Gaussian one, and we would calculate the global kleiber divergance between the true posterior and the measure introduced induced by this one and use this this as an approximation.",
                    "label": 0
                },
                {
                    "sent": "So there's one important thing this can be done only if the diffusion term is independent of the state, so it would not be.",
                    "label": 1
                },
                {
                    "sent": "Applicable to state dependent noise because the state dependent noise, I cannot get a Gaussian measure and the diffusions have to be the same in the kullback Leiber divergent because otherwise the kullback Leiber divergences becoming infinite.",
                    "label": 0
                },
                {
                    "sent": "So that is a bit of a problem.",
                    "label": 0
                },
                {
                    "sent": "So now the interesting thing is, since we have a Gaussian measure, linear stochastic differential equation with a linear drift and a Gaussian measure, so we know that now the marginal distribution is a Gaussian and we don't have to write down ifakara complicated Fokker Planck equation, which makes things worse.",
                    "label": 0
                },
                {
                    "sent": "We only have to deal with the mean at time T and the covariance of the state at time T. So these are the only parameters they completely determine.",
                    "label": 0
                },
                {
                    "sent": "The marginal distribution.",
                    "label": 0
                },
                {
                    "sent": "So rather than having to deal with arbitrary marginal distributions, we have to deal with Gaussian ones which are completely determined by mean and covariance.",
                    "label": 0
                },
                {
                    "sent": "Now, rather than having PD is we are, we end up with systems of ODS and that makes of course the treatment simpler.",
                    "label": 0
                },
                {
                    "sent": "So we end up with systems of nonlinear ODS, and I'm not giving the details, but that is sort of the simplification.",
                    "label": 0
                },
                {
                    "sent": "We don't have to solve the PDE's we have to solve ODS.",
                    "label": 0
                },
                {
                    "sent": "Nonlinear.",
                    "label": 0
                },
                {
                    "sent": "Let me see.",
                    "label": 0
                },
                {
                    "sent": "Well, I think the nonlinearity comes in when we we have when we work we introduce LaGrange functions again communicate to this condition and we can eliminate.",
                    "label": 0
                },
                {
                    "sent": "You know, we get a set of differential equations and we can eliminate certain quantities, and then the rest of it becomes nonlinear.",
                    "label": 0
                },
                {
                    "sent": "So you're right, these ones are.",
                    "label": 0
                },
                {
                    "sent": "Linear.",
                    "label": 0
                },
                {
                    "sent": "Look for NVIDIA pardon yes, yes yes, the problem.",
                    "label": 0
                },
                {
                    "sent": "So we get.",
                    "label": 0
                },
                {
                    "sent": "Of course we have to.",
                    "label": 0
                },
                {
                    "sent": "This is the dynamics of mean and covariance.",
                    "label": 1
                },
                {
                    "sent": "Then we get LaGrange functions also for this and for that.",
                    "label": 0
                },
                {
                    "sent": "And we have to do a variation with respect to 2A and B and that ends up becoming non.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Near right, so as an example, is emotion in a double.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The potential that I have mentioned and this is now a variational, the variational result solving these ordinary differential equations compared to a result from Monte Carlo sampling where we do a sampling of the posterior and you see so this the green one is the variational approximation, the blue one is sort of the exact yes.",
                    "label": 0
                },
                {
                    "sent": "I mean is it while it looks very bars going back up for the possibility that it jumps back it one way, John, he isn't this possibility that that jumps back the opposite direction.",
                    "label": 0
                },
                {
                    "sent": "Yes, yes, but not with the parameters that we've chosen and in this in this case, and so there's a typical thing here that happens in many variational approximation.",
                    "label": 0
                },
                {
                    "sent": "So the variances on is under estimated, but the mean is.",
                    "label": 0
                },
                {
                    "sent": "Assumed to be no, no pun.",
                    "label": 0
                },
                {
                    "sent": "The drift in this case is known, yes, yes, but we can also do.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Sort of estimations on parameters.",
                    "label": 0
                },
                {
                    "sent": "So in this case we were doing estimation on the diffusion constant, introducing a prior over diffusions, and this is again the variational inference in comparison with Monte Carlo inference.",
                    "label": 0
                },
                {
                    "sent": "So I mean it's not perfect, but you see it seems like the mean and roughly also the uncertainty are sort of preserved in in the approx.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Timation and of course I mean it wouldn't be science if I wouldn't show you an example where it doesn't work so well.",
                    "label": 0
                },
                {
                    "sent": "And of course you can easily understand why it doesn't work so well here.",
                    "label": 0
                },
                {
                    "sent": "This is a case where really the posterior is very far from a Gaussian measure and so you see, this is a case where we have large observation noise, so the observations don't really tell you exactly where the state don't tell you much about whether state is.",
                    "label": 1
                },
                {
                    "sent": "So if you look, for instance at the marginal at a certain time.",
                    "label": 0
                },
                {
                    "sent": "It would be a Tri modal distribution and so we try to model it with essentially something that is unimodal marginally, and so we're not even getting the correct transition.",
                    "label": 0
                },
                {
                    "sent": "And also, you know this is no no good approximation for the variance, and it's clear.",
                    "label": 0
                },
                {
                    "sent": "So we try to approximate something which is non Gaussian, highly non Gaussian by by something which is much more concentrated.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Yeah, so it has its limits of course, and so we can also go to.",
                    "label": 0
                },
                {
                    "sent": "Well, of course we were planning to go to very high dimensionality at the moment.",
                    "label": 0
                },
                {
                    "sent": "We do three dimension, so this is a this is designed for you this.",
                    "label": 0
                },
                {
                    "sent": "So this is a noisy Lauren system, so I think the blue one is the true is the true underlying path and the red one is is the prediction so we don't make a comparison here with the exact model.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Other results, but we show we show these are the three coordinates and we make comparison with other types of approximation.",
                    "label": 0
                },
                {
                    "sent": "So that seems to be beyond unscented Kalman.",
                    "label": 0
                },
                {
                    "sent": "Smoother result.",
                    "label": 0
                },
                {
                    "sent": "Again, Blue is exact and so the dashed line is the prediction of.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Yes, the prediction.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is a regression, and that's sort of that's what we got.",
                    "label": 0
                },
                {
                    "sent": "It looks sort of more reasonable.",
                    "label": 0
                },
                {
                    "sent": "For the prediction and also for the for the the error bar.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Right, I haven't spoken about Markov jump processes.",
                    "label": 0
                },
                {
                    "sent": "Just briefly.",
                    "label": 0
                },
                {
                    "sent": "Of course, we can't approximate them with a Gaussian, but if we have a multivariate problem, we can still say, well, a reasonable approximation is to factorize the measure over paths into a product of measures where each you know where each measure is only.",
                    "label": 0
                },
                {
                    "sent": "With a with a single coordinate, right?",
                    "label": 0
                },
                {
                    "sent": "So we're not doing any factorization in time.",
                    "label": 0
                },
                {
                    "sent": "Of course, we preserve temporal correlations, but we factorize the measure in the different components and use that as an approximation that is known as mean field or factorizing variational approximation and sort of what we gain is the exact system backward equation that we would have to solve is linear odies in South to the D variables, where X is the number of state D is.",
                    "label": 0
                },
                {
                    "sent": "The dimensionality of the problem and we would get away with S * D. Is a complexity reduction, so we can do that.",
                    "label": 0
                },
                {
                    "sent": "Yeah, I don't want to give any.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I don't have enough time, so one of the problems of course that we're facing at the moment is.",
                    "label": 0
                },
                {
                    "sent": "When we go back to stochastic differential equations, we can't deal with with state dependent diffusion terms, so D of X is not possible because the kullback Leiber divergent between a Gaussian and the true posterior would be infinite.",
                    "label": 0
                },
                {
                    "sent": "In such a case.",
                    "label": 0
                },
                {
                    "sent": "So we would have to do other types of things we might think for instance, and transforming the state variable, but that is usually not possible if you run if you.",
                    "label": 0
                },
                {
                    "sent": "Deal with multivariate problems.",
                    "label": 0
                },
                {
                    "sent": "Those usually don't exist.",
                    "label": 0
                },
                {
                    "sent": "These transformations for any interesting case.",
                    "label": 0
                },
                {
                    "sent": "So at the moment we help ourselves with.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The types of approximations, so we go back to the exact solution and the exact solution.",
                    "label": 0
                },
                {
                    "sent": "For instance, the backward equation.",
                    "label": 0
                },
                {
                    "sent": "We go back to the PDE that we would have to solve, and in the case where we say that the diffusion term is relatively small.",
                    "label": 0
                },
                {
                    "sent": "So what we do formally we go from a diffusion to epsilon time diffusion in work with small epsilons.",
                    "label": 0
                },
                {
                    "sent": "Then you can get kind of a Gaussian shape scaling.",
                    "label": 0
                },
                {
                    "sent": "Form of the solution to that key.",
                    "label": 0
                },
                {
                    "sent": "KSP equation.",
                    "label": 0
                },
                {
                    "sent": "What we do is just we solve this.",
                    "label": 0
                },
                {
                    "sent": "We solve the PDE with this type of approximation backwards in one sweep, and then we get an approximation to the posterior drift that can also be computed for the case of multiplicative noise, but it's not a variational approximation, just using this type of unsers within within the.",
                    "label": 0
                },
                {
                    "sent": "Pardon, this is a small that's a small noise kind of thing and and the application area would be something like that.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For instance, it would be applicable to chemical kinetics or these type of prey predator system where sort of the average number of individuals or molecules involved in the problem is large compared sort of large, so that the usually the fluctuations are small and so you can treat well.",
                    "label": 0
                },
                {
                    "sent": "This is originally a mark of jump process, but you can come up with a diffusion approximation for it in the limit where we have large number of.",
                    "label": 0
                },
                {
                    "sent": "Species and so so jumps are relatively small compared to that, and if you look at at this problem just from far away, it looks more or less like a diffusion path, and so you can approximate it by a stochastic differential equation.",
                    "label": 0
                },
                {
                    "sent": "And again you can make this weak noise assumption on top of it and you get something salute.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Things that don't look so bad.",
                    "label": 0
                },
                {
                    "sent": "So for instance, this is.",
                    "label": 0
                },
                {
                    "sent": "We repeat this experiment with many new random realizations and you see so our approximation would be that there is a Gaussian, and so this is not a Bayesian type of thing.",
                    "label": 0
                },
                {
                    "sent": "This is a frequentist type of, you know, we see is our mean prediction over the uncertainty that we get really reflecting the true true.",
                    "label": 0
                },
                {
                    "sent": "So this is kind of a calibration experiment and.",
                    "label": 0
                },
                {
                    "sent": "So let's say if you are.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In this region, maybe the Gaussian assumption is not so bad.",
                    "label": 0
                },
                {
                    "sent": "So what we get out of this sort of approximate weak noise inference seems to be reasonable.",
                    "label": 0
                },
                {
                    "sent": "But of course, if you're here in the area where things die out, of course, sort of Gaussian assumptions are probably bad, but if you're in that area, then and it's OK. And on top of it, So what we do now is essentially we use this week noise approximation and it's if it's weak noise.",
                    "label": 0
                },
                {
                    "sent": "Everything looks more or less Kelsey and you can also calculate free energies for that case and use.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "System for doing Peru.",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Meter estimation and they also look reasonably well, so you make a prediction error for OP.",
                    "label": 0
                },
                {
                    "sent": "Four parameters in that process and sort of these are comparisons between estimates and and truth, so it seems like maximum likelihood is doing fairly well in that case.",
                    "label": 0
                },
                {
                    "sent": "And also the sort of the curvature of the likelihood gives you more or less the uncertainty, so it calibrates well, at least in the week noise limit, but it's not a variational type of thing.",
                    "label": 0
                },
                {
                    "sent": "And we have to work on that.",
                    "label": 0
                },
                {
                    "sent": "I think this is a good point probably to stop.",
                    "label": 0
                },
                {
                    "sent": "So we.",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Something that we're playing now with and hope to get something ready for NIPS.",
                    "label": 0
                },
                {
                    "sent": "Of course, so less transparency is systems where we have a hybrid kind of structure.",
                    "label": 0
                },
                {
                    "sent": "We have something which is continuous state, so it's like a Norristown Uhlenbeck process.",
                    "label": 0
                },
                {
                    "sent": "But the noise is no longer white white noise, but the noise is is a flip is a random, is a Markov jump processes that flips between plus and minus one with a certain rate.",
                    "label": 0
                },
                {
                    "sent": "So this is a.",
                    "label": 0
                },
                {
                    "sent": "This is driven by a Markov process, and so we want to see if we can do inference on what's going on here.",
                    "label": 0
                },
                {
                    "sent": "What's the posterior over these flip variables and.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so this problem is simple enough so you can solve the underlying stochastic the underlying partial differential equation and we compare it with a variational method so this zed is no longer Markovian.",
                    "label": 0
                },
                {
                    "sent": "After I've seen the observation, so the posterior is no longer Markovian, but the whole system X end together with said is Markovian in the joint variables and you can play with that.",
                    "label": 0
                },
                {
                    "sent": "And yeah, I think just.",
                    "label": 0
                },
                {
                    "sent": "I'd rather stop now.",
                    "label": 0
                },
                {
                    "sent": "Thank you very much.",
                    "label": 0
                },
                {
                    "sent": "I guess in the spiritual sense of lady purses you could look at dynamics, which has both drift and diffusion as well as jump components.",
                    "label": 0
                },
                {
                    "sent": "Yes?",
                    "label": 0
                },
                {
                    "sent": "Well the question is we would have to write down kullback Leiber divergent for that case, and I would assume even that's probably known in the literature how they look like, and we would have to see if we could do something.",
                    "label": 0
                },
                {
                    "sent": "But the question is what would be the underlying sort of more tractable processes?",
                    "label": 0
                },
                {
                    "sent": "I'm not sure what.",
                    "label": 0
                },
                {
                    "sent": "But if you need the callback library and you need an approximating process that you can handle, so that will be the question.",
                    "label": 0
                },
                {
                    "sent": "If you could, you said that your condition Brownian motion to be at a specific point at a specific time.",
                    "label": 0
                },
                {
                    "sent": "You get around in fridge.",
                    "label": 0
                },
                {
                    "sent": "Yeah, that was a simple example.",
                    "label": 0
                },
                {
                    "sent": "Gotta get out of here and which tells you what you want to sort of be, rather nikodym derivative when you compare the.",
                    "label": 0
                },
                {
                    "sent": "Diffusion with a space dependent drift.",
                    "label": 0
                },
                {
                    "sent": "Yes, Brownian motion.",
                    "label": 0
                },
                {
                    "sent": "Yes, combine these two observations to come up with the distribution of the diffusion condition to be at a specific point in specific time.",
                    "label": 0
                },
                {
                    "sent": "I'm not quite sure if I fully understand.",
                    "label": 0
                },
                {
                    "sent": "I mean I cannot use a comparison with the with the Brownian motion that has a constant drift because these two processes would not be continued.",
                    "label": 0
                },
                {
                    "sent": "How do you say absolutely continues?",
                    "label": 0
                },
                {
                    "sent": "Yeah, they would not be equivalent.",
                    "label": 0
                },
                {
                    "sent": "Is not as frequent, diffusion coefficient is the same.",
                    "label": 0
                },
                {
                    "sent": "They are equivalent.",
                    "label": 0
                },
                {
                    "sent": "Yes, yes you're right.",
                    "label": 0
                },
                {
                    "sent": "Yeah yeah, but still it would leave me with processes that have state dependent diffusion and they are not so easy to handle.",
                    "label": 0
                },
                {
                    "sent": "So I sort of.",
                    "label": 0
                },
                {
                    "sent": "I mean I was forced to do Gaussians because Gaussians are the simplest things to deal with.",
                    "label": 0
                },
                {
                    "sent": "As soon as I leave the family of Gaussians things there are not so many nice approximating rich classes of of distribution.",
                    "label": 0
                },
                {
                    "sent": "That's the problem we need attract.",
                    "label": 0
                },
                {
                    "sent": "Table class that we can nicely manipulate and do computations with and I think there are not too many that have state dependent.",
                    "label": 0
                },
                {
                    "sent": "Noise.",
                    "label": 0
                },
                {
                    "sent": "Sure, I would bet that diffusion time actually changes when you condition the measurements, but OK, that's not my question.",
                    "label": 0
                },
                {
                    "sent": "How much is that various nonlinear optimization related to so-called statistical linearizations?",
                    "label": 0
                },
                {
                    "sent": "This I to be honest, I don't know what it means statistically narration you would have to explain.",
                    "label": 0
                },
                {
                    "sent": "It is a very common algorithm, but it's not related to extended, filter.",
                    "label": 0
                },
                {
                    "sent": "Well, we described in alright.",
                    "label": 0
                },
                {
                    "sent": "The question is, is what you propose?",
                    "label": 0
                },
                {
                    "sent": "Is it a local type of sort of adjustment, a local approximation?",
                    "label": 0
                },
                {
                    "sent": "This is sort of a global one.",
                    "label": 0
                },
                {
                    "sent": "It looks at the entire path and it says OK, that here's a here's a functional.",
                    "label": 0
                },
                {
                    "sent": "I mean, I think maybe this would explain it.",
                    "label": 0
                },
                {
                    "sent": "The function of the kullback Leiber that we're using.",
                    "label": 0
                },
                {
                    "sent": "It looks at the process two processes, so that along the entire path, so it's not a local type of things.",
                    "label": 0
                },
                {
                    "sent": "Of course, we approximate something with Gaussian, so that means effectively we deal with the linear stochastic differential equation approximating the original one, but.",
                    "label": 0
                },
                {
                    "sent": "The measure that we use for closeness takes into account the entire path, and I'm not sure if this would be done in stochastic linearization, but probably you have.",
                    "label": 0
                },
                {
                    "sent": "Have you looked into the?",
                    "label": 0
                },
                {
                    "sent": "Essentially it's very close.",
                    "label": 0
                },
                {
                    "sent": "Speak Linearizations except where you have observations so you can rewrite it like statistically very limited.",
                    "label": 0
                },
                {
                    "sent": "The standard way of doing the expectation of the ACE in the beast, but then here you have the direct motion to apply that come into play where you have, yeah.",
                    "label": 0
                },
                {
                    "sent": "It depends on on the whole window, in fact.",
                    "label": 0
                },
                {
                    "sent": "So it's yeah, yeah, so.",
                    "label": 0
                },
                {
                    "sent": "So in the original.",
                    "label": 0
                },
                {
                    "sent": "I mean we we started this we made we derive this callback library and then we try to minimize it.",
                    "label": 0
                },
                {
                    "sent": "But we made them.",
                    "label": 0
                },
                {
                    "sent": "We made a mistake and it looked everything looked very much like Council.",
                    "label": 0
                },
                {
                    "sent": "But then we found out that if we do a variation then there is also approximate propagation of sort of information from the past in from the from the future into the path.",
                    "label": 0
                },
                {
                    "sent": "So there's.",
                    "label": 0
                },
                {
                    "sent": "This thing is nonlocal, this approximation.",
                    "label": 0
                },
                {
                    "sent": "So this is really no system for small thing.",
                    "label": 0
                },
                {
                    "sent": "Also yes yes OK, that is moving, so you would you would believe it's the same.",
                    "label": 0
                },
                {
                    "sent": "I'm not sure, I don't know.",
                    "label": 0
                },
                {
                    "sent": "I think mathematically so these LaGrange multipliers that really take you know the.",
                    "label": 0
                },
                {
                    "sent": "The starting point of the idea is very different, but the equation look.",
                    "label": 0
                },
                {
                    "sent": "The results were similar, so at least could be so in your case is it.",
                    "label": 0
                },
                {
                    "sent": "Is it a one shot type of thing where you have to just solve some backward equation once?",
                    "label": 0
                },
                {
                    "sent": "I mean in our case, we really you know, in order to get the solution we have to sort of iterate backward and forward many times to get this converge.",
                    "label": 0
                },
                {
                    "sent": "I think that got in the statistical.",
                    "label": 0
                },
                {
                    "sent": "Based on kind of discriptive functions so that you have to calculate.",
                    "label": 0
                },
                {
                    "sent": "Something in closed form, but it's possible only for certain types of.",
                    "label": 0
                },
                {
                    "sent": "I think one different.",
                    "label": 0
                },
                {
                    "sent": "One different aspect might be that this opens up the possibility also to go for for further suboptimal types of approximation.",
                    "label": 0
                },
                {
                    "sent": "So you could say I specify my solution but not by by an entire path of functions, but maybe something that I can do in a parametric way.",
                    "label": 0
                },
                {
                    "sent": "Then it can plug it again and I haven't.",
                    "label": 0
                },
                {
                    "sent": "Sort of.",
                    "label": 0
                },
                {
                    "sent": "I have an optimization method, sort of to get the optimal.",
                    "label": 0
                },
                {
                    "sent": "Wait, so This is why we hope in the future we can deal with the better parameterized approximations that have smaller number of parameters and then go to higher dimension.",
                    "label": 0
                },
                {
                    "sent": "So maybe this is not.",
                    "label": 0
                },
                {
                    "sent": "Doable in the other one.",
                    "label": 0
                },
                {
                    "sent": "I'm not sure that's.",
                    "label": 0
                },
                {
                    "sent": "This computer system has many problems 'cause you have to actually calculate something in closed form and this you don't have that data restriction so.",
                    "label": 0
                },
                {
                    "sent": "There are reasons why this collaboration is not very commonly used 'cause it's not so flexible framework.",
                    "label": 0
                },
                {
                    "sent": "OK, so maybe we should then really compare it.",
                    "label": 0
                },
                {
                    "sent": "The mathematics if you want.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        }
    }
}