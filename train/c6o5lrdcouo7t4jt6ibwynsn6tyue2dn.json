{
    "id": "c6o5lrdcouo7t4jt6ibwynsn6tyue2dn",
    "title": "On the Adequacy of Baseform Pronunciations and Pronunciation Variants",
    "info": {
        "author": [
            "Mathew Magimai Doss, IDIAP Research Institute"
        ],
        "published": "Feb. 25, 2007",
        "recorded": "June 2004",
        "category": [
            "Top->Computer Science->Speech Analysis"
        ]
    },
    "url": "http://videolectures.net/mlmi04ch_doss_abppv/",
    "segmentation": [
        [
            "There, so it's basically going to leave us in six months or so so so, but we started working on a new problem and we change the title actually and he doesn't want to give the talk 'cause I decided to give it a slightly different flavor than to full paper.",
            "That would be quite technical.",
            "But since I know that into room, hopefully there are so many representative of the Pascal Network of excellence and this is a joint workshop, and I know that some Pascal people are looking for challenges in machine learning, so I try to turn this story into a little bit of kind of a challenge.",
            "So just busy basically presenting the beginning of an ID that we started to scratch while that Matthew started to scratch under my supervision, and which I find maybe stimulating.",
            "I may also be wrong.",
            "You know the problem in pattern recognition and speech and vision and all the things that we're talking about doing the next day or two day two days, is that how do we evaluate our models?",
            "So we get training data and then we train those models.",
            "And how do we evaluate them as we heard just for Mixi?",
            "Right now?",
            "The only way we know, as far as I know at least, is that we run a recognizer.",
            "You know, recognizing pictures or whatever, or recognizing speech, and we compute error rates.",
            "You know, so is there any way to basically evaluate the quality of models without running a recognizer or without doing much of the work?",
            "So that is that of that work, so there's a little bit of the quest."
        ],
        [
            "That we try to ask ourselves here in terms of pronunciation models you will see that I don't.",
            "I'm not going to get into the details of a speech recognition system.",
            "OK 25 minutes 25.",
            "So this is a complete recognition system with signal processing, likely with local likely destination decoders, and so I'm not going to get into the details that the important point.",
            "Check out the pointer, but this was your own pointer I guess.",
            "OK, it's it's.",
            "It's OK.",
            "Important point that we're going to talk about today is this block here where we have to lexicon, you know we have a lexicon, so you know, recognizers, we have a lexicon which is basically representing all the lexicon words.",
            "Thank you.",
            "In terms of phonetic strings, OK, and this lexicon should reflect many things should reflect the intra and Inter speaker variability as well as the lexical variability including particulation assimilation and so on."
        ],
        [
            "But many things have been tried during the last 10 years or to improve that lexicon and people who work in the field know that this none of them really works very well.",
            "So the first one is to pick the lexicon from a dictionary.",
            "So you're going to a dictionary.",
            "You pick up the phonetic transcription of the world, and you've got your lexicon.",
            "This is very limited and doesn't reflect the pronunciation variants variability.",
            "You can also enrich this lexicon by using some knowledge coming from phonological rules, and then you are going to end, which this lexicon and the third solution is to use data driven approach, so more like machine learning approach where you are going to do.",
            "Try to do some kind of Markov model inference from the reconditioned outputs, so you try to do unsupervised recognition.",
            "You look at the funding strings.",
            "Is a Stefon showed and based on that you try to get a new phonetic model, new electrical model which you are going to retrain and they have been also approaches where you mix all the other hello and you try many things and you include you.",
            "You basically increase the size of your lexicon, you know so you have more models for world and usually it works just a little bit.",
            "It means that you can basically add maybe 1 two word pronunciation variants and after that it starts collapsing for a good reason is that you increase the likelihood of the model.",
            "But at the same time you decrease to discrimination between the words.",
            "Ideally you would like to have a fully connected model you know very rich lexical model for every word, and the likelihood is going to be maximum, but the discrimination capability between the words is going to be minimum at the same time.",
            "So so far we haven't found any reasonable solution to that problem.",
            "So Matthew and I recently we started looking at.",
            "A different proof that the problem."
        ],
        [
            "To a different perspective.",
            "So what we are going to try to do here is to ask ourselves how can we evaluate the stupidest ability?",
            "What I would call the stability of a base form pronunciation model, or what is the stability of my model right?",
            "And once I know to measure the stability of the model, I'm going to hurt myself or can I improve the stability of the model?",
            "You know this is a completely different way of thinking about the model.",
            "Instead of evaluating the model by recognition, I would like to know there is some new theories around.",
            "Siri, you know you want to go to a little bit of model and see oh good is it for all stable?",
            "Is it or is it going to diverge easier?",
            "Recognition, performance.",
            "Way to divert this soon as you start changing a little bit.",
            "Over bits to your model, you know.",
            "So how to evaluate the stability?",
            "How to improve the stability and basically we end up with a system where we can evaluate the lexical models without looking at the recognition rate at all.",
            "So this is the goal of our work, and as I said, we just started scratching the surface."
        ],
        [
            "Is it something that we are going to use in this world?",
            "But it's not really mandatory to understand it to understand the rest of the work, but it's kind of interesting also to know is that in this work we're also going to use the notion of auxiliary variable, something that is very important to know in statistics is that sometimes it is important to add a new variable to improve your model, but you should not add the new variable as an observer.",
            "Valuable, but there's a conditional variable and in statistics this changes completely.",
            "Your multiway you model things.",
            "So instead of so the standard way also in pattern recognition to make a model work better.",
            "I know two ways and I can listen to thousands of talk about it all the time.",
            "The first one is to change the features so that it better better match tomorrow.",
            "So this is the low level process or people are changing the features and they showed their features work better for a given model we have to modeling guys.",
            "They don't touch the features and they change the baseball topologies.",
            "They change the lexicon to try to have the lexicon.",
            "Matching the features that they forgot that this term solution is actually you keep to the lexical model as it is to accuse there the sequence of phonemes.",
            "But basically the probability density function.",
            "I don't want to be technical, but this this likelihood is going to be conditional, yet by an additional variable here, which is going to be hidden which is so exhilarating valuable for people knowing about speech recognition is what is being successful.",
            "When we did general modeling, male or female.",
            "In that case, it's easy because the A there is basically discrete variable which can only take two values and it's easy.",
            "What happens when we have continuous values there, but this is."
        ],
        [
            "Not the topic of the tour, but we know to do it and we used to do it.",
            "OK, so let's come back to the core of the opportunity.",
            "Stability of lexical model.",
            "So what we are going to ask ourselves is when decoding a lexical entity to a perturb hmm topology.",
            "Oh merge all fast.",
            "Does the infer from the transcription is going to change?",
            "So your case, the preservation is going to basically relaxing a constraint HMM and moving it slowly to an unconstrained hmm.",
            "So basically we're going to move from left to right based on phonetic transcription to a fully connected ergotic Markov model, which is none of them at the optimal solution.",
            "But we're going to look for the solution in between where the model is more stable.",
            "OK, and just a PDT is going to be measure in terms of two parameters and I'll show you what it means in the in the in the next slide confidence measure we have to talk about confidence measure so it's related to what Steven Cook mentioned.",
            "So we also know how to compute confidence measures and so on and so on of decoded phoneme sequences and the second measure is going to be delivering distance between the new.",
            "Pronunciation model and the baseball.",
            "So basically I want to increase the confidence measure of my inferred model while keeping to leverage time distance between the dictionary model and my new model.",
            "I want to keep the distance minimum, so I want to maximize the confidence measure, minimize delivers time distance.",
            "So basically what we do here?"
        ],
        [
            "So we start from.",
            "Suppose if you ever left or right funny model to work at is C-80 left or right, three phonemes, so it's a Markov model describing the pronunciation of the word cap, C. 80.",
            "That model can be approximated by a bigram.",
            "Phonetic model, so this is the bigram approximation of the world cat.",
            "So if I have a faulty phoneme, see I have a 40 * 40 transition matrix, but I'm only going to use like a subset of the transition matrix representing the transition between 2 forms.",
            "OK, that are allowed into work at, except it now in my model I have a little epsilon here, which you may or may not read at the back of the room there, but this matrix is the interesting property that if epsilon is equal to Infinity.",
            "This gives me the baseline model, so left to right model and when I'm going to decrease the epsilon toward zero, I'm going to relax my model in my model is going to converge more and more towards an Eggo Dick model where I have all possible phonemes following all possible forms.",
            "So it's it's a unigram phoneme language model.",
            "OK, so basically I start with the base form and then I'm going to relax the epsilon.",
            "I'm going to relax the the model slowly and for each epsilon value I'm going to test all stable.",
            "My new model is.",
            "OK, so I'm going to put up.",
            "The model is basically if I start moving the epsilon from Infinity to zero and phonetic transcription generated from the training data is still to work at C-80.",
            "My model is very stable, I don't need pronunciation violence.",
            "I have a very stable model because whatever flexibility I give you, the model is still going to use the constraint model.",
            "OK, now if I increase, decrease the epsilon and start generating other pronunciation variants, it means that my model is not stable."
        ],
        [
            "So this is typically the two pictures that you are going to get.",
            "An example of a stable model and an example for unstable model stable model.",
            "I don't know which Rd disease I start from.",
            "The lexical model is given by the dictionary with a value of epsilon equal to, well, something Infinity here.",
            "So this is the base form and I'm going to start decreasing the epsilon and so I relaxed my motor and here I am already like a negative model so.",
            "I have a model with all phone is connected, but I'm still recognizing the base for transcription.",
            "So this model is very stable and actually delivering distance between the inferred model and the base for model is 0 until a certain point.",
            "Of course we're at the movies 2 flexible and start diverging in terms of leverage time, distance and of course the likelihood is increasing likelihood is increasing.",
            "Confidence measure is increasing, but confidence measure doesn't mean improving recognition rate.",
            "So typically I would like to stop here.",
            "So I would like to stop at the model which is as general as possible in terms of transition.",
            "Probability is very close to a negative model but still very stable.",
            "This will be an example where the motor is very unstable, at least the base form transcription is very unstable and I have to apply a several steps of relaxation before I reach some kind of plateau.",
            "Here you know with good confidence level and reasonable leverage and distance, which in this case is for me that I had to change my baseball model.",
            "I have to make 4 edit changes to my base form.",
            "Transcription to get a stable model.",
            "Interestingly enough, you see that the confidence level you may not be able to read it there makes very little sense.",
            "You know, in a stable model, even from the beginning, the confidence level is already above .5.",
            "This is a real value.",
            "I don't tell you how we compute confidence scores is going to be in the full paper, but these bases you can interpret it as kind of the average posterior probability over the whole passes above .5 all the time.",
            "He is home too and we have to it's .2 yeah and then we have to do something to the baseball mode.",
            "Also raise it to something close to .5 and .5 as a confidence measure is pretty good since in confidence measure we have two hypothesis.",
            "It is a good model or it is why it is a good recognition or it is not a good recognition, right, valid or invalid.",
            "So it's two hypothesis.",
            "So as soon as I am close or harbor .5 it's very good and this is what's happening here automatically."
        ],
        [
            "I'm going to skip this life because time is running for five minutes.",
            "OK, OK, so but this this is what happens with auxiliary variable.",
            "I'm going to skip this slide.",
            "It may be a little bit too technical, but you see that it gets already much better.",
            "So my model, even the unstable one, suddenly is already most stable, very quickly, more stable if I have an additional auxiliary variable.",
            "So you see, the idea is to make the model most stable without changing the lexical transcription.",
            "And I can go a little bit further by adding an auxiliary variable into a probability density function.",
            "OK, that's the idea, OK?"
        ],
        [
            "Couple of things very Mens.",
            "Although this is not really necessary at this stage I would say because this is just crashed ship scratching with just the surface of the problem but just to show you that this is feasible.",
            "So we were with database called phone book where this is a large well kind of large database except it is it's activated world so far 600 words.",
            "The usual speci stuff there, so the usual state of the art features 21 dimensional MFCC features and Delta features and so on.",
            "So large training, set validation set development is set, and the actual test set on which we are reporting perform."
        ],
        [
            "And this is what we are getting.",
            "Basically relaxing to models that are not stable.",
            "You know where we picked and what are the only the models that table you know?",
            "Then we go as far as we can in terms of being so having a model that is stable but also as general as possible.",
            "So there's the idea.",
            "So 4 out of 606 hundred 2 words 441 didn't need alternate alternate pronunciation.",
            "106 words needed to pronunciation 48 words in the tree, 7 words needed, four pronunciation.",
            "So we had total lexical form of 825.",
            "Different lexical form to represent 602 words."
        ],
        [
            "And these were the recognition performance and in any good to talk on speech you know you always have the final slide it in nice table and showing that your metal works and also to get better recognition results.",
            "And this is the case here.",
            "So with the original lexiko.",
            "You know Ann.",
            "With this updated lexicon by using our new approach to create violence.",
            "So value, alternate pronunciation models and each time I think it's quite significant, quite, very significant performance improvement for small lexicon as well As for laugh lexica.",
            "Again, this is just preliminary work, and it needs much more work."
        ],
        [
            "Especially on spontaneous speech, and this is something that we certainly do next, but Matthew hope that he will be graduated so we can leave this up to someone else.",
            "But thank you for your attention."
        ],
        [
            "How many questions?",
            "Two others.",
            "Well.",
            "So how does heritage credit your?",
            "WHI WHI is taking multiple things into this application to having some sort of complexity prior?",
            "Answer second question Rd.",
            "Well said, he's acting this one too.",
            "Like no I would like to have a model that he says general is possible that can accommodate based measures availability to the feature in the features.",
            "So the model which is a general is possible, but we've already generated the same phonetic transcription.",
            "Whatever noise in the input is.",
            "So therefore I am measuring.",
            "But instead of playing with noisy inputs angry with Posey, hmm.",
            "I'm going to take the one that is more than my whole day.",
            "Most of the rivalry.",
            "In the in sequence.",
            "But is this playing a different role for description of this has to be investigated, yeah?",
            "Description like trials.",
            "Basically you did prior to Super Bowl.",
            "Here will try to give higher priority to more complex forms.",
            "As long as they are stable.",
            "So I guess my question is this stability have a correlation with simplicity?",
            "Maybe in the books?",
            "Now some linear model is more stable than some horrible polynomial thing, right so?",
            "Yeah, but it's not going to be robbers too.",
            "In recognition is not going to be robust, you know, so there's no.",
            "You don't have a good model, usually no model, so of course it is.",
            "It's simpler, it may be more stable and some training data, but during recognition is not going to be in good condition with metal.",
            "So if you use a liter motor or a simple model during recognition we get pre conditional then we say OK let's try and only know model and so you go to a more complex model and then you see work.",
            "So here we are trying to find new approaches where you don't have to do recognition to know in advance whether your model is this going to be stable or ruffles or not.",
            "I think I think.",
            "I asked my question whether you saw a correlation between the stability and the length of the the pronunciations of the word.",
            "Was not able to measure the pronunciation of the word.",
            "Yeah, so I was wondering that the other thing I was wondering is if you looked at the words that needed extra pronunciations?",
            "Yeah, did you see anything about them?",
            "That was when I think Matthews would answer the question, is it?",
            "Cancel.",
            "Starbucks.",
            "For the short bus this morning.",
            "David versus #2010 season differently.",
            "So again, this was a little bit of a kind of a boost with the machine learning people, so it's I think there is really a lot of work to be done in order to evaluate models without doing recognition, and we know of course is related to regularization.",
            "I hear that the Steve mentioned and so it's also we enter ticket in complexity of the model and so on, but I really would like to have a Model S complex as possible which is going to generalize well to test data, right?",
            "And we want to evaluate them without looking at the test data.",
            "So this is the problem that we're trying to address here.",
            "Start.",
            "In some way so we can check I was going to ask whether it's when you were evaluating the complexity where you're looking at a healthy outside?",
            "Or did you look at the training data or so to cuz I put there or looking at?",
            "Well so when you are deciding whether to add new pronunciations and you're looking at the so this was also mentioned elopement data I guess.",
            "Later, the phone book excitement, what do you say it like that instead?",
            "And the relation in this set up early independence?",
            "The words because other than that.",
            "So what we did was displayed at the test set into like speakers.",
            "So there he's what is spoken backwards speakers.",
            "So we could like 45% of the data for the government said, and the underlying that have used like kind of day.",
            "So you don't want to pay someone figure out once we got on the plane, indecision.",
            "So we need to make sure and see if it's it's like that.",
            "So and then update on that, reset it, then, then then said was not adding any speaker who was that we have looked instead at all.",
            "And then how do you?",
            "So it's a little bit question was very kind of very controversial and very tricky, and so you know there is a very abusive and abusive relationship with complexity theory, but it looks like what we are doing here goes against complexity theory because instead of looking for the simplest model, we are trying to look for the most complex model which is going to generalize working together.",
            "Is he?",
            "Yeah, my family transcription.",
            "You know for work could be a fully connected everything model containing all the fun and just rely on the initial probabilities so that this model is going to output to work at.",
            "If I say cat and dog if I say dog right?",
            "That would be the ideal model and it's very complex.",
            "So where can we?",
            "How can we go between the baseline transcription very linear left or right to the very complex model?",
            "What is solution in between?",
            "Final question.",
            "Over there we thought doing recognition yeah.",
            "Now I can be active sampling some simple.",
            "I think the adjectives complex and simple or inverted.",
            "Here the completely connection model.",
            "I think it's a simple swap.",
            "Yeah, in terms of behavior, most components that are good, that's good.",
            "I will remember that.",
            "So that's a very good answer.",
            "Yeah, we have because we are moving from bigram to unigrams, but there are more parameters.",
            "It's it's simple demo.",
            "OK well."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "There, so it's basically going to leave us in six months or so so so, but we started working on a new problem and we change the title actually and he doesn't want to give the talk 'cause I decided to give it a slightly different flavor than to full paper.",
                    "label": 0
                },
                {
                    "sent": "That would be quite technical.",
                    "label": 0
                },
                {
                    "sent": "But since I know that into room, hopefully there are so many representative of the Pascal Network of excellence and this is a joint workshop, and I know that some Pascal people are looking for challenges in machine learning, so I try to turn this story into a little bit of kind of a challenge.",
                    "label": 0
                },
                {
                    "sent": "So just busy basically presenting the beginning of an ID that we started to scratch while that Matthew started to scratch under my supervision, and which I find maybe stimulating.",
                    "label": 0
                },
                {
                    "sent": "I may also be wrong.",
                    "label": 0
                },
                {
                    "sent": "You know the problem in pattern recognition and speech and vision and all the things that we're talking about doing the next day or two day two days, is that how do we evaluate our models?",
                    "label": 0
                },
                {
                    "sent": "So we get training data and then we train those models.",
                    "label": 0
                },
                {
                    "sent": "And how do we evaluate them as we heard just for Mixi?",
                    "label": 0
                },
                {
                    "sent": "Right now?",
                    "label": 0
                },
                {
                    "sent": "The only way we know, as far as I know at least, is that we run a recognizer.",
                    "label": 0
                },
                {
                    "sent": "You know, recognizing pictures or whatever, or recognizing speech, and we compute error rates.",
                    "label": 0
                },
                {
                    "sent": "You know, so is there any way to basically evaluate the quality of models without running a recognizer or without doing much of the work?",
                    "label": 0
                },
                {
                    "sent": "So that is that of that work, so there's a little bit of the quest.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "That we try to ask ourselves here in terms of pronunciation models you will see that I don't.",
                    "label": 0
                },
                {
                    "sent": "I'm not going to get into the details of a speech recognition system.",
                    "label": 0
                },
                {
                    "sent": "OK 25 minutes 25.",
                    "label": 0
                },
                {
                    "sent": "So this is a complete recognition system with signal processing, likely with local likely destination decoders, and so I'm not going to get into the details that the important point.",
                    "label": 0
                },
                {
                    "sent": "Check out the pointer, but this was your own pointer I guess.",
                    "label": 0
                },
                {
                    "sent": "OK, it's it's.",
                    "label": 0
                },
                {
                    "sent": "It's OK.",
                    "label": 0
                },
                {
                    "sent": "Important point that we're going to talk about today is this block here where we have to lexicon, you know we have a lexicon, so you know, recognizers, we have a lexicon which is basically representing all the lexicon words.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                },
                {
                    "sent": "In terms of phonetic strings, OK, and this lexicon should reflect many things should reflect the intra and Inter speaker variability as well as the lexical variability including particulation assimilation and so on.",
                    "label": 1
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "But many things have been tried during the last 10 years or to improve that lexicon and people who work in the field know that this none of them really works very well.",
                    "label": 0
                },
                {
                    "sent": "So the first one is to pick the lexicon from a dictionary.",
                    "label": 0
                },
                {
                    "sent": "So you're going to a dictionary.",
                    "label": 0
                },
                {
                    "sent": "You pick up the phonetic transcription of the world, and you've got your lexicon.",
                    "label": 1
                },
                {
                    "sent": "This is very limited and doesn't reflect the pronunciation variants variability.",
                    "label": 0
                },
                {
                    "sent": "You can also enrich this lexicon by using some knowledge coming from phonological rules, and then you are going to end, which this lexicon and the third solution is to use data driven approach, so more like machine learning approach where you are going to do.",
                    "label": 1
                },
                {
                    "sent": "Try to do some kind of Markov model inference from the reconditioned outputs, so you try to do unsupervised recognition.",
                    "label": 0
                },
                {
                    "sent": "You look at the funding strings.",
                    "label": 0
                },
                {
                    "sent": "Is a Stefon showed and based on that you try to get a new phonetic model, new electrical model which you are going to retrain and they have been also approaches where you mix all the other hello and you try many things and you include you.",
                    "label": 0
                },
                {
                    "sent": "You basically increase the size of your lexicon, you know so you have more models for world and usually it works just a little bit.",
                    "label": 0
                },
                {
                    "sent": "It means that you can basically add maybe 1 two word pronunciation variants and after that it starts collapsing for a good reason is that you increase the likelihood of the model.",
                    "label": 0
                },
                {
                    "sent": "But at the same time you decrease to discrimination between the words.",
                    "label": 0
                },
                {
                    "sent": "Ideally you would like to have a fully connected model you know very rich lexical model for every word, and the likelihood is going to be maximum, but the discrimination capability between the words is going to be minimum at the same time.",
                    "label": 0
                },
                {
                    "sent": "So so far we haven't found any reasonable solution to that problem.",
                    "label": 0
                },
                {
                    "sent": "So Matthew and I recently we started looking at.",
                    "label": 0
                },
                {
                    "sent": "A different proof that the problem.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "To a different perspective.",
                    "label": 0
                },
                {
                    "sent": "So what we are going to try to do here is to ask ourselves how can we evaluate the stupidest ability?",
                    "label": 0
                },
                {
                    "sent": "What I would call the stability of a base form pronunciation model, or what is the stability of my model right?",
                    "label": 1
                },
                {
                    "sent": "And once I know to measure the stability of the model, I'm going to hurt myself or can I improve the stability of the model?",
                    "label": 0
                },
                {
                    "sent": "You know this is a completely different way of thinking about the model.",
                    "label": 0
                },
                {
                    "sent": "Instead of evaluating the model by recognition, I would like to know there is some new theories around.",
                    "label": 0
                },
                {
                    "sent": "Siri, you know you want to go to a little bit of model and see oh good is it for all stable?",
                    "label": 0
                },
                {
                    "sent": "Is it or is it going to diverge easier?",
                    "label": 0
                },
                {
                    "sent": "Recognition, performance.",
                    "label": 0
                },
                {
                    "sent": "Way to divert this soon as you start changing a little bit.",
                    "label": 0
                },
                {
                    "sent": "Over bits to your model, you know.",
                    "label": 0
                },
                {
                    "sent": "So how to evaluate the stability?",
                    "label": 0
                },
                {
                    "sent": "How to improve the stability and basically we end up with a system where we can evaluate the lexical models without looking at the recognition rate at all.",
                    "label": 1
                },
                {
                    "sent": "So this is the goal of our work, and as I said, we just started scratching the surface.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Is it something that we are going to use in this world?",
                    "label": 0
                },
                {
                    "sent": "But it's not really mandatory to understand it to understand the rest of the work, but it's kind of interesting also to know is that in this work we're also going to use the notion of auxiliary variable, something that is very important to know in statistics is that sometimes it is important to add a new variable to improve your model, but you should not add the new variable as an observer.",
                    "label": 0
                },
                {
                    "sent": "Valuable, but there's a conditional variable and in statistics this changes completely.",
                    "label": 1
                },
                {
                    "sent": "Your multiway you model things.",
                    "label": 1
                },
                {
                    "sent": "So instead of so the standard way also in pattern recognition to make a model work better.",
                    "label": 0
                },
                {
                    "sent": "I know two ways and I can listen to thousands of talk about it all the time.",
                    "label": 0
                },
                {
                    "sent": "The first one is to change the features so that it better better match tomorrow.",
                    "label": 0
                },
                {
                    "sent": "So this is the low level process or people are changing the features and they showed their features work better for a given model we have to modeling guys.",
                    "label": 0
                },
                {
                    "sent": "They don't touch the features and they change the baseball topologies.",
                    "label": 1
                },
                {
                    "sent": "They change the lexicon to try to have the lexicon.",
                    "label": 0
                },
                {
                    "sent": "Matching the features that they forgot that this term solution is actually you keep to the lexical model as it is to accuse there the sequence of phonemes.",
                    "label": 0
                },
                {
                    "sent": "But basically the probability density function.",
                    "label": 0
                },
                {
                    "sent": "I don't want to be technical, but this this likelihood is going to be conditional, yet by an additional variable here, which is going to be hidden which is so exhilarating valuable for people knowing about speech recognition is what is being successful.",
                    "label": 0
                },
                {
                    "sent": "When we did general modeling, male or female.",
                    "label": 0
                },
                {
                    "sent": "In that case, it's easy because the A there is basically discrete variable which can only take two values and it's easy.",
                    "label": 0
                },
                {
                    "sent": "What happens when we have continuous values there, but this is.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Not the topic of the tour, but we know to do it and we used to do it.",
                    "label": 0
                },
                {
                    "sent": "OK, so let's come back to the core of the opportunity.",
                    "label": 0
                },
                {
                    "sent": "Stability of lexical model.",
                    "label": 0
                },
                {
                    "sent": "So what we are going to ask ourselves is when decoding a lexical entity to a perturb hmm topology.",
                    "label": 0
                },
                {
                    "sent": "Oh merge all fast.",
                    "label": 0
                },
                {
                    "sent": "Does the infer from the transcription is going to change?",
                    "label": 0
                },
                {
                    "sent": "So your case, the preservation is going to basically relaxing a constraint HMM and moving it slowly to an unconstrained hmm.",
                    "label": 0
                },
                {
                    "sent": "So basically we're going to move from left to right based on phonetic transcription to a fully connected ergotic Markov model, which is none of them at the optimal solution.",
                    "label": 0
                },
                {
                    "sent": "But we're going to look for the solution in between where the model is more stable.",
                    "label": 0
                },
                {
                    "sent": "OK, and just a PDT is going to be measure in terms of two parameters and I'll show you what it means in the in the in the next slide confidence measure we have to talk about confidence measure so it's related to what Steven Cook mentioned.",
                    "label": 0
                },
                {
                    "sent": "So we also know how to compute confidence measures and so on and so on of decoded phoneme sequences and the second measure is going to be delivering distance between the new.",
                    "label": 0
                },
                {
                    "sent": "Pronunciation model and the baseball.",
                    "label": 0
                },
                {
                    "sent": "So basically I want to increase the confidence measure of my inferred model while keeping to leverage time distance between the dictionary model and my new model.",
                    "label": 0
                },
                {
                    "sent": "I want to keep the distance minimum, so I want to maximize the confidence measure, minimize delivers time distance.",
                    "label": 0
                },
                {
                    "sent": "So basically what we do here?",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we start from.",
                    "label": 0
                },
                {
                    "sent": "Suppose if you ever left or right funny model to work at is C-80 left or right, three phonemes, so it's a Markov model describing the pronunciation of the word cap, C. 80.",
                    "label": 0
                },
                {
                    "sent": "That model can be approximated by a bigram.",
                    "label": 0
                },
                {
                    "sent": "Phonetic model, so this is the bigram approximation of the world cat.",
                    "label": 0
                },
                {
                    "sent": "So if I have a faulty phoneme, see I have a 40 * 40 transition matrix, but I'm only going to use like a subset of the transition matrix representing the transition between 2 forms.",
                    "label": 0
                },
                {
                    "sent": "OK, that are allowed into work at, except it now in my model I have a little epsilon here, which you may or may not read at the back of the room there, but this matrix is the interesting property that if epsilon is equal to Infinity.",
                    "label": 0
                },
                {
                    "sent": "This gives me the baseline model, so left to right model and when I'm going to decrease the epsilon toward zero, I'm going to relax my model in my model is going to converge more and more towards an Eggo Dick model where I have all possible phonemes following all possible forms.",
                    "label": 0
                },
                {
                    "sent": "So it's it's a unigram phoneme language model.",
                    "label": 1
                },
                {
                    "sent": "OK, so basically I start with the base form and then I'm going to relax the epsilon.",
                    "label": 0
                },
                {
                    "sent": "I'm going to relax the the model slowly and for each epsilon value I'm going to test all stable.",
                    "label": 0
                },
                {
                    "sent": "My new model is.",
                    "label": 0
                },
                {
                    "sent": "OK, so I'm going to put up.",
                    "label": 0
                },
                {
                    "sent": "The model is basically if I start moving the epsilon from Infinity to zero and phonetic transcription generated from the training data is still to work at C-80.",
                    "label": 0
                },
                {
                    "sent": "My model is very stable, I don't need pronunciation violence.",
                    "label": 0
                },
                {
                    "sent": "I have a very stable model because whatever flexibility I give you, the model is still going to use the constraint model.",
                    "label": 0
                },
                {
                    "sent": "OK, now if I increase, decrease the epsilon and start generating other pronunciation variants, it means that my model is not stable.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is typically the two pictures that you are going to get.",
                    "label": 0
                },
                {
                    "sent": "An example of a stable model and an example for unstable model stable model.",
                    "label": 0
                },
                {
                    "sent": "I don't know which Rd disease I start from.",
                    "label": 0
                },
                {
                    "sent": "The lexical model is given by the dictionary with a value of epsilon equal to, well, something Infinity here.",
                    "label": 0
                },
                {
                    "sent": "So this is the base form and I'm going to start decreasing the epsilon and so I relaxed my motor and here I am already like a negative model so.",
                    "label": 0
                },
                {
                    "sent": "I have a model with all phone is connected, but I'm still recognizing the base for transcription.",
                    "label": 0
                },
                {
                    "sent": "So this model is very stable and actually delivering distance between the inferred model and the base for model is 0 until a certain point.",
                    "label": 0
                },
                {
                    "sent": "Of course we're at the movies 2 flexible and start diverging in terms of leverage time, distance and of course the likelihood is increasing likelihood is increasing.",
                    "label": 0
                },
                {
                    "sent": "Confidence measure is increasing, but confidence measure doesn't mean improving recognition rate.",
                    "label": 0
                },
                {
                    "sent": "So typically I would like to stop here.",
                    "label": 0
                },
                {
                    "sent": "So I would like to stop at the model which is as general as possible in terms of transition.",
                    "label": 0
                },
                {
                    "sent": "Probability is very close to a negative model but still very stable.",
                    "label": 0
                },
                {
                    "sent": "This will be an example where the motor is very unstable, at least the base form transcription is very unstable and I have to apply a several steps of relaxation before I reach some kind of plateau.",
                    "label": 0
                },
                {
                    "sent": "Here you know with good confidence level and reasonable leverage and distance, which in this case is for me that I had to change my baseball model.",
                    "label": 0
                },
                {
                    "sent": "I have to make 4 edit changes to my base form.",
                    "label": 0
                },
                {
                    "sent": "Transcription to get a stable model.",
                    "label": 0
                },
                {
                    "sent": "Interestingly enough, you see that the confidence level you may not be able to read it there makes very little sense.",
                    "label": 0
                },
                {
                    "sent": "You know, in a stable model, even from the beginning, the confidence level is already above .5.",
                    "label": 0
                },
                {
                    "sent": "This is a real value.",
                    "label": 0
                },
                {
                    "sent": "I don't tell you how we compute confidence scores is going to be in the full paper, but these bases you can interpret it as kind of the average posterior probability over the whole passes above .5 all the time.",
                    "label": 0
                },
                {
                    "sent": "He is home too and we have to it's .2 yeah and then we have to do something to the baseball mode.",
                    "label": 0
                },
                {
                    "sent": "Also raise it to something close to .5 and .5 as a confidence measure is pretty good since in confidence measure we have two hypothesis.",
                    "label": 0
                },
                {
                    "sent": "It is a good model or it is why it is a good recognition or it is not a good recognition, right, valid or invalid.",
                    "label": 0
                },
                {
                    "sent": "So it's two hypothesis.",
                    "label": 0
                },
                {
                    "sent": "So as soon as I am close or harbor .5 it's very good and this is what's happening here automatically.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I'm going to skip this life because time is running for five minutes.",
                    "label": 0
                },
                {
                    "sent": "OK, OK, so but this this is what happens with auxiliary variable.",
                    "label": 0
                },
                {
                    "sent": "I'm going to skip this slide.",
                    "label": 0
                },
                {
                    "sent": "It may be a little bit too technical, but you see that it gets already much better.",
                    "label": 0
                },
                {
                    "sent": "So my model, even the unstable one, suddenly is already most stable, very quickly, more stable if I have an additional auxiliary variable.",
                    "label": 0
                },
                {
                    "sent": "So you see, the idea is to make the model most stable without changing the lexical transcription.",
                    "label": 0
                },
                {
                    "sent": "And I can go a little bit further by adding an auxiliary variable into a probability density function.",
                    "label": 0
                },
                {
                    "sent": "OK, that's the idea, OK?",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Couple of things very Mens.",
                    "label": 0
                },
                {
                    "sent": "Although this is not really necessary at this stage I would say because this is just crashed ship scratching with just the surface of the problem but just to show you that this is feasible.",
                    "label": 0
                },
                {
                    "sent": "So we were with database called phone book where this is a large well kind of large database except it is it's activated world so far 600 words.",
                    "label": 0
                },
                {
                    "sent": "The usual speci stuff there, so the usual state of the art features 21 dimensional MFCC features and Delta features and so on.",
                    "label": 1
                },
                {
                    "sent": "So large training, set validation set development is set, and the actual test set on which we are reporting perform.",
                    "label": 1
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And this is what we are getting.",
                    "label": 0
                },
                {
                    "sent": "Basically relaxing to models that are not stable.",
                    "label": 0
                },
                {
                    "sent": "You know where we picked and what are the only the models that table you know?",
                    "label": 0
                },
                {
                    "sent": "Then we go as far as we can in terms of being so having a model that is stable but also as general as possible.",
                    "label": 0
                },
                {
                    "sent": "So there's the idea.",
                    "label": 0
                },
                {
                    "sent": "So 4 out of 606 hundred 2 words 441 didn't need alternate alternate pronunciation.",
                    "label": 0
                },
                {
                    "sent": "106 words needed to pronunciation 48 words in the tree, 7 words needed, four pronunciation.",
                    "label": 0
                },
                {
                    "sent": "So we had total lexical form of 825.",
                    "label": 1
                },
                {
                    "sent": "Different lexical form to represent 602 words.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And these were the recognition performance and in any good to talk on speech you know you always have the final slide it in nice table and showing that your metal works and also to get better recognition results.",
                    "label": 0
                },
                {
                    "sent": "And this is the case here.",
                    "label": 0
                },
                {
                    "sent": "So with the original lexiko.",
                    "label": 0
                },
                {
                    "sent": "You know Ann.",
                    "label": 0
                },
                {
                    "sent": "With this updated lexicon by using our new approach to create violence.",
                    "label": 0
                },
                {
                    "sent": "So value, alternate pronunciation models and each time I think it's quite significant, quite, very significant performance improvement for small lexicon as well As for laugh lexica.",
                    "label": 0
                },
                {
                    "sent": "Again, this is just preliminary work, and it needs much more work.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Especially on spontaneous speech, and this is something that we certainly do next, but Matthew hope that he will be graduated so we can leave this up to someone else.",
                    "label": 0
                },
                {
                    "sent": "But thank you for your attention.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "How many questions?",
                    "label": 0
                },
                {
                    "sent": "Two others.",
                    "label": 0
                },
                {
                    "sent": "Well.",
                    "label": 0
                },
                {
                    "sent": "So how does heritage credit your?",
                    "label": 0
                },
                {
                    "sent": "WHI WHI is taking multiple things into this application to having some sort of complexity prior?",
                    "label": 0
                },
                {
                    "sent": "Answer second question Rd.",
                    "label": 0
                },
                {
                    "sent": "Well said, he's acting this one too.",
                    "label": 0
                },
                {
                    "sent": "Like no I would like to have a model that he says general is possible that can accommodate based measures availability to the feature in the features.",
                    "label": 0
                },
                {
                    "sent": "So the model which is a general is possible, but we've already generated the same phonetic transcription.",
                    "label": 0
                },
                {
                    "sent": "Whatever noise in the input is.",
                    "label": 0
                },
                {
                    "sent": "So therefore I am measuring.",
                    "label": 0
                },
                {
                    "sent": "But instead of playing with noisy inputs angry with Posey, hmm.",
                    "label": 0
                },
                {
                    "sent": "I'm going to take the one that is more than my whole day.",
                    "label": 0
                },
                {
                    "sent": "Most of the rivalry.",
                    "label": 0
                },
                {
                    "sent": "In the in sequence.",
                    "label": 0
                },
                {
                    "sent": "But is this playing a different role for description of this has to be investigated, yeah?",
                    "label": 0
                },
                {
                    "sent": "Description like trials.",
                    "label": 0
                },
                {
                    "sent": "Basically you did prior to Super Bowl.",
                    "label": 0
                },
                {
                    "sent": "Here will try to give higher priority to more complex forms.",
                    "label": 0
                },
                {
                    "sent": "As long as they are stable.",
                    "label": 0
                },
                {
                    "sent": "So I guess my question is this stability have a correlation with simplicity?",
                    "label": 0
                },
                {
                    "sent": "Maybe in the books?",
                    "label": 0
                },
                {
                    "sent": "Now some linear model is more stable than some horrible polynomial thing, right so?",
                    "label": 0
                },
                {
                    "sent": "Yeah, but it's not going to be robbers too.",
                    "label": 0
                },
                {
                    "sent": "In recognition is not going to be robust, you know, so there's no.",
                    "label": 0
                },
                {
                    "sent": "You don't have a good model, usually no model, so of course it is.",
                    "label": 0
                },
                {
                    "sent": "It's simpler, it may be more stable and some training data, but during recognition is not going to be in good condition with metal.",
                    "label": 0
                },
                {
                    "sent": "So if you use a liter motor or a simple model during recognition we get pre conditional then we say OK let's try and only know model and so you go to a more complex model and then you see work.",
                    "label": 0
                },
                {
                    "sent": "So here we are trying to find new approaches where you don't have to do recognition to know in advance whether your model is this going to be stable or ruffles or not.",
                    "label": 0
                },
                {
                    "sent": "I think I think.",
                    "label": 0
                },
                {
                    "sent": "I asked my question whether you saw a correlation between the stability and the length of the the pronunciations of the word.",
                    "label": 0
                },
                {
                    "sent": "Was not able to measure the pronunciation of the word.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so I was wondering that the other thing I was wondering is if you looked at the words that needed extra pronunciations?",
                    "label": 0
                },
                {
                    "sent": "Yeah, did you see anything about them?",
                    "label": 0
                },
                {
                    "sent": "That was when I think Matthews would answer the question, is it?",
                    "label": 0
                },
                {
                    "sent": "Cancel.",
                    "label": 0
                },
                {
                    "sent": "Starbucks.",
                    "label": 0
                },
                {
                    "sent": "For the short bus this morning.",
                    "label": 0
                },
                {
                    "sent": "David versus #2010 season differently.",
                    "label": 0
                },
                {
                    "sent": "So again, this was a little bit of a kind of a boost with the machine learning people, so it's I think there is really a lot of work to be done in order to evaluate models without doing recognition, and we know of course is related to regularization.",
                    "label": 0
                },
                {
                    "sent": "I hear that the Steve mentioned and so it's also we enter ticket in complexity of the model and so on, but I really would like to have a Model S complex as possible which is going to generalize well to test data, right?",
                    "label": 0
                },
                {
                    "sent": "And we want to evaluate them without looking at the test data.",
                    "label": 0
                },
                {
                    "sent": "So this is the problem that we're trying to address here.",
                    "label": 0
                },
                {
                    "sent": "Start.",
                    "label": 0
                },
                {
                    "sent": "In some way so we can check I was going to ask whether it's when you were evaluating the complexity where you're looking at a healthy outside?",
                    "label": 0
                },
                {
                    "sent": "Or did you look at the training data or so to cuz I put there or looking at?",
                    "label": 0
                },
                {
                    "sent": "Well so when you are deciding whether to add new pronunciations and you're looking at the so this was also mentioned elopement data I guess.",
                    "label": 0
                },
                {
                    "sent": "Later, the phone book excitement, what do you say it like that instead?",
                    "label": 0
                },
                {
                    "sent": "And the relation in this set up early independence?",
                    "label": 0
                },
                {
                    "sent": "The words because other than that.",
                    "label": 0
                },
                {
                    "sent": "So what we did was displayed at the test set into like speakers.",
                    "label": 0
                },
                {
                    "sent": "So there he's what is spoken backwards speakers.",
                    "label": 0
                },
                {
                    "sent": "So we could like 45% of the data for the government said, and the underlying that have used like kind of day.",
                    "label": 0
                },
                {
                    "sent": "So you don't want to pay someone figure out once we got on the plane, indecision.",
                    "label": 0
                },
                {
                    "sent": "So we need to make sure and see if it's it's like that.",
                    "label": 0
                },
                {
                    "sent": "So and then update on that, reset it, then, then then said was not adding any speaker who was that we have looked instead at all.",
                    "label": 0
                },
                {
                    "sent": "And then how do you?",
                    "label": 0
                },
                {
                    "sent": "So it's a little bit question was very kind of very controversial and very tricky, and so you know there is a very abusive and abusive relationship with complexity theory, but it looks like what we are doing here goes against complexity theory because instead of looking for the simplest model, we are trying to look for the most complex model which is going to generalize working together.",
                    "label": 0
                },
                {
                    "sent": "Is he?",
                    "label": 0
                },
                {
                    "sent": "Yeah, my family transcription.",
                    "label": 0
                },
                {
                    "sent": "You know for work could be a fully connected everything model containing all the fun and just rely on the initial probabilities so that this model is going to output to work at.",
                    "label": 0
                },
                {
                    "sent": "If I say cat and dog if I say dog right?",
                    "label": 0
                },
                {
                    "sent": "That would be the ideal model and it's very complex.",
                    "label": 0
                },
                {
                    "sent": "So where can we?",
                    "label": 0
                },
                {
                    "sent": "How can we go between the baseline transcription very linear left or right to the very complex model?",
                    "label": 0
                },
                {
                    "sent": "What is solution in between?",
                    "label": 0
                },
                {
                    "sent": "Final question.",
                    "label": 0
                },
                {
                    "sent": "Over there we thought doing recognition yeah.",
                    "label": 0
                },
                {
                    "sent": "Now I can be active sampling some simple.",
                    "label": 0
                },
                {
                    "sent": "I think the adjectives complex and simple or inverted.",
                    "label": 0
                },
                {
                    "sent": "Here the completely connection model.",
                    "label": 0
                },
                {
                    "sent": "I think it's a simple swap.",
                    "label": 0
                },
                {
                    "sent": "Yeah, in terms of behavior, most components that are good, that's good.",
                    "label": 0
                },
                {
                    "sent": "I will remember that.",
                    "label": 0
                },
                {
                    "sent": "So that's a very good answer.",
                    "label": 0
                },
                {
                    "sent": "Yeah, we have because we are moving from bigram to unigrams, but there are more parameters.",
                    "label": 0
                },
                {
                    "sent": "It's it's simple demo.",
                    "label": 0
                },
                {
                    "sent": "OK well.",
                    "label": 0
                }
            ]
        }
    }
}