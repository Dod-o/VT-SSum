{
    "id": "4eedbdugwwvwyq7rbnd5sxr6xflvtzho",
    "title": "Convolutional Neural Networks and Computer Vision",
    "info": {
        "author": [
            "Rob Fergus, New York University (NYU)"
        ],
        "published": "Aug. 23, 2016",
        "recorded": "August 2016",
        "category": [
            "Top->Computer Science->Machine Learning->Deep Learning",
            "Top->Computer Science->Machine Learning->Reinforcement Learning",
            "Top->Computer Science->Machine Learning->Unsupervised Learning"
        ]
    },
    "url": "http://videolectures.net/deeplearning2016_fergus_neural_networks/",
    "segmentation": [
        [
            "Alright, so I'm now I'm not quite sure about everybody's backgrounds here today, so I'm going to give a bit of a general overview of continents starting from very basic principles.",
            "You had back problems.",
            "I'm not going to come back problems OK, but so pretty over fairly quickly.",
            "Then the simple stuff and then talk a little bit more."
        ],
        [
            "About some of the applications side of things in vision.",
            "So one thing to say is that I'm so many papers coming out of the moment in CPR and the other vision conferences that use components I can't possibly attempt to sort of covered.",
            "Also, apologies if your paper or you know some important piece of work isn't mentioned here, but you know this is in some sense you know some sparse sampling of this sort of stuff that's happening at the moment.",
            "Of course, unfortunately a little biased towards stuff that I've been involved with just because I haven't.",
            "Have to be able to access the slides and so on.",
            "OK, so this is."
        ],
        [
            "Interesting sort of taxonomy.",
            "The marker aliens are to put together.",
            "So basically today's entire talk.",
            "You just make the point that there are many deep models are different types of deep learning model out there.",
            "I'm just going to talk about just one particular model, so anyway."
        ],
        [
            "This is going to be our covenants as I've abbreviated, so this is a model that iannacone and colleagues at Bell Labs came up with in the late late 80s, and this is effectively really just the standard neural net with some specialized connectivity structure and a few other things in there.",
            "And just so just I'm just going to give a bit of historical overview of the thing of sort of, you know of stuff.",
            "And then we'll talk a little bit in detail what actually goes on in these models."
        ],
        [
            "So just to say that they're not, they weren't sort of invented completely out of the blue.",
            "There was a long sort of series of work that preceded them so broadly one could think these models are something called a multi stage.",
            "Who will diesel architecture?",
            "So who lives where?",
            "Your scientists were trying to find how the human visual system worked, and they notice that you have these stages of sort of simple cells which essentially filters and complex cells.",
            "That sort of combine the outputs of these simple cells, and then the idea.",
            "I mean, that's been the incarnation.",
            "That sort of computationally carnation.",
            "You see in these models is really so repeated stages of this simple cell complex cell structure, and then the idea is that that would hopefully compute successively more invariant features, and then you could stick a classifier on top.",
            "So Fukushima had some very interesting work on this model.",
            "Corneal cognat Ron.",
            "Which essentially embody this concept and didn't quite wasn't clear was be trained and so on and so forth.",
            "And then, you know Yan's conference, and then there are other people also have tried to sort of instantiate the biology like Poggio and stuff more recently."
        ],
        [
            "So very roughly, I'm sure most of you know this, so I'll just go very quickly.",
            "So roughly very roughly speaking, essentially it's a feedforward model.",
            "You're going to put in some image.",
            "OK sorry, trained by clustering rice.",
            "OK, I see I see so they didn't have the snow backdrop in the thing right?",
            "Yeah, back then so.",
            "OK, so very roughly, you're going to be taking input in this.",
            "In most cases there's going to be image will look at a few cases where it might be something like a video later on, and you're going to be essentially filtering that image with a series of learned filters.",
            "That's the convolution operation passing through some nonlinearity and doing some pooling, and to get some feature Maps, that's one layer of the model, and this is going to be repeated multiple times, so into this in more detail later on.",
            "OK and at the output of the network we will have some prediction is going to think just for example, consider the classification scenario.",
            "You'll have some prediction as to what class objects in the image, and then we'll have some ground truth label available so these models can be trained, supervised in contrast to many other models you'll hear about later on in the week, and we're going to train the whole thing essentially by back prop.",
            "OK, and that's going to update the parameters in the model, which in this particular zone the simplistic incarnation is just the convolutional filters that you have in each layer.",
            "OK, so so these models have been around for a long time just."
        ],
        [
            "To sort of give some context so they work very well on these on these sort of simple, you know, perhaps you might say simple problems like handwritten recognition and stuff like that, so you know, and indeed that people have managed to sort of crank down the errors on amnesty.",
            "Another sort of handwritten datasets, incredible values in fact, slightly better even than human performance on some of these tasks.",
            "And then for sort of similar recognition problems like you know, recognizing Rd signs, they also got people got very good results and stuff like that.",
            "But when people try them, this is sort of winding back to say the mid 2000s.",
            "About 10 years ago when people tried these on the sort of computer vision benchmarks at the time, like Caltech 101, they didn't do very well at all, and in fact they were being beaten quite dramatically by standard methods like support vector machines and that kind of stuff.",
            "And so This is why you know people weren't paying too much attention to them back then.",
            "OK, So what changed?",
            "There was a bunch of factors that came in.",
            "So first of all."
        ],
        [
            "With the availability of big labeled datasets, image that was the first one.",
            "Now we have things like Coco as well and so the idea, essentially by sort of justice.",
            "Things like Amazon Mechanical Turk and a lot of time and energy.",
            "You know, the community managed to label these big enough collection of images that we could start to think about, you know, training some these component models effectively.",
            "So imagine it's the full version.",
            "Burnett is actually 14,000,000 images or so on across 20,000 classes.",
            "There's a smaller version which you all know is users.",
            "The challenge one which is about a million images and 1000 classes.",
            "And in 2012, Jeff Hinton and a couple of students access key analysis.",
            "Cava decided to apply this.",
            "You know, basically decided to have a go with sort of classical converts.",
            "On this image, net data set.",
            "OK, so in this."
        ],
        [
            "Just to clarify, image that challenge.",
            "The goal here is basically given a single image and you have to break.",
            "You know one of 1000 sort of prediction as to what's in the picture.",
            "OK so these are some example images.",
            "The ground truth is just shown on each image and this was the sort of typical output from the network.",
            "So in the top five responses, because the classes can be somewhat close, the scoring metric in image net allows you know if the correct the correct positions in the top five, then that's considered sort of OK and then acts considered correct.",
            "So in this case here you can see if it's in red.",
            "Then that's correct in this case here.",
            "The true answer lens cap wasn't in the top five predictions, but you can still see it was making sort of sensible predictions as to what was going on.",
            "OK, so now what was so this was this was just showing some sample output from their model so their model affect."
        ],
        [
            "It was the same model as Jen Kerns, model from along time ago, but really just scaled up in size.",
            "OK, so it's much bigger in terms of number of layers or 8 layers.",
            "It had many more parameters so you can see at the bottom it had.",
            "Actually, you know 60 million parameters and of course to estimate all these parameters, need lots of training data, and that's where image net came in.",
            "So instead of you know thousands of images that you have in datasets like Caltech in image net you got million plus images.",
            "And then the other sort of 3rd component of this sort of success was this be able to sort of run these models on the GPU.",
            "OK, so big models, lots of data.",
            "You have a lot of computation, train them and access keeps wizard coder, so he implemented some very efficient GPU kernels which were big speedup there was there were one or two little tricks in there too for sort of better regularization of the models, but that's basically it.",
            "OK so."
        ],
        [
            "This was the state of the computer vision sort of state of the arts prior to the conference error, so this was the rampant competition starting 2010 and these are the best results in those in 2010 and 2011, so these were not using deep Nets, which is using a lot of very complicated setups or handcrafted features.",
            "The top five error rate here was, you know you can see about 28 to 26% to lower is better here and then you know it's risky paper came in.",
            "You know it dropped it down quite dramatically down to sort of about 18%, sixteen 1718%, and perhaps even more remarkable thing is, since then people have really been able to take these models, adapt the architectures, tune them up, figure out what works and what doesn't, and the error rates are just kept dropping, so this in 2014 it was down to sort of about 6:00 or 7% and then a crude estimate of human performance will put this about 5%.",
            "And then instead of last year, things were down below 5%.",
            "So it's a little bit better than humans on this data set, so it's really gone from being a sort of.",
            "Problem, which was a long way from being solved in the networks are really giving kind of pretty useless answers to being the case where it really works very well indeed.",
            "And."
        ],
        [
            "Just to show you sort of, you know, one of these.",
            "This is just maybe not state of the art model, but this is a sort of from clarify which is a startup which has a little.",
            "Website you can upload a picture and get some results back.",
            "These are showing the kind of results you get so they can take these complicated scenes and they can give pretty sensible sort of."
        ],
        [
            "This back problem and stuff like this so you still a few slightly weird things going on there, like Helsinki for some reason scores very high and this was."
        ],
        [
            "Deliberately complicated one, so this is actually inside of a cave, OK, and you can see here for some reason I think the Sagrada Familia in Barcelona is, perhaps, you know, some similarity there so you can see that they're not completely foolproof.",
            "They still make mistakes that humans wouldn't, but certainly there are still doing way better than.",
            "Before now, one actually very important aspect, I think, is that you might say, well, this is great on image net well, but I don't really care about Internet.",
            "I have another vision problem.",
            "I want to be able to use some deep net on and I think one of the pleasant surprises from all of this was the fact."
        ],
        [
            "But if you train your model on image net, the features, the feature presentation you get from it, so that is if you just chop off that last layer of your model, which is the classifier which we're going to in a bit, and he just regard the hot the rest of the models are giant feature extractor.",
            "Those features generalize quite nicely to other datasets, so fighting for example."
        ],
        [
            "Go back to these old sort of problem.",
            "People don't so many other datasets.",
            "This is some old graphs that I have just showing on account at 256.",
            "So this was in sort of 2013.",
            "This was back with the sort of previous best state of the art models and if you just take that feature extractor you trained on image net and just now train just the top classifier classifier on the Caltech rather small number of Catholic training images."
        ],
        [
            "You can see on this X axis, but just varying that you can see very very dramatic, so we just in fact we just six image training samples per class.",
            "You already exceeding the previous sort of pre deep learning state models and you can see it sort of having the overall error rate and things like that.",
            "And this was a pretty small architecture.",
            "I'm sure the latest deep Nets would do even better.",
            "Way better than this, but that's been sort of very, very handy thing because it really means now that we're able to take a lot of different vision problems even if we don't have a huge amount of training data we can train on image, net and then sort of adapt the features.",
            "Just by retraining, you know the top layers of the model.",
            "OK, so now let's go in."
        ],
        [
            "Some of the details, so let's just we're going to review.",
            "So what goes on each layer?",
            "Just talk about how you select the architecture and stuff like that and look at how the training procedures and then look at some results on a different supervision applications.",
            "Alright, so."
        ],
        [
            "So just to start with, essentially each layer is going to take in as input.",
            "Either if it's the first day will take in pixels of its subsequent layers, it will take in different able take in.",
            "The feature Maps in the previous layer and you can just think about you know the feature Maps being an image with just multiple color planes instead of just three color planes are going to have a much larger number 700 or so, and you're going to follow up with something to learn dictionary and they're going to pass the resulting feature Maps some elementwise nonlinearity, and then there's gonna be something operation to give you output features OK, and then the whole thing repeated.",
            "So let's look at each of these boxes in turn."
        ],
        [
            "So the convolution operation.",
            "So basically there's your input image.",
            "For example, firstly you got a little filter.",
            "Now the filters only need to be small because in some sense you need to capture some of the local dependencies in the image.",
            "OK and the local dependencies are far far stronger than the longer range ones and that the longer rate and so those long arrangements will be captured over the course of multiple layers.",
            "But within each layer you can sort of get away.",
            "Effectively we're just having a fairly small filter, so that's one sort of.",
            "Key property that you're exploiting somehow in the structure of natural images.",
            "That sort of would be true about general general signals.",
            "And the second point is of course we're going to slide this filter all over the image now.",
            "Effectively it means we're using the same set of filter coefficients of each different spatial location, and that's again, we can sort of get away with that by and large, but cause you know the statistics images are spatially stationary, so just doesn't really, you know the 1st order approximation.",
            "It doesn't matter whether we are applying this edge filter, we expect to see the same distribution of edges.",
            "Perhaps in this sort of bottom of the image to the top of the image.",
            "And things like that.",
            "OK, so each one of those convolution operations is going to give us sort of feature map looks like this so.",
            "Gray 0 black is negative, white is positive and we're going to have a whole bunch of these filters.",
            "OK, so this is just one filter channel 1 filter and corresponding feature map channel and we're going to have a whole bunch of these which we're going to compute each layer, so we'll have a whole stack of these feature Maps.",
            "That we've computed now just to make the point that there are some sort of variants that you do see sometimes in some models, which we."
        ],
        [
            "Don't have the wait time across different spatial locations, so you might actually want to stamp for each spatial position.",
            "You might not allow different filter, so this is often called your local locally connected layers and one nice example of that where that comes in is for example face recognition.",
            "So what I'm showing here is a little this is actually one of these sort of system that was used at Facebook for recognizing faces, so they've already done some kind of alignment procedure and the first couple of days are convolutional, but then these sorry can't see the type here, but this these less down here.",
            "Locally connected, so the idea is that somehow you want to have different filters that analyze the eyes to ones that analyze the mouth, and so on and so forth, right?",
            "So, in this case, you know the sort of special transformations have been removed, so you know that you're going to be seeing sort of eyes and eyebrows and hair and stuff like that at the top of the image, and then things like mouth and chin and so on at the bottom.",
            "So you want to undo the weight tying, and that does definitely help performance in this in this particular case, but this is obvious or other specialized application.",
            "So in this case you would have a different.",
            "Oh yeah, Yep.",
            "No, no, because there's only.",
            "As I said, there's already been a sort of a pre preprocessing stage where they fit Runner face detector.",
            "They fit a 3D mesh to the face and then normalize it to some Canonical thing.",
            "Yeah, so it's already been done.",
            "Yes, and so the idea is they basically have a different filter, different sort of weights at each spatial location because it explodes the number of parameters in your model, which is why in some sense they only have it high up in the model when the feature Maps are fairly small, but nevertheless it does give it important performance gain."
        ],
        [
            "OK, so then you can have some sort of compromise in the two.",
            "You can have some sort of style representation which would allow you to have you know you wouldn't essentially have the same.",
            "This is a way to essentially get you get more filters into your model.",
            "If you want more capacity, but I don't think I should start to think of any models that use this.",
            "Actually, at the moment successfully.",
            "OK, let's skip.",
            "I'm sorry.",
            "Actually coming from the first layers of the convolutional, yes.",
            "Actually it's like I did actually take that image, and I convolved those filters.",
            "I sort of, you know, manually constructed, and I did indeed convolve those filters with that image to get these Maps so they are accurate in that sense.",
            "OK, so anyway that's the basic idea is for the most part go forward, and as I mentioned otherwise, I'm going to be talking about essentially just the standard normal convolutional thing where we have a wait time across different spatial locations.",
            "OK, so those feature Maps we're now going to pass into some elementwise nonlinearity.",
            "Sorry, we just run through these silly anime."
        ],
        [
            "Again, for a second.",
            "OK, so here we go.",
            "So the most common nonlinearity that people use, and this is going to be paid per pixel.",
            "So this is the input value of the feature map pixel and this is the output value.",
            "So essentially it's going to be a zero if it's less than if the input is less than zero and it's going to be just, you know, identity mapping if it's positive, OK, and so you're going to take this feature Maps now.",
            "One thing I sort of forgot to mention or sort of skipped over, was that you're going to have per feature map bias, which effectively concert is going to translate this function.",
            "The left or the right.",
            "OK, so that can change exactly where this threshold where this thresholding operation is going to take place.",
            "So this is your input feature Maps you got black values which are negative, which are positive when you pass it.",
            "Through this, you're going to essentially remove those non negative values.",
            "So this is what it's going to look like.",
            "Now there's a whole bunch of different energies you could use so the classical choices would have."
        ],
        [
            "Things like in a sigmoids as, which would give you this sort of output between zero and one, and then you've got 10 H functions, which sort of looks somewhat similar, but it's between minus one and one for various reasons.",
            "I think people found that those things don't work quite so well.",
            "In fact, I think it's Joshua's group who first."
        ],
        [
            "Notice that these rectified linear units do in fact work seem to work very well.",
            "They also have a nice computational advantage, which is that if you think about when you compute the backdrop operation, you do actually need to incorporate all you need to do is we keep around a mask of binary mask that tells you whether you're in this sort of dead part of the nonlinearity, or in the sort of linear region.",
            "OK, so you don't need to keep around the derivative of your."
        ],
        [
            "Your activation normal problem.",
            "You have to keep around where you're forgiven activation what the slope is of this of this nonlinearity, but in this case of course the slopes either."
        ],
        [
            "One or zero.",
            "So it's sort of computationally more efficient to compute during back prop speed things up as well.",
            "There are one or two attempts.",
            "One problem, of course, is that."
        ],
        [
            "If you're down here, there's no gradient, so you're sort of that element is sort of off.",
            "It's hard to turn on again.",
            "There's one or two attempts to fix that.",
            "For example, you can sort of trying to have, you know, make this not as different slope, so this will be the A here would be a very small number, so we sort of skimming along the axis here, and you could try even attempting to try to learn this value a per per feature map or something like that, so these things give small advantages, but I think for the most part these are very simple rectified linear units.",
            "Actually work very well.",
            "OK, now the next part of the system is the pooling."
        ],
        [
            "So the idea here is we've got these feature Maps.",
            "They encode sort of spatial spatial layout.",
            "Still of the image, so there's sort of 2D structure of the picture is preserved, and we're going to do.",
            "I mean there's a whole I should say there's a bunch of different variants of pulling that people have explored.",
            "The simplest one is what I'm describing here, especially going to put down various Windows the size those windows will be predefined.",
            "Something like there are two by two or three by three pixels, and sometimes they'll be overlapping with one another in this drawing here there sort of non overlapping and you're just going to compute.",
            "Very simple Max.",
            "Over those elements you can take the largest elements.",
            "Obviously these are larger than three by three.",
            "I just threw them nice and big so you can see and then if you take per window Max then you get something like this.",
            "If you take the other alternative is to do a sum or an average operation and that's going to give you something something like this.",
            "So I think in practice most people find the Max operation seems to work better.",
            "I mean, there were some attempts to sort of analyze why this might be theoretically, but I think empirically anyway, this is the Max, at least in these big component seems to be working pretty well, so so the intuition behind this is an operation which isn't present of course, in standard, your standard neural net.",
            "Just say Yep, sorry.",
            "To say that the filtering layers work as the classical filters that were not part of neural networks like Siri Crossing, doing something like as you're crossing and well, OK, OK in the first layer they do turn out to sort of have these sort of Gabor like structure which does have this property.",
            "Catching zero crossing types off, but naturalize.",
            "They're not doing that kind of thing at all.",
            "And so.",
            "Yeah, I think it's.",
            "I mean, it's just by chance that happens to look a little bit like sort of.",
            "I mean we can go into this sort of more detail offline, but yeah, I mean it's the first layers do look for edges essentially which you have, which the optimal thing is along the lines of we describe.",
            "So just give some motivation as to why spatial pooling.",
            "So what sorry, there's nothing you can do about it.",
            "You can have overlapping windows and so on like so it gives."
        ],
        [
            "More of the same thing.",
            "You can also try to sort of put across feature Maps, in fact, so this was sort of pooling within a feature map, but you kind of pull across them, so there's an interesting model buying Goodfellow and actually other folks in Montreal where they took in some sense of Max.",
            "This element Max.",
            "Here we look at both Max over both spatial position and over feature map 2.",
            "So."
        ],
        [
            "Cursively what's why do you want to do pooling?",
            "Well, I think one very important thing, of course, is that in images you want to sort of basically learn kind of invariants, right?",
            "So you want to make it so that, for example, if you translate the object slightly, that shouldn't change your feature representation.",
            "Too much or if you have a small deformations of the objects and stuff like that, and the pooling gives you that kind of invariants, and particularly when we stack this, remember what I'm describing is just a single layer in the model.",
            "When you've got multiple air stacked on top of one another, you're going to end up being very complicated.",
            "Invariances will see just a moment and the other point, of course, is that we want to sort of each in this first layer of the model.",
            "You've got a fairly small receptive field that is the model.",
            "Each element in the feature map only sees a fairly small window.",
            "The inputs as you have this pooling operation in there, as we got the model, the pixels in the feature Maps of the high levels will actually start to see you know essentially entire image.",
            "And of course we want to ultimately make a decision about the identity object based on all pixels in the image, not just a small subset of them.",
            "And so just these are just just a little and you can also try and play around a little bit and in these models this is some sort of visualization technique from quickly which try to show the kinds of variances that you can learn, sort of in.",
            "And this is showing, for example, an invariant to scale is showing a sort of little transformations, the input image which don't change the essentially the signal in a particular feature mapping the model.",
            "So this is the kind of this kind of scale invariant feature.",
            "This one seems to be variants or diagonal translation and stuff like that.",
            "OK, well look will look at some visualizations of the models later in in just a moment which will give you a more of a feel for this kind of thing.",
            "OK. Sure, sorry.",
            "Like Max pooling versus everything.",
            "This one should be used right?",
            "Well I guess people have done a lot of so the question was when should one use Max pooling versus sampling and so on I think.",
            "There's been a lot of empirical investigation of that issue.",
            "OK, so people tried all these different flavors of pooling in sort of, you know, exhaustively over these different model architectures, and I think even though it's hard to give a sort of really compelling theoretical justification, I would say empirically, it seems that the Max pooling seems to be doing pretty well.",
            "Yeah, I mean, I wish I could give us like more satisfying answer that, but unfortunately I can't really."
        ],
        [
            "So one of the things that people do do a little bit is also they also.",
            "So just so just to wrap up.",
            "We just looked at the filtering Operation RT, the spatial pooling, which is usually just local in each feature map and it's just the Max pooling and will be I guess in a lot of models now.",
            "People do some kind of normalization here as well, so we'll talk about that in just a second with optimization.",
            "How you train these models effectively."
        ],
        [
            "So I'll just skip over that.",
            "OK, now the next thing is the architecture.",
            "So in some sense you know I've described.",
            "You know these stages of the model, but there's a lot of sort of important details that are missing, like how would one select number of feature Maps of each layer?",
            "How many layers should we have?",
            "All these sorts of things, and indeed you know all these will affect the sort of parameters we have we have.",
            "We have a set of train data.",
            "What's the best way to sort of arrange these things?",
            "OK so."
        ],
        [
            "So in some sense, just as a sort of side note, you know in the pre deep learning error people spent all their energies trying to sort of engineer good feature representations.",
            "So in some sense with the planning everything is just shifted up a level of abstraction.",
            "So instead of designing the features, we now learn them, but what's in fact happen now is we spend a lot of time trying to sort of discover good architectures for the models, and then given those architectures, we can then train your feature presentations underneath.",
            "So I have to say that at this point I think we still don't have a really kind of principled way of picking architectures directly.",
            "I mean the most simple one.",
            "Of course, you can imagine having some validation set and just trying different ones out, and we can do a sort of brute force grid search, sort of smarter strategies that Joshua's and colleagues came up with.",
            "You know that in your high dimensional so hyperparameter space, there's like, you know, if you just do a random strategy, just picking random points within that, then you're likely to stumble across kind of a good zone faster than just doing things just by grid search.",
            "And there are sort of other sorry, forgot for the reference in here, but there are strategies where you can try and.",
            "So for example, Ryan Adams, Bryan Adams Group has some approach for sort of trying to fit a very simple function to the sort of performance of different model architectures and try and try to predict which model architectures might be good ones to try next in your search, and so on and so forth.",
            "But I think this is an interesting story, also forgot to update the slide.",
            "I guess there's a whole bunch of recent papers which look at trying to sort of grow models incrementally, sort of like you know, adding layers and expanding the number of units in each layer and so on and so forth.",
            "I mean, yeah, I mean, that's of course.",
            "It doesn't sort of quite.",
            "It doesn't tell you beforehand exactly how you should pick pick things.",
            "So I guess one.",
            "However, there is sort of I guess one very important."
        ],
        [
            "And so the reason is that the deep in deep learning is really, really important, and we're going to just sort of going to this little bit more details."
        ],
        [
            "This is the architecture that excludes FC and Leah and Jeff Hinton.",
            "You know, proposing that 2012 paper?",
            "So essentially these are the 7 hidden layers and then you go to softmax output.",
            "So just to look at it you got this convolution rectified linear and Max pooling the same thing in there two and then they had some layers just with convolutions and rectified linear units and with no pooling and then had another final pooling on top of stage five and they had some fully connected layers.",
            "Just densely connected layers, so this loss or to the structure at this point and turn it into a giant factor and then just have fully connected layers up to some softmax output.",
            "With 1000 outputs for the 1000 different classes and Imagenet OK, so that's.",
            "Get when they trained the single one of these models that they got about.",
            "Whoops, sorry, forgot about apologies.",
            "They got about 18.2% of 5 error.",
            "So when we re implemented by she got slightly better than they did.",
            "So one thing you can say is OK, So what makes this model works so well?",
            "Maybe we're going to start chopping out different parts of the model, retraining from scratch of course because you can't just remove weights in the middle.",
            "That would mess up what you know.",
            "The signal that the less above were expecting, but we can remove different components, model, retrain from scratch and see how it does."
        ],
        [
            "You can do it, you can just try for example just from one is fully connected at the top past this thing straight to the softmax.",
            "You just remove 16,000,000 parameters there, about 60 million in total.",
            "That's a big chunk of the capacity in the model, but actually it really makes very little difference to performance.",
            "You lose a percent or so, so that clearly wasn't sort of vital to the networks performance.",
            "OK, so now you can."
        ],
        [
            "Look at both of them, so I'm just now dropped.",
            "The majority of net parameters in the model 50,000,000, and it's true that the performance has dropped now about 6%.",
            "But it's still actually a lot better than the classical approaches that we had before deep learning.",
            "So somehow the rabbit isn't in those layers either.",
            "So let's try.",
            "OK, some other strategies, so maybe."
        ],
        [
            "Back end, maybe we can now remove these convolutional layers down the bottom.",
            "Remember there wasn't any pooling."
        ],
        [
            "Right, so we can just easily we're not changing the dimensions of."
        ],
        [
            "Difference of the architecture to dramatically so this one is only about a million parameters in those convolutional layers because the wait time makes them very efficient.",
            "So any thoughts about 3% performance?",
            "So at some point at this point you're like, well, OK, I mean, you know what's going on because it's not, it's not there.",
            "It doesn't seem to be down here.",
            "So is it really?",
            "These three layers that you are doing?",
            "Everything?",
            "What you?"
        ],
        [
            "Try sort of, you know, just try those three layers alone and now it really now broken it.",
            "OK, so now it really does very badly and but you'll notice is really we only have 4 layers or three layers.",
            "3 hidden layers really between input and output OK, and so in some sense that you must have a good number of nonlinearities.",
            "And you know you need basically a decent number of different inputs and outputs.",
            "Learner sort of good classification.",
            "Function so this is what this is telling us now and just to say that you know, if you look at the trends this is Alex is model back in 2012.",
            "The trend subsequently has really been to sort of dramatically increase the number of layers in the model.",
            "Anna's, and correspondingly, the error rates have just kept falling.",
            "I mean, that's that's the main difference on that graph I showed with the sort of image.",
            "Net performance, overtime.",
            "The other thing you can do actually, just as another source light thing you."
        ],
        [
            "So tap off the features at different layers in Alex is model and just train little SVM on top of them on this.",
            "These are on some old datasets just to see how well they do and it sure enough you do see that the performance of systematically increases as we this is features from one features from 7 and so on so that you know the features seem to be more powerful as we go down through the network."
        ],
        [
            "Another little fun thing you can do is you can look at sort of invariants of different transformations of your input signal.",
            "OK, so as I was mentioning, you know by stacking these liars, you're going to get some increasingly complicated invariants is being learned, so here's a little example.",
            "What we're doing is we're going to take a single image sharing, translated vertically through different vertical translations, and we're going to see.",
            "So I guess the middle one is the original, and this is a sort of shifting down the shifting up and what we're looking at here is the sort of sort of differences like the DOT product or something like that between the.",
            "Feature Maps in the untranslated layer, one versus the features you get from the inlet one.",
            "When you translated the input signal so you can see things are pretty sensitive.",
            "Right?",
            "Small shifts in the image cause quite dramatic changes in the input feature map, and these are for the each of the different images up here.",
            "OK, but by the time we get to the last seven, things have come sort of much more, much better behaved right.",
            "So now things are sort of.",
            "The translation is now becomes sort of simple linear shift or there's much less much less sensitive somehow to the transformation.",
            "And at the output you can see it.",
            "See now it's pretty invariant in fact, so you can see the lawnmower.",
            "And this is probably true class so that you can tell it's lawnmower even though there's quite dramatic shifts in the input image.",
            "So you might say, well, translations come easy one."
        ],
        [
            "What about scale changes that so much more nonlinear thing?",
            "So something this small scale changes quite dramatic, changes them in the future presentation layer one, but by less 7.",
            "They've become much more sort of, you know, much simpler sort of linear change in the representation, and sure enough, the model now is still, but it's pretty invariant to them at the top of the model.",
            "So in some sense these layers do let us unpack."
        ],
        [
            "Things this is.",
            "Rotation invariants shows somewhat similar thing."
        ],
        [
            "So as I was saying, what's effectively happened is people now just focus on sort of building bigger and bigger models, and so this is this is the VGG model from Oxford from Karen Simonyan Android system and this is the one from Oxford.",
            "So what they've done really is to replace the convolution operations, which typically in Alex is model things like 7 by 7.",
            "You know sized filters with multiple three by three convolutions, each one of which has a nonlinearity after it.",
            "OK, so you basically end up with the same kind of receptive field, but now you've got a much more powerful function.",
            "In the sense that it can, it can decision surfaces and just sort of simple linear thing anymore, but you have with a single convolution it's going to be a much more complicated things.",
            "You've got multiple linear convolutions and then multiple multiple rectified linear nonlinearities coming afterwards.",
            "OK, so the you can see here for example, each of these stacks is basically a combination with a three by three kernel and followed by a value combination with real you and so on and so forth.",
            "You can see they really sort of stacking these things in there, so I guess this one has about 19 different.",
            "Hidden lies in total and the results on image net at the time were state of the art.",
            "They went down to sort of, you know, 6.8 for the top five.",
            "Which is pretty impressive.",
            "'cause Alex's model was getting about 18% top five performance."
        ],
        [
            "So then the Google folks also have some some more complicated model where they're essentially going to sort of each layer of combinations of different size of 5, three by three, one by one.",
            "They have some sort of sort of PCA, like dimensionality reduction to sort of control.",
            "This size of things, all compatible.",
            "This is the little."
        ],
        [
            "Inception module and this is just a visualization of the role models.",
            "This is actually very complicated model and then they actually to help train it.",
            "They actually introduced labels that sort of different points in the model, not just at the end.",
            "And this is just comparing to sort of something basically the same size as Alex Net from a few years ago.",
            "So these models are getting really very very big.",
            "And then yeah."
        ],
        [
            "This is just showing the number of feature Maps player so you can see this is a pretty big model.",
            "Basically what they did do though is they got rid of completely the fully connected layers in this so that in some sense the total number of parameters even though they have many more feature Maps, player and more layers went down dramatically right?",
            "So they just only have only about 5 million parameters and this also got sort of pretty very low performance on very good, very low error rate.",
            "Sorry on image net I think one thing to say that I think people have this in Google Inception model.",
            "People tried it on other datasets like for example the Cocoa challenge and stuff like that.",
            "I've used it for attention.",
            "It doesn't seem to generalize quite as well as VG."
        ],
        [
            "Model that are showing here, which is somewhat simpler approach.",
            "It's really just fairly simple modification of the Alex net thing.",
            "Just have three by three convolutions and more of them, whereas this one was sort of more dramatic change the architecture, but this one somehow seems to generalize better, and I guess the."
        ],
        [
            "Latest one thing that came out I guess.",
            "Well technically last year, but I suppose this years residual network, so this is actually the models have got really deep, like hundreds and hundreds of layers and this motivated by this quite interesting observation.",
            "If you just take the models like Gigi and you just add more convolutions to them.",
            "You might think, well, OK?",
            "Sure the importance just improve.",
            "Well, actually the answer is no it doesn't.",
            "And then when you try this is the training error on seafile, right?",
            "So in theory you got more layers and more powerful function.",
            "There's more parameters you'd expect a lower training error.",
            "What you see in fact is the training goes up, which is telling you that somehow you're having trouble optimizing these incredibly deep models and do this, and then you see of course in that other test set as well.",
            "Actually the performance is worse with 56 layers than 20 layers, so that's just sort of naively adding layers to your VG model.",
            "And So what they did was introduced this nice simple idea which is whereby instead of just stacking the convolution layers together like like you would in this pathway, what you're going to do is have a sort of bypass.",
            "We're going to take your input signal and just add it in.",
            "Afterwards, So what this means is effectively that these white lies only have to kind of make a sort of changes to the sort of residual they're looking to make some modifications to existing features that come in.",
            "They don't have to sort of propagate the features themselves, and so in practice this seems to sort of improve the conditioning of the whole system and make it a lot easier to train.",
            "And when they train these things, so this is now a visualization of the things, so this was the biggest Fiji model from the previous slide, and this is the sort of the naive 34 layer version where they just added a whole bunch of extra convolutions in.",
            "And this is what they call the 34 layer residual net where they've got these sort of bypass.",
            "This identity function that's basically propagating the features sort of round between pairs of convolutional layers after each convolution layer.",
            "There's a rally operation that goes on as well.",
            "So the doctor bypasses where they actually have a slight change in.",
            "This is where they've done some pooling operation, so they have a change in the dimensionality of the signal so they actually have to have a little.",
            "This function here has implement some actual change in dimension to make it compatible, so this is what this is.",
            "Effectively the 34 model and when they.",
            "So this is I think this line here.",
            "So this goes down to five point, 7% of 5 error and then with if they just keep jacking up the number of layers.",
            "This things you know the errors keep dropping so they get that with 152 layer model that down at 4.5% error and if they on sambol that they get down to 3.6 or so which is I think I'm nervous of saying this 'cause the numbers keep changing archive the whole time.",
            "I think that's the current state of the art but these models are fairly easy to train still.",
            "So I mean I'm not.",
            "So these things you know do really work well, and other datasets too for sure.",
            "OK, so the answer is that you know the whole deep in deep learning is really important.",
            "You know the depth is key here, rather than necessarily having crazy numbers of feature Maps in each layer.",
            "Notice here that they mostly have hit.",
            "Their end is sort of 512 and things like that and and the number of parameters isn't actually that dramatic in this in this in these models it's smaller than quite a lot smaller than VG and Alex net, so they.",
            "Which is great so that you don't take up crazy amounts of memory on your GPU, and you can compute these things fairly fast and stuff like that.",
            "OK."
        ],
        [
            "So.",
            "Right, so one thing says yeah, whoops, sorry.",
            "So the filters in the first layer kind of easy to visualize that just directly accessing the pixels.",
            "You can look at the filters and they make sense, but in the highlights they're just complicated functions of some of the input Maps, right?",
            "So you can't actually direct look at those coefficients or make any sense of them.",
            "So there's essentially two sort of schools of two ways you can kind of.",
            "Well, there's a whole little cottage industry impact interest on these models are doing.",
            "I guess you can broadly classify them into sort of two different.",
            "Schools one would be to sort of project somehow individual activations in the model back into into pixel space through some approach.",
            "The other alternative is to try and.",
            "To try and do sort of some sort of gradient descent.",
            "Update to change your input image to maximize the output of the model, or to maximize the activation in some particular.",
            "So this is sort of doing back basically, but going all the way back to the input pixels and updating those so there."
        ],
        [
            "Whole bunch of in terms of the projection back from hi.",
            "Lisa, whole bunch of approaches for doing this that are sort of different sort of variance on the."
        ],
        [
            "Thing I just got some describe one that one of my students did, so this idea was you were trained model.",
            "So training component model you're going to take a single input image, you push it through.",
            "You get a whole bunch of feature Maps, feature activations up let's say in this case let 3.",
            "So there's a Gray bars here in sort of, you know, height.",
            "The height indicates sort of the strength of the activation and what we're going to do is.",
            "We're going to just take a single strong activation.",
            "Said everything else is zero in the model, and then we're going to basically do sort of backdrop affectively with that vector of activation.",
            "Or that those activations rather than a gradient signal.",
            "So we're going to be sort of reconstructing back down all the way, projecting this thing all way back down to the pixels again.",
            "And if you look the operations involved end up in.",
            "Basically the same as backdrop with sort of small changes, basically to the whole procedure so."
        ],
        [
            "So just so this is, you know, you come forward, you got the commercial floating or rally on your Max pooling and if you in backdrop of course when you think about it, when you do back prop with Max pooling, you have to remember where the location of the Max on the forward pass, and So what we're doing here is just sort of keeping track in the same way, keeping track of that location.",
            "So when we're projecting the signal back down again in each pooling region we kind of push it down to the location that it came from on the upward pass, and then we do actually.",
            "So in this particular visualization technique we do pass.",
            "These activations then through a rally, you write their own rally rather than using their value.",
            "From the forward pass, and then convolving with the transpose, which is what you would have done in the back."
        ],
        [
            "OK, so just so just I mean what I mean by the pooling.",
            "So this is your pulling in the forward pass.",
            "This is your two by two Max pooling, so you basically taking the different pulling regions taking Max is these are the locations the little grey squares so this is telling you that this guy the top left one in this little block at the Max.",
            "So when you projecting down again you've got sort of easier.",
            "Directions from there above and you're going to stick these different locations so it's not a sort of true inverse or anything like that, because you know there's the rest of these going to be set to 0 basically, but you're sort of preserving the sort of structure of the of the model.",
            "So that's what we're going to do in this particular visualization strategy.",
            "So they say there's a bunch of different ones at all.",
            "You have slight different twists on how exactly they reconstruct the input."
        ],
        [
            "So the first slide we can just look at the filters.",
            "This is what they look like.",
            "They look, they pick up sort of edges, basically different orientations and scales.",
            "You can see sort of high frequency edges, you can see low frequency edges.",
            "You see also low frequency color opponency, so you can see sort of you know red green stuff going on here sort of blue and yellow over there."
        ],
        [
            "Now for the otherwise, we use this projection trick that I was referring to.",
            "Seattle is going to validation set of images and for each violation image going to shove it through, get those feature Maps and we can do that for all the images in violation set and we're going to take for a particular feature map.",
            "Say you know this one here we're going to take a few strongest activations across the entire stack.",
            "Of valuation images of that particular feature for that particular feature map, and for each of those activations individually, we're going to sort of project back down to the input in the pixel space.",
            "OK, and that's going to use this sort of pulling switches that were peculiar to that particular image on the forward pass."
        ],
        [
            "OK, so it's just so this is just showing a slightly different projection.",
            "This is just showing the input patches that caused the strong activations for each of the different filters.",
            "So for example, let's just take this one over here so you can see.",
            "This makes diagonal edges if you look at the filter it's I guess this one here, which so whoops which makes sense.",
            "So you can see you can see this invariant somehow.",
            "The color on either side of the edge already cares about is the having a strong edge of that orientation OK, and other ones like example this, you know the green one here.",
            "This one just likes uniform kind of greenie regions, which makes sense."
        ],
        [
            "So this is now projecting, taking the strong activation from each of the layer 2 feature Maps projected back down to pixel space, so that you can see here now is this.",
            "You're seeing effectively these sort of conjunctions of those low one filters, basically so you find along edges, curved structures, little circular structures, and things like that.",
            "In this case of green blobs and things like that, and for each of these feature Maps, we can actually this is just showing the strongest single strong activation across the validation set projected back, but you can take the top few that gives you."
        ],
        [
            "Nonparametric feel for the kind of invariances at the models learning so that he can see.",
            "So just to be clear, these are not sample.",
            "This is not any kind of generative model that we're looking at here.",
            "This is just, you know, sort of nonparametric way to get it feels each of these corresponds to some structure.",
            "So each of those tiles corresponds to 1 activation in in a certain feature map in a validation image.",
            "OK, and this is these are sort of the same feature map, just different coming from different images.",
            "Basically so you can see this sort of.",
            "Slight wiggling in the orientation of the edge.",
            "You can see things that are picking up kind of texture, but little bits of writing, perhaps in a feature map and stuff like that.",
            "A little curve structures or circles and so on.",
            "And you can if you look."
        ],
        [
            "This sort of input patches that correspond to these.",
            "You can see that it's now picking up some quite interesting invariants.",
            "So hey, go, you can see something that this one seems like text, but doesn't really care what the color is or anything like that."
        ],
        [
            "You can see it's just focusing on somehow the edge structures."
        ],
        [
            "Over here it doesn't again, doesn't care on the colors or anything like that or the brightness of the edge, it just is picking up on that discontinuity.",
            "Or at least pick up little circular structures, and so on and so forth.",
            "OK, so."
        ],
        [
            "So we can keep going through the model, so let three.",
            "Now the receptive fields getting larger so we're picking up some chunks of object and also you know because of all these non ASMR nonlinearity pulling we're getting increasingly more complicated invariances in there as well, so this is."
        ],
        [
            "This for example, now you can see this feature Maps that seem to sort of pick up on.",
            "This looks like text on the sides of objects."
        ],
        [
            "OK, you can see that again.",
            "It's just focusing on the text so that the brighter the higher the contrast the pixel is, the stronger the bigger contribution that part of the image made to the activation.",
            "OK, so that you can see that it doesn't really care about the background, he just cares about the text.",
            "Once we got here, so I guess.",
            "Yeah, so you can see some complicated things like sort of you know parallel lines and stuff like that have been picked up."
        ],
        [
            "And then coming to Le."
        ],
        [
            "For us at this point, except the receptive fields pretty big.",
            "So it's picking up most of the image.",
            "So now you can see this in case we started to see sort object specific stuff going on so the previous ones were kind of somewhat, you know, agnostic to the exact object identity.",
            "So now you can see for example dogs.",
            "There's lots of dogs in image net, so there's lots of dog feature Maps, so this one is picking up."
        ],
        [
            "You know certain types of dog.",
            "In this case, the dogs seem most dogs in this one pair alright.",
            "We sort of made it OK, so just."
        ],
        [
            "In the nervous about these ones are the top layers that fire.",
            "At this point, things getting pretty specific.",
            "You can see things things like this Huskies this feature out seems to be gone, like Husky Dogs which you can see."
        ],
        [
            "Clearly here, so one of my favorite ones actually is this feature Maps.",
            "I was looking at it like, well, what is this thing?",
            "What's it picking up on it?",
            "You know?",
            "Is it picking up on people by the sea or something like that?",
            "So if you think about it, most of the energy energy is really on these foreground objects, right?",
            "The people and so on and so forth.",
            "But actually if you look at what the model is picking up."
        ],
        [
            "It's actually picking up the water behind.",
            "It's ignored, completely ignoring that very strong foreground signal.",
            "But there's lots of energy and just essentially a water detector, and so it's doing something very complicated there, which you know you couldn't possibly get, or just a simple one or two layer model and the other fun thing, sorry, dangerously do this is like these keyboards, so for example, different orientations of keyboards, all of which are sort of being as causing this one particular feature map just fire strongly, and this is obviously something there's no rotation invariance built into the model, so it's learned that.",
            "Kind of automatically, which is very cool."
        ],
        [
            "The other approach I mentioned sorry to visualization, was to try and think that I'm here OK.",
            "Better speed up a bit was to try and maximize the input respect some particular output.",
            "So basically I do is sort of, you know you have some initial image.",
            "You do 4 prop, you get some output and then you can try and maximize the particular output.",
            "Sort of back popping all way back to the input and you can one fund.",
            "Application of this is the sort of funky artistic things from Google Deep Dream.",
            "So they basically said they would take some sort of random image like this.",
            "Push it forward to the network train.",
            "Now do back prop to maximize the banana output and you would have some little bit of constraints just to make sure that the image of made some kind of basic statistics."
        ],
        [
            "You expect and you can get these sort of credit.",
            "You can do this sort of different scales and stuff and get these crazy sort of psychologically summations and stuff like that.",
            "I mean, it's not quite clear that this tells you about the model, but it does look very cool.",
            "OK, so let's talk about that."
        ],
        [
            "Training, so this is a bit perhaps more useful.",
            "So essentially the dominant paradigm for training these models is stochastic gradient descent, so the idea is going to take a small chunk of data, do back prop with that, the gradients noisy.",
            "It doesn't matter.",
            "The key point is you want lots of steps because the energy surface is changing, so that if you spend a lot of time trying to compute very accurate gradient information at a particular point, it's a waste of time.",
            "You might as well just go roughly in the right direction and get a new gradient estimate there, and so basically that's the rough intuition.",
            "So This is why you know, having a small batch size seems to be affective.",
            "Initially you can start off with a large initial learning rate, but to sort of make progress you do actually need to anneal it OK and then and momentum seems to be very useful thing, so I guess I maybe don't have a slight momentum, but momentum generally seems to help when there's variance something called Nestor Amentum that Ilya gave it looked into, which also seems to help too.",
            "So generally these two are sort of, you know, components, simply vital to sort of optimize these models effectively."
        ],
        [
            "Just look at the annealing of the learning rate.",
            "So this is just showing.",
            "I guess here this is your training set error in the solid lines you can see it starts to plateau basically after September of parks and then if you just drop the learning rate it drops down to new drops down yet again and so rough intuition is your energy service has sort of curvature different scales and that the large learning rate you can optimize the shallow directions of curvature, but the very narrow valleys you're going to be oscillating back and forth and if you drop the learning rate will drop down and optimize those much more narrow dimensions and you keep getting by but you start with a .1 learning right up here by to hear yourself down to point.",
            "You know 1 -- 5 or something and then really you know things started to flatten out and you put the key.",
            "Point is, as you can see also that the violation error the tests or whatever is also dropping when you do this annealing of the learning rate.",
            "So it is very important."
        ],
        [
            "And then just using that visualization technique, you can see that in fact how the features evolved during training.",
            "So this is rather non linear scales.",
            "This is sort of 1 two whoops sorry 1 two you know.",
            "Five 1020 Thirty 5000 epochs or something like that, so you can see these early layers train very fast and they get locked in, but those in the middle of the model.",
            "This is Alex net only got you know."
        ],
        [
            "Five coalition allies.",
            "It does actually take right until the very end before these.",
            "That's sort of the higher up lies in the model train.",
            "Effectively.",
            "OK, so before that they're just really not picking up anything distinctive, but they do start to pick out quite distinctive things towards the end, so this is sort of saying that you know This is why it's very if you stop your model after just any parks or whatever, that doesn't tend to do as well as if you just have the patience to let it rain for a lot longer.",
            "Now one."
        ],
        [
            "Thing that it does seem to work quite effectively is trying to sort of normalize the data between layers so I haven't talked much about preprocessing.",
            "But you know, the classic sort of advice.",
            "You should just try and whiten your data in the waiting for data removes the sort of 1st and 2nd World dependencies and therefore let's the model focus on these much more sort of interesting ones like that instead of wasting his time trying to handle the 1st and 2nd order moments of the data and so this is batch normalization is a little trick that some of the quotes are group came up with where you going.",
            "Essentially, appliance of impoverished form whitening in between the layers of the model.",
            "So the rough idea is going to compute a sort of.",
            "Over a little mini batch of data, I kind of mean vector over your activations X.",
            "Here is your sort of feature mapping sort of vector form, so you're going to compute it sort of per pixel mean, so either of these means and your computer pixel variance, and you can use that to just normalize the output, normalize the feature responses OK, and so this in practice.",
            "Helps the convergence of the model quite a bit.",
            "OK, so this is the sort of this is the Inception network in the black dashed line.",
            "Without this trick.",
            "This is, I guess it's number of weight updates and this is sort of I guess accuracy.",
            "And if you use this batch normalization idea they are able to sort of you can see the convergence is much faster in a fraction of the epoch.",
            "So this thing this is a trip seems to work quite well.",
            "Lot of different things now.",
            "You might say, well, what about that?"
        ],
        [
            "Great, so in this diagram I showed here, this was some sort of manual annealing, essentially with it when the training error sort of started to plateau, you manually dropped it by some predetermined scale fact."
        ],
        [
            "How about doing this automatically?",
            "Is there some sort of more principle where you can do it, says whole little cottage industry of trying to come up with different ways of dynamically adjusting the learning rate so autographs one very you know very well known one year amsinger.",
            "So this is an idea here where this is your step size which uses fixed.",
            "This is your your gradients and see what your weight update is going to have this little denominated term which is going to take into account.",
            "It's going to accumulate the gradients from the previous weight updates and the problem with this one is it's a nice idea so naturally gives you a way to attenuate.",
            "This this, this this overall number he's going to small, of course, because this denominator monotonically increases, so it gives you a nice way of tuning down the learning rate catches.",
            "Of course, you sort of amount of progress you can make is kind of fixed, because this thing you know as I said it can never decrease.",
            "In practice, you end up under training the model's a little bit with this one out of deltas.",
            "Another approach this is 1 sort of motivated by self dimensionality arguments that sort of tries to fix some of the problems with this one.",
            "So the denominator is the same, but the numerator is different.",
            "There's a whole bunch of you know.",
            "Again, postdocs at the time had a sort of.",
            "Quite a complicated one that was sort of her dimension adjustment of the learning rate and then there are some more recent ones as well that seems to work quite well.",
            "Adam and stuff like that.",
            "And so on.",
            "So these the truth is, I guess people try these things for some applications that seem to work well, others not so much."
        ],
        [
            "So one of the classical objections to this whole neural net story was was this worry about kind of local minima.",
            "So all these people who worked on convex optimization was very happy that they can sort of guarantee that they would.",
            "There was a single minima to their solution, maybe, and they were sort of the sceptical.",
            "The neural net sort of finding good minima, and so this is an interesting, admittedly, rather simplistic sort of experiments where they took some very small multiple perceptrons are fully connected Nets.",
            "Tried training them from realizations, this one of Gans postdocs in fact.",
            "Yamaken postdocs and a command scare, so she took it very small network of his two hidden layers, each with 25 units and from different randomizations, train them very carefully and then looked at the test losses OK. And So what you see is a distribution as you might, which tells you that you know there is some difference in the energies or or the loss, whatever that you discover with the different initializations.",
            "With very small models you know that you can imagine that the difference between the sort of the global minimum and the typical minimum that you could find.",
            "It may be quite large, right?",
            "So we sort of this distance here I guess.",
            "But the nice sort of story that seems to emerge is that when you make the models bigger, well, first thing, of course is that they're sort of test losses decreased, which sort of makes sense, right there?",
            "More capacity not fitting befitting the data, and they're not overfitting quite yet.",
            "But the nice thing is that with the distribution gets narrower.",
            "OK, so in other words, it's really sort of saying that with these bigger models that you know there are many minima, yes, but they all have some sort of quivalent energies that which is good, so it doesn't really matter which minimum you fall into, it's going to be.",
            "Pretty close in terms of overall energy to the lowest one out there.",
            "Oh, so they were doing.",
            "I mean, each model is initialized randomly.",
            "I guess the prescription they used.",
            "I'm not quite.",
            "I can't remember exactly how they did it.",
            "I mean, it probably was drawn from Gaussian distribution and how they can they estimate.",
            "The variance is probably some ratio fan in fan out and stuff like that.",
            "There's various kind of rules of thumb for doing these things.",
            "You know that it's a local minimum.",
            "I mean they didn't test degrading well, right?",
            "So they train it right?",
            "So that at this point the grading becomes very small, so there was some minimum, but it's obviously unclear whether it's a good minimum or bad minimum.",
            "So This is why they made this histogram and you can then see that there's the overall sort of depth of the minimum.",
            "Doesn't seem to vary too much between all these different memory.",
            "I mean, it's clearly lots and lots of memory can just permute the matrices in the model and then you end up with a different solution, but.",
            "Yeah, so this is.",
            "I mean I it's I think it's encouraging.",
            "Of course it's not completely conclusive thing because these are the small toy models and so on, but I think it's an interesting result nevertheless.",
            "OK, So what about?"
        ],
        [
            "2nd Order methods right this whole.",
            "You know people don't.",
            "Automation courses.",
            "Most of the things they are focused on sort of more complicated strategies for optimizing, so you can imagine that you know if you can complete secondary information, you'll be able to build this Hessian matrix HT and then you would compute or wait update by kind of inverting.",
            "So this gives you sort of quadratic approximation, drainage surface all those different dimensions of curvature would suddenly sort of.",
            "You wouldn't have to worry about it too much.",
            "So the catch is of course that you know if this is a big model with millions of parameters.",
            "This is a sort of, you know, maybe a going to be a very large vector so you know million 50,000,000 dimensional vector and then this way matrix is 50,000,000 by 50,000,000.",
            "So building storing it is impossible, let alone turn.",
            "Invert it and stuff like that.",
            "So there's a whole bunch of approximations you can think of.",
            "Dream up, you could sort of forget about the off diagonal elements.",
            "Just try and look at that.",
            "And in fact you can compute that quite efficiently.",
            "There's a sort of just requires effectively double the number of.",
            "Regular back prop operations and then you can compute these sort of diagonal hash in terms.",
            "There's a bunch of sort of you can sort of computing approximate version of this with some sort of truncated consecrated methods.",
            "This is James Martens thing, as you can try and come with a low rank version of it for each batch.",
            "This was a yes or Dickstein had this idea and there's some talk about this in the next slide, so I guess the truth is that despite all these efforts, the extra computational doesn't seem to be really worth it empirically, I mean.",
            "Then they is taking these dumb steps more dumb steps into better than taking fewer carefully carefully.",
            "Computed steps, so I mean this story might change if you've got a very very large distributed setting with thousands of different GPU's, you might argue, well, you know, maybe it makes sense to sort of have some of the workers computing kind of 2nd order information to do the update, but no ones actually sort of really demonstrated this practically."
        ],
        [
            "There's some interesting work from Yonder Fan and Yoshi's Group.",
            "Looking at this whole optimization problem.",
            "Kind of subtle point perspective.",
            "So you can think of this idea that we start out initially many of your directions of curvature kind of pointing downwards, so and then as you get when you're in some local minimum rule pointing up.",
            "So as you're in the middle optimization, there are sort of many other dimensions as sort of down another ones up, and so you're basically in this sort of very high dimensional sort of saddle point.",
            "And then you can make this paper to make some arguments that that's some of the traditional.",
            "STD and things like that have problems.",
            "A scaping from the saddle points that they sort of get linger in this saddle point and what you really want to roll off down one of the sides.",
            "And there's some sort of you know this is a sort of version of Newton method where the eigen values on the diagonal Hessian are kind of enforced to be sort of positive essentially, which basically taking absolute value of your Hessian matrix and then that.",
            "Experiment seems to sort of improve the convergence performance and stuff like that with these models.",
            "OK, so that was a bit of a whistle stop tour.",
            "You know how you actually optimize these models?"
        ],
        [
            "Terms of proving generalization, so the obvious tricks you can use, like if there are certain variances you know you don't want to have in the model so you don't have the model.",
            "You can kind of help the model by sort of giving it to in the form of the data.",
            "So by taking the input image, translating it by adding small translations, but keeping the same output label, that sort of helps them learn that maybe small translations aren't important, and it should kind of ignore them, and so you can do this can be extended to many things, like color transformations, scale changes.",
            "Flips and so on so forth.",
            "This is a regular thing that always seems to help.",
            "You can do weight decay, so sending fully connected layers, this seems to be very useful.",
            "We got lots of parameters that convolutional networks naturally give you weight sharing.",
            "If you do have multiple tasks, so you want to sort of, you know, classify objects.",
            "We also want to, perhaps you know.",
            "Segment them or something or two will look at it in second by having multiple heads to the model.",
            "So this is sort of just having a simple classifier.",
            "The top you have multiple different outputs that cannot help regularize two and then of course you can also inject noise into the network, so most Whiting.",
            "I know one of this is dropout from Jeff Hinton, and there's a few other variance."
        ],
        [
            "Just so one natural question that people so you spend less time regularising, why do you have a smaller model and be done with it?",
            "Well, you know anyone have to worry about regularization.",
            "Well this is a sort of rough little diagram explains why I think so.",
            "We have some data.",
            "There is high density regions where the data structures quite complicated.",
            "This sort of low density regions where the very few points.",
            "If you have a low capacity model you're going to.",
            "It'll do something sensible everywhere, but it will sort of miss some of the fine structure in the height.",
            "OK, now if you have a big model, lots of parameters.",
            "Well now it can fit all those little you know all the details of your data nicely.",
            "But then it's got his extra capacity and it's liable to do site more crazy things in their low density regions.",
            "There's nothing to kind of constrain the function and what you're doing.",
            "Regularization is regularization, should have an effect in these low density regions where there's nothing where there's no data to sort of, override it, and so it will sort of.",
            "You get the best of both worlds, hopefully right, so it will fit the details in the high density regions and still not do anything to nuts outside of them."
        ],
        [
            "OK, so one other quirky thing to mention, I suppose, is that there's a whole interesting sort of observation which is true of any sort of discriminative approach.",
            "I guess that you do see it is possible to construct images which will in fact fool the model into producing a certain desired output.",
            "So this is, you know, a couple of papers that look into this.",
            "And I'm not quite sure how this where this has links on from next seriously, but it's worth.",
            "These are fun, so you can create sort of these noise images, which will you know the model will think is a Peacock or something like that.",
            "OK, so and so no human would make such a mistake, but somehow these models along way from this sort of training images seen in the training set.",
            "The decision surface can be doing slightly weird things right?",
            "So there is some argument for trying to come up with better regulations of these models."
        ],
        [
            "Just to talk about, drop out for a second, very briefly, you've got this.",
            "This is just adding random noise to the feature activations.",
            "This is in fully connected layers and you basically randomly set half the feature activations to zero during training, but this is a different random subset for each example and then at Test time you don't do this random deletion, you just, but you do have to remember to re scale the weights because you the subsequent we're expected to sort of smaller activation.",
            "Coming into them, and this does seem to sort of help immensely if you have enough training data, you don't need to do this, But this thing does seem to help.",
            "Alright."
        ],
        [
            "OK, I've got some slides which is sort of rules of thumb on how to get these things to work well from Mark Aralias slides I could talk about these, or I could dig into people cover these things, something yesterday.",
            "Like just."
        ],
        [
            "Is a. OK, I'll do it very quickly.",
            "OK, so essentially this is just sort of how do you get your models to work?",
            "You know you've built your beautiful model, you got your nice cool data set, you press go and it doesn't really train very well.",
            "So one thing you can do is you, as I said, you can look at the filters in the first layer.",
            "You know, certainly expect if it's an image to see.",
            "Surveys like things this something bad has gone wrong.",
            "If you get any of these sorts of things coming out to correlate these things like structure, you can try the brace or feature visualization things I mentioned earlier you."
        ],
        [
            "Hope to see something sensible.",
            "Certainly if you just.",
            "For giving given life is if you look at this is different in units and these are different training examples.",
            "You don't want to see this sort of thing.",
            "This is telling you that some of the units have died.",
            "They don't have any activation at all.",
            "There's also telling you that somehow.",
            "You know different training examples causing the same broadly similar activations across the network, and so it's very very strong correlations here between different units, which is kind of weird."
        ],
        [
            "And that's wrong.",
            "We're looking for is much sparser thing like this, where different units are turning on for different inputs, and so on and so forth.",
            "So that's the sort of thing you'd like to see.",
            "This is of course, just you know effectively vectorizing your feature Maps at each each layer to give each row he'll be the vectorization of your feature Maps of each."
        ],
        [
            "One thing you could, of course, is just just take a small subset of related checker training model, should be able to minimize the training or effectively on that."
        ],
        [
            "Let's see what else.",
            "If you're training blows up, maybe learning rates too large, or you've got an error in your numerical gradients.",
            "If you if.",
            "If you do minimize your loss, but then you the thing you care about, the accuracy on your task is terrible, you might want to check your loss function.",
            "Maybe you've got some degeneracy in that, or something.",
            "If you're not.",
            "If the networks converging but they're pretty bad solution.",
            "I mean this sort of sort of Canonical deep learning solution just to make the model bigger, which is a bit of a.",
            "Live answer, but you know that might be something to do with it, and if it's too slow then you know basically get a bigger computer.",
            "It's the slightly silly answer.",
            "OK so."
        ],
        [
            "OK, so I'm just going to.",
            "I guess I should say that these models of course are now very widely used in industry, so in Facebook won't be spending some time last couple of years.",
            "So there's about a billion images of they uploaded or something like that, and each image gets seen by two of these components.",
            "Wonders face recognition.",
            "This is one of the older face recognition models.",
            "Another one does sort of generic object recognition and stuff like that, so they really used in this very serious way and there's very they do a lot of important things, you know.",
            "Facebook and Google and stuff like that so it really work in a pretty spectacular way."
        ],
        [
            "I'll just skip over this because yeah, sure.",
            "What is Pennzoil to your test that is so?",
            "This is on the.",
            "Label faces in the wild data set, so this was this was a slightly old paper I guess now, but this was a red model.",
            "Was that this deep face system that again it's now they've got a bigger model and it's you know these things constantly change and I'm slightly lost track of where exactly what the structure is, but with this model they were sort of getting quite close here to sort of human performance, and I think the best results are better than that now.",
            "So I think the mega faces the new data set that's come out.",
            "The bigger one with sort of millions of examples and I don't have my account.",
            "Don't know how the Facebook system works on that.",
            "I'm not sure they've actually tried.",
            "Tried it in anger.",
            "I mean, of course there optimizing for some internal benchmark which is different to the public benchmarks, right?",
            "So it's going to be hard to say, but they were all using big continents basically."
        ],
        [
            "This is fair to say.",
            "OK, so I can't train quickly in the last few minutes.",
            "Go over some of the applications of these things in different vision things.",
            "Broadly speaking, one of the things we often carry selected is trying to localize the object bounding box around, not just simply wasn't picturing cause you."
        ],
        [
            "Multiple objects in.",
            "There's two broad of ways of doing this.",
            "One is you just going to sort of ascension.",
            "Examine every single position and scale exhaustively so the Canonical example of this would be the over feat system from Yan students, PS, seminarian others.",
            "The second approach is to essentially have some mechanism you know beforehand, identifying potentially interesting regions of the image, and then take each of those interesting regions and shoving through a component to classify them.",
            "What's interesting is that despite intuitively you think maybe this thing would be the, even though it might be expensive, would do the best in practice.",
            "You know the best models do seem to end up using this second approach, so it's obviously you have to have a sort of comprehensive set of regions.",
            "So let me just quickly go through those two."
        ],
        [
            "Things before I get into too much details.",
            "OK, so broadly speaking yes, exhaustive approach is just going to slide this thing over the image.",
            "Everything is sort of convolutional in some sense, so these things, even though there is a fully connected layer here, they become sort of 1 by 1 convolution when you do it like this, so you can just sort of slide them all over the image again."
        ],
        [
            "And you do this in multiple scales, so you're going to get a bunch of Maps basically.",
            "So if you have 1000 classes, you'll have for each location of the input window you're going to get 1000 dimensional vector, so different positions input window.",
            "You're going to get rid of these and then that happened over different scales, and then you can also try and progress on the bounding box coordinates too."
        ],
        [
            "So that will become a sort of four dimensional output and this."
        ],
        [
            "And so these are.",
            "This is before non maximal suppression, the kind of result you get."
        ],
        [
            "And then and then these are results with non Max suppression.",
            "OK so this is."
        ],
        [
            "This exhaustive slide over everywhere.",
            "OK, so not Max."
        ],
        [
            "Impression would be So what happens if you do this?",
            "Of course you're going to multiple high scoring.",
            "Bounding box is very very similar to one another.",
            "OK, because if you just shift the input window slightly, it's not going to change the output to dramatically service high in one location is going to be in neighboring scales and positions, So what you can do is you can just have some mechanism of merging these these bounding boxes into a single one, and so this is I have to say a little bit.",
            "This is what non Max suppression means.",
            "This is a little bit heuristic I would have to say.",
            "I mean I think.",
            "There are more steps to try and merge this into the whole learning procedure, but it turns out to be quite important.",
            "Quite important mechanism for sort of because you get penalized, of course for saying there were two objects when they're really one in the various valuation criteria people use."
        ],
        [
            "So one, So what happens in practice, of course, is that you know when you're doing the sliding window thing.",
            "You do end up with errors in Omak suppression and also just sort of false alarms like random bits of background.",
            "The model seems to fire on.",
            "You do end up with false alarms, which I think is the main reason these models don't do."
        ],
        [
            "As well as these things where you have an initial input image, you have some proposals, some proposal mechanism which is extracts a large number, so you know 2000 different regions, and then you're going to pretend each one is a separate image and slam it through your favorite classifier.",
            "So there's a whole bunch of these different approaches.",
            "I think the state of the art with this I'm probably going to be wrong because changes so fast mine, so if you take the residual network models from coming here and others and use that as your neural net, and there's very sort of sophisticated proposal mechanisms, that seems to give the best.",
            "Detection performance on the on the various benchmarks.",
            "But there's a lot of engineering there on how you do the proposals, and so on."
        ],
        [
            "The whole thing works for video as well, so you can just simply have 3.",
            "Answers for different regions.",
            "Because there's some seating structure that's right.",
            "So yeah, I think there are people are doing this sort of thing.",
            "It helps, but it's much less.",
            "It's always been underwhelming actually.",
            "I mean, it gives some small gain, but it's.",
            "I think the general rule is like building a better classifier has thus far delivered the biggest performance gain, so that in the Coco challenge that happened last year's one, I mean the residual networks, had a far better than Microsoft Gang, had a much, much better classified, anybody else with residual network thing, and that in the end just blew everything else out of the water 'cause people were trying all these other things too.",
            "But I mean at some point of course will probably be unable to improve the classifiers anymore.",
            "And then yeah, these things should not helping.",
            "So this is the.",
            "This is a 3D component now, so you got a video and you're just going to do now 3D convolutions.",
            "So your kernels have on 2D kernels at three by 3D kernels, and so it's basically three by three by three convolution kernels with two by two by two Max pooling, and this is sort of again a fairly shallow model by modern standards, but this is when you run on video.",
            "There's a really substantial amount of computational overhead trying to run on.",
            "Decent resolution video."
        ],
        [
            "Things I'll show you some.",
            "Just some fun so this is just some benchmark on people use.",
            "Interestingly, combining with at least maybe a little bit out of date with what the current state of the art is.",
            "But until very recently combining with some of the handcrafted features did actually give solve some gain over the 3D component, but I'm pretty sure every time that the handcrafted.",
            "Yeah, so this was using some features drive from optical flow.",
            "I'm sure overtime these numbers will I mean the raw component things will improve."
        ],
        [
            "This is just showing that if you do have some temporal extent your filters, it does give again.",
            "The blue curve is without, you know, is a sort of 2D filter spatially, but no temporal extent.",
            "Red is.",
            "If you have a little bit of a little bit of temporal extent, it does actually give a performance gain and this is just showing this sort of.",
            "You get about a feature representation.",
            "If you incorporate this."
        ],
        [
            "Some temporal structure just show some videos of these things running, so these are like this is different sports being played.",
            "This is a top 2 predictions from the model so you can see it's able to sort of discriminate between fairly similar sports.",
            "Basically this is I guess another one.",
            "So lots of obscure sports in this data set, but the model does fairly well.",
            "Yep.",
            "Yeah, so it does.",
            "It does beat out a single frame, yeah?",
            "There is some dynamic structure that does actually help you.",
            "Yeah, the baselines are in the tables of a single frames and stuff, OK.",
            "So that so you can see that single frame stuff.",
            "And."
        ],
        [
            "OK, I guess I can very quickly go through this.",
            "So yeah, so one thing of course you want to do is you might want to just give you know.",
            "Classifications about going from pixels to a sparse label vector detection is about going to some bounding box, but you can actually very easily get these models to produce pixel images as output.",
            "OK, and these images could be, for example, segmentation.",
            "The image or other things, and will.",
            "One key difference here is you don't want to pull at this point because you know classifications by going from this very high dimensional signal down to this very low dimensional signal or not very low dimensional but relatively low dimensional, whereas in outputs also an image.",
            "It turns out that pooling you don't want too much more."
        ],
        [
            "Pulling so."
        ],
        [
            "Is just a little example of a simple model you can predict, like a sort of semantic per pixel label.",
            "So this is, you know wall floor, bed, pillow etc."
        ],
        [
            "And this is one of the depth.",
            "You can produce a pix."
        ],
        [
            "Depth map or even a surface normal map telling the orientation of each pixel in the scene."
        ],
        [
            "And this is 1 model that one of my students looked at with sort of multiscale thing.",
            "So these are sort of, you know, this is the number of feature channels.",
            "This is these are convolutional or basic convolutional layers.",
            "You take those convolutional feature Maps and you stick them in the subsequent scale of the network and repeat and so on.",
            "And you can train up."
        ],
        [
            "Nice and you can do basically the same architecture, just slightly different.",
            "You know different weights you can keep the same weights for this layer of the model, but for this sort of finer scales you have to sort of retrain for different modalities like surface normals."
        ],
        [
            "And class labels.",
            "So this layout here is sort of classic, so Alex net or VG style model that gives you sort of broader understanding of the scene as you."
        ],
        [
            "You can't predict the stuff you know.",
            "You can't predict.",
            "The sort of depth of just looking at a tiny Patch.",
            "You have to actually understand.",
            "OK, you know these are two walls and this is the floor and stuff like that.",
            "So you get that overall structure from the from the core scale and then this is just refining to make things sharper."
        ],
        [
            "And all you have to do really is just change the loss functions to be appropriate.",
            "So there was a bit of messing around here.",
            "We're just trying to find a sort of something that was invariant, you know, looked at this relative depths 'cause you know.",
            "Obviously predicting absolute depth is very difficult to do, but you can put it relative depths if you have the right loss function, surface normals.",
            "Just looking at kind of angles between surface normals and a standard sort of per pixel softmax for the late."
        ],
        [
            "Task and yeah, you can actually get some pretty nice.",
            "I mean these are just this is ground truth.",
            "These images collected with you know you get with the Kinect depth sensor.",
            "These are sort of predictions actually knew results may be a little bit cleaner than this to be honest."
        ],
        [
            "And this is surface normal, so you can see these.",
            "Actually look at many ways better than the ground truth."
        ],
        [
            "And then."
        ],
        [
            "You can use these things for scene pausing, so trying."
        ],
        [
            "Segment the scene with different object categories.",
            "This was some early work from young students."
        ],
        [
            "You can also use it for.",
            "Sort of bottles complications.",
            "This is a. Folks at MIT Sebastian songs Group that they were using it for sort of segmenting slices of microscope slides.",
            "So one thing you can do is sort of combine this notion of segmentation detection somehow.",
            "What you want to do, some producing bounding boxes you can do segmentations.",
            "This was a recent piece of work by some of the folks on Facebook where they have basically a little of Jeannette with sort of fancy head on top and are going to slide some window over the image and for each window they're going to try and predict a kind of segmentation mask for the object that's in the middle of the frame.",
            "And also they're going to score for saying how object like it is.",
            "So this is.",
            "This is a mechanism basically for that this is a way to propose a bunch of bounding boxes that can be used with your favorite super strong classifier.",
            "OK, so this is a object proposal mechanism, not a detection mechanism.",
            "Object detection mechanism itself.",
            "So when you run this over big image, you end up with this sort of big map of masks, right?",
            "So the ones in the center of Bright because they have high objectness and you can see there nicely sort of segmenting the animal.",
            "Versus the other objects in the scene.",
            "And this is just a map of the scores and you can use this to produce a whole bunch of bounding boxes, and so this gives you a nice way of justice.",
            "Taking a complicated scene like this because it's trying to sort of segment the object in the middle of the scanning window.",
            "You're able to sort of segment and detect these different object instances.",
            "If you have just a per pixel segmentation.",
            "All these sheep would have been merged into one sort of amorphus blob of sheep, but that's not actually very useful.",
            "You want to actually pick out each individual animal.",
            "And you can get it with this kind of approach.",
            "OK, so I'm rushing slightly but."
        ],
        [
            "Quickly go through this so well.",
            "You can also use these things for low level vision problems.",
            "You can use it with denoising.",
            "Is BM3DS is sort of state of the art nonparametric denoising approach and these neural Nets.",
            "Actually you can train them.",
            "So basically you train it to protect this as input and produce.",
            "You know that the original image is output.",
            "That's a training time.",
            "This is a test example.",
            "As you can see, it does a reasonable job."
        ],
        [
            "You can even get it to deblur images as well, so there's slight more complicated setup, but you can even use it in the blind setting where you don't have knowledge of the blur kernel, so you can sort of training all kinds of different blur functions, and then it will sort of, you know, still figure out what's going on so you can actually, which is somewhat surprising."
        ],
        [
            "Do things like inpainting, so this is just removing.",
            "Text to get a sort of clean photograph."
        ],
        [
            "And this was so slightly crazy.",
            "So big from being from.",
            "Of course rain is something that occurs very frequently and this was somewhat slightly.",
            "Crazy thing where you got a piece of glass, you got raindrops falling on it.",
            "You know.",
            "Can you actually remove the rain from your photograph so you can do this with the component?",
            "So this is this is the output from the components, so it's just removing the you can see as the rain gets heavier and heavier there's more and more glass water building up, but the output of this component doesn't really doesn't really don't see it effectively.",
            "So anyway, this slightly crazy application, but it shows that the comments can do some quite fun things.",
            "And if you just try doing something very simple like you know some pretty simple baseline like a median filter.",
            "You can see that all the rain is there, for example.",
            "When the jobs get really big, of course the network can't do anything.",
            "But and then finally I guess you know."
        ],
        [
            "Sort of sort of interesting directions and stuff like that.",
            "You know it's combining confidence with some kind of structured model on top so you know this idea is very old, in fact, so some of the check reading systems that Yan and Leon, Batu and Joshua designed back in the late 90s.",
            "AT&T use this kind of structure.",
            "You have a neural net the recognizing pieces of digit, and then you'll have some kind of.",
            "You have to do some sort of search to find the optimal combination of these different fragments to give the best overall explanation of the signal.",
            "So there was kind of an optimization problem.",
            "Had to do here on top and you can train the whole thing jointly and stuff like this and so this I think this is."
        ],
        [
            "So people are thinking about how to apply those different vision problems so."
        ],
        [
            "This example would be if you wanted to sort of.",
            "No.",
            "Get human body pose so you have a certain little graphical model here, which represents sort of different limbs and you know the head is dependent on the shoulder and the shoulders dependent on the elbow and always dependent on the wrist and so on, and vice versa as well.",
            "So these sort of conditional dependencies present so you specify the structure.",
            "This model you want to fit this to quite complicated data of humans, and so this was an attempt to try and do this sort of, you know."
        ],
        [
            "Common structure, so you basically have these part detectors that would find."
        ],
        [
            "Parts of the image.",
            "So you have these unique potentials that would basically be you know where do I think the face structure is and then you have these potential.",
            "These complicated distributions that you would learn with conditionals of like where's the face given the shoulder.",
            "OK and then this will be the sort of message you are passing in this little graphical model to then infer where where was the face and then from there you could.",
            "So this is sort of slightly bastardized version of some product belief propagation, instantiated in."
        ],
        [
            "Tickle model, so instantiate it in the neural net and so you can turn a lot of these operations that you would normally compute in belief propagation into.",
            "Something that you can sort of try and backdrop through.",
            "So I'm going very fast because I want to try and finish, But anyway this gave some nice results on sort of face.",
            "Post recognition and also for using for hand tracking too.",
            "'cause he was, so there's a clear, clearly defined model for the hand and and the fingers and so on and so forth.",
            "So that was sort of rather rapid overview of components in vision, so I apologize if I missed this latest greatest papers and stuff like that.",
            "But you know, trying to keep up with everything.",
            "There's an archive is very challenging, and so on so forth.",
            "Alright, so I'll stop there.",
            "Thanks very much."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Alright, so I'm now I'm not quite sure about everybody's backgrounds here today, so I'm going to give a bit of a general overview of continents starting from very basic principles.",
                    "label": 0
                },
                {
                    "sent": "You had back problems.",
                    "label": 0
                },
                {
                    "sent": "I'm not going to come back problems OK, but so pretty over fairly quickly.",
                    "label": 0
                },
                {
                    "sent": "Then the simple stuff and then talk a little bit more.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "About some of the applications side of things in vision.",
                    "label": 1
                },
                {
                    "sent": "So one thing to say is that I'm so many papers coming out of the moment in CPR and the other vision conferences that use components I can't possibly attempt to sort of covered.",
                    "label": 0
                },
                {
                    "sent": "Also, apologies if your paper or you know some important piece of work isn't mentioned here, but you know this is in some sense you know some sparse sampling of this sort of stuff that's happening at the moment.",
                    "label": 0
                },
                {
                    "sent": "Of course, unfortunately a little biased towards stuff that I've been involved with just because I haven't.",
                    "label": 0
                },
                {
                    "sent": "Have to be able to access the slides and so on.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Interesting sort of taxonomy.",
                    "label": 0
                },
                {
                    "sent": "The marker aliens are to put together.",
                    "label": 0
                },
                {
                    "sent": "So basically today's entire talk.",
                    "label": 0
                },
                {
                    "sent": "You just make the point that there are many deep models are different types of deep learning model out there.",
                    "label": 0
                },
                {
                    "sent": "I'm just going to talk about just one particular model, so anyway.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This is going to be our covenants as I've abbreviated, so this is a model that iannacone and colleagues at Bell Labs came up with in the late late 80s, and this is effectively really just the standard neural net with some specialized connectivity structure and a few other things in there.",
                    "label": 1
                },
                {
                    "sent": "And just so just I'm just going to give a bit of historical overview of the thing of sort of, you know of stuff.",
                    "label": 0
                },
                {
                    "sent": "And then we'll talk a little bit in detail what actually goes on in these models.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So just to say that they're not, they weren't sort of invented completely out of the blue.",
                    "label": 0
                },
                {
                    "sent": "There was a long sort of series of work that preceded them so broadly one could think these models are something called a multi stage.",
                    "label": 0
                },
                {
                    "sent": "Who will diesel architecture?",
                    "label": 0
                },
                {
                    "sent": "So who lives where?",
                    "label": 0
                },
                {
                    "sent": "Your scientists were trying to find how the human visual system worked, and they notice that you have these stages of sort of simple cells which essentially filters and complex cells.",
                    "label": 1
                },
                {
                    "sent": "That sort of combine the outputs of these simple cells, and then the idea.",
                    "label": 0
                },
                {
                    "sent": "I mean, that's been the incarnation.",
                    "label": 0
                },
                {
                    "sent": "That sort of computationally carnation.",
                    "label": 1
                },
                {
                    "sent": "You see in these models is really so repeated stages of this simple cell complex cell structure, and then the idea is that that would hopefully compute successively more invariant features, and then you could stick a classifier on top.",
                    "label": 0
                },
                {
                    "sent": "So Fukushima had some very interesting work on this model.",
                    "label": 0
                },
                {
                    "sent": "Corneal cognat Ron.",
                    "label": 0
                },
                {
                    "sent": "Which essentially embody this concept and didn't quite wasn't clear was be trained and so on and so forth.",
                    "label": 0
                },
                {
                    "sent": "And then, you know Yan's conference, and then there are other people also have tried to sort of instantiate the biology like Poggio and stuff more recently.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So very roughly, I'm sure most of you know this, so I'll just go very quickly.",
                    "label": 0
                },
                {
                    "sent": "So roughly very roughly speaking, essentially it's a feedforward model.",
                    "label": 0
                },
                {
                    "sent": "You're going to put in some image.",
                    "label": 0
                },
                {
                    "sent": "OK sorry, trained by clustering rice.",
                    "label": 0
                },
                {
                    "sent": "OK, I see I see so they didn't have the snow backdrop in the thing right?",
                    "label": 0
                },
                {
                    "sent": "Yeah, back then so.",
                    "label": 0
                },
                {
                    "sent": "OK, so very roughly, you're going to be taking input in this.",
                    "label": 0
                },
                {
                    "sent": "In most cases there's going to be image will look at a few cases where it might be something like a video later on, and you're going to be essentially filtering that image with a series of learned filters.",
                    "label": 0
                },
                {
                    "sent": "That's the convolution operation passing through some nonlinearity and doing some pooling, and to get some feature Maps, that's one layer of the model, and this is going to be repeated multiple times, so into this in more detail later on.",
                    "label": 0
                },
                {
                    "sent": "OK and at the output of the network we will have some prediction is going to think just for example, consider the classification scenario.",
                    "label": 0
                },
                {
                    "sent": "You'll have some prediction as to what class objects in the image, and then we'll have some ground truth label available so these models can be trained, supervised in contrast to many other models you'll hear about later on in the week, and we're going to train the whole thing essentially by back prop.",
                    "label": 0
                },
                {
                    "sent": "OK, and that's going to update the parameters in the model, which in this particular zone the simplistic incarnation is just the convolutional filters that you have in each layer.",
                    "label": 0
                },
                {
                    "sent": "OK, so so these models have been around for a long time just.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To sort of give some context so they work very well on these on these sort of simple, you know, perhaps you might say simple problems like handwritten recognition and stuff like that, so you know, and indeed that people have managed to sort of crank down the errors on amnesty.",
                    "label": 0
                },
                {
                    "sent": "Another sort of handwritten datasets, incredible values in fact, slightly better even than human performance on some of these tasks.",
                    "label": 0
                },
                {
                    "sent": "And then for sort of similar recognition problems like you know, recognizing Rd signs, they also got people got very good results and stuff like that.",
                    "label": 0
                },
                {
                    "sent": "But when people try them, this is sort of winding back to say the mid 2000s.",
                    "label": 0
                },
                {
                    "sent": "About 10 years ago when people tried these on the sort of computer vision benchmarks at the time, like Caltech 101, they didn't do very well at all, and in fact they were being beaten quite dramatically by standard methods like support vector machines and that kind of stuff.",
                    "label": 0
                },
                {
                    "sent": "And so This is why you know people weren't paying too much attention to them back then.",
                    "label": 0
                },
                {
                    "sent": "OK, So what changed?",
                    "label": 0
                },
                {
                    "sent": "There was a bunch of factors that came in.",
                    "label": 0
                },
                {
                    "sent": "So first of all.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "With the availability of big labeled datasets, image that was the first one.",
                    "label": 0
                },
                {
                    "sent": "Now we have things like Coco as well and so the idea, essentially by sort of justice.",
                    "label": 0
                },
                {
                    "sent": "Things like Amazon Mechanical Turk and a lot of time and energy.",
                    "label": 0
                },
                {
                    "sent": "You know, the community managed to label these big enough collection of images that we could start to think about, you know, training some these component models effectively.",
                    "label": 0
                },
                {
                    "sent": "So imagine it's the full version.",
                    "label": 0
                },
                {
                    "sent": "Burnett is actually 14,000,000 images or so on across 20,000 classes.",
                    "label": 0
                },
                {
                    "sent": "There's a smaller version which you all know is users.",
                    "label": 0
                },
                {
                    "sent": "The challenge one which is about a million images and 1000 classes.",
                    "label": 0
                },
                {
                    "sent": "And in 2012, Jeff Hinton and a couple of students access key analysis.",
                    "label": 0
                },
                {
                    "sent": "Cava decided to apply this.",
                    "label": 0
                },
                {
                    "sent": "You know, basically decided to have a go with sort of classical converts.",
                    "label": 0
                },
                {
                    "sent": "On this image, net data set.",
                    "label": 0
                },
                {
                    "sent": "OK, so in this.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Just to clarify, image that challenge.",
                    "label": 0
                },
                {
                    "sent": "The goal here is basically given a single image and you have to break.",
                    "label": 0
                },
                {
                    "sent": "You know one of 1000 sort of prediction as to what's in the picture.",
                    "label": 0
                },
                {
                    "sent": "OK so these are some example images.",
                    "label": 0
                },
                {
                    "sent": "The ground truth is just shown on each image and this was the sort of typical output from the network.",
                    "label": 0
                },
                {
                    "sent": "So in the top five responses, because the classes can be somewhat close, the scoring metric in image net allows you know if the correct the correct positions in the top five, then that's considered sort of OK and then acts considered correct.",
                    "label": 0
                },
                {
                    "sent": "So in this case here you can see if it's in red.",
                    "label": 0
                },
                {
                    "sent": "Then that's correct in this case here.",
                    "label": 0
                },
                {
                    "sent": "The true answer lens cap wasn't in the top five predictions, but you can still see it was making sort of sensible predictions as to what was going on.",
                    "label": 0
                },
                {
                    "sent": "OK, so now what was so this was this was just showing some sample output from their model so their model affect.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "It was the same model as Jen Kerns, model from along time ago, but really just scaled up in size.",
                    "label": 1
                },
                {
                    "sent": "OK, so it's much bigger in terms of number of layers or 8 layers.",
                    "label": 0
                },
                {
                    "sent": "It had many more parameters so you can see at the bottom it had.",
                    "label": 0
                },
                {
                    "sent": "Actually, you know 60 million parameters and of course to estimate all these parameters, need lots of training data, and that's where image net came in.",
                    "label": 0
                },
                {
                    "sent": "So instead of you know thousands of images that you have in datasets like Caltech in image net you got million plus images.",
                    "label": 0
                },
                {
                    "sent": "And then the other sort of 3rd component of this sort of success was this be able to sort of run these models on the GPU.",
                    "label": 0
                },
                {
                    "sent": "OK, so big models, lots of data.",
                    "label": 0
                },
                {
                    "sent": "You have a lot of computation, train them and access keeps wizard coder, so he implemented some very efficient GPU kernels which were big speedup there was there were one or two little tricks in there too for sort of better regularization of the models, but that's basically it.",
                    "label": 0
                },
                {
                    "sent": "OK so.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This was the state of the computer vision sort of state of the arts prior to the conference error, so this was the rampant competition starting 2010 and these are the best results in those in 2010 and 2011, so these were not using deep Nets, which is using a lot of very complicated setups or handcrafted features.",
                    "label": 0
                },
                {
                    "sent": "The top five error rate here was, you know you can see about 28 to 26% to lower is better here and then you know it's risky paper came in.",
                    "label": 0
                },
                {
                    "sent": "You know it dropped it down quite dramatically down to sort of about 18%, sixteen 1718%, and perhaps even more remarkable thing is, since then people have really been able to take these models, adapt the architectures, tune them up, figure out what works and what doesn't, and the error rates are just kept dropping, so this in 2014 it was down to sort of about 6:00 or 7% and then a crude estimate of human performance will put this about 5%.",
                    "label": 0
                },
                {
                    "sent": "And then instead of last year, things were down below 5%.",
                    "label": 0
                },
                {
                    "sent": "So it's a little bit better than humans on this data set, so it's really gone from being a sort of.",
                    "label": 0
                },
                {
                    "sent": "Problem, which was a long way from being solved in the networks are really giving kind of pretty useless answers to being the case where it really works very well indeed.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Just to show you sort of, you know, one of these.",
                    "label": 0
                },
                {
                    "sent": "This is just maybe not state of the art model, but this is a sort of from clarify which is a startup which has a little.",
                    "label": 0
                },
                {
                    "sent": "Website you can upload a picture and get some results back.",
                    "label": 0
                },
                {
                    "sent": "These are showing the kind of results you get so they can take these complicated scenes and they can give pretty sensible sort of.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This back problem and stuff like this so you still a few slightly weird things going on there, like Helsinki for some reason scores very high and this was.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Deliberately complicated one, so this is actually inside of a cave, OK, and you can see here for some reason I think the Sagrada Familia in Barcelona is, perhaps, you know, some similarity there so you can see that they're not completely foolproof.",
                    "label": 0
                },
                {
                    "sent": "They still make mistakes that humans wouldn't, but certainly there are still doing way better than.",
                    "label": 0
                },
                {
                    "sent": "Before now, one actually very important aspect, I think, is that you might say, well, this is great on image net well, but I don't really care about Internet.",
                    "label": 0
                },
                {
                    "sent": "I have another vision problem.",
                    "label": 0
                },
                {
                    "sent": "I want to be able to use some deep net on and I think one of the pleasant surprises from all of this was the fact.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But if you train your model on image net, the features, the feature presentation you get from it, so that is if you just chop off that last layer of your model, which is the classifier which we're going to in a bit, and he just regard the hot the rest of the models are giant feature extractor.",
                    "label": 0
                },
                {
                    "sent": "Those features generalize quite nicely to other datasets, so fighting for example.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Go back to these old sort of problem.",
                    "label": 0
                },
                {
                    "sent": "People don't so many other datasets.",
                    "label": 0
                },
                {
                    "sent": "This is some old graphs that I have just showing on account at 256.",
                    "label": 0
                },
                {
                    "sent": "So this was in sort of 2013.",
                    "label": 0
                },
                {
                    "sent": "This was back with the sort of previous best state of the art models and if you just take that feature extractor you trained on image net and just now train just the top classifier classifier on the Caltech rather small number of Catholic training images.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You can see on this X axis, but just varying that you can see very very dramatic, so we just in fact we just six image training samples per class.",
                    "label": 0
                },
                {
                    "sent": "You already exceeding the previous sort of pre deep learning state models and you can see it sort of having the overall error rate and things like that.",
                    "label": 0
                },
                {
                    "sent": "And this was a pretty small architecture.",
                    "label": 0
                },
                {
                    "sent": "I'm sure the latest deep Nets would do even better.",
                    "label": 0
                },
                {
                    "sent": "Way better than this, but that's been sort of very, very handy thing because it really means now that we're able to take a lot of different vision problems even if we don't have a huge amount of training data we can train on image, net and then sort of adapt the features.",
                    "label": 0
                },
                {
                    "sent": "Just by retraining, you know the top layers of the model.",
                    "label": 0
                },
                {
                    "sent": "OK, so now let's go in.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Some of the details, so let's just we're going to review.",
                    "label": 1
                },
                {
                    "sent": "So what goes on each layer?",
                    "label": 1
                },
                {
                    "sent": "Just talk about how you select the architecture and stuff like that and look at how the training procedures and then look at some results on a different supervision applications.",
                    "label": 0
                },
                {
                    "sent": "Alright, so.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So just to start with, essentially each layer is going to take in as input.",
                    "label": 1
                },
                {
                    "sent": "Either if it's the first day will take in pixels of its subsequent layers, it will take in different able take in.",
                    "label": 0
                },
                {
                    "sent": "The feature Maps in the previous layer and you can just think about you know the feature Maps being an image with just multiple color planes instead of just three color planes are going to have a much larger number 700 or so, and you're going to follow up with something to learn dictionary and they're going to pass the resulting feature Maps some elementwise nonlinearity, and then there's gonna be something operation to give you output features OK, and then the whole thing repeated.",
                    "label": 0
                },
                {
                    "sent": "So let's look at each of these boxes in turn.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the convolution operation.",
                    "label": 0
                },
                {
                    "sent": "So basically there's your input image.",
                    "label": 0
                },
                {
                    "sent": "For example, firstly you got a little filter.",
                    "label": 0
                },
                {
                    "sent": "Now the filters only need to be small because in some sense you need to capture some of the local dependencies in the image.",
                    "label": 0
                },
                {
                    "sent": "OK and the local dependencies are far far stronger than the longer range ones and that the longer rate and so those long arrangements will be captured over the course of multiple layers.",
                    "label": 0
                },
                {
                    "sent": "But within each layer you can sort of get away.",
                    "label": 0
                },
                {
                    "sent": "Effectively we're just having a fairly small filter, so that's one sort of.",
                    "label": 0
                },
                {
                    "sent": "Key property that you're exploiting somehow in the structure of natural images.",
                    "label": 0
                },
                {
                    "sent": "That sort of would be true about general general signals.",
                    "label": 0
                },
                {
                    "sent": "And the second point is of course we're going to slide this filter all over the image now.",
                    "label": 0
                },
                {
                    "sent": "Effectively it means we're using the same set of filter coefficients of each different spatial location, and that's again, we can sort of get away with that by and large, but cause you know the statistics images are spatially stationary, so just doesn't really, you know the 1st order approximation.",
                    "label": 0
                },
                {
                    "sent": "It doesn't matter whether we are applying this edge filter, we expect to see the same distribution of edges.",
                    "label": 0
                },
                {
                    "sent": "Perhaps in this sort of bottom of the image to the top of the image.",
                    "label": 0
                },
                {
                    "sent": "And things like that.",
                    "label": 0
                },
                {
                    "sent": "OK, so each one of those convolution operations is going to give us sort of feature map looks like this so.",
                    "label": 0
                },
                {
                    "sent": "Gray 0 black is negative, white is positive and we're going to have a whole bunch of these filters.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is just one filter channel 1 filter and corresponding feature map channel and we're going to have a whole bunch of these which we're going to compute each layer, so we'll have a whole stack of these feature Maps.",
                    "label": 0
                },
                {
                    "sent": "That we've computed now just to make the point that there are some sort of variants that you do see sometimes in some models, which we.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Don't have the wait time across different spatial locations, so you might actually want to stamp for each spatial position.",
                    "label": 0
                },
                {
                    "sent": "You might not allow different filter, so this is often called your local locally connected layers and one nice example of that where that comes in is for example face recognition.",
                    "label": 1
                },
                {
                    "sent": "So what I'm showing here is a little this is actually one of these sort of system that was used at Facebook for recognizing faces, so they've already done some kind of alignment procedure and the first couple of days are convolutional, but then these sorry can't see the type here, but this these less down here.",
                    "label": 0
                },
                {
                    "sent": "Locally connected, so the idea is that somehow you want to have different filters that analyze the eyes to ones that analyze the mouth, and so on and so forth, right?",
                    "label": 0
                },
                {
                    "sent": "So, in this case, you know the sort of special transformations have been removed, so you know that you're going to be seeing sort of eyes and eyebrows and hair and stuff like that at the top of the image, and then things like mouth and chin and so on at the bottom.",
                    "label": 0
                },
                {
                    "sent": "So you want to undo the weight tying, and that does definitely help performance in this in this particular case, but this is obvious or other specialized application.",
                    "label": 1
                },
                {
                    "sent": "So in this case you would have a different.",
                    "label": 0
                },
                {
                    "sent": "Oh yeah, Yep.",
                    "label": 0
                },
                {
                    "sent": "No, no, because there's only.",
                    "label": 0
                },
                {
                    "sent": "As I said, there's already been a sort of a pre preprocessing stage where they fit Runner face detector.",
                    "label": 0
                },
                {
                    "sent": "They fit a 3D mesh to the face and then normalize it to some Canonical thing.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so it's already been done.",
                    "label": 0
                },
                {
                    "sent": "Yes, and so the idea is they basically have a different filter, different sort of weights at each spatial location because it explodes the number of parameters in your model, which is why in some sense they only have it high up in the model when the feature Maps are fairly small, but nevertheless it does give it important performance gain.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so then you can have some sort of compromise in the two.",
                    "label": 0
                },
                {
                    "sent": "You can have some sort of style representation which would allow you to have you know you wouldn't essentially have the same.",
                    "label": 0
                },
                {
                    "sent": "This is a way to essentially get you get more filters into your model.",
                    "label": 1
                },
                {
                    "sent": "If you want more capacity, but I don't think I should start to think of any models that use this.",
                    "label": 0
                },
                {
                    "sent": "Actually, at the moment successfully.",
                    "label": 0
                },
                {
                    "sent": "OK, let's skip.",
                    "label": 0
                },
                {
                    "sent": "I'm sorry.",
                    "label": 0
                },
                {
                    "sent": "Actually coming from the first layers of the convolutional, yes.",
                    "label": 0
                },
                {
                    "sent": "Actually it's like I did actually take that image, and I convolved those filters.",
                    "label": 0
                },
                {
                    "sent": "I sort of, you know, manually constructed, and I did indeed convolve those filters with that image to get these Maps so they are accurate in that sense.",
                    "label": 0
                },
                {
                    "sent": "OK, so anyway that's the basic idea is for the most part go forward, and as I mentioned otherwise, I'm going to be talking about essentially just the standard normal convolutional thing where we have a wait time across different spatial locations.",
                    "label": 0
                },
                {
                    "sent": "OK, so those feature Maps we're now going to pass into some elementwise nonlinearity.",
                    "label": 0
                },
                {
                    "sent": "Sorry, we just run through these silly anime.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Again, for a second.",
                    "label": 0
                },
                {
                    "sent": "OK, so here we go.",
                    "label": 0
                },
                {
                    "sent": "So the most common nonlinearity that people use, and this is going to be paid per pixel.",
                    "label": 0
                },
                {
                    "sent": "So this is the input value of the feature map pixel and this is the output value.",
                    "label": 1
                },
                {
                    "sent": "So essentially it's going to be a zero if it's less than if the input is less than zero and it's going to be just, you know, identity mapping if it's positive, OK, and so you're going to take this feature Maps now.",
                    "label": 0
                },
                {
                    "sent": "One thing I sort of forgot to mention or sort of skipped over, was that you're going to have per feature map bias, which effectively concert is going to translate this function.",
                    "label": 0
                },
                {
                    "sent": "The left or the right.",
                    "label": 0
                },
                {
                    "sent": "OK, so that can change exactly where this threshold where this thresholding operation is going to take place.",
                    "label": 1
                },
                {
                    "sent": "So this is your input feature Maps you got black values which are negative, which are positive when you pass it.",
                    "label": 0
                },
                {
                    "sent": "Through this, you're going to essentially remove those non negative values.",
                    "label": 0
                },
                {
                    "sent": "So this is what it's going to look like.",
                    "label": 0
                },
                {
                    "sent": "Now there's a whole bunch of different energies you could use so the classical choices would have.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Things like in a sigmoids as, which would give you this sort of output between zero and one, and then you've got 10 H functions, which sort of looks somewhat similar, but it's between minus one and one for various reasons.",
                    "label": 0
                },
                {
                    "sent": "I think people found that those things don't work quite so well.",
                    "label": 0
                },
                {
                    "sent": "In fact, I think it's Joshua's group who first.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Notice that these rectified linear units do in fact work seem to work very well.",
                    "label": 1
                },
                {
                    "sent": "They also have a nice computational advantage, which is that if you think about when you compute the backdrop operation, you do actually need to incorporate all you need to do is we keep around a mask of binary mask that tells you whether you're in this sort of dead part of the nonlinearity, or in the sort of linear region.",
                    "label": 0
                },
                {
                    "sent": "OK, so you don't need to keep around the derivative of your.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Your activation normal problem.",
                    "label": 0
                },
                {
                    "sent": "You have to keep around where you're forgiven activation what the slope is of this of this nonlinearity, but in this case of course the slopes either.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "One or zero.",
                    "label": 0
                },
                {
                    "sent": "So it's sort of computationally more efficient to compute during back prop speed things up as well.",
                    "label": 0
                },
                {
                    "sent": "There are one or two attempts.",
                    "label": 0
                },
                {
                    "sent": "One problem, of course, is that.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "If you're down here, there's no gradient, so you're sort of that element is sort of off.",
                    "label": 0
                },
                {
                    "sent": "It's hard to turn on again.",
                    "label": 0
                },
                {
                    "sent": "There's one or two attempts to fix that.",
                    "label": 0
                },
                {
                    "sent": "For example, you can sort of trying to have, you know, make this not as different slope, so this will be the A here would be a very small number, so we sort of skimming along the axis here, and you could try even attempting to try to learn this value a per per feature map or something like that, so these things give small advantages, but I think for the most part these are very simple rectified linear units.",
                    "label": 0
                },
                {
                    "sent": "Actually work very well.",
                    "label": 0
                },
                {
                    "sent": "OK, now the next part of the system is the pooling.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the idea here is we've got these feature Maps.",
                    "label": 0
                },
                {
                    "sent": "They encode sort of spatial spatial layout.",
                    "label": 0
                },
                {
                    "sent": "Still of the image, so there's sort of 2D structure of the picture is preserved, and we're going to do.",
                    "label": 0
                },
                {
                    "sent": "I mean there's a whole I should say there's a bunch of different variants of pulling that people have explored.",
                    "label": 0
                },
                {
                    "sent": "The simplest one is what I'm describing here, especially going to put down various Windows the size those windows will be predefined.",
                    "label": 0
                },
                {
                    "sent": "Something like there are two by two or three by three pixels, and sometimes they'll be overlapping with one another in this drawing here there sort of non overlapping and you're just going to compute.",
                    "label": 0
                },
                {
                    "sent": "Very simple Max.",
                    "label": 0
                },
                {
                    "sent": "Over those elements you can take the largest elements.",
                    "label": 0
                },
                {
                    "sent": "Obviously these are larger than three by three.",
                    "label": 0
                },
                {
                    "sent": "I just threw them nice and big so you can see and then if you take per window Max then you get something like this.",
                    "label": 0
                },
                {
                    "sent": "If you take the other alternative is to do a sum or an average operation and that's going to give you something something like this.",
                    "label": 1
                },
                {
                    "sent": "So I think in practice most people find the Max operation seems to work better.",
                    "label": 0
                },
                {
                    "sent": "I mean, there were some attempts to sort of analyze why this might be theoretically, but I think empirically anyway, this is the Max, at least in these big component seems to be working pretty well, so so the intuition behind this is an operation which isn't present of course, in standard, your standard neural net.",
                    "label": 0
                },
                {
                    "sent": "Just say Yep, sorry.",
                    "label": 0
                },
                {
                    "sent": "To say that the filtering layers work as the classical filters that were not part of neural networks like Siri Crossing, doing something like as you're crossing and well, OK, OK in the first layer they do turn out to sort of have these sort of Gabor like structure which does have this property.",
                    "label": 0
                },
                {
                    "sent": "Catching zero crossing types off, but naturalize.",
                    "label": 0
                },
                {
                    "sent": "They're not doing that kind of thing at all.",
                    "label": 0
                },
                {
                    "sent": "And so.",
                    "label": 0
                },
                {
                    "sent": "Yeah, I think it's.",
                    "label": 0
                },
                {
                    "sent": "I mean, it's just by chance that happens to look a little bit like sort of.",
                    "label": 0
                },
                {
                    "sent": "I mean we can go into this sort of more detail offline, but yeah, I mean it's the first layers do look for edges essentially which you have, which the optimal thing is along the lines of we describe.",
                    "label": 0
                },
                {
                    "sent": "So just give some motivation as to why spatial pooling.",
                    "label": 1
                },
                {
                    "sent": "So what sorry, there's nothing you can do about it.",
                    "label": 0
                },
                {
                    "sent": "You can have overlapping windows and so on like so it gives.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "More of the same thing.",
                    "label": 0
                },
                {
                    "sent": "You can also try to sort of put across feature Maps, in fact, so this was sort of pooling within a feature map, but you kind of pull across them, so there's an interesting model buying Goodfellow and actually other folks in Montreal where they took in some sense of Max.",
                    "label": 0
                },
                {
                    "sent": "This element Max.",
                    "label": 0
                },
                {
                    "sent": "Here we look at both Max over both spatial position and over feature map 2.",
                    "label": 1
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Cursively what's why do you want to do pooling?",
                    "label": 0
                },
                {
                    "sent": "Well, I think one very important thing, of course, is that in images you want to sort of basically learn kind of invariants, right?",
                    "label": 0
                },
                {
                    "sent": "So you want to make it so that, for example, if you translate the object slightly, that shouldn't change your feature representation.",
                    "label": 0
                },
                {
                    "sent": "Too much or if you have a small deformations of the objects and stuff like that, and the pooling gives you that kind of invariants, and particularly when we stack this, remember what I'm describing is just a single layer in the model.",
                    "label": 0
                },
                {
                    "sent": "When you've got multiple air stacked on top of one another, you're going to end up being very complicated.",
                    "label": 0
                },
                {
                    "sent": "Invariances will see just a moment and the other point, of course, is that we want to sort of each in this first layer of the model.",
                    "label": 0
                },
                {
                    "sent": "You've got a fairly small receptive field that is the model.",
                    "label": 0
                },
                {
                    "sent": "Each element in the feature map only sees a fairly small window.",
                    "label": 0
                },
                {
                    "sent": "The inputs as you have this pooling operation in there, as we got the model, the pixels in the feature Maps of the high levels will actually start to see you know essentially entire image.",
                    "label": 0
                },
                {
                    "sent": "And of course we want to ultimately make a decision about the identity object based on all pixels in the image, not just a small subset of them.",
                    "label": 0
                },
                {
                    "sent": "And so just these are just just a little and you can also try and play around a little bit and in these models this is some sort of visualization technique from quickly which try to show the kinds of variances that you can learn, sort of in.",
                    "label": 1
                },
                {
                    "sent": "And this is showing, for example, an invariant to scale is showing a sort of little transformations, the input image which don't change the essentially the signal in a particular feature mapping the model.",
                    "label": 0
                },
                {
                    "sent": "So this is the kind of this kind of scale invariant feature.",
                    "label": 0
                },
                {
                    "sent": "This one seems to be variants or diagonal translation and stuff like that.",
                    "label": 1
                },
                {
                    "sent": "OK, well look will look at some visualizations of the models later in in just a moment which will give you a more of a feel for this kind of thing.",
                    "label": 0
                },
                {
                    "sent": "OK. Sure, sorry.",
                    "label": 0
                },
                {
                    "sent": "Like Max pooling versus everything.",
                    "label": 0
                },
                {
                    "sent": "This one should be used right?",
                    "label": 0
                },
                {
                    "sent": "Well I guess people have done a lot of so the question was when should one use Max pooling versus sampling and so on I think.",
                    "label": 0
                },
                {
                    "sent": "There's been a lot of empirical investigation of that issue.",
                    "label": 0
                },
                {
                    "sent": "OK, so people tried all these different flavors of pooling in sort of, you know, exhaustively over these different model architectures, and I think even though it's hard to give a sort of really compelling theoretical justification, I would say empirically, it seems that the Max pooling seems to be doing pretty well.",
                    "label": 0
                },
                {
                    "sent": "Yeah, I mean, I wish I could give us like more satisfying answer that, but unfortunately I can't really.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So one of the things that people do do a little bit is also they also.",
                    "label": 0
                },
                {
                    "sent": "So just so just to wrap up.",
                    "label": 0
                },
                {
                    "sent": "We just looked at the filtering Operation RT, the spatial pooling, which is usually just local in each feature map and it's just the Max pooling and will be I guess in a lot of models now.",
                    "label": 0
                },
                {
                    "sent": "People do some kind of normalization here as well, so we'll talk about that in just a second with optimization.",
                    "label": 0
                },
                {
                    "sent": "How you train these models effectively.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So I'll just skip over that.",
                    "label": 0
                },
                {
                    "sent": "OK, now the next thing is the architecture.",
                    "label": 0
                },
                {
                    "sent": "So in some sense you know I've described.",
                    "label": 0
                },
                {
                    "sent": "You know these stages of the model, but there's a lot of sort of important details that are missing, like how would one select number of feature Maps of each layer?",
                    "label": 0
                },
                {
                    "sent": "How many layers should we have?",
                    "label": 0
                },
                {
                    "sent": "All these sorts of things, and indeed you know all these will affect the sort of parameters we have we have.",
                    "label": 0
                },
                {
                    "sent": "We have a set of train data.",
                    "label": 0
                },
                {
                    "sent": "What's the best way to sort of arrange these things?",
                    "label": 0
                },
                {
                    "sent": "OK so.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So in some sense, just as a sort of side note, you know in the pre deep learning error people spent all their energies trying to sort of engineer good feature representations.",
                    "label": 0
                },
                {
                    "sent": "So in some sense with the planning everything is just shifted up a level of abstraction.",
                    "label": 0
                },
                {
                    "sent": "So instead of designing the features, we now learn them, but what's in fact happen now is we spend a lot of time trying to sort of discover good architectures for the models, and then given those architectures, we can then train your feature presentations underneath.",
                    "label": 0
                },
                {
                    "sent": "So I have to say that at this point I think we still don't have a really kind of principled way of picking architectures directly.",
                    "label": 0
                },
                {
                    "sent": "I mean the most simple one.",
                    "label": 0
                },
                {
                    "sent": "Of course, you can imagine having some validation set and just trying different ones out, and we can do a sort of brute force grid search, sort of smarter strategies that Joshua's and colleagues came up with.",
                    "label": 1
                },
                {
                    "sent": "You know that in your high dimensional so hyperparameter space, there's like, you know, if you just do a random strategy, just picking random points within that, then you're likely to stumble across kind of a good zone faster than just doing things just by grid search.",
                    "label": 0
                },
                {
                    "sent": "And there are sort of other sorry, forgot for the reference in here, but there are strategies where you can try and.",
                    "label": 0
                },
                {
                    "sent": "So for example, Ryan Adams, Bryan Adams Group has some approach for sort of trying to fit a very simple function to the sort of performance of different model architectures and try and try to predict which model architectures might be good ones to try next in your search, and so on and so forth.",
                    "label": 0
                },
                {
                    "sent": "But I think this is an interesting story, also forgot to update the slide.",
                    "label": 0
                },
                {
                    "sent": "I guess there's a whole bunch of recent papers which look at trying to sort of grow models incrementally, sort of like you know, adding layers and expanding the number of units in each layer and so on and so forth.",
                    "label": 0
                },
                {
                    "sent": "I mean, yeah, I mean, that's of course.",
                    "label": 0
                },
                {
                    "sent": "It doesn't sort of quite.",
                    "label": 0
                },
                {
                    "sent": "It doesn't tell you beforehand exactly how you should pick pick things.",
                    "label": 0
                },
                {
                    "sent": "So I guess one.",
                    "label": 0
                },
                {
                    "sent": "However, there is sort of I guess one very important.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And so the reason is that the deep in deep learning is really, really important, and we're going to just sort of going to this little bit more details.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is the architecture that excludes FC and Leah and Jeff Hinton.",
                    "label": 0
                },
                {
                    "sent": "You know, proposing that 2012 paper?",
                    "label": 0
                },
                {
                    "sent": "So essentially these are the 7 hidden layers and then you go to softmax output.",
                    "label": 0
                },
                {
                    "sent": "So just to look at it you got this convolution rectified linear and Max pooling the same thing in there two and then they had some layers just with convolutions and rectified linear units and with no pooling and then had another final pooling on top of stage five and they had some fully connected layers.",
                    "label": 0
                },
                {
                    "sent": "Just densely connected layers, so this loss or to the structure at this point and turn it into a giant factor and then just have fully connected layers up to some softmax output.",
                    "label": 0
                },
                {
                    "sent": "With 1000 outputs for the 1000 different classes and Imagenet OK, so that's.",
                    "label": 0
                },
                {
                    "sent": "Get when they trained the single one of these models that they got about.",
                    "label": 0
                },
                {
                    "sent": "Whoops, sorry, forgot about apologies.",
                    "label": 0
                },
                {
                    "sent": "They got about 18.2% of 5 error.",
                    "label": 0
                },
                {
                    "sent": "So when we re implemented by she got slightly better than they did.",
                    "label": 0
                },
                {
                    "sent": "So one thing you can say is OK, So what makes this model works so well?",
                    "label": 0
                },
                {
                    "sent": "Maybe we're going to start chopping out different parts of the model, retraining from scratch of course because you can't just remove weights in the middle.",
                    "label": 0
                },
                {
                    "sent": "That would mess up what you know.",
                    "label": 0
                },
                {
                    "sent": "The signal that the less above were expecting, but we can remove different components, model, retrain from scratch and see how it does.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You can do it, you can just try for example just from one is fully connected at the top past this thing straight to the softmax.",
                    "label": 0
                },
                {
                    "sent": "You just remove 16,000,000 parameters there, about 60 million in total.",
                    "label": 0
                },
                {
                    "sent": "That's a big chunk of the capacity in the model, but actually it really makes very little difference to performance.",
                    "label": 0
                },
                {
                    "sent": "You lose a percent or so, so that clearly wasn't sort of vital to the networks performance.",
                    "label": 0
                },
                {
                    "sent": "OK, so now you can.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Look at both of them, so I'm just now dropped.",
                    "label": 0
                },
                {
                    "sent": "The majority of net parameters in the model 50,000,000, and it's true that the performance has dropped now about 6%.",
                    "label": 0
                },
                {
                    "sent": "But it's still actually a lot better than the classical approaches that we had before deep learning.",
                    "label": 0
                },
                {
                    "sent": "So somehow the rabbit isn't in those layers either.",
                    "label": 0
                },
                {
                    "sent": "So let's try.",
                    "label": 0
                },
                {
                    "sent": "OK, some other strategies, so maybe.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Back end, maybe we can now remove these convolutional layers down the bottom.",
                    "label": 0
                },
                {
                    "sent": "Remember there wasn't any pooling.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Right, so we can just easily we're not changing the dimensions of.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Difference of the architecture to dramatically so this one is only about a million parameters in those convolutional layers because the wait time makes them very efficient.",
                    "label": 0
                },
                {
                    "sent": "So any thoughts about 3% performance?",
                    "label": 0
                },
                {
                    "sent": "So at some point at this point you're like, well, OK, I mean, you know what's going on because it's not, it's not there.",
                    "label": 0
                },
                {
                    "sent": "It doesn't seem to be down here.",
                    "label": 0
                },
                {
                    "sent": "So is it really?",
                    "label": 0
                },
                {
                    "sent": "These three layers that you are doing?",
                    "label": 0
                },
                {
                    "sent": "Everything?",
                    "label": 0
                },
                {
                    "sent": "What you?",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Try sort of, you know, just try those three layers alone and now it really now broken it.",
                    "label": 0
                },
                {
                    "sent": "OK, so now it really does very badly and but you'll notice is really we only have 4 layers or three layers.",
                    "label": 0
                },
                {
                    "sent": "3 hidden layers really between input and output OK, and so in some sense that you must have a good number of nonlinearities.",
                    "label": 0
                },
                {
                    "sent": "And you know you need basically a decent number of different inputs and outputs.",
                    "label": 0
                },
                {
                    "sent": "Learner sort of good classification.",
                    "label": 0
                },
                {
                    "sent": "Function so this is what this is telling us now and just to say that you know, if you look at the trends this is Alex is model back in 2012.",
                    "label": 0
                },
                {
                    "sent": "The trend subsequently has really been to sort of dramatically increase the number of layers in the model.",
                    "label": 0
                },
                {
                    "sent": "Anna's, and correspondingly, the error rates have just kept falling.",
                    "label": 0
                },
                {
                    "sent": "I mean, that's that's the main difference on that graph I showed with the sort of image.",
                    "label": 0
                },
                {
                    "sent": "Net performance, overtime.",
                    "label": 0
                },
                {
                    "sent": "The other thing you can do actually, just as another source light thing you.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So tap off the features at different layers in Alex is model and just train little SVM on top of them on this.",
                    "label": 0
                },
                {
                    "sent": "These are on some old datasets just to see how well they do and it sure enough you do see that the performance of systematically increases as we this is features from one features from 7 and so on so that you know the features seem to be more powerful as we go down through the network.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Another little fun thing you can do is you can look at sort of invariants of different transformations of your input signal.",
                    "label": 0
                },
                {
                    "sent": "OK, so as I was mentioning, you know by stacking these liars, you're going to get some increasingly complicated invariants is being learned, so here's a little example.",
                    "label": 0
                },
                {
                    "sent": "What we're doing is we're going to take a single image sharing, translated vertically through different vertical translations, and we're going to see.",
                    "label": 0
                },
                {
                    "sent": "So I guess the middle one is the original, and this is a sort of shifting down the shifting up and what we're looking at here is the sort of sort of differences like the DOT product or something like that between the.",
                    "label": 0
                },
                {
                    "sent": "Feature Maps in the untranslated layer, one versus the features you get from the inlet one.",
                    "label": 0
                },
                {
                    "sent": "When you translated the input signal so you can see things are pretty sensitive.",
                    "label": 0
                },
                {
                    "sent": "Right?",
                    "label": 0
                },
                {
                    "sent": "Small shifts in the image cause quite dramatic changes in the input feature map, and these are for the each of the different images up here.",
                    "label": 0
                },
                {
                    "sent": "OK, but by the time we get to the last seven, things have come sort of much more, much better behaved right.",
                    "label": 0
                },
                {
                    "sent": "So now things are sort of.",
                    "label": 0
                },
                {
                    "sent": "The translation is now becomes sort of simple linear shift or there's much less much less sensitive somehow to the transformation.",
                    "label": 0
                },
                {
                    "sent": "And at the output you can see it.",
                    "label": 0
                },
                {
                    "sent": "See now it's pretty invariant in fact, so you can see the lawnmower.",
                    "label": 0
                },
                {
                    "sent": "And this is probably true class so that you can tell it's lawnmower even though there's quite dramatic shifts in the input image.",
                    "label": 0
                },
                {
                    "sent": "So you might say, well, translations come easy one.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "What about scale changes that so much more nonlinear thing?",
                    "label": 0
                },
                {
                    "sent": "So something this small scale changes quite dramatic, changes them in the future presentation layer one, but by less 7.",
                    "label": 0
                },
                {
                    "sent": "They've become much more sort of, you know, much simpler sort of linear change in the representation, and sure enough, the model now is still, but it's pretty invariant to them at the top of the model.",
                    "label": 0
                },
                {
                    "sent": "So in some sense these layers do let us unpack.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Things this is.",
                    "label": 0
                },
                {
                    "sent": "Rotation invariants shows somewhat similar thing.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So as I was saying, what's effectively happened is people now just focus on sort of building bigger and bigger models, and so this is this is the VGG model from Oxford from Karen Simonyan Android system and this is the one from Oxford.",
                    "label": 0
                },
                {
                    "sent": "So what they've done really is to replace the convolution operations, which typically in Alex is model things like 7 by 7.",
                    "label": 0
                },
                {
                    "sent": "You know sized filters with multiple three by three convolutions, each one of which has a nonlinearity after it.",
                    "label": 0
                },
                {
                    "sent": "OK, so you basically end up with the same kind of receptive field, but now you've got a much more powerful function.",
                    "label": 0
                },
                {
                    "sent": "In the sense that it can, it can decision surfaces and just sort of simple linear thing anymore, but you have with a single convolution it's going to be a much more complicated things.",
                    "label": 0
                },
                {
                    "sent": "You've got multiple linear convolutions and then multiple multiple rectified linear nonlinearities coming afterwards.",
                    "label": 0
                },
                {
                    "sent": "OK, so the you can see here for example, each of these stacks is basically a combination with a three by three kernel and followed by a value combination with real you and so on and so forth.",
                    "label": 0
                },
                {
                    "sent": "You can see they really sort of stacking these things in there, so I guess this one has about 19 different.",
                    "label": 0
                },
                {
                    "sent": "Hidden lies in total and the results on image net at the time were state of the art.",
                    "label": 0
                },
                {
                    "sent": "They went down to sort of, you know, 6.8 for the top five.",
                    "label": 0
                },
                {
                    "sent": "Which is pretty impressive.",
                    "label": 0
                },
                {
                    "sent": "'cause Alex's model was getting about 18% top five performance.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So then the Google folks also have some some more complicated model where they're essentially going to sort of each layer of combinations of different size of 5, three by three, one by one.",
                    "label": 1
                },
                {
                    "sent": "They have some sort of sort of PCA, like dimensionality reduction to sort of control.",
                    "label": 1
                },
                {
                    "sent": "This size of things, all compatible.",
                    "label": 0
                },
                {
                    "sent": "This is the little.",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Inception module and this is just a visualization of the role models.",
                    "label": 0
                },
                {
                    "sent": "This is actually very complicated model and then they actually to help train it.",
                    "label": 0
                },
                {
                    "sent": "They actually introduced labels that sort of different points in the model, not just at the end.",
                    "label": 0
                },
                {
                    "sent": "And this is just comparing to sort of something basically the same size as Alex Net from a few years ago.",
                    "label": 0
                },
                {
                    "sent": "So these models are getting really very very big.",
                    "label": 0
                },
                {
                    "sent": "And then yeah.",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This is just showing the number of feature Maps player so you can see this is a pretty big model.",
                    "label": 0
                },
                {
                    "sent": "Basically what they did do though is they got rid of completely the fully connected layers in this so that in some sense the total number of parameters even though they have many more feature Maps, player and more layers went down dramatically right?",
                    "label": 1
                },
                {
                    "sent": "So they just only have only about 5 million parameters and this also got sort of pretty very low performance on very good, very low error rate.",
                    "label": 1
                },
                {
                    "sent": "Sorry on image net I think one thing to say that I think people have this in Google Inception model.",
                    "label": 0
                },
                {
                    "sent": "People tried it on other datasets like for example the Cocoa challenge and stuff like that.",
                    "label": 0
                },
                {
                    "sent": "I've used it for attention.",
                    "label": 0
                },
                {
                    "sent": "It doesn't seem to generalize quite as well as VG.",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Model that are showing here, which is somewhat simpler approach.",
                    "label": 0
                },
                {
                    "sent": "It's really just fairly simple modification of the Alex net thing.",
                    "label": 0
                },
                {
                    "sent": "Just have three by three convolutions and more of them, whereas this one was sort of more dramatic change the architecture, but this one somehow seems to generalize better, and I guess the.",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Latest one thing that came out I guess.",
                    "label": 0
                },
                {
                    "sent": "Well technically last year, but I suppose this years residual network, so this is actually the models have got really deep, like hundreds and hundreds of layers and this motivated by this quite interesting observation.",
                    "label": 0
                },
                {
                    "sent": "If you just take the models like Gigi and you just add more convolutions to them.",
                    "label": 0
                },
                {
                    "sent": "You might think, well, OK?",
                    "label": 0
                },
                {
                    "sent": "Sure the importance just improve.",
                    "label": 0
                },
                {
                    "sent": "Well, actually the answer is no it doesn't.",
                    "label": 0
                },
                {
                    "sent": "And then when you try this is the training error on seafile, right?",
                    "label": 0
                },
                {
                    "sent": "So in theory you got more layers and more powerful function.",
                    "label": 0
                },
                {
                    "sent": "There's more parameters you'd expect a lower training error.",
                    "label": 0
                },
                {
                    "sent": "What you see in fact is the training goes up, which is telling you that somehow you're having trouble optimizing these incredibly deep models and do this, and then you see of course in that other test set as well.",
                    "label": 0
                },
                {
                    "sent": "Actually the performance is worse with 56 layers than 20 layers, so that's just sort of naively adding layers to your VG model.",
                    "label": 0
                },
                {
                    "sent": "And So what they did was introduced this nice simple idea which is whereby instead of just stacking the convolution layers together like like you would in this pathway, what you're going to do is have a sort of bypass.",
                    "label": 0
                },
                {
                    "sent": "We're going to take your input signal and just add it in.",
                    "label": 0
                },
                {
                    "sent": "Afterwards, So what this means is effectively that these white lies only have to kind of make a sort of changes to the sort of residual they're looking to make some modifications to existing features that come in.",
                    "label": 0
                },
                {
                    "sent": "They don't have to sort of propagate the features themselves, and so in practice this seems to sort of improve the conditioning of the whole system and make it a lot easier to train.",
                    "label": 0
                },
                {
                    "sent": "And when they train these things, so this is now a visualization of the things, so this was the biggest Fiji model from the previous slide, and this is the sort of the naive 34 layer version where they just added a whole bunch of extra convolutions in.",
                    "label": 0
                },
                {
                    "sent": "And this is what they call the 34 layer residual net where they've got these sort of bypass.",
                    "label": 0
                },
                {
                    "sent": "This identity function that's basically propagating the features sort of round between pairs of convolutional layers after each convolution layer.",
                    "label": 0
                },
                {
                    "sent": "There's a rally operation that goes on as well.",
                    "label": 0
                },
                {
                    "sent": "So the doctor bypasses where they actually have a slight change in.",
                    "label": 0
                },
                {
                    "sent": "This is where they've done some pooling operation, so they have a change in the dimensionality of the signal so they actually have to have a little.",
                    "label": 0
                },
                {
                    "sent": "This function here has implement some actual change in dimension to make it compatible, so this is what this is.",
                    "label": 0
                },
                {
                    "sent": "Effectively the 34 model and when they.",
                    "label": 0
                },
                {
                    "sent": "So this is I think this line here.",
                    "label": 0
                },
                {
                    "sent": "So this goes down to five point, 7% of 5 error and then with if they just keep jacking up the number of layers.",
                    "label": 0
                },
                {
                    "sent": "This things you know the errors keep dropping so they get that with 152 layer model that down at 4.5% error and if they on sambol that they get down to 3.6 or so which is I think I'm nervous of saying this 'cause the numbers keep changing archive the whole time.",
                    "label": 0
                },
                {
                    "sent": "I think that's the current state of the art but these models are fairly easy to train still.",
                    "label": 0
                },
                {
                    "sent": "So I mean I'm not.",
                    "label": 0
                },
                {
                    "sent": "So these things you know do really work well, and other datasets too for sure.",
                    "label": 0
                },
                {
                    "sent": "OK, so the answer is that you know the whole deep in deep learning is really important.",
                    "label": 0
                },
                {
                    "sent": "You know the depth is key here, rather than necessarily having crazy numbers of feature Maps in each layer.",
                    "label": 0
                },
                {
                    "sent": "Notice here that they mostly have hit.",
                    "label": 0
                },
                {
                    "sent": "Their end is sort of 512 and things like that and and the number of parameters isn't actually that dramatic in this in this in these models it's smaller than quite a lot smaller than VG and Alex net, so they.",
                    "label": 0
                },
                {
                    "sent": "Which is great so that you don't take up crazy amounts of memory on your GPU, and you can compute these things fairly fast and stuff like that.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Right, so one thing says yeah, whoops, sorry.",
                    "label": 0
                },
                {
                    "sent": "So the filters in the first layer kind of easy to visualize that just directly accessing the pixels.",
                    "label": 1
                },
                {
                    "sent": "You can look at the filters and they make sense, but in the highlights they're just complicated functions of some of the input Maps, right?",
                    "label": 0
                },
                {
                    "sent": "So you can't actually direct look at those coefficients or make any sense of them.",
                    "label": 0
                },
                {
                    "sent": "So there's essentially two sort of schools of two ways you can kind of.",
                    "label": 0
                },
                {
                    "sent": "Well, there's a whole little cottage industry impact interest on these models are doing.",
                    "label": 0
                },
                {
                    "sent": "I guess you can broadly classify them into sort of two different.",
                    "label": 0
                },
                {
                    "sent": "Schools one would be to sort of project somehow individual activations in the model back into into pixel space through some approach.",
                    "label": 0
                },
                {
                    "sent": "The other alternative is to try and.",
                    "label": 0
                },
                {
                    "sent": "To try and do sort of some sort of gradient descent.",
                    "label": 0
                },
                {
                    "sent": "Update to change your input image to maximize the output of the model, or to maximize the activation in some particular.",
                    "label": 1
                },
                {
                    "sent": "So this is sort of doing back basically, but going all the way back to the input pixels and updating those so there.",
                    "label": 0
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Whole bunch of in terms of the projection back from hi.",
                    "label": 0
                },
                {
                    "sent": "Lisa, whole bunch of approaches for doing this that are sort of different sort of variance on the.",
                    "label": 0
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Thing I just got some describe one that one of my students did, so this idea was you were trained model.",
                    "label": 0
                },
                {
                    "sent": "So training component model you're going to take a single input image, you push it through.",
                    "label": 0
                },
                {
                    "sent": "You get a whole bunch of feature Maps, feature activations up let's say in this case let 3.",
                    "label": 1
                },
                {
                    "sent": "So there's a Gray bars here in sort of, you know, height.",
                    "label": 0
                },
                {
                    "sent": "The height indicates sort of the strength of the activation and what we're going to do is.",
                    "label": 0
                },
                {
                    "sent": "We're going to just take a single strong activation.",
                    "label": 0
                },
                {
                    "sent": "Said everything else is zero in the model, and then we're going to basically do sort of backdrop affectively with that vector of activation.",
                    "label": 0
                },
                {
                    "sent": "Or that those activations rather than a gradient signal.",
                    "label": 0
                },
                {
                    "sent": "So we're going to be sort of reconstructing back down all the way, projecting this thing all way back down to the pixels again.",
                    "label": 0
                },
                {
                    "sent": "And if you look the operations involved end up in.",
                    "label": 0
                },
                {
                    "sent": "Basically the same as backdrop with sort of small changes, basically to the whole procedure so.",
                    "label": 0
                }
            ]
        },
        "clip_55": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So just so this is, you know, you come forward, you got the commercial floating or rally on your Max pooling and if you in backdrop of course when you think about it, when you do back prop with Max pooling, you have to remember where the location of the Max on the forward pass, and So what we're doing here is just sort of keeping track in the same way, keeping track of that location.",
                    "label": 0
                },
                {
                    "sent": "So when we're projecting the signal back down again in each pooling region we kind of push it down to the location that it came from on the upward pass, and then we do actually.",
                    "label": 0
                },
                {
                    "sent": "So in this particular visualization technique we do pass.",
                    "label": 0
                },
                {
                    "sent": "These activations then through a rally, you write their own rally rather than using their value.",
                    "label": 0
                },
                {
                    "sent": "From the forward pass, and then convolving with the transpose, which is what you would have done in the back.",
                    "label": 0
                }
            ]
        },
        "clip_56": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so just so just I mean what I mean by the pooling.",
                    "label": 0
                },
                {
                    "sent": "So this is your pulling in the forward pass.",
                    "label": 0
                },
                {
                    "sent": "This is your two by two Max pooling, so you basically taking the different pulling regions taking Max is these are the locations the little grey squares so this is telling you that this guy the top left one in this little block at the Max.",
                    "label": 0
                },
                {
                    "sent": "So when you projecting down again you've got sort of easier.",
                    "label": 0
                },
                {
                    "sent": "Directions from there above and you're going to stick these different locations so it's not a sort of true inverse or anything like that, because you know there's the rest of these going to be set to 0 basically, but you're sort of preserving the sort of structure of the of the model.",
                    "label": 0
                },
                {
                    "sent": "So that's what we're going to do in this particular visualization strategy.",
                    "label": 0
                },
                {
                    "sent": "So they say there's a bunch of different ones at all.",
                    "label": 0
                },
                {
                    "sent": "You have slight different twists on how exactly they reconstruct the input.",
                    "label": 0
                }
            ]
        },
        "clip_57": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the first slide we can just look at the filters.",
                    "label": 0
                },
                {
                    "sent": "This is what they look like.",
                    "label": 0
                },
                {
                    "sent": "They look, they pick up sort of edges, basically different orientations and scales.",
                    "label": 0
                },
                {
                    "sent": "You can see sort of high frequency edges, you can see low frequency edges.",
                    "label": 0
                },
                {
                    "sent": "You see also low frequency color opponency, so you can see sort of you know red green stuff going on here sort of blue and yellow over there.",
                    "label": 0
                }
            ]
        },
        "clip_58": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now for the otherwise, we use this projection trick that I was referring to.",
                    "label": 0
                },
                {
                    "sent": "Seattle is going to validation set of images and for each violation image going to shove it through, get those feature Maps and we can do that for all the images in violation set and we're going to take for a particular feature map.",
                    "label": 0
                },
                {
                    "sent": "Say you know this one here we're going to take a few strongest activations across the entire stack.",
                    "label": 0
                },
                {
                    "sent": "Of valuation images of that particular feature for that particular feature map, and for each of those activations individually, we're going to sort of project back down to the input in the pixel space.",
                    "label": 1
                },
                {
                    "sent": "OK, and that's going to use this sort of pulling switches that were peculiar to that particular image on the forward pass.",
                    "label": 0
                }
            ]
        },
        "clip_59": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so it's just so this is just showing a slightly different projection.",
                    "label": 0
                },
                {
                    "sent": "This is just showing the input patches that caused the strong activations for each of the different filters.",
                    "label": 0
                },
                {
                    "sent": "So for example, let's just take this one over here so you can see.",
                    "label": 0
                },
                {
                    "sent": "This makes diagonal edges if you look at the filter it's I guess this one here, which so whoops which makes sense.",
                    "label": 0
                },
                {
                    "sent": "So you can see you can see this invariant somehow.",
                    "label": 0
                },
                {
                    "sent": "The color on either side of the edge already cares about is the having a strong edge of that orientation OK, and other ones like example this, you know the green one here.",
                    "label": 0
                },
                {
                    "sent": "This one just likes uniform kind of greenie regions, which makes sense.",
                    "label": 0
                }
            ]
        },
        "clip_60": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is now projecting, taking the strong activation from each of the layer 2 feature Maps projected back down to pixel space, so that you can see here now is this.",
                    "label": 0
                },
                {
                    "sent": "You're seeing effectively these sort of conjunctions of those low one filters, basically so you find along edges, curved structures, little circular structures, and things like that.",
                    "label": 0
                },
                {
                    "sent": "In this case of green blobs and things like that, and for each of these feature Maps, we can actually this is just showing the strongest single strong activation across the validation set projected back, but you can take the top few that gives you.",
                    "label": 0
                }
            ]
        },
        "clip_61": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Nonparametric feel for the kind of invariances at the models learning so that he can see.",
                    "label": 0
                },
                {
                    "sent": "So just to be clear, these are not sample.",
                    "label": 0
                },
                {
                    "sent": "This is not any kind of generative model that we're looking at here.",
                    "label": 0
                },
                {
                    "sent": "This is just, you know, sort of nonparametric way to get it feels each of these corresponds to some structure.",
                    "label": 0
                },
                {
                    "sent": "So each of those tiles corresponds to 1 activation in in a certain feature map in a validation image.",
                    "label": 0
                },
                {
                    "sent": "OK, and this is these are sort of the same feature map, just different coming from different images.",
                    "label": 0
                },
                {
                    "sent": "Basically so you can see this sort of.",
                    "label": 0
                },
                {
                    "sent": "Slight wiggling in the orientation of the edge.",
                    "label": 0
                },
                {
                    "sent": "You can see things that are picking up kind of texture, but little bits of writing, perhaps in a feature map and stuff like that.",
                    "label": 0
                },
                {
                    "sent": "A little curve structures or circles and so on.",
                    "label": 0
                },
                {
                    "sent": "And you can if you look.",
                    "label": 0
                }
            ]
        },
        "clip_62": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This sort of input patches that correspond to these.",
                    "label": 0
                },
                {
                    "sent": "You can see that it's now picking up some quite interesting invariants.",
                    "label": 0
                },
                {
                    "sent": "So hey, go, you can see something that this one seems like text, but doesn't really care what the color is or anything like that.",
                    "label": 0
                }
            ]
        },
        "clip_63": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You can see it's just focusing on somehow the edge structures.",
                    "label": 0
                }
            ]
        },
        "clip_64": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Over here it doesn't again, doesn't care on the colors or anything like that or the brightness of the edge, it just is picking up on that discontinuity.",
                    "label": 0
                },
                {
                    "sent": "Or at least pick up little circular structures, and so on and so forth.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                }
            ]
        },
        "clip_65": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we can keep going through the model, so let three.",
                    "label": 0
                },
                {
                    "sent": "Now the receptive fields getting larger so we're picking up some chunks of object and also you know because of all these non ASMR nonlinearity pulling we're getting increasingly more complicated invariances in there as well, so this is.",
                    "label": 0
                }
            ]
        },
        "clip_66": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This for example, now you can see this feature Maps that seem to sort of pick up on.",
                    "label": 0
                },
                {
                    "sent": "This looks like text on the sides of objects.",
                    "label": 0
                }
            ]
        },
        "clip_67": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, you can see that again.",
                    "label": 0
                },
                {
                    "sent": "It's just focusing on the text so that the brighter the higher the contrast the pixel is, the stronger the bigger contribution that part of the image made to the activation.",
                    "label": 0
                },
                {
                    "sent": "OK, so that you can see that it doesn't really care about the background, he just cares about the text.",
                    "label": 0
                },
                {
                    "sent": "Once we got here, so I guess.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so you can see some complicated things like sort of you know parallel lines and stuff like that have been picked up.",
                    "label": 0
                }
            ]
        },
        "clip_68": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then coming to Le.",
                    "label": 0
                }
            ]
        },
        "clip_69": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For us at this point, except the receptive fields pretty big.",
                    "label": 0
                },
                {
                    "sent": "So it's picking up most of the image.",
                    "label": 0
                },
                {
                    "sent": "So now you can see this in case we started to see sort object specific stuff going on so the previous ones were kind of somewhat, you know, agnostic to the exact object identity.",
                    "label": 0
                },
                {
                    "sent": "So now you can see for example dogs.",
                    "label": 0
                },
                {
                    "sent": "There's lots of dogs in image net, so there's lots of dog feature Maps, so this one is picking up.",
                    "label": 0
                }
            ]
        },
        "clip_70": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You know certain types of dog.",
                    "label": 0
                },
                {
                    "sent": "In this case, the dogs seem most dogs in this one pair alright.",
                    "label": 0
                },
                {
                    "sent": "We sort of made it OK, so just.",
                    "label": 0
                }
            ]
        },
        "clip_71": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In the nervous about these ones are the top layers that fire.",
                    "label": 0
                },
                {
                    "sent": "At this point, things getting pretty specific.",
                    "label": 0
                },
                {
                    "sent": "You can see things things like this Huskies this feature out seems to be gone, like Husky Dogs which you can see.",
                    "label": 0
                }
            ]
        },
        "clip_72": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Clearly here, so one of my favorite ones actually is this feature Maps.",
                    "label": 0
                },
                {
                    "sent": "I was looking at it like, well, what is this thing?",
                    "label": 0
                },
                {
                    "sent": "What's it picking up on it?",
                    "label": 0
                },
                {
                    "sent": "You know?",
                    "label": 0
                },
                {
                    "sent": "Is it picking up on people by the sea or something like that?",
                    "label": 0
                },
                {
                    "sent": "So if you think about it, most of the energy energy is really on these foreground objects, right?",
                    "label": 0
                },
                {
                    "sent": "The people and so on and so forth.",
                    "label": 0
                },
                {
                    "sent": "But actually if you look at what the model is picking up.",
                    "label": 0
                }
            ]
        },
        "clip_73": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It's actually picking up the water behind.",
                    "label": 0
                },
                {
                    "sent": "It's ignored, completely ignoring that very strong foreground signal.",
                    "label": 0
                },
                {
                    "sent": "But there's lots of energy and just essentially a water detector, and so it's doing something very complicated there, which you know you couldn't possibly get, or just a simple one or two layer model and the other fun thing, sorry, dangerously do this is like these keyboards, so for example, different orientations of keyboards, all of which are sort of being as causing this one particular feature map just fire strongly, and this is obviously something there's no rotation invariance built into the model, so it's learned that.",
                    "label": 0
                },
                {
                    "sent": "Kind of automatically, which is very cool.",
                    "label": 0
                }
            ]
        },
        "clip_74": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The other approach I mentioned sorry to visualization, was to try and think that I'm here OK.",
                    "label": 0
                },
                {
                    "sent": "Better speed up a bit was to try and maximize the input respect some particular output.",
                    "label": 0
                },
                {
                    "sent": "So basically I do is sort of, you know you have some initial image.",
                    "label": 0
                },
                {
                    "sent": "You do 4 prop, you get some output and then you can try and maximize the particular output.",
                    "label": 0
                },
                {
                    "sent": "Sort of back popping all way back to the input and you can one fund.",
                    "label": 0
                },
                {
                    "sent": "Application of this is the sort of funky artistic things from Google Deep Dream.",
                    "label": 0
                },
                {
                    "sent": "So they basically said they would take some sort of random image like this.",
                    "label": 0
                },
                {
                    "sent": "Push it forward to the network train.",
                    "label": 0
                },
                {
                    "sent": "Now do back prop to maximize the banana output and you would have some little bit of constraints just to make sure that the image of made some kind of basic statistics.",
                    "label": 1
                }
            ]
        },
        "clip_75": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You expect and you can get these sort of credit.",
                    "label": 0
                },
                {
                    "sent": "You can do this sort of different scales and stuff and get these crazy sort of psychologically summations and stuff like that.",
                    "label": 0
                },
                {
                    "sent": "I mean, it's not quite clear that this tells you about the model, but it does look very cool.",
                    "label": 0
                },
                {
                    "sent": "OK, so let's talk about that.",
                    "label": 0
                }
            ]
        },
        "clip_76": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Training, so this is a bit perhaps more useful.",
                    "label": 0
                },
                {
                    "sent": "So essentially the dominant paradigm for training these models is stochastic gradient descent, so the idea is going to take a small chunk of data, do back prop with that, the gradients noisy.",
                    "label": 1
                },
                {
                    "sent": "It doesn't matter.",
                    "label": 0
                },
                {
                    "sent": "The key point is you want lots of steps because the energy surface is changing, so that if you spend a lot of time trying to compute very accurate gradient information at a particular point, it's a waste of time.",
                    "label": 0
                },
                {
                    "sent": "You might as well just go roughly in the right direction and get a new gradient estimate there, and so basically that's the rough intuition.",
                    "label": 1
                },
                {
                    "sent": "So This is why you know, having a small batch size seems to be affective.",
                    "label": 0
                },
                {
                    "sent": "Initially you can start off with a large initial learning rate, but to sort of make progress you do actually need to anneal it OK and then and momentum seems to be very useful thing, so I guess I maybe don't have a slight momentum, but momentum generally seems to help when there's variance something called Nestor Amentum that Ilya gave it looked into, which also seems to help too.",
                    "label": 0
                },
                {
                    "sent": "So generally these two are sort of, you know, components, simply vital to sort of optimize these models effectively.",
                    "label": 0
                }
            ]
        },
        "clip_77": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Just look at the annealing of the learning rate.",
                    "label": 1
                },
                {
                    "sent": "So this is just showing.",
                    "label": 0
                },
                {
                    "sent": "I guess here this is your training set error in the solid lines you can see it starts to plateau basically after September of parks and then if you just drop the learning rate it drops down to new drops down yet again and so rough intuition is your energy service has sort of curvature different scales and that the large learning rate you can optimize the shallow directions of curvature, but the very narrow valleys you're going to be oscillating back and forth and if you drop the learning rate will drop down and optimize those much more narrow dimensions and you keep getting by but you start with a .1 learning right up here by to hear yourself down to point.",
                    "label": 0
                },
                {
                    "sent": "You know 1 -- 5 or something and then really you know things started to flatten out and you put the key.",
                    "label": 0
                },
                {
                    "sent": "Point is, as you can see also that the violation error the tests or whatever is also dropping when you do this annealing of the learning rate.",
                    "label": 0
                },
                {
                    "sent": "So it is very important.",
                    "label": 0
                }
            ]
        },
        "clip_78": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And then just using that visualization technique, you can see that in fact how the features evolved during training.",
                    "label": 1
                },
                {
                    "sent": "So this is rather non linear scales.",
                    "label": 0
                },
                {
                    "sent": "This is sort of 1 two whoops sorry 1 two you know.",
                    "label": 0
                },
                {
                    "sent": "Five 1020 Thirty 5000 epochs or something like that, so you can see these early layers train very fast and they get locked in, but those in the middle of the model.",
                    "label": 0
                },
                {
                    "sent": "This is Alex net only got you know.",
                    "label": 0
                }
            ]
        },
        "clip_79": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Five coalition allies.",
                    "label": 0
                },
                {
                    "sent": "It does actually take right until the very end before these.",
                    "label": 0
                },
                {
                    "sent": "That's sort of the higher up lies in the model train.",
                    "label": 0
                },
                {
                    "sent": "Effectively.",
                    "label": 0
                },
                {
                    "sent": "OK, so before that they're just really not picking up anything distinctive, but they do start to pick out quite distinctive things towards the end, so this is sort of saying that you know This is why it's very if you stop your model after just any parks or whatever, that doesn't tend to do as well as if you just have the patience to let it rain for a lot longer.",
                    "label": 0
                },
                {
                    "sent": "Now one.",
                    "label": 0
                }
            ]
        },
        "clip_80": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Thing that it does seem to work quite effectively is trying to sort of normalize the data between layers so I haven't talked much about preprocessing.",
                    "label": 0
                },
                {
                    "sent": "But you know, the classic sort of advice.",
                    "label": 0
                },
                {
                    "sent": "You should just try and whiten your data in the waiting for data removes the sort of 1st and 2nd World dependencies and therefore let's the model focus on these much more sort of interesting ones like that instead of wasting his time trying to handle the 1st and 2nd order moments of the data and so this is batch normalization is a little trick that some of the quotes are group came up with where you going.",
                    "label": 0
                },
                {
                    "sent": "Essentially, appliance of impoverished form whitening in between the layers of the model.",
                    "label": 0
                },
                {
                    "sent": "So the rough idea is going to compute a sort of.",
                    "label": 0
                },
                {
                    "sent": "Over a little mini batch of data, I kind of mean vector over your activations X.",
                    "label": 0
                },
                {
                    "sent": "Here is your sort of feature mapping sort of vector form, so you're going to compute it sort of per pixel mean, so either of these means and your computer pixel variance, and you can use that to just normalize the output, normalize the feature responses OK, and so this in practice.",
                    "label": 0
                },
                {
                    "sent": "Helps the convergence of the model quite a bit.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is the sort of this is the Inception network in the black dashed line.",
                    "label": 0
                },
                {
                    "sent": "Without this trick.",
                    "label": 0
                },
                {
                    "sent": "This is, I guess it's number of weight updates and this is sort of I guess accuracy.",
                    "label": 0
                },
                {
                    "sent": "And if you use this batch normalization idea they are able to sort of you can see the convergence is much faster in a fraction of the epoch.",
                    "label": 0
                },
                {
                    "sent": "So this thing this is a trip seems to work quite well.",
                    "label": 0
                },
                {
                    "sent": "Lot of different things now.",
                    "label": 0
                },
                {
                    "sent": "You might say, well, what about that?",
                    "label": 0
                }
            ]
        },
        "clip_81": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Great, so in this diagram I showed here, this was some sort of manual annealing, essentially with it when the training error sort of started to plateau, you manually dropped it by some predetermined scale fact.",
                    "label": 0
                }
            ]
        },
        "clip_82": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "How about doing this automatically?",
                    "label": 0
                },
                {
                    "sent": "Is there some sort of more principle where you can do it, says whole little cottage industry of trying to come up with different ways of dynamically adjusting the learning rate so autographs one very you know very well known one year amsinger.",
                    "label": 0
                },
                {
                    "sent": "So this is an idea here where this is your step size which uses fixed.",
                    "label": 0
                },
                {
                    "sent": "This is your your gradients and see what your weight update is going to have this little denominated term which is going to take into account.",
                    "label": 0
                },
                {
                    "sent": "It's going to accumulate the gradients from the previous weight updates and the problem with this one is it's a nice idea so naturally gives you a way to attenuate.",
                    "label": 0
                },
                {
                    "sent": "This this, this this overall number he's going to small, of course, because this denominator monotonically increases, so it gives you a nice way of tuning down the learning rate catches.",
                    "label": 0
                },
                {
                    "sent": "Of course, you sort of amount of progress you can make is kind of fixed, because this thing you know as I said it can never decrease.",
                    "label": 0
                },
                {
                    "sent": "In practice, you end up under training the model's a little bit with this one out of deltas.",
                    "label": 0
                },
                {
                    "sent": "Another approach this is 1 sort of motivated by self dimensionality arguments that sort of tries to fix some of the problems with this one.",
                    "label": 0
                },
                {
                    "sent": "So the denominator is the same, but the numerator is different.",
                    "label": 0
                },
                {
                    "sent": "There's a whole bunch of you know.",
                    "label": 0
                },
                {
                    "sent": "Again, postdocs at the time had a sort of.",
                    "label": 0
                },
                {
                    "sent": "Quite a complicated one that was sort of her dimension adjustment of the learning rate and then there are some more recent ones as well that seems to work quite well.",
                    "label": 0
                },
                {
                    "sent": "Adam and stuff like that.",
                    "label": 0
                },
                {
                    "sent": "And so on.",
                    "label": 0
                },
                {
                    "sent": "So these the truth is, I guess people try these things for some applications that seem to work well, others not so much.",
                    "label": 0
                }
            ]
        },
        "clip_83": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So one of the classical objections to this whole neural net story was was this worry about kind of local minima.",
                    "label": 1
                },
                {
                    "sent": "So all these people who worked on convex optimization was very happy that they can sort of guarantee that they would.",
                    "label": 0
                },
                {
                    "sent": "There was a single minima to their solution, maybe, and they were sort of the sceptical.",
                    "label": 0
                },
                {
                    "sent": "The neural net sort of finding good minima, and so this is an interesting, admittedly, rather simplistic sort of experiments where they took some very small multiple perceptrons are fully connected Nets.",
                    "label": 0
                },
                {
                    "sent": "Tried training them from realizations, this one of Gans postdocs in fact.",
                    "label": 0
                },
                {
                    "sent": "Yamaken postdocs and a command scare, so she took it very small network of his two hidden layers, each with 25 units and from different randomizations, train them very carefully and then looked at the test losses OK. And So what you see is a distribution as you might, which tells you that you know there is some difference in the energies or or the loss, whatever that you discover with the different initializations.",
                    "label": 0
                },
                {
                    "sent": "With very small models you know that you can imagine that the difference between the sort of the global minimum and the typical minimum that you could find.",
                    "label": 0
                },
                {
                    "sent": "It may be quite large, right?",
                    "label": 0
                },
                {
                    "sent": "So we sort of this distance here I guess.",
                    "label": 0
                },
                {
                    "sent": "But the nice sort of story that seems to emerge is that when you make the models bigger, well, first thing, of course is that they're sort of test losses decreased, which sort of makes sense, right there?",
                    "label": 1
                },
                {
                    "sent": "More capacity not fitting befitting the data, and they're not overfitting quite yet.",
                    "label": 0
                },
                {
                    "sent": "But the nice thing is that with the distribution gets narrower.",
                    "label": 0
                },
                {
                    "sent": "OK, so in other words, it's really sort of saying that with these bigger models that you know there are many minima, yes, but they all have some sort of quivalent energies that which is good, so it doesn't really matter which minimum you fall into, it's going to be.",
                    "label": 0
                },
                {
                    "sent": "Pretty close in terms of overall energy to the lowest one out there.",
                    "label": 0
                },
                {
                    "sent": "Oh, so they were doing.",
                    "label": 0
                },
                {
                    "sent": "I mean, each model is initialized randomly.",
                    "label": 0
                },
                {
                    "sent": "I guess the prescription they used.",
                    "label": 0
                },
                {
                    "sent": "I'm not quite.",
                    "label": 0
                },
                {
                    "sent": "I can't remember exactly how they did it.",
                    "label": 0
                },
                {
                    "sent": "I mean, it probably was drawn from Gaussian distribution and how they can they estimate.",
                    "label": 0
                },
                {
                    "sent": "The variance is probably some ratio fan in fan out and stuff like that.",
                    "label": 0
                },
                {
                    "sent": "There's various kind of rules of thumb for doing these things.",
                    "label": 0
                },
                {
                    "sent": "You know that it's a local minimum.",
                    "label": 0
                },
                {
                    "sent": "I mean they didn't test degrading well, right?",
                    "label": 0
                },
                {
                    "sent": "So they train it right?",
                    "label": 0
                },
                {
                    "sent": "So that at this point the grading becomes very small, so there was some minimum, but it's obviously unclear whether it's a good minimum or bad minimum.",
                    "label": 0
                },
                {
                    "sent": "So This is why they made this histogram and you can then see that there's the overall sort of depth of the minimum.",
                    "label": 0
                },
                {
                    "sent": "Doesn't seem to vary too much between all these different memory.",
                    "label": 0
                },
                {
                    "sent": "I mean, it's clearly lots and lots of memory can just permute the matrices in the model and then you end up with a different solution, but.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so this is.",
                    "label": 0
                },
                {
                    "sent": "I mean I it's I think it's encouraging.",
                    "label": 0
                },
                {
                    "sent": "Of course it's not completely conclusive thing because these are the small toy models and so on, but I think it's an interesting result nevertheless.",
                    "label": 0
                },
                {
                    "sent": "OK, So what about?",
                    "label": 0
                }
            ]
        },
        "clip_84": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "2nd Order methods right this whole.",
                    "label": 0
                },
                {
                    "sent": "You know people don't.",
                    "label": 0
                },
                {
                    "sent": "Automation courses.",
                    "label": 0
                },
                {
                    "sent": "Most of the things they are focused on sort of more complicated strategies for optimizing, so you can imagine that you know if you can complete secondary information, you'll be able to build this Hessian matrix HT and then you would compute or wait update by kind of inverting.",
                    "label": 0
                },
                {
                    "sent": "So this gives you sort of quadratic approximation, drainage surface all those different dimensions of curvature would suddenly sort of.",
                    "label": 0
                },
                {
                    "sent": "You wouldn't have to worry about it too much.",
                    "label": 0
                },
                {
                    "sent": "So the catch is of course that you know if this is a big model with millions of parameters.",
                    "label": 0
                },
                {
                    "sent": "This is a sort of, you know, maybe a going to be a very large vector so you know million 50,000,000 dimensional vector and then this way matrix is 50,000,000 by 50,000,000.",
                    "label": 0
                },
                {
                    "sent": "So building storing it is impossible, let alone turn.",
                    "label": 0
                },
                {
                    "sent": "Invert it and stuff like that.",
                    "label": 0
                },
                {
                    "sent": "So there's a whole bunch of approximations you can think of.",
                    "label": 0
                },
                {
                    "sent": "Dream up, you could sort of forget about the off diagonal elements.",
                    "label": 0
                },
                {
                    "sent": "Just try and look at that.",
                    "label": 0
                },
                {
                    "sent": "And in fact you can compute that quite efficiently.",
                    "label": 0
                },
                {
                    "sent": "There's a sort of just requires effectively double the number of.",
                    "label": 0
                },
                {
                    "sent": "Regular back prop operations and then you can compute these sort of diagonal hash in terms.",
                    "label": 0
                },
                {
                    "sent": "There's a bunch of sort of you can sort of computing approximate version of this with some sort of truncated consecrated methods.",
                    "label": 0
                },
                {
                    "sent": "This is James Martens thing, as you can try and come with a low rank version of it for each batch.",
                    "label": 0
                },
                {
                    "sent": "This was a yes or Dickstein had this idea and there's some talk about this in the next slide, so I guess the truth is that despite all these efforts, the extra computational doesn't seem to be really worth it empirically, I mean.",
                    "label": 0
                },
                {
                    "sent": "Then they is taking these dumb steps more dumb steps into better than taking fewer carefully carefully.",
                    "label": 0
                },
                {
                    "sent": "Computed steps, so I mean this story might change if you've got a very very large distributed setting with thousands of different GPU's, you might argue, well, you know, maybe it makes sense to sort of have some of the workers computing kind of 2nd order information to do the update, but no ones actually sort of really demonstrated this practically.",
                    "label": 0
                }
            ]
        },
        "clip_85": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "There's some interesting work from Yonder Fan and Yoshi's Group.",
                    "label": 0
                },
                {
                    "sent": "Looking at this whole optimization problem.",
                    "label": 0
                },
                {
                    "sent": "Kind of subtle point perspective.",
                    "label": 0
                },
                {
                    "sent": "So you can think of this idea that we start out initially many of your directions of curvature kind of pointing downwards, so and then as you get when you're in some local minimum rule pointing up.",
                    "label": 0
                },
                {
                    "sent": "So as you're in the middle optimization, there are sort of many other dimensions as sort of down another ones up, and so you're basically in this sort of very high dimensional sort of saddle point.",
                    "label": 0
                },
                {
                    "sent": "And then you can make this paper to make some arguments that that's some of the traditional.",
                    "label": 0
                },
                {
                    "sent": "STD and things like that have problems.",
                    "label": 0
                },
                {
                    "sent": "A scaping from the saddle points that they sort of get linger in this saddle point and what you really want to roll off down one of the sides.",
                    "label": 0
                },
                {
                    "sent": "And there's some sort of you know this is a sort of version of Newton method where the eigen values on the diagonal Hessian are kind of enforced to be sort of positive essentially, which basically taking absolute value of your Hessian matrix and then that.",
                    "label": 0
                },
                {
                    "sent": "Experiment seems to sort of improve the convergence performance and stuff like that with these models.",
                    "label": 0
                },
                {
                    "sent": "OK, so that was a bit of a whistle stop tour.",
                    "label": 0
                },
                {
                    "sent": "You know how you actually optimize these models?",
                    "label": 0
                }
            ]
        },
        "clip_86": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Terms of proving generalization, so the obvious tricks you can use, like if there are certain variances you know you don't want to have in the model so you don't have the model.",
                    "label": 0
                },
                {
                    "sent": "You can kind of help the model by sort of giving it to in the form of the data.",
                    "label": 0
                },
                {
                    "sent": "So by taking the input image, translating it by adding small translations, but keeping the same output label, that sort of helps them learn that maybe small translations aren't important, and it should kind of ignore them, and so you can do this can be extended to many things, like color transformations, scale changes.",
                    "label": 0
                },
                {
                    "sent": "Flips and so on so forth.",
                    "label": 0
                },
                {
                    "sent": "This is a regular thing that always seems to help.",
                    "label": 0
                },
                {
                    "sent": "You can do weight decay, so sending fully connected layers, this seems to be very useful.",
                    "label": 1
                },
                {
                    "sent": "We got lots of parameters that convolutional networks naturally give you weight sharing.",
                    "label": 1
                },
                {
                    "sent": "If you do have multiple tasks, so you want to sort of, you know, classify objects.",
                    "label": 0
                },
                {
                    "sent": "We also want to, perhaps you know.",
                    "label": 0
                },
                {
                    "sent": "Segment them or something or two will look at it in second by having multiple heads to the model.",
                    "label": 0
                },
                {
                    "sent": "So this is sort of just having a simple classifier.",
                    "label": 0
                },
                {
                    "sent": "The top you have multiple different outputs that cannot help regularize two and then of course you can also inject noise into the network, so most Whiting.",
                    "label": 1
                },
                {
                    "sent": "I know one of this is dropout from Jeff Hinton, and there's a few other variance.",
                    "label": 0
                }
            ]
        },
        "clip_87": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Just so one natural question that people so you spend less time regularising, why do you have a smaller model and be done with it?",
                    "label": 0
                },
                {
                    "sent": "Well, you know anyone have to worry about regularization.",
                    "label": 0
                },
                {
                    "sent": "Well this is a sort of rough little diagram explains why I think so.",
                    "label": 0
                },
                {
                    "sent": "We have some data.",
                    "label": 0
                },
                {
                    "sent": "There is high density regions where the data structures quite complicated.",
                    "label": 0
                },
                {
                    "sent": "This sort of low density regions where the very few points.",
                    "label": 0
                },
                {
                    "sent": "If you have a low capacity model you're going to.",
                    "label": 0
                },
                {
                    "sent": "It'll do something sensible everywhere, but it will sort of miss some of the fine structure in the height.",
                    "label": 0
                },
                {
                    "sent": "OK, now if you have a big model, lots of parameters.",
                    "label": 1
                },
                {
                    "sent": "Well now it can fit all those little you know all the details of your data nicely.",
                    "label": 0
                },
                {
                    "sent": "But then it's got his extra capacity and it's liable to do site more crazy things in their low density regions.",
                    "label": 0
                },
                {
                    "sent": "There's nothing to kind of constrain the function and what you're doing.",
                    "label": 0
                },
                {
                    "sent": "Regularization is regularization, should have an effect in these low density regions where there's nothing where there's no data to sort of, override it, and so it will sort of.",
                    "label": 0
                },
                {
                    "sent": "You get the best of both worlds, hopefully right, so it will fit the details in the high density regions and still not do anything to nuts outside of them.",
                    "label": 0
                }
            ]
        },
        "clip_88": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so one other quirky thing to mention, I suppose, is that there's a whole interesting sort of observation which is true of any sort of discriminative approach.",
                    "label": 0
                },
                {
                    "sent": "I guess that you do see it is possible to construct images which will in fact fool the model into producing a certain desired output.",
                    "label": 0
                },
                {
                    "sent": "So this is, you know, a couple of papers that look into this.",
                    "label": 0
                },
                {
                    "sent": "And I'm not quite sure how this where this has links on from next seriously, but it's worth.",
                    "label": 0
                },
                {
                    "sent": "These are fun, so you can create sort of these noise images, which will you know the model will think is a Peacock or something like that.",
                    "label": 0
                },
                {
                    "sent": "OK, so and so no human would make such a mistake, but somehow these models along way from this sort of training images seen in the training set.",
                    "label": 0
                },
                {
                    "sent": "The decision surface can be doing slightly weird things right?",
                    "label": 0
                },
                {
                    "sent": "So there is some argument for trying to come up with better regulations of these models.",
                    "label": 0
                }
            ]
        },
        "clip_89": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Just to talk about, drop out for a second, very briefly, you've got this.",
                    "label": 0
                },
                {
                    "sent": "This is just adding random noise to the feature activations.",
                    "label": 0
                },
                {
                    "sent": "This is in fully connected layers and you basically randomly set half the feature activations to zero during training, but this is a different random subset for each example and then at Test time you don't do this random deletion, you just, but you do have to remember to re scale the weights because you the subsequent we're expected to sort of smaller activation.",
                    "label": 0
                },
                {
                    "sent": "Coming into them, and this does seem to sort of help immensely if you have enough training data, you don't need to do this, But this thing does seem to help.",
                    "label": 0
                },
                {
                    "sent": "Alright.",
                    "label": 0
                }
            ]
        },
        "clip_90": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, I've got some slides which is sort of rules of thumb on how to get these things to work well from Mark Aralias slides I could talk about these, or I could dig into people cover these things, something yesterday.",
                    "label": 0
                },
                {
                    "sent": "Like just.",
                    "label": 0
                }
            ]
        },
        "clip_91": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is a. OK, I'll do it very quickly.",
                    "label": 0
                },
                {
                    "sent": "OK, so essentially this is just sort of how do you get your models to work?",
                    "label": 0
                },
                {
                    "sent": "You know you've built your beautiful model, you got your nice cool data set, you press go and it doesn't really train very well.",
                    "label": 0
                },
                {
                    "sent": "So one thing you can do is you, as I said, you can look at the filters in the first layer.",
                    "label": 0
                },
                {
                    "sent": "You know, certainly expect if it's an image to see.",
                    "label": 0
                },
                {
                    "sent": "Surveys like things this something bad has gone wrong.",
                    "label": 0
                },
                {
                    "sent": "If you get any of these sorts of things coming out to correlate these things like structure, you can try the brace or feature visualization things I mentioned earlier you.",
                    "label": 0
                }
            ]
        },
        "clip_92": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Hope to see something sensible.",
                    "label": 0
                },
                {
                    "sent": "Certainly if you just.",
                    "label": 0
                },
                {
                    "sent": "For giving given life is if you look at this is different in units and these are different training examples.",
                    "label": 0
                },
                {
                    "sent": "You don't want to see this sort of thing.",
                    "label": 0
                },
                {
                    "sent": "This is telling you that some of the units have died.",
                    "label": 0
                },
                {
                    "sent": "They don't have any activation at all.",
                    "label": 0
                },
                {
                    "sent": "There's also telling you that somehow.",
                    "label": 0
                },
                {
                    "sent": "You know different training examples causing the same broadly similar activations across the network, and so it's very very strong correlations here between different units, which is kind of weird.",
                    "label": 0
                }
            ]
        },
        "clip_93": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And that's wrong.",
                    "label": 0
                },
                {
                    "sent": "We're looking for is much sparser thing like this, where different units are turning on for different inputs, and so on and so forth.",
                    "label": 0
                },
                {
                    "sent": "So that's the sort of thing you'd like to see.",
                    "label": 0
                },
                {
                    "sent": "This is of course, just you know effectively vectorizing your feature Maps at each each layer to give each row he'll be the vectorization of your feature Maps of each.",
                    "label": 0
                }
            ]
        },
        "clip_94": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "One thing you could, of course, is just just take a small subset of related checker training model, should be able to minimize the training or effectively on that.",
                    "label": 0
                }
            ]
        },
        "clip_95": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Let's see what else.",
                    "label": 0
                },
                {
                    "sent": "If you're training blows up, maybe learning rates too large, or you've got an error in your numerical gradients.",
                    "label": 0
                },
                {
                    "sent": "If you if.",
                    "label": 0
                },
                {
                    "sent": "If you do minimize your loss, but then you the thing you care about, the accuracy on your task is terrible, you might want to check your loss function.",
                    "label": 0
                },
                {
                    "sent": "Maybe you've got some degeneracy in that, or something.",
                    "label": 0
                },
                {
                    "sent": "If you're not.",
                    "label": 0
                },
                {
                    "sent": "If the networks converging but they're pretty bad solution.",
                    "label": 0
                },
                {
                    "sent": "I mean this sort of sort of Canonical deep learning solution just to make the model bigger, which is a bit of a.",
                    "label": 0
                },
                {
                    "sent": "Live answer, but you know that might be something to do with it, and if it's too slow then you know basically get a bigger computer.",
                    "label": 0
                },
                {
                    "sent": "It's the slightly silly answer.",
                    "label": 0
                },
                {
                    "sent": "OK so.",
                    "label": 0
                }
            ]
        },
        "clip_96": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so I'm just going to.",
                    "label": 0
                },
                {
                    "sent": "I guess I should say that these models of course are now very widely used in industry, so in Facebook won't be spending some time last couple of years.",
                    "label": 1
                },
                {
                    "sent": "So there's about a billion images of they uploaded or something like that, and each image gets seen by two of these components.",
                    "label": 0
                },
                {
                    "sent": "Wonders face recognition.",
                    "label": 0
                },
                {
                    "sent": "This is one of the older face recognition models.",
                    "label": 0
                },
                {
                    "sent": "Another one does sort of generic object recognition and stuff like that, so they really used in this very serious way and there's very they do a lot of important things, you know.",
                    "label": 0
                },
                {
                    "sent": "Facebook and Google and stuff like that so it really work in a pretty spectacular way.",
                    "label": 0
                }
            ]
        },
        "clip_97": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I'll just skip over this because yeah, sure.",
                    "label": 0
                },
                {
                    "sent": "What is Pennzoil to your test that is so?",
                    "label": 0
                },
                {
                    "sent": "This is on the.",
                    "label": 0
                },
                {
                    "sent": "Label faces in the wild data set, so this was this was a slightly old paper I guess now, but this was a red model.",
                    "label": 0
                },
                {
                    "sent": "Was that this deep face system that again it's now they've got a bigger model and it's you know these things constantly change and I'm slightly lost track of where exactly what the structure is, but with this model they were sort of getting quite close here to sort of human performance, and I think the best results are better than that now.",
                    "label": 0
                },
                {
                    "sent": "So I think the mega faces the new data set that's come out.",
                    "label": 0
                },
                {
                    "sent": "The bigger one with sort of millions of examples and I don't have my account.",
                    "label": 0
                },
                {
                    "sent": "Don't know how the Facebook system works on that.",
                    "label": 0
                },
                {
                    "sent": "I'm not sure they've actually tried.",
                    "label": 0
                },
                {
                    "sent": "Tried it in anger.",
                    "label": 0
                },
                {
                    "sent": "I mean, of course there optimizing for some internal benchmark which is different to the public benchmarks, right?",
                    "label": 0
                },
                {
                    "sent": "So it's going to be hard to say, but they were all using big continents basically.",
                    "label": 0
                }
            ]
        },
        "clip_98": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is fair to say.",
                    "label": 0
                },
                {
                    "sent": "OK, so I can't train quickly in the last few minutes.",
                    "label": 0
                },
                {
                    "sent": "Go over some of the applications of these things in different vision things.",
                    "label": 0
                },
                {
                    "sent": "Broadly speaking, one of the things we often carry selected is trying to localize the object bounding box around, not just simply wasn't picturing cause you.",
                    "label": 0
                }
            ]
        },
        "clip_99": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Multiple objects in.",
                    "label": 0
                },
                {
                    "sent": "There's two broad of ways of doing this.",
                    "label": 0
                },
                {
                    "sent": "One is you just going to sort of ascension.",
                    "label": 0
                },
                {
                    "sent": "Examine every single position and scale exhaustively so the Canonical example of this would be the over feat system from Yan students, PS, seminarian others.",
                    "label": 0
                },
                {
                    "sent": "The second approach is to essentially have some mechanism you know beforehand, identifying potentially interesting regions of the image, and then take each of those interesting regions and shoving through a component to classify them.",
                    "label": 0
                },
                {
                    "sent": "What's interesting is that despite intuitively you think maybe this thing would be the, even though it might be expensive, would do the best in practice.",
                    "label": 0
                },
                {
                    "sent": "You know the best models do seem to end up using this second approach, so it's obviously you have to have a sort of comprehensive set of regions.",
                    "label": 0
                },
                {
                    "sent": "So let me just quickly go through those two.",
                    "label": 0
                }
            ]
        },
        "clip_100": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Things before I get into too much details.",
                    "label": 0
                },
                {
                    "sent": "OK, so broadly speaking yes, exhaustive approach is just going to slide this thing over the image.",
                    "label": 0
                },
                {
                    "sent": "Everything is sort of convolutional in some sense, so these things, even though there is a fully connected layer here, they become sort of 1 by 1 convolution when you do it like this, so you can just sort of slide them all over the image again.",
                    "label": 0
                }
            ]
        },
        "clip_101": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And you do this in multiple scales, so you're going to get a bunch of Maps basically.",
                    "label": 0
                },
                {
                    "sent": "So if you have 1000 classes, you'll have for each location of the input window you're going to get 1000 dimensional vector, so different positions input window.",
                    "label": 0
                },
                {
                    "sent": "You're going to get rid of these and then that happened over different scales, and then you can also try and progress on the bounding box coordinates too.",
                    "label": 0
                }
            ]
        },
        "clip_102": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So that will become a sort of four dimensional output and this.",
                    "label": 0
                }
            ]
        },
        "clip_103": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And so these are.",
                    "label": 0
                },
                {
                    "sent": "This is before non maximal suppression, the kind of result you get.",
                    "label": 0
                }
            ]
        },
        "clip_104": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then and then these are results with non Max suppression.",
                    "label": 0
                },
                {
                    "sent": "OK so this is.",
                    "label": 0
                }
            ]
        },
        "clip_105": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This exhaustive slide over everywhere.",
                    "label": 0
                },
                {
                    "sent": "OK, so not Max.",
                    "label": 0
                }
            ]
        },
        "clip_106": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Impression would be So what happens if you do this?",
                    "label": 0
                },
                {
                    "sent": "Of course you're going to multiple high scoring.",
                    "label": 0
                },
                {
                    "sent": "Bounding box is very very similar to one another.",
                    "label": 0
                },
                {
                    "sent": "OK, because if you just shift the input window slightly, it's not going to change the output to dramatically service high in one location is going to be in neighboring scales and positions, So what you can do is you can just have some mechanism of merging these these bounding boxes into a single one, and so this is I have to say a little bit.",
                    "label": 0
                },
                {
                    "sent": "This is what non Max suppression means.",
                    "label": 0
                },
                {
                    "sent": "This is a little bit heuristic I would have to say.",
                    "label": 0
                },
                {
                    "sent": "I mean I think.",
                    "label": 0
                },
                {
                    "sent": "There are more steps to try and merge this into the whole learning procedure, but it turns out to be quite important.",
                    "label": 0
                },
                {
                    "sent": "Quite important mechanism for sort of because you get penalized, of course for saying there were two objects when they're really one in the various valuation criteria people use.",
                    "label": 0
                }
            ]
        },
        "clip_107": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So one, So what happens in practice, of course, is that you know when you're doing the sliding window thing.",
                    "label": 0
                },
                {
                    "sent": "You do end up with errors in Omak suppression and also just sort of false alarms like random bits of background.",
                    "label": 0
                },
                {
                    "sent": "The model seems to fire on.",
                    "label": 0
                },
                {
                    "sent": "You do end up with false alarms, which I think is the main reason these models don't do.",
                    "label": 0
                }
            ]
        },
        "clip_108": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "As well as these things where you have an initial input image, you have some proposals, some proposal mechanism which is extracts a large number, so you know 2000 different regions, and then you're going to pretend each one is a separate image and slam it through your favorite classifier.",
                    "label": 0
                },
                {
                    "sent": "So there's a whole bunch of these different approaches.",
                    "label": 0
                },
                {
                    "sent": "I think the state of the art with this I'm probably going to be wrong because changes so fast mine, so if you take the residual network models from coming here and others and use that as your neural net, and there's very sort of sophisticated proposal mechanisms, that seems to give the best.",
                    "label": 0
                },
                {
                    "sent": "Detection performance on the on the various benchmarks.",
                    "label": 0
                },
                {
                    "sent": "But there's a lot of engineering there on how you do the proposals, and so on.",
                    "label": 0
                }
            ]
        },
        "clip_109": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The whole thing works for video as well, so you can just simply have 3.",
                    "label": 0
                },
                {
                    "sent": "Answers for different regions.",
                    "label": 0
                },
                {
                    "sent": "Because there's some seating structure that's right.",
                    "label": 0
                },
                {
                    "sent": "So yeah, I think there are people are doing this sort of thing.",
                    "label": 0
                },
                {
                    "sent": "It helps, but it's much less.",
                    "label": 0
                },
                {
                    "sent": "It's always been underwhelming actually.",
                    "label": 0
                },
                {
                    "sent": "I mean, it gives some small gain, but it's.",
                    "label": 0
                },
                {
                    "sent": "I think the general rule is like building a better classifier has thus far delivered the biggest performance gain, so that in the Coco challenge that happened last year's one, I mean the residual networks, had a far better than Microsoft Gang, had a much, much better classified, anybody else with residual network thing, and that in the end just blew everything else out of the water 'cause people were trying all these other things too.",
                    "label": 0
                },
                {
                    "sent": "But I mean at some point of course will probably be unable to improve the classifiers anymore.",
                    "label": 0
                },
                {
                    "sent": "And then yeah, these things should not helping.",
                    "label": 0
                },
                {
                    "sent": "So this is the.",
                    "label": 0
                },
                {
                    "sent": "This is a 3D component now, so you got a video and you're just going to do now 3D convolutions.",
                    "label": 0
                },
                {
                    "sent": "So your kernels have on 2D kernels at three by 3D kernels, and so it's basically three by three by three convolution kernels with two by two by two Max pooling, and this is sort of again a fairly shallow model by modern standards, but this is when you run on video.",
                    "label": 0
                },
                {
                    "sent": "There's a really substantial amount of computational overhead trying to run on.",
                    "label": 0
                },
                {
                    "sent": "Decent resolution video.",
                    "label": 0
                }
            ]
        },
        "clip_110": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Things I'll show you some.",
                    "label": 0
                },
                {
                    "sent": "Just some fun so this is just some benchmark on people use.",
                    "label": 0
                },
                {
                    "sent": "Interestingly, combining with at least maybe a little bit out of date with what the current state of the art is.",
                    "label": 0
                },
                {
                    "sent": "But until very recently combining with some of the handcrafted features did actually give solve some gain over the 3D component, but I'm pretty sure every time that the handcrafted.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so this was using some features drive from optical flow.",
                    "label": 0
                },
                {
                    "sent": "I'm sure overtime these numbers will I mean the raw component things will improve.",
                    "label": 0
                }
            ]
        },
        "clip_111": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is just showing that if you do have some temporal extent your filters, it does give again.",
                    "label": 0
                },
                {
                    "sent": "The blue curve is without, you know, is a sort of 2D filter spatially, but no temporal extent.",
                    "label": 0
                },
                {
                    "sent": "Red is.",
                    "label": 0
                },
                {
                    "sent": "If you have a little bit of a little bit of temporal extent, it does actually give a performance gain and this is just showing this sort of.",
                    "label": 0
                },
                {
                    "sent": "You get about a feature representation.",
                    "label": 0
                },
                {
                    "sent": "If you incorporate this.",
                    "label": 0
                }
            ]
        },
        "clip_112": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Some temporal structure just show some videos of these things running, so these are like this is different sports being played.",
                    "label": 0
                },
                {
                    "sent": "This is a top 2 predictions from the model so you can see it's able to sort of discriminate between fairly similar sports.",
                    "label": 0
                },
                {
                    "sent": "Basically this is I guess another one.",
                    "label": 0
                },
                {
                    "sent": "So lots of obscure sports in this data set, but the model does fairly well.",
                    "label": 0
                },
                {
                    "sent": "Yep.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so it does.",
                    "label": 0
                },
                {
                    "sent": "It does beat out a single frame, yeah?",
                    "label": 0
                },
                {
                    "sent": "There is some dynamic structure that does actually help you.",
                    "label": 0
                },
                {
                    "sent": "Yeah, the baselines are in the tables of a single frames and stuff, OK.",
                    "label": 0
                },
                {
                    "sent": "So that so you can see that single frame stuff.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                }
            ]
        },
        "clip_113": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, I guess I can very quickly go through this.",
                    "label": 0
                },
                {
                    "sent": "So yeah, so one thing of course you want to do is you might want to just give you know.",
                    "label": 1
                },
                {
                    "sent": "Classifications about going from pixels to a sparse label vector detection is about going to some bounding box, but you can actually very easily get these models to produce pixel images as output.",
                    "label": 0
                },
                {
                    "sent": "OK, and these images could be, for example, segmentation.",
                    "label": 0
                },
                {
                    "sent": "The image or other things, and will.",
                    "label": 0
                },
                {
                    "sent": "One key difference here is you don't want to pull at this point because you know classifications by going from this very high dimensional signal down to this very low dimensional signal or not very low dimensional but relatively low dimensional, whereas in outputs also an image.",
                    "label": 0
                },
                {
                    "sent": "It turns out that pooling you don't want too much more.",
                    "label": 1
                }
            ]
        },
        "clip_114": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Pulling so.",
                    "label": 0
                }
            ]
        },
        "clip_115": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is just a little example of a simple model you can predict, like a sort of semantic per pixel label.",
                    "label": 0
                },
                {
                    "sent": "So this is, you know wall floor, bed, pillow etc.",
                    "label": 0
                }
            ]
        },
        "clip_116": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And this is one of the depth.",
                    "label": 0
                },
                {
                    "sent": "You can produce a pix.",
                    "label": 0
                }
            ]
        },
        "clip_117": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Depth map or even a surface normal map telling the orientation of each pixel in the scene.",
                    "label": 0
                }
            ]
        },
        "clip_118": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And this is 1 model that one of my students looked at with sort of multiscale thing.",
                    "label": 0
                },
                {
                    "sent": "So these are sort of, you know, this is the number of feature channels.",
                    "label": 0
                },
                {
                    "sent": "This is these are convolutional or basic convolutional layers.",
                    "label": 0
                },
                {
                    "sent": "You take those convolutional feature Maps and you stick them in the subsequent scale of the network and repeat and so on.",
                    "label": 0
                },
                {
                    "sent": "And you can train up.",
                    "label": 0
                }
            ]
        },
        "clip_119": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Nice and you can do basically the same architecture, just slightly different.",
                    "label": 0
                },
                {
                    "sent": "You know different weights you can keep the same weights for this layer of the model, but for this sort of finer scales you have to sort of retrain for different modalities like surface normals.",
                    "label": 0
                }
            ]
        },
        "clip_120": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And class labels.",
                    "label": 0
                },
                {
                    "sent": "So this layout here is sort of classic, so Alex net or VG style model that gives you sort of broader understanding of the scene as you.",
                    "label": 0
                }
            ]
        },
        "clip_121": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You can't predict the stuff you know.",
                    "label": 0
                },
                {
                    "sent": "You can't predict.",
                    "label": 0
                },
                {
                    "sent": "The sort of depth of just looking at a tiny Patch.",
                    "label": 0
                },
                {
                    "sent": "You have to actually understand.",
                    "label": 0
                },
                {
                    "sent": "OK, you know these are two walls and this is the floor and stuff like that.",
                    "label": 0
                },
                {
                    "sent": "So you get that overall structure from the from the core scale and then this is just refining to make things sharper.",
                    "label": 0
                }
            ]
        },
        "clip_122": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And all you have to do really is just change the loss functions to be appropriate.",
                    "label": 0
                },
                {
                    "sent": "So there was a bit of messing around here.",
                    "label": 0
                },
                {
                    "sent": "We're just trying to find a sort of something that was invariant, you know, looked at this relative depths 'cause you know.",
                    "label": 0
                },
                {
                    "sent": "Obviously predicting absolute depth is very difficult to do, but you can put it relative depths if you have the right loss function, surface normals.",
                    "label": 0
                },
                {
                    "sent": "Just looking at kind of angles between surface normals and a standard sort of per pixel softmax for the late.",
                    "label": 0
                }
            ]
        },
        "clip_123": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Task and yeah, you can actually get some pretty nice.",
                    "label": 0
                },
                {
                    "sent": "I mean these are just this is ground truth.",
                    "label": 0
                },
                {
                    "sent": "These images collected with you know you get with the Kinect depth sensor.",
                    "label": 0
                },
                {
                    "sent": "These are sort of predictions actually knew results may be a little bit cleaner than this to be honest.",
                    "label": 0
                }
            ]
        },
        "clip_124": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And this is surface normal, so you can see these.",
                    "label": 0
                },
                {
                    "sent": "Actually look at many ways better than the ground truth.",
                    "label": 0
                }
            ]
        },
        "clip_125": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then.",
                    "label": 0
                }
            ]
        },
        "clip_126": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You can use these things for scene pausing, so trying.",
                    "label": 0
                }
            ]
        },
        "clip_127": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Segment the scene with different object categories.",
                    "label": 0
                },
                {
                    "sent": "This was some early work from young students.",
                    "label": 0
                }
            ]
        },
        "clip_128": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You can also use it for.",
                    "label": 0
                },
                {
                    "sent": "Sort of bottles complications.",
                    "label": 0
                },
                {
                    "sent": "This is a. Folks at MIT Sebastian songs Group that they were using it for sort of segmenting slices of microscope slides.",
                    "label": 0
                },
                {
                    "sent": "So one thing you can do is sort of combine this notion of segmentation detection somehow.",
                    "label": 0
                },
                {
                    "sent": "What you want to do, some producing bounding boxes you can do segmentations.",
                    "label": 0
                },
                {
                    "sent": "This was a recent piece of work by some of the folks on Facebook where they have basically a little of Jeannette with sort of fancy head on top and are going to slide some window over the image and for each window they're going to try and predict a kind of segmentation mask for the object that's in the middle of the frame.",
                    "label": 0
                },
                {
                    "sent": "And also they're going to score for saying how object like it is.",
                    "label": 0
                },
                {
                    "sent": "So this is.",
                    "label": 0
                },
                {
                    "sent": "This is a mechanism basically for that this is a way to propose a bunch of bounding boxes that can be used with your favorite super strong classifier.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is a object proposal mechanism, not a detection mechanism.",
                    "label": 0
                },
                {
                    "sent": "Object detection mechanism itself.",
                    "label": 0
                },
                {
                    "sent": "So when you run this over big image, you end up with this sort of big map of masks, right?",
                    "label": 0
                },
                {
                    "sent": "So the ones in the center of Bright because they have high objectness and you can see there nicely sort of segmenting the animal.",
                    "label": 0
                },
                {
                    "sent": "Versus the other objects in the scene.",
                    "label": 0
                },
                {
                    "sent": "And this is just a map of the scores and you can use this to produce a whole bunch of bounding boxes, and so this gives you a nice way of justice.",
                    "label": 0
                },
                {
                    "sent": "Taking a complicated scene like this because it's trying to sort of segment the object in the middle of the scanning window.",
                    "label": 0
                },
                {
                    "sent": "You're able to sort of segment and detect these different object instances.",
                    "label": 0
                },
                {
                    "sent": "If you have just a per pixel segmentation.",
                    "label": 0
                },
                {
                    "sent": "All these sheep would have been merged into one sort of amorphus blob of sheep, but that's not actually very useful.",
                    "label": 0
                },
                {
                    "sent": "You want to actually pick out each individual animal.",
                    "label": 0
                },
                {
                    "sent": "And you can get it with this kind of approach.",
                    "label": 0
                },
                {
                    "sent": "OK, so I'm rushing slightly but.",
                    "label": 0
                }
            ]
        },
        "clip_129": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Quickly go through this so well.",
                    "label": 0
                },
                {
                    "sent": "You can also use these things for low level vision problems.",
                    "label": 0
                },
                {
                    "sent": "You can use it with denoising.",
                    "label": 0
                },
                {
                    "sent": "Is BM3DS is sort of state of the art nonparametric denoising approach and these neural Nets.",
                    "label": 0
                },
                {
                    "sent": "Actually you can train them.",
                    "label": 0
                },
                {
                    "sent": "So basically you train it to protect this as input and produce.",
                    "label": 0
                },
                {
                    "sent": "You know that the original image is output.",
                    "label": 0
                },
                {
                    "sent": "That's a training time.",
                    "label": 0
                },
                {
                    "sent": "This is a test example.",
                    "label": 0
                },
                {
                    "sent": "As you can see, it does a reasonable job.",
                    "label": 0
                }
            ]
        },
        "clip_130": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You can even get it to deblur images as well, so there's slight more complicated setup, but you can even use it in the blind setting where you don't have knowledge of the blur kernel, so you can sort of training all kinds of different blur functions, and then it will sort of, you know, still figure out what's going on so you can actually, which is somewhat surprising.",
                    "label": 0
                }
            ]
        },
        "clip_131": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Do things like inpainting, so this is just removing.",
                    "label": 0
                },
                {
                    "sent": "Text to get a sort of clean photograph.",
                    "label": 0
                }
            ]
        },
        "clip_132": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And this was so slightly crazy.",
                    "label": 0
                },
                {
                    "sent": "So big from being from.",
                    "label": 0
                },
                {
                    "sent": "Of course rain is something that occurs very frequently and this was somewhat slightly.",
                    "label": 0
                },
                {
                    "sent": "Crazy thing where you got a piece of glass, you got raindrops falling on it.",
                    "label": 0
                },
                {
                    "sent": "You know.",
                    "label": 0
                },
                {
                    "sent": "Can you actually remove the rain from your photograph so you can do this with the component?",
                    "label": 0
                },
                {
                    "sent": "So this is this is the output from the components, so it's just removing the you can see as the rain gets heavier and heavier there's more and more glass water building up, but the output of this component doesn't really doesn't really don't see it effectively.",
                    "label": 0
                },
                {
                    "sent": "So anyway, this slightly crazy application, but it shows that the comments can do some quite fun things.",
                    "label": 0
                },
                {
                    "sent": "And if you just try doing something very simple like you know some pretty simple baseline like a median filter.",
                    "label": 0
                },
                {
                    "sent": "You can see that all the rain is there, for example.",
                    "label": 0
                },
                {
                    "sent": "When the jobs get really big, of course the network can't do anything.",
                    "label": 0
                },
                {
                    "sent": "But and then finally I guess you know.",
                    "label": 0
                }
            ]
        },
        "clip_133": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Sort of sort of interesting directions and stuff like that.",
                    "label": 0
                },
                {
                    "sent": "You know it's combining confidence with some kind of structured model on top so you know this idea is very old, in fact, so some of the check reading systems that Yan and Leon, Batu and Joshua designed back in the late 90s.",
                    "label": 0
                },
                {
                    "sent": "AT&T use this kind of structure.",
                    "label": 0
                },
                {
                    "sent": "You have a neural net the recognizing pieces of digit, and then you'll have some kind of.",
                    "label": 0
                },
                {
                    "sent": "You have to do some sort of search to find the optimal combination of these different fragments to give the best overall explanation of the signal.",
                    "label": 0
                },
                {
                    "sent": "So there was kind of an optimization problem.",
                    "label": 0
                },
                {
                    "sent": "Had to do here on top and you can train the whole thing jointly and stuff like this and so this I think this is.",
                    "label": 0
                }
            ]
        },
        "clip_134": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So people are thinking about how to apply those different vision problems so.",
                    "label": 0
                }
            ]
        },
        "clip_135": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This example would be if you wanted to sort of.",
                    "label": 0
                },
                {
                    "sent": "No.",
                    "label": 0
                },
                {
                    "sent": "Get human body pose so you have a certain little graphical model here, which represents sort of different limbs and you know the head is dependent on the shoulder and the shoulders dependent on the elbow and always dependent on the wrist and so on, and vice versa as well.",
                    "label": 0
                },
                {
                    "sent": "So these sort of conditional dependencies present so you specify the structure.",
                    "label": 0
                },
                {
                    "sent": "This model you want to fit this to quite complicated data of humans, and so this was an attempt to try and do this sort of, you know.",
                    "label": 0
                }
            ]
        },
        "clip_136": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Common structure, so you basically have these part detectors that would find.",
                    "label": 0
                }
            ]
        },
        "clip_137": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Parts of the image.",
                    "label": 0
                },
                {
                    "sent": "So you have these unique potentials that would basically be you know where do I think the face structure is and then you have these potential.",
                    "label": 0
                },
                {
                    "sent": "These complicated distributions that you would learn with conditionals of like where's the face given the shoulder.",
                    "label": 0
                },
                {
                    "sent": "OK and then this will be the sort of message you are passing in this little graphical model to then infer where where was the face and then from there you could.",
                    "label": 0
                },
                {
                    "sent": "So this is sort of slightly bastardized version of some product belief propagation, instantiated in.",
                    "label": 1
                }
            ]
        },
        "clip_138": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Tickle model, so instantiate it in the neural net and so you can turn a lot of these operations that you would normally compute in belief propagation into.",
                    "label": 0
                },
                {
                    "sent": "Something that you can sort of try and backdrop through.",
                    "label": 0
                },
                {
                    "sent": "So I'm going very fast because I want to try and finish, But anyway this gave some nice results on sort of face.",
                    "label": 0
                },
                {
                    "sent": "Post recognition and also for using for hand tracking too.",
                    "label": 0
                },
                {
                    "sent": "'cause he was, so there's a clear, clearly defined model for the hand and and the fingers and so on and so forth.",
                    "label": 0
                },
                {
                    "sent": "So that was sort of rather rapid overview of components in vision, so I apologize if I missed this latest greatest papers and stuff like that.",
                    "label": 0
                },
                {
                    "sent": "But you know, trying to keep up with everything.",
                    "label": 0
                },
                {
                    "sent": "There's an archive is very challenging, and so on so forth.",
                    "label": 0
                },
                {
                    "sent": "Alright, so I'll stop there.",
                    "label": 0
                },
                {
                    "sent": "Thanks very much.",
                    "label": 0
                }
            ]
        }
    }
}