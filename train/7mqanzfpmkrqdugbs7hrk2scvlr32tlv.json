{
    "id": "7mqanzfpmkrqdugbs7hrk2scvlr32tlv",
    "title": "Active Inference and Uncertainty",
    "info": {
        "author": [
            "Karl Friston, Wellcome Trust Centre for Neuroimaging, University College London"
        ],
        "published": "Aug. 24, 2011",
        "recorded": "July 2011",
        "category": [
            "Top->Computer Science->Artificial Intelligence"
        ]
    },
    "url": "http://videolectures.net/uai2011_friston_active/",
    "segmentation": [
        [
            "It's a great honor and pleasure to be here.",
            "I'm always more flattered to be invited the more out of depth I feel an in this audience.",
            "I do feel a little bit outside my normal comfort zone, so my background is in physics and psychology as a student.",
            "But then I trained as a psychiatrist and neurologist, so the story that I'm going to tell today is more about applying.",
            "Leave it up, yeah.",
            "Is that better?",
            "Can you hear?",
            "No, should I stand by come closer?",
            "Can you hear me now?",
            "Yeah.",
            "Is that better?",
            "No.",
            "I could just point to all the key bits on the slides and ask you to read at the back that might be altered, or you could hear that Sir right in the back.",
            "That's good.",
            "That means it's working.",
            "I was just saying I'm outside my comfort zone and by virtue of that I'm very flattered to be here.",
            "I trained in psychology and physics, but for the past decades have been focusing on your apology.",
            "So the story that I'm going to tell today is very much the application.",
            "Of the idea, ideas that your community has brought to the table in trying to understand how the brain works.",
            "So for those of you in machine learning.",
            "What I'm going to be doing is assuming that the brain entails or is a generative model of its world and that it performs very simple Bayesian filtering on sensory inputs.",
            "But there is a twist.",
            "In addition to this Bayesian perspective on the brain as an inference machine, I'm going to assume that it is equipped with reflexes that enable it to sample data but also maximize the evidence or marginal likelihood associated with the model that is represented by the brain, and that's what I'm going to refer to as active inference.",
            "So those two things together give a model for perception and action.",
            "And I'm going to use that model to illustrate for you some of the issues of uncertainty in a perceptual and behavioral context, so that's that's.",
            "A very brief overview of what I'm going to be talking about."
        ],
        [
            "Would you like to do first?",
            "There is just acknowledge the intellectual architects of all the ideas I'm going to be talking about.",
            "You'll be familiar with many of these people, either historically or personally.",
            "Much of what I'm going to say takes its lead from the notion of generative models as articulated by Helmholtz.",
            "A nice quote up there, objects have to be in the field of vision.",
            "They have to be there in order to produce the same impression on the nervous mechanism.",
            "In other words, there is an explicit requirement.",
            "Or a constructive generative approach to the perception that I'm going to formalize in terms of Bayesian filtering or modeling version along the lines suggested by Geoffrey Hinton and colleagues.",
            "I'm going to use the free energy construct, but we heard about in the last presentation prior to the poster spotlights an and Furthermore, going to introduce some dynamical systems theory to to give the simulations and autonomy and itinerancy that is meant to represent behavior and uncertainty about that behavior."
        ],
        [
            "So brief overview of the talk.",
            "To motivate the importance of maximizing the marginal likelihood or the evidence, I'm going to take a.",
            "An ensemble dynamics or population dynamics perspective and asks a very simple question about the nature of adaptive self organizing systems like the brain.",
            "So I'm going to spend a bit of time trying to describe the motivation for the free energy minimization that we heard about earlier on today, and that's going to lead us to the free energy principle.",
            "A lot of that rests upon generative models, and I'm going to briefly outline the sorts of models that we will assume the brain users to make sense of it.",
            "Sensory input, and then the second half of the talk will be giving you two illustrative examples, one in the domain of perception and one in the domain of action.",
            "And given the theme of this meeting, I'm going to try and emphasize uncertainty both in formal terms and in terms.",
            "Of behavior and affordance.",
            "So I know."
        ],
        [
            "To stop.",
            "This sort of presentation by asking you to think about in simple terms.",
            "What it is to be a self organizing system like the brain?",
            "Specifically, what is the difference between a bird and a snowflake given that they are both open systems exchanging entropy and information and energy with the environment, they both have beautiful self similar self organized structure.",
            "So what is the key difference that distinguishes between the behaving bird and the snowflake?",
            "Any ideas?",
            "The bird yeah yeah alright, you've got it.",
            "So that's exactly it moves it behaves, and that's the only difference.",
            "So in fact the answer was up there, but I'm sure you didn't cheat.",
            "So a bird basically moves, alters its physical relationship with the environment, and from our perspective that basically means it is in control of the sensory streams that it's samples, and it's at one simple fact that I'm going to exploit when extending free energy minimization, not just to perceptual inference, but also to movement and behavior.",
            "And with that one extension hopefully account for the sorts of behaviors that we observe in animate.",
            "Systems like."
        ],
        [
            "Sound.",
            "So.",
            "Let me extend that question now and let's think about the difference between a population or ensemble of snowflakes snowfall and a flock of birds and trying to motivate the importance of maximizing the log marginal likelihood in terms of minimizing the entropy of the distribution.",
            "The way that I want to do that is just to note that if a self organizing system like a bird.",
            "Is going to injure over extended periods of time.",
            "It has to avoid phase transitions in a whole variety of high dimensional state.",
            "Space is phase spaces be the physiological or physical or behavioral?",
            "In other words, it has to constrain or confine the states that it occupies to a limited domain of all the states it could occupy in order to remain categorizable as a bird.",
            "Otherwise it would be a dead bird or.",
            "Have an exploded bird or a bird that could not fly.",
            "So the notion here is that basically biological agents stay in the same place.",
            "In terms of statistical physics, they basically resist the second law of thermodynamics that says the entropy should."
        ],
        [
            "Increase, but what is entropy?",
            "Well, entropy is just the average surprisal and I'm going to call surprise or surprise here.",
            "The negative log probability of some sensory data given a model of that sensory data that I'm denoting by censored S and a model here.",
            "So this quantity here I'm going to refer to a surprise.",
            "It's just the negative log marginal likelihood or the negative log evidence for a model given for.",
            "In data for a particular model and other exotic assumptions, the long term time average of surprise is just the entropy of the sensory states under consideration.",
            "And this nicely summarizes the requirement that self organizing systems that have to avoid phase transitions and remain in a small part of phase space should minimize their surprise.",
            "In other words, they have to occupy a limited number of States and you can think of this quite simply as a homeostasis or generalization of the notion of homeostasis.",
            "I should excuse or qualify why I've got Donald Duck here.",
            "I had to give this talk to some schoolchildren in Berlin and they asked me to remove all the equations and replacing with Donald Duck.",
            "But ever since then.",
            "I found that the Donald Duck slides work much better than the ones with equations for grownups as well, so I'm going to use the Donald Duck with a few equations put back in again.",
            "So basically this Donald Ducks in a state of high surprise.",
            "He's not usually in this state.",
            "He's hungry, is closed to demise and needs to find where his friends are to find the part of state space that he occupies that has a high ensemble density or a low surprise and will hopefully move there.",
            "If you can minimize surprise by."
        ],
        [
            "But there's a problem.",
            "Agents can't measure their surprise explicitly, and this is where the free energy comes in an hour.",
            "Repeat it is being used here in exactly the same sense that either you or the people sitting next to you will use it in machine learning.",
            "It's just a bound approximation or an upper bound on surprise that can be evaluated by an agent given its sensory signals that can be minimized, and implicitly therefore.",
            "Minimizing surprises anyone point in time and therefore minimizing the long term time average or path integral which hundred consumptions will be the entropy?",
            "So this means that agents are minimize their free energy, so what's free energy?"
        ],
        [
            "Many of you will know this, but let me just make for those who don't just make it very intuitive.",
            "Essentially, under some simplifying assumptions it reduces to the prediction error.",
            "The amplitude of the differences between sensory inputs and predictions optimized predictions of those inputs under the model that is entailed by.",
            "In this instance the brain and that makes common sense in that having.",
            "Very very small predictions means that you are not going to be surprised and surprise is perpetually minimized and you avoid these surprising exchanges with the world and hopefully avoid these phase transitions when you move too far away from the part of state space that you should use."
        ],
        [
            "Be occupying.",
            "So more formally than I have in mind here.",
            "A universe that comprises internal states of the brain or quantity is owned by the brain that I'm summarizing here in terms of sufficient statistics of an arbitrary probability distribution density which will call the recognition density.",
            "And action variables that the way that we move our effector organs are muscles.",
            "Will cause a change in the sampling of sensory inputs that are generated through some dynamical process in the real world.",
            "Here, the Theater Capitol Theater, here basically spammed in for all quantities in the real world that are hidden.",
            "There hidden quantities that can be time dependent or fixed.",
            "I refer to those as hidden States and hidden parameters subsequently so these evolve according to stochastic differential equation, they supply sensory inputs, which through a sensory nonlinear century mapping.",
            "Here we had some sensory noise and these enter the system and then the internal states of the brain respond in some way, as do the action and the whole cycle is complete and the underlying idea here is that both the internal brain states.",
            "Encoding this recognition density and action simply minimize free energy that is a function of the sensory impressions and the internal brain states.",
            "Now these internal brain states are the sufficient statistics of Q.",
            "This recognition density over the hidden unknown causes in the world and the free energy an it's called a free energy larger because it can be decomposed into an energy and entropy has this very simple form.",
            "Here it's just the expected Gibbs energy here.",
            "Under Q recognition density plus the negentropy of the recognition density Q itself.",
            "Where the Gibbs energy is just the negative log joint probability of getting these data and their causes under the model in question, which you will be familiar with in terms of a mixture of log likelihood and and log prior there.",
            "The reason I'm writing this out in full is largely too.",
            "Emphasize the central role played by this Gibbs energy, or indeed one could understand this G are sending it for a generative model and implied by this joint distribution here.",
            "So what sorts of models might the brain news and I'm going to take my lead here from your anatomy and in particular?"
        ],
        [
            "The hierarchical organization of the brain and assume that the brain is using a hierarchal dynamical model of this form.",
            "Here man, this is fairly simple in the sense that it's just a composition of continuous time state space models.",
            "So for example, at the lowest part of the hierarchy we have sensory data here that are produced as a static mapping from some hidden states.",
            "Here X.",
            "Who that evolve?",
            "Who have equations of motion parameterized by these parameters?",
            "Here we had some random fluctuations whose precision inverse variance for amplitude is controlled by these variables.",
            "Pi here and then we produce these sensory data here crucially.",
            "The inputs, the exhaust, its inputs or perturbations to these hidden states are the outputs of another hierarchal or state space model.",
            "And then we build that as high as we like.",
            "So that's the underlying model.",
            "I'm going to assume that the brain is using to explain or predict its sensory information and also prescribed action in terms of trying to minimize free energy or prediction error."
        ],
        [
            "So again, very intuitively, for those people not in machine learning.",
            "All that we've said here really is that the brain has an internal representation of the causes of its sensory input.",
            "It delivers predictions of sensory input to low levels in the hierarchy.",
            "It compares's predictions with what is actually being sampled to generate prediction errors that are then passed forward to adjust and optimize the estimates of the underlying causes.",
            "And this reciprocal message passing persists until the free energy or the prediction errors have been minimized and one has a Bayes optimal explanation for the causes of the sensory information.",
            "Essentially hierarchal message passing in the brain."
        ],
        [
            "The form of this.",
            "Actually, is almost identical to a common bucy filter.",
            "It's a slightly slight generalization of the common BC filter an.",
            "That generalization comes from the fact that I'm dealing here, not with just the values of hidden variables.",
            "And in the world.",
            "But those variables in generalized coordinates of motions, so the state its motion is acceleration in its jerkan.",
            "So onto arbitrarily high order in terms of temporal derivatives, and that finesses a number of problems in terms of the numerics of doing the Bayesian filtering implied by this free energy minimization.",
            "And you can see that intuitively, for those of you familiar with common filtering, what we've basically got here is a.",
            "The rate of change of the updates of the conditional expectations of this recognition dense density map estimates of these causes maximum posteriori estimates here are mixture of the prediction.",
            "Plus a. Tim here, which one can associate, say, the Kalman gain times a prediction error here, and in fact these prediction errors have been weighted by their precisions in this hierarchal model.",
            "That's going to become important later on when we look at how uncertainty can be manipulated by changing the precision of these of these errors.",
            "So this is the sort of scheme that I'm assuming that the brain uses an.",
            "It just implements this Bayesian filtering.",
            "Generalized filtering here using or constructing online prediction errors in accordance with these equations here so that, for example, if we have some hypothesis about what caused these sensory data here, that hypothesis generates predictions there compared to the actual input.",
            "The generating prediction error that's passed forward.",
            "It's using this generalized filtering to optimize the predictions and the whole cycle continues.",
            "Until dictionaries have been minimized and this is occurring throughout every level of the hierarchy.",
            "So that the explanation for the sensory data has multiple levels of description empirical prize.",
            "If you like that are formally constrained by the hierarchal structure to give us an explanation at different levels of abstraction, that in principle should be Bayes optimal by virtue of minimizing this."
        ],
        [
            "Free energy.",
            "So in summary, biological agents resist the second law of thermodynamics.",
            "They must minimize their average surprise, namely entropy.",
            "They can minimize surprise by suppressing prediction error.",
            "In other words, free energy prediction error can be reduced by changing predictions, and we're going to associate that with perception or prediction.",
            "Error can be reduced by changing sensations, and we're going to associate that with action.",
            "Perception entails recurrent message passing the brain to optimize those predictions and importantly, for this talk, predictions depend upon the precision or inverse variance of the prediction errors, and those can be regarded as hyperparameters of our model that control the unknowns or the uncertainty in the quantity."
        ],
        [
            "Being estimated, so let me now move on to two examples.",
            "The first one is purely perceptual in nature and is being used to illustrate this generalized Bayesian filtering.",
            "Through minimizing free energy.",
            "And I'm going to try and illustrate what it's like to be uncertain about your inferences by lesioning a simulated model of a bird trying to recognize or decode a song produced by another bird, so to produce hallucinations or delusions.",
            "So I'm going to start with a simple example of perceptual categorization, just to show you how it works, and then we'll turn to more complicated hierarchical example that we can then lesion by cutting top down connections or lateral connections encoding those empirical prize that come from the hierarchical model I mentioned a few slides ago."
        ],
        [
            "The model of birdsong that I'm going to use.",
            "Is based upon a Lorentz attractor here that I'm assuming spans in for the higher vocal center of a bird, generating songs that are then going to be decoded or perceived by a listening bird.",
            "So I'm taking the two control parameters of Lorentz attractor.",
            "The parental rally numbers here to produce a particular attractive manifold, and then I'm borrowing two of the states of the rents, a tractor to modulate the.",
            "Amplitude and the frequency of sounds emitted by The Byrds voice box or syrinx here and I'm displaying those in terms of oscillogram here and I'll just play you an example.",
            "Of that this so you can hear what what it sounds like.",
            "So that's a little chirp.",
            "Little series of little chirps there that this simple rental tractor has generated.",
            "Notice that by changing the control parameters so I can change the shape of the attractor.",
            "And therefore change the category or the nature of this little chirp, so I can encode these extended.",
            "Sonogram dynamics in terms of just one point in some perceptual or categorical space song space, just in terms of V sub one and V sub two here.",
            "And when we generate well, I'll show you an example."
        ],
        [
            "In the second, let me just show you how that decoding works using the graphic or the message passing scheme that I illustrated earlier on.",
            "So here we have a very simple two level hierarchical model.",
            "The sonograma comes in here.",
            "It elicits prediction errors which drive the hidden states of the attractor here.",
            "Model thinks it knows the motion of the trajectory of those hidden states because it thinks it knows the two hidden causes that control the manifold upon which that the flow of hidden states is confined.",
            "Because these prediction errors tell it it's wrong, and then it optimizes its underlying map representation of those two control parameters based upon the flow which itself is being optimized by the prediction errors on what's actually being registered in terms of the.",
            "The motion of frequencies and amplitudes and this whole scheme continues for several 100 milliseconds until after about the third chirp.",
            "Here these two estimators converge on the true values, the true values being the Gray lines, the map estimators of conditional expectations being the blue and the green, and these being the 90% composing confidence intervals here until by about 100 milliseconds or 200 seconds it's got a fairly accurate.",
            "Perceptual categorization of what's caused this chirp and can predict what will happen over the next few 100 milliseconds."
        ],
        [
            "So what I've done here is created 3 songs by changing the values of those control parameters V1 and V2 here and then ask the bird to recognize and try to categorize these three songs which appear and that categorization, the product of that generalized filtering are shown here for songs AB&C and in this last time point or penultimate timeslice here.",
            "I've shown the estimators and the conditional competence here, showing that this particular bird is able to categorize correctly each of the three songs in the sense that the true values lie in the 90% confidence intervals.",
            "Do you want to see if you can categorize them?",
            "I'm sure you can, it's quite easy.",
            "With this waste of time, see if I can get the so this is song A.",
            "That song be.",
            "So those are the songs that, yeah, I'm sure you were able to categorize and and this machine bird was also able to categorize what I."
        ],
        [
            "To do now is use this sort of simulation just to illustrate uncertainty.",
            "When we deliberately use the wrong model to make the inference, and I'm going to create wrong models by lesioning.",
            "Formally, the form of the model by removing certain connections in this hierarchical model.",
            "But to make a hierarchal model I have to put another layer on top and the way that I'm doing that is by taking another Lorentz attractor.",
            "That is unfolding at an order of magnitude slower in terms of its motion and using two of the states of the high Order attractor as the control variables in the previous illustration.",
            "So now I have a sequence of chirps or a sequence of sequences that produce a song which brings us a little bit closer now to a more realistic birdsong, so the two control parameters we saw previously are these two here, but these are now.",
            "The states of a more slowly moving Lorenz attractor that now generates more complex and more appealing.",
            "Byrdsong so fucking display this which is.",
            "Not nice.",
            "And I'm sure there's there is a Lawrence bird in my garden because, yeah, once you've done this and you hear it, you know you can identify real birds will have a very similar.",
            "Call"
        ],
        [
            "Alright, so we took this synthetic bird song and then asked.",
            "A bird that had the correct model to filter that input and try to infer on all the states at all the hierarchal levels.",
            "So it has to not only track the frequency and amplitude modulation, but also the slow drifts in the tractor manifold as the song progresses and it goes into different phases of the song and different tempos.",
            "But we we did so here.",
            "With and without leaving the model.",
            "So here is the percept.",
            "If you remember the real input, you'll notice that it's dropped the first.",
            "The first few syllables of this particular song, but once it's cached, once it's found the trajectory, it can then fairly faithfully follow and predict and infer on the rest of the song, but it does require if you like some prediction errors in order to drive it onto the right trajectory within this manifold.",
            "What I'm what I've done here?",
            "Is basically removes.",
            "My policy is basically remove the.",
            "Structural priors by removing the topdown connections that give it an overall hierarchical structure and the percept that comes now.",
            "From this lesion bird.",
            "Is a failure or an hallucination that is not informed by the overall shape of projector, so it's lost the overall temporal structure in terms of its empirical prior expectations by virtue of the fact it cannot communicate the higher hierarchical level to the dynamics and that should be compared with the equivalent lesion where I'm removing the lateral connections in the model.",
            "That mediate the prediction errors about the motion in these generalized coordinates.",
            "So here what we get is a loss of the fine grain or fine scale, temporal structure and the following.",
            "Which is a very sick bird and you can imagine would completely fail to recognize its conspecifics, and presumably through evolutionary pressure, will become quickly extinct.",
            "So those are just two larger for your amusement illustrations of formal uncertainty that arrive arise from using inappropriate models of failure of inference or model space or uncertainty about the correct model."
        ],
        [
            "What I'm going to do now is conclude with a similar demonstration in action, but looking specifically those hyperparameters that control the precision or the certainty about representations of conditional estimators at different levels in a model."
        ],
        [
            "I'm again going to be using a tractor to drive these simulations, but the attractor here is like more design sort.",
            "It's based upon.",
            "Well, I'll come to the next slide, let me just over view for you.",
            "In the last few slides, what we're going to be dealing with, what I've got here is a fairly realistic.",
            "Biological model of queued reaching movements.",
            "So the idea here is I want to build an agent that sees various locations in its visual field.",
            "Become bright or become switched on, become salient and I want the agent to point to each of these cues in term.",
            "Furthermore, I want it to learn or to know, or to infer whether there is a particular sequence of cues that goes in a clockwise direction.",
            "And on big at certain points during the simulation I want to see how it responds to violations of that sequential higher order structure and whether it can recognize through this generalized Bayesian filtering whether the context or the order of these cues has changed.",
            "So I'm getting lots of things together here at abusive, fairly realistic synthetic experimental subject that I can perform e.g experiments on.",
            "I can do psychophysics, Aiken room.",
            "Measure reaction times accuracies and see how easy it is to confuse.",
            "And I did promise in my abstract that I would show you a confused.",
            "Bayesian agent at the end, and that will be my final slide.",
            "So how is this done?",
            "It's done using a very simple generative model.",
            "This generative model is again exactly like the birds, for example, based upon two attractors of exactly the same form.",
            "Those attractors actually have a stable heteroclinic channel, and I will explain what that means in the next slide.",
            "At the moment, we just need to know that essentially with cycle through a number of unstable fixed points in a fixed order.",
            "The first tractor goes very very slowly and provides the speed of cycling through the lower attractor here, which goes through four locations.",
            "This.",
            "Each of these abstract attractor points that I'm labeling as affordance here produces two sorts of predictions, three sorts of predictions.",
            "In fact it produces.",
            "Perceptive predictions about movements that are sent down to the spinal cord and then offer filled by action.",
            "So this is a reflex part.",
            "The suppression of free energy by action simply through suppressing sensory, motor, or proprioceptive or movement prediction errors through classical reflex arcs to minimize prediction error here.",
            "So these predictions actually enslave or drive movement so that the movements.",
            "Make come true, what the model predicted would happen and the model is predicting that when a light comes on, the finger is drawn by an invisible elastic band to each of these locations.",
            "But there are also predictions about the queues themselves.",
            "The brightness of these cues, the salience which one is going to be coming on, and also cues about what the agent expects to see happen to its arm.",
            "So not only does it feel it's on moving.",
            "It will expect to see it's are moving and if action is working properly.",
            "Of course that expectation will come true because both inference an action are trying to minimize prediction error or free energy.",
            "So what we should hopefully see is that when we set this attractor in motion, these queues should light up and the arm should point to each of the queues in succession I put.",
            "Press F elements.",
            "Picture up here because this particular model of movement is very similar to the equilibrium point hypothesis in motor control, where basically you prescribe where you want to be in terms of motor trajectory is just in terms of desired setpoint, and I'm using the same sort of notion here, but here the prescription is in terms of predictions, so I'm predicting my arm will be here and in doing that through the free energy formulation or minimization action will cause that to come true.",
            "Let me show you what's the sort of movements that we can listen with this model, so here.",
            "So this is the sort of behavior that is generated by this scheme.",
            "The trick that I've done here is slightly confound the agent by halfway through switching the order from clockwise.",
            "Now there's a switch to anticlockwise and at that point it thought it was going clockwise, but there are prediction errors here on the motion and generalized coordinates.",
            "The drive a switch in the higher level representation so that it is recognized.",
            "The context in which these cues are being presented and to which it should respond, has switched or reversed, so this is an example in psychology of set switching.",
            "A very trivial example, if you like of reversal learning, there's no learning.",
            "Here's all influence on States and the reason I've set this up is that I want to now illustrate what happens when we perturb."
        ],
        [
            "The precision of the information at various levels in this hierarchal model.",
            "We introduced deliberately uncertainty about one level of representation or map estimate in relation to another.",
            "Before I do that, let me just.",
            "Acknowledge Misha Rabinovich in terms of his contributions of these winners.",
            "This winless competition, in terms of stable heteroclinic channels that are just really a stereotyped set of orbits that link or connect unstable, fixed points that are attracting in One Direction and then expelling in another direction but crucially expelled to another fixed point that is attracting in that direction but excels in another relatively.",
            "Easy to set up with these equations of motion here and control.",
            "Their speeds are very versatile devices in terms of generating or prescribing itinerant or wandering trajectory's that have this stereotyped form where they're all competing to be high, but none of them can win because they've got built-in self destruct dynamics in these equations of motion here."
        ],
        [
            "So.",
            "What I'm going to do now is to take that model that I've just shown you, and deliberately.",
            "Deplete or suppress the precision?",
            "Of prediction errors encoded by these red units here at different levels in the model, and examine the responses.",
            "As an empirical or phenomenological?",
            "Study of how uncertainty in this sort of brain simulation would manifest.",
            "I'm going to start with prediction errors in the when I called here formally, the superior colliculus encoding the contrast, or the salience of the cues that are attracting the pointing movements.",
            "And when I do."
        ],
        [
            "Art.",
            "I'm and I progressively reduce the precision on these particular prediction errors.",
            "Here I see something that is characteristic of Parkinson's disease, and the reason that's important is that it may well be that the way in the brain that this precision, waiting or gating or modulation is encoded is through dopamine or dopaminergic.",
            "Neuromodulation of principle cells are reporting the prediction errors and passing this prediction here.",
            "Errors to high levels of the hierarchy and when I deplete.",
            "This proxy for doping or precision what we see is a failure of this sets, which is what I'm what I'm showing here.",
            "On the map, estimates of the higher level encoding the sequence order clockwise or not here and the associated projectors.",
            "And as I decrease the precision, there's a failure to recognize that the context has changed.",
            "The reversal has changed.",
            "You can see it takes 234 move trials before enough evidence has been accumulated in order to support the inference.",
            "That the order or the context has changed, and if I reduce the log precision by factor of two, then there's a complete failure too.",
            "Reverse the direction of inference about the direction.",
            "What we see here is a perturbation to the project."
        ],
        [
            "Which is more clearly shown on this slide and I want to try to illustrate here is that when everything is.",
            "Unfolding in a way that the agent thinks it should and infers it should, an is confident about where it should.",
            "It leads one target in exactly the right direction for the next one, but when it's confused about what the order of the context is, then the initial trajectory is in the wrong direction and then when sensory information arrives, there's a corrective movement that draws it back to the.",
            "The correct location.",
            "So just so you can see that in action.",
            "If I can find the.",
            "So here it everything's fine, and now the switch and you can see that there is things it's going to go to the next one in the clockwise direction, and then has to make a correction to that.",
            "So it's a bit confused, so this is a sub optimal inference that's been made suboptimal by virtue of reducing the precision of the."
        ],
        [
            "Information I won't go through this slide in detail, it's my second to last slide.",
            "I'm just making the point in this slide.",
            "That it's very it depends.",
            "In a very sensitive way.",
            "Sorry, the behavior of these sorts of simulations depend in a very sensitive way on where in the hierarchy you introduce these sorts of lesions and quantifying the behavior here in terms of reaction times as a function of the number of trials with the reversal occurring here as a function of either high levels of dopamine or precision from high to low, this one shows the failure of set switching here.",
            "And also an increase in reaction time or a slowing of the movements.",
            "But notice I get the opposite effect with an increase in the movements in terms of a decrease in reaction time if I lesion or decrease the precision at higher levels in the hierarchy, and that's entirely intuitive in that it's really the relative amount of confidence or certainty in low level representations relative to high level representations.",
            "That is the important quantity here something.",
            "Absolute precision, it's the.",
            "It's a relative precision so I can get this sort of complete reversal of behavioral abnormalities just depending upon whether I lesion the dopamine or precision at this level in terms of units encoding, prediction error, or Atlas level here.",
            "What would happen if I completely remove all the prediction errors?",
            "And what happens is that the agent enters a delusional state.",
            "Where it's completely impervious or insensitive to any sensory information because it has absolutely no precision, so it has the delusion.",
            "It knows exactly what is happening and will continue to behave and see what it thinks and expects to happen based upon its prior expectations."
        ],
        [
            "And you can see this here in terms of a persistent clockwise movement, despite the fact that in reality the queues are actually switching their direction halfway through, but the agent doesn't care, it just sees the next Q that expects to QC and carries on, and the final simulation is 1 where I've lesion not only the low level precision, but also the high level precision.",
            "So it's now got no idea.",
            "What the queues in the external world are delivering or.",
            "It has, it is very unconfident about the motion of its effector organs or the motion of visual dynamics.",
            "That's the last illustration, which I repeat, was the promise.",
            "Confused agent.",
            "So this is basically.",
            "A Bayes optimal agent under the free energy principle that's been made to be very, very confused, and with that I will close, thank you."
        ],
        [
            "Attention and also thank my collaborators and colleagues and many other people.",
            "Thank you.",
            "So that was discontinued.",
            "You say that living creatures must minimize entropy in order to survive, and they do this by minimizing free energy, which, because energy sponsors actually maximizing entropy, right?",
            "So the energy is an interest I'm talking about here purely information theoretic quantities, so.",
            "By virtue of the fact that the.",
            "By virtue of the fact that the free energy represents an upper bound on surprise and by virtue of the fact that the entropy is the time average of surprise by minimizing free energy, I'm implicitly minimizing surprise, which means that I'm implicitly minimizing the path integral, which which is the actual entropy that I'm interested in.",
            "So here it's the.",
            "It's the entropy of an infinite number of copies of me taking sensory samples at this point in time.",
            "400 garlic assumptions me sampling sensory states over infinite amount of time under the condition that I'm minimizing surprise at each point in time, right?",
            "It's not homeostasis that's happening.",
            "It's the opposite, right?",
            "Learning is the opposite of homeostasis.",
            "Well, you can actually generalize this principle to clue not just the hidden states.",
            "Of interest, the hidden states that I've been talking about.",
            "Sorry.",
            "Hidden states that I've been talking about.",
            "In this lecture, but also the parameters of the equations of motion.",
            "So the learning aspect would also fall very comfortably within this framework and would be motivated using exactly the same arguments that basically we have to resist the second law.",
            "I mean, that's what distinguishes us from our snowflake or a stone or a fire, is that we paradoxically tend to resist a natural tendency to disorder through minimizing.",
            "Our entropy, and in fact that generalized filtering really treats these parameters that are optimized with respect to free energy.",
            "That would be like the core of learning per say.",
            "It addresses that by treating them as well as.",
            "Time dependent states that change very, very slowly by putting prize on their motion.",
            "Basically the motion is zero.",
            "That's basically basically how that works.",
            "So it is actually should be all self consistent in principle.",
            "Something that you.",
            "And how things work, thanks.",
            "They don't believe it, and the reason why is analogous to kind of saying that the brain is trying to predict sensory inputs and trying to minimize the error.",
            "And I don't believe that because it seems like it's kind of competition, Sir, because the bandwidth of our country, it's just much higher than seems reasonable to try to predict, and in fact I think a lot of people talking to trouble because they try to just predict sensory inputs.",
            "And then there's no sort of folks with attention mechanism, and then they never get anything done.",
            "Right?",
            "Again.",
            "Yeah, I'll track.",
            "I am the question was that the bandwidth of this is my version of your question.",
            "The question was that the computational goal and just trying to predict sensory inputs is a little bit ridiculous because the bandwidth and their presumed dimensionality, the number of them is so enormous that it's.",
            "It's it's one, probably not computationally infeasible, and certainly suboptimal in relation to focusing on presumably a subspace of relevance, either through attentional.",
            "Mechanisms of you are psychologist, author, importance, weights.",
            "If you're a machine learning person, or some form of weighted least squares if you're you're decentralizing your data is that is that basically the question.",
            "Yep.",
            "Yeah, so in this framework that would be basically optimizing the precision hyperparameters.",
            "So this the weighting of the prediction errors actually provides those that importance weighting all that all that precision waiting.",
            "So there are papers out there where attentional paradigms such as a positive paradigm have been simulated using exactly these numerics, where here the precision is not mediated by dopamine.",
            "But by attentional gain on gating of sensory representations, so immediately that brings to mind the question.",
            "Well, how then does that attentional gating or that waiting that defining of the good subspace is?",
            "How is that optimized in relation to your prior expectations injected model?",
            "And that requires you then to have state dependent precision which requires you to generalize the equations of motion here such that the random fluctuations here now becomes state dependent.",
            "And that can be done quite trivially under this scheme.",
            "So you can generalize filtering scheme will handle state dependent precisions and will give you that sort of focusing of attention for you.",
            "Be more convinced now is still a bit sceptical.",
            "Do you want to think about it?",
            "Simulation.",
            "But now you're.",
            "Rod no, I would contend.",
            "I mean, I see the argument, but no.",
            "The nice thing about this is if you just build in state dependent precision into your generative model, you've just got one fairly simple generative model.",
            "It's just a very simple, very simple generalization of this where you just basically take these quantities in the brackets here and put them after the Omega as well.",
            "It's actually very simple, and I repeat the derivatives and the numerics and that generalized filtering.",
            "Actually fairly trivial is specially if you assume that.",
            "These can be parameterized in terms of log precisions.",
            "They actually fall out into very simple the recognition dynamics or the generalized filter in the common beauty light filtering just has a couple of extra terms which are actually very simple and biologically plausible, but, crucially, nothing has really changed.",
            "All you've said is the Omega becomes in the same way that these equations of motion here depends upon the states.",
            "These random fluctuations, depending on the space.",
            "Nothing's really changed.",
            "This is a more general.",
            "A more natural model to have.",
            "Question.",
            "Rock there are no goals or losses, so this optimization is of free energy, so there is no loss functions or rewards here, and I would appeal to the complete class theorems to replace loss functions with priors.",
            "So if you're more comfortable thinking about optimizing in a sort of Bayesian decision theory sense your expected loss.",
            "What you do here is you replace those with prior expectations.",
            "So if you remember, the action is basically there to minimize prediction errors or make predictions come true.",
            "Predictions have a likelihood part in a prior part, so you can bias the likelihood part to a greater or lesser extent by biasing the decisions by putting desired behaviors into the prior expectations.",
            "So instead of saying this is a rewarding state to be in, you simply say I expect to be in this state.",
            "A priority, and that's written down in terms of the equations of motion.",
            "So in a sense, those attractors basically define a subspace of all states.",
            "You could be in and generate all sensory states by the form of the equations of motion in the generative model and that subspace.",
            "You can think of as a rewarding place to be and the job of action is to get you there, because that's where you expect to be.",
            "It dispenses with loss functions and reward functions and replaces them with priors and I.",
            "What is the only thing which is rewarding here is as a removal of surprise.",
            "I'm not talking bout surprises you get with birthday presence which I'm talking about the sort of surprise when you put your hand in your pocket in your wallet's not there or you're walking down the street and you trip and fall over those unexpected.",
            "Oh my God, sort of surprises things you just did not predict and you gotta completely readjust on the basis of audio production are so from in terms of sort of comfortable rhetoric, I would say.",
            "Having those priors that that define what is surprising allow you then to recast reward's, avoiding of unrewarding surprising events.",
            "That's basically the story.",
            "And you define what is rewarding or unsurprising in terms of the prize.",
            "Where do they come from?",
            "Where they come from?",
            "The nature of what you are, the things that you like to, the States you like to be in the states you'll find surprising and you do not like to be in like being very cold or being very hungry or being too hot.",
            "We're thinking about that.",
            "Because.",
            "Missing light the light without any surprises.",
            "Yeah.",
            "There is.",
            "I mean, I think that's a sensitive question that there is a debate which has been going on for about two or three years now in philosophy.",
            "I thought about this and after several months they came to the same conclusion you came to.",
            "After several minutes that.",
            "That was a paradox that it's called the darkroom problem and that the darkroom problem means that if you're trying to minimize surprise or free energy through action and perception, then clearly the best place to be is in completely isolated dark room where you can predict exactly you're sensing absolutely nothing, and therefore you will be perpetually unsurprised and very, very happy and rewarded, that's.",
            "If you're dead, absolutely yes.",
            "Absolutely, that's the perfect as well.",
            "I don't like dead, because dead you tend to decompose and that your state space drifts over all sorts of phase transitions.",
            "I don't.",
            "I don't include dead in this, but if at the dark Room is actually a specious argument speech, it's plausable, but false, and it's easy to to counter on a number of different levels.",
            "And if you email me and please do, I can send you.",
            "Other short exchanges or very long detailed discussions about it.",
            "The very simple answer is we do not expect to be in a dark room.",
            "We expect our world to change.",
            "We are built to have these itinerant dynamics in terms of our priors so our loss functions and our rewards are intrinsically dynamic.",
            "They're not about getting the money, they are about the dynamics of the way that we live our lives.",
            "The way that we itinerantly wander from one source of nourishment to the next, one to the next, one to the next, one there about trajectory's that are encoded in our prior expectations that appeal to these empirical prize encoded by the form of the equations of motion.",
            "The central pattern generators in our brain that cause our movements and our plans, and indeed our career trajectory.",
            "Another way to think of it.",
            "Optimistic ways to say the best thing for us going forward is to have an accurate perception of the world.",
            "Yeah, yeah.",
            "And if you didn't have that, then clearly you're not going to be able to negotiate on navigate that world and you may well cross one of these phase transitions and be very surprised and die and decompose, or evaporate or explode.",
            "So the trick is to keep on that well trodden path.",
            "That is unsurprising and a sense that through the challenge I mean, you know for something that has to survive.",
            "Avoiding surprises is the only thing that is necessary, is not necessary to seek out rewards, it is just necessary not to get destroyed.",
            "That's that's.",
            "Active perception is a subgoal, it's not adult.",
            "Yeah, absolutely yeah, absolutely yeah.",
            "Yeah, I think that's absolutely right, so your mathematic Lee Ann geologically when you unpack all this, you suddenly see that perception is just in the service of providing good predictions for action.",
            "It is, there is nothing in the nothing in perception which will just change.",
            "Q will change surprise in and of itself because it doesn't.",
            "Surprise, if you remember, is the log evidence which is a function of the sensory data in the model.",
            "Changing Q does not change the model or the sensory data, so you does nothing for you.",
            "You really need it to induce or create the Ferengi bound that then allows action to do stuff to change, change S that changes the evidence, or the entropy.",
            "That's absolutely true.",
            "So almost paradoxically, perception becomes secondary an in the service of action in this particular formalism, absolutely essential.",
            "And, of course, there's a circular causality there, but.",
            "At the end of the day, operationally, it's the action that is the key thing in minimizing the.",
            "Beyond repair.",
            "I don't find satisfying.",
            "Surprise to kind of make sense.",
            "The buses, it seems in some sense that you're considering the brain as this thing floating and then trying to.",
            "It's a sensory.",
            "It's ridic things, but it has a buddy with it.",
            "And then there's some losses with the body remarkable survival.",
            "Very strong signal prediction.",
            "No, absolutely, and I think in a sense you know you're coming back to the concept about attention and and defining the subset of all sensory samples one could.",
            "One could actually take.",
            "One could actually look at evolution as putting by anatomical attentional constraints on the sampling, like we have eyes.",
            "You know that this sample and narrow range of wavelengths.",
            "Why?",
            "Well, through evolution through model selection, model optimization, then natural selection is found, the models that are internally consistent with the environment.",
            "That we have to predict.",
            "So I haven't spoken about about it here, but this whole story actually is this part of the same story in hierarchal setting.",
            "So you can use the free energy which is integrated over the lifetime of the model as a measure of the goodness of the model.",
            "And then you can do Bayesian model selection on the basis of the free energy.",
            "And that is the direct analogue of natural selection.",
            "So there will be through Bayesian model selection accord with the free energy minimum in accord with feeling minimalization.",
            "A progressive refinement and tuning a matching of the phenotype to the environment in which it is immersed which impart resolves your concerns about the plurality of all possible sensory states are called this sample.",
            "It is only those that are relevant for modeling and negotiating and navigating that particularly Cornish so much of the motivation here really comes from a selectionist thinking about how biological agents optimize their models, and once they've got their model, then how do we optimize the parameters?",
            "All the states of the infrastructure of that of that model in their particular cinematic lifetime.",
            "End up.",
            "Yeah.",
            "Maybe a dark balance?",
            "Yep.",
            "I don't think one could.",
            "At the moment, I'm purely theoretical terms.",
            "I think what you have to do is put if we were talking before about sort of learning.",
            "Think you had to put learning back in and optimize the parameters with respect to the free energy lesion and see how the model responded and then make empirical predictions about recovery, for example from stroke.",
            "So this is another domain of application here.",
            "Yep.",
            "Yep, Yep, I mean that actually it would be an easy experimental thing to do.",
            "You can actually include.",
            "Yes, I think to use this in a empirical neuroscience setting to use this style of thinking and modeling.",
            "As you probably all know, I think you would generate predictions about how real patients or subjects would respond adaptively given your hypothesis that about what is being optimized and in this instance it would be free energy.",
            "And you would allow all plausable optimization procedures to proceed, including re learning and also want to know one could in a neural developmental context introduced this notion of model optimization because the model is defined by which connections are present or absent.",
            "So it brings to the table the notion of neurogenesis, the the homeostasis of synaptic connections themselves.",
            "So during sleep so you can regard sleep really as a period of model optimization.",
            "Well, you're minimizing a complexity term of the free energy approximation to the log evidence, so all these implausible biologically plausible optimization processes.",
            "I think it would be including the model you leaving, the model, you see how it behaves following the lesion, and then made predictions that you would then look for in real subjects.",
            "I think that's the.",
            "Press.",
            "What's normal?",
            "Right, OK, that's a slightly deeper question.",
            "Clear from my point of view that the model and the state of any particular model and at any one time has a free energy.",
            "The best is the one with the lowest free energy, and it's a purely relativistic response.",
            "But you know, I can.",
            "I can.",
            "I can appeal either to evolutionary arguments or to inference argument, sort of optimal behavior.",
            "Arguments to say that it is best in that particular context.",
            "So there is only best relative to an alternative.",
            "There clearly is no.",
            "Canonical, a platonic good model, is just sufficient to minimize define the local minima when that particular model is immersed in that particular environment or that particular.",
            "Universal of sensory inputs.",
            "OK, let's thank all again."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "It's a great honor and pleasure to be here.",
                    "label": 0
                },
                {
                    "sent": "I'm always more flattered to be invited the more out of depth I feel an in this audience.",
                    "label": 1
                },
                {
                    "sent": "I do feel a little bit outside my normal comfort zone, so my background is in physics and psychology as a student.",
                    "label": 0
                },
                {
                    "sent": "But then I trained as a psychiatrist and neurologist, so the story that I'm going to tell today is more about applying.",
                    "label": 0
                },
                {
                    "sent": "Leave it up, yeah.",
                    "label": 0
                },
                {
                    "sent": "Is that better?",
                    "label": 0
                },
                {
                    "sent": "Can you hear?",
                    "label": 0
                },
                {
                    "sent": "No, should I stand by come closer?",
                    "label": 0
                },
                {
                    "sent": "Can you hear me now?",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Is that better?",
                    "label": 0
                },
                {
                    "sent": "No.",
                    "label": 0
                },
                {
                    "sent": "I could just point to all the key bits on the slides and ask you to read at the back that might be altered, or you could hear that Sir right in the back.",
                    "label": 0
                },
                {
                    "sent": "That's good.",
                    "label": 0
                },
                {
                    "sent": "That means it's working.",
                    "label": 0
                },
                {
                    "sent": "I was just saying I'm outside my comfort zone and by virtue of that I'm very flattered to be here.",
                    "label": 0
                },
                {
                    "sent": "I trained in psychology and physics, but for the past decades have been focusing on your apology.",
                    "label": 0
                },
                {
                    "sent": "So the story that I'm going to tell today is very much the application.",
                    "label": 0
                },
                {
                    "sent": "Of the idea, ideas that your community has brought to the table in trying to understand how the brain works.",
                    "label": 1
                },
                {
                    "sent": "So for those of you in machine learning.",
                    "label": 0
                },
                {
                    "sent": "What I'm going to be doing is assuming that the brain entails or is a generative model of its world and that it performs very simple Bayesian filtering on sensory inputs.",
                    "label": 0
                },
                {
                    "sent": "But there is a twist.",
                    "label": 0
                },
                {
                    "sent": "In addition to this Bayesian perspective on the brain as an inference machine, I'm going to assume that it is equipped with reflexes that enable it to sample data but also maximize the evidence or marginal likelihood associated with the model that is represented by the brain, and that's what I'm going to refer to as active inference.",
                    "label": 1
                },
                {
                    "sent": "So those two things together give a model for perception and action.",
                    "label": 1
                },
                {
                    "sent": "And I'm going to use that model to illustrate for you some of the issues of uncertainty in a perceptual and behavioral context, so that's that's.",
                    "label": 0
                },
                {
                    "sent": "A very brief overview of what I'm going to be talking about.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Would you like to do first?",
                    "label": 0
                },
                {
                    "sent": "There is just acknowledge the intellectual architects of all the ideas I'm going to be talking about.",
                    "label": 0
                },
                {
                    "sent": "You'll be familiar with many of these people, either historically or personally.",
                    "label": 0
                },
                {
                    "sent": "Much of what I'm going to say takes its lead from the notion of generative models as articulated by Helmholtz.",
                    "label": 0
                },
                {
                    "sent": "A nice quote up there, objects have to be in the field of vision.",
                    "label": 1
                },
                {
                    "sent": "They have to be there in order to produce the same impression on the nervous mechanism.",
                    "label": 1
                },
                {
                    "sent": "In other words, there is an explicit requirement.",
                    "label": 0
                },
                {
                    "sent": "Or a constructive generative approach to the perception that I'm going to formalize in terms of Bayesian filtering or modeling version along the lines suggested by Geoffrey Hinton and colleagues.",
                    "label": 0
                },
                {
                    "sent": "I'm going to use the free energy construct, but we heard about in the last presentation prior to the poster spotlights an and Furthermore, going to introduce some dynamical systems theory to to give the simulations and autonomy and itinerancy that is meant to represent behavior and uncertainty about that behavior.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So brief overview of the talk.",
                    "label": 0
                },
                {
                    "sent": "To motivate the importance of maximizing the marginal likelihood or the evidence, I'm going to take a.",
                    "label": 0
                },
                {
                    "sent": "An ensemble dynamics or population dynamics perspective and asks a very simple question about the nature of adaptive self organizing systems like the brain.",
                    "label": 0
                },
                {
                    "sent": "So I'm going to spend a bit of time trying to describe the motivation for the free energy minimization that we heard about earlier on today, and that's going to lead us to the free energy principle.",
                    "label": 0
                },
                {
                    "sent": "A lot of that rests upon generative models, and I'm going to briefly outline the sorts of models that we will assume the brain users to make sense of it.",
                    "label": 0
                },
                {
                    "sent": "Sensory input, and then the second half of the talk will be giving you two illustrative examples, one in the domain of perception and one in the domain of action.",
                    "label": 0
                },
                {
                    "sent": "And given the theme of this meeting, I'm going to try and emphasize uncertainty both in formal terms and in terms.",
                    "label": 0
                },
                {
                    "sent": "Of behavior and affordance.",
                    "label": 0
                },
                {
                    "sent": "So I know.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "To stop.",
                    "label": 0
                },
                {
                    "sent": "This sort of presentation by asking you to think about in simple terms.",
                    "label": 0
                },
                {
                    "sent": "What it is to be a self organizing system like the brain?",
                    "label": 0
                },
                {
                    "sent": "Specifically, what is the difference between a bird and a snowflake given that they are both open systems exchanging entropy and information and energy with the environment, they both have beautiful self similar self organized structure.",
                    "label": 1
                },
                {
                    "sent": "So what is the key difference that distinguishes between the behaving bird and the snowflake?",
                    "label": 0
                },
                {
                    "sent": "Any ideas?",
                    "label": 0
                },
                {
                    "sent": "The bird yeah yeah alright, you've got it.",
                    "label": 0
                },
                {
                    "sent": "So that's exactly it moves it behaves, and that's the only difference.",
                    "label": 0
                },
                {
                    "sent": "So in fact the answer was up there, but I'm sure you didn't cheat.",
                    "label": 0
                },
                {
                    "sent": "So a bird basically moves, alters its physical relationship with the environment, and from our perspective that basically means it is in control of the sensory streams that it's samples, and it's at one simple fact that I'm going to exploit when extending free energy minimization, not just to perceptual inference, but also to movement and behavior.",
                    "label": 0
                },
                {
                    "sent": "And with that one extension hopefully account for the sorts of behaviors that we observe in animate.",
                    "label": 0
                },
                {
                    "sent": "Systems like.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Sound.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Let me extend that question now and let's think about the difference between a population or ensemble of snowflakes snowfall and a flock of birds and trying to motivate the importance of maximizing the log marginal likelihood in terms of minimizing the entropy of the distribution.",
                    "label": 0
                },
                {
                    "sent": "The way that I want to do that is just to note that if a self organizing system like a bird.",
                    "label": 0
                },
                {
                    "sent": "Is going to injure over extended periods of time.",
                    "label": 0
                },
                {
                    "sent": "It has to avoid phase transitions in a whole variety of high dimensional state.",
                    "label": 0
                },
                {
                    "sent": "Space is phase spaces be the physiological or physical or behavioral?",
                    "label": 0
                },
                {
                    "sent": "In other words, it has to constrain or confine the states that it occupies to a limited domain of all the states it could occupy in order to remain categorizable as a bird.",
                    "label": 0
                },
                {
                    "sent": "Otherwise it would be a dead bird or.",
                    "label": 0
                },
                {
                    "sent": "Have an exploded bird or a bird that could not fly.",
                    "label": 0
                },
                {
                    "sent": "So the notion here is that basically biological agents stay in the same place.",
                    "label": 1
                },
                {
                    "sent": "In terms of statistical physics, they basically resist the second law of thermodynamics that says the entropy should.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Increase, but what is entropy?",
                    "label": 0
                },
                {
                    "sent": "Well, entropy is just the average surprisal and I'm going to call surprise or surprise here.",
                    "label": 0
                },
                {
                    "sent": "The negative log probability of some sensory data given a model of that sensory data that I'm denoting by censored S and a model here.",
                    "label": 0
                },
                {
                    "sent": "So this quantity here I'm going to refer to a surprise.",
                    "label": 0
                },
                {
                    "sent": "It's just the negative log marginal likelihood or the negative log evidence for a model given for.",
                    "label": 0
                },
                {
                    "sent": "In data for a particular model and other exotic assumptions, the long term time average of surprise is just the entropy of the sensory states under consideration.",
                    "label": 0
                },
                {
                    "sent": "And this nicely summarizes the requirement that self organizing systems that have to avoid phase transitions and remain in a small part of phase space should minimize their surprise.",
                    "label": 0
                },
                {
                    "sent": "In other words, they have to occupy a limited number of States and you can think of this quite simply as a homeostasis or generalization of the notion of homeostasis.",
                    "label": 1
                },
                {
                    "sent": "I should excuse or qualify why I've got Donald Duck here.",
                    "label": 0
                },
                {
                    "sent": "I had to give this talk to some schoolchildren in Berlin and they asked me to remove all the equations and replacing with Donald Duck.",
                    "label": 0
                },
                {
                    "sent": "But ever since then.",
                    "label": 0
                },
                {
                    "sent": "I found that the Donald Duck slides work much better than the ones with equations for grownups as well, so I'm going to use the Donald Duck with a few equations put back in again.",
                    "label": 0
                },
                {
                    "sent": "So basically this Donald Ducks in a state of high surprise.",
                    "label": 0
                },
                {
                    "sent": "He's not usually in this state.",
                    "label": 0
                },
                {
                    "sent": "He's hungry, is closed to demise and needs to find where his friends are to find the part of state space that he occupies that has a high ensemble density or a low surprise and will hopefully move there.",
                    "label": 0
                },
                {
                    "sent": "If you can minimize surprise by.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "But there's a problem.",
                    "label": 0
                },
                {
                    "sent": "Agents can't measure their surprise explicitly, and this is where the free energy comes in an hour.",
                    "label": 1
                },
                {
                    "sent": "Repeat it is being used here in exactly the same sense that either you or the people sitting next to you will use it in machine learning.",
                    "label": 0
                },
                {
                    "sent": "It's just a bound approximation or an upper bound on surprise that can be evaluated by an agent given its sensory signals that can be minimized, and implicitly therefore.",
                    "label": 0
                },
                {
                    "sent": "Minimizing surprises anyone point in time and therefore minimizing the long term time average or path integral which hundred consumptions will be the entropy?",
                    "label": 0
                },
                {
                    "sent": "So this means that agents are minimize their free energy, so what's free energy?",
                    "label": 1
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Many of you will know this, but let me just make for those who don't just make it very intuitive.",
                    "label": 0
                },
                {
                    "sent": "Essentially, under some simplifying assumptions it reduces to the prediction error.",
                    "label": 1
                },
                {
                    "sent": "The amplitude of the differences between sensory inputs and predictions optimized predictions of those inputs under the model that is entailed by.",
                    "label": 0
                },
                {
                    "sent": "In this instance the brain and that makes common sense in that having.",
                    "label": 0
                },
                {
                    "sent": "Very very small predictions means that you are not going to be surprised and surprise is perpetually minimized and you avoid these surprising exchanges with the world and hopefully avoid these phase transitions when you move too far away from the part of state space that you should use.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Be occupying.",
                    "label": 0
                },
                {
                    "sent": "So more formally than I have in mind here.",
                    "label": 0
                },
                {
                    "sent": "A universe that comprises internal states of the brain or quantity is owned by the brain that I'm summarizing here in terms of sufficient statistics of an arbitrary probability distribution density which will call the recognition density.",
                    "label": 0
                },
                {
                    "sent": "And action variables that the way that we move our effector organs are muscles.",
                    "label": 0
                },
                {
                    "sent": "Will cause a change in the sampling of sensory inputs that are generated through some dynamical process in the real world.",
                    "label": 0
                },
                {
                    "sent": "Here, the Theater Capitol Theater, here basically spammed in for all quantities in the real world that are hidden.",
                    "label": 0
                },
                {
                    "sent": "There hidden quantities that can be time dependent or fixed.",
                    "label": 0
                },
                {
                    "sent": "I refer to those as hidden States and hidden parameters subsequently so these evolve according to stochastic differential equation, they supply sensory inputs, which through a sensory nonlinear century mapping.",
                    "label": 0
                },
                {
                    "sent": "Here we had some sensory noise and these enter the system and then the internal states of the brain respond in some way, as do the action and the whole cycle is complete and the underlying idea here is that both the internal brain states.",
                    "label": 0
                },
                {
                    "sent": "Encoding this recognition density and action simply minimize free energy that is a function of the sensory impressions and the internal brain states.",
                    "label": 1
                },
                {
                    "sent": "Now these internal brain states are the sufficient statistics of Q.",
                    "label": 1
                },
                {
                    "sent": "This recognition density over the hidden unknown causes in the world and the free energy an it's called a free energy larger because it can be decomposed into an energy and entropy has this very simple form.",
                    "label": 0
                },
                {
                    "sent": "Here it's just the expected Gibbs energy here.",
                    "label": 0
                },
                {
                    "sent": "Under Q recognition density plus the negentropy of the recognition density Q itself.",
                    "label": 0
                },
                {
                    "sent": "Where the Gibbs energy is just the negative log joint probability of getting these data and their causes under the model in question, which you will be familiar with in terms of a mixture of log likelihood and and log prior there.",
                    "label": 0
                },
                {
                    "sent": "The reason I'm writing this out in full is largely too.",
                    "label": 1
                },
                {
                    "sent": "Emphasize the central role played by this Gibbs energy, or indeed one could understand this G are sending it for a generative model and implied by this joint distribution here.",
                    "label": 1
                },
                {
                    "sent": "So what sorts of models might the brain news and I'm going to take my lead here from your anatomy and in particular?",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The hierarchical organization of the brain and assume that the brain is using a hierarchal dynamical model of this form.",
                    "label": 0
                },
                {
                    "sent": "Here man, this is fairly simple in the sense that it's just a composition of continuous time state space models.",
                    "label": 0
                },
                {
                    "sent": "So for example, at the lowest part of the hierarchy we have sensory data here that are produced as a static mapping from some hidden states.",
                    "label": 0
                },
                {
                    "sent": "Here X.",
                    "label": 0
                },
                {
                    "sent": "Who that evolve?",
                    "label": 0
                },
                {
                    "sent": "Who have equations of motion parameterized by these parameters?",
                    "label": 0
                },
                {
                    "sent": "Here we had some random fluctuations whose precision inverse variance for amplitude is controlled by these variables.",
                    "label": 0
                },
                {
                    "sent": "Pi here and then we produce these sensory data here crucially.",
                    "label": 0
                },
                {
                    "sent": "The inputs, the exhaust, its inputs or perturbations to these hidden states are the outputs of another hierarchal or state space model.",
                    "label": 0
                },
                {
                    "sent": "And then we build that as high as we like.",
                    "label": 0
                },
                {
                    "sent": "So that's the underlying model.",
                    "label": 0
                },
                {
                    "sent": "I'm going to assume that the brain is using to explain or predict its sensory information and also prescribed action in terms of trying to minimize free energy or prediction error.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So again, very intuitively, for those people not in machine learning.",
                    "label": 0
                },
                {
                    "sent": "All that we've said here really is that the brain has an internal representation of the causes of its sensory input.",
                    "label": 0
                },
                {
                    "sent": "It delivers predictions of sensory input to low levels in the hierarchy.",
                    "label": 0
                },
                {
                    "sent": "It compares's predictions with what is actually being sampled to generate prediction errors that are then passed forward to adjust and optimize the estimates of the underlying causes.",
                    "label": 0
                },
                {
                    "sent": "And this reciprocal message passing persists until the free energy or the prediction errors have been minimized and one has a Bayes optimal explanation for the causes of the sensory information.",
                    "label": 0
                },
                {
                    "sent": "Essentially hierarchal message passing in the brain.",
                    "label": 1
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The form of this.",
                    "label": 0
                },
                {
                    "sent": "Actually, is almost identical to a common bucy filter.",
                    "label": 0
                },
                {
                    "sent": "It's a slightly slight generalization of the common BC filter an.",
                    "label": 0
                },
                {
                    "sent": "That generalization comes from the fact that I'm dealing here, not with just the values of hidden variables.",
                    "label": 0
                },
                {
                    "sent": "And in the world.",
                    "label": 0
                },
                {
                    "sent": "But those variables in generalized coordinates of motions, so the state its motion is acceleration in its jerkan.",
                    "label": 0
                },
                {
                    "sent": "So onto arbitrarily high order in terms of temporal derivatives, and that finesses a number of problems in terms of the numerics of doing the Bayesian filtering implied by this free energy minimization.",
                    "label": 0
                },
                {
                    "sent": "And you can see that intuitively, for those of you familiar with common filtering, what we've basically got here is a.",
                    "label": 0
                },
                {
                    "sent": "The rate of change of the updates of the conditional expectations of this recognition dense density map estimates of these causes maximum posteriori estimates here are mixture of the prediction.",
                    "label": 0
                },
                {
                    "sent": "Plus a. Tim here, which one can associate, say, the Kalman gain times a prediction error here, and in fact these prediction errors have been weighted by their precisions in this hierarchal model.",
                    "label": 0
                },
                {
                    "sent": "That's going to become important later on when we look at how uncertainty can be manipulated by changing the precision of these of these errors.",
                    "label": 0
                },
                {
                    "sent": "So this is the sort of scheme that I'm assuming that the brain uses an.",
                    "label": 0
                },
                {
                    "sent": "It just implements this Bayesian filtering.",
                    "label": 0
                },
                {
                    "sent": "Generalized filtering here using or constructing online prediction errors in accordance with these equations here so that, for example, if we have some hypothesis about what caused these sensory data here, that hypothesis generates predictions there compared to the actual input.",
                    "label": 0
                },
                {
                    "sent": "The generating prediction error that's passed forward.",
                    "label": 0
                },
                {
                    "sent": "It's using this generalized filtering to optimize the predictions and the whole cycle continues.",
                    "label": 0
                },
                {
                    "sent": "Until dictionaries have been minimized and this is occurring throughout every level of the hierarchy.",
                    "label": 0
                },
                {
                    "sent": "So that the explanation for the sensory data has multiple levels of description empirical prize.",
                    "label": 0
                },
                {
                    "sent": "If you like that are formally constrained by the hierarchal structure to give us an explanation at different levels of abstraction, that in principle should be Bayes optimal by virtue of minimizing this.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Free energy.",
                    "label": 0
                },
                {
                    "sent": "So in summary, biological agents resist the second law of thermodynamics.",
                    "label": 1
                },
                {
                    "sent": "They must minimize their average surprise, namely entropy.",
                    "label": 1
                },
                {
                    "sent": "They can minimize surprise by suppressing prediction error.",
                    "label": 0
                },
                {
                    "sent": "In other words, free energy prediction error can be reduced by changing predictions, and we're going to associate that with perception or prediction.",
                    "label": 0
                },
                {
                    "sent": "Error can be reduced by changing sensations, and we're going to associate that with action.",
                    "label": 0
                },
                {
                    "sent": "Perception entails recurrent message passing the brain to optimize those predictions and importantly, for this talk, predictions depend upon the precision or inverse variance of the prediction errors, and those can be regarded as hyperparameters of our model that control the unknowns or the uncertainty in the quantity.",
                    "label": 1
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Being estimated, so let me now move on to two examples.",
                    "label": 0
                },
                {
                    "sent": "The first one is purely perceptual in nature and is being used to illustrate this generalized Bayesian filtering.",
                    "label": 0
                },
                {
                    "sent": "Through minimizing free energy.",
                    "label": 0
                },
                {
                    "sent": "And I'm going to try and illustrate what it's like to be uncertain about your inferences by lesioning a simulated model of a bird trying to recognize or decode a song produced by another bird, so to produce hallucinations or delusions.",
                    "label": 0
                },
                {
                    "sent": "So I'm going to start with a simple example of perceptual categorization, just to show you how it works, and then we'll turn to more complicated hierarchical example that we can then lesion by cutting top down connections or lateral connections encoding those empirical prize that come from the hierarchical model I mentioned a few slides ago.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The model of birdsong that I'm going to use.",
                    "label": 0
                },
                {
                    "sent": "Is based upon a Lorentz attractor here that I'm assuming spans in for the higher vocal center of a bird, generating songs that are then going to be decoded or perceived by a listening bird.",
                    "label": 0
                },
                {
                    "sent": "So I'm taking the two control parameters of Lorentz attractor.",
                    "label": 0
                },
                {
                    "sent": "The parental rally numbers here to produce a particular attractive manifold, and then I'm borrowing two of the states of the rents, a tractor to modulate the.",
                    "label": 0
                },
                {
                    "sent": "Amplitude and the frequency of sounds emitted by The Byrds voice box or syrinx here and I'm displaying those in terms of oscillogram here and I'll just play you an example.",
                    "label": 0
                },
                {
                    "sent": "Of that this so you can hear what what it sounds like.",
                    "label": 0
                },
                {
                    "sent": "So that's a little chirp.",
                    "label": 0
                },
                {
                    "sent": "Little series of little chirps there that this simple rental tractor has generated.",
                    "label": 0
                },
                {
                    "sent": "Notice that by changing the control parameters so I can change the shape of the attractor.",
                    "label": 0
                },
                {
                    "sent": "And therefore change the category or the nature of this little chirp, so I can encode these extended.",
                    "label": 0
                },
                {
                    "sent": "Sonogram dynamics in terms of just one point in some perceptual or categorical space song space, just in terms of V sub one and V sub two here.",
                    "label": 0
                },
                {
                    "sent": "And when we generate well, I'll show you an example.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In the second, let me just show you how that decoding works using the graphic or the message passing scheme that I illustrated earlier on.",
                    "label": 0
                },
                {
                    "sent": "So here we have a very simple two level hierarchical model.",
                    "label": 0
                },
                {
                    "sent": "The sonograma comes in here.",
                    "label": 0
                },
                {
                    "sent": "It elicits prediction errors which drive the hidden states of the attractor here.",
                    "label": 0
                },
                {
                    "sent": "Model thinks it knows the motion of the trajectory of those hidden states because it thinks it knows the two hidden causes that control the manifold upon which that the flow of hidden states is confined.",
                    "label": 0
                },
                {
                    "sent": "Because these prediction errors tell it it's wrong, and then it optimizes its underlying map representation of those two control parameters based upon the flow which itself is being optimized by the prediction errors on what's actually being registered in terms of the.",
                    "label": 0
                },
                {
                    "sent": "The motion of frequencies and amplitudes and this whole scheme continues for several 100 milliseconds until after about the third chirp.",
                    "label": 0
                },
                {
                    "sent": "Here these two estimators converge on the true values, the true values being the Gray lines, the map estimators of conditional expectations being the blue and the green, and these being the 90% composing confidence intervals here until by about 100 milliseconds or 200 seconds it's got a fairly accurate.",
                    "label": 0
                },
                {
                    "sent": "Perceptual categorization of what's caused this chirp and can predict what will happen over the next few 100 milliseconds.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So what I've done here is created 3 songs by changing the values of those control parameters V1 and V2 here and then ask the bird to recognize and try to categorize these three songs which appear and that categorization, the product of that generalized filtering are shown here for songs AB&C and in this last time point or penultimate timeslice here.",
                    "label": 0
                },
                {
                    "sent": "I've shown the estimators and the conditional competence here, showing that this particular bird is able to categorize correctly each of the three songs in the sense that the true values lie in the 90% confidence intervals.",
                    "label": 0
                },
                {
                    "sent": "Do you want to see if you can categorize them?",
                    "label": 0
                },
                {
                    "sent": "I'm sure you can, it's quite easy.",
                    "label": 0
                },
                {
                    "sent": "With this waste of time, see if I can get the so this is song A.",
                    "label": 1
                },
                {
                    "sent": "That song be.",
                    "label": 0
                },
                {
                    "sent": "So those are the songs that, yeah, I'm sure you were able to categorize and and this machine bird was also able to categorize what I.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To do now is use this sort of simulation just to illustrate uncertainty.",
                    "label": 0
                },
                {
                    "sent": "When we deliberately use the wrong model to make the inference, and I'm going to create wrong models by lesioning.",
                    "label": 0
                },
                {
                    "sent": "Formally, the form of the model by removing certain connections in this hierarchical model.",
                    "label": 0
                },
                {
                    "sent": "But to make a hierarchal model I have to put another layer on top and the way that I'm doing that is by taking another Lorentz attractor.",
                    "label": 0
                },
                {
                    "sent": "That is unfolding at an order of magnitude slower in terms of its motion and using two of the states of the high Order attractor as the control variables in the previous illustration.",
                    "label": 0
                },
                {
                    "sent": "So now I have a sequence of chirps or a sequence of sequences that produce a song which brings us a little bit closer now to a more realistic birdsong, so the two control parameters we saw previously are these two here, but these are now.",
                    "label": 0
                },
                {
                    "sent": "The states of a more slowly moving Lorenz attractor that now generates more complex and more appealing.",
                    "label": 0
                },
                {
                    "sent": "Byrdsong so fucking display this which is.",
                    "label": 0
                },
                {
                    "sent": "Not nice.",
                    "label": 0
                },
                {
                    "sent": "And I'm sure there's there is a Lawrence bird in my garden because, yeah, once you've done this and you hear it, you know you can identify real birds will have a very similar.",
                    "label": 0
                },
                {
                    "sent": "Call",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Alright, so we took this synthetic bird song and then asked.",
                    "label": 0
                },
                {
                    "sent": "A bird that had the correct model to filter that input and try to infer on all the states at all the hierarchal levels.",
                    "label": 0
                },
                {
                    "sent": "So it has to not only track the frequency and amplitude modulation, but also the slow drifts in the tractor manifold as the song progresses and it goes into different phases of the song and different tempos.",
                    "label": 0
                },
                {
                    "sent": "But we we did so here.",
                    "label": 0
                },
                {
                    "sent": "With and without leaving the model.",
                    "label": 0
                },
                {
                    "sent": "So here is the percept.",
                    "label": 0
                },
                {
                    "sent": "If you remember the real input, you'll notice that it's dropped the first.",
                    "label": 0
                },
                {
                    "sent": "The first few syllables of this particular song, but once it's cached, once it's found the trajectory, it can then fairly faithfully follow and predict and infer on the rest of the song, but it does require if you like some prediction errors in order to drive it onto the right trajectory within this manifold.",
                    "label": 0
                },
                {
                    "sent": "What I'm what I've done here?",
                    "label": 0
                },
                {
                    "sent": "Is basically removes.",
                    "label": 0
                },
                {
                    "sent": "My policy is basically remove the.",
                    "label": 0
                },
                {
                    "sent": "Structural priors by removing the topdown connections that give it an overall hierarchical structure and the percept that comes now.",
                    "label": 0
                },
                {
                    "sent": "From this lesion bird.",
                    "label": 0
                },
                {
                    "sent": "Is a failure or an hallucination that is not informed by the overall shape of projector, so it's lost the overall temporal structure in terms of its empirical prior expectations by virtue of the fact it cannot communicate the higher hierarchical level to the dynamics and that should be compared with the equivalent lesion where I'm removing the lateral connections in the model.",
                    "label": 0
                },
                {
                    "sent": "That mediate the prediction errors about the motion in these generalized coordinates.",
                    "label": 0
                },
                {
                    "sent": "So here what we get is a loss of the fine grain or fine scale, temporal structure and the following.",
                    "label": 0
                },
                {
                    "sent": "Which is a very sick bird and you can imagine would completely fail to recognize its conspecifics, and presumably through evolutionary pressure, will become quickly extinct.",
                    "label": 0
                },
                {
                    "sent": "So those are just two larger for your amusement illustrations of formal uncertainty that arrive arise from using inappropriate models of failure of inference or model space or uncertainty about the correct model.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "What I'm going to do now is conclude with a similar demonstration in action, but looking specifically those hyperparameters that control the precision or the certainty about representations of conditional estimators at different levels in a model.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I'm again going to be using a tractor to drive these simulations, but the attractor here is like more design sort.",
                    "label": 0
                },
                {
                    "sent": "It's based upon.",
                    "label": 0
                },
                {
                    "sent": "Well, I'll come to the next slide, let me just over view for you.",
                    "label": 0
                },
                {
                    "sent": "In the last few slides, what we're going to be dealing with, what I've got here is a fairly realistic.",
                    "label": 0
                },
                {
                    "sent": "Biological model of queued reaching movements.",
                    "label": 0
                },
                {
                    "sent": "So the idea here is I want to build an agent that sees various locations in its visual field.",
                    "label": 0
                },
                {
                    "sent": "Become bright or become switched on, become salient and I want the agent to point to each of these cues in term.",
                    "label": 0
                },
                {
                    "sent": "Furthermore, I want it to learn or to know, or to infer whether there is a particular sequence of cues that goes in a clockwise direction.",
                    "label": 0
                },
                {
                    "sent": "And on big at certain points during the simulation I want to see how it responds to violations of that sequential higher order structure and whether it can recognize through this generalized Bayesian filtering whether the context or the order of these cues has changed.",
                    "label": 0
                },
                {
                    "sent": "So I'm getting lots of things together here at abusive, fairly realistic synthetic experimental subject that I can perform e.g experiments on.",
                    "label": 0
                },
                {
                    "sent": "I can do psychophysics, Aiken room.",
                    "label": 0
                },
                {
                    "sent": "Measure reaction times accuracies and see how easy it is to confuse.",
                    "label": 0
                },
                {
                    "sent": "And I did promise in my abstract that I would show you a confused.",
                    "label": 0
                },
                {
                    "sent": "Bayesian agent at the end, and that will be my final slide.",
                    "label": 0
                },
                {
                    "sent": "So how is this done?",
                    "label": 0
                },
                {
                    "sent": "It's done using a very simple generative model.",
                    "label": 0
                },
                {
                    "sent": "This generative model is again exactly like the birds, for example, based upon two attractors of exactly the same form.",
                    "label": 0
                },
                {
                    "sent": "Those attractors actually have a stable heteroclinic channel, and I will explain what that means in the next slide.",
                    "label": 0
                },
                {
                    "sent": "At the moment, we just need to know that essentially with cycle through a number of unstable fixed points in a fixed order.",
                    "label": 0
                },
                {
                    "sent": "The first tractor goes very very slowly and provides the speed of cycling through the lower attractor here, which goes through four locations.",
                    "label": 0
                },
                {
                    "sent": "This.",
                    "label": 0
                },
                {
                    "sent": "Each of these abstract attractor points that I'm labeling as affordance here produces two sorts of predictions, three sorts of predictions.",
                    "label": 0
                },
                {
                    "sent": "In fact it produces.",
                    "label": 0
                },
                {
                    "sent": "Perceptive predictions about movements that are sent down to the spinal cord and then offer filled by action.",
                    "label": 0
                },
                {
                    "sent": "So this is a reflex part.",
                    "label": 0
                },
                {
                    "sent": "The suppression of free energy by action simply through suppressing sensory, motor, or proprioceptive or movement prediction errors through classical reflex arcs to minimize prediction error here.",
                    "label": 0
                },
                {
                    "sent": "So these predictions actually enslave or drive movement so that the movements.",
                    "label": 0
                },
                {
                    "sent": "Make come true, what the model predicted would happen and the model is predicting that when a light comes on, the finger is drawn by an invisible elastic band to each of these locations.",
                    "label": 0
                },
                {
                    "sent": "But there are also predictions about the queues themselves.",
                    "label": 0
                },
                {
                    "sent": "The brightness of these cues, the salience which one is going to be coming on, and also cues about what the agent expects to see happen to its arm.",
                    "label": 0
                },
                {
                    "sent": "So not only does it feel it's on moving.",
                    "label": 0
                },
                {
                    "sent": "It will expect to see it's are moving and if action is working properly.",
                    "label": 0
                },
                {
                    "sent": "Of course that expectation will come true because both inference an action are trying to minimize prediction error or free energy.",
                    "label": 0
                },
                {
                    "sent": "So what we should hopefully see is that when we set this attractor in motion, these queues should light up and the arm should point to each of the queues in succession I put.",
                    "label": 0
                },
                {
                    "sent": "Press F elements.",
                    "label": 0
                },
                {
                    "sent": "Picture up here because this particular model of movement is very similar to the equilibrium point hypothesis in motor control, where basically you prescribe where you want to be in terms of motor trajectory is just in terms of desired setpoint, and I'm using the same sort of notion here, but here the prescription is in terms of predictions, so I'm predicting my arm will be here and in doing that through the free energy formulation or minimization action will cause that to come true.",
                    "label": 0
                },
                {
                    "sent": "Let me show you what's the sort of movements that we can listen with this model, so here.",
                    "label": 0
                },
                {
                    "sent": "So this is the sort of behavior that is generated by this scheme.",
                    "label": 0
                },
                {
                    "sent": "The trick that I've done here is slightly confound the agent by halfway through switching the order from clockwise.",
                    "label": 0
                },
                {
                    "sent": "Now there's a switch to anticlockwise and at that point it thought it was going clockwise, but there are prediction errors here on the motion and generalized coordinates.",
                    "label": 0
                },
                {
                    "sent": "The drive a switch in the higher level representation so that it is recognized.",
                    "label": 0
                },
                {
                    "sent": "The context in which these cues are being presented and to which it should respond, has switched or reversed, so this is an example in psychology of set switching.",
                    "label": 0
                },
                {
                    "sent": "A very trivial example, if you like of reversal learning, there's no learning.",
                    "label": 0
                },
                {
                    "sent": "Here's all influence on States and the reason I've set this up is that I want to now illustrate what happens when we perturb.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The precision of the information at various levels in this hierarchal model.",
                    "label": 0
                },
                {
                    "sent": "We introduced deliberately uncertainty about one level of representation or map estimate in relation to another.",
                    "label": 0
                },
                {
                    "sent": "Before I do that, let me just.",
                    "label": 0
                },
                {
                    "sent": "Acknowledge Misha Rabinovich in terms of his contributions of these winners.",
                    "label": 0
                },
                {
                    "sent": "This winless competition, in terms of stable heteroclinic channels that are just really a stereotyped set of orbits that link or connect unstable, fixed points that are attracting in One Direction and then expelling in another direction but crucially expelled to another fixed point that is attracting in that direction but excels in another relatively.",
                    "label": 0
                },
                {
                    "sent": "Easy to set up with these equations of motion here and control.",
                    "label": 0
                },
                {
                    "sent": "Their speeds are very versatile devices in terms of generating or prescribing itinerant or wandering trajectory's that have this stereotyped form where they're all competing to be high, but none of them can win because they've got built-in self destruct dynamics in these equations of motion here.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "What I'm going to do now is to take that model that I've just shown you, and deliberately.",
                    "label": 0
                },
                {
                    "sent": "Deplete or suppress the precision?",
                    "label": 0
                },
                {
                    "sent": "Of prediction errors encoded by these red units here at different levels in the model, and examine the responses.",
                    "label": 0
                },
                {
                    "sent": "As an empirical or phenomenological?",
                    "label": 0
                },
                {
                    "sent": "Study of how uncertainty in this sort of brain simulation would manifest.",
                    "label": 0
                },
                {
                    "sent": "I'm going to start with prediction errors in the when I called here formally, the superior colliculus encoding the contrast, or the salience of the cues that are attracting the pointing movements.",
                    "label": 0
                },
                {
                    "sent": "And when I do.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Art.",
                    "label": 0
                },
                {
                    "sent": "I'm and I progressively reduce the precision on these particular prediction errors.",
                    "label": 0
                },
                {
                    "sent": "Here I see something that is characteristic of Parkinson's disease, and the reason that's important is that it may well be that the way in the brain that this precision, waiting or gating or modulation is encoded is through dopamine or dopaminergic.",
                    "label": 0
                },
                {
                    "sent": "Neuromodulation of principle cells are reporting the prediction errors and passing this prediction here.",
                    "label": 0
                },
                {
                    "sent": "Errors to high levels of the hierarchy and when I deplete.",
                    "label": 0
                },
                {
                    "sent": "This proxy for doping or precision what we see is a failure of this sets, which is what I'm what I'm showing here.",
                    "label": 0
                },
                {
                    "sent": "On the map, estimates of the higher level encoding the sequence order clockwise or not here and the associated projectors.",
                    "label": 0
                },
                {
                    "sent": "And as I decrease the precision, there's a failure to recognize that the context has changed.",
                    "label": 0
                },
                {
                    "sent": "The reversal has changed.",
                    "label": 0
                },
                {
                    "sent": "You can see it takes 234 move trials before enough evidence has been accumulated in order to support the inference.",
                    "label": 0
                },
                {
                    "sent": "That the order or the context has changed, and if I reduce the log precision by factor of two, then there's a complete failure too.",
                    "label": 0
                },
                {
                    "sent": "Reverse the direction of inference about the direction.",
                    "label": 0
                },
                {
                    "sent": "What we see here is a perturbation to the project.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Which is more clearly shown on this slide and I want to try to illustrate here is that when everything is.",
                    "label": 0
                },
                {
                    "sent": "Unfolding in a way that the agent thinks it should and infers it should, an is confident about where it should.",
                    "label": 0
                },
                {
                    "sent": "It leads one target in exactly the right direction for the next one, but when it's confused about what the order of the context is, then the initial trajectory is in the wrong direction and then when sensory information arrives, there's a corrective movement that draws it back to the.",
                    "label": 0
                },
                {
                    "sent": "The correct location.",
                    "label": 0
                },
                {
                    "sent": "So just so you can see that in action.",
                    "label": 0
                },
                {
                    "sent": "If I can find the.",
                    "label": 0
                },
                {
                    "sent": "So here it everything's fine, and now the switch and you can see that there is things it's going to go to the next one in the clockwise direction, and then has to make a correction to that.",
                    "label": 0
                },
                {
                    "sent": "So it's a bit confused, so this is a sub optimal inference that's been made suboptimal by virtue of reducing the precision of the.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Information I won't go through this slide in detail, it's my second to last slide.",
                    "label": 0
                },
                {
                    "sent": "I'm just making the point in this slide.",
                    "label": 0
                },
                {
                    "sent": "That it's very it depends.",
                    "label": 0
                },
                {
                    "sent": "In a very sensitive way.",
                    "label": 0
                },
                {
                    "sent": "Sorry, the behavior of these sorts of simulations depend in a very sensitive way on where in the hierarchy you introduce these sorts of lesions and quantifying the behavior here in terms of reaction times as a function of the number of trials with the reversal occurring here as a function of either high levels of dopamine or precision from high to low, this one shows the failure of set switching here.",
                    "label": 0
                },
                {
                    "sent": "And also an increase in reaction time or a slowing of the movements.",
                    "label": 0
                },
                {
                    "sent": "But notice I get the opposite effect with an increase in the movements in terms of a decrease in reaction time if I lesion or decrease the precision at higher levels in the hierarchy, and that's entirely intuitive in that it's really the relative amount of confidence or certainty in low level representations relative to high level representations.",
                    "label": 0
                },
                {
                    "sent": "That is the important quantity here something.",
                    "label": 0
                },
                {
                    "sent": "Absolute precision, it's the.",
                    "label": 0
                },
                {
                    "sent": "It's a relative precision so I can get this sort of complete reversal of behavioral abnormalities just depending upon whether I lesion the dopamine or precision at this level in terms of units encoding, prediction error, or Atlas level here.",
                    "label": 0
                },
                {
                    "sent": "What would happen if I completely remove all the prediction errors?",
                    "label": 0
                },
                {
                    "sent": "And what happens is that the agent enters a delusional state.",
                    "label": 0
                },
                {
                    "sent": "Where it's completely impervious or insensitive to any sensory information because it has absolutely no precision, so it has the delusion.",
                    "label": 0
                },
                {
                    "sent": "It knows exactly what is happening and will continue to behave and see what it thinks and expects to happen based upon its prior expectations.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And you can see this here in terms of a persistent clockwise movement, despite the fact that in reality the queues are actually switching their direction halfway through, but the agent doesn't care, it just sees the next Q that expects to QC and carries on, and the final simulation is 1 where I've lesion not only the low level precision, but also the high level precision.",
                    "label": 0
                },
                {
                    "sent": "So it's now got no idea.",
                    "label": 0
                },
                {
                    "sent": "What the queues in the external world are delivering or.",
                    "label": 0
                },
                {
                    "sent": "It has, it is very unconfident about the motion of its effector organs or the motion of visual dynamics.",
                    "label": 0
                },
                {
                    "sent": "That's the last illustration, which I repeat, was the promise.",
                    "label": 0
                },
                {
                    "sent": "Confused agent.",
                    "label": 0
                },
                {
                    "sent": "So this is basically.",
                    "label": 0
                },
                {
                    "sent": "A Bayes optimal agent under the free energy principle that's been made to be very, very confused, and with that I will close, thank you.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Attention and also thank my collaborators and colleagues and many other people.",
                    "label": 1
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                },
                {
                    "sent": "So that was discontinued.",
                    "label": 0
                },
                {
                    "sent": "You say that living creatures must minimize entropy in order to survive, and they do this by minimizing free energy, which, because energy sponsors actually maximizing entropy, right?",
                    "label": 0
                },
                {
                    "sent": "So the energy is an interest I'm talking about here purely information theoretic quantities, so.",
                    "label": 0
                },
                {
                    "sent": "By virtue of the fact that the.",
                    "label": 0
                },
                {
                    "sent": "By virtue of the fact that the free energy represents an upper bound on surprise and by virtue of the fact that the entropy is the time average of surprise by minimizing free energy, I'm implicitly minimizing surprise, which means that I'm implicitly minimizing the path integral, which which is the actual entropy that I'm interested in.",
                    "label": 0
                },
                {
                    "sent": "So here it's the.",
                    "label": 0
                },
                {
                    "sent": "It's the entropy of an infinite number of copies of me taking sensory samples at this point in time.",
                    "label": 0
                },
                {
                    "sent": "400 garlic assumptions me sampling sensory states over infinite amount of time under the condition that I'm minimizing surprise at each point in time, right?",
                    "label": 0
                },
                {
                    "sent": "It's not homeostasis that's happening.",
                    "label": 0
                },
                {
                    "sent": "It's the opposite, right?",
                    "label": 0
                },
                {
                    "sent": "Learning is the opposite of homeostasis.",
                    "label": 0
                },
                {
                    "sent": "Well, you can actually generalize this principle to clue not just the hidden states.",
                    "label": 0
                },
                {
                    "sent": "Of interest, the hidden states that I've been talking about.",
                    "label": 0
                },
                {
                    "sent": "Sorry.",
                    "label": 0
                },
                {
                    "sent": "Hidden states that I've been talking about.",
                    "label": 0
                },
                {
                    "sent": "In this lecture, but also the parameters of the equations of motion.",
                    "label": 0
                },
                {
                    "sent": "So the learning aspect would also fall very comfortably within this framework and would be motivated using exactly the same arguments that basically we have to resist the second law.",
                    "label": 0
                },
                {
                    "sent": "I mean, that's what distinguishes us from our snowflake or a stone or a fire, is that we paradoxically tend to resist a natural tendency to disorder through minimizing.",
                    "label": 0
                },
                {
                    "sent": "Our entropy, and in fact that generalized filtering really treats these parameters that are optimized with respect to free energy.",
                    "label": 0
                },
                {
                    "sent": "That would be like the core of learning per say.",
                    "label": 0
                },
                {
                    "sent": "It addresses that by treating them as well as.",
                    "label": 0
                },
                {
                    "sent": "Time dependent states that change very, very slowly by putting prize on their motion.",
                    "label": 0
                },
                {
                    "sent": "Basically the motion is zero.",
                    "label": 0
                },
                {
                    "sent": "That's basically basically how that works.",
                    "label": 0
                },
                {
                    "sent": "So it is actually should be all self consistent in principle.",
                    "label": 0
                },
                {
                    "sent": "Something that you.",
                    "label": 0
                },
                {
                    "sent": "And how things work, thanks.",
                    "label": 0
                },
                {
                    "sent": "They don't believe it, and the reason why is analogous to kind of saying that the brain is trying to predict sensory inputs and trying to minimize the error.",
                    "label": 0
                },
                {
                    "sent": "And I don't believe that because it seems like it's kind of competition, Sir, because the bandwidth of our country, it's just much higher than seems reasonable to try to predict, and in fact I think a lot of people talking to trouble because they try to just predict sensory inputs.",
                    "label": 0
                },
                {
                    "sent": "And then there's no sort of folks with attention mechanism, and then they never get anything done.",
                    "label": 0
                },
                {
                    "sent": "Right?",
                    "label": 0
                },
                {
                    "sent": "Again.",
                    "label": 0
                },
                {
                    "sent": "Yeah, I'll track.",
                    "label": 0
                },
                {
                    "sent": "I am the question was that the bandwidth of this is my version of your question.",
                    "label": 0
                },
                {
                    "sent": "The question was that the computational goal and just trying to predict sensory inputs is a little bit ridiculous because the bandwidth and their presumed dimensionality, the number of them is so enormous that it's.",
                    "label": 0
                },
                {
                    "sent": "It's it's one, probably not computationally infeasible, and certainly suboptimal in relation to focusing on presumably a subspace of relevance, either through attentional.",
                    "label": 0
                },
                {
                    "sent": "Mechanisms of you are psychologist, author, importance, weights.",
                    "label": 0
                },
                {
                    "sent": "If you're a machine learning person, or some form of weighted least squares if you're you're decentralizing your data is that is that basically the question.",
                    "label": 0
                },
                {
                    "sent": "Yep.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so in this framework that would be basically optimizing the precision hyperparameters.",
                    "label": 0
                },
                {
                    "sent": "So this the weighting of the prediction errors actually provides those that importance weighting all that all that precision waiting.",
                    "label": 0
                },
                {
                    "sent": "So there are papers out there where attentional paradigms such as a positive paradigm have been simulated using exactly these numerics, where here the precision is not mediated by dopamine.",
                    "label": 0
                },
                {
                    "sent": "But by attentional gain on gating of sensory representations, so immediately that brings to mind the question.",
                    "label": 0
                },
                {
                    "sent": "Well, how then does that attentional gating or that waiting that defining of the good subspace is?",
                    "label": 0
                },
                {
                    "sent": "How is that optimized in relation to your prior expectations injected model?",
                    "label": 0
                },
                {
                    "sent": "And that requires you then to have state dependent precision which requires you to generalize the equations of motion here such that the random fluctuations here now becomes state dependent.",
                    "label": 0
                },
                {
                    "sent": "And that can be done quite trivially under this scheme.",
                    "label": 0
                },
                {
                    "sent": "So you can generalize filtering scheme will handle state dependent precisions and will give you that sort of focusing of attention for you.",
                    "label": 0
                },
                {
                    "sent": "Be more convinced now is still a bit sceptical.",
                    "label": 0
                },
                {
                    "sent": "Do you want to think about it?",
                    "label": 0
                },
                {
                    "sent": "Simulation.",
                    "label": 0
                },
                {
                    "sent": "But now you're.",
                    "label": 0
                },
                {
                    "sent": "Rod no, I would contend.",
                    "label": 0
                },
                {
                    "sent": "I mean, I see the argument, but no.",
                    "label": 0
                },
                {
                    "sent": "The nice thing about this is if you just build in state dependent precision into your generative model, you've just got one fairly simple generative model.",
                    "label": 0
                },
                {
                    "sent": "It's just a very simple, very simple generalization of this where you just basically take these quantities in the brackets here and put them after the Omega as well.",
                    "label": 0
                },
                {
                    "sent": "It's actually very simple, and I repeat the derivatives and the numerics and that generalized filtering.",
                    "label": 0
                },
                {
                    "sent": "Actually fairly trivial is specially if you assume that.",
                    "label": 0
                },
                {
                    "sent": "These can be parameterized in terms of log precisions.",
                    "label": 0
                },
                {
                    "sent": "They actually fall out into very simple the recognition dynamics or the generalized filter in the common beauty light filtering just has a couple of extra terms which are actually very simple and biologically plausible, but, crucially, nothing has really changed.",
                    "label": 0
                },
                {
                    "sent": "All you've said is the Omega becomes in the same way that these equations of motion here depends upon the states.",
                    "label": 0
                },
                {
                    "sent": "These random fluctuations, depending on the space.",
                    "label": 0
                },
                {
                    "sent": "Nothing's really changed.",
                    "label": 0
                },
                {
                    "sent": "This is a more general.",
                    "label": 0
                },
                {
                    "sent": "A more natural model to have.",
                    "label": 0
                },
                {
                    "sent": "Question.",
                    "label": 0
                },
                {
                    "sent": "Rock there are no goals or losses, so this optimization is of free energy, so there is no loss functions or rewards here, and I would appeal to the complete class theorems to replace loss functions with priors.",
                    "label": 0
                },
                {
                    "sent": "So if you're more comfortable thinking about optimizing in a sort of Bayesian decision theory sense your expected loss.",
                    "label": 0
                },
                {
                    "sent": "What you do here is you replace those with prior expectations.",
                    "label": 0
                },
                {
                    "sent": "So if you remember, the action is basically there to minimize prediction errors or make predictions come true.",
                    "label": 0
                },
                {
                    "sent": "Predictions have a likelihood part in a prior part, so you can bias the likelihood part to a greater or lesser extent by biasing the decisions by putting desired behaviors into the prior expectations.",
                    "label": 0
                },
                {
                    "sent": "So instead of saying this is a rewarding state to be in, you simply say I expect to be in this state.",
                    "label": 0
                },
                {
                    "sent": "A priority, and that's written down in terms of the equations of motion.",
                    "label": 0
                },
                {
                    "sent": "So in a sense, those attractors basically define a subspace of all states.",
                    "label": 0
                },
                {
                    "sent": "You could be in and generate all sensory states by the form of the equations of motion in the generative model and that subspace.",
                    "label": 0
                },
                {
                    "sent": "You can think of as a rewarding place to be and the job of action is to get you there, because that's where you expect to be.",
                    "label": 0
                },
                {
                    "sent": "It dispenses with loss functions and reward functions and replaces them with priors and I.",
                    "label": 0
                },
                {
                    "sent": "What is the only thing which is rewarding here is as a removal of surprise.",
                    "label": 0
                },
                {
                    "sent": "I'm not talking bout surprises you get with birthday presence which I'm talking about the sort of surprise when you put your hand in your pocket in your wallet's not there or you're walking down the street and you trip and fall over those unexpected.",
                    "label": 0
                },
                {
                    "sent": "Oh my God, sort of surprises things you just did not predict and you gotta completely readjust on the basis of audio production are so from in terms of sort of comfortable rhetoric, I would say.",
                    "label": 0
                },
                {
                    "sent": "Having those priors that that define what is surprising allow you then to recast reward's, avoiding of unrewarding surprising events.",
                    "label": 0
                },
                {
                    "sent": "That's basically the story.",
                    "label": 0
                },
                {
                    "sent": "And you define what is rewarding or unsurprising in terms of the prize.",
                    "label": 0
                },
                {
                    "sent": "Where do they come from?",
                    "label": 0
                },
                {
                    "sent": "Where they come from?",
                    "label": 0
                },
                {
                    "sent": "The nature of what you are, the things that you like to, the States you like to be in the states you'll find surprising and you do not like to be in like being very cold or being very hungry or being too hot.",
                    "label": 0
                },
                {
                    "sent": "We're thinking about that.",
                    "label": 0
                },
                {
                    "sent": "Because.",
                    "label": 0
                },
                {
                    "sent": "Missing light the light without any surprises.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "There is.",
                    "label": 0
                },
                {
                    "sent": "I mean, I think that's a sensitive question that there is a debate which has been going on for about two or three years now in philosophy.",
                    "label": 0
                },
                {
                    "sent": "I thought about this and after several months they came to the same conclusion you came to.",
                    "label": 0
                },
                {
                    "sent": "After several minutes that.",
                    "label": 0
                },
                {
                    "sent": "That was a paradox that it's called the darkroom problem and that the darkroom problem means that if you're trying to minimize surprise or free energy through action and perception, then clearly the best place to be is in completely isolated dark room where you can predict exactly you're sensing absolutely nothing, and therefore you will be perpetually unsurprised and very, very happy and rewarded, that's.",
                    "label": 0
                },
                {
                    "sent": "If you're dead, absolutely yes.",
                    "label": 0
                },
                {
                    "sent": "Absolutely, that's the perfect as well.",
                    "label": 0
                },
                {
                    "sent": "I don't like dead, because dead you tend to decompose and that your state space drifts over all sorts of phase transitions.",
                    "label": 0
                },
                {
                    "sent": "I don't.",
                    "label": 0
                },
                {
                    "sent": "I don't include dead in this, but if at the dark Room is actually a specious argument speech, it's plausable, but false, and it's easy to to counter on a number of different levels.",
                    "label": 0
                },
                {
                    "sent": "And if you email me and please do, I can send you.",
                    "label": 0
                },
                {
                    "sent": "Other short exchanges or very long detailed discussions about it.",
                    "label": 0
                },
                {
                    "sent": "The very simple answer is we do not expect to be in a dark room.",
                    "label": 0
                },
                {
                    "sent": "We expect our world to change.",
                    "label": 0
                },
                {
                    "sent": "We are built to have these itinerant dynamics in terms of our priors so our loss functions and our rewards are intrinsically dynamic.",
                    "label": 0
                },
                {
                    "sent": "They're not about getting the money, they are about the dynamics of the way that we live our lives.",
                    "label": 0
                },
                {
                    "sent": "The way that we itinerantly wander from one source of nourishment to the next, one to the next, one to the next, one there about trajectory's that are encoded in our prior expectations that appeal to these empirical prize encoded by the form of the equations of motion.",
                    "label": 0
                },
                {
                    "sent": "The central pattern generators in our brain that cause our movements and our plans, and indeed our career trajectory.",
                    "label": 0
                },
                {
                    "sent": "Another way to think of it.",
                    "label": 0
                },
                {
                    "sent": "Optimistic ways to say the best thing for us going forward is to have an accurate perception of the world.",
                    "label": 0
                },
                {
                    "sent": "Yeah, yeah.",
                    "label": 0
                },
                {
                    "sent": "And if you didn't have that, then clearly you're not going to be able to negotiate on navigate that world and you may well cross one of these phase transitions and be very surprised and die and decompose, or evaporate or explode.",
                    "label": 0
                },
                {
                    "sent": "So the trick is to keep on that well trodden path.",
                    "label": 0
                },
                {
                    "sent": "That is unsurprising and a sense that through the challenge I mean, you know for something that has to survive.",
                    "label": 0
                },
                {
                    "sent": "Avoiding surprises is the only thing that is necessary, is not necessary to seek out rewards, it is just necessary not to get destroyed.",
                    "label": 0
                },
                {
                    "sent": "That's that's.",
                    "label": 0
                },
                {
                    "sent": "Active perception is a subgoal, it's not adult.",
                    "label": 0
                },
                {
                    "sent": "Yeah, absolutely yeah, absolutely yeah.",
                    "label": 0
                },
                {
                    "sent": "Yeah, I think that's absolutely right, so your mathematic Lee Ann geologically when you unpack all this, you suddenly see that perception is just in the service of providing good predictions for action.",
                    "label": 0
                },
                {
                    "sent": "It is, there is nothing in the nothing in perception which will just change.",
                    "label": 0
                },
                {
                    "sent": "Q will change surprise in and of itself because it doesn't.",
                    "label": 0
                },
                {
                    "sent": "Surprise, if you remember, is the log evidence which is a function of the sensory data in the model.",
                    "label": 0
                },
                {
                    "sent": "Changing Q does not change the model or the sensory data, so you does nothing for you.",
                    "label": 0
                },
                {
                    "sent": "You really need it to induce or create the Ferengi bound that then allows action to do stuff to change, change S that changes the evidence, or the entropy.",
                    "label": 0
                },
                {
                    "sent": "That's absolutely true.",
                    "label": 0
                },
                {
                    "sent": "So almost paradoxically, perception becomes secondary an in the service of action in this particular formalism, absolutely essential.",
                    "label": 0
                },
                {
                    "sent": "And, of course, there's a circular causality there, but.",
                    "label": 0
                },
                {
                    "sent": "At the end of the day, operationally, it's the action that is the key thing in minimizing the.",
                    "label": 0
                },
                {
                    "sent": "Beyond repair.",
                    "label": 0
                },
                {
                    "sent": "I don't find satisfying.",
                    "label": 0
                },
                {
                    "sent": "Surprise to kind of make sense.",
                    "label": 0
                },
                {
                    "sent": "The buses, it seems in some sense that you're considering the brain as this thing floating and then trying to.",
                    "label": 0
                },
                {
                    "sent": "It's a sensory.",
                    "label": 0
                },
                {
                    "sent": "It's ridic things, but it has a buddy with it.",
                    "label": 0
                },
                {
                    "sent": "And then there's some losses with the body remarkable survival.",
                    "label": 0
                },
                {
                    "sent": "Very strong signal prediction.",
                    "label": 0
                },
                {
                    "sent": "No, absolutely, and I think in a sense you know you're coming back to the concept about attention and and defining the subset of all sensory samples one could.",
                    "label": 0
                },
                {
                    "sent": "One could actually take.",
                    "label": 0
                },
                {
                    "sent": "One could actually look at evolution as putting by anatomical attentional constraints on the sampling, like we have eyes.",
                    "label": 0
                },
                {
                    "sent": "You know that this sample and narrow range of wavelengths.",
                    "label": 0
                },
                {
                    "sent": "Why?",
                    "label": 0
                },
                {
                    "sent": "Well, through evolution through model selection, model optimization, then natural selection is found, the models that are internally consistent with the environment.",
                    "label": 0
                },
                {
                    "sent": "That we have to predict.",
                    "label": 0
                },
                {
                    "sent": "So I haven't spoken about about it here, but this whole story actually is this part of the same story in hierarchal setting.",
                    "label": 0
                },
                {
                    "sent": "So you can use the free energy which is integrated over the lifetime of the model as a measure of the goodness of the model.",
                    "label": 0
                },
                {
                    "sent": "And then you can do Bayesian model selection on the basis of the free energy.",
                    "label": 0
                },
                {
                    "sent": "And that is the direct analogue of natural selection.",
                    "label": 0
                },
                {
                    "sent": "So there will be through Bayesian model selection accord with the free energy minimum in accord with feeling minimalization.",
                    "label": 0
                },
                {
                    "sent": "A progressive refinement and tuning a matching of the phenotype to the environment in which it is immersed which impart resolves your concerns about the plurality of all possible sensory states are called this sample.",
                    "label": 0
                },
                {
                    "sent": "It is only those that are relevant for modeling and negotiating and navigating that particularly Cornish so much of the motivation here really comes from a selectionist thinking about how biological agents optimize their models, and once they've got their model, then how do we optimize the parameters?",
                    "label": 0
                },
                {
                    "sent": "All the states of the infrastructure of that of that model in their particular cinematic lifetime.",
                    "label": 0
                },
                {
                    "sent": "End up.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Maybe a dark balance?",
                    "label": 0
                },
                {
                    "sent": "Yep.",
                    "label": 0
                },
                {
                    "sent": "I don't think one could.",
                    "label": 0
                },
                {
                    "sent": "At the moment, I'm purely theoretical terms.",
                    "label": 0
                },
                {
                    "sent": "I think what you have to do is put if we were talking before about sort of learning.",
                    "label": 0
                },
                {
                    "sent": "Think you had to put learning back in and optimize the parameters with respect to the free energy lesion and see how the model responded and then make empirical predictions about recovery, for example from stroke.",
                    "label": 0
                },
                {
                    "sent": "So this is another domain of application here.",
                    "label": 0
                },
                {
                    "sent": "Yep.",
                    "label": 0
                },
                {
                    "sent": "Yep, Yep, I mean that actually it would be an easy experimental thing to do.",
                    "label": 0
                },
                {
                    "sent": "You can actually include.",
                    "label": 0
                },
                {
                    "sent": "Yes, I think to use this in a empirical neuroscience setting to use this style of thinking and modeling.",
                    "label": 0
                },
                {
                    "sent": "As you probably all know, I think you would generate predictions about how real patients or subjects would respond adaptively given your hypothesis that about what is being optimized and in this instance it would be free energy.",
                    "label": 0
                },
                {
                    "sent": "And you would allow all plausable optimization procedures to proceed, including re learning and also want to know one could in a neural developmental context introduced this notion of model optimization because the model is defined by which connections are present or absent.",
                    "label": 0
                },
                {
                    "sent": "So it brings to the table the notion of neurogenesis, the the homeostasis of synaptic connections themselves.",
                    "label": 0
                },
                {
                    "sent": "So during sleep so you can regard sleep really as a period of model optimization.",
                    "label": 0
                },
                {
                    "sent": "Well, you're minimizing a complexity term of the free energy approximation to the log evidence, so all these implausible biologically plausible optimization processes.",
                    "label": 0
                },
                {
                    "sent": "I think it would be including the model you leaving, the model, you see how it behaves following the lesion, and then made predictions that you would then look for in real subjects.",
                    "label": 0
                },
                {
                    "sent": "I think that's the.",
                    "label": 0
                },
                {
                    "sent": "Press.",
                    "label": 0
                },
                {
                    "sent": "What's normal?",
                    "label": 0
                },
                {
                    "sent": "Right, OK, that's a slightly deeper question.",
                    "label": 0
                },
                {
                    "sent": "Clear from my point of view that the model and the state of any particular model and at any one time has a free energy.",
                    "label": 0
                },
                {
                    "sent": "The best is the one with the lowest free energy, and it's a purely relativistic response.",
                    "label": 0
                },
                {
                    "sent": "But you know, I can.",
                    "label": 0
                },
                {
                    "sent": "I can.",
                    "label": 0
                },
                {
                    "sent": "I can appeal either to evolutionary arguments or to inference argument, sort of optimal behavior.",
                    "label": 0
                },
                {
                    "sent": "Arguments to say that it is best in that particular context.",
                    "label": 0
                },
                {
                    "sent": "So there is only best relative to an alternative.",
                    "label": 0
                },
                {
                    "sent": "There clearly is no.",
                    "label": 0
                },
                {
                    "sent": "Canonical, a platonic good model, is just sufficient to minimize define the local minima when that particular model is immersed in that particular environment or that particular.",
                    "label": 0
                },
                {
                    "sent": "Universal of sensory inputs.",
                    "label": 0
                },
                {
                    "sent": "OK, let's thank all again.",
                    "label": 0
                }
            ]
        }
    }
}