{
    "id": "4yryh5h5p7jk2mncangs6nauhhfvgb6o",
    "title": "SOFIE: Self-Organizing Flexible Information Extraction",
    "info": {
        "author": [
            "Fabian M. Suchanek, INRIA Saclay - \u00cele-de-France",
            "Mauro Sozio, Max Planck Institute for Computer Science, Max Planck Institute",
            "Gerhard Weikum, Max Planck Institute for Informatics, Max Planck Institute"
        ],
        "published": "May 20, 2009",
        "recorded": "April 2009",
        "category": [
            "Top->Computer Science->Semantic Computing"
        ]
    },
    "url": "http://videolectures.net/www09_suchanek_sofie/",
    "segmentation": [
        [
            "I've been talking about linking open data and linking the data in.",
            "This talk will actually be about where we get the data from.",
            "So this is not my laptop.",
            "Shut up.",
            "Yeah.",
            "Well."
        ],
        [
            "OK yeah, so in the recent years Wikipedia has gained a lot of important as a source of knowledge, and this is particularly also because it has these nice infoboxes that is the structured information here.",
            "For example, this is about my favorite musician, musician Elvis, and it says the birthplace of the United States of America and there have been several approaches that leverage this structured information to extract ontologies so you all have known them.",
            "Probably there are DB pedia Jago.",
            "And Kaylin and many other approaches that use these structured information from Wikipedia to extract graphs and knowledge graphs, such as here for example, this small ontology piece there.",
            "Elvis is born than in the United States, and Elvis is a singer and a single as a subclass of entity, and the United States of America is a country, and this is a subclass of entity and so on.",
            "So we have these large knowledge structures there, and they've been extracted from Wikipedia.",
            "But Wikipedia does not know everything.",
            "Assume, for example, that Wikipedia knows the birthplace of Elvis and the birthdate and everything, but it does not talk about the death place and death date.",
            "So let's assume that.",
            "So we would think that Elvis is still alive, right?",
            "This is a very reasonable assumption.",
            "So now there are other sources.",
            "For example here, the Internet, the web, and there are tons of other sources which we would also like to harvest.",
            "For example, we might find a web document that says Elvis died in England.",
            "And so we're very frustrated because this would mean that Elvis died.",
            "So we're very keen to extract this information as well.",
            "So the key question here is we did the information extraction from Wikipedia in a very well understood way.",
            "How can we transfer this?",
            "These approaches to the whole web?",
            "How can we extract more information from more sources?",
            "And this is actually the main goal of our work, extracting information from natural language documents.",
            "So this was nicely mentioned this morning.",
            "In the keynote we have this sentence there ever start in England and we're trying to find a canonicalized fact from it.",
            "So this Elvis, this person, the ontology.",
            "Died in place so we have a given relationship in England, which is another entity, so the task is going from the natural language to a canonicalized fact.",
            "And this is a very popular goal.",
            "There are tons of."
        ],
        [
            "Project's Presto Dipper Laylas Noble text owner Alice and many, many others.",
            "But these have all certain problems with this.",
            "We are not there yet.",
            "For example, these may deliver non canonic relations.",
            "Here are some examples.",
            "They would not extract.",
            "The relation died in place, but they would expect the verb of the sentence.",
            "So we would get facts about died in or perished in or was killed in or whatever.",
            "But we would not get.",
            "Died in place necessarily, so this is a complicated thing.",
            "We need to map the sentence.",
            "The verb of the sentence to the right relationship.",
            "Another problem is that these may deliver non canonic entities.",
            "So for example they might deliver England because the word England appeared in the sentence or UK or Great Britain and they would not actually know that these are all the same.",
            "So we need to canonicalize them to put them into the ontology, and 3rd these approaches may also deliver inconsistent facts.",
            "For example, they might figure out that Elvis died in England and then they read some other documents.",
            "Find out that Elvis died in Germany so and they would not even care about this these this inconsistency.",
            "So to convince you that this is really a problem, I have here a sample output of one of these approaches.",
            "They are quite recent.",
            "I won't say which one, but these are the kinds of facts we can also expect from these engines.",
            "So for example, they scroll, they crawl the web and find facts and they would find facts like recover without most people medication or are under 0% the age of 18.",
            "Support these findings, the notion.",
            "So this is already an advancement, so we are.",
            "About to trip defy the natural language texts, but we're still a way of far away from the real economic effects.",
            "So.",
            "Of course, different projects, different advantages, and I want to say they're all bad or something.",
            "They all have their specific.",
            "Contributions, but now I will try to present an approach that covers all of these three problems at once.",
            "So we are trying to one shot solution and this is the Sophie framework.",
            "And for this goal, let me step back and let me start from scratch."
        ],
        [
            "The pitfalls of information extraction.",
            "How does information extraction work?",
            "On the left hand side you see the web page with our sentence and it is died in England and on the right hand side you see the ontology.",
            "What we have so far and our goal is extracting the facts from the sentence and putting it into the ontology.",
            "So the first thing we can do with the sentence is exactly nothing because we don't know, or the system does not know what Evers died in England means there's no clue what died in means.",
            "So the common way to bootstrap this system is to look for other sentences.",
            "For example, Louis XIV style in France.",
            "And if in the ontology, or we know that this guy died in France, we can deduce that since this pattern DIDIN appears with two entities, and these entities stand in a relationship in the ontology, we can deduce that this pattern probably has this meaning.",
            "So died in probably Maps to died in place, and then we go further and we see that this pattern occurs again here with Elvis and England.",
            "And then we did use look, we know died in means died in place and so we can deduce that probably.",
            "If a meaningful pattern occurs with the two entities, then these two entities, Evers in England, they stand in this relationship.",
            "So we go there."
        ],
        [
            "Here we know that.",
            "Some entity, called Elvis, sends the relation died in place with England, but here the next problem comes."
        ],
        [
            "Elvis can refer to very many entities first one, this one.",
            "Of course our favorite Elvis, but many other people have called themselves Evers.",
            "For example, these two guys here.",
            "They have also called themselves over the bed.",
            "So is the kind of a problem which ever is meant in this case.",
            "And a third problem peers.",
            "That Elvis is actually a taxi deforest.",
            "This means he is afraid of traveling and he is afraid of leaving his country.",
            "And that's actually true.",
            "After his military service in Germany, Evers Neverless left his country.",
            "He was always touring in the US and he shares this property with many other people.",
            "So now.",
            "If if this is a taxi to public, so here's tendency to stay in his country.",
            "So then it's summer, highly unlikely he died in England, right?",
            "If he was born in the US and he stays there, why would he die in England?",
            "So actually it is very complicated to understand this very simple sentence.",
            "Elvis died in England, but we have constant problems to understand this sentence into crisply identify what it means."
        ],
        [
            "We first have a reasoning problem here.",
            "What does it mean to be a text of harvest?"
        ],
        [
            "2nd, we have a disambiguation problem.",
            "So what does Elvis mean in this context?"
        ],
        [
            "We have a pattern matching problem.",
            "So what does that actually mean and up to now, these problems have often been studied in isolation, so people have looked at the reasoning so they did description logics and efficiency efficient calculations there, and reasoning over there.",
            "But those people who did the reasoning did not care too often about petrol matching or meanings of patterns.",
            "Those linguists who were concerned with the disambiguation, like what does the word refer to and how can we understand its meaning?",
            "Rarely thought about reasoning, and this is a pity.",
            "Because these problems are highly interlinked.",
            "So for example, if I know that probably Elvis did not do this, traveling to England so Evers is not intended the intended meaning in this document.",
            "This will simplify my disambiguation problem.",
            "Once I simplified the disambiguation problem, I can better do the pattern matching when I have better petting math pattern matching, I find new facts which can enhance my reasoning, right?",
            "So these are all highly interlinked.",
            "And Philthy aims at solving all of them simultaneously.",
            "Let's start with the reasoning problem."
        ],
        [
            "Our idea was to express all of these three problems as formulas, so this problem is very simple.",
            "Formulas formulas.",
            "We simply say that Elvis is a text of harvest and we use some pseudo logic representation here.",
            "And we can formalize what this means by another logic formula.",
            "So if X is a text of harvest and X is born in some place, then probably he did not die in another place.",
            "This is roughly what this what we understand there.",
            "And we can assign a weight to these to these classes.",
            "So we can say that this is probably probable, but not necessary necessary.",
            "This is how."
        ],
        [
            "We simplified the first problem and we mapped it to logical formulas.",
            "Let's look at the other problems.",
            "Let's look at the disambiguation problem."
        ],
        [
            "So we make two assumptions to simplify the problem.",
            "We first assume that in one document one word has always the same meaning.",
            "So if one document is about Elvis Presley and the whatever occurs there, then this document is always about Everest Presley.",
            "This is somehow simplifying.",
            "There's some theory about it, but we simply took this assumption.",
            "Second, we assume that the ontology already knows all important meanings of proper names, so we assume that the ontology knows all Elvis is in the case of VGO or DB pedia, this probably.",
            "Even true.",
            "And then we can make statements of the following form.",
            "We can say that one possible meaning of this word, Elvis in this document is Elvis Presley.",
            "Let's look at this statement more detailed version."
        ],
        [
            "Um?",
            "We take this word errors and we say that we identify this word in this document.",
            "We call this a word in context a week.",
            "So it's Elvis in document 15 or whatever.",
            "And then we say one possible meaning as given by the ontology.",
            "We know whatever can refer to is Elvis Presley, and then we compute a prior we like a prior estimation of the probability that this word really refers to Elvis Presley and this is simply done by a bag of words approach.",
            "Very simple thing that's just a prior where we compare the words in the document.",
            "Like if there are mostly about rock, music and everything and his his songs with the entities that are around Elvis Presley in the ontology.",
            "And if these have a high overlap.",
            "Then it's highly probable that this document really talks about Elvis Presley.",
            "This."
        ],
        [
            "How we create logical statements for this disambiguation problem, and we go further, and we formalize our intuitive understanding of this disambiguation process.",
            "We say if this word has the possible meaning, why we simply imply it?",
            "We say then X means why there's very, very brute force approach, and then we say, well, one word can only have 1 meaning.",
            "So if X means Y&Y&Z are different than X cannot refer to that.",
            "And these three formula."
        ],
        [
            "Formulas are disambiguation problem, so we have reduced this complex integration problem to basically 1st order logic formulas.",
            "What remains is the upper left part.",
            "And this is the pattern matching problem and guess it this one can also be formalized as logical formulas."
        ],
        [
            "As follows, we take the document and we create one logical statement for each pattern that occurs for each pattern occurrence.",
            "Here, for example, we would say the pattern died in occurs with the words Elvis and England, and then we give away to it.",
            "They we saw this 14 times or something.",
            "Remember, we are always talking about weeks here, but words in context so not about the entities yet.",
            "Just about the words.",
            "And then we formalize our understanding of this pattern matching problem by two by two logical statements.",
            "The first says if a pattern like died in occurs with two words.",
            "For example with Elvis in England.",
            "And we know that the first word means X.",
            "So this word Elvis means Elvis Presley, and we know that the second word means why.",
            "So England means the United Kingdom roughly, and we know that ever in England already standing in one relationship, for example, died in place.",
            "Then probably this pattern died in Means died in place.",
            "So this is how we did use the meaning of patterns biological formula.",
            "And then there's the way in the other way around.",
            "If the pattern occurs with two words and these have their respective meanings, and we already know that this pattern has this meaning, so we know that died in means that in place, then we can deduce.",
            "That the relation indeed holds between these two entities.",
            "So this is how we have reduced."
        ],
        [
            "All three problems too.",
            "Basic logic statements and logic formulas, and now the only thing we have to do is find truth assignments to be hypothesis so that the weight of satisfied formulas maximized.",
            "So we ask ourselves, does Elvis really mean Elvis Presley does died in mean died in place?",
            "And did Elvis die in England?",
            "And once we assign truth values to these values to these hypothesis, we try to make all formulas happy.",
            "That is, we try to maximize the weight of the satisfied formulas.",
            "And then the the final assignment of Truth fails.",
            "Is the meaning of the text.",
            "This is the basic idea.",
            "It sounds very simple, is not simple, because this is the."
        ],
        [
            "Weighted maximum satisfiability problem?",
            "It is finding truth assignments to have offices, so the weight of satisfied formulas maximized.",
            "And let me just make a quick brief.",
            "This is conversion problems from Openoffice.",
            "This is a subcase of Markov logic networks, Markov logic networks model the same problem, basically by probabilities and the weighted maximum sales for Belgium is a subcase of Markov logic problems.",
            "So if we're only interested in the maximum in the assignment of truth values that satisfy all formulas, then we can do without the probabilities and stick with weighted Max SAT.",
            "Unfortunately, this weighted maximum satisfiability problem is NP hard, and our instance of the problem is huge because we will have very many facts and very many hypothesis.",
            "An even more unfortunate, the most unpopular greedy approximation algorithm is we're looking for greedy algorithms that work fast that assign one value after the other without looking backwards.",
            "But the most popular 1 cannot work well without type of formulas.",
            "What does this mean?",
            "We often have mutual exclusion formulas.",
            "For example, if a guy is born in one place, he can't be born in the other place and this translates to clauses of the following form.",
            "So either A or B or either A or C or either B or C. So these are clauses that mirror this mutual exclusion so people cannot be born in one place or people cannot be born on one on different on different dates.",
            "And exactly for this shape of formulas, the most popular algorithm, Johnsons, has an upper bound of two, 3rd on the approximation guarantee.",
            "3rd can't get better than two third.",
            "This is why we came up with another algorithm."
        ],
        [
            "Which is the functional maximum satisfiability algorithm?",
            "And this is exactly the type of formulas that we just saw here.",
            "And let's see how this algorithm solves them.",
            "And it's a very simple algorithm and very intuitive, so the formulas here basically say of a B&C pick, only one and Pixie.",
            "So the right response is of course picking C and saying all the others are false.",
            "And this was the algorithm does it looks only at unit classes.",
            "So at this stage it will only look at the variable C. And will simply set it to true and by setting see to true.",
            "Other clauses also become unit classes.",
            "And now we can look at them again and therefore set the set the other variables in accordance.",
            "So it is a very simple algorithm that basically propagates the unit clauses and heuristically always choose the value that makes most sense at the current stage of the of the process.",
            "It uses one other technique that is dominating unit loss propagation.",
            "We stole this from the classical Max IT algorithm and generalized it to maximum weighted satisfiability.",
            "And this is the following scenario.",
            "Suppose you have the free formulas.",
            "So if you set A to true, you get a benefit of 30.",
            "If you set A to fall to get a benefit of 10, and then you have to set either A2 falls or beta true to get 10.",
            "And in this case, we observe that no matter what the value of B is, if we set A to true, we are sure to gain more than if we set a true false becausw 30 is larger than 10 + 10, so a priority, we can say a must be set to true without even knowing the value of B.",
            "This is dominating unit class propagation.",
            "Um?"
        ],
        [
            "So basically we have this.",
            "Algorithm and we can show that it works in polynomial time, so it's it is an approximation algorithm.",
            "It is.",
            "It doesn't always find the optimal solution, but we do have an approximation guarantee which is 0.5, so it's not so cool, but we can show that in our setting, like when these exclusiveness constraints are very frequent.",
            "Then our experiments show better performance than Johnson's algorithm, and this algorithm actually works like."
        ],
        [
            "Panel and this is the basic message of this talk where you take all your documents and with the Center for example ever start in England, you formalize it into into logical statements, as we've seen before, you take all your formulas.",
            "You also put them into the funnel and then you take your whole ontologies and your whole ontology.",
            "Everything you have also put it as logical statements and also put it into the."
        ],
        [
            "And this way, since all this logical formulas, the algorithm will start crunching and will try to find out what is the most likely meaning of the text.",
            "In this case it will first see.",
            "Well Elvis is the taxidermist.",
            "This we know then we know that probably over did not die in England.",
            "Then we know that in this case Elvis cannot mean our Elvis, so to speak, especially and then so Evans must mean something different and in the end, in this case, as it turns out, that the document was actually about Saint Elvis and St. Elvis is a holy person who lived and died and eat in England in the 16th century.",
            "So this document was just about some other Elvis and our algorithm can use the different constraints from the ontology and from.",
            "From the logical formulas to take this into account to figure out the right meaning of absence."
        ],
        [
            "We've conducted other experiments now, so this is the main take home.",
            "The main message here.",
            "So it's just posing for pictures.",
            "Sophie does.",
            "This is acts like a funnel."
        ],
        [
            "We've done other experiments.",
            "With different types of structured semi structured and unstructured corpora.",
            "Because the idea is that our algorithm can work with both structured data and unstructured data, so it works with Infoboxes as well as with the natural language text.",
            "And we always achieve a very high precision.",
            "Especially we are proud of the last experiment which is downloading biographies from the web.",
            "So we took for like some persons with 400 people.",
            "We took 10 biographies from the web.",
            "The top 10 Google hits and we analyzed them.",
            "So these are really completely weird documents with advertisements in them.",
            "An error message is an right and correct.",
            "An ambiguous name and everything.",
            "And there we achieve accuracy of 90%.",
            "So."
        ],
        [
            "This concludes the talk.",
            "We have seen that Sophie unifies the task of entity ambiguation, pattern extraction and semantic constraint reasoning in one framework, and it delivers Canonical aspects of canonicalized entities, Canonical last relations of a high precision, and there's summarized again the picture.",
            "Take your documents taking formulas, put them in, get nice facts, but of course the most important conclusion of this talk is that yes, maybe this guy died in England, but Elvis is alive.",
            "Thank you for your attention.",
            "Can you show me that?",
            "Very interesting one question about the.",
            "Yes.",
            "So you know, you might say that a certain speaker died from the audience, right?",
            "I I learn a new word today about Elsa's inability to travel overseas, but if you're not, if you don't have that crucial piece of information.",
            "Does this thing still hold together or unravel?",
            "Yeah, that is a very good observation.",
            "So we have metaphorical use and we in the same category is also false information.",
            "Some documents must be false and this approach Fortunately has a gradient between very good and very bad.",
            "It won't fail just because there's one bad thing, because we are using a weighted maximum satisfiability approach.",
            "So even if in some cases it does not hold, or in some cases it does not work, that's not a problem.",
            "It will still try to get the best out of it, and if there's only very weird data, it won't come up with anything good.",
            "But as soon as some things are reasonable, it will try to make the best out of it and it will hopefully be like get rid of these patterns that are often metaphorically used.",
            "Try to shop.",
            "Let me know.",
            "What is the time?",
            "I was wondering that the the main examples and it still seems to be about accuracy configuration.",
            "Yes.",
            "Open domain.",
            "Possibly finding awful test.",
            "It's a procedure.",
            "OK, I'm asking this because the example with Elvis it sounds very nice, but the actual for this particular example that you have achievement of figuring out the document about stand stand Elvis is not does not happen to the sense of things that we care about.",
            "The musician doing that is not really that hard because information is documented in my mentions of, you know, instruments always.",
            "What did you find in a position?",
            "Of course that is right, so we have not compared explicitly with different disintegration approaches.",
            "The main message is just that we have the unified framework, and now if there are different disintegration approaches that can actually be plugged in as priors.",
            "And in this case, if you take nothing, then just these priors, then our method will be exactly as good as exactly the previous approach.",
            "And once you add the semantic constraints, it can only get better if we take this.",
            "If you take this into account.",
            "But it might be interesting to try out different disambiguation approaches, right?",
            "Relation like in the example you said about the idea that you have a happens field for that matter, to build those patterns or how do you know how do you get all this in relationship?",
            "Tracking from the former Soviet like like dieting or whatever other things like playing at right.",
            "So we're using the Yahoo ontology.",
            "And there we assume that the relations are all given.",
            "So in a certain sense the relations are given either manual or somehow extracted.",
            "So died in place is given, but the patterns themselves so died in this place or was killed in or perished in these.",
            "The algorithm will find automatically.",
            "Does this answer the question?",
            "OK.",
            "I think yeah, yeah.",
            "Map this week.",
            "I suppose that you use existing techniques for these different to get the knowledge because it pushes question.",
            "Here's how you get that knowledge into the system, right?",
            "Yes, yeah, yeah, So what specific tasks that we use for separation or.",
            "Pattern matching for reasoning.",
            "So how did you get the boots for reasoning?",
            "How to get the parents?",
            "How you get the same gauge technology?",
            "OK, maybe I should make this even clearer.",
            "The patterns are extracted automatically and we don't have to select them.",
            "This is all done by the machinery.",
            "This is the very purpose of it.",
            "Sophie does all of this at the same time, and there are no specific approaches.",
            "What I told you here is everything we did.",
            "We didn't use any pre existing work, it just does everything on its own.",
            "Maybe I'm misunderstanding the question or are you asking for evaluation?",
            "Mention.",
            "Yes.",
            "No no, no.",
            "This Sophie does all of this simultaneously at the same time it is not like we first extract the patterns and then we do this and then we do this and we use this technology for this part.",
            "This technology for this part.",
            "All of this is done by Sophie Auto automatically or on the same framework.",
            "The knowledge comes from Jago, so the original ontology which we try to extend is YAGO, and so this is pre existing.",
            "No, the patterns.",
            "This is extracted by by Sophie on his own.",
            "Maybe I'm misunderstanding you.",
            "Maybe talk offline and then we clarify this.",
            "Thank you.",
            "My question if there is any?",
            "So I'm always looking for the resurgence of old school AI, and this reminds me a lot of work on trees making systems on what truth maintenance systems from 8 is.",
            "Do you have any reflection on?",
            "OK, so the question was about truth mentioned systems, and I assume this is about when we get new data in how we maintain consistency with it.",
            "Well, this was a theme of war.",
            "OK yeah yeah.",
            "So we thought about this because one of the basic ideas and Sophie is that if you find like 10 documents, let's say ever start in England and then you find it 11th he died in Germany.",
            "You would still believe he died in England.",
            "But then what if you store?",
            "He died in England and then you find 1000 documents that he died in Germany.",
            "So then you would need to revise your knowledge.",
            "Is this something?",
            "And in the Sophie approaches you would not need to do that because with Sophie you can compute snapshots.",
            "So after if your computer.",
            "Shot after 10 documents you would think he died in England.",
            "Then you keep gathering patterns to keep gathering data.",
            "You say no where did he die according to the current knowledge.",
            "So he runs the FMS algorithm and computes.",
            "Now it is more likely that he died in Germany and if afterwards you find a million documents he died in the US.",
            "He did die in the US, then you know he died in the US and it's actually not necessary to prematurely get stuck on one truth.",
            "But you can keep accumulating and compute the current truth at each each stage.",
            "OK, thank you very much.",
            "Again, thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I've been talking about linking open data and linking the data in.",
                    "label": 0
                },
                {
                    "sent": "This talk will actually be about where we get the data from.",
                    "label": 0
                },
                {
                    "sent": "So this is not my laptop.",
                    "label": 0
                },
                {
                    "sent": "Shut up.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Well.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK yeah, so in the recent years Wikipedia has gained a lot of important as a source of knowledge, and this is particularly also because it has these nice infoboxes that is the structured information here.",
                    "label": 0
                },
                {
                    "sent": "For example, this is about my favorite musician, musician Elvis, and it says the birthplace of the United States of America and there have been several approaches that leverage this structured information to extract ontologies so you all have known them.",
                    "label": 0
                },
                {
                    "sent": "Probably there are DB pedia Jago.",
                    "label": 0
                },
                {
                    "sent": "And Kaylin and many other approaches that use these structured information from Wikipedia to extract graphs and knowledge graphs, such as here for example, this small ontology piece there.",
                    "label": 0
                },
                {
                    "sent": "Elvis is born than in the United States, and Elvis is a singer and a single as a subclass of entity, and the United States of America is a country, and this is a subclass of entity and so on.",
                    "label": 0
                },
                {
                    "sent": "So we have these large knowledge structures there, and they've been extracted from Wikipedia.",
                    "label": 0
                },
                {
                    "sent": "But Wikipedia does not know everything.",
                    "label": 0
                },
                {
                    "sent": "Assume, for example, that Wikipedia knows the birthplace of Elvis and the birthdate and everything, but it does not talk about the death place and death date.",
                    "label": 0
                },
                {
                    "sent": "So let's assume that.",
                    "label": 0
                },
                {
                    "sent": "So we would think that Elvis is still alive, right?",
                    "label": 0
                },
                {
                    "sent": "This is a very reasonable assumption.",
                    "label": 0
                },
                {
                    "sent": "So now there are other sources.",
                    "label": 0
                },
                {
                    "sent": "For example here, the Internet, the web, and there are tons of other sources which we would also like to harvest.",
                    "label": 0
                },
                {
                    "sent": "For example, we might find a web document that says Elvis died in England.",
                    "label": 1
                },
                {
                    "sent": "And so we're very frustrated because this would mean that Elvis died.",
                    "label": 0
                },
                {
                    "sent": "So we're very keen to extract this information as well.",
                    "label": 0
                },
                {
                    "sent": "So the key question here is we did the information extraction from Wikipedia in a very well understood way.",
                    "label": 0
                },
                {
                    "sent": "How can we transfer this?",
                    "label": 0
                },
                {
                    "sent": "These approaches to the whole web?",
                    "label": 0
                },
                {
                    "sent": "How can we extract more information from more sources?",
                    "label": 0
                },
                {
                    "sent": "And this is actually the main goal of our work, extracting information from natural language documents.",
                    "label": 0
                },
                {
                    "sent": "So this was nicely mentioned this morning.",
                    "label": 0
                },
                {
                    "sent": "In the keynote we have this sentence there ever start in England and we're trying to find a canonicalized fact from it.",
                    "label": 0
                },
                {
                    "sent": "So this Elvis, this person, the ontology.",
                    "label": 0
                },
                {
                    "sent": "Died in place so we have a given relationship in England, which is another entity, so the task is going from the natural language to a canonicalized fact.",
                    "label": 0
                },
                {
                    "sent": "And this is a very popular goal.",
                    "label": 0
                },
                {
                    "sent": "There are tons of.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Project's Presto Dipper Laylas Noble text owner Alice and many, many others.",
                    "label": 0
                },
                {
                    "sent": "But these have all certain problems with this.",
                    "label": 0
                },
                {
                    "sent": "We are not there yet.",
                    "label": 0
                },
                {
                    "sent": "For example, these may deliver non canonic relations.",
                    "label": 0
                },
                {
                    "sent": "Here are some examples.",
                    "label": 0
                },
                {
                    "sent": "They would not extract.",
                    "label": 0
                },
                {
                    "sent": "The relation died in place, but they would expect the verb of the sentence.",
                    "label": 0
                },
                {
                    "sent": "So we would get facts about died in or perished in or was killed in or whatever.",
                    "label": 1
                },
                {
                    "sent": "But we would not get.",
                    "label": 0
                },
                {
                    "sent": "Died in place necessarily, so this is a complicated thing.",
                    "label": 0
                },
                {
                    "sent": "We need to map the sentence.",
                    "label": 0
                },
                {
                    "sent": "The verb of the sentence to the right relationship.",
                    "label": 0
                },
                {
                    "sent": "Another problem is that these may deliver non canonic entities.",
                    "label": 0
                },
                {
                    "sent": "So for example they might deliver England because the word England appeared in the sentence or UK or Great Britain and they would not actually know that these are all the same.",
                    "label": 0
                },
                {
                    "sent": "So we need to canonicalize them to put them into the ontology, and 3rd these approaches may also deliver inconsistent facts.",
                    "label": 1
                },
                {
                    "sent": "For example, they might figure out that Elvis died in England and then they read some other documents.",
                    "label": 0
                },
                {
                    "sent": "Find out that Elvis died in Germany so and they would not even care about this these this inconsistency.",
                    "label": 0
                },
                {
                    "sent": "So to convince you that this is really a problem, I have here a sample output of one of these approaches.",
                    "label": 0
                },
                {
                    "sent": "They are quite recent.",
                    "label": 0
                },
                {
                    "sent": "I won't say which one, but these are the kinds of facts we can also expect from these engines.",
                    "label": 0
                },
                {
                    "sent": "So for example, they scroll, they crawl the web and find facts and they would find facts like recover without most people medication or are under 0% the age of 18.",
                    "label": 0
                },
                {
                    "sent": "Support these findings, the notion.",
                    "label": 0
                },
                {
                    "sent": "So this is already an advancement, so we are.",
                    "label": 0
                },
                {
                    "sent": "About to trip defy the natural language texts, but we're still a way of far away from the real economic effects.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Of course, different projects, different advantages, and I want to say they're all bad or something.",
                    "label": 0
                },
                {
                    "sent": "They all have their specific.",
                    "label": 0
                },
                {
                    "sent": "Contributions, but now I will try to present an approach that covers all of these three problems at once.",
                    "label": 0
                },
                {
                    "sent": "So we are trying to one shot solution and this is the Sophie framework.",
                    "label": 0
                },
                {
                    "sent": "And for this goal, let me step back and let me start from scratch.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The pitfalls of information extraction.",
                    "label": 1
                },
                {
                    "sent": "How does information extraction work?",
                    "label": 0
                },
                {
                    "sent": "On the left hand side you see the web page with our sentence and it is died in England and on the right hand side you see the ontology.",
                    "label": 0
                },
                {
                    "sent": "What we have so far and our goal is extracting the facts from the sentence and putting it into the ontology.",
                    "label": 0
                },
                {
                    "sent": "So the first thing we can do with the sentence is exactly nothing because we don't know, or the system does not know what Evers died in England means there's no clue what died in means.",
                    "label": 0
                },
                {
                    "sent": "So the common way to bootstrap this system is to look for other sentences.",
                    "label": 1
                },
                {
                    "sent": "For example, Louis XIV style in France.",
                    "label": 0
                },
                {
                    "sent": "And if in the ontology, or we know that this guy died in France, we can deduce that since this pattern DIDIN appears with two entities, and these entities stand in a relationship in the ontology, we can deduce that this pattern probably has this meaning.",
                    "label": 0
                },
                {
                    "sent": "So died in probably Maps to died in place, and then we go further and we see that this pattern occurs again here with Elvis and England.",
                    "label": 0
                },
                {
                    "sent": "And then we did use look, we know died in means died in place and so we can deduce that probably.",
                    "label": 0
                },
                {
                    "sent": "If a meaningful pattern occurs with the two entities, then these two entities, Evers in England, they stand in this relationship.",
                    "label": 1
                },
                {
                    "sent": "So we go there.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here we know that.",
                    "label": 0
                },
                {
                    "sent": "Some entity, called Elvis, sends the relation died in place with England, but here the next problem comes.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Elvis can refer to very many entities first one, this one.",
                    "label": 0
                },
                {
                    "sent": "Of course our favorite Elvis, but many other people have called themselves Evers.",
                    "label": 0
                },
                {
                    "sent": "For example, these two guys here.",
                    "label": 0
                },
                {
                    "sent": "They have also called themselves over the bed.",
                    "label": 0
                },
                {
                    "sent": "So is the kind of a problem which ever is meant in this case.",
                    "label": 0
                },
                {
                    "sent": "And a third problem peers.",
                    "label": 0
                },
                {
                    "sent": "That Elvis is actually a taxi deforest.",
                    "label": 0
                },
                {
                    "sent": "This means he is afraid of traveling and he is afraid of leaving his country.",
                    "label": 0
                },
                {
                    "sent": "And that's actually true.",
                    "label": 0
                },
                {
                    "sent": "After his military service in Germany, Evers Neverless left his country.",
                    "label": 0
                },
                {
                    "sent": "He was always touring in the US and he shares this property with many other people.",
                    "label": 0
                },
                {
                    "sent": "So now.",
                    "label": 0
                },
                {
                    "sent": "If if this is a taxi to public, so here's tendency to stay in his country.",
                    "label": 0
                },
                {
                    "sent": "So then it's summer, highly unlikely he died in England, right?",
                    "label": 0
                },
                {
                    "sent": "If he was born in the US and he stays there, why would he die in England?",
                    "label": 0
                },
                {
                    "sent": "So actually it is very complicated to understand this very simple sentence.",
                    "label": 0
                },
                {
                    "sent": "Elvis died in England, but we have constant problems to understand this sentence into crisply identify what it means.",
                    "label": 1
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We first have a reasoning problem here.",
                    "label": 0
                },
                {
                    "sent": "What does it mean to be a text of harvest?",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "2nd, we have a disambiguation problem.",
                    "label": 0
                },
                {
                    "sent": "So what does Elvis mean in this context?",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We have a pattern matching problem.",
                    "label": 1
                },
                {
                    "sent": "So what does that actually mean and up to now, these problems have often been studied in isolation, so people have looked at the reasoning so they did description logics and efficiency efficient calculations there, and reasoning over there.",
                    "label": 0
                },
                {
                    "sent": "But those people who did the reasoning did not care too often about petrol matching or meanings of patterns.",
                    "label": 0
                },
                {
                    "sent": "Those linguists who were concerned with the disambiguation, like what does the word refer to and how can we understand its meaning?",
                    "label": 0
                },
                {
                    "sent": "Rarely thought about reasoning, and this is a pity.",
                    "label": 0
                },
                {
                    "sent": "Because these problems are highly interlinked.",
                    "label": 0
                },
                {
                    "sent": "So for example, if I know that probably Elvis did not do this, traveling to England so Evers is not intended the intended meaning in this document.",
                    "label": 1
                },
                {
                    "sent": "This will simplify my disambiguation problem.",
                    "label": 0
                },
                {
                    "sent": "Once I simplified the disambiguation problem, I can better do the pattern matching when I have better petting math pattern matching, I find new facts which can enhance my reasoning, right?",
                    "label": 0
                },
                {
                    "sent": "So these are all highly interlinked.",
                    "label": 1
                },
                {
                    "sent": "And Philthy aims at solving all of them simultaneously.",
                    "label": 0
                },
                {
                    "sent": "Let's start with the reasoning problem.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Our idea was to express all of these three problems as formulas, so this problem is very simple.",
                    "label": 1
                },
                {
                    "sent": "Formulas formulas.",
                    "label": 0
                },
                {
                    "sent": "We simply say that Elvis is a text of harvest and we use some pseudo logic representation here.",
                    "label": 0
                },
                {
                    "sent": "And we can formalize what this means by another logic formula.",
                    "label": 0
                },
                {
                    "sent": "So if X is a text of harvest and X is born in some place, then probably he did not die in another place.",
                    "label": 0
                },
                {
                    "sent": "This is roughly what this what we understand there.",
                    "label": 0
                },
                {
                    "sent": "And we can assign a weight to these to these classes.",
                    "label": 0
                },
                {
                    "sent": "So we can say that this is probably probable, but not necessary necessary.",
                    "label": 0
                },
                {
                    "sent": "This is how.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We simplified the first problem and we mapped it to logical formulas.",
                    "label": 0
                },
                {
                    "sent": "Let's look at the other problems.",
                    "label": 0
                },
                {
                    "sent": "Let's look at the disambiguation problem.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we make two assumptions to simplify the problem.",
                    "label": 0
                },
                {
                    "sent": "We first assume that in one document one word has always the same meaning.",
                    "label": 1
                },
                {
                    "sent": "So if one document is about Elvis Presley and the whatever occurs there, then this document is always about Everest Presley.",
                    "label": 0
                },
                {
                    "sent": "This is somehow simplifying.",
                    "label": 0
                },
                {
                    "sent": "There's some theory about it, but we simply took this assumption.",
                    "label": 1
                },
                {
                    "sent": "Second, we assume that the ontology already knows all important meanings of proper names, so we assume that the ontology knows all Elvis is in the case of VGO or DB pedia, this probably.",
                    "label": 0
                },
                {
                    "sent": "Even true.",
                    "label": 0
                },
                {
                    "sent": "And then we can make statements of the following form.",
                    "label": 0
                },
                {
                    "sent": "We can say that one possible meaning of this word, Elvis in this document is Elvis Presley.",
                    "label": 0
                },
                {
                    "sent": "Let's look at this statement more detailed version.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "We take this word errors and we say that we identify this word in this document.",
                    "label": 0
                },
                {
                    "sent": "We call this a word in context a week.",
                    "label": 1
                },
                {
                    "sent": "So it's Elvis in document 15 or whatever.",
                    "label": 0
                },
                {
                    "sent": "And then we say one possible meaning as given by the ontology.",
                    "label": 1
                },
                {
                    "sent": "We know whatever can refer to is Elvis Presley, and then we compute a prior we like a prior estimation of the probability that this word really refers to Elvis Presley and this is simply done by a bag of words approach.",
                    "label": 0
                },
                {
                    "sent": "Very simple thing that's just a prior where we compare the words in the document.",
                    "label": 0
                },
                {
                    "sent": "Like if there are mostly about rock, music and everything and his his songs with the entities that are around Elvis Presley in the ontology.",
                    "label": 0
                },
                {
                    "sent": "And if these have a high overlap.",
                    "label": 0
                },
                {
                    "sent": "Then it's highly probable that this document really talks about Elvis Presley.",
                    "label": 0
                },
                {
                    "sent": "This.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "How we create logical statements for this disambiguation problem, and we go further, and we formalize our intuitive understanding of this disambiguation process.",
                    "label": 0
                },
                {
                    "sent": "We say if this word has the possible meaning, why we simply imply it?",
                    "label": 0
                },
                {
                    "sent": "We say then X means why there's very, very brute force approach, and then we say, well, one word can only have 1 meaning.",
                    "label": 0
                },
                {
                    "sent": "So if X means Y&Y&Z are different than X cannot refer to that.",
                    "label": 0
                },
                {
                    "sent": "And these three formula.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Formulas are disambiguation problem, so we have reduced this complex integration problem to basically 1st order logic formulas.",
                    "label": 1
                },
                {
                    "sent": "What remains is the upper left part.",
                    "label": 0
                },
                {
                    "sent": "And this is the pattern matching problem and guess it this one can also be formalized as logical formulas.",
                    "label": 1
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "As follows, we take the document and we create one logical statement for each pattern that occurs for each pattern occurrence.",
                    "label": 0
                },
                {
                    "sent": "Here, for example, we would say the pattern died in occurs with the words Elvis and England, and then we give away to it.",
                    "label": 0
                },
                {
                    "sent": "They we saw this 14 times or something.",
                    "label": 0
                },
                {
                    "sent": "Remember, we are always talking about weeks here, but words in context so not about the entities yet.",
                    "label": 0
                },
                {
                    "sent": "Just about the words.",
                    "label": 0
                },
                {
                    "sent": "And then we formalize our understanding of this pattern matching problem by two by two logical statements.",
                    "label": 1
                },
                {
                    "sent": "The first says if a pattern like died in occurs with two words.",
                    "label": 1
                },
                {
                    "sent": "For example with Elvis in England.",
                    "label": 0
                },
                {
                    "sent": "And we know that the first word means X.",
                    "label": 0
                },
                {
                    "sent": "So this word Elvis means Elvis Presley, and we know that the second word means why.",
                    "label": 0
                },
                {
                    "sent": "So England means the United Kingdom roughly, and we know that ever in England already standing in one relationship, for example, died in place.",
                    "label": 0
                },
                {
                    "sent": "Then probably this pattern died in Means died in place.",
                    "label": 1
                },
                {
                    "sent": "So this is how we did use the meaning of patterns biological formula.",
                    "label": 0
                },
                {
                    "sent": "And then there's the way in the other way around.",
                    "label": 0
                },
                {
                    "sent": "If the pattern occurs with two words and these have their respective meanings, and we already know that this pattern has this meaning, so we know that died in means that in place, then we can deduce.",
                    "label": 0
                },
                {
                    "sent": "That the relation indeed holds between these two entities.",
                    "label": 0
                },
                {
                    "sent": "So this is how we have reduced.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "All three problems too.",
                    "label": 0
                },
                {
                    "sent": "Basic logic statements and logic formulas, and now the only thing we have to do is find truth assignments to be hypothesis so that the weight of satisfied formulas maximized.",
                    "label": 1
                },
                {
                    "sent": "So we ask ourselves, does Elvis really mean Elvis Presley does died in mean died in place?",
                    "label": 0
                },
                {
                    "sent": "And did Elvis die in England?",
                    "label": 0
                },
                {
                    "sent": "And once we assign truth values to these values to these hypothesis, we try to make all formulas happy.",
                    "label": 0
                },
                {
                    "sent": "That is, we try to maximize the weight of the satisfied formulas.",
                    "label": 0
                },
                {
                    "sent": "And then the the final assignment of Truth fails.",
                    "label": 0
                },
                {
                    "sent": "Is the meaning of the text.",
                    "label": 0
                },
                {
                    "sent": "This is the basic idea.",
                    "label": 0
                },
                {
                    "sent": "It sounds very simple, is not simple, because this is the.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Weighted maximum satisfiability problem?",
                    "label": 0
                },
                {
                    "sent": "It is finding truth assignments to have offices, so the weight of satisfied formulas maximized.",
                    "label": 1
                },
                {
                    "sent": "And let me just make a quick brief.",
                    "label": 0
                },
                {
                    "sent": "This is conversion problems from Openoffice.",
                    "label": 0
                },
                {
                    "sent": "This is a subcase of Markov logic networks, Markov logic networks model the same problem, basically by probabilities and the weighted maximum sales for Belgium is a subcase of Markov logic problems.",
                    "label": 1
                },
                {
                    "sent": "So if we're only interested in the maximum in the assignment of truth values that satisfy all formulas, then we can do without the probabilities and stick with weighted Max SAT.",
                    "label": 0
                },
                {
                    "sent": "Unfortunately, this weighted maximum satisfiability problem is NP hard, and our instance of the problem is huge because we will have very many facts and very many hypothesis.",
                    "label": 1
                },
                {
                    "sent": "An even more unfortunate, the most unpopular greedy approximation algorithm is we're looking for greedy algorithms that work fast that assign one value after the other without looking backwards.",
                    "label": 0
                },
                {
                    "sent": "But the most popular 1 cannot work well without type of formulas.",
                    "label": 0
                },
                {
                    "sent": "What does this mean?",
                    "label": 0
                },
                {
                    "sent": "We often have mutual exclusion formulas.",
                    "label": 0
                },
                {
                    "sent": "For example, if a guy is born in one place, he can't be born in the other place and this translates to clauses of the following form.",
                    "label": 0
                },
                {
                    "sent": "So either A or B or either A or C or either B or C. So these are clauses that mirror this mutual exclusion so people cannot be born in one place or people cannot be born on one on different on different dates.",
                    "label": 0
                },
                {
                    "sent": "And exactly for this shape of formulas, the most popular algorithm, Johnsons, has an upper bound of two, 3rd on the approximation guarantee.",
                    "label": 0
                },
                {
                    "sent": "3rd can't get better than two third.",
                    "label": 0
                },
                {
                    "sent": "This is why we came up with another algorithm.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Which is the functional maximum satisfiability algorithm?",
                    "label": 1
                },
                {
                    "sent": "And this is exactly the type of formulas that we just saw here.",
                    "label": 0
                },
                {
                    "sent": "And let's see how this algorithm solves them.",
                    "label": 0
                },
                {
                    "sent": "And it's a very simple algorithm and very intuitive, so the formulas here basically say of a B&C pick, only one and Pixie.",
                    "label": 0
                },
                {
                    "sent": "So the right response is of course picking C and saying all the others are false.",
                    "label": 0
                },
                {
                    "sent": "And this was the algorithm does it looks only at unit classes.",
                    "label": 0
                },
                {
                    "sent": "So at this stage it will only look at the variable C. And will simply set it to true and by setting see to true.",
                    "label": 0
                },
                {
                    "sent": "Other clauses also become unit classes.",
                    "label": 0
                },
                {
                    "sent": "And now we can look at them again and therefore set the set the other variables in accordance.",
                    "label": 1
                },
                {
                    "sent": "So it is a very simple algorithm that basically propagates the unit clauses and heuristically always choose the value that makes most sense at the current stage of the of the process.",
                    "label": 0
                },
                {
                    "sent": "It uses one other technique that is dominating unit loss propagation.",
                    "label": 0
                },
                {
                    "sent": "We stole this from the classical Max IT algorithm and generalized it to maximum weighted satisfiability.",
                    "label": 0
                },
                {
                    "sent": "And this is the following scenario.",
                    "label": 0
                },
                {
                    "sent": "Suppose you have the free formulas.",
                    "label": 0
                },
                {
                    "sent": "So if you set A to true, you get a benefit of 30.",
                    "label": 0
                },
                {
                    "sent": "If you set A to fall to get a benefit of 10, and then you have to set either A2 falls or beta true to get 10.",
                    "label": 0
                },
                {
                    "sent": "And in this case, we observe that no matter what the value of B is, if we set A to true, we are sure to gain more than if we set a true false becausw 30 is larger than 10 + 10, so a priority, we can say a must be set to true without even knowing the value of B.",
                    "label": 1
                },
                {
                    "sent": "This is dominating unit class propagation.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So basically we have this.",
                    "label": 0
                },
                {
                    "sent": "Algorithm and we can show that it works in polynomial time, so it's it is an approximation algorithm.",
                    "label": 0
                },
                {
                    "sent": "It is.",
                    "label": 0
                },
                {
                    "sent": "It doesn't always find the optimal solution, but we do have an approximation guarantee which is 0.5, so it's not so cool, but we can show that in our setting, like when these exclusiveness constraints are very frequent.",
                    "label": 0
                },
                {
                    "sent": "Then our experiments show better performance than Johnson's algorithm, and this algorithm actually works like.",
                    "label": 1
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Panel and this is the basic message of this talk where you take all your documents and with the Center for example ever start in England, you formalize it into into logical statements, as we've seen before, you take all your formulas.",
                    "label": 0
                },
                {
                    "sent": "You also put them into the funnel and then you take your whole ontologies and your whole ontology.",
                    "label": 0
                },
                {
                    "sent": "Everything you have also put it as logical statements and also put it into the.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And this way, since all this logical formulas, the algorithm will start crunching and will try to find out what is the most likely meaning of the text.",
                    "label": 0
                },
                {
                    "sent": "In this case it will first see.",
                    "label": 0
                },
                {
                    "sent": "Well Elvis is the taxidermist.",
                    "label": 0
                },
                {
                    "sent": "This we know then we know that probably over did not die in England.",
                    "label": 0
                },
                {
                    "sent": "Then we know that in this case Elvis cannot mean our Elvis, so to speak, especially and then so Evans must mean something different and in the end, in this case, as it turns out, that the document was actually about Saint Elvis and St. Elvis is a holy person who lived and died and eat in England in the 16th century.",
                    "label": 0
                },
                {
                    "sent": "So this document was just about some other Elvis and our algorithm can use the different constraints from the ontology and from.",
                    "label": 0
                },
                {
                    "sent": "From the logical formulas to take this into account to figure out the right meaning of absence.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We've conducted other experiments now, so this is the main take home.",
                    "label": 0
                },
                {
                    "sent": "The main message here.",
                    "label": 0
                },
                {
                    "sent": "So it's just posing for pictures.",
                    "label": 0
                },
                {
                    "sent": "Sophie does.",
                    "label": 0
                },
                {
                    "sent": "This is acts like a funnel.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We've done other experiments.",
                    "label": 0
                },
                {
                    "sent": "With different types of structured semi structured and unstructured corpora.",
                    "label": 1
                },
                {
                    "sent": "Because the idea is that our algorithm can work with both structured data and unstructured data, so it works with Infoboxes as well as with the natural language text.",
                    "label": 0
                },
                {
                    "sent": "And we always achieve a very high precision.",
                    "label": 0
                },
                {
                    "sent": "Especially we are proud of the last experiment which is downloading biographies from the web.",
                    "label": 0
                },
                {
                    "sent": "So we took for like some persons with 400 people.",
                    "label": 0
                },
                {
                    "sent": "We took 10 biographies from the web.",
                    "label": 1
                },
                {
                    "sent": "The top 10 Google hits and we analyzed them.",
                    "label": 0
                },
                {
                    "sent": "So these are really completely weird documents with advertisements in them.",
                    "label": 0
                },
                {
                    "sent": "An error message is an right and correct.",
                    "label": 0
                },
                {
                    "sent": "An ambiguous name and everything.",
                    "label": 0
                },
                {
                    "sent": "And there we achieve accuracy of 90%.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This concludes the talk.",
                    "label": 0
                },
                {
                    "sent": "We have seen that Sophie unifies the task of entity ambiguation, pattern extraction and semantic constraint reasoning in one framework, and it delivers Canonical aspects of canonicalized entities, Canonical last relations of a high precision, and there's summarized again the picture.",
                    "label": 1
                },
                {
                    "sent": "Take your documents taking formulas, put them in, get nice facts, but of course the most important conclusion of this talk is that yes, maybe this guy died in England, but Elvis is alive.",
                    "label": 0
                },
                {
                    "sent": "Thank you for your attention.",
                    "label": 0
                },
                {
                    "sent": "Can you show me that?",
                    "label": 0
                },
                {
                    "sent": "Very interesting one question about the.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "So you know, you might say that a certain speaker died from the audience, right?",
                    "label": 0
                },
                {
                    "sent": "I I learn a new word today about Elsa's inability to travel overseas, but if you're not, if you don't have that crucial piece of information.",
                    "label": 0
                },
                {
                    "sent": "Does this thing still hold together or unravel?",
                    "label": 0
                },
                {
                    "sent": "Yeah, that is a very good observation.",
                    "label": 0
                },
                {
                    "sent": "So we have metaphorical use and we in the same category is also false information.",
                    "label": 0
                },
                {
                    "sent": "Some documents must be false and this approach Fortunately has a gradient between very good and very bad.",
                    "label": 0
                },
                {
                    "sent": "It won't fail just because there's one bad thing, because we are using a weighted maximum satisfiability approach.",
                    "label": 0
                },
                {
                    "sent": "So even if in some cases it does not hold, or in some cases it does not work, that's not a problem.",
                    "label": 0
                },
                {
                    "sent": "It will still try to get the best out of it, and if there's only very weird data, it won't come up with anything good.",
                    "label": 0
                },
                {
                    "sent": "But as soon as some things are reasonable, it will try to make the best out of it and it will hopefully be like get rid of these patterns that are often metaphorically used.",
                    "label": 0
                },
                {
                    "sent": "Try to shop.",
                    "label": 0
                },
                {
                    "sent": "Let me know.",
                    "label": 0
                },
                {
                    "sent": "What is the time?",
                    "label": 0
                },
                {
                    "sent": "I was wondering that the the main examples and it still seems to be about accuracy configuration.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "Open domain.",
                    "label": 0
                },
                {
                    "sent": "Possibly finding awful test.",
                    "label": 0
                },
                {
                    "sent": "It's a procedure.",
                    "label": 0
                },
                {
                    "sent": "OK, I'm asking this because the example with Elvis it sounds very nice, but the actual for this particular example that you have achievement of figuring out the document about stand stand Elvis is not does not happen to the sense of things that we care about.",
                    "label": 0
                },
                {
                    "sent": "The musician doing that is not really that hard because information is documented in my mentions of, you know, instruments always.",
                    "label": 0
                },
                {
                    "sent": "What did you find in a position?",
                    "label": 0
                },
                {
                    "sent": "Of course that is right, so we have not compared explicitly with different disintegration approaches.",
                    "label": 0
                },
                {
                    "sent": "The main message is just that we have the unified framework, and now if there are different disintegration approaches that can actually be plugged in as priors.",
                    "label": 0
                },
                {
                    "sent": "And in this case, if you take nothing, then just these priors, then our method will be exactly as good as exactly the previous approach.",
                    "label": 0
                },
                {
                    "sent": "And once you add the semantic constraints, it can only get better if we take this.",
                    "label": 0
                },
                {
                    "sent": "If you take this into account.",
                    "label": 0
                },
                {
                    "sent": "But it might be interesting to try out different disambiguation approaches, right?",
                    "label": 0
                },
                {
                    "sent": "Relation like in the example you said about the idea that you have a happens field for that matter, to build those patterns or how do you know how do you get all this in relationship?",
                    "label": 0
                },
                {
                    "sent": "Tracking from the former Soviet like like dieting or whatever other things like playing at right.",
                    "label": 0
                },
                {
                    "sent": "So we're using the Yahoo ontology.",
                    "label": 0
                },
                {
                    "sent": "And there we assume that the relations are all given.",
                    "label": 0
                },
                {
                    "sent": "So in a certain sense the relations are given either manual or somehow extracted.",
                    "label": 0
                },
                {
                    "sent": "So died in place is given, but the patterns themselves so died in this place or was killed in or perished in these.",
                    "label": 0
                },
                {
                    "sent": "The algorithm will find automatically.",
                    "label": 0
                },
                {
                    "sent": "Does this answer the question?",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "I think yeah, yeah.",
                    "label": 0
                },
                {
                    "sent": "Map this week.",
                    "label": 0
                },
                {
                    "sent": "I suppose that you use existing techniques for these different to get the knowledge because it pushes question.",
                    "label": 0
                },
                {
                    "sent": "Here's how you get that knowledge into the system, right?",
                    "label": 0
                },
                {
                    "sent": "Yes, yeah, yeah, So what specific tasks that we use for separation or.",
                    "label": 0
                },
                {
                    "sent": "Pattern matching for reasoning.",
                    "label": 0
                },
                {
                    "sent": "So how did you get the boots for reasoning?",
                    "label": 0
                },
                {
                    "sent": "How to get the parents?",
                    "label": 0
                },
                {
                    "sent": "How you get the same gauge technology?",
                    "label": 0
                },
                {
                    "sent": "OK, maybe I should make this even clearer.",
                    "label": 0
                },
                {
                    "sent": "The patterns are extracted automatically and we don't have to select them.",
                    "label": 0
                },
                {
                    "sent": "This is all done by the machinery.",
                    "label": 0
                },
                {
                    "sent": "This is the very purpose of it.",
                    "label": 0
                },
                {
                    "sent": "Sophie does all of this at the same time, and there are no specific approaches.",
                    "label": 0
                },
                {
                    "sent": "What I told you here is everything we did.",
                    "label": 0
                },
                {
                    "sent": "We didn't use any pre existing work, it just does everything on its own.",
                    "label": 0
                },
                {
                    "sent": "Maybe I'm misunderstanding the question or are you asking for evaluation?",
                    "label": 0
                },
                {
                    "sent": "Mention.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "No no, no.",
                    "label": 0
                },
                {
                    "sent": "This Sophie does all of this simultaneously at the same time it is not like we first extract the patterns and then we do this and then we do this and we use this technology for this part.",
                    "label": 0
                },
                {
                    "sent": "This technology for this part.",
                    "label": 0
                },
                {
                    "sent": "All of this is done by Sophie Auto automatically or on the same framework.",
                    "label": 0
                },
                {
                    "sent": "The knowledge comes from Jago, so the original ontology which we try to extend is YAGO, and so this is pre existing.",
                    "label": 0
                },
                {
                    "sent": "No, the patterns.",
                    "label": 0
                },
                {
                    "sent": "This is extracted by by Sophie on his own.",
                    "label": 0
                },
                {
                    "sent": "Maybe I'm misunderstanding you.",
                    "label": 0
                },
                {
                    "sent": "Maybe talk offline and then we clarify this.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                },
                {
                    "sent": "My question if there is any?",
                    "label": 0
                },
                {
                    "sent": "So I'm always looking for the resurgence of old school AI, and this reminds me a lot of work on trees making systems on what truth maintenance systems from 8 is.",
                    "label": 0
                },
                {
                    "sent": "Do you have any reflection on?",
                    "label": 0
                },
                {
                    "sent": "OK, so the question was about truth mentioned systems, and I assume this is about when we get new data in how we maintain consistency with it.",
                    "label": 0
                },
                {
                    "sent": "Well, this was a theme of war.",
                    "label": 0
                },
                {
                    "sent": "OK yeah yeah.",
                    "label": 0
                },
                {
                    "sent": "So we thought about this because one of the basic ideas and Sophie is that if you find like 10 documents, let's say ever start in England and then you find it 11th he died in Germany.",
                    "label": 1
                },
                {
                    "sent": "You would still believe he died in England.",
                    "label": 0
                },
                {
                    "sent": "But then what if you store?",
                    "label": 0
                },
                {
                    "sent": "He died in England and then you find 1000 documents that he died in Germany.",
                    "label": 0
                },
                {
                    "sent": "So then you would need to revise your knowledge.",
                    "label": 0
                },
                {
                    "sent": "Is this something?",
                    "label": 0
                },
                {
                    "sent": "And in the Sophie approaches you would not need to do that because with Sophie you can compute snapshots.",
                    "label": 0
                },
                {
                    "sent": "So after if your computer.",
                    "label": 0
                },
                {
                    "sent": "Shot after 10 documents you would think he died in England.",
                    "label": 0
                },
                {
                    "sent": "Then you keep gathering patterns to keep gathering data.",
                    "label": 0
                },
                {
                    "sent": "You say no where did he die according to the current knowledge.",
                    "label": 0
                },
                {
                    "sent": "So he runs the FMS algorithm and computes.",
                    "label": 0
                },
                {
                    "sent": "Now it is more likely that he died in Germany and if afterwards you find a million documents he died in the US.",
                    "label": 0
                },
                {
                    "sent": "He did die in the US, then you know he died in the US and it's actually not necessary to prematurely get stuck on one truth.",
                    "label": 0
                },
                {
                    "sent": "But you can keep accumulating and compute the current truth at each each stage.",
                    "label": 0
                },
                {
                    "sent": "OK, thank you very much.",
                    "label": 0
                },
                {
                    "sent": "Again, thank you.",
                    "label": 0
                }
            ]
        }
    }
}