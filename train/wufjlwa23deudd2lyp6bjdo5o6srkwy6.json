{
    "id": "wufjlwa23deudd2lyp6bjdo5o6srkwy6",
    "title": "Optimizing Estimated Loss Reduction for Active Sampling in Rank Learning",
    "info": {
        "author": [
            "Pinar Donmez, Language Technologies Institute, Carnegie Mellon University"
        ],
        "published": "Aug. 29, 2008",
        "recorded": "July 2008",
        "category": [
            "Top->Computer Science->Machine Learning->Learning to Rank"
        ]
    },
    "url": "http://videolectures.net/icml08_donmez_oelr/",
    "segmentation": [
        [
            "So hello everyone, my name is Culloden, Mass, and I will be talking about our work on Active rank learning today and this is a joint work with Jaime Carbonell from Carnegie Mellon University."
        ],
        [
            "So let me first give you a brief outline of my talk.",
            "I will start with the with why we care about active rank learning in the 1st place and we will go over some recent related work in the area and then I will introduce our method which we called the flows and then we will look at some results and finally the."
        ],
        [
            "Version.",
            "So, um.",
            "Rank learning requires last large, large amount of labeled data, but gathering those labeled data is not a is a challenging task because it requires gathering relative orderings over a set of alternatives, and this task can be quite costly, and it also takes a lot of time for a human to manually go over all the items to label them.",
            "And this is.",
            "This is obviously a very extensive effort.",
            "But on the other hand, rank learning has numerous application areas, including documents retrieval, collaborative filtering, product rating and so on.",
            "And in this work today I'll be focusing on document retrieval."
        ],
        [
            "No, um, let me just give you a brief motivation behind our approach and I would like to cite Nicholas Rowan, Andrew Mccallum's Paper in 2001 and they were arguing in this paper that an active learning and optimal active learning should sample instances such that once they are labeled an edit into the training, then this should result in the lowest estimated expected error on the test set, but.",
            "This this requires for each candidate instance it you give it some label and add it into your training and then you train your learning algorithm and you have to do it do this for all possible labels for every candidate and obviously this is a very time consuming task and it is.",
            "It turns out to be very impractical for many rank learning applications since they are typically large scale so.",
            "The natural question we asked is that can we estimate this without actually going through the retraining process and?",
            "We are.",
            "We are trying to estimate this with with using some kind of likelihood of the change in your current hypothesis, and we argue that when this if an instance is resulting in a greater shift in your current hypothesis, we hope that this would lead us to a better, faster convergence to a true hypothesis.",
            "We noted greater shift in the current hypothesis does not always lead to better generalization, but we hope that as more data is sampled.",
            "The effect of outliers would be minimal."
        ],
        [
            "And these are two recent.",
            "Approaches on the on active rank learning.",
            "First one is MoD is called margin based sampling and essentially aversion space reduction technique where the margin is defined assuming that you have scores on the documents on your rank, order them and you look at the score differences between the items in that rank list and the margin is defined as the minimum difference in scores between the items and this algorithm selects the examples with the minimum margin.",
            "And this method is quite simple to implement.",
            "It's very general, but.",
            "It has a disadvantage and it's that you can think of similar items with the same rank label.",
            "They may get assigned very similar scores and they may have the minimal margin, but selecting such instances is not going to help you improve the rank ranking function.",
            "The other relevant work is called divergance based sampling and is similar to query by committee sampling algorithm and selects the instances where two ranking functions maximally disagree and it is a well founded algorithm, but the major disadvantage is that it requires a sufficiently large initial training data to begin with, which is not very practical for large scale."
        ],
        [
            "Ranking applications.",
            "So we proposed to active learning methods, one for rank SVM and the other is for rank boost and I will start with the.",
            "With the one for rank as well, and you can assume that you have a large set of unlabeled sets which is denoted as.",
            "Capital you and you assume that you pick an instance from this set and you give it some label Y.",
            "Obviously you don't know the true label Y, but you just for now assume that you just give it some label from the set of labels and then this.",
            "This example would create pairs with the existing instances in your training set and rank SVM.",
            "It works on the pairs of instances and you can.",
            "You can define the total loss on these new pairs that include this new instance as a sum.",
            "Here where these are the difference vectors by rank, SVM uses and this is the label for this difference vector and it is 1 whenever the first one is ranked above the second one in minus one otherwise, and here we we are focusing on the.",
            "A linear SVM's, so you can think of that ranking function is defined as this one, where the W is the weight vector.",
            "And X Rays are the instances that are already in your training set that have a different label than the Dandle label that you assume for that.",
            "For that instance that you are considering and and is the number of such instances.",
            "So, um."
        ],
        [
            "Let's look at the objective function rank.",
            "SVM tries to minimize.",
            "Then you can write the objective function.",
            "If you were retraining rank SVM on this new and large data, this would be the objective function that you are minimizing.",
            "So this is this is the objective function that your rank SVM algorithm already optimized in the current training set.",
            "So this is like the case, the number of training instances, and this is the margin margin part and you have this extra last term that comes from this.",
            "Additional item and assume that your current ranking solution, let's denoted by W star.",
            "So there are two possible cases that may arise.",
            "One is that W star also minimizes this extra loss, but then.",
            "But then you can.",
            "You can conclude that W star.",
            "X was in your training set your current ranking function would not be different than what you have right now because you already know that W star minimizes this part because that's the current solution.",
            "And if you also assume that W star minimizes this extra loss than double star minimizes the entire thing.",
            "So it means that if X was in your training set to begin with, than your current function would not be different than what you have right now and from an active learning perspective.",
            "Means that this example is useless, because if it was in your training set then nothing would be different, so we only care about the cases where your current solution does not minimize this new loss that you are introducing an you can.",
            "You can denote the minimizer of these nodes of this loss as W head, and you can.",
            "And we are going to look at the difference between W star and W head.",
            "Try to see.",
            "How much you need to update your current hypothesis to compensate for the loss on these new pairs that you just introduced, and you can.",
            "You can take the gradient of this loss.",
            "You can take the derivative with respect to W and you can think of it as if you are doing a gradient descent type algorithm where your starting point is this current hypothesis.",
            "So you can think of it."
        ],
        [
            "You can think of it as like you are substituting W star as the starting point for your gradient descent type algorithm and you are going to look at the magnitude of this derivative and it will tell you how much you need to move from your current position.",
            "Compensate or reduce the loss on these new new pairs.",
            "And, um.",
            "Essentially this this difference, this magnitude of the derivative tells you the ability of this candidate instance to change the current rancor if it was in the training set.",
            "But obviously we we assumed at the beginning some label for this instance, but we need to calculate this derivative for for all possible labels in your in your set and then we have to take the expectation.",
            "And this is the score that we base our selection on and the posterior on the class on the rank label is calculated by fitting sigmoid to the SVM output."
        ],
        [
            "Now all let me switch to.",
            "Our methods for rank boost and essentially the idea is the same.",
            "Again, we try to estimate how the current hypothesis would change or would be different if your candidate instance was added to the training and we we try to estimate this by the ranking loss that are.",
            "That you would get on the new pairs.",
            "Again, you assume that you assume some label to that candidate instance and then you look at the ranking loss on these new pairs and four to calculate the ranking loss we use the distribution that you learn using the current training set by by the rank boost, and this distribution is the final distribution that you would get after your after training the boosting algorithm and the reason why we choose this is becausw.",
            "First, it contains the most updated information on the differential ability of the players and also it can be easily written in terms of the final ranking function that rank bulls outputs.",
            "So this a capital H is the rank boost ranking function."
        ],
        [
            "And we look at the loss on the on the pairs that this candidate instances creating.",
            "So this is your candidate instance.",
            "These are the instances in your training set, and you look at this loss.",
            "And again, if this loss was zero, then it means that your ranking function already correctly labeling those instances.",
            "So again this instance would be useless if this loss was zero, so we only care about the cases where this loss is large.",
            "Because it tells us that you need to.",
            "We need to update our current hypothesis and then again we need to.",
            "We will just assume some label for this candidate instance.",
            "So we need to calculate it for all possible labels.",
            "And again we take the expectation and this would be our selection criteria."
        ],
        [
            "So to talk about the experimental settings we we used.",
            "2003 and 2004 track topic distillation datasets that are publicly available in the little package and those are binary.",
            "Those have binary relevance, so each document has is either relevant or non relevant.",
            "And the 2003 data has 50 queries, the other one has 75 and each has about 1000 documents per query and you can see here the relevance ratios.",
            "The number of relevant documents in the set and.",
            "These datasets come comes with already defined training testing supplies, so we use them in our in our experiments and to start with we picked 16 documents per query where only one of them is relevant and the others are non relevant and at each iteration we select five documents.",
            "The five documents that the top five documents according to our selection score and we repeat this for 25 iterations."
        ],
        [
            "And for the performance measures we used one of the two of the most commonly used by our metrics.",
            "One is the nearest precision and the other one is normalized discounted cumulative gain.",
            "An average precision is like the you calculate the precision at every rank position, and then you divide divide the sum by the total number of relevant documents and map is just your average term for for all queries for N DCG.",
            "The impact of each each item each item contributes to the game, but the gain is just discounted by the rank position, so it is this proportional to the positioning."
        ],
        [
            "Rank so these are the results on track.",
            "2003 data.",
            "I need to fix so the left column is the results on rank SVM and right column on rank boost and in each figure our our algorithm is the solid curve and we compare our algorithm against random sampling and margin based sampling where random sampling is the dotted one margin is the dashed curve.",
            "The X axis shows the number of iterations and the Y axis shows the performance metric that we are using and horizontal line in each figure corresponds to the performance you would get if you use the entire training set."
        ],
        [
            "And let's look at the results on track 2004.",
            "Again, our method has a faster learning rate compared to the other ones, and these results are significant and there is an interesting case here on rank SVM you see that we are actually exceeding the performance you would get if you use the entire training set initially.",
            "This is a surprising result, but you can one of the main reasons is that.",
            "Um?",
            "This data is very skewed.",
            "It says like relevance number of relevant documents is below 1% and then we actively sampled.",
            "We are sampling.",
            "We have less amount of data but the data is more balanced compared to the compared to the whole training set so.",
            "Apparently ranks does not do so well when the vendors are large skill in your training set."
        ],
        [
            "So to summarize the results we have seen that our method performs outperforms the baselines significantly, outperforms the baselines, and especially achieves 30% relative improvement over the margin based sampling on track 2003 datasets, and then when we use rank SVM we can reach the performance you would get if you use the entire training set after about 10 rounds which correspond to.",
            "Actively sampling 50 documents per query and this makes in total we have about 15% of the data as labeled data and for rank boost we can reach 9095% of the performance after that many rounds."
        ],
        [
            "And to wrap up, so we just introduce an active learning framework for rank learning.",
            "And even though we use rank SVM and rank boost, you can generalize it to other rank ranking algorithms as long as you based you based on your sampling on selecting the instances with expected with the largest expected loss differential and we have.",
            "Experimental results show us that we have a faster Lord learning rate compared to the baselines and as feature work we plan to focus on algorithms while you try to directly optimize the performance metric that you are using and also it would be.",
            "It would be nice if the algorithms can detect automatically want to stop during the runtime so that you just stop at the at the peak.",
            "That you are reaching."
        ],
        [
            "So that's all I wanted to say today.",
            "Thank you for listening.",
            "Questions.",
            "What was the actual?",
            "During the training.",
            "We start with one relevant and 15 non relevant initially per per query.",
            "And in the training set, the relevance ratio is .6% in the entire training set.",
            "Yeah.",
            "For the test set or what is the prevalence in the test set?",
            "In the test set, I don't remember the exact numbers off the top of my head, but test set is a little bit smaller than the training set, but the person to just.",
            "Are a little bit.",
            "In terms of percentages, is a little bit better than the training set, but I should look at the exact numbers to give you a better concrete answer.",
            "Makes sense.",
            "The extra last term.",
            "Whether to add something like the distance between the permutations of order of stay unseen examples as opposed to the difference.",
            "Maybe the error invented?",
            "So.",
            "I see so you are suggesting to look at the distance in the permutations.",
            "When you order the unlabeled instances, but.",
            "What is the criteria that you would be comparing against?",
            "Without OK. Oh, I see I see OK. Um, but in that case you would need to.",
            "So the order would be different.",
            "But then you may need to somehow guess the you may change the orders, but you may be changing the orders of the instances that have the same rank label.",
            "Changes in the lower.",
            "Yeah you can.",
            "Yeah, that's that's one option, but you may.",
            "You may still need to know the rank label so that because you may have two different permutations.",
            "But in terms of the performance metrics that you are using, they might be equivalent because you may be only changing the instances with the same rank label.",
            "And it wouldn't change.",
            "OK, that that might be another alternative to try, definitely.",
            "Any other questions?",
            "So.",
            "Under the empirical results.",
            "You only talked about it, I think.",
            "Trek 2004 the increase.",
            "Yeah.",
            "But it also looks like that happens in in in interact 2013 reasons.",
            "Yeah yeah yeah.",
            "Any other questions?",
            "Yes.",
            "Freeway?",
            "In during the training you mean?",
            "Had all the training data.",
            "Classification.",
            "Um?",
            "So the ranking algorithms works on pairs, so I'm not quite sure how you would weigh the pairs.",
            "I mean why?",
            "Why would some pair would be more important?",
            "Should weigh more than the other pair?",
            "It might.",
            "You may need to do it some other steps in during your training to get the correct weights on those players, obviously.",
            "There is also the case that not every query is also important.",
            "Some queries are more important than the other queries, for instance like in web search, some queries are just factual queries that are easy to come up with the relevant documents, but some are more navigational or longer queries.",
            "More complex, not easy to understand.",
            "The user information need, so you may also need to consider different queries separately because they are more difficult or they're more.",
            "Important for you.",
            "So there is also this tradeoff between the queries and also among the queries.",
            "Some players might be more harder to distinguish.",
            "So it may require some other processing step during your training, but I'm not sure.",
            "I'm not quite sure what that could be."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So hello everyone, my name is Culloden, Mass, and I will be talking about our work on Active rank learning today and this is a joint work with Jaime Carbonell from Carnegie Mellon University.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So let me first give you a brief outline of my talk.",
                    "label": 0
                },
                {
                    "sent": "I will start with the with why we care about active rank learning in the 1st place and we will go over some recent related work in the area and then I will introduce our method which we called the flows and then we will look at some results and finally the.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Version.",
                    "label": 0
                },
                {
                    "sent": "So, um.",
                    "label": 0
                },
                {
                    "sent": "Rank learning requires last large, large amount of labeled data, but gathering those labeled data is not a is a challenging task because it requires gathering relative orderings over a set of alternatives, and this task can be quite costly, and it also takes a lot of time for a human to manually go over all the items to label them.",
                    "label": 1
                },
                {
                    "sent": "And this is.",
                    "label": 0
                },
                {
                    "sent": "This is obviously a very extensive effort.",
                    "label": 0
                },
                {
                    "sent": "But on the other hand, rank learning has numerous application areas, including documents retrieval, collaborative filtering, product rating and so on.",
                    "label": 1
                },
                {
                    "sent": "And in this work today I'll be focusing on document retrieval.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "No, um, let me just give you a brief motivation behind our approach and I would like to cite Nicholas Rowan, Andrew Mccallum's Paper in 2001 and they were arguing in this paper that an active learning and optimal active learning should sample instances such that once they are labeled an edit into the training, then this should result in the lowest estimated expected error on the test set, but.",
                    "label": 1
                },
                {
                    "sent": "This this requires for each candidate instance it you give it some label and add it into your training and then you train your learning algorithm and you have to do it do this for all possible labels for every candidate and obviously this is a very time consuming task and it is.",
                    "label": 1
                },
                {
                    "sent": "It turns out to be very impractical for many rank learning applications since they are typically large scale so.",
                    "label": 0
                },
                {
                    "sent": "The natural question we asked is that can we estimate this without actually going through the retraining process and?",
                    "label": 0
                },
                {
                    "sent": "We are.",
                    "label": 1
                },
                {
                    "sent": "We are trying to estimate this with with using some kind of likelihood of the change in your current hypothesis, and we argue that when this if an instance is resulting in a greater shift in your current hypothesis, we hope that this would lead us to a better, faster convergence to a true hypothesis.",
                    "label": 0
                },
                {
                    "sent": "We noted greater shift in the current hypothesis does not always lead to better generalization, but we hope that as more data is sampled.",
                    "label": 0
                },
                {
                    "sent": "The effect of outliers would be minimal.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And these are two recent.",
                    "label": 0
                },
                {
                    "sent": "Approaches on the on active rank learning.",
                    "label": 0
                },
                {
                    "sent": "First one is MoD is called margin based sampling and essentially aversion space reduction technique where the margin is defined assuming that you have scores on the documents on your rank, order them and you look at the score differences between the items in that rank list and the margin is defined as the minimum difference in scores between the items and this algorithm selects the examples with the minimum margin.",
                    "label": 0
                },
                {
                    "sent": "And this method is quite simple to implement.",
                    "label": 1
                },
                {
                    "sent": "It's very general, but.",
                    "label": 0
                },
                {
                    "sent": "It has a disadvantage and it's that you can think of similar items with the same rank label.",
                    "label": 1
                },
                {
                    "sent": "They may get assigned very similar scores and they may have the minimal margin, but selecting such instances is not going to help you improve the rank ranking function.",
                    "label": 0
                },
                {
                    "sent": "The other relevant work is called divergance based sampling and is similar to query by committee sampling algorithm and selects the instances where two ranking functions maximally disagree and it is a well founded algorithm, but the major disadvantage is that it requires a sufficiently large initial training data to begin with, which is not very practical for large scale.",
                    "label": 1
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Ranking applications.",
                    "label": 0
                },
                {
                    "sent": "So we proposed to active learning methods, one for rank SVM and the other is for rank boost and I will start with the.",
                    "label": 0
                },
                {
                    "sent": "With the one for rank as well, and you can assume that you have a large set of unlabeled sets which is denoted as.",
                    "label": 0
                },
                {
                    "sent": "Capital you and you assume that you pick an instance from this set and you give it some label Y.",
                    "label": 0
                },
                {
                    "sent": "Obviously you don't know the true label Y, but you just for now assume that you just give it some label from the set of labels and then this.",
                    "label": 0
                },
                {
                    "sent": "This example would create pairs with the existing instances in your training set and rank SVM.",
                    "label": 0
                },
                {
                    "sent": "It works on the pairs of instances and you can.",
                    "label": 0
                },
                {
                    "sent": "You can define the total loss on these new pairs that include this new instance as a sum.",
                    "label": 1
                },
                {
                    "sent": "Here where these are the difference vectors by rank, SVM uses and this is the label for this difference vector and it is 1 whenever the first one is ranked above the second one in minus one otherwise, and here we we are focusing on the.",
                    "label": 0
                },
                {
                    "sent": "A linear SVM's, so you can think of that ranking function is defined as this one, where the W is the weight vector.",
                    "label": 1
                },
                {
                    "sent": "And X Rays are the instances that are already in your training set that have a different label than the Dandle label that you assume for that.",
                    "label": 1
                },
                {
                    "sent": "For that instance that you are considering and and is the number of such instances.",
                    "label": 0
                },
                {
                    "sent": "So, um.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Let's look at the objective function rank.",
                    "label": 1
                },
                {
                    "sent": "SVM tries to minimize.",
                    "label": 0
                },
                {
                    "sent": "Then you can write the objective function.",
                    "label": 0
                },
                {
                    "sent": "If you were retraining rank SVM on this new and large data, this would be the objective function that you are minimizing.",
                    "label": 0
                },
                {
                    "sent": "So this is this is the objective function that your rank SVM algorithm already optimized in the current training set.",
                    "label": 0
                },
                {
                    "sent": "So this is like the case, the number of training instances, and this is the margin margin part and you have this extra last term that comes from this.",
                    "label": 0
                },
                {
                    "sent": "Additional item and assume that your current ranking solution, let's denoted by W star.",
                    "label": 0
                },
                {
                    "sent": "So there are two possible cases that may arise.",
                    "label": 1
                },
                {
                    "sent": "One is that W star also minimizes this extra loss, but then.",
                    "label": 0
                },
                {
                    "sent": "But then you can.",
                    "label": 0
                },
                {
                    "sent": "You can conclude that W star.",
                    "label": 0
                },
                {
                    "sent": "X was in your training set your current ranking function would not be different than what you have right now because you already know that W star minimizes this part because that's the current solution.",
                    "label": 0
                },
                {
                    "sent": "And if you also assume that W star minimizes this extra loss than double star minimizes the entire thing.",
                    "label": 0
                },
                {
                    "sent": "So it means that if X was in your training set to begin with, than your current function would not be different than what you have right now and from an active learning perspective.",
                    "label": 0
                },
                {
                    "sent": "Means that this example is useless, because if it was in your training set then nothing would be different, so we only care about the cases where your current solution does not minimize this new loss that you are introducing an you can.",
                    "label": 0
                },
                {
                    "sent": "You can denote the minimizer of these nodes of this loss as W head, and you can.",
                    "label": 0
                },
                {
                    "sent": "And we are going to look at the difference between W star and W head.",
                    "label": 0
                },
                {
                    "sent": "Try to see.",
                    "label": 0
                },
                {
                    "sent": "How much you need to update your current hypothesis to compensate for the loss on these new pairs that you just introduced, and you can.",
                    "label": 0
                },
                {
                    "sent": "You can take the gradient of this loss.",
                    "label": 0
                },
                {
                    "sent": "You can take the derivative with respect to W and you can think of it as if you are doing a gradient descent type algorithm where your starting point is this current hypothesis.",
                    "label": 0
                },
                {
                    "sent": "So you can think of it.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "You can think of it as like you are substituting W star as the starting point for your gradient descent type algorithm and you are going to look at the magnitude of this derivative and it will tell you how much you need to move from your current position.",
                    "label": 0
                },
                {
                    "sent": "Compensate or reduce the loss on these new new pairs.",
                    "label": 0
                },
                {
                    "sent": "And, um.",
                    "label": 0
                },
                {
                    "sent": "Essentially this this difference, this magnitude of the derivative tells you the ability of this candidate instance to change the current rancor if it was in the training set.",
                    "label": 1
                },
                {
                    "sent": "But obviously we we assumed at the beginning some label for this instance, but we need to calculate this derivative for for all possible labels in your in your set and then we have to take the expectation.",
                    "label": 0
                },
                {
                    "sent": "And this is the score that we base our selection on and the posterior on the class on the rank label is calculated by fitting sigmoid to the SVM output.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now all let me switch to.",
                    "label": 0
                },
                {
                    "sent": "Our methods for rank boost and essentially the idea is the same.",
                    "label": 0
                },
                {
                    "sent": "Again, we try to estimate how the current hypothesis would change or would be different if your candidate instance was added to the training and we we try to estimate this by the ranking loss that are.",
                    "label": 1
                },
                {
                    "sent": "That you would get on the new pairs.",
                    "label": 0
                },
                {
                    "sent": "Again, you assume that you assume some label to that candidate instance and then you look at the ranking loss on these new pairs and four to calculate the ranking loss we use the distribution that you learn using the current training set by by the rank boost, and this distribution is the final distribution that you would get after your after training the boosting algorithm and the reason why we choose this is becausw.",
                    "label": 0
                },
                {
                    "sent": "First, it contains the most updated information on the differential ability of the players and also it can be easily written in terms of the final ranking function that rank bulls outputs.",
                    "label": 0
                },
                {
                    "sent": "So this a capital H is the rank boost ranking function.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And we look at the loss on the on the pairs that this candidate instances creating.",
                    "label": 1
                },
                {
                    "sent": "So this is your candidate instance.",
                    "label": 0
                },
                {
                    "sent": "These are the instances in your training set, and you look at this loss.",
                    "label": 0
                },
                {
                    "sent": "And again, if this loss was zero, then it means that your ranking function already correctly labeling those instances.",
                    "label": 0
                },
                {
                    "sent": "So again this instance would be useless if this loss was zero, so we only care about the cases where this loss is large.",
                    "label": 0
                },
                {
                    "sent": "Because it tells us that you need to.",
                    "label": 0
                },
                {
                    "sent": "We need to update our current hypothesis and then again we need to.",
                    "label": 0
                },
                {
                    "sent": "We will just assume some label for this candidate instance.",
                    "label": 0
                },
                {
                    "sent": "So we need to calculate it for all possible labels.",
                    "label": 0
                },
                {
                    "sent": "And again we take the expectation and this would be our selection criteria.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So to talk about the experimental settings we we used.",
                    "label": 0
                },
                {
                    "sent": "2003 and 2004 track topic distillation datasets that are publicly available in the little package and those are binary.",
                    "label": 1
                },
                {
                    "sent": "Those have binary relevance, so each document has is either relevant or non relevant.",
                    "label": 0
                },
                {
                    "sent": "And the 2003 data has 50 queries, the other one has 75 and each has about 1000 documents per query and you can see here the relevance ratios.",
                    "label": 0
                },
                {
                    "sent": "The number of relevant documents in the set and.",
                    "label": 0
                },
                {
                    "sent": "These datasets come comes with already defined training testing supplies, so we use them in our in our experiments and to start with we picked 16 documents per query where only one of them is relevant and the others are non relevant and at each iteration we select five documents.",
                    "label": 0
                },
                {
                    "sent": "The five documents that the top five documents according to our selection score and we repeat this for 25 iterations.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And for the performance measures we used one of the two of the most commonly used by our metrics.",
                    "label": 0
                },
                {
                    "sent": "One is the nearest precision and the other one is normalized discounted cumulative gain.",
                    "label": 1
                },
                {
                    "sent": "An average precision is like the you calculate the precision at every rank position, and then you divide divide the sum by the total number of relevant documents and map is just your average term for for all queries for N DCG.",
                    "label": 1
                },
                {
                    "sent": "The impact of each each item each item contributes to the game, but the gain is just discounted by the rank position, so it is this proportional to the positioning.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Rank so these are the results on track.",
                    "label": 1
                },
                {
                    "sent": "2003 data.",
                    "label": 0
                },
                {
                    "sent": "I need to fix so the left column is the results on rank SVM and right column on rank boost and in each figure our our algorithm is the solid curve and we compare our algorithm against random sampling and margin based sampling where random sampling is the dotted one margin is the dashed curve.",
                    "label": 0
                },
                {
                    "sent": "The X axis shows the number of iterations and the Y axis shows the performance metric that we are using and horizontal line in each figure corresponds to the performance you would get if you use the entire training set.",
                    "label": 1
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And let's look at the results on track 2004.",
                    "label": 0
                },
                {
                    "sent": "Again, our method has a faster learning rate compared to the other ones, and these results are significant and there is an interesting case here on rank SVM you see that we are actually exceeding the performance you would get if you use the entire training set initially.",
                    "label": 0
                },
                {
                    "sent": "This is a surprising result, but you can one of the main reasons is that.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "This data is very skewed.",
                    "label": 0
                },
                {
                    "sent": "It says like relevance number of relevant documents is below 1% and then we actively sampled.",
                    "label": 0
                },
                {
                    "sent": "We are sampling.",
                    "label": 0
                },
                {
                    "sent": "We have less amount of data but the data is more balanced compared to the compared to the whole training set so.",
                    "label": 0
                },
                {
                    "sent": "Apparently ranks does not do so well when the vendors are large skill in your training set.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So to summarize the results we have seen that our method performs outperforms the baselines significantly, outperforms the baselines, and especially achieves 30% relative improvement over the margin based sampling on track 2003 datasets, and then when we use rank SVM we can reach the performance you would get if you use the entire training set after about 10 rounds which correspond to.",
                    "label": 0
                },
                {
                    "sent": "Actively sampling 50 documents per query and this makes in total we have about 15% of the data as labeled data and for rank boost we can reach 9095% of the performance after that many rounds.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And to wrap up, so we just introduce an active learning framework for rank learning.",
                    "label": 1
                },
                {
                    "sent": "And even though we use rank SVM and rank boost, you can generalize it to other rank ranking algorithms as long as you based you based on your sampling on selecting the instances with expected with the largest expected loss differential and we have.",
                    "label": 1
                },
                {
                    "sent": "Experimental results show us that we have a faster Lord learning rate compared to the baselines and as feature work we plan to focus on algorithms while you try to directly optimize the performance metric that you are using and also it would be.",
                    "label": 1
                },
                {
                    "sent": "It would be nice if the algorithms can detect automatically want to stop during the runtime so that you just stop at the at the peak.",
                    "label": 0
                },
                {
                    "sent": "That you are reaching.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So that's all I wanted to say today.",
                    "label": 0
                },
                {
                    "sent": "Thank you for listening.",
                    "label": 0
                },
                {
                    "sent": "Questions.",
                    "label": 0
                },
                {
                    "sent": "What was the actual?",
                    "label": 0
                },
                {
                    "sent": "During the training.",
                    "label": 0
                },
                {
                    "sent": "We start with one relevant and 15 non relevant initially per per query.",
                    "label": 0
                },
                {
                    "sent": "And in the training set, the relevance ratio is .6% in the entire training set.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "For the test set or what is the prevalence in the test set?",
                    "label": 0
                },
                {
                    "sent": "In the test set, I don't remember the exact numbers off the top of my head, but test set is a little bit smaller than the training set, but the person to just.",
                    "label": 0
                },
                {
                    "sent": "Are a little bit.",
                    "label": 0
                },
                {
                    "sent": "In terms of percentages, is a little bit better than the training set, but I should look at the exact numbers to give you a better concrete answer.",
                    "label": 0
                },
                {
                    "sent": "Makes sense.",
                    "label": 0
                },
                {
                    "sent": "The extra last term.",
                    "label": 0
                },
                {
                    "sent": "Whether to add something like the distance between the permutations of order of stay unseen examples as opposed to the difference.",
                    "label": 0
                },
                {
                    "sent": "Maybe the error invented?",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "I see so you are suggesting to look at the distance in the permutations.",
                    "label": 0
                },
                {
                    "sent": "When you order the unlabeled instances, but.",
                    "label": 0
                },
                {
                    "sent": "What is the criteria that you would be comparing against?",
                    "label": 0
                },
                {
                    "sent": "Without OK. Oh, I see I see OK. Um, but in that case you would need to.",
                    "label": 0
                },
                {
                    "sent": "So the order would be different.",
                    "label": 0
                },
                {
                    "sent": "But then you may need to somehow guess the you may change the orders, but you may be changing the orders of the instances that have the same rank label.",
                    "label": 0
                },
                {
                    "sent": "Changes in the lower.",
                    "label": 0
                },
                {
                    "sent": "Yeah you can.",
                    "label": 0
                },
                {
                    "sent": "Yeah, that's that's one option, but you may.",
                    "label": 0
                },
                {
                    "sent": "You may still need to know the rank label so that because you may have two different permutations.",
                    "label": 0
                },
                {
                    "sent": "But in terms of the performance metrics that you are using, they might be equivalent because you may be only changing the instances with the same rank label.",
                    "label": 0
                },
                {
                    "sent": "And it wouldn't change.",
                    "label": 0
                },
                {
                    "sent": "OK, that that might be another alternative to try, definitely.",
                    "label": 0
                },
                {
                    "sent": "Any other questions?",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Under the empirical results.",
                    "label": 0
                },
                {
                    "sent": "You only talked about it, I think.",
                    "label": 0
                },
                {
                    "sent": "Trek 2004 the increase.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "But it also looks like that happens in in in interact 2013 reasons.",
                    "label": 0
                },
                {
                    "sent": "Yeah yeah yeah.",
                    "label": 0
                },
                {
                    "sent": "Any other questions?",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "Freeway?",
                    "label": 0
                },
                {
                    "sent": "In during the training you mean?",
                    "label": 0
                },
                {
                    "sent": "Had all the training data.",
                    "label": 0
                },
                {
                    "sent": "Classification.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "So the ranking algorithms works on pairs, so I'm not quite sure how you would weigh the pairs.",
                    "label": 0
                },
                {
                    "sent": "I mean why?",
                    "label": 0
                },
                {
                    "sent": "Why would some pair would be more important?",
                    "label": 0
                },
                {
                    "sent": "Should weigh more than the other pair?",
                    "label": 0
                },
                {
                    "sent": "It might.",
                    "label": 0
                },
                {
                    "sent": "You may need to do it some other steps in during your training to get the correct weights on those players, obviously.",
                    "label": 0
                },
                {
                    "sent": "There is also the case that not every query is also important.",
                    "label": 0
                },
                {
                    "sent": "Some queries are more important than the other queries, for instance like in web search, some queries are just factual queries that are easy to come up with the relevant documents, but some are more navigational or longer queries.",
                    "label": 0
                },
                {
                    "sent": "More complex, not easy to understand.",
                    "label": 0
                },
                {
                    "sent": "The user information need, so you may also need to consider different queries separately because they are more difficult or they're more.",
                    "label": 0
                },
                {
                    "sent": "Important for you.",
                    "label": 0
                },
                {
                    "sent": "So there is also this tradeoff between the queries and also among the queries.",
                    "label": 0
                },
                {
                    "sent": "Some players might be more harder to distinguish.",
                    "label": 0
                },
                {
                    "sent": "So it may require some other processing step during your training, but I'm not sure.",
                    "label": 0
                },
                {
                    "sent": "I'm not quite sure what that could be.",
                    "label": 0
                }
            ]
        }
    }
}