{
    "id": "75ins6irmyow6iwvnngsbkn4g7q2rvst",
    "title": "Semantic-Based Process Analysis",
    "info": {
        "author": [
            "Mauro Dragoni, Fondazione Bruno Kessler"
        ],
        "published": "Dec. 19, 2014",
        "recorded": "October 2014",
        "category": [
            "Top->Computer Science->Semantic Web"
        ]
    },
    "url": "http://videolectures.net/iswc2014_dragoni_process_analysis/",
    "segmentation": [
        [
            "So good afternoon to everybody I'm out.",
            "I'm only maybe all of you already know me.",
            "It's another way.",
            "And then today I will present the work that we've done in collaboration like that have done in collaboration with my colleague in FBC and also with the people from the same service company in Trento in the context of our local project called Promo.",
            "So our."
        ],
        [
            "Our main goal was to abstract analytical knowledge of concerning the performances of business processes starting from the collection of data format systems and for doing this we have three main challenges that we have to address.",
            "The first one is to combine three different dimensions.",
            "The procedural dimensions that describes the particular models that we have in our domain, that basically consisting, for example, of analyzing if the execution of the process passes through a particular path or no.",
            "The second dimension is the domain of interest, that is, that contains all information concerning our domain, the domain in which the procedure and the procedural are deployed, and then the third dimension, that is, the execution dimension that contains all the data concerning the traces and the information that we collect from the systems.",
            "Then the second challenger is the semantic reasoning becausw from the data we are allowed, we are allowed only to have a partial view of our business process.",
            "But we know that a lot of information that can be inferred from from visitors.",
            "So we need to apply reasoning approaches in order to infer this this information and materialize them into our system.",
            "While our third challenge is the scalability because in complex and coping complex organization we need.",
            "To manage data data produced at faster, faster rate and we need to implement the system that is able to manage these disease scenario."
        ],
        [
            "So we asked ourselves if semantic web technologies allow us to address such challenges.",
            "So by considering that we are here, the answer we given out an answer close ourself that is yes and this is how we have addressed each.",
            "Each challenge is the first one.",
            "It would have been addressed by developing semantic web models by using the Outlander DF models for presenting information of each domain.",
            "Anusa sparkle queries for training data.",
            "The second challenge has been addressed by implementing our reasoning for inferring information and knowledge from our data, and then the third challenge has been addressed by implementing and after an architecture based on the use on paper stores be cause their system that they are able to manage and huge quantity of data and those two appliances to perform a rezoning on them."
        ],
        [
            "This is an outline of what I will show now, just representation of which was our UK is in this.",
            "In this worker the model that we proposed that architecture that we implement and then the evaluation that that we perform."
        ],
        [
            "This is a process that we took into account in this in this work that represents the generation of the documents concerning the birth management process of the Italian Public Administration, and here I don't will not go into the detail of the process, but it is represented by using the PMN notation and considering the load of the system in about this process we estimated to have.",
            "Mloda of around 1/2 million of traces in a year.",
            "So the peculiarity of this model is that."
        ],
        [
            "Besides the dynamic execution of the of the process, we also have a lot of static representation of data, in particular the representation of the of the documents and in our model we have a strong interactions between the dynamic part, that is the procedural knowledge and then the static path.",
            "That is the way with which the documents are represented."
        ],
        [
            "The first, our first goal was to reconcile all our knowledge because we have these three different noise that I that I explain early, early and our knowledge is split into different levels.",
            "The first one is the business level that contains both the procedural and the domain knowledge, and then we have the data level that contains all the traces that we collect.",
            "So the first the first thing to do is to align the procedural.",
            "And the domain knowledge and then to create alignment between the data that we collect from the system with the information that we have at the business level.",
            "For doing this."
        ],
        [
            "We have we have to use different ontologies.",
            "The first one is the VPN ontology that isn't all that represent each element of the BPM.",
            "An standard then we use."
        ],
        [
            "The domain Ontology, this domain and it is on target.",
            "We define for the domain that we have to analyze that contains a core part that is the one that we have here in this picture, and then this one charges is extended based on the domain on which it is a it is applied and."
        ],
        [
            "And we have iteration teologi that contains only information contact regarding the execution of the of the audit process.",
            "For example, flows element, timestamps and things like this."
        ],
        [
            "And in this picture we have an idea of how these ontologies have been used into into our model.",
            "We have at the bottom at the bottom of the model we have all the information concerning concerning the hour to consider our data.",
            "Then we have a middle layer model in which we have the definition of all processes of our domain and then we have at the middle level the three ontologies that I've just presented and for that race and for the ontology we have both the core version of the.",
            "And then their extension that is used based on the domain.",
            "This level is Monday is a is a is constant with respect it.",
            "Sorry is still I mean I mean the same in dependently of the of the processes that we have at the middle layer."
        ],
        [
            "The second goal was to implement an architecture that was able to address our challenges and the things that we have to address mainly was to collect that we have to invent something that is able to collect data at fast rate, and then that is able to answer to complex queries.",
            "So our implementation, our implement solution was based on the triple stores, for the reasons that that I've shown that explaining so sorry.",
            "Early."
        ],
        [
            "And how these data are organized, populated and started from our systems.",
            "So first of all we have the finest central tripod store in which we store all information concerning the process model and all information concerning our trace data differ in each of the graphs we stored both the explicit information that we have from our model and then the the materialization of the implicit information that we had.",
            "We obtain after the performance of reasoning activities on our data."
        ],
        [
            "Then, concerning the population of our model for the process model, once we have defined it, we stalling for me or all explicit information into a temporary inferencing triple store and on this we perform reasoning activity for for obtaining a materialization of typos that we use for augmenting the information of the process model and one once the system is started we store.",
            "All this information also in the Central Triple Store and still remain independent during the execution of the order system.",
            "Then each time Trace update is triggered, we store all information concerning the trace into a temporary tribal store together with the information coming from the process.",
            "Then we perform in reasoning activity in order to augment also information that we have about the tracer and then we store the trace.",
            "Into the Central typo store.",
            "Here we use different name graphs for each, for each.",
            "For each trace.",
            "This way we allowed to perform the store operation very quickly and that still remain constant through time, in dependently by the load of the system.",
            "However, we have better back that we cannot do inferencing inferences intertribal's, but it was into requested by our use cases, so we it wasn't a. I mean, it wasn't an issue on our point of view.",
            "For full"
        ],
        [
            "Our point of view, and then considering closing the query we perform sparkle queries on the Central Tripod store and we are a toaster result to our user we.",
            "Use a lot of aggregates operator in order to have a lot of even to satisfy the analytical queries performed by user and we implemented also some extensions on the on the on our approach in order to.",
            "To provide the more notice to make the system able to answer to more complex queries, for example to computing upset type between timestamp, timestamps and things like this.",
            "So."
        ],
        [
            "Then we perform the evaluation of our project here.",
            "That details of of our processor, the number of the classes and activities on the domain, and the set of the execution traces that that we use for our experiment."
        ],
        [
            "In this table we had a subset of the queries that we that we used that we measured just for showing how so just to show which kind of interactions and reconciliation knowledge we need on different kind of queries.",
            "And then concerning."
        ],
        [
            "Performance on this system we consider the three different load of the our system."
        ],
        [
            "And the number of traces loaded in one day in one week, and so serving in yes one day, one week and one month.",
            "Then for these traces we measured."
        ],
        [
            "Which is the throughput of the system.",
            "That, as expected, still remains constant thanks to the fact that we performing inference is independent on each on each trace and then."
        ],
        [
            "We took into account two different queries, one analytical analytical queries and query and one that is more selective, and we've seen that in dependently from the load of the system then response time of our engines dealer email acceptable for a real time usage.",
            "So."
        ],
        [
            "Which are the lessons that we learn from our experiences for experience?",
            "Basically, we've seen that thanks to the possibility of performing dependently independent reasoning on the traces, we were able to have a high scalability of our system that is very positive positive aspect for our power pods project.",
            "And then I'm quite sure that all of you visited our demo last Tuesday about this this system because I've seen all of you.",
            "And you will be.",
            "You were able to see which is which are the interfaces that we implement in order to allow people with the low expertise to represent modeling.",
            "The process is to define the structure of the document and also to define which are the peas that are used for querying the system and the feedback that we received from people involved in the in our experiment was basically that even if the system is could be.",
            "Easy to use for presenting data.",
            "Sometimes we need to provide more.",
            "Useful facilities, especially for modeling the KPI and because the template that we provide wasn't enough to allow people with low expertise in semantic web technology technologies in particular concerning this particular query.",
            "To build any kind of kepis existing from besides the one that you allowed to be by using the templates that will provide."
        ],
        [
            "OK, so thank you very much.",
            "Are there any questions?",
            "So I was wondering if you have done or if you intend to do some comparison between your approach and the approach from the process mining community, which are exactly the same goal to analyze process traces.",
            "And they also did some work in extending their tools in a semantic direction.",
            "No, we did.",
            "We didn't perform this.",
            "Did this comparison?",
            "I mean you think is an interesting point.",
            "I mean for this is from this point of view, it could be a good thing to do.",
            "Maybe I mean by consider that was an experienced a very sort of applied research.",
            "We didn't have time for doing this.",
            "Not only, but yeah, yeah, absolutely.",
            "If for improving the quality of the output that we obtain by by our work, it's for sure the next step to do.",
            "Like totally agree."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So good afternoon to everybody I'm out.",
                    "label": 0
                },
                {
                    "sent": "I'm only maybe all of you already know me.",
                    "label": 0
                },
                {
                    "sent": "It's another way.",
                    "label": 0
                },
                {
                    "sent": "And then today I will present the work that we've done in collaboration like that have done in collaboration with my colleague in FBC and also with the people from the same service company in Trento in the context of our local project called Promo.",
                    "label": 1
                },
                {
                    "sent": "So our.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Our main goal was to abstract analytical knowledge of concerning the performances of business processes starting from the collection of data format systems and for doing this we have three main challenges that we have to address.",
                    "label": 1
                },
                {
                    "sent": "The first one is to combine three different dimensions.",
                    "label": 1
                },
                {
                    "sent": "The procedural dimensions that describes the particular models that we have in our domain, that basically consisting, for example, of analyzing if the execution of the process passes through a particular path or no.",
                    "label": 0
                },
                {
                    "sent": "The second dimension is the domain of interest, that is, that contains all information concerning our domain, the domain in which the procedure and the procedural are deployed, and then the third dimension, that is, the execution dimension that contains all the data concerning the traces and the information that we collect from the systems.",
                    "label": 1
                },
                {
                    "sent": "Then the second challenger is the semantic reasoning becausw from the data we are allowed, we are allowed only to have a partial view of our business process.",
                    "label": 0
                },
                {
                    "sent": "But we know that a lot of information that can be inferred from from visitors.",
                    "label": 0
                },
                {
                    "sent": "So we need to apply reasoning approaches in order to infer this this information and materialize them into our system.",
                    "label": 0
                },
                {
                    "sent": "While our third challenge is the scalability because in complex and coping complex organization we need.",
                    "label": 0
                },
                {
                    "sent": "To manage data data produced at faster, faster rate and we need to implement the system that is able to manage these disease scenario.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we asked ourselves if semantic web technologies allow us to address such challenges.",
                    "label": 0
                },
                {
                    "sent": "So by considering that we are here, the answer we given out an answer close ourself that is yes and this is how we have addressed each.",
                    "label": 0
                },
                {
                    "sent": "Each challenge is the first one.",
                    "label": 0
                },
                {
                    "sent": "It would have been addressed by developing semantic web models by using the Outlander DF models for presenting information of each domain.",
                    "label": 0
                },
                {
                    "sent": "Anusa sparkle queries for training data.",
                    "label": 0
                },
                {
                    "sent": "The second challenge has been addressed by implementing our reasoning for inferring information and knowledge from our data, and then the third challenge has been addressed by implementing and after an architecture based on the use on paper stores be cause their system that they are able to manage and huge quantity of data and those two appliances to perform a rezoning on them.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is an outline of what I will show now, just representation of which was our UK is in this.",
                    "label": 0
                },
                {
                    "sent": "In this worker the model that we proposed that architecture that we implement and then the evaluation that that we perform.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is a process that we took into account in this in this work that represents the generation of the documents concerning the birth management process of the Italian Public Administration, and here I don't will not go into the detail of the process, but it is represented by using the PMN notation and considering the load of the system in about this process we estimated to have.",
                    "label": 0
                },
                {
                    "sent": "Mloda of around 1/2 million of traces in a year.",
                    "label": 0
                },
                {
                    "sent": "So the peculiarity of this model is that.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Besides the dynamic execution of the of the process, we also have a lot of static representation of data, in particular the representation of the of the documents and in our model we have a strong interactions between the dynamic part, that is the procedural knowledge and then the static path.",
                    "label": 0
                },
                {
                    "sent": "That is the way with which the documents are represented.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The first, our first goal was to reconcile all our knowledge because we have these three different noise that I that I explain early, early and our knowledge is split into different levels.",
                    "label": 0
                },
                {
                    "sent": "The first one is the business level that contains both the procedural and the domain knowledge, and then we have the data level that contains all the traces that we collect.",
                    "label": 1
                },
                {
                    "sent": "So the first the first thing to do is to align the procedural.",
                    "label": 0
                },
                {
                    "sent": "And the domain knowledge and then to create alignment between the data that we collect from the system with the information that we have at the business level.",
                    "label": 0
                },
                {
                    "sent": "For doing this.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We have we have to use different ontologies.",
                    "label": 0
                },
                {
                    "sent": "The first one is the VPN ontology that isn't all that represent each element of the BPM.",
                    "label": 0
                },
                {
                    "sent": "An standard then we use.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The domain Ontology, this domain and it is on target.",
                    "label": 0
                },
                {
                    "sent": "We define for the domain that we have to analyze that contains a core part that is the one that we have here in this picture, and then this one charges is extended based on the domain on which it is a it is applied and.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we have iteration teologi that contains only information contact regarding the execution of the of the audit process.",
                    "label": 0
                },
                {
                    "sent": "For example, flows element, timestamps and things like this.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And in this picture we have an idea of how these ontologies have been used into into our model.",
                    "label": 0
                },
                {
                    "sent": "We have at the bottom at the bottom of the model we have all the information concerning concerning the hour to consider our data.",
                    "label": 0
                },
                {
                    "sent": "Then we have a middle layer model in which we have the definition of all processes of our domain and then we have at the middle level the three ontologies that I've just presented and for that race and for the ontology we have both the core version of the.",
                    "label": 0
                },
                {
                    "sent": "And then their extension that is used based on the domain.",
                    "label": 0
                },
                {
                    "sent": "This level is Monday is a is a is constant with respect it.",
                    "label": 0
                },
                {
                    "sent": "Sorry is still I mean I mean the same in dependently of the of the processes that we have at the middle layer.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The second goal was to implement an architecture that was able to address our challenges and the things that we have to address mainly was to collect that we have to invent something that is able to collect data at fast rate, and then that is able to answer to complex queries.",
                    "label": 0
                },
                {
                    "sent": "So our implementation, our implement solution was based on the triple stores, for the reasons that that I've shown that explaining so sorry.",
                    "label": 0
                },
                {
                    "sent": "Early.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And how these data are organized, populated and started from our systems.",
                    "label": 0
                },
                {
                    "sent": "So first of all we have the finest central tripod store in which we store all information concerning the process model and all information concerning our trace data differ in each of the graphs we stored both the explicit information that we have from our model and then the the materialization of the implicit information that we had.",
                    "label": 0
                },
                {
                    "sent": "We obtain after the performance of reasoning activities on our data.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Then, concerning the population of our model for the process model, once we have defined it, we stalling for me or all explicit information into a temporary inferencing triple store and on this we perform reasoning activity for for obtaining a materialization of typos that we use for augmenting the information of the process model and one once the system is started we store.",
                    "label": 0
                },
                {
                    "sent": "All this information also in the Central Triple Store and still remain independent during the execution of the order system.",
                    "label": 0
                },
                {
                    "sent": "Then each time Trace update is triggered, we store all information concerning the trace into a temporary tribal store together with the information coming from the process.",
                    "label": 0
                },
                {
                    "sent": "Then we perform in reasoning activity in order to augment also information that we have about the tracer and then we store the trace.",
                    "label": 0
                },
                {
                    "sent": "Into the Central typo store.",
                    "label": 0
                },
                {
                    "sent": "Here we use different name graphs for each, for each.",
                    "label": 0
                },
                {
                    "sent": "For each trace.",
                    "label": 0
                },
                {
                    "sent": "This way we allowed to perform the store operation very quickly and that still remain constant through time, in dependently by the load of the system.",
                    "label": 0
                },
                {
                    "sent": "However, we have better back that we cannot do inferencing inferences intertribal's, but it was into requested by our use cases, so we it wasn't a. I mean, it wasn't an issue on our point of view.",
                    "label": 0
                },
                {
                    "sent": "For full",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Our point of view, and then considering closing the query we perform sparkle queries on the Central Tripod store and we are a toaster result to our user we.",
                    "label": 0
                },
                {
                    "sent": "Use a lot of aggregates operator in order to have a lot of even to satisfy the analytical queries performed by user and we implemented also some extensions on the on the on our approach in order to.",
                    "label": 0
                },
                {
                    "sent": "To provide the more notice to make the system able to answer to more complex queries, for example to computing upset type between timestamp, timestamps and things like this.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Then we perform the evaluation of our project here.",
                    "label": 0
                },
                {
                    "sent": "That details of of our processor, the number of the classes and activities on the domain, and the set of the execution traces that that we use for our experiment.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In this table we had a subset of the queries that we that we used that we measured just for showing how so just to show which kind of interactions and reconciliation knowledge we need on different kind of queries.",
                    "label": 0
                },
                {
                    "sent": "And then concerning.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Performance on this system we consider the three different load of the our system.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And the number of traces loaded in one day in one week, and so serving in yes one day, one week and one month.",
                    "label": 0
                },
                {
                    "sent": "Then for these traces we measured.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Which is the throughput of the system.",
                    "label": 0
                },
                {
                    "sent": "That, as expected, still remains constant thanks to the fact that we performing inference is independent on each on each trace and then.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We took into account two different queries, one analytical analytical queries and query and one that is more selective, and we've seen that in dependently from the load of the system then response time of our engines dealer email acceptable for a real time usage.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Which are the lessons that we learn from our experiences for experience?",
                    "label": 0
                },
                {
                    "sent": "Basically, we've seen that thanks to the possibility of performing dependently independent reasoning on the traces, we were able to have a high scalability of our system that is very positive positive aspect for our power pods project.",
                    "label": 0
                },
                {
                    "sent": "And then I'm quite sure that all of you visited our demo last Tuesday about this this system because I've seen all of you.",
                    "label": 0
                },
                {
                    "sent": "And you will be.",
                    "label": 0
                },
                {
                    "sent": "You were able to see which is which are the interfaces that we implement in order to allow people with the low expertise to represent modeling.",
                    "label": 0
                },
                {
                    "sent": "The process is to define the structure of the document and also to define which are the peas that are used for querying the system and the feedback that we received from people involved in the in our experiment was basically that even if the system is could be.",
                    "label": 0
                },
                {
                    "sent": "Easy to use for presenting data.",
                    "label": 0
                },
                {
                    "sent": "Sometimes we need to provide more.",
                    "label": 0
                },
                {
                    "sent": "Useful facilities, especially for modeling the KPI and because the template that we provide wasn't enough to allow people with low expertise in semantic web technology technologies in particular concerning this particular query.",
                    "label": 0
                },
                {
                    "sent": "To build any kind of kepis existing from besides the one that you allowed to be by using the templates that will provide.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so thank you very much.",
                    "label": 0
                },
                {
                    "sent": "Are there any questions?",
                    "label": 0
                },
                {
                    "sent": "So I was wondering if you have done or if you intend to do some comparison between your approach and the approach from the process mining community, which are exactly the same goal to analyze process traces.",
                    "label": 0
                },
                {
                    "sent": "And they also did some work in extending their tools in a semantic direction.",
                    "label": 0
                },
                {
                    "sent": "No, we did.",
                    "label": 0
                },
                {
                    "sent": "We didn't perform this.",
                    "label": 0
                },
                {
                    "sent": "Did this comparison?",
                    "label": 0
                },
                {
                    "sent": "I mean you think is an interesting point.",
                    "label": 0
                },
                {
                    "sent": "I mean for this is from this point of view, it could be a good thing to do.",
                    "label": 0
                },
                {
                    "sent": "Maybe I mean by consider that was an experienced a very sort of applied research.",
                    "label": 0
                },
                {
                    "sent": "We didn't have time for doing this.",
                    "label": 0
                },
                {
                    "sent": "Not only, but yeah, yeah, absolutely.",
                    "label": 0
                },
                {
                    "sent": "If for improving the quality of the output that we obtain by by our work, it's for sure the next step to do.",
                    "label": 0
                },
                {
                    "sent": "Like totally agree.",
                    "label": 0
                }
            ]
        }
    }
}