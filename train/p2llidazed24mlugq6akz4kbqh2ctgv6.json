{
    "id": "p2llidazed24mlugq6akz4kbqh2ctgv6",
    "title": "Poster Spotlights",
    "info": {
        "author": [
            "Simon Baker, Microsoft Research",
            "Yu-Wing Tai, KAIST - Korea Advanced Institute of Science and Technology",
            "David Marimon, Telefonica R&D, Barcelona",
            "Yunpeng Li, Department of Computer Science, Cornell University",
            "Deqing Sun, Computer Science Department, Brown University",
            "Shaojie Zhuo, School of Computing, National University of Singapore",
            "Jingyi Yu, Department of Computer and Information Science, University of Delaware",
            "Xiaohui Shen, Adobe Systems Incorporated",
            "Manuel Werlberger, Institute for Computer Graphics and Vision, Graz University of Technology",
            "Christopher Kanan, Department of Computer Science and Engineering, UC San Diego",
            "Simon Lucey, Carnegie Mellon University",
            "Dhruv Batra, School of Interactive Computing, College of Computing, Georgia Institute of Technology",
            "Kyong Joon Lee, Seoul National University",
            "Ayan Chakrabarti, Harvard School of Engineering and Applied Sciences, Harvard University",
            "Iasonas Kokkinos, Applied Mathematics and Systems Department, \u00c9cole Centrale Paris",
            "Matthew Zeiler, Computer Science Department, New York University (NYU)",
            "Hanno Scharr, Forschungszentrum J\u00fclich",
            "David S. Bolme, Department of Computer Science, Colorado State University",
            "Marc\u2019Aurelio Ranzato, Department of Computer Science, University of Toronto",
            "Y-Lan Boureau, Computer Science Department, New York University (NYU)"
        ],
        "published": "Dec. 3, 2010",
        "recorded": "June 2010",
        "category": [
            "Top->Computer Science->Computer Vision",
            "Top->Computer Science->Machine Learning"
        ]
    },
    "url": "http://videolectures.net/cvpr2010_spotlights8/",
    "segmentation": [
        [
            "OK, here's a camera.",
            "It's a phone that has a rolling shutter camera in it.",
            "This is not a very good one, right?",
            "Here's a good one.",
            "This is a nice camera, but this is still has a rolling."
        ],
        [
            "If I take some video everything is fine, but if I put this in a car or helicopter on a bike and they drive at 100 miles an hour, the camera is doing this and all sorts of crazy things happen.",
            "And as you can see clearly in the videos here, they're completely nuts.",
            "If you see the videos, it's all over the place.",
            "We have an algorithm that works on like the most crazy sequences we could find on the web, and the difference from like all the prior work, is most of the prior work is sort of follows the sort of repeats history from 20 years ago.",
            "Don't use translation using a fine.",
            "Don't use an offline user demography.",
            "Don't use a homography user flow field, but the problem is that all of 30 frames a second.",
            "If I take it, it's basically where did the pixels move from one frame to another.",
            "If the camera is going crazy, you need to move nowhere.",
            "That pixel is moving at 1000 frames a second.",
            "We have an algorithm thanks to very related to Michaela Ronnies work on basically enhancing the freak motion from 30 frames per second motion, optical flow, or translations to 1000 frames per second.",
            "And come see the videos of the poster."
        ],
        [
            "So the title of our paper is supervised Rosen using at pirran single image details synthesis and this work is working with me your entire and."
        ],
        [
            "Ioffer something new and also Michael broadcast evening so are worth.",
            "We basically want to combine the reconstruction based superexcellent algorithm and learning based algorithms so our poetry refers.",
            "We construct the high resolution address using the reconstruction based algorithm and then based on this ash constraint, we sympathize the details using the learning based album and the result is that our results.",
            "It's very good that capture both running base and reconstruction based at least for the supervised losers.",
            "And please come to our poster for discussions."
        ],
        [
            "OK, so this is another paper, so the title is cold exposure imaging for projective motion during I'm doing time and this work is working with legend cost."
        ],
        [
            "Playing an solution.",
            "So this is a new approach for motion moving object during.",
            "Suppose you have a moving hand.",
            "So this is so common and then we use opposed by allowing a user to draw very scribbles that this cripple can provide a great thing for us to estimate the postback functions and we also have a method to accept moving objects over the backwards, while traditional mapping techniques also fails for such kind of method because it has a very similar color for the background and we wish.",
            "We actually use are mostly into segment moving objects and then the final is.",
            "So is, uh, divert resources.",
            "So this is a little approach so please come to our poster for discussions."
        ],
        [
            "Hi, my name is David Merriman and this is joint work with Arturo Bonnin, Thomas Adamek and Regina Ann.",
            "We're presenting darts, which is an official."
        ],
        [
            "On way to extract keypoints in scale space an also use a Daisy layout for the descriptor.",
            "So what we do I'll jump to the results, which is the nice part.",
            "We obtained similar battery results as compared to sit and surf and we are six times faster than fifth than three times faster than surface.",
            "The way we do that is that we have obtained a new.",
            "The demonstration approximation by triangle filters that is computed sufficiently another orientation assignment algorithm and also we have done some optimization of the sampling space on the Daisy layout, and it's nice to have results, but it is even better to apply it so we have applied successfully to 3D reconstruction on video sequences captured with a mobile phone.",
            "Also, object tracking tracking by detection type of stuff.",
            "An object recognition from a mobile phone as well.",
            "Visual search, an video copy detection.",
            "So just join me on the basement.",
            "I will be there for your answer.",
            "Thank you."
        ],
        [
            "Hi, my name is Simpang and this is trying to work with Sing Bing Kang, New Joshi Steve Sites and Dan Huttenlocher."
        ],
        [
            "Almost all cameras nowadays can take videos, so an easy way to generate a Panorama is to pander camera around in video mode and then stitch it from the video.",
            "In fact, this is such a useful thing to do that a lot of companies already producing these sort of cameras with this beauty in functionality and they are even advertising it on TV during World Cup games must be very expensive commercial.",
            "But once the commercials didn't tell you, that, is that if you move the camera a little bit too quickly, or if the exposure time is a little bit long, then you're going to get motion blur.",
            "And I'll go is to automatically estimate and remove motion blur.",
            "And in addition, we also able to obtain the camera duty cycles as a byproduct of the dibbler process.",
            "So if you come to our poster will show you how it is done.",
            "It's at G8.",
            "Thank you."
        ],
        [
            "Hello, I'm touching this is joint work with Stephen Ross and Michael Black."
        ],
        [
            "What makes optical flow accurate and why?",
            "130 questions.",
            "We perform an analysis of recent practices in optical flow estimation.",
            "Plastic Plus Plus is directly descended from Holland Shank, yet our implementation produces results very close to the state of the art.",
            "We found the key is to perform median filtering of the flow field during each iterative warping step.",
            "However, we find this median filtering process actually minimizes a different objective with a non local term.",
            "We've done this inside.",
            "We propose an improved method that uses color, motion and occlusion information to better preserve motion details.",
            "This method is currently ranked first in both Angular and endpoint error on the Middlebury optical flow benchmark.",
            "Our method code is freely available online.",
            "Please visit our poster for the detailed list and other tricks that make optical flow accurate.",
            "Thank you."
        ],
        [
            "Hi, my name is target or I'm I'm presenting robust fast diverting is the joint work with Stonewall and turns in from?"
        ],
        [
            "National University of Singapore.",
            "Photo under low light conditions using a handheld camera.",
            "The capture image usually suffer from motion blur caused by camera shake.",
            "So it's challenging to remove motion blur from a single broad image.",
            "In this work we propose.",
            "Novel method for image blurring using its corresponding flash image.",
            "You can see from the image.",
            "We observed that the.",
            "The.",
            "The intensity of sharp image and flash image is quite different from each other.",
            "While the intensity of our gradients of the flash image and sharp image is quite similar based on the observation we proposed flash gradient constrained by integrating this fast gradient constraint into our debugging framework, we are method can achieve more accurate broken estimation result.",
            "An can significantly reduce the convolution artifacts.",
            "For more detail and results, please come to our poster.",
            "Thanks."
        ],
        [
            "Good afternoon, I'm checking you from the University of Delaware.",
            "I'll work focuses are recovering fluid type of emotions from images.",
            "This work is done by my student.",
            "Definitely enjoy it with."
        ],
        [
            "Actually, actually, and Philip, so of traditional flow assumes that the image, perhaps brightness, does not change the offer feature points, but for fluid type emotions, actually the brightness does change, in fact they follow specific fluid models.",
            "So in our work we produce a general brightness constraint that directly models how the brightness changes using the velocity potential flow.",
            "Essentially the gradient of the potential flow corresponds to the motion flow.",
            "So in this example we show that traditional optical flow method generates a uniform translational motion, whereas our method reviews.",
            "The contract ING flow in the highlighted images, so our method is very general.",
            "It can be applied to many phenomenons.",
            "For example we can even predict how temperature changes if you give me a temperature flow.",
            "So in that case if you want to know how why someone Cisco Summer feels like winter so please come to our poster, thank you."
        ],
        [
            "Good afternoon, I'm Salvation from Northwestern University.",
            "This is joint work with my advisor, professor in Wu's Party Model 4."
        ],
        [
            "Optical flow estimation.",
            "Handling motion discontinuity.",
            "The critical critical issue in flow computation as many priors violated in these areas.",
            "In this paper we introduce the novel's party prior to address this problem, and we can see the flow field can be sparsely represented in the wavelet domain as well as well as gradient domain cause most coefficients in these domains are zero.",
            "On such assumption, we formulated the flow computation in another underdetermined linear system and its minimum.",
            "One norm leads to a very accurate estimation.",
            "It can be shown that it can preserve Chris motion boundaries, but Furthermore it allows to estimate the entire flow field from only small subset of measurements.",
            "We also invest investigate the noise problem in the flow field benefiting from the ability to.",
            "The completion of our model.",
            "We can use ransacked, remove outliers and make the result more robust.",
            "Corrective and quantitative result both shows that our sparkling model outperforms traditional priors such as smoothness and piecewise smoothness, especially at motion discontinuity.",
            "For more details, please come to see my post poster at G 12.",
            "Thank you."
        ],
        [
            "Hi everyone, my name is Manuel and this is joint work with Thomas Broken Horse Beef Shop with the title, motion estimation with nonlocal total variation regularization."
        ],
        [
            "So first of all, think of a moving object, certainly at least part of the object would have similar motion and we want to exploit this fact.",
            "So first of all, historically might have seen this formulation quite often, so optical flow estimation is often embedded into a variational framework featuring a regularization term at the data term, and we want to use such formulations an include this exploited object motion.",
            "So how do we group pixels together?",
            "This is the first question.",
            "First of all we look at, for example, when you take this small image Patch, you have some certain color similarity measure.",
            "Color similarities and some approximate distances to neighboring pixels.",
            "And when you group these together, you get a more less soft.",
            "We call it soft segmentation of this object object parts.",
            "So how do we include this stuff into these formulations?",
            "So most of you will be familiar with nonlocal means and the equivalent to TV and one in this case is this nonlocal total variation and including this into a clever optimization framework.",
            "You can also use some clever data terms, like in this case normalized cross correlation.",
            "That can handle illumination variations, and all this stuff.",
            "So if you want to hear more details about this, come to my personal thanks."
        ],
        [
            "Have you ever wondered how we humans acquire and process visual information?",
            "We make about 170,000 psychotic eye movements every day.",
            "How do we determine where to look?"
        ],
        [
            "Next, how do we combine and integrate information across fixations?",
            "My name is Christopher Canaan with Gary Cottrell.",
            "We have turned up to recognition in static scenes into an active vision problem that is inspired by how people acquire and process visual information using eye movements as illustrating this top diagram.",
            "Our approach is assailing SNAP, determine where to look next with a simulated fixation, and uses self taught learning applied to natural images to learn very distributive image features with properties similar to cells in primary visual cortex.",
            "Our approach is validated using object flowerin face datasets or methods.",
            "Performance exceeds the best methods out there at least as of January and especially at one shot learning when the number of training instances very small in this bar chart at bottom I'm showing the relative performance of our approach versus the best out there on Caltech 101.",
            "Notice that with a single training image we are over 30% better than state of the art approaches.",
            "We also demonstrate we are.",
            "We believe that a vision system should be robust, so it should work well across changing scenarios and changing conditions.",
            "And we tested this and verify that it works even in situations where people wearing disguises or there's a significant illumination variance.",
            "We also kept the parameters fixed across all of our experiments to ensure that it's robust across datasets.",
            "So Chris, what's the trick?",
            "Come see my poster and I'll tell you all about it.",
            "G 14."
        ],
        [
            "Guys, my name's Simon Lucy.",
            "This is the title of our paper is fast image alignment in the free domain and this was done by a student Co.",
            "Supervised by myself and Sue Hanchen Ahmed Bilal Ashraf.",
            "You wish you could be here but he."
        ],
        [
            "Cody's back, so he's not for those of you in the audience without binoculars.",
            "I'll tell you what's up here.",
            "Basically, what we looked at in this paper was Lucas Kanade algorithm and one problem with the Lucas Kanade algorithm is that if you want to apply lots of banks of filters, the cost of the Lucas Kanade algorithm keeps on going up exponentially.",
            "So one thing that we looked at was that.",
            "Can we frame the Lucas Kanade algorithm in the Fourier domain?",
            "And if you frame the Lucas Kanade algorithm the free domain you get also it's nice things.",
            "The main thing is that if you're working with banks are filters, they all get subsumed into a single weighting matrix that can be completely precomputed.",
            "So for those of you who do anything with the Lucas Kanade algorithm or have any interest in doing really fast tracking with multiple filters, come see our fill.",
            "Come see our poster, it's G15 and the resolution is better at poster."
        ],
        [
            "Good afternoon Andrew Butter from Carnegie Mellon and this is joint work with Andrew Gallagher from Eastman Kodak David product from TGC and our advisors who launched from Cornell."
        ],
        [
            "The goal of this work is map inference in Markov random fields, we're given a discrete energy function, and what we'd like to do is find the optimal assignment to these discrete variables that minimizes this energy function.",
            "This problem is an important problem in computer vision, but unfortunately it's NP hard in general.",
            "In this paper, we present an approximate inference algorithm called outer planar decomposition.",
            "The key idea of our algorithm is that we decompose an intractable problem onto tractable subproblems on outer planar subgraphs that we can find in.",
            "In the given graph, which do allow for exact methods, we solve the problem exactly on these outer planar subgraphs and then use a message passing algorithm on top of it to get approximate global solution.",
            "Interestingly, we find we can show that our method contains in it as special cases, popular techniques like BP and TRW.",
            "In fact, we can show that OPD our work is a strict generalization of TRW, and is guaranteed to perform better, which we also find in practice in our experiments.",
            "So to learn more about what this special family of outer planar graphs is and why you should care.",
            "Come to our poster in the basement.",
            "Thank you."
        ],
        [
            "Hi my name is Kimberly from Selection University and this is joint work with a tongue jinwan anatomy and bio divisor sound."
        ],
        [
            "Ann and I work is about the optical flow estimation technique, which uses a adaptive smoothness prior on based on discrete framework and we have two ideas.",
            "In general an first thing is we provide a discrete analog to the smoothest prior on version version approach which has been well developed historically.",
            "And thanks to the recent advances in discrete optimization technique, we benefit from both both approaches and second thing is we provided you some of this prior.",
            "Which which avoids us simultaneously over smoothing and our segmentation over segmentation artifacts.",
            "Without the proper training.",
            "So here we present also presented very comparative results.",
            "And which contain for the images containing various tough situations.",
            "So for more details, please come by thank you."
        ],
        [
            "Hello this is Irene Chakraborty and this is joint work with Todd Zickler and Bill Freeman.",
            "So the blur estimation problem refers to.",
            "What's?"
        ],
        [
            "The blur estimation problem refers to detecting the characteristics of the blur.",
            "Usually the blur kernel.",
            "Other points that function from an image, and so if uniform layer is the case when you have one kernel affecting the whole image so typically caused by camera shake and there you have the benefit of using all the pixels in the image to estimate that one kernel.",
            "But for spatially varying blur, you're forced to make local inference.",
            "You're forced to do inference on local windows an.",
            "You know, so if you have like orders of magnitudes less data to do this inference, which is why you find lots of specially wearing lots of papers dealing with specially wearing blurred by either dealing with multiple images or by using optical methods to exaggerate the blur or to make the PSF invariant, like using focus sweep.",
            "So our paper titled Analyzing specially wearing blurred.",
            "Tackle the problem with working with specially waiting there from a single image captured using a regular camera and this paper has two contributions.",
            "The 1st is a local blur Q which basically we hope that services building block for a bunch of as a building block for work dealing with specially wearing blurred and it's basically likelihood measure which given a local window Anna candidate kernel gives you a likelihood measure.",
            "It basically says how likely is it that window was blurred by a certain by that kernel.",
            "And the second country in the second contribution.",
            "We basically take this blur to an apply to an application which is to.",
            "G 19."
        ],
        [
            "Hello, my name is Yasmin escort you know so I'm working in.",
            "A coastal perient inria.",
            "So in this paper work."
        ],
        [
            "Dealing with two problems on the one hand, we were pushing further.",
            "The machine learning approach to boundary detection and on the other hand we're introducing a simple and efficient algorithm for bounder grouping.",
            "So for detection we're starting with extracting sift features at multiple scales around every candidate, so, and we thereby comes capture the context around every candidate which providers with complementary information that helps us improve improve the detection.",
            "And by complementing the primarily local queues are currently used by boundary vectors.",
            "So we experiment with several ideas such as performing discriminative, dimensionality reduction and also using boosting that is robust to outliers and we empirically demonstrate that these results in systematic improvements on boundary detection on standard birthmarks.",
            "Now for grouping, our contribution lies in developing an efficient algorithm for for for the problem.",
            "So we start with a standard scale normalized saliency course, but instead of optimizing it with graph theoretic techniques, we formulate this optimization measure.",
            "Fractional program, which we can then translate into an equivalent lunar program.",
            "Now, once we do a continuous relaxation, we can solve this optimization problem using standard linear programming techniques.",
            "Anne with everybody come up with a very simple and efficient grouping algorithm.",
            "By putting these two contributions together, we achieve state of the art performance on the Berkeley Segmentation Benchmark.",
            "In specific, specific from Zero Point 7, which is the current state of the art, we're going to zero point 73, which brings us closer to human, closer to humans which are at zero point 79 so we can do that.",
            "Sorry."
        ],
        [
            "So hi, my name is Matt Zeiler and I'm here to talk about the convolutional networks, which is joint work with Graham Taylor, Rob Ferguson, Dilip Krishnan.",
            "Why you?"
        ],
        [
            "The convolutional networks are a new architecture used for learning mid level features from images that can be useful for high level tasks such as object recognition and low level tasks such as image denoising.",
            "So this is based on convolutional sparse coding and it can be stacked layer by layer to form a hierarchy that learns interesting filters at each layer.",
            "So in the first layer here with a simple circle image you decompose it into a set of filters which learn oriented edges and a corresponding set of feature Maps which basically indicate the strength and location of these edges in the image.",
            "So this this can be used to do a top down reconstruction of the image by convolving the filters with the feature Maps and summing the results.",
            "This is different than a convolutional network because our learn filters are convolved with feature Maps as opposed to with the input image itself, so this is typically hard to solve because of the convolutions and sparse constraint across feature Maps.",
            "But we come up with an approximation algorithm that can do it in seconds per image on a CPU.",
            "And finally showing here in the bottom right as we stack we learn V2 like structures in the second layer directly from natural images.",
            "So if you would like to hear more about the deconvolutional networks, come see the poster in G 21.",
            "Thank you."
        ],
        [
            "Hi, my name is Hannah Shaw from Julie and I present diffusion filtering without parameter tuning.",
            "This is joint work with Kitic."
        ],
        [
            "The contribution in this paper is that we show a classification of different diffusion schemes according to their statistical properties.",
            "This allows us to learn all parameters in these diffusion schemes, especially the potential functions.",
            "And with this we then.",
            "Estimate the hyperparameters weighing data term and diffusion term simultaneously with the denoising denoised image data.",
            "For.",
            "Diffusion schemes featuring an Emer effort.",
            "And energy.",
            "We also show how to estimate a covariance.",
            "As a quality measure for the resultant resulting image data that the noise data.",
            "The results we get on the quality of the results we get are in the same range as fields of experts deliver at a much smaller computational cost due to the common diffusion schemes we use.",
            "For more details, please visit my poster.",
            "Thank you."
        ],
        [
            "Hey I'm David Bonnie from Colorado State University and my posters about visual object tracking using a day."
        ],
        [
            "Active correlation filters.",
            "So what's unique about this work is the way that we train our correlation filters.",
            "We use a process called Moss and what's nice about Moss is it gives us very nice correlation peaks, but it also does a very good job of suppressing background.",
            "If you combine that with the tracker, you get a tracker that can handle very lots of different tracking challenges such as fast motion camera motion.",
            "Appearance changes, lighting changes, rotation and scale, and even occlusion.",
            "So another nice thing is that since it's still a correlation based tracker, you have many of the advantage of correlation based tracking, including speed and simplicity.",
            "So we've actually got a commercial version of this algorithm that's running at over 669 frames per second on the standard CPU, so if you're interested in this work, please stop by and see the poster.",
            "Thank you."
        ],
        [
            "Hi I am Marco Rosato and this is joint work with Geoff Hinton in Toronto.",
            "We propose a probabilistic model on natural images and."
        ],
        [
            "The key idea is to have two sets of latent variables.",
            "Once said, that modulates pairwise interactions between pixels and another set that determine the mean intensity of pixel values.",
            "So if PCA determines one meenan one covariance for all data points, now each image is represented by a Gaussian that has a certain mean Anderson covariance.",
            "Actually, we can generate exponentially many.",
            "Options.",
            "We learn features from natural images that look like localized and oriented gabors we can generate from the model extremely realistic samples and also we use the letter representation for object recognition achieving state of the art accuracy on the Super 10 data style.",
            "Thank you."
        ],
        [
            "Hi, my name is Ellenboro and this is joint work with Conces.",
            "Back then Luca and Rumples about learning mid level features for recognition."
        ],
        [
            "So the three main points of our work is first that we introduce a novel method to learn supervised dictionaries for sparse coding.",
            "Second, we performed a systematic experimental evaluation of several coding and pooling strategies, and the best combination achieves state of the art results on two benchmarks and 3rd one striking result of our evaluation is that Max pooling consistently performs better than average pooling, so we have tried to find.",
            "Experimental theoretical explanation of why this is the case.",
            "If you want more details, please come see our poster downstairs.",
            "GT25, thanks."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, here's a camera.",
                    "label": 0
                },
                {
                    "sent": "It's a phone that has a rolling shutter camera in it.",
                    "label": 0
                },
                {
                    "sent": "This is not a very good one, right?",
                    "label": 0
                },
                {
                    "sent": "Here's a good one.",
                    "label": 0
                },
                {
                    "sent": "This is a nice camera, but this is still has a rolling.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "If I take some video everything is fine, but if I put this in a car or helicopter on a bike and they drive at 100 miles an hour, the camera is doing this and all sorts of crazy things happen.",
                    "label": 0
                },
                {
                    "sent": "And as you can see clearly in the videos here, they're completely nuts.",
                    "label": 0
                },
                {
                    "sent": "If you see the videos, it's all over the place.",
                    "label": 0
                },
                {
                    "sent": "We have an algorithm that works on like the most crazy sequences we could find on the web, and the difference from like all the prior work, is most of the prior work is sort of follows the sort of repeats history from 20 years ago.",
                    "label": 0
                },
                {
                    "sent": "Don't use translation using a fine.",
                    "label": 0
                },
                {
                    "sent": "Don't use an offline user demography.",
                    "label": 0
                },
                {
                    "sent": "Don't use a homography user flow field, but the problem is that all of 30 frames a second.",
                    "label": 0
                },
                {
                    "sent": "If I take it, it's basically where did the pixels move from one frame to another.",
                    "label": 0
                },
                {
                    "sent": "If the camera is going crazy, you need to move nowhere.",
                    "label": 0
                },
                {
                    "sent": "That pixel is moving at 1000 frames a second.",
                    "label": 0
                },
                {
                    "sent": "We have an algorithm thanks to very related to Michaela Ronnies work on basically enhancing the freak motion from 30 frames per second motion, optical flow, or translations to 1000 frames per second.",
                    "label": 0
                },
                {
                    "sent": "And come see the videos of the poster.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the title of our paper is supervised Rosen using at pirran single image details synthesis and this work is working with me your entire and.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Ioffer something new and also Michael broadcast evening so are worth.",
                    "label": 0
                },
                {
                    "sent": "We basically want to combine the reconstruction based superexcellent algorithm and learning based algorithms so our poetry refers.",
                    "label": 0
                },
                {
                    "sent": "We construct the high resolution address using the reconstruction based algorithm and then based on this ash constraint, we sympathize the details using the learning based album and the result is that our results.",
                    "label": 0
                },
                {
                    "sent": "It's very good that capture both running base and reconstruction based at least for the supervised losers.",
                    "label": 0
                },
                {
                    "sent": "And please come to our poster for discussions.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so this is another paper, so the title is cold exposure imaging for projective motion during I'm doing time and this work is working with legend cost.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Playing an solution.",
                    "label": 0
                },
                {
                    "sent": "So this is a new approach for motion moving object during.",
                    "label": 1
                },
                {
                    "sent": "Suppose you have a moving hand.",
                    "label": 0
                },
                {
                    "sent": "So this is so common and then we use opposed by allowing a user to draw very scribbles that this cripple can provide a great thing for us to estimate the postback functions and we also have a method to accept moving objects over the backwards, while traditional mapping techniques also fails for such kind of method because it has a very similar color for the background and we wish.",
                    "label": 0
                },
                {
                    "sent": "We actually use are mostly into segment moving objects and then the final is.",
                    "label": 0
                },
                {
                    "sent": "So is, uh, divert resources.",
                    "label": 0
                },
                {
                    "sent": "So this is a little approach so please come to our poster for discussions.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Hi, my name is David Merriman and this is joint work with Arturo Bonnin, Thomas Adamek and Regina Ann.",
                    "label": 0
                },
                {
                    "sent": "We're presenting darts, which is an official.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "On way to extract keypoints in scale space an also use a Daisy layout for the descriptor.",
                    "label": 0
                },
                {
                    "sent": "So what we do I'll jump to the results, which is the nice part.",
                    "label": 0
                },
                {
                    "sent": "We obtained similar battery results as compared to sit and surf and we are six times faster than fifth than three times faster than surface.",
                    "label": 1
                },
                {
                    "sent": "The way we do that is that we have obtained a new.",
                    "label": 1
                },
                {
                    "sent": "The demonstration approximation by triangle filters that is computed sufficiently another orientation assignment algorithm and also we have done some optimization of the sampling space on the Daisy layout, and it's nice to have results, but it is even better to apply it so we have applied successfully to 3D reconstruction on video sequences captured with a mobile phone.",
                    "label": 1
                },
                {
                    "sent": "Also, object tracking tracking by detection type of stuff.",
                    "label": 0
                },
                {
                    "sent": "An object recognition from a mobile phone as well.",
                    "label": 1
                },
                {
                    "sent": "Visual search, an video copy detection.",
                    "label": 0
                },
                {
                    "sent": "So just join me on the basement.",
                    "label": 0
                },
                {
                    "sent": "I will be there for your answer.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Hi, my name is Simpang and this is trying to work with Sing Bing Kang, New Joshi Steve Sites and Dan Huttenlocher.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Almost all cameras nowadays can take videos, so an easy way to generate a Panorama is to pander camera around in video mode and then stitch it from the video.",
                    "label": 0
                },
                {
                    "sent": "In fact, this is such a useful thing to do that a lot of companies already producing these sort of cameras with this beauty in functionality and they are even advertising it on TV during World Cup games must be very expensive commercial.",
                    "label": 0
                },
                {
                    "sent": "But once the commercials didn't tell you, that, is that if you move the camera a little bit too quickly, or if the exposure time is a little bit long, then you're going to get motion blur.",
                    "label": 0
                },
                {
                    "sent": "And I'll go is to automatically estimate and remove motion blur.",
                    "label": 0
                },
                {
                    "sent": "And in addition, we also able to obtain the camera duty cycles as a byproduct of the dibbler process.",
                    "label": 0
                },
                {
                    "sent": "So if you come to our poster will show you how it is done.",
                    "label": 0
                },
                {
                    "sent": "It's at G8.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Hello, I'm touching this is joint work with Stephen Ross and Michael Black.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "What makes optical flow accurate and why?",
                    "label": 0
                },
                {
                    "sent": "130 questions.",
                    "label": 0
                },
                {
                    "sent": "We perform an analysis of recent practices in optical flow estimation.",
                    "label": 0
                },
                {
                    "sent": "Plastic Plus Plus is directly descended from Holland Shank, yet our implementation produces results very close to the state of the art.",
                    "label": 0
                },
                {
                    "sent": "We found the key is to perform median filtering of the flow field during each iterative warping step.",
                    "label": 0
                },
                {
                    "sent": "However, we find this median filtering process actually minimizes a different objective with a non local term.",
                    "label": 0
                },
                {
                    "sent": "We've done this inside.",
                    "label": 0
                },
                {
                    "sent": "We propose an improved method that uses color, motion and occlusion information to better preserve motion details.",
                    "label": 0
                },
                {
                    "sent": "This method is currently ranked first in both Angular and endpoint error on the Middlebury optical flow benchmark.",
                    "label": 0
                },
                {
                    "sent": "Our method code is freely available online.",
                    "label": 0
                },
                {
                    "sent": "Please visit our poster for the detailed list and other tricks that make optical flow accurate.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Hi, my name is target or I'm I'm presenting robust fast diverting is the joint work with Stonewall and turns in from?",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "National University of Singapore.",
                    "label": 0
                },
                {
                    "sent": "Photo under low light conditions using a handheld camera.",
                    "label": 0
                },
                {
                    "sent": "The capture image usually suffer from motion blur caused by camera shake.",
                    "label": 0
                },
                {
                    "sent": "So it's challenging to remove motion blur from a single broad image.",
                    "label": 0
                },
                {
                    "sent": "In this work we propose.",
                    "label": 0
                },
                {
                    "sent": "Novel method for image blurring using its corresponding flash image.",
                    "label": 0
                },
                {
                    "sent": "You can see from the image.",
                    "label": 0
                },
                {
                    "sent": "We observed that the.",
                    "label": 0
                },
                {
                    "sent": "The.",
                    "label": 0
                },
                {
                    "sent": "The intensity of sharp image and flash image is quite different from each other.",
                    "label": 0
                },
                {
                    "sent": "While the intensity of our gradients of the flash image and sharp image is quite similar based on the observation we proposed flash gradient constrained by integrating this fast gradient constraint into our debugging framework, we are method can achieve more accurate broken estimation result.",
                    "label": 1
                },
                {
                    "sent": "An can significantly reduce the convolution artifacts.",
                    "label": 0
                },
                {
                    "sent": "For more detail and results, please come to our poster.",
                    "label": 0
                },
                {
                    "sent": "Thanks.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Good afternoon, I'm checking you from the University of Delaware.",
                    "label": 0
                },
                {
                    "sent": "I'll work focuses are recovering fluid type of emotions from images.",
                    "label": 0
                },
                {
                    "sent": "This work is done by my student.",
                    "label": 0
                },
                {
                    "sent": "Definitely enjoy it with.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Actually, actually, and Philip, so of traditional flow assumes that the image, perhaps brightness, does not change the offer feature points, but for fluid type emotions, actually the brightness does change, in fact they follow specific fluid models.",
                    "label": 0
                },
                {
                    "sent": "So in our work we produce a general brightness constraint that directly models how the brightness changes using the velocity potential flow.",
                    "label": 1
                },
                {
                    "sent": "Essentially the gradient of the potential flow corresponds to the motion flow.",
                    "label": 0
                },
                {
                    "sent": "So in this example we show that traditional optical flow method generates a uniform translational motion, whereas our method reviews.",
                    "label": 0
                },
                {
                    "sent": "The contract ING flow in the highlighted images, so our method is very general.",
                    "label": 0
                },
                {
                    "sent": "It can be applied to many phenomenons.",
                    "label": 0
                },
                {
                    "sent": "For example we can even predict how temperature changes if you give me a temperature flow.",
                    "label": 0
                },
                {
                    "sent": "So in that case if you want to know how why someone Cisco Summer feels like winter so please come to our poster, thank you.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Good afternoon, I'm Salvation from Northwestern University.",
                    "label": 0
                },
                {
                    "sent": "This is joint work with my advisor, professor in Wu's Party Model 4.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Optical flow estimation.",
                    "label": 0
                },
                {
                    "sent": "Handling motion discontinuity.",
                    "label": 0
                },
                {
                    "sent": "The critical critical issue in flow computation as many priors violated in these areas.",
                    "label": 0
                },
                {
                    "sent": "In this paper we introduce the novel's party prior to address this problem, and we can see the flow field can be sparsely represented in the wavelet domain as well as well as gradient domain cause most coefficients in these domains are zero.",
                    "label": 1
                },
                {
                    "sent": "On such assumption, we formulated the flow computation in another underdetermined linear system and its minimum.",
                    "label": 0
                },
                {
                    "sent": "One norm leads to a very accurate estimation.",
                    "label": 1
                },
                {
                    "sent": "It can be shown that it can preserve Chris motion boundaries, but Furthermore it allows to estimate the entire flow field from only small subset of measurements.",
                    "label": 1
                },
                {
                    "sent": "We also invest investigate the noise problem in the flow field benefiting from the ability to.",
                    "label": 0
                },
                {
                    "sent": "The completion of our model.",
                    "label": 0
                },
                {
                    "sent": "We can use ransacked, remove outliers and make the result more robust.",
                    "label": 0
                },
                {
                    "sent": "Corrective and quantitative result both shows that our sparkling model outperforms traditional priors such as smoothness and piecewise smoothness, especially at motion discontinuity.",
                    "label": 0
                },
                {
                    "sent": "For more details, please come to see my post poster at G 12.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Hi everyone, my name is Manuel and this is joint work with Thomas Broken Horse Beef Shop with the title, motion estimation with nonlocal total variation regularization.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So first of all, think of a moving object, certainly at least part of the object would have similar motion and we want to exploit this fact.",
                    "label": 0
                },
                {
                    "sent": "So first of all, historically might have seen this formulation quite often, so optical flow estimation is often embedded into a variational framework featuring a regularization term at the data term, and we want to use such formulations an include this exploited object motion.",
                    "label": 0
                },
                {
                    "sent": "So how do we group pixels together?",
                    "label": 0
                },
                {
                    "sent": "This is the first question.",
                    "label": 0
                },
                {
                    "sent": "First of all we look at, for example, when you take this small image Patch, you have some certain color similarity measure.",
                    "label": 0
                },
                {
                    "sent": "Color similarities and some approximate distances to neighboring pixels.",
                    "label": 0
                },
                {
                    "sent": "And when you group these together, you get a more less soft.",
                    "label": 0
                },
                {
                    "sent": "We call it soft segmentation of this object object parts.",
                    "label": 0
                },
                {
                    "sent": "So how do we include this stuff into these formulations?",
                    "label": 0
                },
                {
                    "sent": "So most of you will be familiar with nonlocal means and the equivalent to TV and one in this case is this nonlocal total variation and including this into a clever optimization framework.",
                    "label": 1
                },
                {
                    "sent": "You can also use some clever data terms, like in this case normalized cross correlation.",
                    "label": 1
                },
                {
                    "sent": "That can handle illumination variations, and all this stuff.",
                    "label": 0
                },
                {
                    "sent": "So if you want to hear more details about this, come to my personal thanks.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Have you ever wondered how we humans acquire and process visual information?",
                    "label": 0
                },
                {
                    "sent": "We make about 170,000 psychotic eye movements every day.",
                    "label": 0
                },
                {
                    "sent": "How do we determine where to look?",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Next, how do we combine and integrate information across fixations?",
                    "label": 0
                },
                {
                    "sent": "My name is Christopher Canaan with Gary Cottrell.",
                    "label": 0
                },
                {
                    "sent": "We have turned up to recognition in static scenes into an active vision problem that is inspired by how people acquire and process visual information using eye movements as illustrating this top diagram.",
                    "label": 0
                },
                {
                    "sent": "Our approach is assailing SNAP, determine where to look next with a simulated fixation, and uses self taught learning applied to natural images to learn very distributive image features with properties similar to cells in primary visual cortex.",
                    "label": 0
                },
                {
                    "sent": "Our approach is validated using object flowerin face datasets or methods.",
                    "label": 0
                },
                {
                    "sent": "Performance exceeds the best methods out there at least as of January and especially at one shot learning when the number of training instances very small in this bar chart at bottom I'm showing the relative performance of our approach versus the best out there on Caltech 101.",
                    "label": 0
                },
                {
                    "sent": "Notice that with a single training image we are over 30% better than state of the art approaches.",
                    "label": 0
                },
                {
                    "sent": "We also demonstrate we are.",
                    "label": 0
                },
                {
                    "sent": "We believe that a vision system should be robust, so it should work well across changing scenarios and changing conditions.",
                    "label": 0
                },
                {
                    "sent": "And we tested this and verify that it works even in situations where people wearing disguises or there's a significant illumination variance.",
                    "label": 0
                },
                {
                    "sent": "We also kept the parameters fixed across all of our experiments to ensure that it's robust across datasets.",
                    "label": 0
                },
                {
                    "sent": "So Chris, what's the trick?",
                    "label": 0
                },
                {
                    "sent": "Come see my poster and I'll tell you all about it.",
                    "label": 0
                },
                {
                    "sent": "G 14.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Guys, my name's Simon Lucy.",
                    "label": 0
                },
                {
                    "sent": "This is the title of our paper is fast image alignment in the free domain and this was done by a student Co.",
                    "label": 1
                },
                {
                    "sent": "Supervised by myself and Sue Hanchen Ahmed Bilal Ashraf.",
                    "label": 0
                },
                {
                    "sent": "You wish you could be here but he.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Cody's back, so he's not for those of you in the audience without binoculars.",
                    "label": 0
                },
                {
                    "sent": "I'll tell you what's up here.",
                    "label": 0
                },
                {
                    "sent": "Basically, what we looked at in this paper was Lucas Kanade algorithm and one problem with the Lucas Kanade algorithm is that if you want to apply lots of banks of filters, the cost of the Lucas Kanade algorithm keeps on going up exponentially.",
                    "label": 0
                },
                {
                    "sent": "So one thing that we looked at was that.",
                    "label": 0
                },
                {
                    "sent": "Can we frame the Lucas Kanade algorithm in the Fourier domain?",
                    "label": 0
                },
                {
                    "sent": "And if you frame the Lucas Kanade algorithm the free domain you get also it's nice things.",
                    "label": 0
                },
                {
                    "sent": "The main thing is that if you're working with banks are filters, they all get subsumed into a single weighting matrix that can be completely precomputed.",
                    "label": 0
                },
                {
                    "sent": "So for those of you who do anything with the Lucas Kanade algorithm or have any interest in doing really fast tracking with multiple filters, come see our fill.",
                    "label": 0
                },
                {
                    "sent": "Come see our poster, it's G15 and the resolution is better at poster.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Good afternoon Andrew Butter from Carnegie Mellon and this is joint work with Andrew Gallagher from Eastman Kodak David product from TGC and our advisors who launched from Cornell.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The goal of this work is map inference in Markov random fields, we're given a discrete energy function, and what we'd like to do is find the optimal assignment to these discrete variables that minimizes this energy function.",
                    "label": 0
                },
                {
                    "sent": "This problem is an important problem in computer vision, but unfortunately it's NP hard in general.",
                    "label": 0
                },
                {
                    "sent": "In this paper, we present an approximate inference algorithm called outer planar decomposition.",
                    "label": 0
                },
                {
                    "sent": "The key idea of our algorithm is that we decompose an intractable problem onto tractable subproblems on outer planar subgraphs that we can find in.",
                    "label": 0
                },
                {
                    "sent": "In the given graph, which do allow for exact methods, we solve the problem exactly on these outer planar subgraphs and then use a message passing algorithm on top of it to get approximate global solution.",
                    "label": 0
                },
                {
                    "sent": "Interestingly, we find we can show that our method contains in it as special cases, popular techniques like BP and TRW.",
                    "label": 1
                },
                {
                    "sent": "In fact, we can show that OPD our work is a strict generalization of TRW, and is guaranteed to perform better, which we also find in practice in our experiments.",
                    "label": 0
                },
                {
                    "sent": "So to learn more about what this special family of outer planar graphs is and why you should care.",
                    "label": 0
                },
                {
                    "sent": "Come to our poster in the basement.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Hi my name is Kimberly from Selection University and this is joint work with a tongue jinwan anatomy and bio divisor sound.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Ann and I work is about the optical flow estimation technique, which uses a adaptive smoothness prior on based on discrete framework and we have two ideas.",
                    "label": 1
                },
                {
                    "sent": "In general an first thing is we provide a discrete analog to the smoothest prior on version version approach which has been well developed historically.",
                    "label": 1
                },
                {
                    "sent": "And thanks to the recent advances in discrete optimization technique, we benefit from both both approaches and second thing is we provided you some of this prior.",
                    "label": 0
                },
                {
                    "sent": "Which which avoids us simultaneously over smoothing and our segmentation over segmentation artifacts.",
                    "label": 0
                },
                {
                    "sent": "Without the proper training.",
                    "label": 0
                },
                {
                    "sent": "So here we present also presented very comparative results.",
                    "label": 0
                },
                {
                    "sent": "And which contain for the images containing various tough situations.",
                    "label": 0
                },
                {
                    "sent": "So for more details, please come by thank you.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Hello this is Irene Chakraborty and this is joint work with Todd Zickler and Bill Freeman.",
                    "label": 0
                },
                {
                    "sent": "So the blur estimation problem refers to.",
                    "label": 0
                },
                {
                    "sent": "What's?",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The blur estimation problem refers to detecting the characteristics of the blur.",
                    "label": 1
                },
                {
                    "sent": "Usually the blur kernel.",
                    "label": 0
                },
                {
                    "sent": "Other points that function from an image, and so if uniform layer is the case when you have one kernel affecting the whole image so typically caused by camera shake and there you have the benefit of using all the pixels in the image to estimate that one kernel.",
                    "label": 0
                },
                {
                    "sent": "But for spatially varying blur, you're forced to make local inference.",
                    "label": 0
                },
                {
                    "sent": "You're forced to do inference on local windows an.",
                    "label": 0
                },
                {
                    "sent": "You know, so if you have like orders of magnitudes less data to do this inference, which is why you find lots of specially wearing lots of papers dealing with specially wearing blurred by either dealing with multiple images or by using optical methods to exaggerate the blur or to make the PSF invariant, like using focus sweep.",
                    "label": 0
                },
                {
                    "sent": "So our paper titled Analyzing specially wearing blurred.",
                    "label": 0
                },
                {
                    "sent": "Tackle the problem with working with specially waiting there from a single image captured using a regular camera and this paper has two contributions.",
                    "label": 0
                },
                {
                    "sent": "The 1st is a local blur Q which basically we hope that services building block for a bunch of as a building block for work dealing with specially wearing blurred and it's basically likelihood measure which given a local window Anna candidate kernel gives you a likelihood measure.",
                    "label": 0
                },
                {
                    "sent": "It basically says how likely is it that window was blurred by a certain by that kernel.",
                    "label": 0
                },
                {
                    "sent": "And the second country in the second contribution.",
                    "label": 0
                },
                {
                    "sent": "We basically take this blur to an apply to an application which is to.",
                    "label": 0
                },
                {
                    "sent": "G 19.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Hello, my name is Yasmin escort you know so I'm working in.",
                    "label": 0
                },
                {
                    "sent": "A coastal perient inria.",
                    "label": 0
                },
                {
                    "sent": "So in this paper work.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Dealing with two problems on the one hand, we were pushing further.",
                    "label": 0
                },
                {
                    "sent": "The machine learning approach to boundary detection and on the other hand we're introducing a simple and efficient algorithm for bounder grouping.",
                    "label": 1
                },
                {
                    "sent": "So for detection we're starting with extracting sift features at multiple scales around every candidate, so, and we thereby comes capture the context around every candidate which providers with complementary information that helps us improve improve the detection.",
                    "label": 0
                },
                {
                    "sent": "And by complementing the primarily local queues are currently used by boundary vectors.",
                    "label": 0
                },
                {
                    "sent": "So we experiment with several ideas such as performing discriminative, dimensionality reduction and also using boosting that is robust to outliers and we empirically demonstrate that these results in systematic improvements on boundary detection on standard birthmarks.",
                    "label": 0
                },
                {
                    "sent": "Now for grouping, our contribution lies in developing an efficient algorithm for for for the problem.",
                    "label": 0
                },
                {
                    "sent": "So we start with a standard scale normalized saliency course, but instead of optimizing it with graph theoretic techniques, we formulate this optimization measure.",
                    "label": 0
                },
                {
                    "sent": "Fractional program, which we can then translate into an equivalent lunar program.",
                    "label": 1
                },
                {
                    "sent": "Now, once we do a continuous relaxation, we can solve this optimization problem using standard linear programming techniques.",
                    "label": 0
                },
                {
                    "sent": "Anne with everybody come up with a very simple and efficient grouping algorithm.",
                    "label": 0
                },
                {
                    "sent": "By putting these two contributions together, we achieve state of the art performance on the Berkeley Segmentation Benchmark.",
                    "label": 0
                },
                {
                    "sent": "In specific, specific from Zero Point 7, which is the current state of the art, we're going to zero point 73, which brings us closer to human, closer to humans which are at zero point 79 so we can do that.",
                    "label": 0
                },
                {
                    "sent": "Sorry.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So hi, my name is Matt Zeiler and I'm here to talk about the convolutional networks, which is joint work with Graham Taylor, Rob Ferguson, Dilip Krishnan.",
                    "label": 0
                },
                {
                    "sent": "Why you?",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The convolutional networks are a new architecture used for learning mid level features from images that can be useful for high level tasks such as object recognition and low level tasks such as image denoising.",
                    "label": 0
                },
                {
                    "sent": "So this is based on convolutional sparse coding and it can be stacked layer by layer to form a hierarchy that learns interesting filters at each layer.",
                    "label": 1
                },
                {
                    "sent": "So in the first layer here with a simple circle image you decompose it into a set of filters which learn oriented edges and a corresponding set of feature Maps which basically indicate the strength and location of these edges in the image.",
                    "label": 0
                },
                {
                    "sent": "So this this can be used to do a top down reconstruction of the image by convolving the filters with the feature Maps and summing the results.",
                    "label": 0
                },
                {
                    "sent": "This is different than a convolutional network because our learn filters are convolved with feature Maps as opposed to with the input image itself, so this is typically hard to solve because of the convolutions and sparse constraint across feature Maps.",
                    "label": 0
                },
                {
                    "sent": "But we come up with an approximation algorithm that can do it in seconds per image on a CPU.",
                    "label": 0
                },
                {
                    "sent": "And finally showing here in the bottom right as we stack we learn V2 like structures in the second layer directly from natural images.",
                    "label": 1
                },
                {
                    "sent": "So if you would like to hear more about the deconvolutional networks, come see the poster in G 21.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Hi, my name is Hannah Shaw from Julie and I present diffusion filtering without parameter tuning.",
                    "label": 0
                },
                {
                    "sent": "This is joint work with Kitic.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The contribution in this paper is that we show a classification of different diffusion schemes according to their statistical properties.",
                    "label": 1
                },
                {
                    "sent": "This allows us to learn all parameters in these diffusion schemes, especially the potential functions.",
                    "label": 0
                },
                {
                    "sent": "And with this we then.",
                    "label": 0
                },
                {
                    "sent": "Estimate the hyperparameters weighing data term and diffusion term simultaneously with the denoising denoised image data.",
                    "label": 0
                },
                {
                    "sent": "For.",
                    "label": 0
                },
                {
                    "sent": "Diffusion schemes featuring an Emer effort.",
                    "label": 0
                },
                {
                    "sent": "And energy.",
                    "label": 0
                },
                {
                    "sent": "We also show how to estimate a covariance.",
                    "label": 0
                },
                {
                    "sent": "As a quality measure for the resultant resulting image data that the noise data.",
                    "label": 1
                },
                {
                    "sent": "The results we get on the quality of the results we get are in the same range as fields of experts deliver at a much smaller computational cost due to the common diffusion schemes we use.",
                    "label": 0
                },
                {
                    "sent": "For more details, please visit my poster.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Hey I'm David Bonnie from Colorado State University and my posters about visual object tracking using a day.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Active correlation filters.",
                    "label": 0
                },
                {
                    "sent": "So what's unique about this work is the way that we train our correlation filters.",
                    "label": 0
                },
                {
                    "sent": "We use a process called Moss and what's nice about Moss is it gives us very nice correlation peaks, but it also does a very good job of suppressing background.",
                    "label": 0
                },
                {
                    "sent": "If you combine that with the tracker, you get a tracker that can handle very lots of different tracking challenges such as fast motion camera motion.",
                    "label": 0
                },
                {
                    "sent": "Appearance changes, lighting changes, rotation and scale, and even occlusion.",
                    "label": 1
                },
                {
                    "sent": "So another nice thing is that since it's still a correlation based tracker, you have many of the advantage of correlation based tracking, including speed and simplicity.",
                    "label": 0
                },
                {
                    "sent": "So we've actually got a commercial version of this algorithm that's running at over 669 frames per second on the standard CPU, so if you're interested in this work, please stop by and see the poster.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Hi I am Marco Rosato and this is joint work with Geoff Hinton in Toronto.",
                    "label": 0
                },
                {
                    "sent": "We propose a probabilistic model on natural images and.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The key idea is to have two sets of latent variables.",
                    "label": 0
                },
                {
                    "sent": "Once said, that modulates pairwise interactions between pixels and another set that determine the mean intensity of pixel values.",
                    "label": 0
                },
                {
                    "sent": "So if PCA determines one meenan one covariance for all data points, now each image is represented by a Gaussian that has a certain mean Anderson covariance.",
                    "label": 0
                },
                {
                    "sent": "Actually, we can generate exponentially many.",
                    "label": 0
                },
                {
                    "sent": "Options.",
                    "label": 0
                },
                {
                    "sent": "We learn features from natural images that look like localized and oriented gabors we can generate from the model extremely realistic samples and also we use the letter representation for object recognition achieving state of the art accuracy on the Super 10 data style.",
                    "label": 1
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Hi, my name is Ellenboro and this is joint work with Conces.",
                    "label": 0
                },
                {
                    "sent": "Back then Luca and Rumples about learning mid level features for recognition.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the three main points of our work is first that we introduce a novel method to learn supervised dictionaries for sparse coding.",
                    "label": 0
                },
                {
                    "sent": "Second, we performed a systematic experimental evaluation of several coding and pooling strategies, and the best combination achieves state of the art results on two benchmarks and 3rd one striking result of our evaluation is that Max pooling consistently performs better than average pooling, so we have tried to find.",
                    "label": 0
                },
                {
                    "sent": "Experimental theoretical explanation of why this is the case.",
                    "label": 0
                },
                {
                    "sent": "If you want more details, please come see our poster downstairs.",
                    "label": 0
                },
                {
                    "sent": "GT25, thanks.",
                    "label": 0
                }
            ]
        }
    }
}