{
    "id": "dztfzhuryooeimye2gda3bx3jfeypxr3",
    "title": "Bayesian Machine Learning for Controlling Autonomous Systems",
    "info": {
        "author": [
            "Marc Peter Deisenroth, Department of Computing, Imperial College London"
        ],
        "published": "Nov. 7, 2013",
        "recorded": "September 2013",
        "category": [
            "Top->Computer Science->Decision Support",
            "Top->Computer Science->Machine Learning->On-line Learning"
        ]
    },
    "url": "http://videolectures.net/lsoldm2013_deisenroth_autonomous_systems/",
    "segmentation": [
        [
            "So I hope you're not too sleepy.",
            "After lunch.",
            "Might come later, so I'm going to talk a little bit about how we can use space in machine learning methods for control for robot control or for mechanical systems control."
        ],
        [
            "So if we talk about autonomous systems, then we basically need to talk about three key challenging challenges.",
            "One is modeling, one is predicting and one is decision making.",
            "For example, if we look at this super robot over here, we might be interested in modeling the dynamics of the kinematics of this robot, but typically we're not really done with modeling, but we also want to use this kind of model for doing predictions.",
            "So what's going to happen when we activate this robot?",
            "And based on these predictions, we also want to change the control signals, which basically corresponds to a decision making problem.",
            "The problem is that especially with these kind of robots, we have a lot of noisy signals and the processes which generate the underlying which generate these signals might be not very well understood.",
            "For example, if you have this robot here with some sort of like elasticities, we have a lot of noise and uncertainty and actually modeling these elasticities or also impact when we when we start walking.",
            "So this is tricky and we need to model these things.",
            "And if we want to increase the autonomy of today's robots, we need to deal with uncertainties instead of like engineering this away and Bayesian machine learning is a principled framework for dealing with these uncertainties.",
            "So based on machine learning and also this modeling predicting and decision making problems are.",
            "Also there in other kind of applications.",
            "For example, if you look at climate science, we might wonder model the climate based on CO2 emissions model.",
            "The effect of CO2 emissions on the climate.",
            "And we might even want to change some of these.",
            "Some of our policies in terms of heating and whatever to have some sort of impact brain computer interface.",
            "We might be interested in using huge signals to to infer what the human actually wants to do.",
            "An actuator robot to do it in the end?",
            "Or we could use neural signals to control prosthetic hands."
        ],
        [
            "So the outline of my talk is basically.",
            "As follows, so I'm very focused on controller learning in this talk, so I'm not talking about climate signs or anything else.",
            "Controller learning for robots and mechanical systems.",
            "I'm going to talk about two approaches to four controller learning.",
            "One is based on reinforcement learning and one is based on Bayesian optimization.",
            "So the interesting thing here is also that we have we have two kind of approaches.",
            "For controller learning here, this one was basically from the point of view.",
            "We have a method and we apply the method in the end.",
            "Here we had a problem where we couldn't apply that method.",
            "I'm going to explain why afterwards and then we use the machine learning technique to solve this problem.",
            "So from method to problem and this one was from problem to method.",
            "So let's start with the."
        ],
        [
            "Reinforcement learning part.",
            "So we consider a set up where we have a state of Aleutian so XD plus one is a function of XT&UT, so access the state.",
            "You is a control signal and F is an unknown transition function.",
            "We have some noise on top here.",
            "We also assume that the control is a function of the state and some parameters and this function is called the policy in these parameters were parameterized the policy.",
            "So the objective is that we want to find pulse parameters Theta star that minimize some sort of expected long-term cost which is denoted by J of Theta.",
            "So it's a sum over a finite time horizon of some.",
            "Expected cost.",
            "We have an initial distribution over overall start state and we assume that this one is Gaussian and this instantaneous costaceae vex could for example be a squared distance between your current position and where you actually want to go in the end.",
            "And there's some typical objective in reinforcement learning or optimal control."
        ],
        [
            "So I'm going to propose or introduce a very conceptually very simple algorithm for solving this problem.",
            "So we want to minimize this expected long-term cost, and the algorithm proceeds in four steps.",
            "Very high level.",
            "Initially we learn a probabilistic model for this transition function, and it needs to be probabilistic to be robust to model errors, and I'm going to explain that in a little bit.",
            "Then we use this model to compute long-term predictions of the state evolution conditioned on on the current parameterisation of the policy.",
            "Then we improve this policy based on these long-term predictions and when we improve the policy, we go back and say, OK, let's apply this controller to our system.",
            "Yes please.",
            "Function.",
            "Yes, so I know the parameterisation of the policy function, so I fixed the parameterisation.",
            "OK, so I'm going to go through all of these steps at some reasonably high level, so let's start."
        ],
        [
            "The probabilistic model.",
            "Assuming that we want to learn a model, then this model learning problem is basically a regression problem.",
            "So let's for example, say we want to find a function of Maps X2F of X, and for simplicity assume these.",
            "These observations, these Y values are noise free, so solving this model learning problem corresponds to finding a function that kind of goes through all of these points.",
            "So let's do."
        ],
        [
            "So that so this is my function.",
            "It goes through all of these points, solves the problem.",
            "But usually we're not done with modeling, but we also want to do predictions.",
            "And based on these predictions, we want to make make decisions.",
            "So if."
        ],
        [
            "So what's going to happen at X = 7?",
            "This function is going to say oh it's minus one, so I'm happy with minus one.",
            "Go to my policy, apply my controller, and I fall off the Cliff.",
            "That can happen, right?",
            "Because you don't actually know anything about the function in this area, so other possible function approximators that also solve this regression problem?"
        ],
        [
            "Here and they give you completely different answers, so this was minus one.",
            "This is plus one.",
            "This is zero, and that could be decisions go left, go right or don't do anything.",
            "And if you walk along the Cliff you fall over at some point.",
            "So, but what you actually want to do is you want to express your kind of uncertainty about the model in areas we haven't.",
            "We haven't observed anything and you can do this with."
        ],
        [
            "Probabilistic model.",
            "Probabilistic model at X = 7 would say well on average.",
            "I think it's zero, but I have no clue.",
            "And if you take this no clue into consideration when you make decisions then you are more robust to say wrong models.",
            "Then when you actually use a deterministic model.",
            "So I think or we think it's very.",
            "Essentially that you express uncertainty about the underlying function, and we're going to use Gaussian processes for solving this model learning problem."
        ],
        [
            "So assuming we have now these Gaussian processes for this transition function, let's have a look at how we compute these long term predictions of the of these states."
        ],
        [
            "So the idea is basically to iteratively compute these probability distributions P of X1 to P of X capital T. Assuming you have an initial start date, start set distribution here you propagate this information of this uncertainty overtime and follow.",
            "Basically these dashed line.",
            "In the context of a GP this."
        ],
        [
            "It's like this.",
            "So assuming we have a Gaussian distribution over state and controls at timestep T, you want to map this Gaussian distribution through a probabilistic Gaussian process.",
            "And then you would."
        ],
        [
            "10 The next state distribution.",
            "So I'm sorry it's almost invisible.",
            "Think potentially problem with projector, so this says PFX T + 1 is a triple integral of.",
            "Well, basically this model times this model and we integrate out everything that is uncertain, so it's X because we have a distribution over X.",
            "We have a distribution over U and we also have a probability distribution over the function which is given by this Gaussian process.",
            "And if we integrate that out, then."
        ],
        [
            "We get this probability distribution.",
            "Problem is you can't actually compute this interval, so I only got this 2 Monte Carlo sampling with a kernel density estimator afterwards to make it look nice.",
            "So you can't solve this integral.",
            "That's a problem, but what you can do is you can compute the mean and the variance of this distribution and just say OK.",
            "I just fitted Gaussian to this, so if you do that, you have this kind of fit to this.",
            "In this example.",
            "And this is called moment matching, and we're going to use that to compute these predictive distributions.",
            "So if this is your next set distribution, you can kind of like feed that in here and then cycle through iteratively and get these.",
            "Say approximations to these predicted state distributions, P. FX-1 to PFX capital T."
        ],
        [
            "So, assuming that we have now, these are approximations of these state distributions that improve the policy.",
            "So it's basically 2 steps.",
            "We compute the expected long-term cost J.",
            "So this guy over here and then find parameters which minimize this J."
        ],
        [
            "So if you already know how to predict or how to get this sequence of state distributions while computing J just boils down to computing these expected values at each time step and sum them up.",
            "So, given that we have Gaussian approximations of the state distributions, we just need to integrate our cost function against this against a Gaussian distribution.",
            "And since we can choose this cost function, we just assume that we can compute this in closed form so.",
            "C could for example be any polynomial it could be.",
            "Fourier series expansion could be radial basis function, network.",
            "So there's various various functions you can choose to for this cost function instead of question.",
            "So sorry, so so we can compute these guys, sum them up and then we have J.",
            "So nice thing is that so far everything is can be computed in closed form, so no sampling, nothing.",
            "And that also means that we can compute the gradients of J with respect to the policy.",
            "Parameters can be computed in close form.",
            "And if we have the gradient and we have the function value where you can use a standard Bayesian standard gradient based optimizer, for example beefs to find Theta star.",
            "So it's not a global.",
            "Probably don't file find the global minimum, but something that is useful.",
            "And that's exactly what this with our pickle framework for controller learning does.",
            "So this is, this is what it's based on."
        ],
        [
            "And I think I'm going to demonstrate how it works in an example, so here's an example which some of us know from, usually from simulation.",
            "It's a center benchmark problem.",
            "It's called the cart pole swing up.",
            "We have a cart running on a track, appendages attached to it.",
            "The pendulum is freely swinging.",
            "Initially it's hanging downwards and the idea is to find a strategy that swings the pendulum up and balances it in the middle of the track where the red crosses.",
            "We have a cost function C which is a non normalized Gaussian or 1 minus and a normalized Gaussian.",
            "Um?",
            "And it penalizes the distance from the tip of the pendulum to the Red Cross.",
            "So no velocity penalties and no control penalties and.",
            "The learning framework.",
            "We just search one work.",
            "So works like this, so initially we apply some random actions to the system to collect a small initial data set.",
            "So we do this twice, so each of these trials is about two or is 2 1/2 seconds long.",
            "Sampling rate is 10 Hertz.",
            "Then we have these like 50 data points, training Gaussian process model.",
            "Do these long-term predictions improve the policy?",
            "Go back to the system and apply the policy.",
            "OK, so this was very say you would say useless, but it already learned that it needs to keep the card in the middle of the track.",
            "The model was very very uncertain.",
            "But it now has new experience now can update the model and update the policy and the next time it applies the policy.",
            "It kind of gets really excited about swinging this thing up and now it has now it has new experience now and learns from this experience that the last strategy was maybe a little bit too aggressive.",
            "And now in the subsequent trials you can actually see how the learner tries to slow down the swing up movement and tries to keep the.",
            "To balance the pendulum in this inverted position, and this is one of the very few reinforcement learning methods where you can actually see an improvement at each time, each in each trial, and you don't have to wait for thousands of iterations.",
            "OK, so that was the difference between simulation and reality.",
            "In simulation you have an infinitely long track.",
            "In reality you don't.",
            "And so after 7 after 7 trials and less than 20 seconds of data, we could learn a reasonably good model and a reasonably good controller that balances the pendulum here and it's even robust to small disturbances.",
            "So that's how the algorithm works.",
            "And so code is freely available.",
            "The nice thing with benchmark problems is that other people also try this.",
            "It's really good, so I can.",
            "I can also show how much, say, data other people needed for solving the same problem, so we're talking only about reinforcement learning where you you don't have any useful prior information, so no, say optimal control methods where you actually know the model, and so here the references to the literature on the Y axis.",
            "We have the required interaction time in seconds.",
            "On a logarithmic scale.",
            "Compared to all of these methods.",
            "We are here.",
            "So in order of magnitude better.",
            "This approach is based on multilayer perceptrons.",
            "I think is from from Helsinki.",
            "And we achieve an unprecedented speed of learning compared to state of the art reinforcement learning.",
            "So this was very encouraging and we thought, OK. Now let's apply this to some sort of like different problems."
        ],
        [
            "So we try to learn we made a relatively cheap robot.",
            "Learn to stack a tower of blocks fully autonomously.",
            "The robot is very noisy.",
            "We used to connect camera for tracking and we only had information about the block in the gripper, so we didn't have any information about the configuration of the robot.",
            "And this is again learning from scratch.",
            "And so yeah, so this was a prototype of a Kinect camera.",
            "Here you can see that.",
            "The robot is basically a piece of junk.",
            "And you can't.",
            "So the nice thing is with this fast learning you can actually apply reinforcement learning to this robot arm, but my experience was that if you actually do say around 50 experiments, you start tightening the screws and after 70 or 80 experiments the gripper falls off and so you can't do thousands of experiments.",
            "So the Connect camera tracks the block in the gripper and the after about 20 trials.",
            "The robot learns to stack this power.",
            "This tower of blocks six blocks fully autonomously, very low sampling frequency.",
            "That also makes sure that we don't have too much data, too much data.",
            "But it's the same idea as we had behind this card code problem.",
            "The error function was the distance between the block and the target position where it should go to.",
            "So that kind of information was was included."
        ],
        [
            "OK, so this is another interesting thing, so I'm not involved in this besides for spending the code.",
            "So Bosch applied this learning method for controlling throttle valves in combustion engine's.",
            "And so I'm just going to show a quick quick video.",
            "Or parts of a video?",
            "So the entire.",
            "I think the entire learning learning is very similar, so they start so they start with.",
            "With random collection of data by kind of like doing motor babbling to the throttle valve.",
            "And so if we scroll move forward.",
            "You can give a desire.",
            "It's very hard to see here, so the you give a desired trajectory through through the desired trajectory of the throttle valve and the controller makes sure that it can actually follow this desired trajectory and you can change it on time like on the fly.",
            "You can do whatever you want and if I remember correctly, the people involved in this project told me that this controller works better than the implemented PD controllers.",
            "They have an actual combustion engine.",
            "So.",
            "How much time do I have?",
            "10 OK, great."
        ],
        [
            "So first summary.",
            "So I presented a practical framework for autonomous learning.",
            "The key here is really the explicit incorporation of model uncertainty into modeling and predict into predicting and also into decision making.",
            "And we applied it to a bunch of real systems."
        ],
        [
            "So now let's let me have a just quickly go through the Bayesian optimization part where we kind of failed with the with the reinforcement learning method that I just presented."
        ],
        [
            "So we were interested in.",
            "In learning controllers for small by people robot.",
            "The problem with this robot is that learning these forward models is actually quite tricky when you have impact and ground when you have ground Contacts, because then the functions we want to model are not differentiable anymore and then the Gaussian process assumption of you have some sort of smoothness in there fails.",
            "You can say, well we can smooth them out.",
            "That's also.",
            "Well, that's what I thought, but at some point when we do these long term predictions this smoothing out.",
            "Cause some sort of uncertainty in the model, and this uncertainty propagates overtime very unfavorably.",
            "So after three or four prediction steps you have aerobars of that size and that's kind of useless and collecting more data was not helpful anymore.",
            "Right, so in order to do this approximate inference, we rely on polynomial kernels or on squared exponential kernels.",
            "You could probably, so we just for modeling purposes.",
            "We also tried a neural network kernel that was not very helpful either.",
            "We have other solutions to this problem, but I can't talk about this right noise, but we can maybe talk about this offline.",
            "So, but in the end we have the same problem again, so we want to find parameters to control this bipad.",
            "Challenges here were, well, we can't learn a good forward model.",
            "We have no analytic cost function and no demonstrations, so we kind of want to make this robot walk, but we can't actually write down a cost function in terms of as a function of the parameters, so it's very tricky.",
            "We still need to be data efficient because if you run I think around 100 or 200 experiments with the robot you need to replace the Motors.",
            "That changes the mechanical properties and then you can basically start from scratch.",
            "And manual parameters search.",
            "So we have 8 parameters we have.",
            "Two actuated knees and two actuated tips, and each of these actuated.",
            "Degrees of freedom.",
            "They have two controller parameters, so it's eight parameters in the end so.",
            "We are not free my students.",
            "He spent a couple of weeks on finding these eight parameters such that the robot was could actually limp like this without falling an.",
            "He said Mark, I really hate this.",
            "I hate engineering and then he said then we said, well, let's do Bayesian optimization because that's like a problem where we can apply this to.",
            "So we don't want to do many function evaluations.",
            "We want to find some good parameters and we can't really write down the loss function.",
            "So yeah, so we use Bayesian optimization for this, and Nando introduced Bayesian optimization before, so really appreciate that."
        ],
        [
            "The idea so this is Roberto Calandra, so he's in dump shot still and so he spent quite a while on this kind of hardware.",
            "Idea was we want to maximize robustness and walking speed, so robustness robustness in terms of be robust to initial configurations and maybe also some.",
            "To some noise.",
            "For Motors with two actuator tips and two actuated knees.",
            "With eight parameters and with Bayesian optimization, we found good parameters.",
            "After approximately 100 experiments and I have a short video for this, whoops.",
            "For this one too.",
            "So here.",
            "Now so we don't learn the forward.",
            "We don't learn the we don't learn the dynamics of this robot.",
            "We just.",
            "Learn so the Bayesian optimization does a mapping from controller parameters to walking speed.",
            "That's the objective function.",
            "Or walking distance in 12 seconds time.",
            "So the initially this robot was or the other controller parameterisation was kind of useless.",
            "The first snippet shows.",
            "What the controller does after a few optimizations.",
            "This one is already like halfway through, but it's still very unstable and you can maybe also understand that you can't run thousands of experiments with this robot on without destroying this robot.",
            "But after these 80 or 100 experiments we got a really good walking gait, so it was running for I think 10 or 15 rounds on this table without falling.",
            "Velocity was 45 centimeters per second, which was approximately.",
            "As good as the engineered Walking Gate, a PhD students spend in his entire PhD on actually getting this thing while designing this thing and doing the controller prioritization, the finite state machine makes sure that it is a periodical thing.",
            "Yes, yes, yeah, yeah, right.",
            "So we assume that the parameterisation is given and it basically said if you're.",
            "You know if if your configuration of the of the two legs is like this, apply that torque and you could change these parameters.",
            "So this was the talk for each of these Motors was one parameter, so you have four parameters and then you have angle configurations and ground contact.",
            "And there's also info.",
            "In these finite state machines."
        ],
        [
            "OK, so second summary is well, we use Bayesian optimization for learning controllers in only very few experiments.",
            "In this context of this by people robot, so Bayesian optimization is a very general framework and we don't need to do any assumptions on the dynamics.",
            "We don't need an explicit cost function like this C function that penalizes squared distances or something, but practically limited to.",
            "I would say 10 or 20 parameters.",
            "Maybe number has.",
            "Updates, but you also said something like this earlier, like it yeah, effectively.",
            "No, no, I'm talking about prom prom.",
            "Yeah yeah OK.",
            "So if the intrinsic dimensionality.",
            "Yeah.",
            "Yeah.",
            "Right?"
        ],
        [
            "Alright, if you quickly wrap up I was talking bout or introducing.",
            "Two ideas for controller learning for autonomous systems.",
            "One was based on reinforcement learning, one based on Bayesian optimization, but in both of these methods the key to the success was probabilistic modeling and Bayesian inference.",
            "So thank you for your attention.",
            "I have one more slide in my own interest I'm hiring.",
            "I have 3 1/2 years PhD position funded at Imperial College, so if you know a master student.",
            "Unfortunately, he or she needs to be you citizen.",
            "It's a UK who's interested in probabilistic machine learning, then please forward that information to that person and get into or get in touch with me.",
            "Well, thank you very much."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So I hope you're not too sleepy.",
                    "label": 0
                },
                {
                    "sent": "After lunch.",
                    "label": 0
                },
                {
                    "sent": "Might come later, so I'm going to talk a little bit about how we can use space in machine learning methods for control for robot control or for mechanical systems control.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So if we talk about autonomous systems, then we basically need to talk about three key challenging challenges.",
                    "label": 1
                },
                {
                    "sent": "One is modeling, one is predicting and one is decision making.",
                    "label": 0
                },
                {
                    "sent": "For example, if we look at this super robot over here, we might be interested in modeling the dynamics of the kinematics of this robot, but typically we're not really done with modeling, but we also want to use this kind of model for doing predictions.",
                    "label": 0
                },
                {
                    "sent": "So what's going to happen when we activate this robot?",
                    "label": 0
                },
                {
                    "sent": "And based on these predictions, we also want to change the control signals, which basically corresponds to a decision making problem.",
                    "label": 0
                },
                {
                    "sent": "The problem is that especially with these kind of robots, we have a lot of noisy signals and the processes which generate the underlying which generate these signals might be not very well understood.",
                    "label": 0
                },
                {
                    "sent": "For example, if you have this robot here with some sort of like elasticities, we have a lot of noise and uncertainty and actually modeling these elasticities or also impact when we when we start walking.",
                    "label": 0
                },
                {
                    "sent": "So this is tricky and we need to model these things.",
                    "label": 1
                },
                {
                    "sent": "And if we want to increase the autonomy of today's robots, we need to deal with uncertainties instead of like engineering this away and Bayesian machine learning is a principled framework for dealing with these uncertainties.",
                    "label": 0
                },
                {
                    "sent": "So based on machine learning and also this modeling predicting and decision making problems are.",
                    "label": 1
                },
                {
                    "sent": "Also there in other kind of applications.",
                    "label": 0
                },
                {
                    "sent": "For example, if you look at climate science, we might wonder model the climate based on CO2 emissions model.",
                    "label": 0
                },
                {
                    "sent": "The effect of CO2 emissions on the climate.",
                    "label": 0
                },
                {
                    "sent": "And we might even want to change some of these.",
                    "label": 0
                },
                {
                    "sent": "Some of our policies in terms of heating and whatever to have some sort of impact brain computer interface.",
                    "label": 0
                },
                {
                    "sent": "We might be interested in using huge signals to to infer what the human actually wants to do.",
                    "label": 0
                },
                {
                    "sent": "An actuator robot to do it in the end?",
                    "label": 0
                },
                {
                    "sent": "Or we could use neural signals to control prosthetic hands.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the outline of my talk is basically.",
                    "label": 0
                },
                {
                    "sent": "As follows, so I'm very focused on controller learning in this talk, so I'm not talking about climate signs or anything else.",
                    "label": 0
                },
                {
                    "sent": "Controller learning for robots and mechanical systems.",
                    "label": 1
                },
                {
                    "sent": "I'm going to talk about two approaches to four controller learning.",
                    "label": 0
                },
                {
                    "sent": "One is based on reinforcement learning and one is based on Bayesian optimization.",
                    "label": 0
                },
                {
                    "sent": "So the interesting thing here is also that we have we have two kind of approaches.",
                    "label": 0
                },
                {
                    "sent": "For controller learning here, this one was basically from the point of view.",
                    "label": 0
                },
                {
                    "sent": "We have a method and we apply the method in the end.",
                    "label": 0
                },
                {
                    "sent": "Here we had a problem where we couldn't apply that method.",
                    "label": 0
                },
                {
                    "sent": "I'm going to explain why afterwards and then we use the machine learning technique to solve this problem.",
                    "label": 0
                },
                {
                    "sent": "So from method to problem and this one was from problem to method.",
                    "label": 0
                },
                {
                    "sent": "So let's start with the.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Reinforcement learning part.",
                    "label": 0
                },
                {
                    "sent": "So we consider a set up where we have a state of Aleutian so XD plus one is a function of XT&UT, so access the state.",
                    "label": 0
                },
                {
                    "sent": "You is a control signal and F is an unknown transition function.",
                    "label": 0
                },
                {
                    "sent": "We have some noise on top here.",
                    "label": 0
                },
                {
                    "sent": "We also assume that the control is a function of the state and some parameters and this function is called the policy in these parameters were parameterized the policy.",
                    "label": 0
                },
                {
                    "sent": "So the objective is that we want to find pulse parameters Theta star that minimize some sort of expected long-term cost which is denoted by J of Theta.",
                    "label": 1
                },
                {
                    "sent": "So it's a sum over a finite time horizon of some.",
                    "label": 0
                },
                {
                    "sent": "Expected cost.",
                    "label": 0
                },
                {
                    "sent": "We have an initial distribution over overall start state and we assume that this one is Gaussian and this instantaneous costaceae vex could for example be a squared distance between your current position and where you actually want to go in the end.",
                    "label": 0
                },
                {
                    "sent": "And there's some typical objective in reinforcement learning or optimal control.",
                    "label": 1
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So I'm going to propose or introduce a very conceptually very simple algorithm for solving this problem.",
                    "label": 0
                },
                {
                    "sent": "So we want to minimize this expected long-term cost, and the algorithm proceeds in four steps.",
                    "label": 1
                },
                {
                    "sent": "Very high level.",
                    "label": 1
                },
                {
                    "sent": "Initially we learn a probabilistic model for this transition function, and it needs to be probabilistic to be robust to model errors, and I'm going to explain that in a little bit.",
                    "label": 1
                },
                {
                    "sent": "Then we use this model to compute long-term predictions of the state evolution conditioned on on the current parameterisation of the policy.",
                    "label": 0
                },
                {
                    "sent": "Then we improve this policy based on these long-term predictions and when we improve the policy, we go back and say, OK, let's apply this controller to our system.",
                    "label": 0
                },
                {
                    "sent": "Yes please.",
                    "label": 0
                },
                {
                    "sent": "Function.",
                    "label": 0
                },
                {
                    "sent": "Yes, so I know the parameterisation of the policy function, so I fixed the parameterisation.",
                    "label": 0
                },
                {
                    "sent": "OK, so I'm going to go through all of these steps at some reasonably high level, so let's start.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The probabilistic model.",
                    "label": 0
                },
                {
                    "sent": "Assuming that we want to learn a model, then this model learning problem is basically a regression problem.",
                    "label": 1
                },
                {
                    "sent": "So let's for example, say we want to find a function of Maps X2F of X, and for simplicity assume these.",
                    "label": 0
                },
                {
                    "sent": "These observations, these Y values are noise free, so solving this model learning problem corresponds to finding a function that kind of goes through all of these points.",
                    "label": 1
                },
                {
                    "sent": "So let's do.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So that so this is my function.",
                    "label": 0
                },
                {
                    "sent": "It goes through all of these points, solves the problem.",
                    "label": 0
                },
                {
                    "sent": "But usually we're not done with modeling, but we also want to do predictions.",
                    "label": 0
                },
                {
                    "sent": "And based on these predictions, we want to make make decisions.",
                    "label": 0
                },
                {
                    "sent": "So if.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So what's going to happen at X = 7?",
                    "label": 0
                },
                {
                    "sent": "This function is going to say oh it's minus one, so I'm happy with minus one.",
                    "label": 0
                },
                {
                    "sent": "Go to my policy, apply my controller, and I fall off the Cliff.",
                    "label": 0
                },
                {
                    "sent": "That can happen, right?",
                    "label": 0
                },
                {
                    "sent": "Because you don't actually know anything about the function in this area, so other possible function approximators that also solve this regression problem?",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here and they give you completely different answers, so this was minus one.",
                    "label": 0
                },
                {
                    "sent": "This is plus one.",
                    "label": 0
                },
                {
                    "sent": "This is zero, and that could be decisions go left, go right or don't do anything.",
                    "label": 0
                },
                {
                    "sent": "And if you walk along the Cliff you fall over at some point.",
                    "label": 0
                },
                {
                    "sent": "So, but what you actually want to do is you want to express your kind of uncertainty about the model in areas we haven't.",
                    "label": 0
                },
                {
                    "sent": "We haven't observed anything and you can do this with.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Probabilistic model.",
                    "label": 0
                },
                {
                    "sent": "Probabilistic model at X = 7 would say well on average.",
                    "label": 0
                },
                {
                    "sent": "I think it's zero, but I have no clue.",
                    "label": 0
                },
                {
                    "sent": "And if you take this no clue into consideration when you make decisions then you are more robust to say wrong models.",
                    "label": 0
                },
                {
                    "sent": "Then when you actually use a deterministic model.",
                    "label": 0
                },
                {
                    "sent": "So I think or we think it's very.",
                    "label": 0
                },
                {
                    "sent": "Essentially that you express uncertainty about the underlying function, and we're going to use Gaussian processes for solving this model learning problem.",
                    "label": 1
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So assuming we have now these Gaussian processes for this transition function, let's have a look at how we compute these long term predictions of the of these states.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the idea is basically to iteratively compute these probability distributions P of X1 to P of X capital T. Assuming you have an initial start date, start set distribution here you propagate this information of this uncertainty overtime and follow.",
                    "label": 0
                },
                {
                    "sent": "Basically these dashed line.",
                    "label": 0
                },
                {
                    "sent": "In the context of a GP this.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It's like this.",
                    "label": 0
                },
                {
                    "sent": "So assuming we have a Gaussian distribution over state and controls at timestep T, you want to map this Gaussian distribution through a probabilistic Gaussian process.",
                    "label": 0
                },
                {
                    "sent": "And then you would.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "10 The next state distribution.",
                    "label": 0
                },
                {
                    "sent": "So I'm sorry it's almost invisible.",
                    "label": 0
                },
                {
                    "sent": "Think potentially problem with projector, so this says PFX T + 1 is a triple integral of.",
                    "label": 0
                },
                {
                    "sent": "Well, basically this model times this model and we integrate out everything that is uncertain, so it's X because we have a distribution over X.",
                    "label": 0
                },
                {
                    "sent": "We have a distribution over U and we also have a probability distribution over the function which is given by this Gaussian process.",
                    "label": 0
                },
                {
                    "sent": "And if we integrate that out, then.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We get this probability distribution.",
                    "label": 0
                },
                {
                    "sent": "Problem is you can't actually compute this interval, so I only got this 2 Monte Carlo sampling with a kernel density estimator afterwards to make it look nice.",
                    "label": 0
                },
                {
                    "sent": "So you can't solve this integral.",
                    "label": 0
                },
                {
                    "sent": "That's a problem, but what you can do is you can compute the mean and the variance of this distribution and just say OK.",
                    "label": 0
                },
                {
                    "sent": "I just fitted Gaussian to this, so if you do that, you have this kind of fit to this.",
                    "label": 0
                },
                {
                    "sent": "In this example.",
                    "label": 0
                },
                {
                    "sent": "And this is called moment matching, and we're going to use that to compute these predictive distributions.",
                    "label": 0
                },
                {
                    "sent": "So if this is your next set distribution, you can kind of like feed that in here and then cycle through iteratively and get these.",
                    "label": 0
                },
                {
                    "sent": "Say approximations to these predicted state distributions, P. FX-1 to PFX capital T.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So, assuming that we have now, these are approximations of these state distributions that improve the policy.",
                    "label": 0
                },
                {
                    "sent": "So it's basically 2 steps.",
                    "label": 0
                },
                {
                    "sent": "We compute the expected long-term cost J.",
                    "label": 1
                },
                {
                    "sent": "So this guy over here and then find parameters which minimize this J.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So if you already know how to predict or how to get this sequence of state distributions while computing J just boils down to computing these expected values at each time step and sum them up.",
                    "label": 1
                },
                {
                    "sent": "So, given that we have Gaussian approximations of the state distributions, we just need to integrate our cost function against this against a Gaussian distribution.",
                    "label": 0
                },
                {
                    "sent": "And since we can choose this cost function, we just assume that we can compute this in closed form so.",
                    "label": 0
                },
                {
                    "sent": "C could for example be any polynomial it could be.",
                    "label": 0
                },
                {
                    "sent": "Fourier series expansion could be radial basis function, network.",
                    "label": 0
                },
                {
                    "sent": "So there's various various functions you can choose to for this cost function instead of question.",
                    "label": 0
                },
                {
                    "sent": "So sorry, so so we can compute these guys, sum them up and then we have J.",
                    "label": 0
                },
                {
                    "sent": "So nice thing is that so far everything is can be computed in closed form, so no sampling, nothing.",
                    "label": 0
                },
                {
                    "sent": "And that also means that we can compute the gradients of J with respect to the policy.",
                    "label": 0
                },
                {
                    "sent": "Parameters can be computed in close form.",
                    "label": 0
                },
                {
                    "sent": "And if we have the gradient and we have the function value where you can use a standard Bayesian standard gradient based optimizer, for example beefs to find Theta star.",
                    "label": 0
                },
                {
                    "sent": "So it's not a global.",
                    "label": 0
                },
                {
                    "sent": "Probably don't file find the global minimum, but something that is useful.",
                    "label": 1
                },
                {
                    "sent": "And that's exactly what this with our pickle framework for controller learning does.",
                    "label": 0
                },
                {
                    "sent": "So this is, this is what it's based on.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And I think I'm going to demonstrate how it works in an example, so here's an example which some of us know from, usually from simulation.",
                    "label": 0
                },
                {
                    "sent": "It's a center benchmark problem.",
                    "label": 1
                },
                {
                    "sent": "It's called the cart pole swing up.",
                    "label": 1
                },
                {
                    "sent": "We have a cart running on a track, appendages attached to it.",
                    "label": 1
                },
                {
                    "sent": "The pendulum is freely swinging.",
                    "label": 0
                },
                {
                    "sent": "Initially it's hanging downwards and the idea is to find a strategy that swings the pendulum up and balances it in the middle of the track where the red crosses.",
                    "label": 0
                },
                {
                    "sent": "We have a cost function C which is a non normalized Gaussian or 1 minus and a normalized Gaussian.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "And it penalizes the distance from the tip of the pendulum to the Red Cross.",
                    "label": 0
                },
                {
                    "sent": "So no velocity penalties and no control penalties and.",
                    "label": 0
                },
                {
                    "sent": "The learning framework.",
                    "label": 0
                },
                {
                    "sent": "We just search one work.",
                    "label": 0
                },
                {
                    "sent": "So works like this, so initially we apply some random actions to the system to collect a small initial data set.",
                    "label": 0
                },
                {
                    "sent": "So we do this twice, so each of these trials is about two or is 2 1/2 seconds long.",
                    "label": 0
                },
                {
                    "sent": "Sampling rate is 10 Hertz.",
                    "label": 0
                },
                {
                    "sent": "Then we have these like 50 data points, training Gaussian process model.",
                    "label": 0
                },
                {
                    "sent": "Do these long-term predictions improve the policy?",
                    "label": 0
                },
                {
                    "sent": "Go back to the system and apply the policy.",
                    "label": 0
                },
                {
                    "sent": "OK, so this was very say you would say useless, but it already learned that it needs to keep the card in the middle of the track.",
                    "label": 0
                },
                {
                    "sent": "The model was very very uncertain.",
                    "label": 0
                },
                {
                    "sent": "But it now has new experience now can update the model and update the policy and the next time it applies the policy.",
                    "label": 0
                },
                {
                    "sent": "It kind of gets really excited about swinging this thing up and now it has now it has new experience now and learns from this experience that the last strategy was maybe a little bit too aggressive.",
                    "label": 0
                },
                {
                    "sent": "And now in the subsequent trials you can actually see how the learner tries to slow down the swing up movement and tries to keep the.",
                    "label": 0
                },
                {
                    "sent": "To balance the pendulum in this inverted position, and this is one of the very few reinforcement learning methods where you can actually see an improvement at each time, each in each trial, and you don't have to wait for thousands of iterations.",
                    "label": 0
                },
                {
                    "sent": "OK, so that was the difference between simulation and reality.",
                    "label": 0
                },
                {
                    "sent": "In simulation you have an infinitely long track.",
                    "label": 0
                },
                {
                    "sent": "In reality you don't.",
                    "label": 0
                },
                {
                    "sent": "And so after 7 after 7 trials and less than 20 seconds of data, we could learn a reasonably good model and a reasonably good controller that balances the pendulum here and it's even robust to small disturbances.",
                    "label": 0
                },
                {
                    "sent": "So that's how the algorithm works.",
                    "label": 0
                },
                {
                    "sent": "And so code is freely available.",
                    "label": 0
                },
                {
                    "sent": "The nice thing with benchmark problems is that other people also try this.",
                    "label": 0
                },
                {
                    "sent": "It's really good, so I can.",
                    "label": 1
                },
                {
                    "sent": "I can also show how much, say, data other people needed for solving the same problem, so we're talking only about reinforcement learning where you you don't have any useful prior information, so no, say optimal control methods where you actually know the model, and so here the references to the literature on the Y axis.",
                    "label": 0
                },
                {
                    "sent": "We have the required interaction time in seconds.",
                    "label": 1
                },
                {
                    "sent": "On a logarithmic scale.",
                    "label": 0
                },
                {
                    "sent": "Compared to all of these methods.",
                    "label": 0
                },
                {
                    "sent": "We are here.",
                    "label": 0
                },
                {
                    "sent": "So in order of magnitude better.",
                    "label": 0
                },
                {
                    "sent": "This approach is based on multilayer perceptrons.",
                    "label": 0
                },
                {
                    "sent": "I think is from from Helsinki.",
                    "label": 0
                },
                {
                    "sent": "And we achieve an unprecedented speed of learning compared to state of the art reinforcement learning.",
                    "label": 0
                },
                {
                    "sent": "So this was very encouraging and we thought, OK. Now let's apply this to some sort of like different problems.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we try to learn we made a relatively cheap robot.",
                    "label": 0
                },
                {
                    "sent": "Learn to stack a tower of blocks fully autonomously.",
                    "label": 0
                },
                {
                    "sent": "The robot is very noisy.",
                    "label": 1
                },
                {
                    "sent": "We used to connect camera for tracking and we only had information about the block in the gripper, so we didn't have any information about the configuration of the robot.",
                    "label": 1
                },
                {
                    "sent": "And this is again learning from scratch.",
                    "label": 0
                },
                {
                    "sent": "And so yeah, so this was a prototype of a Kinect camera.",
                    "label": 0
                },
                {
                    "sent": "Here you can see that.",
                    "label": 0
                },
                {
                    "sent": "The robot is basically a piece of junk.",
                    "label": 0
                },
                {
                    "sent": "And you can't.",
                    "label": 0
                },
                {
                    "sent": "So the nice thing is with this fast learning you can actually apply reinforcement learning to this robot arm, but my experience was that if you actually do say around 50 experiments, you start tightening the screws and after 70 or 80 experiments the gripper falls off and so you can't do thousands of experiments.",
                    "label": 1
                },
                {
                    "sent": "So the Connect camera tracks the block in the gripper and the after about 20 trials.",
                    "label": 0
                },
                {
                    "sent": "The robot learns to stack this power.",
                    "label": 0
                },
                {
                    "sent": "This tower of blocks six blocks fully autonomously, very low sampling frequency.",
                    "label": 0
                },
                {
                    "sent": "That also makes sure that we don't have too much data, too much data.",
                    "label": 0
                },
                {
                    "sent": "But it's the same idea as we had behind this card code problem.",
                    "label": 0
                },
                {
                    "sent": "The error function was the distance between the block and the target position where it should go to.",
                    "label": 0
                },
                {
                    "sent": "So that kind of information was was included.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so this is another interesting thing, so I'm not involved in this besides for spending the code.",
                    "label": 0
                },
                {
                    "sent": "So Bosch applied this learning method for controlling throttle valves in combustion engine's.",
                    "label": 1
                },
                {
                    "sent": "And so I'm just going to show a quick quick video.",
                    "label": 0
                },
                {
                    "sent": "Or parts of a video?",
                    "label": 0
                },
                {
                    "sent": "So the entire.",
                    "label": 0
                },
                {
                    "sent": "I think the entire learning learning is very similar, so they start so they start with.",
                    "label": 0
                },
                {
                    "sent": "With random collection of data by kind of like doing motor babbling to the throttle valve.",
                    "label": 0
                },
                {
                    "sent": "And so if we scroll move forward.",
                    "label": 0
                },
                {
                    "sent": "You can give a desire.",
                    "label": 0
                },
                {
                    "sent": "It's very hard to see here, so the you give a desired trajectory through through the desired trajectory of the throttle valve and the controller makes sure that it can actually follow this desired trajectory and you can change it on time like on the fly.",
                    "label": 0
                },
                {
                    "sent": "You can do whatever you want and if I remember correctly, the people involved in this project told me that this controller works better than the implemented PD controllers.",
                    "label": 0
                },
                {
                    "sent": "They have an actual combustion engine.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "How much time do I have?",
                    "label": 0
                },
                {
                    "sent": "10 OK, great.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So first summary.",
                    "label": 0
                },
                {
                    "sent": "So I presented a practical framework for autonomous learning.",
                    "label": 1
                },
                {
                    "sent": "The key here is really the explicit incorporation of model uncertainty into modeling and predict into predicting and also into decision making.",
                    "label": 1
                },
                {
                    "sent": "And we applied it to a bunch of real systems.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So now let's let me have a just quickly go through the Bayesian optimization part where we kind of failed with the with the reinforcement learning method that I just presented.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we were interested in.",
                    "label": 0
                },
                {
                    "sent": "In learning controllers for small by people robot.",
                    "label": 0
                },
                {
                    "sent": "The problem with this robot is that learning these forward models is actually quite tricky when you have impact and ground when you have ground Contacts, because then the functions we want to model are not differentiable anymore and then the Gaussian process assumption of you have some sort of smoothness in there fails.",
                    "label": 0
                },
                {
                    "sent": "You can say, well we can smooth them out.",
                    "label": 0
                },
                {
                    "sent": "That's also.",
                    "label": 0
                },
                {
                    "sent": "Well, that's what I thought, but at some point when we do these long term predictions this smoothing out.",
                    "label": 0
                },
                {
                    "sent": "Cause some sort of uncertainty in the model, and this uncertainty propagates overtime very unfavorably.",
                    "label": 0
                },
                {
                    "sent": "So after three or four prediction steps you have aerobars of that size and that's kind of useless and collecting more data was not helpful anymore.",
                    "label": 0
                },
                {
                    "sent": "Right, so in order to do this approximate inference, we rely on polynomial kernels or on squared exponential kernels.",
                    "label": 0
                },
                {
                    "sent": "You could probably, so we just for modeling purposes.",
                    "label": 0
                },
                {
                    "sent": "We also tried a neural network kernel that was not very helpful either.",
                    "label": 0
                },
                {
                    "sent": "We have other solutions to this problem, but I can't talk about this right noise, but we can maybe talk about this offline.",
                    "label": 0
                },
                {
                    "sent": "So, but in the end we have the same problem again, so we want to find parameters to control this bipad.",
                    "label": 0
                },
                {
                    "sent": "Challenges here were, well, we can't learn a good forward model.",
                    "label": 0
                },
                {
                    "sent": "We have no analytic cost function and no demonstrations, so we kind of want to make this robot walk, but we can't actually write down a cost function in terms of as a function of the parameters, so it's very tricky.",
                    "label": 0
                },
                {
                    "sent": "We still need to be data efficient because if you run I think around 100 or 200 experiments with the robot you need to replace the Motors.",
                    "label": 1
                },
                {
                    "sent": "That changes the mechanical properties and then you can basically start from scratch.",
                    "label": 0
                },
                {
                    "sent": "And manual parameters search.",
                    "label": 0
                },
                {
                    "sent": "So we have 8 parameters we have.",
                    "label": 0
                },
                {
                    "sent": "Two actuated knees and two actuated tips, and each of these actuated.",
                    "label": 0
                },
                {
                    "sent": "Degrees of freedom.",
                    "label": 0
                },
                {
                    "sent": "They have two controller parameters, so it's eight parameters in the end so.",
                    "label": 0
                },
                {
                    "sent": "We are not free my students.",
                    "label": 0
                },
                {
                    "sent": "He spent a couple of weeks on finding these eight parameters such that the robot was could actually limp like this without falling an.",
                    "label": 0
                },
                {
                    "sent": "He said Mark, I really hate this.",
                    "label": 0
                },
                {
                    "sent": "I hate engineering and then he said then we said, well, let's do Bayesian optimization because that's like a problem where we can apply this to.",
                    "label": 0
                },
                {
                    "sent": "So we don't want to do many function evaluations.",
                    "label": 0
                },
                {
                    "sent": "We want to find some good parameters and we can't really write down the loss function.",
                    "label": 1
                },
                {
                    "sent": "So yeah, so we use Bayesian optimization for this, and Nando introduced Bayesian optimization before, so really appreciate that.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The idea so this is Roberto Calandra, so he's in dump shot still and so he spent quite a while on this kind of hardware.",
                    "label": 0
                },
                {
                    "sent": "Idea was we want to maximize robustness and walking speed, so robustness robustness in terms of be robust to initial configurations and maybe also some.",
                    "label": 1
                },
                {
                    "sent": "To some noise.",
                    "label": 1
                },
                {
                    "sent": "For Motors with two actuator tips and two actuated knees.",
                    "label": 0
                },
                {
                    "sent": "With eight parameters and with Bayesian optimization, we found good parameters.",
                    "label": 0
                },
                {
                    "sent": "After approximately 100 experiments and I have a short video for this, whoops.",
                    "label": 0
                },
                {
                    "sent": "For this one too.",
                    "label": 0
                },
                {
                    "sent": "So here.",
                    "label": 0
                },
                {
                    "sent": "Now so we don't learn the forward.",
                    "label": 0
                },
                {
                    "sent": "We don't learn the we don't learn the dynamics of this robot.",
                    "label": 0
                },
                {
                    "sent": "We just.",
                    "label": 0
                },
                {
                    "sent": "Learn so the Bayesian optimization does a mapping from controller parameters to walking speed.",
                    "label": 0
                },
                {
                    "sent": "That's the objective function.",
                    "label": 0
                },
                {
                    "sent": "Or walking distance in 12 seconds time.",
                    "label": 0
                },
                {
                    "sent": "So the initially this robot was or the other controller parameterisation was kind of useless.",
                    "label": 0
                },
                {
                    "sent": "The first snippet shows.",
                    "label": 0
                },
                {
                    "sent": "What the controller does after a few optimizations.",
                    "label": 0
                },
                {
                    "sent": "This one is already like halfway through, but it's still very unstable and you can maybe also understand that you can't run thousands of experiments with this robot on without destroying this robot.",
                    "label": 0
                },
                {
                    "sent": "But after these 80 or 100 experiments we got a really good walking gait, so it was running for I think 10 or 15 rounds on this table without falling.",
                    "label": 0
                },
                {
                    "sent": "Velocity was 45 centimeters per second, which was approximately.",
                    "label": 0
                },
                {
                    "sent": "As good as the engineered Walking Gate, a PhD students spend in his entire PhD on actually getting this thing while designing this thing and doing the controller prioritization, the finite state machine makes sure that it is a periodical thing.",
                    "label": 0
                },
                {
                    "sent": "Yes, yes, yeah, yeah, right.",
                    "label": 0
                },
                {
                    "sent": "So we assume that the parameterisation is given and it basically said if you're.",
                    "label": 0
                },
                {
                    "sent": "You know if if your configuration of the of the two legs is like this, apply that torque and you could change these parameters.",
                    "label": 0
                },
                {
                    "sent": "So this was the talk for each of these Motors was one parameter, so you have four parameters and then you have angle configurations and ground contact.",
                    "label": 0
                },
                {
                    "sent": "And there's also info.",
                    "label": 0
                },
                {
                    "sent": "In these finite state machines.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so second summary is well, we use Bayesian optimization for learning controllers in only very few experiments.",
                    "label": 1
                },
                {
                    "sent": "In this context of this by people robot, so Bayesian optimization is a very general framework and we don't need to do any assumptions on the dynamics.",
                    "label": 0
                },
                {
                    "sent": "We don't need an explicit cost function like this C function that penalizes squared distances or something, but practically limited to.",
                    "label": 0
                },
                {
                    "sent": "I would say 10 or 20 parameters.",
                    "label": 0
                },
                {
                    "sent": "Maybe number has.",
                    "label": 0
                },
                {
                    "sent": "Updates, but you also said something like this earlier, like it yeah, effectively.",
                    "label": 0
                },
                {
                    "sent": "No, no, I'm talking about prom prom.",
                    "label": 0
                },
                {
                    "sent": "Yeah yeah OK.",
                    "label": 0
                },
                {
                    "sent": "So if the intrinsic dimensionality.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Right?",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Alright, if you quickly wrap up I was talking bout or introducing.",
                    "label": 0
                },
                {
                    "sent": "Two ideas for controller learning for autonomous systems.",
                    "label": 1
                },
                {
                    "sent": "One was based on reinforcement learning, one based on Bayesian optimization, but in both of these methods the key to the success was probabilistic modeling and Bayesian inference.",
                    "label": 1
                },
                {
                    "sent": "So thank you for your attention.",
                    "label": 0
                },
                {
                    "sent": "I have one more slide in my own interest I'm hiring.",
                    "label": 0
                },
                {
                    "sent": "I have 3 1/2 years PhD position funded at Imperial College, so if you know a master student.",
                    "label": 0
                },
                {
                    "sent": "Unfortunately, he or she needs to be you citizen.",
                    "label": 0
                },
                {
                    "sent": "It's a UK who's interested in probabilistic machine learning, then please forward that information to that person and get into or get in touch with me.",
                    "label": 0
                },
                {
                    "sent": "Well, thank you very much.",
                    "label": 0
                }
            ]
        }
    }
}