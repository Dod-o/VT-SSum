{
    "id": "ppkxadjwxlkl2arbp54wmnyk2f4vxdpi",
    "title": "Correlation Clustering with Noisy Partial Information",
    "info": {
        "author": [
            "Aravindan Vijayaraghavan, Courant Institute of Mathematical Sciences, New York University (NYU)"
        ],
        "published": "Aug. 20, 2015",
        "recorded": "July 2015",
        "category": [
            "Top->Computer Science->Machine Learning->Active Learning",
            "Top->Computer Science->Machine Learning->Computational Learning Theory",
            "Top->Computer Science->Machine Learning->On-line Learning",
            "Top->Computer Science->Machine Learning->Reinforcement Learning",
            "Top->Computer Science->Machine Learning->Semi-supervised Learning"
        ]
    },
    "url": "http://videolectures.net/colt2015_vijayaraghavan_partial_information/",
    "segmentation": [
        [
            "Hey, so this is based on joint work with constant in McCarthy, Chevron, Urema College who are both here.",
            "And I'll tell you a little bit about how to cluster with qualitative information."
        ],
        [
            "So in many networks today, like social networks, are protein, protein interaction networks.",
            "You're given mean relational information between many pairs of nodes.",
            "OK, so in this work today, we'll talk about relational information that corresponds to qualitative information like between two nodes.",
            "You have some information about whether these two nodes are similar or dissimilar.",
            "OK, so these are represented by typically by sign networks, so you have an edge between two nodes.",
            "If you have some information about mean between them, relational information between them and there's a + between them if they're similar and there's a - between them if they are dissimilar.",
            "OK, and."
        ],
        [
            "The clustering problem using qualitative information was formalized by Bansal, Blum, and Travelers called Correlation Clustering.",
            "Here, given a graph, you have some edges that corresponds to pairs that you have some information about, and you have positive edges that say that these two things are similar.",
            "Positive edges are represented in green here and negative.",
            "It just say that these two pairs are dissimilar.",
            "OK, so they are represented by red here, and ideally you want to find a clustering OK where?",
            "You only have green edges inside the clusters and read it just between the clusters.",
            "OK, but this may not be possible and the goal here is to minimize the disagreements.",
            "OK to minimize the errors.",
            "So one nice thing about this formulation is that you don't need to specify the number of clusters.",
            "Can Fortunately this problem is NP hard and it's also hard to approximate and the best approximation algorithm is a log in factor multiplicative approximation.",
            "OK, so this is intractable in the worst case, so you look at generative models OK, and this is being studied quite a bit and."
        ],
        [
            "A nice generator model for correlation clustering is the following.",
            "You have a ground truth clustering and you have relational information between some of the pairs that is represented by this under undirected graph G, and for every edge that is inside a cluster inside one of the clusters is a ground truth clustering.",
            "You have positive edges and all the edges between clusters in the ground truth clustering or negative edges.",
            "OK, so here now I mean if you just have this kind of a sign graph, it's very easy.",
            "The cluster OK, but then you have some noise, so some of these signs are OK.",
            "They flip with probability excellent.",
            "And all these choices are independently at random.",
            "OK, and the goal is to recover the groundtruth clustering."
        ],
        [
            "This been studied quite a bit of work that introduced correlation clustering also looked at this kind of an average case model and this was seen in the context of a complete graph.",
            "When you have information between all pairs.",
            "OK, and some recent work looks at this problem when the underlying graph is a random graph, a GNP graph.",
            "OK, and the focus of this work is to give results when there is no assumption.",
            "Essentially no assumption about the underlying graph tree.",
            "OK, so this too."
        ],
        [
            "Via flavor of our results.",
            "1st Result is an algorithm which approximates the objective OK.",
            "So Oh yeah, the one thing about the model is set.",
            "The only randomness in the model is in the flips.",
            "There is in what I've said so far, there is no randomness in the graph.",
            "In the first person to give a polynomial time algorithm which gives a very good approximation to the objective for any graph G. OK, with high probability and the randomness is over the flips.",
            "OK, and the other goal that you could ask is can you recover the ground truth clustering and here you cannot do this unless you have some additional assumptions about the graph.",
            "Like for instance it needs to be well connected inside the clusters and so on.",
            "You need enough information between inside the clusters and between every pair of clusters, and if you have some of these minimal assumptions you can also recover the ground truth up to arbitrary accuracy.",
            "OK, whew, this is using simple definite programming, and if you want more details you can look at the poster or you can come and talk to any of us.",
            "Thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Hey, so this is based on joint work with constant in McCarthy, Chevron, Urema College who are both here.",
                    "label": 0
                },
                {
                    "sent": "And I'll tell you a little bit about how to cluster with qualitative information.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So in many networks today, like social networks, are protein, protein interaction networks.",
                    "label": 0
                },
                {
                    "sent": "You're given mean relational information between many pairs of nodes.",
                    "label": 0
                },
                {
                    "sent": "OK, so in this work today, we'll talk about relational information that corresponds to qualitative information like between two nodes.",
                    "label": 0
                },
                {
                    "sent": "You have some information about whether these two nodes are similar or dissimilar.",
                    "label": 0
                },
                {
                    "sent": "OK, so these are represented by typically by sign networks, so you have an edge between two nodes.",
                    "label": 0
                },
                {
                    "sent": "If you have some information about mean between them, relational information between them and there's a + between them if they're similar and there's a - between them if they are dissimilar.",
                    "label": 0
                },
                {
                    "sent": "OK, and.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The clustering problem using qualitative information was formalized by Bansal, Blum, and Travelers called Correlation Clustering.",
                    "label": 1
                },
                {
                    "sent": "Here, given a graph, you have some edges that corresponds to pairs that you have some information about, and you have positive edges that say that these two things are similar.",
                    "label": 0
                },
                {
                    "sent": "Positive edges are represented in green here and negative.",
                    "label": 0
                },
                {
                    "sent": "It just say that these two pairs are dissimilar.",
                    "label": 0
                },
                {
                    "sent": "OK, so they are represented by red here, and ideally you want to find a clustering OK where?",
                    "label": 0
                },
                {
                    "sent": "You only have green edges inside the clusters and read it just between the clusters.",
                    "label": 0
                },
                {
                    "sent": "OK, but this may not be possible and the goal here is to minimize the disagreements.",
                    "label": 0
                },
                {
                    "sent": "OK to minimize the errors.",
                    "label": 0
                },
                {
                    "sent": "So one nice thing about this formulation is that you don't need to specify the number of clusters.",
                    "label": 1
                },
                {
                    "sent": "Can Fortunately this problem is NP hard and it's also hard to approximate and the best approximation algorithm is a log in factor multiplicative approximation.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is intractable in the worst case, so you look at generative models OK, and this is being studied quite a bit and.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "A nice generator model for correlation clustering is the following.",
                    "label": 0
                },
                {
                    "sent": "You have a ground truth clustering and you have relational information between some of the pairs that is represented by this under undirected graph G, and for every edge that is inside a cluster inside one of the clusters is a ground truth clustering.",
                    "label": 0
                },
                {
                    "sent": "You have positive edges and all the edges between clusters in the ground truth clustering or negative edges.",
                    "label": 1
                },
                {
                    "sent": "OK, so here now I mean if you just have this kind of a sign graph, it's very easy.",
                    "label": 0
                },
                {
                    "sent": "The cluster OK, but then you have some noise, so some of these signs are OK.",
                    "label": 1
                },
                {
                    "sent": "They flip with probability excellent.",
                    "label": 1
                },
                {
                    "sent": "And all these choices are independently at random.",
                    "label": 0
                },
                {
                    "sent": "OK, and the goal is to recover the groundtruth clustering.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This been studied quite a bit of work that introduced correlation clustering also looked at this kind of an average case model and this was seen in the context of a complete graph.",
                    "label": 0
                },
                {
                    "sent": "When you have information between all pairs.",
                    "label": 0
                },
                {
                    "sent": "OK, and some recent work looks at this problem when the underlying graph is a random graph, a GNP graph.",
                    "label": 1
                },
                {
                    "sent": "OK, and the focus of this work is to give results when there is no assumption.",
                    "label": 0
                },
                {
                    "sent": "Essentially no assumption about the underlying graph tree.",
                    "label": 1
                },
                {
                    "sent": "OK, so this too.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Via flavor of our results.",
                    "label": 1
                },
                {
                    "sent": "1st Result is an algorithm which approximates the objective OK.",
                    "label": 0
                },
                {
                    "sent": "So Oh yeah, the one thing about the model is set.",
                    "label": 0
                },
                {
                    "sent": "The only randomness in the model is in the flips.",
                    "label": 0
                },
                {
                    "sent": "There is in what I've said so far, there is no randomness in the graph.",
                    "label": 1
                },
                {
                    "sent": "In the first person to give a polynomial time algorithm which gives a very good approximation to the objective for any graph G. OK, with high probability and the randomness is over the flips.",
                    "label": 1
                },
                {
                    "sent": "OK, and the other goal that you could ask is can you recover the ground truth clustering and here you cannot do this unless you have some additional assumptions about the graph.",
                    "label": 0
                },
                {
                    "sent": "Like for instance it needs to be well connected inside the clusters and so on.",
                    "label": 0
                },
                {
                    "sent": "You need enough information between inside the clusters and between every pair of clusters, and if you have some of these minimal assumptions you can also recover the ground truth up to arbitrary accuracy.",
                    "label": 0
                },
                {
                    "sent": "OK, whew, this is using simple definite programming, and if you want more details you can look at the poster or you can come and talk to any of us.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                }
            ]
        }
    }
}