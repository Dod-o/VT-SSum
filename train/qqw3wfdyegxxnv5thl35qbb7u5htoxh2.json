{
    "id": "qqw3wfdyegxxnv5thl35qbb7u5htoxh2",
    "title": "Bio2RDF Release 2: Improved coverage, interoperability and provenance of Life Science Linked Data",
    "info": {
        "introducer": [
            "Olaf Hartig, Hasso-Plattner-Institute, University of Potsdam"
        ],
        "author": [
            "Michel Dumontier, Department of Biology, Carleton University"
        ],
        "published": "July 8, 2013",
        "recorded": "May 2013",
        "category": [
            "Top->Computer Science->Semantic Web",
            "Top->Computer Science->Big Data"
        ]
    },
    "url": "http://videolectures.net/eswc2013_dumontier_data/",
    "segmentation": [
        [
            "Our second speaker today is Michel Dumontier I'm who's giving us an update on the second release of the bio two RDF.",
            "Great, thanks very much so.",
            "Yeah, this is exactly this is our first basically coordinated release of Bio Tour DF.",
            "We are a project that is."
        ],
        [
            "It's an open source project that basically the idea is to use these very simple conventions along with the semantic web framework in order to create and publish and share biological link data on this.",
            "This emerging semantic web."
        ],
        [
            "So really, our motivation here is to reduce the overall time and effort that's taken by pretty much every biology lab Informatics lab to download these resources to convert them to link them together, and then to execute queries.",
            "So really we want to enable more science by spending less time working with just data manipulation.",
            "So by TF is best known for its contributions to the emerging Semantic Web.",
            "This lower right pink portion is largely from bio to DF, along with other partners in the Life Sciences an we can really see our mission as getting the thousands of biological databases that are out there that have been published by science scientific researchers and trying to get those resources immediately available.",
            "On the web, so we're focusing our efforts initially on getting the I guess, the databases that are of primary interest to buy informaticians, the ones that everybody knows and understands.",
            "But really the long term goal is to create the means by which it becomes easier for any one scientist to ultimately publish their database and make it accessible.",
            "Make it searchable and."
        ],
        [
            "Enabling queries across those data so.",
            "If you pay no more attention to this talk, this is basically the summary slide presented to you right now, and so the basic idea for release two was to consolidate the set of open source scripts that were all over the place in so many different formats.",
            "I mean, it's a great open source project, but at the same time we had real issues in terms of quality control and also ensuring that the scripts were up most up to date, and So what we ended up doing is creating a Git project.",
            "And that's I think, really one of the cool things is that we can, you know, people can come in.",
            "They can fork the project that can create their own scripts now and they can do a pull request.",
            "We can do a code review and we can bring that in and make it part of our production pipeline.",
            "So we're pretty excited about that.",
            "All of the scripts were open source there, freely available, so we definitely encourage people to take a look and contribute at the heart of the project.",
            "Is the linking an we spent a little bit of time developing a registry of the datasets in order to generate these.",
            "Conforming your eyes so that when a dentist site makes a reference to another data set, we ensure that we have the linking going on, so that's sort of at the at the core of it.",
            "That's one of the most powerful reasons for this.",
            "For this particular project.",
            "In this release we have over a billion triples in 19 datasets, and that's actually less than what we've had before.",
            "We've reported up to 30 billion triples, and now we're sort of systematically going to the bigger datasets and applying the principles that I'll talk to.",
            "About today.",
            "So on top of just the core infrastructure for generating link data, we have also services to provide access to that, including look up services, sparkle query and query Federation services and other kinds of search functionality."
        ],
        [
            "So in a nutshell, this illustration kind of shows what we're trying to do.",
            "We're taking data from all kinds of formats, some of them you know you would be happy to work with the XML ones.",
            "Maybe the top separated ones.",
            "We've seen a lot of, but in the life Sciences there are hundreds if not thousands of different file formats, right?",
            "And often during these nefarious sort of ad hoc formats.",
            "And so we have to write basically parsers for each one of these kinds of data in order to bring them into it.",
            "So the whole idea is to take these legacy file formats.",
            "Convert them into RDF.",
            "We provide.",
            "We generate now some provenance for this information and we calculate metrics or statistics about the data so that we can understand what it is and how it's connected.",
            "So the data we loaded then into triple stores.",
            "We make it available for downloads that triplestores.",
            "Obviously provide us with the Sparkle services search and faceted browsing is provided right now through Virtuoso.",
            "And the web app provides the resolution of your eyes as well as query."
        ],
        [
            "Iteration services.",
            "So the form basically the syntax that we use for your eye generation follows the one of three patterns.",
            "If the resource provides us with an identifier, then we follow this very simple pattern.",
            "Of course we use our biotruedf.org as the base namespace so that we can do the resolution of the entity.",
            "Then there's a namespace component followed by a colon, an identifier, so the namespace component is basically a preferred short name that is in a registry of these datasets.",
            "OK, and then we can look that up and we say what is the preferred name and we can stick it in there now.",
            "There's lots of data that we get which is not identified, so these might be attributes or they might be other relations to data that simply isn't identified but is captured in some kind of data structure.",
            "So at that point we have to because we want to link data and we want to provide resolution services for every data item we often have to create our own identifiers and so when we do that we put it in a slightly different name space so you can see the syntax is.",
            "We use that preferred prefix_resource: followed by the identifier so that really helps people identify that.",
            "OK, this is something that we created in order to our deifies this data and it's not by no means is it guaranteed stable identifier and it certainly doesn't come from the original data provider.",
            "In the third case, this is where we create vocabulary to support the typing and also the establishing of relations.",
            "So this is especially pertinent when you have a tab file.",
            "For instance, you might have a hint from the column name or from some other descripcion some text file that tells you what the content type is, and so here.",
            "Now we're creating types an relations and we put that in our own namespace again to support the authorization process."
        ],
        [
            "OK, so here's an example from Drug Bank which is a database of drugs and drug targets and drug drug interactions.",
            "So we have will have an entity here where we have drugbank: DBS or 650.",
            "This is the cover and you can see that there's a simple type statement and again the namespaces or vocabulary namespace.",
            "We assigned the identifier which is drug.",
            "Now we service this single triple.",
            "There in Drugbank they also make references to drug drug interactions, but again they don't provide an identifier for this drug drug interaction, so again you can see we used the drug bank_resource.",
            "We assign an identifier for that interaction and we relate the two through this DDI in tractor relation right which we created to support it.",
            "OK, so that's."
        ],
        [
            "All fine, pretty much all the datasets look that they have their own vocabularies to describe the types and relations and provide the linking within the datasets and pointers outwards to other datasets where there are some.",
            "So here's an example where in the bottom box we have data firm Pharm GKB, which is a pharmacogenomics knowledge base to associate drugs with genetics and outcomes.",
            "And there's a relationship between this farm GCB, identifier PA. 450198 and there's a relation that's established.",
            "In the data in the data set to the Drug Bank entry, the Leucovorin Drugbank entry.",
            "Now they use a so called database cross reference or X ref, and so this has an ambiguous meaning.",
            "It may be the same, it may be different, it may be related in some way, but by OTF makes no attempt to tell you anything more than what the providers provide us, right?",
            "So the interpretation is as weak as is provided by the data provider, and so but the important thing is that.",
            "When we make that you write generation when we're processing the pharm GKB data set, we use the registry in the API in order to generate the right UI so that when we put the data together it links together."
        ],
        [
            "So of course we provide the basic RDF look up services with our Beautiful Puppy interface, which we're hoping to change at some point, but the principles are there that after every you arrive that we have there you can click through and the important thing to for us to mention is that we don't actually warehouse this.",
            "Every data set is its own triple, it's its own triple store, and so we're actually crossing from 11 server to another.",
            "And really this is at the heart of this project is that it's meant to be.",
            "A Federation query environment really, really want.",
            "Ultimately nothing would make me happier than not to host any of these datasets.",
            "What we want to do is provide this nice interoperability Sheen that basically helps us do the resolution of these.",
            "Your eyes, especially when they differ in so many different communities."
        ],
        [
            "So not only can when we when we sort of coin one of these by 20 after rise, of course will give you back triples about it, but one of the nice services is that we also know for all of the endpoints we know basically what their contents are.",
            "So we query our endpoints and we can give you what is being, what links to that entry as well.",
            "So this is really nice, right?",
            "This is an expected I think idea of having this linked data warehouse you want to go to one entry and you say, well, who's making statements about this?",
            "And now we can show you those at least within our network."
        ],
        [
            "So every data item.",
            "Now this was one of the big critiques was that it was because we had data being generated at random intervals.",
            "We didn't know when or anything about that data.",
            "Where did it come from?",
            "When was it processed?",
            "What is the licensing associated with it?",
            "So now every data item is annotated with this with void in data set.",
            "And then we described the biotrue DF data set as we produced it and we give you a link back to the original data providers data set description.",
            "Right, so we have you know who created it and in our case actually we give you a pointer to the GitHub script that was responsible for generating that version of the data, provide you with the license and rights description appointer to its availability in terms of what sparkle endpoint is hosting this and where can you get the RDF data itself."
        ],
        [
            "OK, so these are for let's see how many biologists are there in the audience.",
            "Just a handful.",
            "OK, so most of these datasets won't.",
            "You won't recognize, but again, a lot of these are pretty important for informatics.",
            "Just a summary.",
            "So there was the 19.",
            "Some of these are actually one of the things that we found over the last few years.",
            "Was that new resources have come about where they aggregate other ones, so a good example is iref index aggregates.",
            "I believe nine different databases, all-in-one, and they do some additional processing to find equivalence is amongst the data in those datasets.",
            "So in fact, even though we have 19 sort of datasets, there are inside of those there are hundreds of them as independent resources that are being collected by aggregators."
        ],
        [
            "So this we have now a pretty good idea of how our data connects and you can see from this diagram these directed graph we can see from which datasets point to what other datasets.",
            "So some of them are really pointed by everybody.",
            "Pub Med is our repository for literature and so most scientific resources will point to that.",
            "And then we have others that basically are doing the pointing.",
            "So there's a lot of curation in order to save the resources that we're curating here.",
            "You can also find in that database in that database and then DOT database.",
            "So it's a pretty highly connected network, and obviously there's lots of ways to get from anyone data to any other data."
        ],
        [
            "Of course, these are.",
            "That graph is produced from data set statistics that we now collect an we put in the graphs in the put in graphs at each of the sparkle endpoints, so you can query them and you can find out how is this data set tech."
        ],
        [
            "Connected and not only do we have just the entire data set connectivity within the ones that we've already advised, but we actually also see all the other references to all the other datasets that are not on the semantic web.",
            "So this diagram gives you an idea of.",
            "Basically you can see thousands of arcs going outwards to datasets that we know nothing about currently, and so from a prioritization process.",
            "Obviously we're going to be looking at that this connectivity network and trying to determine what's the next data set that we should really be focusing on.",
            "Obviously it's the one that is being most pointed to or we have some indication that they're going to be doing the linking that they're the ones that are aggregating the resources insane.",
            "What's the equivalence or what's the relationship between this data and that data and other data sets?"
        ],
        [
            "Right, so the statistics we published now for each of the datasets.",
            "This is an example of snapshot where we just gave you a basic description of them where the sparkle endpoint, the faceted browser, the script conversion location, the download."
        ],
        [
            "Location and we provide the basic metrics that you would expect, like the number of triples, number of unique subject object and predicates and we give you lists of the number of instances of each of those types."
        ],
        [
            "Along we provide also these statistics that give you the pairing so that basically the number of unique predicates an object links predicate literal links and there."
        ],
        [
            "Counts and I think probably most Interestingly, is this statistics that we compute, which basically tells you how many instances of a certain type or connected to instances of another type through a predicate, and this is really probably the most valuable one in terms of query formulation.",
            "Now I can say, well, I'm interested in drugs.",
            "What do drugs linked to?",
            "How do I go from a drug to some other thing in this data set?",
            "And so in this case we can see, for instance, that we have 11127.",
            "Instances of drug that are.",
            "That are connected to 11,512 instances of Pharmaceuticals through this relation product.",
            "Or similarly here we have 1000 instances of drug that are connected to 10,891 instances of drug drug interactions.",
            "So when you want to start querying, you want to get all the drugs and their drug drug interactions.",
            "You basically have a path, a graph by which you can follow and you can compose your query."
        ],
        [
            "So that's fine, but it turns out that there are already tools that do this.",
            "So Cindy J Tech has this tool called sparkly D which does this graph summarization and provide you with it basically and in context auto completion facility for sparkle.",
            "So we compute their grass statistic we stored in each of our endpoints and now you can deploy the sparkly D tool to help you compose and execute the queries."
        ],
        [
            "Of course, because we use virtuoso, you have the faster browser that comes with it and it, I think that this is sort of a relatively unexplored feature for most people, But it turns out you can do some pretty sophisticated queries.",
            "Without doing any sparkle whatsoever, but basically by starting with the keyword search and then following up by summarizing seeing how many instances of those attributes occur and basically start to create your own path.",
            "And the nice thing is that once you capture this query through this fairly natural process, you can get the sparkle query and then you can use that in some application."
        ],
        [
            "So with the advent of Sparkle 1.1, we're quite excited.",
            "Of course, because one of the big missing features in Bio Shodiev was, well, you've got all of these endpoints, which is kind of useless because the data is all separated.",
            "We have no way to create, but now with Sparkle 11 we can do these Federated queries really really easily, so each of our endpoints are enable Sparkle 1.1 query Federation.",
            "And now we can say OK, take data from this end point and that end point.",
            "And because we know how to it all connects together, it's relatively easy to compose this barcode query.",
            "So in this case I'm again we're using virtual, so six and they don't have the transitive paths implemented yet, so we use a special option.",
            "But basically we can reason about one of the big ontologies which the gene ontology and combine that with another database which uses those terms as annotations so we can pull out specific data using subclass reasoning on an ontology stored in another endpoint.",
            "So I think from my perspective.",
            "You know, we always make this argument that a little bit of semantics goes along way.",
            "This is a good example where having access to an ontology helps you retrieve more results than you would have otherwise, or you would have had to compose a union of queries in order to retrieve all the results, so."
        ],
        [
            "So this is I think basically one of the core functional components that we wanted.",
            "Now one of the problems is that while we have each of these datasets, I would argue that some of our datasets are overlapping in terms of their content and we really don't want to necessarily say, OK, give me the drugbank drug, give me the pharm GKB drug.",
            "Give me the seat drug you need.",
            "The pub chem drug there's like about 10 drug databases.",
            "And really what we want to do at the end of the day, I think being part of the semantic web is that we want to say give me all the drugs that have these characteristics, right?",
            "So how do we?",
            "How do we go there?"
        ],
        [
            "So for US, Ontology is the strategy by which we can semantically unify the resources that we have in bio to DF."
        ],
        [
            "And so we've been developing.",
            "I guess an ontology, which we call the Semantic Science Integrated Ontology which has these basic types and relations that we observe in each of our datasets.",
            "So what we're doing at the very first pass is type is simply mapping the bietry F types in relations to this ontology, and that therefore allows."
        ],
        [
            "Best to do queries."
        ],
        [
            "Basically, sparkle queries using the Scientology to retrieve the instances from each of those endpoints, so the desire graphs are loaded there and now we can execute this even using the service keyword for query Federation.",
            "Anne."
        ],
        [
            "OK, so that pretty much gives you a good idea about what the sort of the state of the art was for January of this year is when we made the release in preparation, and now we're working on our next release, which will be at the end of June and we're basically trying to go for every six months releases and trying to bring more and more of these datasets back online following the conventions that I set out here.",
            "One of the big differences.",
            "I think that will see is we've now created an API that is a little bit easier for application developers to use, so we call that the buyer DEF API.",
            "It's implemented in PHP, but at the heart of it we're using now registry that we're creating in collaboration with a group called identifiers.org, and the idea would be that any any parser any application can refer to API services in order to get that Canonical name, and it will be the Canonical name, not just for Bio TF, but potentially even for the original data.",
            "Provider, so that's always been a big critique.",
            "Some of the data is now finally coming online with their own.",
            "Your eyes that data providers are actually generating RDF, and they're providing sparkle services to them.",
            "And of course we want to encourage and respect that so it will be important for us to discover well who is providing RDF, and so identifiers.org is an effort by our community to try to consolidate this idea about who is providing it and then what your eyes are they using to identify those resources.",
            "We're working with open facts, which is another big partner in developing.",
            "I think usable semantic web.",
            "There focuses on providing API services to underlying data, massage ING and making.",
            "I think fairly much more useful in this sense that it takes a little bit of effort and knowledge to integrate the information, so we're working on extending this provenance description that I described with you, but we're doing it now with at least I think there's at least five or six sort of consortiums that are participating.",
            "So that we have a data set description that meets the needs of all of these different partners and so now it's nice because we have some experience.",
            "We know what is working.",
            "We know what still needs to be done and we're going at it with a very sort of determined approach, right?",
            "We're going to get the job done, and it's going to get done pretty quickly.",
            "So we're doing that under the auspices of the W. 3C semantic web for healthcare and life Sciences Interest Group, which I chair and in the task force for the linked Life Data Task Force.",
            "So our next big thing is to try to incorporate some of the resources, in fact, that we've produced through the W. 3 CHELS.",
            "The linking open drug data Group produced a number of datasets, but again, what we want is we want those scripts in Bio today if we want to make that as part of a production facility so that anybody could check that out.",
            "And generate the RDF for any one of these datasets.",
            "You know we want this sort of reproducibility and also the ability for people that when the data changes and somebody cares about it, they can change the scripts and the whole Community benefits.",
            "Already because we have some partners like unit brought that are providing sparkle endpoints.",
            "Biotrue DF also Maps now.",
            "So when people use the unit product you referred by Attorney F we actually go and we queried their endpoint.",
            "So we have this sort of mapping.",
            "You know this query Federation aspect where if somebody comes online with their endpoint we can query it and we can provide that interoperability service for bio trivia.",
            "The whole bio TF network.",
            "So we're pretty excited about that.",
            "That's really our first Test case and we're seeing.",
            "Other organizations also go in that direction."
        ],
        [
            "OK so again, just to summarize our main focus for this release 2 is consolidating of the scripts providing an API for the application developers so that we can generate consistent RDF for any of the data that we already FIS using.",
            "Enforcing this pattern in order to ensure the data interoperability creating the provenance aspect so we can always know where did this data come from and the statistics to.",
            "Not just tell us the content of that graph, but actually it's really useful for per reducing the number of queries on our end points that were basically what's in this graph.",
            "Like what's in this data set.",
            "So I would say probably 40% of our queries and which consumed I mean, consumed our CPU resources.",
            "Were these summarization queries and now we're just can start pointing people to the triples that are inside that graph and say, or the web pages and say this is this is what's in it.",
            "Don't, please don't do these CPU consuming queries.",
            "We just had to do it once."
        ],
        [
            "OK, so with that, thank you very much for attention and certainly we welcome any comments, suggestions or contributions to this effort."
        ],
        [
            "So thank you for the nice talk.",
            "So it's a few years now that BioWare DF is around, and I wonder if you have applications example.",
            "In particular, there's this big promise or the translation.",
            "I'll medicine, so translation at Discovery, where all these datasets interconnected together could bring scientific discoveries.",
            "So are there any efforts?",
            "Are you aware of?",
            "Oh yeah.",
            "Things using the bilateral.",
            "Yeah sure.",
            "I mean obviously for me, my whole reason that I'm doing this is that this is basic infrastructure for the research that we do for the Bio Medical research that we do.",
            "This RDF is not only so we've shown in a variety of venues how we can use this public link data in combination with more private data, including patient data in order to, for instance, find potential alternative therapies given the patient's bio data.",
            "To understand to be able to retrieve an find things like side effects for drugs that are being administered to patients.",
            "And from our perspective, we're really interested in the molecular mechanism of drug action.",
            "So we're mapping basically patient data into pathways, molecular pathways, and trying to understand the mechanism of action.",
            "So we have lots and lots of papers which take this as a basic platform of data, and again, I think the core benefit is that all we have to do is either we can download the data as is, or we can check out the code.",
            "We can run it, get the data, and we can compile our own warehouse.",
            "And do whatever it is we want with it.",
            "But we don't have to worry about it.",
            "So really, the value for this is that you don't have to worry about those problems.",
            "Some of the other work that we do is that we take these triples and then we convert them into Al ontologies to do things like consistency checking to find errors in the data itself, and also to do just like more discovery task which is once you integrate many datasets that provide partially overlapping data, it's possible to find associations that aren't cannot be found in any one data set, and so these if you look at the research that I published, this is all examples of that.",
            "So I wanted to ask a bit about licensing, so some of the datasets you have there, like keg or even former KGB are under weird licenses.",
            "Have you had any issues kind of making available by authority F as an openly available kind of set of endpoints?",
            "So this is a really good question.",
            "So one of the biggest problems that we find in our community is that data is often does not have an explicit license for use.",
            "And in other cases they have up Two's licenses that are very difficult to understand where your rights are and what your responsibilities really are.",
            "Most of the data I think in science, most of the data that informatics science anyways, is that you are free to use it with Attribution.",
            "That is the most commonly.",
            "So that's the base level licensing that people would adhere to.",
            "The often provide in their licensing.",
            "They usually specify things that are far more restrictive to corporations an for commercial.",
            "Use and reuse, but we try to associate these licenses and point to their license documents and it's at that point.",
            "It's really up to the users to investigate, especially if they, I think, plan to use it in some commercial setting.",
            "But generally speaking, bio data is freely available with Attribution to academics, and that's our primary target community.",
            "Thanks, Michelle.",
            "So assume I have a.",
            "Have a data set I want to put it in bio two RDF.",
            "Do you guys have like a clear procedure now or what's the step I should follow?",
            "Is there some are there somewhere describe etc.",
            "Yeah exactly so the on the GitHub wiki there are now sort of this RDF isation guide to help people at least create RDF.",
            "That sort of conforms to that and currently an in sort of in coordination with our release.",
            "Our next release for for.",
            "June will have more explicit documentation from a programmatic API perspective and sort of like how do you really just follow this.",
            "If you have data in RDF, that's something that we haven't really addressed yet in the sense that we're really, I guess, focusing our attention more on the data that is changing and where you need a conversion service.",
            "So I think that's maybe the extent of this project for now, is just about this dynamic generation of RDF as opposed to being.",
            "A repository for audiophiles data.",
            "I think we really as a community.",
            "We also need to find venues where people can have their RDF data be indexed and made available.",
            "So we see also like.",
            "Open Link has their linked open data, cloud cache, and so we're getting them to load arbitrary app data into that cash, but I would also wonder and encourage this idea that maybe independent data producers.",
            "Maybe we can get that data index like you can with Cindy J.",
            "Like that search engine you can give them your files and it could get index, but I think that is kind of still distinct from the ELODIE cash and the other services that people provide, so maybe this is really a topic for our community is to figure out how are we going to make it.",
            "Sort of really seamless for people to just drop a file somewhere and then for that to get indexed and discovered by even projects like Biotrue DF.",
            "I think it's an open question.",
            "Thanks, so let's thank Mike Michelle again.",
            "Thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Our second speaker today is Michel Dumontier I'm who's giving us an update on the second release of the bio two RDF.",
                    "label": 0
                },
                {
                    "sent": "Great, thanks very much so.",
                    "label": 0
                },
                {
                    "sent": "Yeah, this is exactly this is our first basically coordinated release of Bio Tour DF.",
                    "label": 0
                },
                {
                    "sent": "We are a project that is.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It's an open source project that basically the idea is to use these very simple conventions along with the semantic web framework in order to create and publish and share biological link data on this.",
                    "label": 0
                },
                {
                    "sent": "This emerging semantic web.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So really, our motivation here is to reduce the overall time and effort that's taken by pretty much every biology lab Informatics lab to download these resources to convert them to link them together, and then to execute queries.",
                    "label": 1
                },
                {
                    "sent": "So really we want to enable more science by spending less time working with just data manipulation.",
                    "label": 0
                },
                {
                    "sent": "So by TF is best known for its contributions to the emerging Semantic Web.",
                    "label": 0
                },
                {
                    "sent": "This lower right pink portion is largely from bio to DF, along with other partners in the Life Sciences an we can really see our mission as getting the thousands of biological databases that are out there that have been published by science scientific researchers and trying to get those resources immediately available.",
                    "label": 0
                },
                {
                    "sent": "On the web, so we're focusing our efforts initially on getting the I guess, the databases that are of primary interest to buy informaticians, the ones that everybody knows and understands.",
                    "label": 0
                },
                {
                    "sent": "But really the long term goal is to create the means by which it becomes easier for any one scientist to ultimately publish their database and make it accessible.",
                    "label": 0
                },
                {
                    "sent": "Make it searchable and.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Enabling queries across those data so.",
                    "label": 0
                },
                {
                    "sent": "If you pay no more attention to this talk, this is basically the summary slide presented to you right now, and so the basic idea for release two was to consolidate the set of open source scripts that were all over the place in so many different formats.",
                    "label": 0
                },
                {
                    "sent": "I mean, it's a great open source project, but at the same time we had real issues in terms of quality control and also ensuring that the scripts were up most up to date, and So what we ended up doing is creating a Git project.",
                    "label": 0
                },
                {
                    "sent": "And that's I think, really one of the cool things is that we can, you know, people can come in.",
                    "label": 0
                },
                {
                    "sent": "They can fork the project that can create their own scripts now and they can do a pull request.",
                    "label": 0
                },
                {
                    "sent": "We can do a code review and we can bring that in and make it part of our production pipeline.",
                    "label": 0
                },
                {
                    "sent": "So we're pretty excited about that.",
                    "label": 0
                },
                {
                    "sent": "All of the scripts were open source there, freely available, so we definitely encourage people to take a look and contribute at the heart of the project.",
                    "label": 0
                },
                {
                    "sent": "Is the linking an we spent a little bit of time developing a registry of the datasets in order to generate these.",
                    "label": 0
                },
                {
                    "sent": "Conforming your eyes so that when a dentist site makes a reference to another data set, we ensure that we have the linking going on, so that's sort of at the at the core of it.",
                    "label": 0
                },
                {
                    "sent": "That's one of the most powerful reasons for this.",
                    "label": 0
                },
                {
                    "sent": "For this particular project.",
                    "label": 0
                },
                {
                    "sent": "In this release we have over a billion triples in 19 datasets, and that's actually less than what we've had before.",
                    "label": 0
                },
                {
                    "sent": "We've reported up to 30 billion triples, and now we're sort of systematically going to the bigger datasets and applying the principles that I'll talk to.",
                    "label": 0
                },
                {
                    "sent": "About today.",
                    "label": 0
                },
                {
                    "sent": "So on top of just the core infrastructure for generating link data, we have also services to provide access to that, including look up services, sparkle query and query Federation services and other kinds of search functionality.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So in a nutshell, this illustration kind of shows what we're trying to do.",
                    "label": 0
                },
                {
                    "sent": "We're taking data from all kinds of formats, some of them you know you would be happy to work with the XML ones.",
                    "label": 0
                },
                {
                    "sent": "Maybe the top separated ones.",
                    "label": 0
                },
                {
                    "sent": "We've seen a lot of, but in the life Sciences there are hundreds if not thousands of different file formats, right?",
                    "label": 1
                },
                {
                    "sent": "And often during these nefarious sort of ad hoc formats.",
                    "label": 0
                },
                {
                    "sent": "And so we have to write basically parsers for each one of these kinds of data in order to bring them into it.",
                    "label": 0
                },
                {
                    "sent": "So the whole idea is to take these legacy file formats.",
                    "label": 0
                },
                {
                    "sent": "Convert them into RDF.",
                    "label": 0
                },
                {
                    "sent": "We provide.",
                    "label": 0
                },
                {
                    "sent": "We generate now some provenance for this information and we calculate metrics or statistics about the data so that we can understand what it is and how it's connected.",
                    "label": 0
                },
                {
                    "sent": "So the data we loaded then into triple stores.",
                    "label": 0
                },
                {
                    "sent": "We make it available for downloads that triplestores.",
                    "label": 0
                },
                {
                    "sent": "Obviously provide us with the Sparkle services search and faceted browsing is provided right now through Virtuoso.",
                    "label": 0
                },
                {
                    "sent": "And the web app provides the resolution of your eyes as well as query.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Iteration services.",
                    "label": 0
                },
                {
                    "sent": "So the form basically the syntax that we use for your eye generation follows the one of three patterns.",
                    "label": 1
                },
                {
                    "sent": "If the resource provides us with an identifier, then we follow this very simple pattern.",
                    "label": 1
                },
                {
                    "sent": "Of course we use our biotruedf.org as the base namespace so that we can do the resolution of the entity.",
                    "label": 0
                },
                {
                    "sent": "Then there's a namespace component followed by a colon, an identifier, so the namespace component is basically a preferred short name that is in a registry of these datasets.",
                    "label": 0
                },
                {
                    "sent": "OK, and then we can look that up and we say what is the preferred name and we can stick it in there now.",
                    "label": 0
                },
                {
                    "sent": "There's lots of data that we get which is not identified, so these might be attributes or they might be other relations to data that simply isn't identified but is captured in some kind of data structure.",
                    "label": 0
                },
                {
                    "sent": "So at that point we have to because we want to link data and we want to provide resolution services for every data item we often have to create our own identifiers and so when we do that we put it in a slightly different name space so you can see the syntax is.",
                    "label": 0
                },
                {
                    "sent": "We use that preferred prefix_resource: followed by the identifier so that really helps people identify that.",
                    "label": 0
                },
                {
                    "sent": "OK, this is something that we created in order to our deifies this data and it's not by no means is it guaranteed stable identifier and it certainly doesn't come from the original data provider.",
                    "label": 0
                },
                {
                    "sent": "In the third case, this is where we create vocabulary to support the typing and also the establishing of relations.",
                    "label": 0
                },
                {
                    "sent": "So this is especially pertinent when you have a tab file.",
                    "label": 0
                },
                {
                    "sent": "For instance, you might have a hint from the column name or from some other descripcion some text file that tells you what the content type is, and so here.",
                    "label": 0
                },
                {
                    "sent": "Now we're creating types an relations and we put that in our own namespace again to support the authorization process.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so here's an example from Drug Bank which is a database of drugs and drug targets and drug drug interactions.",
                    "label": 0
                },
                {
                    "sent": "So we have will have an entity here where we have drugbank: DBS or 650.",
                    "label": 0
                },
                {
                    "sent": "This is the cover and you can see that there's a simple type statement and again the namespaces or vocabulary namespace.",
                    "label": 0
                },
                {
                    "sent": "We assigned the identifier which is drug.",
                    "label": 0
                },
                {
                    "sent": "Now we service this single triple.",
                    "label": 0
                },
                {
                    "sent": "There in Drugbank they also make references to drug drug interactions, but again they don't provide an identifier for this drug drug interaction, so again you can see we used the drug bank_resource.",
                    "label": 0
                },
                {
                    "sent": "We assign an identifier for that interaction and we relate the two through this DDI in tractor relation right which we created to support it.",
                    "label": 0
                },
                {
                    "sent": "OK, so that's.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "All fine, pretty much all the datasets look that they have their own vocabularies to describe the types and relations and provide the linking within the datasets and pointers outwards to other datasets where there are some.",
                    "label": 0
                },
                {
                    "sent": "So here's an example where in the bottom box we have data firm Pharm GKB, which is a pharmacogenomics knowledge base to associate drugs with genetics and outcomes.",
                    "label": 0
                },
                {
                    "sent": "And there's a relationship between this farm GCB, identifier PA. 450198 and there's a relation that's established.",
                    "label": 0
                },
                {
                    "sent": "In the data in the data set to the Drug Bank entry, the Leucovorin Drugbank entry.",
                    "label": 0
                },
                {
                    "sent": "Now they use a so called database cross reference or X ref, and so this has an ambiguous meaning.",
                    "label": 0
                },
                {
                    "sent": "It may be the same, it may be different, it may be related in some way, but by OTF makes no attempt to tell you anything more than what the providers provide us, right?",
                    "label": 0
                },
                {
                    "sent": "So the interpretation is as weak as is provided by the data provider, and so but the important thing is that.",
                    "label": 0
                },
                {
                    "sent": "When we make that you write generation when we're processing the pharm GKB data set, we use the registry in the API in order to generate the right UI so that when we put the data together it links together.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So of course we provide the basic RDF look up services with our Beautiful Puppy interface, which we're hoping to change at some point, but the principles are there that after every you arrive that we have there you can click through and the important thing to for us to mention is that we don't actually warehouse this.",
                    "label": 0
                },
                {
                    "sent": "Every data set is its own triple, it's its own triple store, and so we're actually crossing from 11 server to another.",
                    "label": 0
                },
                {
                    "sent": "And really this is at the heart of this project is that it's meant to be.",
                    "label": 0
                },
                {
                    "sent": "A Federation query environment really, really want.",
                    "label": 0
                },
                {
                    "sent": "Ultimately nothing would make me happier than not to host any of these datasets.",
                    "label": 0
                },
                {
                    "sent": "What we want to do is provide this nice interoperability Sheen that basically helps us do the resolution of these.",
                    "label": 0
                },
                {
                    "sent": "Your eyes, especially when they differ in so many different communities.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So not only can when we when we sort of coin one of these by 20 after rise, of course will give you back triples about it, but one of the nice services is that we also know for all of the endpoints we know basically what their contents are.",
                    "label": 0
                },
                {
                    "sent": "So we query our endpoints and we can give you what is being, what links to that entry as well.",
                    "label": 1
                },
                {
                    "sent": "So this is really nice, right?",
                    "label": 0
                },
                {
                    "sent": "This is an expected I think idea of having this linked data warehouse you want to go to one entry and you say, well, who's making statements about this?",
                    "label": 0
                },
                {
                    "sent": "And now we can show you those at least within our network.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So every data item.",
                    "label": 0
                },
                {
                    "sent": "Now this was one of the big critiques was that it was because we had data being generated at random intervals.",
                    "label": 0
                },
                {
                    "sent": "We didn't know when or anything about that data.",
                    "label": 0
                },
                {
                    "sent": "Where did it come from?",
                    "label": 0
                },
                {
                    "sent": "When was it processed?",
                    "label": 0
                },
                {
                    "sent": "What is the licensing associated with it?",
                    "label": 0
                },
                {
                    "sent": "So now every data item is annotated with this with void in data set.",
                    "label": 0
                },
                {
                    "sent": "And then we described the biotrue DF data set as we produced it and we give you a link back to the original data providers data set description.",
                    "label": 0
                },
                {
                    "sent": "Right, so we have you know who created it and in our case actually we give you a pointer to the GitHub script that was responsible for generating that version of the data, provide you with the license and rights description appointer to its availability in terms of what sparkle endpoint is hosting this and where can you get the RDF data itself.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so these are for let's see how many biologists are there in the audience.",
                    "label": 0
                },
                {
                    "sent": "Just a handful.",
                    "label": 0
                },
                {
                    "sent": "OK, so most of these datasets won't.",
                    "label": 0
                },
                {
                    "sent": "You won't recognize, but again, a lot of these are pretty important for informatics.",
                    "label": 0
                },
                {
                    "sent": "Just a summary.",
                    "label": 0
                },
                {
                    "sent": "So there was the 19.",
                    "label": 0
                },
                {
                    "sent": "Some of these are actually one of the things that we found over the last few years.",
                    "label": 0
                },
                {
                    "sent": "Was that new resources have come about where they aggregate other ones, so a good example is iref index aggregates.",
                    "label": 0
                },
                {
                    "sent": "I believe nine different databases, all-in-one, and they do some additional processing to find equivalence is amongst the data in those datasets.",
                    "label": 0
                },
                {
                    "sent": "So in fact, even though we have 19 sort of datasets, there are inside of those there are hundreds of them as independent resources that are being collected by aggregators.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this we have now a pretty good idea of how our data connects and you can see from this diagram these directed graph we can see from which datasets point to what other datasets.",
                    "label": 0
                },
                {
                    "sent": "So some of them are really pointed by everybody.",
                    "label": 0
                },
                {
                    "sent": "Pub Med is our repository for literature and so most scientific resources will point to that.",
                    "label": 0
                },
                {
                    "sent": "And then we have others that basically are doing the pointing.",
                    "label": 0
                },
                {
                    "sent": "So there's a lot of curation in order to save the resources that we're curating here.",
                    "label": 0
                },
                {
                    "sent": "You can also find in that database in that database and then DOT database.",
                    "label": 0
                },
                {
                    "sent": "So it's a pretty highly connected network, and obviously there's lots of ways to get from anyone data to any other data.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Of course, these are.",
                    "label": 0
                },
                {
                    "sent": "That graph is produced from data set statistics that we now collect an we put in the graphs in the put in graphs at each of the sparkle endpoints, so you can query them and you can find out how is this data set tech.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Connected and not only do we have just the entire data set connectivity within the ones that we've already advised, but we actually also see all the other references to all the other datasets that are not on the semantic web.",
                    "label": 0
                },
                {
                    "sent": "So this diagram gives you an idea of.",
                    "label": 0
                },
                {
                    "sent": "Basically you can see thousands of arcs going outwards to datasets that we know nothing about currently, and so from a prioritization process.",
                    "label": 0
                },
                {
                    "sent": "Obviously we're going to be looking at that this connectivity network and trying to determine what's the next data set that we should really be focusing on.",
                    "label": 0
                },
                {
                    "sent": "Obviously it's the one that is being most pointed to or we have some indication that they're going to be doing the linking that they're the ones that are aggregating the resources insane.",
                    "label": 0
                },
                {
                    "sent": "What's the equivalence or what's the relationship between this data and that data and other data sets?",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Right, so the statistics we published now for each of the datasets.",
                    "label": 0
                },
                {
                    "sent": "This is an example of snapshot where we just gave you a basic description of them where the sparkle endpoint, the faceted browser, the script conversion location, the download.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Location and we provide the basic metrics that you would expect, like the number of triples, number of unique subject object and predicates and we give you lists of the number of instances of each of those types.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Along we provide also these statistics that give you the pairing so that basically the number of unique predicates an object links predicate literal links and there.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Counts and I think probably most Interestingly, is this statistics that we compute, which basically tells you how many instances of a certain type or connected to instances of another type through a predicate, and this is really probably the most valuable one in terms of query formulation.",
                    "label": 0
                },
                {
                    "sent": "Now I can say, well, I'm interested in drugs.",
                    "label": 0
                },
                {
                    "sent": "What do drugs linked to?",
                    "label": 0
                },
                {
                    "sent": "How do I go from a drug to some other thing in this data set?",
                    "label": 0
                },
                {
                    "sent": "And so in this case we can see, for instance, that we have 11127.",
                    "label": 0
                },
                {
                    "sent": "Instances of drug that are.",
                    "label": 0
                },
                {
                    "sent": "That are connected to 11,512 instances of Pharmaceuticals through this relation product.",
                    "label": 0
                },
                {
                    "sent": "Or similarly here we have 1000 instances of drug that are connected to 10,891 instances of drug drug interactions.",
                    "label": 0
                },
                {
                    "sent": "So when you want to start querying, you want to get all the drugs and their drug drug interactions.",
                    "label": 0
                },
                {
                    "sent": "You basically have a path, a graph by which you can follow and you can compose your query.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So that's fine, but it turns out that there are already tools that do this.",
                    "label": 0
                },
                {
                    "sent": "So Cindy J Tech has this tool called sparkly D which does this graph summarization and provide you with it basically and in context auto completion facility for sparkle.",
                    "label": 0
                },
                {
                    "sent": "So we compute their grass statistic we stored in each of our endpoints and now you can deploy the sparkly D tool to help you compose and execute the queries.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Of course, because we use virtuoso, you have the faster browser that comes with it and it, I think that this is sort of a relatively unexplored feature for most people, But it turns out you can do some pretty sophisticated queries.",
                    "label": 0
                },
                {
                    "sent": "Without doing any sparkle whatsoever, but basically by starting with the keyword search and then following up by summarizing seeing how many instances of those attributes occur and basically start to create your own path.",
                    "label": 0
                },
                {
                    "sent": "And the nice thing is that once you capture this query through this fairly natural process, you can get the sparkle query and then you can use that in some application.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So with the advent of Sparkle 1.1, we're quite excited.",
                    "label": 0
                },
                {
                    "sent": "Of course, because one of the big missing features in Bio Shodiev was, well, you've got all of these endpoints, which is kind of useless because the data is all separated.",
                    "label": 0
                },
                {
                    "sent": "We have no way to create, but now with Sparkle 11 we can do these Federated queries really really easily, so each of our endpoints are enable Sparkle 1.1 query Federation.",
                    "label": 0
                },
                {
                    "sent": "And now we can say OK, take data from this end point and that end point.",
                    "label": 0
                },
                {
                    "sent": "And because we know how to it all connects together, it's relatively easy to compose this barcode query.",
                    "label": 0
                },
                {
                    "sent": "So in this case I'm again we're using virtual, so six and they don't have the transitive paths implemented yet, so we use a special option.",
                    "label": 0
                },
                {
                    "sent": "But basically we can reason about one of the big ontologies which the gene ontology and combine that with another database which uses those terms as annotations so we can pull out specific data using subclass reasoning on an ontology stored in another endpoint.",
                    "label": 0
                },
                {
                    "sent": "So I think from my perspective.",
                    "label": 0
                },
                {
                    "sent": "You know, we always make this argument that a little bit of semantics goes along way.",
                    "label": 0
                },
                {
                    "sent": "This is a good example where having access to an ontology helps you retrieve more results than you would have otherwise, or you would have had to compose a union of queries in order to retrieve all the results, so.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this is I think basically one of the core functional components that we wanted.",
                    "label": 0
                },
                {
                    "sent": "Now one of the problems is that while we have each of these datasets, I would argue that some of our datasets are overlapping in terms of their content and we really don't want to necessarily say, OK, give me the drugbank drug, give me the pharm GKB drug.",
                    "label": 0
                },
                {
                    "sent": "Give me the seat drug you need.",
                    "label": 0
                },
                {
                    "sent": "The pub chem drug there's like about 10 drug databases.",
                    "label": 0
                },
                {
                    "sent": "And really what we want to do at the end of the day, I think being part of the semantic web is that we want to say give me all the drugs that have these characteristics, right?",
                    "label": 1
                },
                {
                    "sent": "So how do we?",
                    "label": 0
                },
                {
                    "sent": "How do we go there?",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So for US, Ontology is the strategy by which we can semantically unify the resources that we have in bio to DF.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And so we've been developing.",
                    "label": 0
                },
                {
                    "sent": "I guess an ontology, which we call the Semantic Science Integrated Ontology which has these basic types and relations that we observe in each of our datasets.",
                    "label": 0
                },
                {
                    "sent": "So what we're doing at the very first pass is type is simply mapping the bietry F types in relations to this ontology, and that therefore allows.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Best to do queries.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Basically, sparkle queries using the Scientology to retrieve the instances from each of those endpoints, so the desire graphs are loaded there and now we can execute this even using the service keyword for query Federation.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_28": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so that pretty much gives you a good idea about what the sort of the state of the art was for January of this year is when we made the release in preparation, and now we're working on our next release, which will be at the end of June and we're basically trying to go for every six months releases and trying to bring more and more of these datasets back online following the conventions that I set out here.",
                    "label": 0
                },
                {
                    "sent": "One of the big differences.",
                    "label": 0
                },
                {
                    "sent": "I think that will see is we've now created an API that is a little bit easier for application developers to use, so we call that the buyer DEF API.",
                    "label": 0
                },
                {
                    "sent": "It's implemented in PHP, but at the heart of it we're using now registry that we're creating in collaboration with a group called identifiers.org, and the idea would be that any any parser any application can refer to API services in order to get that Canonical name, and it will be the Canonical name, not just for Bio TF, but potentially even for the original data.",
                    "label": 1
                },
                {
                    "sent": "Provider, so that's always been a big critique.",
                    "label": 0
                },
                {
                    "sent": "Some of the data is now finally coming online with their own.",
                    "label": 0
                },
                {
                    "sent": "Your eyes that data providers are actually generating RDF, and they're providing sparkle services to them.",
                    "label": 0
                },
                {
                    "sent": "And of course we want to encourage and respect that so it will be important for us to discover well who is providing RDF, and so identifiers.org is an effort by our community to try to consolidate this idea about who is providing it and then what your eyes are they using to identify those resources.",
                    "label": 0
                },
                {
                    "sent": "We're working with open facts, which is another big partner in developing.",
                    "label": 1
                },
                {
                    "sent": "I think usable semantic web.",
                    "label": 0
                },
                {
                    "sent": "There focuses on providing API services to underlying data, massage ING and making.",
                    "label": 0
                },
                {
                    "sent": "I think fairly much more useful in this sense that it takes a little bit of effort and knowledge to integrate the information, so we're working on extending this provenance description that I described with you, but we're doing it now with at least I think there's at least five or six sort of consortiums that are participating.",
                    "label": 0
                },
                {
                    "sent": "So that we have a data set description that meets the needs of all of these different partners and so now it's nice because we have some experience.",
                    "label": 0
                },
                {
                    "sent": "We know what is working.",
                    "label": 0
                },
                {
                    "sent": "We know what still needs to be done and we're going at it with a very sort of determined approach, right?",
                    "label": 0
                },
                {
                    "sent": "We're going to get the job done, and it's going to get done pretty quickly.",
                    "label": 0
                },
                {
                    "sent": "So we're doing that under the auspices of the W. 3C semantic web for healthcare and life Sciences Interest Group, which I chair and in the task force for the linked Life Data Task Force.",
                    "label": 0
                },
                {
                    "sent": "So our next big thing is to try to incorporate some of the resources, in fact, that we've produced through the W. 3 CHELS.",
                    "label": 0
                },
                {
                    "sent": "The linking open drug data Group produced a number of datasets, but again, what we want is we want those scripts in Bio today if we want to make that as part of a production facility so that anybody could check that out.",
                    "label": 1
                },
                {
                    "sent": "And generate the RDF for any one of these datasets.",
                    "label": 0
                },
                {
                    "sent": "You know we want this sort of reproducibility and also the ability for people that when the data changes and somebody cares about it, they can change the scripts and the whole Community benefits.",
                    "label": 0
                },
                {
                    "sent": "Already because we have some partners like unit brought that are providing sparkle endpoints.",
                    "label": 0
                },
                {
                    "sent": "Biotrue DF also Maps now.",
                    "label": 0
                },
                {
                    "sent": "So when people use the unit product you referred by Attorney F we actually go and we queried their endpoint.",
                    "label": 0
                },
                {
                    "sent": "So we have this sort of mapping.",
                    "label": 0
                },
                {
                    "sent": "You know this query Federation aspect where if somebody comes online with their endpoint we can query it and we can provide that interoperability service for bio trivia.",
                    "label": 0
                },
                {
                    "sent": "The whole bio TF network.",
                    "label": 0
                },
                {
                    "sent": "So we're pretty excited about that.",
                    "label": 0
                },
                {
                    "sent": "That's really our first Test case and we're seeing.",
                    "label": 0
                },
                {
                    "sent": "Other organizations also go in that direction.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK so again, just to summarize our main focus for this release 2 is consolidating of the scripts providing an API for the application developers so that we can generate consistent RDF for any of the data that we already FIS using.",
                    "label": 0
                },
                {
                    "sent": "Enforcing this pattern in order to ensure the data interoperability creating the provenance aspect so we can always know where did this data come from and the statistics to.",
                    "label": 0
                },
                {
                    "sent": "Not just tell us the content of that graph, but actually it's really useful for per reducing the number of queries on our end points that were basically what's in this graph.",
                    "label": 0
                },
                {
                    "sent": "Like what's in this data set.",
                    "label": 0
                },
                {
                    "sent": "So I would say probably 40% of our queries and which consumed I mean, consumed our CPU resources.",
                    "label": 0
                },
                {
                    "sent": "Were these summarization queries and now we're just can start pointing people to the triples that are inside that graph and say, or the web pages and say this is this is what's in it.",
                    "label": 0
                },
                {
                    "sent": "Don't, please don't do these CPU consuming queries.",
                    "label": 0
                },
                {
                    "sent": "We just had to do it once.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so with that, thank you very much for attention and certainly we welcome any comments, suggestions or contributions to this effort.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So thank you for the nice talk.",
                    "label": 0
                },
                {
                    "sent": "So it's a few years now that BioWare DF is around, and I wonder if you have applications example.",
                    "label": 0
                },
                {
                    "sent": "In particular, there's this big promise or the translation.",
                    "label": 0
                },
                {
                    "sent": "I'll medicine, so translation at Discovery, where all these datasets interconnected together could bring scientific discoveries.",
                    "label": 0
                },
                {
                    "sent": "So are there any efforts?",
                    "label": 0
                },
                {
                    "sent": "Are you aware of?",
                    "label": 0
                },
                {
                    "sent": "Oh yeah.",
                    "label": 0
                },
                {
                    "sent": "Things using the bilateral.",
                    "label": 0
                },
                {
                    "sent": "Yeah sure.",
                    "label": 0
                },
                {
                    "sent": "I mean obviously for me, my whole reason that I'm doing this is that this is basic infrastructure for the research that we do for the Bio Medical research that we do.",
                    "label": 0
                },
                {
                    "sent": "This RDF is not only so we've shown in a variety of venues how we can use this public link data in combination with more private data, including patient data in order to, for instance, find potential alternative therapies given the patient's bio data.",
                    "label": 0
                },
                {
                    "sent": "To understand to be able to retrieve an find things like side effects for drugs that are being administered to patients.",
                    "label": 0
                },
                {
                    "sent": "And from our perspective, we're really interested in the molecular mechanism of drug action.",
                    "label": 0
                },
                {
                    "sent": "So we're mapping basically patient data into pathways, molecular pathways, and trying to understand the mechanism of action.",
                    "label": 0
                },
                {
                    "sent": "So we have lots and lots of papers which take this as a basic platform of data, and again, I think the core benefit is that all we have to do is either we can download the data as is, or we can check out the code.",
                    "label": 0
                },
                {
                    "sent": "We can run it, get the data, and we can compile our own warehouse.",
                    "label": 0
                },
                {
                    "sent": "And do whatever it is we want with it.",
                    "label": 0
                },
                {
                    "sent": "But we don't have to worry about it.",
                    "label": 0
                },
                {
                    "sent": "So really, the value for this is that you don't have to worry about those problems.",
                    "label": 0
                },
                {
                    "sent": "Some of the other work that we do is that we take these triples and then we convert them into Al ontologies to do things like consistency checking to find errors in the data itself, and also to do just like more discovery task which is once you integrate many datasets that provide partially overlapping data, it's possible to find associations that aren't cannot be found in any one data set, and so these if you look at the research that I published, this is all examples of that.",
                    "label": 0
                },
                {
                    "sent": "So I wanted to ask a bit about licensing, so some of the datasets you have there, like keg or even former KGB are under weird licenses.",
                    "label": 0
                },
                {
                    "sent": "Have you had any issues kind of making available by authority F as an openly available kind of set of endpoints?",
                    "label": 0
                },
                {
                    "sent": "So this is a really good question.",
                    "label": 0
                },
                {
                    "sent": "So one of the biggest problems that we find in our community is that data is often does not have an explicit license for use.",
                    "label": 0
                },
                {
                    "sent": "And in other cases they have up Two's licenses that are very difficult to understand where your rights are and what your responsibilities really are.",
                    "label": 0
                },
                {
                    "sent": "Most of the data I think in science, most of the data that informatics science anyways, is that you are free to use it with Attribution.",
                    "label": 0
                },
                {
                    "sent": "That is the most commonly.",
                    "label": 0
                },
                {
                    "sent": "So that's the base level licensing that people would adhere to.",
                    "label": 0
                },
                {
                    "sent": "The often provide in their licensing.",
                    "label": 0
                },
                {
                    "sent": "They usually specify things that are far more restrictive to corporations an for commercial.",
                    "label": 0
                },
                {
                    "sent": "Use and reuse, but we try to associate these licenses and point to their license documents and it's at that point.",
                    "label": 0
                },
                {
                    "sent": "It's really up to the users to investigate, especially if they, I think, plan to use it in some commercial setting.",
                    "label": 0
                },
                {
                    "sent": "But generally speaking, bio data is freely available with Attribution to academics, and that's our primary target community.",
                    "label": 0
                },
                {
                    "sent": "Thanks, Michelle.",
                    "label": 0
                },
                {
                    "sent": "So assume I have a.",
                    "label": 0
                },
                {
                    "sent": "Have a data set I want to put it in bio two RDF.",
                    "label": 0
                },
                {
                    "sent": "Do you guys have like a clear procedure now or what's the step I should follow?",
                    "label": 0
                },
                {
                    "sent": "Is there some are there somewhere describe etc.",
                    "label": 0
                },
                {
                    "sent": "Yeah exactly so the on the GitHub wiki there are now sort of this RDF isation guide to help people at least create RDF.",
                    "label": 0
                },
                {
                    "sent": "That sort of conforms to that and currently an in sort of in coordination with our release.",
                    "label": 0
                },
                {
                    "sent": "Our next release for for.",
                    "label": 0
                },
                {
                    "sent": "June will have more explicit documentation from a programmatic API perspective and sort of like how do you really just follow this.",
                    "label": 0
                },
                {
                    "sent": "If you have data in RDF, that's something that we haven't really addressed yet in the sense that we're really, I guess, focusing our attention more on the data that is changing and where you need a conversion service.",
                    "label": 0
                },
                {
                    "sent": "So I think that's maybe the extent of this project for now, is just about this dynamic generation of RDF as opposed to being.",
                    "label": 0
                },
                {
                    "sent": "A repository for audiophiles data.",
                    "label": 0
                },
                {
                    "sent": "I think we really as a community.",
                    "label": 0
                },
                {
                    "sent": "We also need to find venues where people can have their RDF data be indexed and made available.",
                    "label": 0
                },
                {
                    "sent": "So we see also like.",
                    "label": 0
                },
                {
                    "sent": "Open Link has their linked open data, cloud cache, and so we're getting them to load arbitrary app data into that cash, but I would also wonder and encourage this idea that maybe independent data producers.",
                    "label": 0
                },
                {
                    "sent": "Maybe we can get that data index like you can with Cindy J.",
                    "label": 0
                },
                {
                    "sent": "Like that search engine you can give them your files and it could get index, but I think that is kind of still distinct from the ELODIE cash and the other services that people provide, so maybe this is really a topic for our community is to figure out how are we going to make it.",
                    "label": 0
                },
                {
                    "sent": "Sort of really seamless for people to just drop a file somewhere and then for that to get indexed and discovered by even projects like Biotrue DF.",
                    "label": 0
                },
                {
                    "sent": "I think it's an open question.",
                    "label": 0
                },
                {
                    "sent": "Thanks, so let's thank Mike Michelle again.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                }
            ]
        }
    }
}