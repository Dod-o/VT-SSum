{
    "id": "b7ekqwlobjp4mzkvtycokmjravuzw7dc",
    "title": "Unsupervised Learning for Stereo Vision",
    "info": {
        "author": [
            "David McAllester, Toyota Technological Institute at Chicago"
        ],
        "published": "July 30, 2009",
        "recorded": "June 2009",
        "category": [
            "Top->Computer Science->Machine Learning->Computational Learning Theory"
        ]
    },
    "url": "http://videolectures.net/mlss09us_mcallester_ulsv/",
    "segmentation": [
        [
            "Afternoon session, so pleasure to introduce David McAllister of Toyota Technological Institute.",
            "Thanks David.",
            "Thanks, Steve."
        ],
        [
            "OK, I'm gonna try to get by without a laser pointer.",
            "But what I want to do today is considered the problem of scene understanding, and particularly in particular scene understanding from a single image.",
            "So monocular scene understanding so there's been a fair amount of work very recently on understanding single images, and Andrew being and shows succinea at Stanford, have done work on predicting depth on inferring 3D structure from a single image.",
            "This is something people are doing quite well.",
            "This is a classical image from the stereovision community, and it's fairly easy to look at it and understand what's there and do approximate depth estimates.",
            "Now in the recent work, there's a lot of emphasis on conditional random fields.",
            "So most of you are probably familiar with conditional random fields.",
            "We take an input like an image and we're interested in inferring a depth map Isaiah depth at every pixel, which is a field value, a structured label for this image.",
            "And so I'm going to be spending some time talking about conditional random fields and generalizations of conditional random fields.",
            "And this the remainder of this talk will be divided into sort of three parts.",
            "That correspond to.",
            "Sort of, the distinction between general approaches to machine learning and domain specific insights into computer vision.",
            "So there's this.",
            "Of course, there's this tendency in vision and in many fields of computer science to be sort of taken over by learning people, and there's this old spectrum within philosophy and and approaches to cognition between one end.",
            "I would say there's Jeff Hinton, sort of a neural net person.",
            "And he's really the learning person.",
            "He believes in very general approaches to machine learning.",
            "He makes an analogy with the principles of aerodynamics and all the complexity of cognition.",
            "Follows from a very general theory of machine learning.",
            "At the other end there's Noam Chomsky.",
            "And Noam Chomsky believes that properties of natural language, the actual syntax of natural language is somehow embedded in our DNA that we come with the prior knowledge of universal grammar.",
            "But this tension between general machine learning and the details of particular domains like vision or computational linguistics.",
            "This tension is is something that we're seeing more and more of, and my talk is going to be divided into sort of three parts.",
            "The first part in the last part will be in the realm of general learning.",
            "And the middle part will be vision specific and the way I think about research like this is, I'm really most excited personally about the general learning formalisms about understanding learning in a domain independent level and in an area like computer vision.",
            "What fascinates me is using that as a testbed or a benchmark or a case study in applications of general machine learning.",
            "Methods, so that's sort of the way I'm going to try to structure this talk.",
            "OK."
        ],
        [
            "I'm going to start with a review of Markov random fields, so the introduction of Markov random fields, in particular this paper by Lafferty at all in 2001, has had a huge impact on the general machine learning community.",
            "It's one of the most cited papers I think in computer science, and you can write down the basic idea in just a few simple equations.",
            "Probably most of you have seen these equations before the 1st two equations here define the model it's defining a conditional probability of Y given X as just a normalized.",
            "Normalization of an exponential in an energy.",
            "And it's the energy function that defines the model.",
            "And here beta you want to beta as a parameter vector.",
            "This is often written as a uniform that restrict it to be linear.",
            "In beta beta transpose a feature vector and XY, but I'm writing a more general form here.",
            "How many people?",
            "Have worked, you know, really understand.",
            "I've seen lots of times, conditional random fields.",
            "Oh OK, I was thinking a lot of people haven't alright.",
            "So so the first 2 equations define the model it's defining a conditional probability of Y given X.",
            "And the second equation is defining training, but I want you to think of it just for a moment.",
            "Think of the monocular monocular image understanding problem in that problem.",
            "We're given an input X, which is an image.",
            "And what we want to do is label it, say with a depth map.",
            "We want to assign a depth to every pixel and the depth map here is Y.",
            "So X&Y are both structured objects, X is an image in this example.",
            "And why is a depth map an assignment of a depth to each pixel and what we're interested in doing?",
            "What we really want to do is define this energy function.",
            "Such that when I take an X and compute a probability distribution over Y, and let's say I take the most likely Y, I'm inferring the actual depth map for that input image.",
            "And the training equation down here assumes that I have as training data XY pairs, so it assumes that I have is training data images together with their depth map and then it what it's doing is it's setting the parameter beta.",
            "So I've got this model class somehow defined by this general parameter beta, and it's setting the parameter beta to minimize a log loss, a sum over the training points.",
            "I I is ranging over training points of one over the probability in the model of the training label for the input X. OK.",
            "This is really a hot topic in acnl machine learning and and you know, computational linguistics.",
            "Here's a much more."
        ],
        [
            "Recent.",
            "Embellishment of a conditional random field called a hidden CRF.",
            "Now, in a hidden CRF.",
            "The first 2 equations define a model that is a CRF.",
            "It's just like the one I listed before, except there's also a hidden variable Z, so we're defining a probability distribution over 2 simultaneous values Y&Z.",
            "Given an input X.",
            "So I thought maybe a good example with this of this would might be a machine translation problem, so think of X is being an input sentence Y as being its translation into, say, from English to French and Z as being a parse tree.",
            "And your training data would have translation pairs, but your model involves a parse tree, so there's a hidden structure, AZ that's not in your training data, but that is part of your model.",
            "And what happens is in the third line.",
            "Here, the probability of the output given the input is a marginalization over the hidden information Z of the probability of of the pairwise E given the input where the pairwise E is defined by these equations.",
            "And then the last equation is the training equation.",
            "It says set the model parameter beta to be that parameter, which optimizes exactly the same loss we had before.",
            "It's a log loss.",
            "And in both of those equations I'm using a quadratic regularizer to try to minimize the norm of the weight vector.",
            "So this has attracted a fair amount of attention because simply because latent."
        ],
        [
            "Rules.",
            "Are quite useful in lots of modeling applications now.",
            "It turns out that you know you can combine a set of adjectives and get a combinatorial number of different models by combining this notion of structured output.",
            "With so you have for many machine learning applications, you're interested in classification, which is you have XY pairs and Y is minus one or one binary classification.",
            "In a CRF, you're interested in a structured output, like a depth map.",
            "Then we can talk about support vector machines.",
            "So let me try again.",
            "How many people are comfortable with support vector machines?",
            "More most OK, so there's a support for every one of these conditional random field notions.",
            "There's a support vector machine analogue, so we can talk about binary output, structured outputs, fully labeled training data or training data with where, where the model has some latent information in it, and then for any combination of those we can do an SVM or a CRF.",
            "And some of these, in particular the structured El SVM that bottom one on the left I think may have just appeared.",
            "There might just be a reference to that this year in the literature, but all of these things.",
            "Can be formulated.",
            "And I don't mean that this is the space of all possible models, but it's nice to have these adjectives and realize you can combine them in any way you want and you get a model and it's nice to be able to, you know, if your machine learning aficionado would be nice to be able to write down any one of these on demand."
        ],
        [
            "OK, well I'm going to do in this talk.",
            "Is introduced sort of another dimension into that chart.",
            "And I'm going to call this an indirect CRF.",
            "So remember that.",
            "What we're interested in doing is, let's say, let's look at the image understanding problem.",
            "What we're interested in doing is.",
            "Learning a certain conditional random field that's going to infer the depth from the image.",
            "That's our monocular image understanding problem.",
            "But now what I want to do is learn that CRF.",
            "From stereo pairs?",
            "OK, that's what I'm going to talk about when I get to vision, so I want to think of a stereo pair as being a pair XY where I think, say at the left image as an input and the right image the right image as a structured output.",
            "And what I'm going to do is have a model that involves a latent variable.",
            "Where the latent variable is the depth map, and.",
            "And then my model is going to have this structure, so let's look at this general structure and I've described it in terms of images, but it's a general.",
            "This is, the idea is that this is a general model for model structure that could be applied in any domain.",
            "I've got training data which is XY pairs.",
            "I'm interested in learning a CRF.",
            "I'm reading the first line here, which is predicting some Z from X.",
            "But she is not explicitly given in the training data.",
            "Z is latent in the training data, so I'm interested in using stereo pairs to train monocular depth estimation.",
            "So I have a model that involves two CRF's.",
            "One is the probability of the CRF defining the probability of the latent information, like the depth map given the input and the 2nd is the probability of the actual label.",
            "I see which is the other image given the input and the latent information.",
            "And then I'm the training equation is going to look just the same.",
            "It's exactly the same we're going to.",
            "We're going to pick now to we're going to pick the parameters from two different CRF's to minimize this log loss plus this regularization term.",
            "But in this case the probability of Y given X is factored into this form, and what I'm really hoping to learn is the probability of Z given X. OK."
        ],
        [
            "So the first thing I want to do is so that's the end of the first part of my talk, sort of general sort of an overview of general models for machine learning.",
            "Now I'm going to start talking about computer Vision, more specifically, and the first thing I want to do is, say is take a look at classical algorithms for stereo vision so stereo vision takes a pair of images and it infers a depth map.",
            "And and a classical algorithm for stereo vision would involve these two energy terms.",
            "I'm going to look at my first equation in my third equation 2 energies.",
            "The first equation is governing.",
            "You can think of it as governing a prior on the depth map.",
            "So Z is a depth map and I'm letting P&Q range over, let's say, pixels.",
            "So P&Q are ranging over pixels and I'm looking in that some P&Q are required to be neighbors, so you take a sum over pairs of neighboring pixels.",
            "And you ask, how much does the depth map change between that pair between those two pixels?",
            "The depth map adds P minus the depth map at Q, and if we take an absolute value of that and some overall neighboring pixel pairs, we get something that's analogous to the what's called the total variation of the depth map.",
            "So this is saying that I'm going to put a prior probability on the depth map which says that depth Maps which are smooth, which have small total variation are.",
            "We're likely so E Lambda here is defining a prior on the depth map, and E Sigma is defining match energy.",
            "So now if I have a depth map, E Sigma is saying if I have a depth map and I want to there's going to be another energy that says if I take a pixel in one image, the depth map defines a map to a pixel in the other image.",
            "If I take the difference between those two image values.",
            "So there's supposed to be images of the same thing.",
            "The depth map is supposed to give you a correspondence between these images.",
            "Each pixel in one image should correspond to a pixel in the other image.",
            "The corresponding pixel should be pixels of the same thing, so they should have the same image value.",
            "So given the correspondence by look at those two image values and take their difference and square it, that's a measure of how much I'm violating the principle.",
            "They should be the same.",
            "It's a measure of it's a match Energia match cost.",
            "Now it turns out that you can interpret this match energy.",
            "As a log probability of Y given up, the right image given the left and the disparity map where your probability model is that the left image is equal to the right image is so.",
            "If I want to, if I want to predict the value in the left image, I look at the corresponding value in the right image, predict that value, but then add Gaussian noise.",
            "So I get the left image from the right image by mapping under the disparity map and then adding Gaussian noise and that probability model.",
            "And that's my second equation.",
            "That probability model corresponds to this energy, and then when we do stereo inference, we simply find the depth map which minimizes the sum of these two energies.",
            "We want it to be smooth and we want to have a good match.",
            "And the point here is that this is.",
            "Just go back this, isn't it?"
        ],
        [
            "Special case sort of a degenerate case of this indirect CRF and indirect CRF.",
            "We have a probability of Z given X.",
            "Here it's degenerate.",
            "We have a probability of C that doesn't depend on X."
        ],
        [
            "And but we do have a probability of Y given X&Z.",
            "OK, so."
        ],
        [
            "There's a precedent for what I'm for.",
            "What we're doing here.",
            "Zhang Insights in CPR 2005 took this.",
            "Took a model very much like this classical model and trained its parameters by maximizing this conditional probability.",
            "But you know, in a traditional stereo model and the one I just wrote, there are only two parameters in the.",
            "One in the model that Zhang Insights used, there were five parameters.",
            "Now an image might have a million pixels.",
            "And if you want to train 2 parameters or five parameters.",
            "It sort of makes sense to train it on one image of a million pixels.",
            "So what they did is instead of, you know, learning from a corpus of stereo pairs, some sophisticated model of depth.",
            "They just looked at one image and tuned the five parameters of a classical stereo algorithm.",
            "But it's a special case, still sort of sort of a special case of this general approach to.",
            "Training and indirect CRF.",
            "But you know what we would like to do, in principle at least, is train more sophisticated models, so you know arbitrarily sophisticated models that lead to monocular depth, or monocular image understanding even."
        ],
        [
            "OK, so I'm dying.",
            "I'm going to start diving deeper into vision.",
            "So what we're going to do?",
            "The actual research content that I'm just going to, or the original work in this talk has to do with using these hog features as a kind of shape from texture queue.",
            "So it's as a monocular shape Q.",
            "So the first thing I want to do is define is described these hog features Now hog features are a descendant of Sift features.",
            "Now Sift features were introduced in 99 by David Lowe and the introduction of that paper and of this kind of feature is probably the most significant development in computer vision and at least the last decade, probably in the last 20 years.",
            "All kinds of things started to work.",
            "Oh yes, yeah.",
            "The most cited paper remove engineering, but it's interesting to know that it was first rejected from ICD.",
            "1040 are very sweet by and in the next few months.",
            "Yeah, so the most cited paper in engineering and hog features are a descendant.",
            "You probably can't see that little picture of a hug feature up there, but it's a bunch of lines at various orientations.",
            "So first let me define what a hog feature vector is, and then I'll say briefly how it relates to SIFT.",
            "So what we do is we take in computing these hog features.",
            "We take a little 8 by 8.",
            "Typically pixels cell of the image.",
            "And at every pixel at all of the 64 pixels we compute the gradient of the image, which is a vector for every gradient vector we quantize its orientation into one of nine bins, and then for each orientation been, we add up all the 60 overall 64 pixels.",
            "All the magnitudes of the vectors that fall into that bin.",
            "And what we get is a histogram.",
            "You think it is a histogram of edge energy over 9 orientations, so it's a histogram of edge energy, and that's what I've tried to show you up there.",
            "Now a SIFT feature is really a four by four array of these hogs, cell features, something like these hog cell features and it's normalized in a slightly different way and allow and Triggs had more sophisticated ways of normalizing who developed the lyrics.",
            "Develop the hog feature as a descendant of the feature and they had more sophisticated ways of normalizing these features, but this is the basic idea so we have these nine so we're going to take our image and we're going to divide into these little cells and each cell we get a 9 dimensional vector.",
            "Feature vector.",
            "Um?"
        ],
        [
            "And the basic idea behind using these so.",
            "I certainly don't understand it.",
            "Certainly no.",
            "I don't know of any theorems which explain why these hog features work so well.",
            "It's mostly an empirical fact that that you know a lot of things started working that weren't working before with the introduction of SIFT features and.",
            "Pedro Felzenszwalb he's going to be talking tomorrow and I have been using these hog features in object detection.",
            "And just the other day he showed me a picture that had a train in it and our detector had found the train.",
            "And you know, we've been designing this thing together for years, and I said, that's amazing.",
            "How does that work?",
            "And he said, I don't know, and I don't know either.",
            "And this.",
            "I mean, it comes back to this fundamental general learning versus understanding the domain phenomenon, right?",
            "If you work on general learning.",
            "And you build this learning mechanism an it works in some domain like vision.",
            "Sometimes you're left wondering well, how did you know it worked?",
            "You know you just cook up some features.",
            "You run PCA, you do a regression and it works and you don't.",
            "You may or may not really understand why it works, so we were trying to understand why our detector works so well.",
            "And there's so our detector is using these hog features, so it's looking for patterns of edges.",
            "To find a person or a train or car, whatever and there's a question of is, are these edges?",
            "These edges correspond to the outline, the silhouette of the object.",
            "Are they object boundary edges, or are they edges from the interior of the object that are telling us something about shape?",
            "And we don't know, we just trained it right.",
            "We just ran this training algorithm and it optimize the performance.",
            "But we don't know whether it's looking for boundary edges or interior edges.",
            "So we.",
            "So we were thinking about, well, what could it be looking for in the interior of an object and we realized that the hog feature could be taken to be a surface orientation queue.",
            "So the idea is if I have a surface that has edges on it.",
            "And I tilt the surface.",
            "Tord you.",
            "The edges that are tilted toward you, like this, the up and down edges get foreshortened, but the vertical edges get foreshortened, but the horizontal edges don't.",
            "So you get an unnatural automatic skew that favors horizontal edges to vertical edges.",
            "So the ratio of horizontal vertical edges will tell you how much in principle, could tell you how much the surface is tilted toward you, and I don't know if you can see this.",
            "I don't think you can see this if you look at the tree.",
            "Maybe you could see that what I've done is taking a region on the surface of the tree and taking the average hog feature down a column of the tree.",
            "And you can see that near the edge of the tree where the tree trunk is twisted to be almost tangential, right?",
            "The rate from the camera is coming in at a very almost tangentially to the surface.",
            "The hog feature is very vertical, and it's much more spread in the middle of the trunk.",
            "So the idea is that maybe we could use this hog feature as a surface orientation cue and maybe even that's part of what's going on when we use it in a recognition filter."
        ],
        [
            "So here we're really diving into domain analysis.",
            "You can prove this theorem that if you have a texture, so a probability distribution over edges that's isotropic has the same amount of edge energy in every direction.",
            "And I take a surface with anisotropic texture and tilt it.",
            "Then you get a skew in the hog feature that satisfies this relationship.",
            "The minimum of the hog histogram divided by the maximum goes is the cosine cubed of the angle between the surface normal and the camera Ray.",
            "We don't use this fact, we just did some domain analysis.",
            "We do use this back."
        ],
        [
            "There's another fact that.",
            "So, so we're going to.",
            "We're going to build a stereo vision algorithm and our stereo vision algorithm is going to divide the image into segments, sometimes called super pixels.",
            "And in each segment, we're going to assume that the object in that segment is actually a plane.",
            "Each segment is going to be modeled as a plane.",
            "And you can prove it's very easy to show that if you have a plane in three space in a projective camera, that disparity in pixels between the two images.",
            "The disparity map is linear, is a linear function of the image coordinates.",
            "So the disparity this first equation.",
            "Here, the disparity is a function of image coordinates.",
            "X&Y is some base based disparity at the at the origin of the coordinate system, plus a linear combination of X&Y.",
            "So we call this a disparity plain, and that's what we're going to be.",
            "We are our latent information, so in our in our Markov random field we have a set of super pixels, a set of segments.",
            "The latent variable in each segment is going to be one of these disparity planes, so we're trying to predict D0A and B at every super pixel, and we and by by some geometry we get this equation at the bottom, which says that this is for the B coefficient.",
            "There's this relationship between the disparity plane coefficient and the depth and the tangent of the angle that the plane makes with the camera Ray.",
            "I don't want to go through."
        ],
        [
            "I I'm naturally interested in learning, so I want to just going to say there are there is this energy function.",
            "We did do a domain analysis to define the form of the energy function.",
            "Here's the energy function that we're using.",
            "There's a match energy.",
            "The other thing we want to do is put in more parameters into our model, so if you remember earlier people had just set five parameters, were interested in machine learning, people were used to training thousands of parameters.",
            "So if we're going to do monocular image understanding, we really want to train a lot of parameters.",
            "So one thing we do it was enrich the match energy to have more parameters.",
            "So we essentially introduce a wait.",
            "We have a feature vector at every pixel, and we introduce a wait for every feature in the feature vector, every pixel and define our match energy in terms of.",
            "The weights with a different weight for every feature at every pixel, so that's a match energy.",
            "It's saying here Petapixel P and the Pixel P plus disparity at P are the two corresponding pixels from the two images.",
            "And we're looking at the difference in their feature vectors and taking the square of that to be a match energy.",
            "We have a smoothness energy which is just which is just the total.",
            "It's a total variation energy on the on the depth map.",
            "And OK, so the first 2 energies are very similar to the classical model.",
            "They define a smoothness on the depth map and they define a match energy between the two images.",
            "But there's no monocular depth prediction, right.",
            "Monocular depth prediction would be an energy on just one image, and the depth map.",
            "Right, so it would allow us in principle to predict the depth map from a single image, so the last term is an energy that's a monocular depth cue energy.",
            "It's an energy defined just on.",
            "Just on one image just on the X image and the depth map.",
            "And basically it says if you look at the last equation, there's sort of two parts of the corresponding to the two directions X&Y direction, which corresponds to the a coefficient and the B coefficient of the disparity plane.",
            "And what we do is we're saying we're going to predict, say, the a coefficient look at the top part of the third line.",
            "We're going to try to predict the a coefficient from the hog feature.",
            "Today we use the hog feature to estimate the angle.",
            "Between the camera Ray and the plane normal, and we're just going to completely naively by having a parameter vector beta a inner product.",
            "The hog feature vector, and then we're going to multiply that by the disparity value, because our analysis said that was the right predictor of the a coefficient, and then we're going to take the difference between that and the a coefficient squared, and that's going to define this energy which is measuring how much our disparity map.",
            "Is in violation of the predictions made by the predictions you would expect if the hog feature was predicted by the plane shape."
        ],
        [
            "OK.",
            "So this is the inevitable results table.",
            "The top this is 2 measures of the accuracy of this algorithm, so I'm skipping over all the problems of training this model.",
            "I'm going to describe that next, but if you just sort of accept that we have this model, we have this energy.",
            "We have some way of training it and I'm just skipping to the results.",
            "And the second column is a measure of the difference between the estimated depth map and the true depth map.",
            "This database that we're using.",
            "Is a database of stereo pairs together with laser range Finder, ground truth depth.",
            "So we're able to and in this data.",
            "So so this hog feature is actually a pretty weak.",
            "Shape feature So what we're doing here is we're taking a stereo algorithm and augmenting it with.",
            "The hog shape from texture.",
            "Monocular cue.",
            "So these numbers are for a stereo algorithm and what we're doing is we're looking at the actual error between the estimated depth and the ground truth depth.",
            "For a system.",
            "For various for various kinds of systems.",
            "So in the first line.",
            "We're not using the texture at all, no texture cues.",
            "We're training the other parameters.",
            "The remaining parameters from the stereo pairs alone.",
            "We're not looking at the ground truth and training, and we get about the same as the best results from saksena at all.",
            "When we add the texture features again, we're training now, so this is called unsupervised texture.",
            "We're training just from the stereo pairs.",
            "So training just from the stereo pairs with monocular depth features, we see an improvement in ground truth depth estimation.",
            "So that's the sense in which this is an unsupervised.",
            "Learning algorithm if we actually train from the ground truth rather than just the pairs, we see that that actually improves things with a boost about the same magnitude is the boost we get from the texture features.",
            "This table has some caveats.",
            "Succinea at all are using a stronger model where they're explicitly modeling the ground plane were not explicitly modeling ground plane.",
            "There's nothing in our energy or features that understands the ground plane, but we're only running on about 3/4 of the images they are running on.",
            "Because our registration algorithm that we need to run our stereo algorithm failed on about 1/4 of the images.",
            "So we're probably running on a slightly easier image set.",
            "We need to get that cleaned up.",
            "I want to pause here and make some sort of philosophical comments.",
            "I don't know higher level comments.",
            "The machine learning community loves to think about general machine learning.",
            "Models methods.",
            "The vision community loves to see your numbers.",
            "And there's sort of a tension between getting those numbers and proving interesting theorems.",
            "You know the people who just interesting theorems.",
            "You can have a very nice theorem, and then at the end of the paper there you know there's a tendency to find some data set on which they can demonstrate their ideas.",
            "I thoroughly believe that.",
            "You have to do both.",
            "Or at least if you wanted interesting machine learning, you have to, you know you know face the music and actually get numbers that make the application people respect you.",
            "On benchmarks that they you know are legitimate, reasonable benchmarks.",
            "That's my personal philosophy, so we've gotten lots of you know, reviews from versions of this paper saying your numbers aren't good enough, and it's painful, but I'm willing to take it and go back and just make the numbers better, because unless you make the numbers better, you don't.",
            "You're not getting feedback from the case.",
            "Study about what's actually working.",
            "And I firmly believe you that that fee."
        ],
        [
            "Back is essential.",
            "Um?",
            "In this."
        ],
        [
            "In this process.",
            "OK, now I'm about to start the third part of this talk, which is just to talk about, so I skipped over how to train this model.",
            "Now I'm going to go back and talk about how we train the model, but I'm going to pop up into General General machine learning land so none of the thing I'm going to say from now on really has much to do with computer vision.",
            "It's just general methods that we can apply to models of this form.",
            "So we use Hardy am.",
            "It's not surprising that we use some form of VM given that the thing we're trying to work with is this latent.",
            "The thing we're trying to predict is some variable that's latent in the data.",
            "So we use a form of Hardy M and Hardy.",
            "M is going to is an iterative process.",
            "It takes, we assume that we have some model.",
            "We initialize the model somehow and that might involve some domain knowledge and then given that we initialize the model, we got these training points.",
            "The training points are XY pairs like there are these stereo image pairs and what we do is we go through the stereo pairs and we infer a depth map for each one using our current model and that depth map is going to involve both of these terms.",
            "Both of these energies it in principle is the is the most likely Z in this model.",
            "And then we make this approximation where we throw out one of the normalization term that depends on Z.",
            "It.",
            "We throw it up.",
            "What can I say?",
            "And then so we actually take ZY to be the argmax of the sum of these two energies.",
            "And then we update the parameters of the two models.",
            "We have two CRF's, one of which is the latent information.",
            "The latency given the input.",
            "That's one CRF that's defined by beta Z, and the other is Y.",
            "Given X&Z, we update those two, assuming that disease that we infer it in the first step or actual ground truth on those data points.",
            "So this is a general.",
            "This is hard YM.",
            "It's a standard.",
            "A standard method in machine learning for training models with latent variables."
        ],
        [
            "OK, now we've got."
        ],
        [
            "2 problems here.",
            "2 optimization problems we've got.",
            "ZI is an argument of a sum of energies, so our inference is an optimization problem and our model parameter update is also an optimization problem.",
            "So now I'm going to discuss general methods for addressing these two optimization problems and the first one I'm going to consider is the."
        ],
        [
            "Inference problem.",
            "So that."
        ],
        [
            "So remember, the inference problem is inferring this depth map Z.",
            "Now in the problem we're dealing with, it's not a depth map.",
            "We have super pixels, and the thing we need to infer is a plane, a disparity plane, or a plane in space for every super pixel.",
            "And the problem is that this is a.",
            "It's a, it's a 3 dimensional continuous latent value at every superpixel because it's a plane, so we've got.",
            "Amounts to a Markov random field over the latent information Z given the XY pair, and we've got a 3 dimensional continuous latent variable at every super pixel, and I want to find the most likely assignment of playing the superpixel.",
            "So it's a it's a Max product graphical model inference problem with a 3 dimensional continuous latent variable at every node and we use a loop."
        ],
        [
            "BP approach.",
            "I'm sorry, no, I'm sorry, not a loopy BP approach.",
            "A particle belief propagation approach and it's really very simple.",
            "The way it works is we somehow initialize a plane at every super pixel.",
            "Then, given that we've got a plane at every superpixel, just some guess.",
            "We go through every superpixel and introduce a whole bunch of other planes with some proposal distribution around the one that we've assigned to that superpixel what we actually uses some Gaussian.",
            "We take that super pixel and add a bunch of points around it, using it by adding a Gaussian deviation.",
            "So then we've got to set a finite set of values at every super pixel.",
            "So that reduces it to a discrete Markov random field.",
            "A discrete graphical model.",
            "And we can you can run your favorite Max product inference algorithm for discrete graphical model like we use loopy BP.",
            "Or you could use TRW.",
            "How many people have studied loopy BP for?",
            "OK. That's another thing that machine learning people."
        ],
        [
            "Hopefully we'll have under their belt.",
            "OK, let me."
        ],
        [
            "Back up again.",
            "So we have these other optimization problems to work on the, which are the model parameter.",
            "See update of the model parameters for the two Markov random fields and for that we use this map."
        ],
        [
            "Did that, Jeff Hinton introduced called contrastive Divergent's.",
            "So what we're going to do is a form of gradient descent.",
            "We're updating the model parameters.",
            "It's very common in this whole area to use gradient descent methods for the to train the model parameters, and there are very standard equations for CRF's.",
            "And for many of these graphical models to express the gradient of your objective function.",
            "The training algorithm remember is defined by an optimization problem.",
            "The optimization problem is minimizing this objective function.",
            "We can express the gradient of the objective function.",
            "I'm just going to skip over.",
            "This is going to be way too much, so I'm just going to try to pass over this at a high level.",
            "You can express the gradient of the objective function.",
            "As a difference of two terms, one is the gradient of the energy that you're actually have at your training points.",
            "In this training algorithm, we assume we know the size, so one term is the actual gradient of the actual energy.",
            "The other term is the average.",
            "Energy gradient averaged over wise that the predictor would predict weighted.",
            "So there's an expectation over why drawn from the prediction distribution under the current model.",
            "So you're looking at your predicting AY.",
            "According to the prediction distribution and looking at the gradient of the energy of that, why under the parameter model?",
            "So that much.",
            "You may or may not have followed, but."
        ],
        [
            "Then there's this contrastive divergent process which I can tell I've lost every how many people have seen contrastive divergent before.",
            "Three, OK.",
            "Idea behind trusted divergents let me just say it at a high level.",
            "Is this second term in the second equation that second term in the second?"
        ],
        [
            "Asian is an expectation over very complicated probability distribution.",
            "The way you do an expectation were very complicated probability distributions.",
            "You do MCMC sampling.",
            "So you do something like a metropolis process.",
            "You set up a stochastic process whose stationary distribution is the distribution you're interested in.",
            "You let the process run for awhile.",
            "Hopefully it's mixing time, and then you, and then you take where it is, and that's a sample.",
            "And if I can get a bunch of independent samples from that distribution, and I take the average of something that average will approach the expectation.",
            "So if I'm interested in expectation by using an MCMC process, the sample I can get an estimate of the expectation.",
            "Now the problem with the MCMC process is it has very high variance.",
            "The this distribution might be fairly diffuse, so the idea in contrastive divergent's in the in the last line here is rather than.",
            "Let this process run till it reaches equilibrium.",
            "We start, we initialize the variable Y that we're going to draw from this distribution.",
            "To be why I so we start the MCMC process at why I?",
            "And we run only two steps or one step of the MCMC process, so we're nowhere near the stationary distribution.",
            "We're very near why I OK and then we just do that and take that instead of that expectation.",
            "And the amazing thing is that this is a good idea.",
            "It dramatically reduces the variance because we're always we're guaranteed to be very near why I?",
            "So there's much less variation.",
            "And you can prove.",
            "Let me see."
        ],
        [
            "On the next slide.",
            "No, you can prove that."
        ],
        [
            "Yeah, in this in the last line here you can prove that if.",
            "If the expectation of this so in contrastive divergent, you get some update direction.",
            "There's some expected update direction if that update direction is integrable into a potential function.",
            "If there's a potential function such as the update direction, is the gradient of that potential function then.",
            "Following that gradient and minimizing that potential function is is a consistent estimator of beta.",
            "And the latest.",
            "The way to see that is is to assume that the actual why eyes are drawn from some P beta, and if that's true then it's not difficult to see that the update direction is zero when the Y eyes are actually drawn from some P beta, and you're at that P beta, then these two distributions are identical and the update direction is 0.",
            "So the rest of."
        ],
        [
            "I have a couple slides here which I'm not going to."
        ],
        [
            "Through because I think I've used up enough time that try to argue that contrastive divergent deserves respect.",
            "Because we had this theorem that said, if there was a potential function then it would be a consistent estimator and it turns out that for natural MCMC processes, for example, for the MCMC process that Standard Lee used with with Markov random fields, you can show that there is a potential function and the contrastive divergent's.",
            "Well, let me just say it for the standard MCMC process for Markov random fields, contrastive divergent's corresponds to maximizing pseudo likelihood.",
            "Which is a standard well known method.",
            "You can also show that for a standard metropolis process."
        ],
        [
            "Over a continuous configuration space, if you take a certain differential limit to get a differential stochastic equation, you get another.",
            "You can prove you get another potential function, and again you get a basically a consistent estimator.",
            "So there are cases where you can prove that these potential functions exist and you've got consistent estimators, and when this is typically used, it's typically used in ways where you don't have these theorems, but the fact that you these theorems are true sometimes suggests that this is a good method.",
            "But it might work."
        ],
        [
            "In general, the fact that it's consistent, however, does not necessarily imply that it's a good thing.",
            "In the case when your data is not drawn from a model in your class.",
            "Different potential functions will give different estimates.",
            "Even if they're consistent in the case."
        ],
        [
            "Where the data is drawn from your model class.",
            "OK, I'm going to stop here.",
            "So the take home message is that we've we formulated this notion of indirect CRF training, where we want to learn a model, a conditional random field of Z given X from training data from training data XY that don't contain Z, right where we're going to be have a latent model for Z that's predicting Y given X&Z, and we're interested in the conditional random field that predicts Z where it's not in the training data.",
            "And we've demonstrated this idea on conditional random fields for monocular depth cues.",
            "In the abstract for this talk, I said I was going to say something about shape from shading and that's it was a classical example of this is going to work before the talk and we experimented with shape from shading and in our initial experiments we did not get much of a boost shape, but its shape from shading is a great area.",
            "In which two I believe we will get there, we will get a boot.",
            "We will be able to train shape from shading models, but we have not gotten any numerical benefit from it yet.",
            "OK, I'll stop there and take questions.",
            "What is the difference between conditional diner radio?",
            "Those are great conversions, conditional random fields and what learning Bayesian learning.",
            "Bing.",
            "Well, in in the conditional random fields.",
            "We're not let me go all the way."
        ],
        [
            "Back here.",
            "So this is the training equation on the bottom and you can interpret the regularization on beta that quadratic regularization on beta as a prior probability over the model parameters.",
            "It's like a Gaussian prior over the model parameters.",
            "So you can interpret this as a.",
            "As a map estimate of beta, real Bayesian would want to average over beta.",
            "There'd be a prior on beta.",
            "There'd be a posterior on beta and you'd want to average.",
            "You'd want your prediction to be an average over beta, weighted by the posterior.",
            "So one difference is that we're taking a map estimate.",
            "Personally, I'm not a Bayesian, so I would be more interested in analyzing this learning algorithm from a frequentist perspective.",
            "It's asking what guarantees could I give for this?",
            "Independent of the assumption that the prior on beta is true and you can give those kinds of theorems.",
            "Some sort of frequentist guarantees?",
            "About the performance of a model trained this way.",
            "So Q year contrastive divergent is kind of a subroutine in your PM algorithm, right?",
            "Step is only going to be approximate.",
            "It's a Hardy step.",
            "So why the consistency results just for this animal sovereignty?",
            "That"
        ],
        [
            "Consistency results.",
            "Only remotely related to what you actually do when you use it, so the consistency results say that if I were to compute that expectation exactly right, if I were to do take enough samples that I got exactly sort of infinite number of samples, and then I followed that gradient at some learning rate that went to zero.",
            "Then I would converge on the actual beta.",
            "This done the fact that only approximately step was not a problem.",
            "Um?",
            "Well, it's hard to know.",
            "We don't know what a you know.",
            "A more faithful approach would would do.",
            "Right and Ari step is only approximate, so that that's another reason the theorem doesn't wouldn't apply, right?",
            "Thanks very much."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Afternoon session, so pleasure to introduce David McAllister of Toyota Technological Institute.",
                    "label": 1
                },
                {
                    "sent": "Thanks David.",
                    "label": 0
                },
                {
                    "sent": "Thanks, Steve.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, I'm gonna try to get by without a laser pointer.",
                    "label": 0
                },
                {
                    "sent": "But what I want to do today is considered the problem of scene understanding, and particularly in particular scene understanding from a single image.",
                    "label": 0
                },
                {
                    "sent": "So monocular scene understanding so there's been a fair amount of work very recently on understanding single images, and Andrew being and shows succinea at Stanford, have done work on predicting depth on inferring 3D structure from a single image.",
                    "label": 0
                },
                {
                    "sent": "This is something people are doing quite well.",
                    "label": 0
                },
                {
                    "sent": "This is a classical image from the stereovision community, and it's fairly easy to look at it and understand what's there and do approximate depth estimates.",
                    "label": 0
                },
                {
                    "sent": "Now in the recent work, there's a lot of emphasis on conditional random fields.",
                    "label": 0
                },
                {
                    "sent": "So most of you are probably familiar with conditional random fields.",
                    "label": 0
                },
                {
                    "sent": "We take an input like an image and we're interested in inferring a depth map Isaiah depth at every pixel, which is a field value, a structured label for this image.",
                    "label": 0
                },
                {
                    "sent": "And so I'm going to be spending some time talking about conditional random fields and generalizations of conditional random fields.",
                    "label": 0
                },
                {
                    "sent": "And this the remainder of this talk will be divided into sort of three parts.",
                    "label": 0
                },
                {
                    "sent": "That correspond to.",
                    "label": 0
                },
                {
                    "sent": "Sort of, the distinction between general approaches to machine learning and domain specific insights into computer vision.",
                    "label": 0
                },
                {
                    "sent": "So there's this.",
                    "label": 0
                },
                {
                    "sent": "Of course, there's this tendency in vision and in many fields of computer science to be sort of taken over by learning people, and there's this old spectrum within philosophy and and approaches to cognition between one end.",
                    "label": 0
                },
                {
                    "sent": "I would say there's Jeff Hinton, sort of a neural net person.",
                    "label": 0
                },
                {
                    "sent": "And he's really the learning person.",
                    "label": 0
                },
                {
                    "sent": "He believes in very general approaches to machine learning.",
                    "label": 0
                },
                {
                    "sent": "He makes an analogy with the principles of aerodynamics and all the complexity of cognition.",
                    "label": 0
                },
                {
                    "sent": "Follows from a very general theory of machine learning.",
                    "label": 0
                },
                {
                    "sent": "At the other end there's Noam Chomsky.",
                    "label": 0
                },
                {
                    "sent": "And Noam Chomsky believes that properties of natural language, the actual syntax of natural language is somehow embedded in our DNA that we come with the prior knowledge of universal grammar.",
                    "label": 0
                },
                {
                    "sent": "But this tension between general machine learning and the details of particular domains like vision or computational linguistics.",
                    "label": 0
                },
                {
                    "sent": "This tension is is something that we're seeing more and more of, and my talk is going to be divided into sort of three parts.",
                    "label": 0
                },
                {
                    "sent": "The first part in the last part will be in the realm of general learning.",
                    "label": 0
                },
                {
                    "sent": "And the middle part will be vision specific and the way I think about research like this is, I'm really most excited personally about the general learning formalisms about understanding learning in a domain independent level and in an area like computer vision.",
                    "label": 0
                },
                {
                    "sent": "What fascinates me is using that as a testbed or a benchmark or a case study in applications of general machine learning.",
                    "label": 0
                },
                {
                    "sent": "Methods, so that's sort of the way I'm going to try to structure this talk.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I'm going to start with a review of Markov random fields, so the introduction of Markov random fields, in particular this paper by Lafferty at all in 2001, has had a huge impact on the general machine learning community.",
                    "label": 0
                },
                {
                    "sent": "It's one of the most cited papers I think in computer science, and you can write down the basic idea in just a few simple equations.",
                    "label": 0
                },
                {
                    "sent": "Probably most of you have seen these equations before the 1st two equations here define the model it's defining a conditional probability of Y given X as just a normalized.",
                    "label": 0
                },
                {
                    "sent": "Normalization of an exponential in an energy.",
                    "label": 0
                },
                {
                    "sent": "And it's the energy function that defines the model.",
                    "label": 0
                },
                {
                    "sent": "And here beta you want to beta as a parameter vector.",
                    "label": 0
                },
                {
                    "sent": "This is often written as a uniform that restrict it to be linear.",
                    "label": 0
                },
                {
                    "sent": "In beta beta transpose a feature vector and XY, but I'm writing a more general form here.",
                    "label": 0
                },
                {
                    "sent": "How many people?",
                    "label": 0
                },
                {
                    "sent": "Have worked, you know, really understand.",
                    "label": 0
                },
                {
                    "sent": "I've seen lots of times, conditional random fields.",
                    "label": 1
                },
                {
                    "sent": "Oh OK, I was thinking a lot of people haven't alright.",
                    "label": 0
                },
                {
                    "sent": "So so the first 2 equations define the model it's defining a conditional probability of Y given X.",
                    "label": 0
                },
                {
                    "sent": "And the second equation is defining training, but I want you to think of it just for a moment.",
                    "label": 0
                },
                {
                    "sent": "Think of the monocular monocular image understanding problem in that problem.",
                    "label": 0
                },
                {
                    "sent": "We're given an input X, which is an image.",
                    "label": 0
                },
                {
                    "sent": "And what we want to do is label it, say with a depth map.",
                    "label": 0
                },
                {
                    "sent": "We want to assign a depth to every pixel and the depth map here is Y.",
                    "label": 0
                },
                {
                    "sent": "So X&Y are both structured objects, X is an image in this example.",
                    "label": 0
                },
                {
                    "sent": "And why is a depth map an assignment of a depth to each pixel and what we're interested in doing?",
                    "label": 0
                },
                {
                    "sent": "What we really want to do is define this energy function.",
                    "label": 0
                },
                {
                    "sent": "Such that when I take an X and compute a probability distribution over Y, and let's say I take the most likely Y, I'm inferring the actual depth map for that input image.",
                    "label": 0
                },
                {
                    "sent": "And the training equation down here assumes that I have as training data XY pairs, so it assumes that I have is training data images together with their depth map and then it what it's doing is it's setting the parameter beta.",
                    "label": 0
                },
                {
                    "sent": "So I've got this model class somehow defined by this general parameter beta, and it's setting the parameter beta to minimize a log loss, a sum over the training points.",
                    "label": 0
                },
                {
                    "sent": "I I is ranging over training points of one over the probability in the model of the training label for the input X. OK.",
                    "label": 0
                },
                {
                    "sent": "This is really a hot topic in acnl machine learning and and you know, computational linguistics.",
                    "label": 0
                },
                {
                    "sent": "Here's a much more.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Recent.",
                    "label": 0
                },
                {
                    "sent": "Embellishment of a conditional random field called a hidden CRF.",
                    "label": 0
                },
                {
                    "sent": "Now, in a hidden CRF.",
                    "label": 0
                },
                {
                    "sent": "The first 2 equations define a model that is a CRF.",
                    "label": 0
                },
                {
                    "sent": "It's just like the one I listed before, except there's also a hidden variable Z, so we're defining a probability distribution over 2 simultaneous values Y&Z.",
                    "label": 0
                },
                {
                    "sent": "Given an input X.",
                    "label": 0
                },
                {
                    "sent": "So I thought maybe a good example with this of this would might be a machine translation problem, so think of X is being an input sentence Y as being its translation into, say, from English to French and Z as being a parse tree.",
                    "label": 0
                },
                {
                    "sent": "And your training data would have translation pairs, but your model involves a parse tree, so there's a hidden structure, AZ that's not in your training data, but that is part of your model.",
                    "label": 0
                },
                {
                    "sent": "And what happens is in the third line.",
                    "label": 0
                },
                {
                    "sent": "Here, the probability of the output given the input is a marginalization over the hidden information Z of the probability of of the pairwise E given the input where the pairwise E is defined by these equations.",
                    "label": 0
                },
                {
                    "sent": "And then the last equation is the training equation.",
                    "label": 0
                },
                {
                    "sent": "It says set the model parameter beta to be that parameter, which optimizes exactly the same loss we had before.",
                    "label": 0
                },
                {
                    "sent": "It's a log loss.",
                    "label": 0
                },
                {
                    "sent": "And in both of those equations I'm using a quadratic regularizer to try to minimize the norm of the weight vector.",
                    "label": 0
                },
                {
                    "sent": "So this has attracted a fair amount of attention because simply because latent.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Rules.",
                    "label": 0
                },
                {
                    "sent": "Are quite useful in lots of modeling applications now.",
                    "label": 0
                },
                {
                    "sent": "It turns out that you know you can combine a set of adjectives and get a combinatorial number of different models by combining this notion of structured output.",
                    "label": 0
                },
                {
                    "sent": "With so you have for many machine learning applications, you're interested in classification, which is you have XY pairs and Y is minus one or one binary classification.",
                    "label": 0
                },
                {
                    "sent": "In a CRF, you're interested in a structured output, like a depth map.",
                    "label": 0
                },
                {
                    "sent": "Then we can talk about support vector machines.",
                    "label": 0
                },
                {
                    "sent": "So let me try again.",
                    "label": 0
                },
                {
                    "sent": "How many people are comfortable with support vector machines?",
                    "label": 0
                },
                {
                    "sent": "More most OK, so there's a support for every one of these conditional random field notions.",
                    "label": 0
                },
                {
                    "sent": "There's a support vector machine analogue, so we can talk about binary output, structured outputs, fully labeled training data or training data with where, where the model has some latent information in it, and then for any combination of those we can do an SVM or a CRF.",
                    "label": 0
                },
                {
                    "sent": "And some of these, in particular the structured El SVM that bottom one on the left I think may have just appeared.",
                    "label": 0
                },
                {
                    "sent": "There might just be a reference to that this year in the literature, but all of these things.",
                    "label": 0
                },
                {
                    "sent": "Can be formulated.",
                    "label": 0
                },
                {
                    "sent": "And I don't mean that this is the space of all possible models, but it's nice to have these adjectives and realize you can combine them in any way you want and you get a model and it's nice to be able to, you know, if your machine learning aficionado would be nice to be able to write down any one of these on demand.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, well I'm going to do in this talk.",
                    "label": 0
                },
                {
                    "sent": "Is introduced sort of another dimension into that chart.",
                    "label": 0
                },
                {
                    "sent": "And I'm going to call this an indirect CRF.",
                    "label": 0
                },
                {
                    "sent": "So remember that.",
                    "label": 0
                },
                {
                    "sent": "What we're interested in doing is, let's say, let's look at the image understanding problem.",
                    "label": 0
                },
                {
                    "sent": "What we're interested in doing is.",
                    "label": 0
                },
                {
                    "sent": "Learning a certain conditional random field that's going to infer the depth from the image.",
                    "label": 0
                },
                {
                    "sent": "That's our monocular image understanding problem.",
                    "label": 0
                },
                {
                    "sent": "But now what I want to do is learn that CRF.",
                    "label": 0
                },
                {
                    "sent": "From stereo pairs?",
                    "label": 0
                },
                {
                    "sent": "OK, that's what I'm going to talk about when I get to vision, so I want to think of a stereo pair as being a pair XY where I think, say at the left image as an input and the right image the right image as a structured output.",
                    "label": 0
                },
                {
                    "sent": "And what I'm going to do is have a model that involves a latent variable.",
                    "label": 0
                },
                {
                    "sent": "Where the latent variable is the depth map, and.",
                    "label": 0
                },
                {
                    "sent": "And then my model is going to have this structure, so let's look at this general structure and I've described it in terms of images, but it's a general.",
                    "label": 0
                },
                {
                    "sent": "This is, the idea is that this is a general model for model structure that could be applied in any domain.",
                    "label": 0
                },
                {
                    "sent": "I've got training data which is XY pairs.",
                    "label": 0
                },
                {
                    "sent": "I'm interested in learning a CRF.",
                    "label": 0
                },
                {
                    "sent": "I'm reading the first line here, which is predicting some Z from X.",
                    "label": 0
                },
                {
                    "sent": "But she is not explicitly given in the training data.",
                    "label": 0
                },
                {
                    "sent": "Z is latent in the training data, so I'm interested in using stereo pairs to train monocular depth estimation.",
                    "label": 0
                },
                {
                    "sent": "So I have a model that involves two CRF's.",
                    "label": 0
                },
                {
                    "sent": "One is the probability of the CRF defining the probability of the latent information, like the depth map given the input and the 2nd is the probability of the actual label.",
                    "label": 0
                },
                {
                    "sent": "I see which is the other image given the input and the latent information.",
                    "label": 0
                },
                {
                    "sent": "And then I'm the training equation is going to look just the same.",
                    "label": 0
                },
                {
                    "sent": "It's exactly the same we're going to.",
                    "label": 0
                },
                {
                    "sent": "We're going to pick now to we're going to pick the parameters from two different CRF's to minimize this log loss plus this regularization term.",
                    "label": 0
                },
                {
                    "sent": "But in this case the probability of Y given X is factored into this form, and what I'm really hoping to learn is the probability of Z given X. OK.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the first thing I want to do is so that's the end of the first part of my talk, sort of general sort of an overview of general models for machine learning.",
                    "label": 0
                },
                {
                    "sent": "Now I'm going to start talking about computer Vision, more specifically, and the first thing I want to do is, say is take a look at classical algorithms for stereo vision so stereo vision takes a pair of images and it infers a depth map.",
                    "label": 0
                },
                {
                    "sent": "And and a classical algorithm for stereo vision would involve these two energy terms.",
                    "label": 0
                },
                {
                    "sent": "I'm going to look at my first equation in my third equation 2 energies.",
                    "label": 0
                },
                {
                    "sent": "The first equation is governing.",
                    "label": 0
                },
                {
                    "sent": "You can think of it as governing a prior on the depth map.",
                    "label": 0
                },
                {
                    "sent": "So Z is a depth map and I'm letting P&Q range over, let's say, pixels.",
                    "label": 0
                },
                {
                    "sent": "So P&Q are ranging over pixels and I'm looking in that some P&Q are required to be neighbors, so you take a sum over pairs of neighboring pixels.",
                    "label": 0
                },
                {
                    "sent": "And you ask, how much does the depth map change between that pair between those two pixels?",
                    "label": 0
                },
                {
                    "sent": "The depth map adds P minus the depth map at Q, and if we take an absolute value of that and some overall neighboring pixel pairs, we get something that's analogous to the what's called the total variation of the depth map.",
                    "label": 0
                },
                {
                    "sent": "So this is saying that I'm going to put a prior probability on the depth map which says that depth Maps which are smooth, which have small total variation are.",
                    "label": 0
                },
                {
                    "sent": "We're likely so E Lambda here is defining a prior on the depth map, and E Sigma is defining match energy.",
                    "label": 0
                },
                {
                    "sent": "So now if I have a depth map, E Sigma is saying if I have a depth map and I want to there's going to be another energy that says if I take a pixel in one image, the depth map defines a map to a pixel in the other image.",
                    "label": 0
                },
                {
                    "sent": "If I take the difference between those two image values.",
                    "label": 0
                },
                {
                    "sent": "So there's supposed to be images of the same thing.",
                    "label": 0
                },
                {
                    "sent": "The depth map is supposed to give you a correspondence between these images.",
                    "label": 0
                },
                {
                    "sent": "Each pixel in one image should correspond to a pixel in the other image.",
                    "label": 0
                },
                {
                    "sent": "The corresponding pixel should be pixels of the same thing, so they should have the same image value.",
                    "label": 0
                },
                {
                    "sent": "So given the correspondence by look at those two image values and take their difference and square it, that's a measure of how much I'm violating the principle.",
                    "label": 0
                },
                {
                    "sent": "They should be the same.",
                    "label": 0
                },
                {
                    "sent": "It's a measure of it's a match Energia match cost.",
                    "label": 0
                },
                {
                    "sent": "Now it turns out that you can interpret this match energy.",
                    "label": 0
                },
                {
                    "sent": "As a log probability of Y given up, the right image given the left and the disparity map where your probability model is that the left image is equal to the right image is so.",
                    "label": 0
                },
                {
                    "sent": "If I want to, if I want to predict the value in the left image, I look at the corresponding value in the right image, predict that value, but then add Gaussian noise.",
                    "label": 0
                },
                {
                    "sent": "So I get the left image from the right image by mapping under the disparity map and then adding Gaussian noise and that probability model.",
                    "label": 0
                },
                {
                    "sent": "And that's my second equation.",
                    "label": 0
                },
                {
                    "sent": "That probability model corresponds to this energy, and then when we do stereo inference, we simply find the depth map which minimizes the sum of these two energies.",
                    "label": 0
                },
                {
                    "sent": "We want it to be smooth and we want to have a good match.",
                    "label": 0
                },
                {
                    "sent": "And the point here is that this is.",
                    "label": 0
                },
                {
                    "sent": "Just go back this, isn't it?",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Special case sort of a degenerate case of this indirect CRF and indirect CRF.",
                    "label": 0
                },
                {
                    "sent": "We have a probability of Z given X.",
                    "label": 0
                },
                {
                    "sent": "Here it's degenerate.",
                    "label": 0
                },
                {
                    "sent": "We have a probability of C that doesn't depend on X.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And but we do have a probability of Y given X&Z.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "There's a precedent for what I'm for.",
                    "label": 0
                },
                {
                    "sent": "What we're doing here.",
                    "label": 0
                },
                {
                    "sent": "Zhang Insights in CPR 2005 took this.",
                    "label": 0
                },
                {
                    "sent": "Took a model very much like this classical model and trained its parameters by maximizing this conditional probability.",
                    "label": 0
                },
                {
                    "sent": "But you know, in a traditional stereo model and the one I just wrote, there are only two parameters in the.",
                    "label": 0
                },
                {
                    "sent": "One in the model that Zhang Insights used, there were five parameters.",
                    "label": 0
                },
                {
                    "sent": "Now an image might have a million pixels.",
                    "label": 0
                },
                {
                    "sent": "And if you want to train 2 parameters or five parameters.",
                    "label": 1
                },
                {
                    "sent": "It sort of makes sense to train it on one image of a million pixels.",
                    "label": 0
                },
                {
                    "sent": "So what they did is instead of, you know, learning from a corpus of stereo pairs, some sophisticated model of depth.",
                    "label": 0
                },
                {
                    "sent": "They just looked at one image and tuned the five parameters of a classical stereo algorithm.",
                    "label": 1
                },
                {
                    "sent": "But it's a special case, still sort of sort of a special case of this general approach to.",
                    "label": 0
                },
                {
                    "sent": "Training and indirect CRF.",
                    "label": 1
                },
                {
                    "sent": "But you know what we would like to do, in principle at least, is train more sophisticated models, so you know arbitrarily sophisticated models that lead to monocular depth, or monocular image understanding even.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so I'm dying.",
                    "label": 0
                },
                {
                    "sent": "I'm going to start diving deeper into vision.",
                    "label": 0
                },
                {
                    "sent": "So what we're going to do?",
                    "label": 0
                },
                {
                    "sent": "The actual research content that I'm just going to, or the original work in this talk has to do with using these hog features as a kind of shape from texture queue.",
                    "label": 0
                },
                {
                    "sent": "So it's as a monocular shape Q.",
                    "label": 0
                },
                {
                    "sent": "So the first thing I want to do is define is described these hog features Now hog features are a descendant of Sift features.",
                    "label": 0
                },
                {
                    "sent": "Now Sift features were introduced in 99 by David Lowe and the introduction of that paper and of this kind of feature is probably the most significant development in computer vision and at least the last decade, probably in the last 20 years.",
                    "label": 0
                },
                {
                    "sent": "All kinds of things started to work.",
                    "label": 0
                },
                {
                    "sent": "Oh yes, yeah.",
                    "label": 0
                },
                {
                    "sent": "The most cited paper remove engineering, but it's interesting to know that it was first rejected from ICD.",
                    "label": 0
                },
                {
                    "sent": "1040 are very sweet by and in the next few months.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so the most cited paper in engineering and hog features are a descendant.",
                    "label": 0
                },
                {
                    "sent": "You probably can't see that little picture of a hug feature up there, but it's a bunch of lines at various orientations.",
                    "label": 0
                },
                {
                    "sent": "So first let me define what a hog feature vector is, and then I'll say briefly how it relates to SIFT.",
                    "label": 0
                },
                {
                    "sent": "So what we do is we take in computing these hog features.",
                    "label": 1
                },
                {
                    "sent": "We take a little 8 by 8.",
                    "label": 0
                },
                {
                    "sent": "Typically pixels cell of the image.",
                    "label": 0
                },
                {
                    "sent": "And at every pixel at all of the 64 pixels we compute the gradient of the image, which is a vector for every gradient vector we quantize its orientation into one of nine bins, and then for each orientation been, we add up all the 60 overall 64 pixels.",
                    "label": 1
                },
                {
                    "sent": "All the magnitudes of the vectors that fall into that bin.",
                    "label": 0
                },
                {
                    "sent": "And what we get is a histogram.",
                    "label": 0
                },
                {
                    "sent": "You think it is a histogram of edge energy over 9 orientations, so it's a histogram of edge energy, and that's what I've tried to show you up there.",
                    "label": 0
                },
                {
                    "sent": "Now a SIFT feature is really a four by four array of these hogs, cell features, something like these hog cell features and it's normalized in a slightly different way and allow and Triggs had more sophisticated ways of normalizing who developed the lyrics.",
                    "label": 0
                },
                {
                    "sent": "Develop the hog feature as a descendant of the feature and they had more sophisticated ways of normalizing these features, but this is the basic idea so we have these nine so we're going to take our image and we're going to divide into these little cells and each cell we get a 9 dimensional vector.",
                    "label": 0
                },
                {
                    "sent": "Feature vector.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And the basic idea behind using these so.",
                    "label": 0
                },
                {
                    "sent": "I certainly don't understand it.",
                    "label": 0
                },
                {
                    "sent": "Certainly no.",
                    "label": 0
                },
                {
                    "sent": "I don't know of any theorems which explain why these hog features work so well.",
                    "label": 0
                },
                {
                    "sent": "It's mostly an empirical fact that that you know a lot of things started working that weren't working before with the introduction of SIFT features and.",
                    "label": 0
                },
                {
                    "sent": "Pedro Felzenszwalb he's going to be talking tomorrow and I have been using these hog features in object detection.",
                    "label": 0
                },
                {
                    "sent": "And just the other day he showed me a picture that had a train in it and our detector had found the train.",
                    "label": 0
                },
                {
                    "sent": "And you know, we've been designing this thing together for years, and I said, that's amazing.",
                    "label": 0
                },
                {
                    "sent": "How does that work?",
                    "label": 0
                },
                {
                    "sent": "And he said, I don't know, and I don't know either.",
                    "label": 0
                },
                {
                    "sent": "And this.",
                    "label": 0
                },
                {
                    "sent": "I mean, it comes back to this fundamental general learning versus understanding the domain phenomenon, right?",
                    "label": 0
                },
                {
                    "sent": "If you work on general learning.",
                    "label": 0
                },
                {
                    "sent": "And you build this learning mechanism an it works in some domain like vision.",
                    "label": 0
                },
                {
                    "sent": "Sometimes you're left wondering well, how did you know it worked?",
                    "label": 0
                },
                {
                    "sent": "You know you just cook up some features.",
                    "label": 0
                },
                {
                    "sent": "You run PCA, you do a regression and it works and you don't.",
                    "label": 0
                },
                {
                    "sent": "You may or may not really understand why it works, so we were trying to understand why our detector works so well.",
                    "label": 0
                },
                {
                    "sent": "And there's so our detector is using these hog features, so it's looking for patterns of edges.",
                    "label": 0
                },
                {
                    "sent": "To find a person or a train or car, whatever and there's a question of is, are these edges?",
                    "label": 0
                },
                {
                    "sent": "These edges correspond to the outline, the silhouette of the object.",
                    "label": 0
                },
                {
                    "sent": "Are they object boundary edges, or are they edges from the interior of the object that are telling us something about shape?",
                    "label": 0
                },
                {
                    "sent": "And we don't know, we just trained it right.",
                    "label": 0
                },
                {
                    "sent": "We just ran this training algorithm and it optimize the performance.",
                    "label": 0
                },
                {
                    "sent": "But we don't know whether it's looking for boundary edges or interior edges.",
                    "label": 0
                },
                {
                    "sent": "So we.",
                    "label": 0
                },
                {
                    "sent": "So we were thinking about, well, what could it be looking for in the interior of an object and we realized that the hog feature could be taken to be a surface orientation queue.",
                    "label": 0
                },
                {
                    "sent": "So the idea is if I have a surface that has edges on it.",
                    "label": 0
                },
                {
                    "sent": "And I tilt the surface.",
                    "label": 0
                },
                {
                    "sent": "Tord you.",
                    "label": 0
                },
                {
                    "sent": "The edges that are tilted toward you, like this, the up and down edges get foreshortened, but the vertical edges get foreshortened, but the horizontal edges don't.",
                    "label": 0
                },
                {
                    "sent": "So you get an unnatural automatic skew that favors horizontal edges to vertical edges.",
                    "label": 0
                },
                {
                    "sent": "So the ratio of horizontal vertical edges will tell you how much in principle, could tell you how much the surface is tilted toward you, and I don't know if you can see this.",
                    "label": 0
                },
                {
                    "sent": "I don't think you can see this if you look at the tree.",
                    "label": 0
                },
                {
                    "sent": "Maybe you could see that what I've done is taking a region on the surface of the tree and taking the average hog feature down a column of the tree.",
                    "label": 0
                },
                {
                    "sent": "And you can see that near the edge of the tree where the tree trunk is twisted to be almost tangential, right?",
                    "label": 0
                },
                {
                    "sent": "The rate from the camera is coming in at a very almost tangentially to the surface.",
                    "label": 0
                },
                {
                    "sent": "The hog feature is very vertical, and it's much more spread in the middle of the trunk.",
                    "label": 0
                },
                {
                    "sent": "So the idea is that maybe we could use this hog feature as a surface orientation cue and maybe even that's part of what's going on when we use it in a recognition filter.",
                    "label": 1
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So here we're really diving into domain analysis.",
                    "label": 0
                },
                {
                    "sent": "You can prove this theorem that if you have a texture, so a probability distribution over edges that's isotropic has the same amount of edge energy in every direction.",
                    "label": 0
                },
                {
                    "sent": "And I take a surface with anisotropic texture and tilt it.",
                    "label": 0
                },
                {
                    "sent": "Then you get a skew in the hog feature that satisfies this relationship.",
                    "label": 0
                },
                {
                    "sent": "The minimum of the hog histogram divided by the maximum goes is the cosine cubed of the angle between the surface normal and the camera Ray.",
                    "label": 1
                },
                {
                    "sent": "We don't use this fact, we just did some domain analysis.",
                    "label": 0
                },
                {
                    "sent": "We do use this back.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "There's another fact that.",
                    "label": 0
                },
                {
                    "sent": "So, so we're going to.",
                    "label": 0
                },
                {
                    "sent": "We're going to build a stereo vision algorithm and our stereo vision algorithm is going to divide the image into segments, sometimes called super pixels.",
                    "label": 0
                },
                {
                    "sent": "And in each segment, we're going to assume that the object in that segment is actually a plane.",
                    "label": 0
                },
                {
                    "sent": "Each segment is going to be modeled as a plane.",
                    "label": 1
                },
                {
                    "sent": "And you can prove it's very easy to show that if you have a plane in three space in a projective camera, that disparity in pixels between the two images.",
                    "label": 0
                },
                {
                    "sent": "The disparity map is linear, is a linear function of the image coordinates.",
                    "label": 0
                },
                {
                    "sent": "So the disparity this first equation.",
                    "label": 0
                },
                {
                    "sent": "Here, the disparity is a function of image coordinates.",
                    "label": 1
                },
                {
                    "sent": "X&Y is some base based disparity at the at the origin of the coordinate system, plus a linear combination of X&Y.",
                    "label": 0
                },
                {
                    "sent": "So we call this a disparity plain, and that's what we're going to be.",
                    "label": 0
                },
                {
                    "sent": "We are our latent information, so in our in our Markov random field we have a set of super pixels, a set of segments.",
                    "label": 0
                },
                {
                    "sent": "The latent variable in each segment is going to be one of these disparity planes, so we're trying to predict D0A and B at every super pixel, and we and by by some geometry we get this equation at the bottom, which says that this is for the B coefficient.",
                    "label": 0
                },
                {
                    "sent": "There's this relationship between the disparity plane coefficient and the depth and the tangent of the angle that the plane makes with the camera Ray.",
                    "label": 0
                },
                {
                    "sent": "I don't want to go through.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I I'm naturally interested in learning, so I want to just going to say there are there is this energy function.",
                    "label": 0
                },
                {
                    "sent": "We did do a domain analysis to define the form of the energy function.",
                    "label": 0
                },
                {
                    "sent": "Here's the energy function that we're using.",
                    "label": 1
                },
                {
                    "sent": "There's a match energy.",
                    "label": 0
                },
                {
                    "sent": "The other thing we want to do is put in more parameters into our model, so if you remember earlier people had just set five parameters, were interested in machine learning, people were used to training thousands of parameters.",
                    "label": 0
                },
                {
                    "sent": "So if we're going to do monocular image understanding, we really want to train a lot of parameters.",
                    "label": 0
                },
                {
                    "sent": "So one thing we do it was enrich the match energy to have more parameters.",
                    "label": 0
                },
                {
                    "sent": "So we essentially introduce a wait.",
                    "label": 0
                },
                {
                    "sent": "We have a feature vector at every pixel, and we introduce a wait for every feature in the feature vector, every pixel and define our match energy in terms of.",
                    "label": 0
                },
                {
                    "sent": "The weights with a different weight for every feature at every pixel, so that's a match energy.",
                    "label": 0
                },
                {
                    "sent": "It's saying here Petapixel P and the Pixel P plus disparity at P are the two corresponding pixels from the two images.",
                    "label": 0
                },
                {
                    "sent": "And we're looking at the difference in their feature vectors and taking the square of that to be a match energy.",
                    "label": 0
                },
                {
                    "sent": "We have a smoothness energy which is just which is just the total.",
                    "label": 0
                },
                {
                    "sent": "It's a total variation energy on the on the depth map.",
                    "label": 0
                },
                {
                    "sent": "And OK, so the first 2 energies are very similar to the classical model.",
                    "label": 0
                },
                {
                    "sent": "They define a smoothness on the depth map and they define a match energy between the two images.",
                    "label": 1
                },
                {
                    "sent": "But there's no monocular depth prediction, right.",
                    "label": 0
                },
                {
                    "sent": "Monocular depth prediction would be an energy on just one image, and the depth map.",
                    "label": 0
                },
                {
                    "sent": "Right, so it would allow us in principle to predict the depth map from a single image, so the last term is an energy that's a monocular depth cue energy.",
                    "label": 0
                },
                {
                    "sent": "It's an energy defined just on.",
                    "label": 0
                },
                {
                    "sent": "Just on one image just on the X image and the depth map.",
                    "label": 0
                },
                {
                    "sent": "And basically it says if you look at the last equation, there's sort of two parts of the corresponding to the two directions X&Y direction, which corresponds to the a coefficient and the B coefficient of the disparity plane.",
                    "label": 0
                },
                {
                    "sent": "And what we do is we're saying we're going to predict, say, the a coefficient look at the top part of the third line.",
                    "label": 0
                },
                {
                    "sent": "We're going to try to predict the a coefficient from the hog feature.",
                    "label": 0
                },
                {
                    "sent": "Today we use the hog feature to estimate the angle.",
                    "label": 0
                },
                {
                    "sent": "Between the camera Ray and the plane normal, and we're just going to completely naively by having a parameter vector beta a inner product.",
                    "label": 0
                },
                {
                    "sent": "The hog feature vector, and then we're going to multiply that by the disparity value, because our analysis said that was the right predictor of the a coefficient, and then we're going to take the difference between that and the a coefficient squared, and that's going to define this energy which is measuring how much our disparity map.",
                    "label": 0
                },
                {
                    "sent": "Is in violation of the predictions made by the predictions you would expect if the hog feature was predicted by the plane shape.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So this is the inevitable results table.",
                    "label": 0
                },
                {
                    "sent": "The top this is 2 measures of the accuracy of this algorithm, so I'm skipping over all the problems of training this model.",
                    "label": 0
                },
                {
                    "sent": "I'm going to describe that next, but if you just sort of accept that we have this model, we have this energy.",
                    "label": 0
                },
                {
                    "sent": "We have some way of training it and I'm just skipping to the results.",
                    "label": 0
                },
                {
                    "sent": "And the second column is a measure of the difference between the estimated depth map and the true depth map.",
                    "label": 0
                },
                {
                    "sent": "This database that we're using.",
                    "label": 0
                },
                {
                    "sent": "Is a database of stereo pairs together with laser range Finder, ground truth depth.",
                    "label": 0
                },
                {
                    "sent": "So we're able to and in this data.",
                    "label": 0
                },
                {
                    "sent": "So so this hog feature is actually a pretty weak.",
                    "label": 0
                },
                {
                    "sent": "Shape feature So what we're doing here is we're taking a stereo algorithm and augmenting it with.",
                    "label": 0
                },
                {
                    "sent": "The hog shape from texture.",
                    "label": 0
                },
                {
                    "sent": "Monocular cue.",
                    "label": 0
                },
                {
                    "sent": "So these numbers are for a stereo algorithm and what we're doing is we're looking at the actual error between the estimated depth and the ground truth depth.",
                    "label": 0
                },
                {
                    "sent": "For a system.",
                    "label": 0
                },
                {
                    "sent": "For various for various kinds of systems.",
                    "label": 0
                },
                {
                    "sent": "So in the first line.",
                    "label": 0
                },
                {
                    "sent": "We're not using the texture at all, no texture cues.",
                    "label": 0
                },
                {
                    "sent": "We're training the other parameters.",
                    "label": 0
                },
                {
                    "sent": "The remaining parameters from the stereo pairs alone.",
                    "label": 0
                },
                {
                    "sent": "We're not looking at the ground truth and training, and we get about the same as the best results from saksena at all.",
                    "label": 0
                },
                {
                    "sent": "When we add the texture features again, we're training now, so this is called unsupervised texture.",
                    "label": 0
                },
                {
                    "sent": "We're training just from the stereo pairs.",
                    "label": 0
                },
                {
                    "sent": "So training just from the stereo pairs with monocular depth features, we see an improvement in ground truth depth estimation.",
                    "label": 0
                },
                {
                    "sent": "So that's the sense in which this is an unsupervised.",
                    "label": 0
                },
                {
                    "sent": "Learning algorithm if we actually train from the ground truth rather than just the pairs, we see that that actually improves things with a boost about the same magnitude is the boost we get from the texture features.",
                    "label": 0
                },
                {
                    "sent": "This table has some caveats.",
                    "label": 0
                },
                {
                    "sent": "Succinea at all are using a stronger model where they're explicitly modeling the ground plane were not explicitly modeling ground plane.",
                    "label": 0
                },
                {
                    "sent": "There's nothing in our energy or features that understands the ground plane, but we're only running on about 3/4 of the images they are running on.",
                    "label": 0
                },
                {
                    "sent": "Because our registration algorithm that we need to run our stereo algorithm failed on about 1/4 of the images.",
                    "label": 0
                },
                {
                    "sent": "So we're probably running on a slightly easier image set.",
                    "label": 0
                },
                {
                    "sent": "We need to get that cleaned up.",
                    "label": 0
                },
                {
                    "sent": "I want to pause here and make some sort of philosophical comments.",
                    "label": 0
                },
                {
                    "sent": "I don't know higher level comments.",
                    "label": 0
                },
                {
                    "sent": "The machine learning community loves to think about general machine learning.",
                    "label": 0
                },
                {
                    "sent": "Models methods.",
                    "label": 0
                },
                {
                    "sent": "The vision community loves to see your numbers.",
                    "label": 0
                },
                {
                    "sent": "And there's sort of a tension between getting those numbers and proving interesting theorems.",
                    "label": 0
                },
                {
                    "sent": "You know the people who just interesting theorems.",
                    "label": 0
                },
                {
                    "sent": "You can have a very nice theorem, and then at the end of the paper there you know there's a tendency to find some data set on which they can demonstrate their ideas.",
                    "label": 0
                },
                {
                    "sent": "I thoroughly believe that.",
                    "label": 0
                },
                {
                    "sent": "You have to do both.",
                    "label": 0
                },
                {
                    "sent": "Or at least if you wanted interesting machine learning, you have to, you know you know face the music and actually get numbers that make the application people respect you.",
                    "label": 0
                },
                {
                    "sent": "On benchmarks that they you know are legitimate, reasonable benchmarks.",
                    "label": 0
                },
                {
                    "sent": "That's my personal philosophy, so we've gotten lots of you know, reviews from versions of this paper saying your numbers aren't good enough, and it's painful, but I'm willing to take it and go back and just make the numbers better, because unless you make the numbers better, you don't.",
                    "label": 0
                },
                {
                    "sent": "You're not getting feedback from the case.",
                    "label": 0
                },
                {
                    "sent": "Study about what's actually working.",
                    "label": 0
                },
                {
                    "sent": "And I firmly believe you that that fee.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Back is essential.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "In this.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In this process.",
                    "label": 0
                },
                {
                    "sent": "OK, now I'm about to start the third part of this talk, which is just to talk about, so I skipped over how to train this model.",
                    "label": 0
                },
                {
                    "sent": "Now I'm going to go back and talk about how we train the model, but I'm going to pop up into General General machine learning land so none of the thing I'm going to say from now on really has much to do with computer vision.",
                    "label": 0
                },
                {
                    "sent": "It's just general methods that we can apply to models of this form.",
                    "label": 0
                },
                {
                    "sent": "So we use Hardy am.",
                    "label": 0
                },
                {
                    "sent": "It's not surprising that we use some form of VM given that the thing we're trying to work with is this latent.",
                    "label": 0
                },
                {
                    "sent": "The thing we're trying to predict is some variable that's latent in the data.",
                    "label": 0
                },
                {
                    "sent": "So we use a form of Hardy M and Hardy.",
                    "label": 1
                },
                {
                    "sent": "M is going to is an iterative process.",
                    "label": 0
                },
                {
                    "sent": "It takes, we assume that we have some model.",
                    "label": 0
                },
                {
                    "sent": "We initialize the model somehow and that might involve some domain knowledge and then given that we initialize the model, we got these training points.",
                    "label": 0
                },
                {
                    "sent": "The training points are XY pairs like there are these stereo image pairs and what we do is we go through the stereo pairs and we infer a depth map for each one using our current model and that depth map is going to involve both of these terms.",
                    "label": 0
                },
                {
                    "sent": "Both of these energies it in principle is the is the most likely Z in this model.",
                    "label": 0
                },
                {
                    "sent": "And then we make this approximation where we throw out one of the normalization term that depends on Z.",
                    "label": 0
                },
                {
                    "sent": "It.",
                    "label": 0
                },
                {
                    "sent": "We throw it up.",
                    "label": 0
                },
                {
                    "sent": "What can I say?",
                    "label": 0
                },
                {
                    "sent": "And then so we actually take ZY to be the argmax of the sum of these two energies.",
                    "label": 0
                },
                {
                    "sent": "And then we update the parameters of the two models.",
                    "label": 0
                },
                {
                    "sent": "We have two CRF's, one of which is the latent information.",
                    "label": 0
                },
                {
                    "sent": "The latency given the input.",
                    "label": 0
                },
                {
                    "sent": "That's one CRF that's defined by beta Z, and the other is Y.",
                    "label": 0
                },
                {
                    "sent": "Given X&Z, we update those two, assuming that disease that we infer it in the first step or actual ground truth on those data points.",
                    "label": 0
                },
                {
                    "sent": "So this is a general.",
                    "label": 0
                },
                {
                    "sent": "This is hard YM.",
                    "label": 0
                },
                {
                    "sent": "It's a standard.",
                    "label": 0
                },
                {
                    "sent": "A standard method in machine learning for training models with latent variables.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, now we've got.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "2 problems here.",
                    "label": 0
                },
                {
                    "sent": "2 optimization problems we've got.",
                    "label": 0
                },
                {
                    "sent": "ZI is an argument of a sum of energies, so our inference is an optimization problem and our model parameter update is also an optimization problem.",
                    "label": 0
                },
                {
                    "sent": "So now I'm going to discuss general methods for addressing these two optimization problems and the first one I'm going to consider is the.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Inference problem.",
                    "label": 0
                },
                {
                    "sent": "So that.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So remember, the inference problem is inferring this depth map Z.",
                    "label": 0
                },
                {
                    "sent": "Now in the problem we're dealing with, it's not a depth map.",
                    "label": 0
                },
                {
                    "sent": "We have super pixels, and the thing we need to infer is a plane, a disparity plane, or a plane in space for every super pixel.",
                    "label": 1
                },
                {
                    "sent": "And the problem is that this is a.",
                    "label": 0
                },
                {
                    "sent": "It's a, it's a 3 dimensional continuous latent value at every superpixel because it's a plane, so we've got.",
                    "label": 1
                },
                {
                    "sent": "Amounts to a Markov random field over the latent information Z given the XY pair, and we've got a 3 dimensional continuous latent variable at every super pixel, and I want to find the most likely assignment of playing the superpixel.",
                    "label": 1
                },
                {
                    "sent": "So it's a it's a Max product graphical model inference problem with a 3 dimensional continuous latent variable at every node and we use a loop.",
                    "label": 1
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "BP approach.",
                    "label": 0
                },
                {
                    "sent": "I'm sorry, no, I'm sorry, not a loopy BP approach.",
                    "label": 0
                },
                {
                    "sent": "A particle belief propagation approach and it's really very simple.",
                    "label": 1
                },
                {
                    "sent": "The way it works is we somehow initialize a plane at every super pixel.",
                    "label": 0
                },
                {
                    "sent": "Then, given that we've got a plane at every superpixel, just some guess.",
                    "label": 0
                },
                {
                    "sent": "We go through every superpixel and introduce a whole bunch of other planes with some proposal distribution around the one that we've assigned to that superpixel what we actually uses some Gaussian.",
                    "label": 0
                },
                {
                    "sent": "We take that super pixel and add a bunch of points around it, using it by adding a Gaussian deviation.",
                    "label": 0
                },
                {
                    "sent": "So then we've got to set a finite set of values at every super pixel.",
                    "label": 0
                },
                {
                    "sent": "So that reduces it to a discrete Markov random field.",
                    "label": 0
                },
                {
                    "sent": "A discrete graphical model.",
                    "label": 0
                },
                {
                    "sent": "And we can you can run your favorite Max product inference algorithm for discrete graphical model like we use loopy BP.",
                    "label": 0
                },
                {
                    "sent": "Or you could use TRW.",
                    "label": 0
                },
                {
                    "sent": "How many people have studied loopy BP for?",
                    "label": 0
                },
                {
                    "sent": "OK. That's another thing that machine learning people.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Hopefully we'll have under their belt.",
                    "label": 0
                },
                {
                    "sent": "OK, let me.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Back up again.",
                    "label": 0
                },
                {
                    "sent": "So we have these other optimization problems to work on the, which are the model parameter.",
                    "label": 0
                },
                {
                    "sent": "See update of the model parameters for the two Markov random fields and for that we use this map.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Did that, Jeff Hinton introduced called contrastive Divergent's.",
                    "label": 0
                },
                {
                    "sent": "So what we're going to do is a form of gradient descent.",
                    "label": 0
                },
                {
                    "sent": "We're updating the model parameters.",
                    "label": 0
                },
                {
                    "sent": "It's very common in this whole area to use gradient descent methods for the to train the model parameters, and there are very standard equations for CRF's.",
                    "label": 0
                },
                {
                    "sent": "And for many of these graphical models to express the gradient of your objective function.",
                    "label": 0
                },
                {
                    "sent": "The training algorithm remember is defined by an optimization problem.",
                    "label": 0
                },
                {
                    "sent": "The optimization problem is minimizing this objective function.",
                    "label": 0
                },
                {
                    "sent": "We can express the gradient of the objective function.",
                    "label": 1
                },
                {
                    "sent": "I'm just going to skip over.",
                    "label": 0
                },
                {
                    "sent": "This is going to be way too much, so I'm just going to try to pass over this at a high level.",
                    "label": 0
                },
                {
                    "sent": "You can express the gradient of the objective function.",
                    "label": 0
                },
                {
                    "sent": "As a difference of two terms, one is the gradient of the energy that you're actually have at your training points.",
                    "label": 0
                },
                {
                    "sent": "In this training algorithm, we assume we know the size, so one term is the actual gradient of the actual energy.",
                    "label": 0
                },
                {
                    "sent": "The other term is the average.",
                    "label": 0
                },
                {
                    "sent": "Energy gradient averaged over wise that the predictor would predict weighted.",
                    "label": 0
                },
                {
                    "sent": "So there's an expectation over why drawn from the prediction distribution under the current model.",
                    "label": 0
                },
                {
                    "sent": "So you're looking at your predicting AY.",
                    "label": 0
                },
                {
                    "sent": "According to the prediction distribution and looking at the gradient of the energy of that, why under the parameter model?",
                    "label": 0
                },
                {
                    "sent": "So that much.",
                    "label": 0
                },
                {
                    "sent": "You may or may not have followed, but.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Then there's this contrastive divergent process which I can tell I've lost every how many people have seen contrastive divergent before.",
                    "label": 0
                },
                {
                    "sent": "Three, OK.",
                    "label": 0
                },
                {
                    "sent": "Idea behind trusted divergents let me just say it at a high level.",
                    "label": 0
                },
                {
                    "sent": "Is this second term in the second equation that second term in the second?",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Asian is an expectation over very complicated probability distribution.",
                    "label": 0
                },
                {
                    "sent": "The way you do an expectation were very complicated probability distributions.",
                    "label": 0
                },
                {
                    "sent": "You do MCMC sampling.",
                    "label": 0
                },
                {
                    "sent": "So you do something like a metropolis process.",
                    "label": 0
                },
                {
                    "sent": "You set up a stochastic process whose stationary distribution is the distribution you're interested in.",
                    "label": 0
                },
                {
                    "sent": "You let the process run for awhile.",
                    "label": 0
                },
                {
                    "sent": "Hopefully it's mixing time, and then you, and then you take where it is, and that's a sample.",
                    "label": 0
                },
                {
                    "sent": "And if I can get a bunch of independent samples from that distribution, and I take the average of something that average will approach the expectation.",
                    "label": 0
                },
                {
                    "sent": "So if I'm interested in expectation by using an MCMC process, the sample I can get an estimate of the expectation.",
                    "label": 0
                },
                {
                    "sent": "Now the problem with the MCMC process is it has very high variance.",
                    "label": 0
                },
                {
                    "sent": "The this distribution might be fairly diffuse, so the idea in contrastive divergent's in the in the last line here is rather than.",
                    "label": 0
                },
                {
                    "sent": "Let this process run till it reaches equilibrium.",
                    "label": 0
                },
                {
                    "sent": "We start, we initialize the variable Y that we're going to draw from this distribution.",
                    "label": 0
                },
                {
                    "sent": "To be why I so we start the MCMC process at why I?",
                    "label": 1
                },
                {
                    "sent": "And we run only two steps or one step of the MCMC process, so we're nowhere near the stationary distribution.",
                    "label": 0
                },
                {
                    "sent": "We're very near why I OK and then we just do that and take that instead of that expectation.",
                    "label": 0
                },
                {
                    "sent": "And the amazing thing is that this is a good idea.",
                    "label": 0
                },
                {
                    "sent": "It dramatically reduces the variance because we're always we're guaranteed to be very near why I?",
                    "label": 0
                },
                {
                    "sent": "So there's much less variation.",
                    "label": 0
                },
                {
                    "sent": "And you can prove.",
                    "label": 0
                },
                {
                    "sent": "Let me see.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "On the next slide.",
                    "label": 0
                },
                {
                    "sent": "No, you can prove that.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Yeah, in this in the last line here you can prove that if.",
                    "label": 0
                },
                {
                    "sent": "If the expectation of this so in contrastive divergent, you get some update direction.",
                    "label": 1
                },
                {
                    "sent": "There's some expected update direction if that update direction is integrable into a potential function.",
                    "label": 1
                },
                {
                    "sent": "If there's a potential function such as the update direction, is the gradient of that potential function then.",
                    "label": 1
                },
                {
                    "sent": "Following that gradient and minimizing that potential function is is a consistent estimator of beta.",
                    "label": 0
                },
                {
                    "sent": "And the latest.",
                    "label": 0
                },
                {
                    "sent": "The way to see that is is to assume that the actual why eyes are drawn from some P beta, and if that's true then it's not difficult to see that the update direction is zero when the Y eyes are actually drawn from some P beta, and you're at that P beta, then these two distributions are identical and the update direction is 0.",
                    "label": 0
                },
                {
                    "sent": "So the rest of.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I have a couple slides here which I'm not going to.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Through because I think I've used up enough time that try to argue that contrastive divergent deserves respect.",
                    "label": 0
                },
                {
                    "sent": "Because we had this theorem that said, if there was a potential function then it would be a consistent estimator and it turns out that for natural MCMC processes, for example, for the MCMC process that Standard Lee used with with Markov random fields, you can show that there is a potential function and the contrastive divergent's.",
                    "label": 0
                },
                {
                    "sent": "Well, let me just say it for the standard MCMC process for Markov random fields, contrastive divergent's corresponds to maximizing pseudo likelihood.",
                    "label": 0
                },
                {
                    "sent": "Which is a standard well known method.",
                    "label": 1
                },
                {
                    "sent": "You can also show that for a standard metropolis process.",
                    "label": 1
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Over a continuous configuration space, if you take a certain differential limit to get a differential stochastic equation, you get another.",
                    "label": 0
                },
                {
                    "sent": "You can prove you get another potential function, and again you get a basically a consistent estimator.",
                    "label": 0
                },
                {
                    "sent": "So there are cases where you can prove that these potential functions exist and you've got consistent estimators, and when this is typically used, it's typically used in ways where you don't have these theorems, but the fact that you these theorems are true sometimes suggests that this is a good method.",
                    "label": 0
                },
                {
                    "sent": "But it might work.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In general, the fact that it's consistent, however, does not necessarily imply that it's a good thing.",
                    "label": 0
                },
                {
                    "sent": "In the case when your data is not drawn from a model in your class.",
                    "label": 1
                },
                {
                    "sent": "Different potential functions will give different estimates.",
                    "label": 0
                },
                {
                    "sent": "Even if they're consistent in the case.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Where the data is drawn from your model class.",
                    "label": 0
                },
                {
                    "sent": "OK, I'm going to stop here.",
                    "label": 0
                },
                {
                    "sent": "So the take home message is that we've we formulated this notion of indirect CRF training, where we want to learn a model, a conditional random field of Z given X from training data from training data XY that don't contain Z, right where we're going to be have a latent model for Z that's predicting Y given X&Z, and we're interested in the conditional random field that predicts Z where it's not in the training data.",
                    "label": 1
                },
                {
                    "sent": "And we've demonstrated this idea on conditional random fields for monocular depth cues.",
                    "label": 1
                },
                {
                    "sent": "In the abstract for this talk, I said I was going to say something about shape from shading and that's it was a classical example of this is going to work before the talk and we experimented with shape from shading and in our initial experiments we did not get much of a boost shape, but its shape from shading is a great area.",
                    "label": 0
                },
                {
                    "sent": "In which two I believe we will get there, we will get a boot.",
                    "label": 0
                },
                {
                    "sent": "We will be able to train shape from shading models, but we have not gotten any numerical benefit from it yet.",
                    "label": 1
                },
                {
                    "sent": "OK, I'll stop there and take questions.",
                    "label": 0
                },
                {
                    "sent": "What is the difference between conditional diner radio?",
                    "label": 0
                },
                {
                    "sent": "Those are great conversions, conditional random fields and what learning Bayesian learning.",
                    "label": 0
                },
                {
                    "sent": "Bing.",
                    "label": 0
                },
                {
                    "sent": "Well, in in the conditional random fields.",
                    "label": 0
                },
                {
                    "sent": "We're not let me go all the way.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Back here.",
                    "label": 0
                },
                {
                    "sent": "So this is the training equation on the bottom and you can interpret the regularization on beta that quadratic regularization on beta as a prior probability over the model parameters.",
                    "label": 0
                },
                {
                    "sent": "It's like a Gaussian prior over the model parameters.",
                    "label": 0
                },
                {
                    "sent": "So you can interpret this as a.",
                    "label": 0
                },
                {
                    "sent": "As a map estimate of beta, real Bayesian would want to average over beta.",
                    "label": 0
                },
                {
                    "sent": "There'd be a prior on beta.",
                    "label": 0
                },
                {
                    "sent": "There'd be a posterior on beta and you'd want to average.",
                    "label": 0
                },
                {
                    "sent": "You'd want your prediction to be an average over beta, weighted by the posterior.",
                    "label": 0
                },
                {
                    "sent": "So one difference is that we're taking a map estimate.",
                    "label": 0
                },
                {
                    "sent": "Personally, I'm not a Bayesian, so I would be more interested in analyzing this learning algorithm from a frequentist perspective.",
                    "label": 0
                },
                {
                    "sent": "It's asking what guarantees could I give for this?",
                    "label": 0
                },
                {
                    "sent": "Independent of the assumption that the prior on beta is true and you can give those kinds of theorems.",
                    "label": 0
                },
                {
                    "sent": "Some sort of frequentist guarantees?",
                    "label": 0
                },
                {
                    "sent": "About the performance of a model trained this way.",
                    "label": 0
                },
                {
                    "sent": "So Q year contrastive divergent is kind of a subroutine in your PM algorithm, right?",
                    "label": 0
                },
                {
                    "sent": "Step is only going to be approximate.",
                    "label": 0
                },
                {
                    "sent": "It's a Hardy step.",
                    "label": 0
                },
                {
                    "sent": "So why the consistency results just for this animal sovereignty?",
                    "label": 0
                },
                {
                    "sent": "That",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Consistency results.",
                    "label": 0
                },
                {
                    "sent": "Only remotely related to what you actually do when you use it, so the consistency results say that if I were to compute that expectation exactly right, if I were to do take enough samples that I got exactly sort of infinite number of samples, and then I followed that gradient at some learning rate that went to zero.",
                    "label": 0
                },
                {
                    "sent": "Then I would converge on the actual beta.",
                    "label": 0
                },
                {
                    "sent": "This done the fact that only approximately step was not a problem.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Well, it's hard to know.",
                    "label": 0
                },
                {
                    "sent": "We don't know what a you know.",
                    "label": 0
                },
                {
                    "sent": "A more faithful approach would would do.",
                    "label": 0
                },
                {
                    "sent": "Right and Ari step is only approximate, so that that's another reason the theorem doesn't wouldn't apply, right?",
                    "label": 0
                },
                {
                    "sent": "Thanks very much.",
                    "label": 0
                }
            ]
        }
    }
}