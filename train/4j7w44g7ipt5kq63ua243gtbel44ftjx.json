{
    "id": "4j7w44g7ipt5kq63ua243gtbel44ftjx",
    "title": "Numerical exploration-exploitation trade-off for large-scale function optimization",
    "info": {
        "author": [
            "R\u00e9mi Munos, SequeL lab, INRIA Lille - Nord Europe"
        ],
        "published": "Nov. 7, 2013",
        "recorded": "September 2013",
        "category": [
            "Top->Computer Science->Decision Support",
            "Top->Computer Science->Machine Learning->On-line Learning"
        ]
    },
    "url": "http://videolectures.net/lsoldm2013_munos_function_optimization/",
    "segmentation": [
        [
            "Oh, good morning everybody.",
            "So.",
            "I would like."
        ],
        [
            "To start this talk by giving you my initial motivation for being interested in it in this work, and this actually happened when I attended a talk by Amy Chrome who was presenting is A is work on a Monte Carlo go annual describing hold the so called Monte Carlo approach in computer goal improved a lot D. Evaluations of the current of the goal positions and made some progress in the quality of the computer go programs.",
            "And so he was describing all this worked in order to estimate the value of a goal configuration.",
            "So you start from this configuration and then you play what they called play out or rollouts which is just write stories where you Alternatively.",
            "Put stones black and white until you reach a terminal position of the game.",
            "Then you see who won you give a score to this time in all position and then you repeat many times.",
            "Then you take the average of those cores and you assign this value to this configuration.",
            "So maybe surprising that actually the value of this game which is the solution to a min Max.",
            "Problem can be approximated actually by an average and so it was saying that actually instead of doing pure random with a uniform.",
            "With uniform distribution assigned to all possible moves, it was saying maybe we can start with a uniform distribution, but then according to the rewards or the games that were that were played, maybe we should advise or sampling in order to put more weights on moves that yell good games.",
            "So if we see for example at the root level, let's say at the beginning, we assign over samples uniformly over all possible immediate States and then based on the actual outcomes of the games.",
            "Say for example if we win this, those games starting from this move nine times out of 10, whereas the other has lower score, then it makes sense to.",
            "Uh, allocate more resources.",
            "More samples in the next runs to this branch because it seems to be more interesting to explore.",
            "And this as the effect of actually deepening the search into some.",
            "Promising directions, so I want to attend this talk.",
            "Well, I immediately thought that actually what was going on here is that you wanted to implement a bandit algorithm, so at each node of the tree, because if you look at the root node, for example at the beginning, it starts with a uniform exploration of the possible actions and then with time as a function of the feedback in gets, then we will spend more and more time.",
            "To explore what seems to be the best action.",
            "So if you do that at the root node and then all the resulting nodes, you will would like to actually implement a bandit algorithm at each node of history."
        ],
        [
            "So the simplest bandit algorithm that was available in the market was a so called UCB algorithm where you see stands for upper confidence bound.",
            "It's been designed by Peter Hour Nicholas at Yankee and Paul Fisher in 2002 and the idea of this UCB algorithm is to assign AB value to all possible actions and the value is a sum of the empirical rewards observed when you play an arm plus some confidence interval.",
            "It depends basically on the number of times you've played this on, and so if you apply this UCB in your Akiko in well in a year key.",
            "So you assign a UCB algorithm to each node on this tree.",
            "So basically, the way you can generate trajectories or paths in this tree is by following at each node the children know that has the highest value, so you will select the path where basically you optimize you look at.",
            "At each iteration, what is the node children that has the highest value you select it and then you keep going on until the end of the tree so.",
            "So we thought about this at the same time some workwear starting to also come out on the exactly same idea.",
            "Notably the work by Lomaticc, Cistanche, Abbassi Perry.",
            "What they call the UCT algorithm, where UCT means UCB applied to trees."
        ],
        [
            "So we started using this UCT algorithm and design on program and it happened that it was quite successful and this type of approach led to improvement in the performance of the computer go programs at that time.",
            "So it was also a success in the sense that not only this Monte Carlo tree search and more precisely this city algorithm.",
            "Where made the progress in this game, but also it was used in other games as well an in order optimization and planning problems.",
            "So it seems that it was a 6 number equal success.",
            "However, it turned out that."
        ],
        [
            "In some problems.",
            "The algorithm fails miserably.",
            "And actually, we can prove that there is no like finite time analysis for this time for this kind of algorithms, and so we can build examples of trees where actually the algorithm is going to be misled and it's going to take a long long time before finding the optimal branch.",
            "So let me illustrate this problem.",
            "On this tree, where basically what happens is that.",
            "Whenever you take the left action.",
            "Well, the rewards are better than when you take right actions.",
            "Until you well and the problem is that the optimal.",
            "Pass is hidden in the area where the rewards are very low, so as long as you haven't found this optimal branch, then less branches seems to be better than right ones.",
            "The problem is that the optimal branches part of those right branches and so.",
            "So if we, if you're familiar with the UCB algorithm, you know that you know out of North samples, it assigns only log samples to the bad arms to the suboptimal arms.",
            "And spends the rest of the samples to the optimal arm.",
            "So what it means is that as long as this optimal branch has not been discovered, then out of N samples that are available, you will assign only Logan samples there.",
            "Because this branch seems to be inferior to this one.",
            "But out of Logan samples assigned here, there is only log log N samples assigned there and so on.",
            "So you see that the time is it time it will take him too.",
            "Actually find the optimal branch is going to be a function which is exponential of exponential D times.",
            "OK, so this is really catastrophic because Wendy's larger than four or five this is just infinite.",
            "So actually this problem illustrates the fact that.",
            "Having a clever algorithm like UCT can be very bad in some problems, in the sense that it's quite hard to, or it's probably impossible to find an algorithm that will be good on all problems.",
            "And so, starting from this observation, we thought that well, of course maybe we cannot find an algorithm that will be good everywhere, But let's try to define classes of problems so that some algorithm will be able to solve functions in that class of problems and characterize this class.",
            "The complexity of this class of problems.",
            "So here you see that the problem is that this function is really unsmooth because.",
            "Very close to the optimal path, there is one which is very bad.",
            "So if you look at the neighborhood of the optimal path you see that there is a very poor pass an.",
            "Of course, this algorithm is extremely bad for an algorithm like UCT because it's misleading at all levels, so it's going to spend a lot of time going there.",
            "An out of these samples, you will spend a lot of time going there, and so on and so on.",
            "An one of the reason if you think a little bit about the mathematics why this actually happens is that you city doesn't build values the B values assigned by use it."
        ],
        [
            "We do not represent actually upper confidence bounds.",
            "High protein UCB is that the reason is that also this works well in a regular bandit algorithm where the rewards are assumed to be IID drawn from some fixed distributions.",
            "Here, the rewards obtained by crossing the node I depends on all the algorithm all the way the actually the rewards are going to be selected by successive.",
            "Bandits and so.",
            "The rewards obtained at a node I.",
            "When you choose one action or no more, I know more independent and no more drawn from unique distribution.",
            "So those be values have actually no reason to represent an upper bound on the true value of the nodes.",
            "So we want to fix that.",
            "OK, so that's I wanted the motivation for this work, and So what we're going to do know is, well, follow this.",
            "So called optimism in the face of uncertainty, principles, principle, and, more precisely, we're going to try to solve well what I call in miracle exploration exploitation tradeoff, which is basically a search in simulation under the constraint that the quantity of resources that we want to use is finite.",
            "So this is a reference to the usual exploration exploitation tradeoff in bandits.",
            "Where you have an unknown environment that you are exploring so you spend time exploring the unknown parameters of your environment and then so that's exploration and then you do exploitation.",
            "So according to your current belief or current knowledge of the environment, then you try to optimize whatever criterion you want to optimize.",
            "So in a regular exploration exploitation tradeoff, you have a cost of exploring suboptimal actions cause your measure of performance is, for example, the cumulative, the sum of rewards you get, whereas in this scenario you actually don't suffer any cost by exploring suboptimal actions because everything is done in simulation.",
            "The only thing you care about is after a given amount of resources where you can explore.",
            "Freely your search space you should return a recommendation of what you think is the best solution."
        ],
        [
            "So I'm going to follow these optimism in the face of uncertainty.",
            "Animum cool.",
            "Now apply it to the simple problem or function optimization so our goal is to find the optimum of a function given a finite numerical budget.",
            "So I will start by very simple illustration of this principle.",
            "When the function is deterministic, Ann is also Lipson.",
            "And starting from this example, I will build on more sophisticated.",
            "Techniques by considering four extensions.",
            "The first is by extending by weakening the assumption on the function.",
            "The second is by designing some tractable algorithm.",
            "The third extension will be to extend this type of algorithm when the smoothness of the function may not be known.",
            "And the last extension would be to the case of stochastic evaluations of the function."
        ],
        [
            "So let me start with the problem of optimizing function assumed to be Lipschitz, so we have a metric space and the metric is written L and we just assume that the function is Lipschitz with respect to this metric, and so the protocol is as follows for end time steps we select the state we observe the value and we repeat.",
            "So this end times.",
            "And at the end, the algorithm should return the state FN and the algorithm is evaluated on the on the loss.",
            "So the value of F at the return point compared to the optimum of F on the domain.",
            "So let me know straight."
        ],
        [
            "This.",
            "On this picture.",
            "So let's say we have a 1 dimensional function F. If a time T, we evaluate the function.",
            "At this point we observe F of XT.",
            "Then we can build a function.",
            "Like piecewise linear this V function.",
            "We whose slope is defined by the metric by the metric L. So basically by the Lipschitz constant and so.",
            "And we have the properties that actually F cannot be above.",
            "This this function let's just because we know that the function is Lipschitz, so its slope cannot be higher than the slope of this function.",
            "And since the value of F at this point was there, so basically we can deduce that this V function is an upper bounding function of V. Of F sorry.",
            "So what happens?"
        ],
        [
            "So if we observe or function at a second point so.",
            "We can actually take the minimum of those two V functions and define this W function, which is also an upper bound on F and it's a refinable.",
            "We can keep."
        ],
        [
            "Doing this when adding more points and so after a few evaluations of the function, we can plot this upper bounding function.",
            "And it's also still an upper bounding and upper bound on the function everywhere.",
            "And so if we apply the optimistic principle, which consists in selecting the States, has the possibility of being the best.",
            "So then we will select the point that has the highest upper bound.",
            "So in the next round, the optimistic strategy will consist in sampling the function at this point and we will get will observe the true value of the function there, and we refine the bound and so on, yes.",
            "Sorry.",
            "That's only bounded interval, yes, let's assume that we are an abundant interval so far.",
            "So we can call this strategy optimism in the face of uncertainty.",
            "But then certainty doesn't come from the fact that the environment is stochastic because everything is domestic here.",
            "So we can call it partial observation and certainty is just uncertainty in the sensor.",
            "Regular sense of the word.",
            "So what happens is that the function is defined in the continuous space, and since we have a finite number of observations, then we can.",
            "Build this upper confidence bound based on those observations, an or knowledge of the smoothness of the function.",
            "And it's actually this strategies is quite nice and we will provide some bounds for this.",
            "For this strategy.",
            "So."
        ],
        [
            "That was the illustration of the idea, but no, of course we want to extend this to more.",
            "Interesting settings, and so we're going to consider four extensions.",
            "First, we're going to extend these two functions that do not satisfy Lipschitz assumption everywhere, because Lipschitz assigned assumption assumption is too strong is way too strong.",
            "And maybe it's not needed.",
            "OK, so we're going to try to define another assumption, which is much weaker than this Lipschitz assumption, and still allows us to do the same strategy.",
            "So can't we want also to find method that is actually numerically?",
            "Efficient because only."
        ],
        [
            "Well, in one dimension is not such a big problem, but just the way of the computational problem.",
            "Finding the maximum of this upper bounding function may be hard in higher dimensions.",
            "So we want to."
        ],
        [
            "Find a way to represent or upper bounding functions so that this.",
            "Processes problem of finding the place where the upper bound is the highest is just simple.",
            "And then we're going to extend this problem this algorithm to the settings where maybe we don't know perfectly symmetric L. So what happens if we don't know the metric L right now?"
        ],
        [
            "So we heavily rely on the knowledge of this metric in order to be able to.",
            "To compute this upper bounding function if we don't know the metric, then it's quite.",
            "It's another problem.",
            "It seems harder."
        ],
        [
            "And then in the end we will handle the case of.",
            "The case when the functions are not observed exactly, but the observations are perturbed by some noise.",
            "So first issue ought to weekend this Lipschitz."
        ],
        [
            "Assumption.",
            "So we get a weekend it in this way we're going to make an assumption that the function is locally smooth, so we call it local is moves around its maximum with respect to some metric L. So what it means is exactly that.",
            "It means that for all X we require that the function at its maximum minus F of X is bounded by L of XX star.",
            "So it looks a little bit like Lipschitz condition, except that the Lipschitz condition was true for any X&Y.",
            "Whereas here we only required to be true around X star.",
            "And So what it means?",
            "So if you look at the function, so here is an example to illustrate this property.",
            "Here is a function F. Here I plotted.",
            "This picky function is F of X star minus LFXX star.",
            "So what this means is that F is above this week.",
            "Earth effect is larger than F of X star minus a lot of extra so.",
            "So we have the property just says that the function should be above this piggy function, so in particular, as of this property doesn't say anything about the smoothness of the function when you are far from the optimum.",
            "So this this this condition contract constraints a function mainly around the optimum of the function.",
            "It has to be true for all X, but you see, for example, if X is.",
            "Less than this quantity, then this doesn't.",
            "Pose any constraint on the function F. We just need that the function is above this big so it can be anything.",
            "It cannot be below.",
            "It cannot be below this week, but there it can be even discontinuous if we want it doesn't matter, so we don't care about the smoothness of the function where it's far from extra.",
            "And So what I'm saying here is that this condition is the only condition that we need to satisfy in order to apply the previous strategy.",
            "So let."
        ],
        [
            "Ministrat this.",
            "So let's use this function and we say we have evaluated this function at the set of points and we build the upper bounding function as before, and So what you observe is that at some places, for example here, the upper bounding function is actually below the true function, so it's not an upper bounding function on F anymore, but it has a property that it is an upper bound.",
            "On F at extra.",
            "So what we care is only that the upper bounding function is actually above F. At the maximum and why?",
            "Well, that's simply because if we are in the setting where the upper bounding function is below the function at suboptimal areas of state space, that means that's even better than before, because then we're going to.",
            "We're not going to even explore those areas because the upper bounding function is low.",
            "That's exactly what we want to do.",
            "We don't care about exploring the function there, we only care about exploring the function.",
            "Around its maximum.",
            "So that's the assumption that we're going to make in the rest of this talk."
        ],
        [
            "OK, second point is to design an efficient implementation implementation of the algorithm.",
            "So a possible way to do so is to consider a year kickel partitioning of the domain.",
            "So let me explain this.",
            "The idea is to simply well consider a partition of the space into cells an assigned to each cell UCB.",
            "That is going to be constant in each cell.",
            "And the UCB there are confidence bound is going to be defined as the value of the function at one point of the cell plus the diameter of the cell expressed in terms of the metric L. And so because of the smooth, locali smooth properties that we had, well, basically we are the properties that for a cell that contains the optimum next are these upper bound on the cell is going to be above F of X star.",
            "And so implementing the previous algorithm would be OK.",
            "I'll start with the.",
            "Discretization of my of my of my domain I assigned to each cell UCB value of the value, then at its wrong I'm going to select the cell that has the highest value I'm going to split it.",
            "And then evaluate the function at the resulting subsets an and repeat an after NA valuation to the function.",
            "I just return the point that had the highest evaluation, so let me illustrate this function is algorithm.",
            "On small simulation in Dimension 1.",
            "OK so here is my function.",
            "My domain is just 01.",
            "Let's evaluate my function at the center of the cell.",
            "So at the beginning of cell is just the interval 01.",
            "Observe this value.",
            "Then I split the corresponding cell.",
            "Let's say for example, I split it in three.",
            "Boxes, so now I have $2 new boxes to evaluate.",
            "Evaluate the function there and there, and then at each of these at this round I assign AB value to those three cells which do not show up because there are above this window.",
            "But basically this is going to be this seller is going to have that has the highest value, so I'm going to split this cell.",
            "This iteration, so I split it in three.",
            "Next, according to the P values, this cell has to be split.",
            "And then I repeat, so let me do this algorithm filtration so we start or we don't see anything.",
            "OK, so if you I don't know if you see something, those small lines which are apparently not not in the right color, but the number so represents the UCB for each for each for each cell, and so the algorithm is just selecting the sellers as the highest recipe.",
            "So let me run this algorithm for a few iteration.",
            "And So what you see is that is going to be the beginning.",
            "Start with kind of a uniform discretization and then it focus on basically those two areas and the actual maximum of the function is there, so it's going to really refine the discretization around the maximum of the function.",
            "So for this simulation I use Lipschitz constant, so I use this metric Euclidean metric with the Lipschitz with constant concern that somehow is close to the true value of the Lipschitz function of this of this function.",
            "So now let me show you what happens if I change the lipstick Lipschitz constant.",
            "So basically I just change my metric and I take a higher value of the Lipschitz constant.",
            "So what happens is that because of that?",
            "The algorithm is going to be exploring much more than previously, and it actually at the beginning you will explore almost uniformly.",
            "All the search space you see here at this point discretization is his uniform.",
            "What happens is that actually because the fact that my Lipschitz constant is 2 is another estimation of the true smoothness of my function.",
            "I chose the upper bounds, dominates the true value of the function, and so whenever there is a cell, it has not been split.",
            "It's UCB is very large, so just select this cell and it splits, but eventually the algorithm will focus more and more on the good part of the space.",
            "But So what we see is that it is spending too much time on the initial exploration of space, yes.",
            "Yeah, that's exactly what I was going to do.",
            "That's a very good thing to think.",
            "An what happens is that.",
            "So here I have a list constant that is very small and it's under the true value of the illusion.",
            "So what happens here?",
            "For example, you see this upper bound is below the value of the function, even at the maximum, so that's bad.",
            "So that means that it thinks that the function is below this, so it will not refine the function there anymore, whereas here the upper bound is higher.",
            "So what we see is that after a few iteration converges to a suboptimal solution.",
            "So it will fail to find the global optimum or the function because it focuses too rapidly to low, possibly local maximum.",
            "So we see that this algorithm is really depends heavily on our knowledge of the smoothness of the function.",
            "So let me know provide some analysis for this algorithm.",
            "So."
        ],
        [
            "In I'm going to get a bound on the loss as a function of N, so the loss will decrease to zero in good situations an the speed at which goes to zero will depend on something that we're going to call the near optimality dimension.",
            "And it's a measure of the quantity of near optimal states, so it's the local measure.",
            "It tells you around the global optimum.",
            "Basically a quantity of how many states that are near optimal, and the precise definition is the following.",
            "So for any possible epsilon we look at the set of states.",
            "That are based on optimal.",
            "So it's a subset of the state space, and now we look at how many balls.",
            "Using my metric L, it takes to cover this subset.",
            "And how many balls of size epsilon forgot to say that?",
            "And so if it takes something of order epsilon to the power minus D balls of size epsilon to cover the set of states that are epsilon optimal, then we say that the near optimality dimension of F. Easy.",
            "Yes.",
            "Epsilon is not necessarily convex, yes, right?",
            "And I have something to say.",
            "You should notice that the near optimality dimension of F is a property of not only F but also L metric.",
            "Because you are using elbows to cover set of epsilon optimal state.",
            "Let me list."
        ],
        [
            "This new commodity dimension in some examples.",
            "So the first example, let's assume that the function is.",
            "Piecewise linear around this maximum.",
            "So if you look at the set of epsilon, learn optimal states basically is the set of size folder epsilon.",
            "So it takes a constant number of balls.",
            "Off size epsilon to cover this set.",
            "And so constant is just excellent to the power zero, and so it means that D = 0.",
            "So the near optimality dimension of this function.",
            "Here is zero an.",
            "Notice that here we have used the Euclidean metric.",
            "Now, what happens if the funk?"
        ],
        [
            "And is smoother than previously.",
            "So for example, let's say its function is locally quadratic around its maximum.",
            "Then the set of near optimal states is or Father squared epsilon.",
            "And so how many balls it takes to cover this set?",
            "With balls of size epsilon.",
            "Scores of children is much larger than epsilon, so it takes one over square root epsilon balls of size epsilon to cover this side.",
            "So epsilon to the power minus 1 / 1 / 2 one half, and if that's in dimension one, if we're in space of dimension capital D, so if the ambient dimension is D, then it will take epsilon to the power minus dealer 2 balls of radius epsilon to cover this set, and so the near optimality dimension is capital D / 2.",
            "And here again we have used the Euclidean metric in our computation and we will see that.",
            "The performance.",
            "Deteriorates with the so the lower D the bear.",
            "If it is for the algorithm.",
            "So from that it seems that here we have a near optimality dimension, which is strictly positive, whereas for the previous function we have a near optimality dimension which was equal to 0.",
            "So using this function is harder to optimize than the previous one.",
            "It appears.",
            "You shouldn't believe me.",
            "And it's point.",
            "Well, actually what's your OK?",
            "Who says who thinks that this function is actually harder to solve?",
            "If you're talking about finding out to more just getting your graph, yes, getting my regret bump my last bound.",
            "Yes, that's very good solution.",
            "It's not.",
            "Maybe it's harder to find the point of optimum because the function is smaller.",
            "There is quite more difficult to find, but in terms of loss, probably is not so much different OK?",
            "And I actually true."
        ],
        [
            "And the way to to see that is true is by actually changing the way we look at this function around it's optimum.",
            "So let's say that instead of using the Euclidean metric, we consider another metric.",
            "The metric Euclidean metric squared.",
            "Which is not a metric anymore, it's a semi metric, but all goes everything goes through with a symmetric, then a bowl of size.",
            "Epsilon, using this metric is of size square root epsilon.",
            "Using the Euclidean metric and so now this thing is can be covered by one bowl or a constant number of balls of size epsilon.",
            "Using this metric.",
            "And so again we recover the fact that number of balls doesn't depend on epsilon and so the near optimality dimension is 0.",
            "And so we see that.",
            "The near optimality dimension is really an iteration that the fact that this depends on both the function and the metric.",
            "And what happens is that if we.",
            "Are able to know the behavior of the function around its maximum.",
            "Then maybe we can choose.",
            "The metric accordingly, in order that the near optimality dimension is 0.",
            "So it may not be true for all functions, but we can take a look at class of functions that will satisfy this property."
        ],
        [
            "For example, if you think about this function, so let's define this function so that local behavior here is further.",
            "Like a square root function.",
            "So the set of states no that are epsilon optimal well is a mass epsilon squared and can be covered.",
            "Actually buy this.",
            "New metric.",
            "By a constant number of balls or size epsilon.",
            "So by choosing the metric according to the smoothness of the function, we get the property that the near optimality dimension function with respect to this metric easier.",
            "You can, no, you cannot have.",
            "You can have.",
            "I think you cannot have a negative.",
            "Well, yes, I think you cannot have negative.",
            "Yeah you."
        ],
        [
            "I don't have a negative D because you still assume that the function satisfies this property this property.",
            "Here, if the function doesn't satisfy this property, you can even think a function that will have a you know negativity, but if it is a function satisfies this property."
        ],
        [
            "By defining the near optimal and I mentioned like that your D is always larger or equal to 0."
        ],
        [
            "So generalization of what I've just said is that if the function has behavior around the maximum, which is something like the distance in some metric to the optimum to the power Alpha where Alpha is strictly larger than 0.",
            "Then an if you choose as a metric.",
            "This norm, to borrow some beta.",
            "And so if you know Alpha then you should set beta equal to Alpha and so you match the exact smoothness of the function and so you get a new optimality dimension or zero.",
            "But if you choose a beta that is strictly less than Alpha, for example, if you don't know the true value of Alpha an, maybe you try to estimate it and so the beta that you choose underestimates the true smoothness of the function.",
            "Then as a consequence you have.",
            "Uh, near optimality dimension is going to be strictly positive.",
            "And know if it happens that you overestimate the true smoothness of the function.",
            "Then what happens is that the function is not locally smooth anymore than satisfies the local smoothness assumption with respect to the metric L. So that's exactly what we'll straighten in the simulation.",
            "And we have the right smoothness.",
            "Then we have good algorithm when we over when we underestimate the smoothness then we explore more of the needle and as a consequence our performance is not so good and but the worst case is actually when you overestimate the true smoothness and in that case.",
            "So you don't have this property anymore, and so you may not converge to the global optimum function."
        ],
        [
            "So now the result is as follows.",
            "Let's assume.",
            "Some properties of the diameter of the sales, so I don't want to go this technical, but the idea is that if you look at the diameters of the cells measure in terms of metric.",
            "Basically as a function of the depth, the number of times you split the sales.",
            "Basically the diameter should shrinks, should shrink in an exponential way.",
            "OK.",
            "So that's usually the case when your search space as finite dimension.",
            "So if your search spaces of space of bounded space of finite dimension, then this is the case.",
            "And So what happens when this happens?",
            "Then we have a bound on the loss of this algorithm called do for deterministic optimistic optimization, which is a constant Times 10 to the power minus 1 / D when D is strictly positive.",
            "So you see that the smaller D well the better.",
            "An when D = 0.",
            "Then we have an exponential rate.",
            "So we have gamma.",
            "Gamma is constantly strictly less than one, so we have exponential of minus N times a constant and all the constants can be made explicit here.",
            "So that's why we really want to.",
            "To use a metric such that the function is going to be locally smooth with respect to this metric, Ann has an ear optimality dimension D equal to 0.",
            "But we should be careful because.",
            "If we don't know the true smoothness of the function, then maybe your choice of the metric is is hard.",
            "And of course the choice of the metric is.",
            "The metric is used in the algorithm.",
            "Remember I told you the diameter of the cells was computed using the metrics, so the choice of our metric really impact the algorithm."
        ],
        [
            "OK, so the consequence we see that do heavily depends on our knowledge of the true local smoothness of the function."
        ],
        [
            "So now let's show you OK, so maybe I can illustrate once more here I can use the same function with two different metrics, either the the one that use the fact that the function is globally Lipschitz.",
            "Or the one that use the fact that the function is locally quadratic.",
            "So on the example I've shown you before, if you use a metric like that then we have a new optimized dimensional half.",
            "If you use quite local quatic quadratic property of the function, then D = 0 and so."
        ],
        [
            "What happens, for example, so that the tree resulting for the discretization obtained after a certain number of iterations?",
            "When we consider this metric based on the... property of the function, we see that basically explores more around those three parts.",
            "Then in other parts.",
            "But when we use the."
        ],
        [
            "The other metric.",
            "We see that it can.",
            "Really go much deeper, faster by using the local property of local quadratic property of the function there, and so the quality of the solution is going to be."
        ],
        [
            "Much better and numerically speaking, so after 150 iterations, if you use a Lipschitz metric then that's the quality of your of your approximation of the maximum, but using the quadratic then you are a way better, and both algorithm anyway are better than the uniform discretization.",
            "Distance from the Max Max basically outside on the Y axis is difference between the function and the maximum function and the function the function evaluated at the point returned by the algorithm."
        ],
        [
            "So now we want to move on.",
            "As I say, the algorithm is very sensitive to our knowledge of the smoothness.",
            "So what happens if we don't know the smoothness and the question we want to ask is whether or not it's possible to implement an optimistic principle when this smoothness is unknown so?"
        ],
        [
            "So the idea is to start from an old algorithm.",
            "Which is called direct algorithm.",
            "Which is Lipschitz and Lipschitz optimization algorithm where the Lipschitz constant is unknown?",
            "So what happens if you know the function is Lipschitz but the constant is unknown?",
            "So the idea of the direct algorithm is to expand all nodes such that there exists Lipschitz constant L such that under this this with this Lipschitz constant, this node is highest as the highest UCB.",
            "So let me look straight."
        ],
        [
            "Is on the function here, so again, we don't very see we will do colors, but for this choice of the Lipschitz constant here I've plotted the upper bound computed by the Department function based on this discretization and we see that for this value of L. I mean, this cell has the highest upper bound and so this cell is going to be the one that should be splitted next.",
            "But what have?"
        ],
        [
            "This is that if we choose another Lipschitz constant, then it's actually this cell that has the highest value, and so this one should be some sample splitted next according to our optimistic algorithm.",
            "And so since we don't know the value of L well, we just played simultaneously those two cells.",
            "So that's the idea."
        ],
        [
            "Of the direct algorithm, the problem of directed at.",
            "First, there is no finding time analysis of the loss and also it makes a very strong assumption that the function is globally Lipschitz.",
            "And so we want to extend the same idea, but to any function that is only locally smooth with respect to some metric and true for any possible symmetric L and provide performance bonds."
        ],
        [
            "So the algorithm is called simultaneous optimistic optimization, and the idea is to split several cells simultaneously.",
            "An you're going to split a cell.",
            "Given size only if the value is larger than the values of all the other sales of same size or higher size.",
            "On lower depths.",
            "So that."
        ],
        [
            "Absolute code and administrate.",
            "The algorithm.",
            "So here you do.",
            "Yes, I don't have an upper bound, so I'm going to decide to split a cell on Earth based on the value of the function.",
            "Yes, so I'm not going to use the diameter of the cells because I don't know the metric, so let me illustrate this.",
            "On the previous function.",
            "So at the beginning I split the first sale.",
            "So no, I have three possible sales and I'm going to just split the one which has the highest value.",
            "OK, no next round.",
            "I have two cells of this size.",
            "And so for this size of sales, I decide which node to split.",
            "So this has the highest value.",
            "So I'm going to put this one and now among all those three cells of this size, I'm going to split this one because it has the highest value among these three, and also because it has value that is larger than this one, because if the value there were above this one, I will not split this one.",
            "But here I will split it.",
            "And so at this round will split two cells simultaneously.",
            "So basically I split the cell when its value is not dominated by the value of a cell of same size or lower size.",
            "No same depth or lower depth, same size or higher size.",
            "OK so I can repeat this algorithm so I did this round.",
            "I will split.",
            "This cell because it has.",
            "There is only one remaining cell of this size, so anyway I'm going to split it and then one cell of this size is split and this one of this size is split.",
            "OK, and I can repeat this and after a few iterations you see how the algorithm works.",
            "So basically it's going to spend more time splitting around area where the function is high, but you can also notice that actually the algorithm will eventually split all the cells.",
            "That's because you know the first sale that is not.",
            "The you always beat a cell of lower depth, whatever its value is, and So what happens is that OK, so we gonna split everywhere.",
            "But of course it's going to spend more time splitting around the interesting part of the space so you can see this algorithm as kind of an optimistic algorithm at all different scales at different scales.",
            "So let me just write this algorithm on another function.",
            "So for example, this function, so the function as many peaks the picks are up for square root shape and there are several optimums are close to each other.",
            "And so after a few iterations.",
            "That's the way it doesn't work.",
            "And so.",
            "Let me in straight.",
            "What happens?",
            "If I run the algorithm on.",
            "A function sample of a Brownian motion.",
            "So I choose a function which is a sample of a Brownian motion, and then I fix it.",
            "And I optimize it so it's deterministic function once it's fine.",
            "Well, if you can ever define it.",
            "But so this type of function is quite hard to optimize.",
            "If you were to use a gradient method, for example, but here so well, we don't see the resolution is not very good, but the higher speak is there.",
            "Yeah, you start to see that no, you found the local team 'em and is going to focus there.",
            "OK, so that's that's it's for simulations.",
            "Let me go back.",
            "There.",
            "Sorry.",
            "OK.",
            "I.",
            "5 minutes.",
            "OK, I just want to mention that this of course extend to several other to other dimensions as well.",
            "If you decide to split in a way, for example spit in One Direction and then the other direction and so on."
        ],
        [
            "So the performance of the algorithm is as follows, so the result and we state like this if there exists a metric L such that the function is local is most respect to L. The diameter of the sales decreases exponentially fast, and the near optimality dimension of F with respect to L 0, then the regret of or the loss of this algorithm is going to be almost exponential.",
            "It's a stretch, exponential loss or damage to the power square root, and it's not exponential of anything special of square root N. And you have similar results if the best possible near optimal time dimension is strictly positive, then you have up to log terms.",
            "This loss of 10 to the power minus one of its OK.",
            "So what you see here is that the analysis, since the algorithm doesn't use the metric, this analysis is true for any possible metric, and so you just choose the best possible one and in particular choose the matrix such that D = 0 if it's possible.",
            "Max.",
            "It's a parameter of the algorithm, so you you bound the number of the depth of your tree by a function that is the parameter of the algorithm.",
            "So here you're mounting by square root N, for example.",
            "So the algorithm is depends on some parameter that I didn't describe, which is the maximal depth you allow the algorithm to expand nodes at a certain time.",
            "Yes.",
            "Space cruise breaks.",
            "Does it constancy?",
            "No, actually when the dimension of X grow, so it really depends on the smoothness of the function, so there is no like general rules.",
            "But I mean you can see see's something that depends on not only local properties of the function but global one.",
            "So it could be that C will depend on the dimension of your ambient dimension of your of your problem.",
            "I didn't mention the definition of C, but it was defined in the definition of the the near.",
            "Did I mention also used a constant so number of balls required to?",
            "Yeah, so that's a constant that appears in the definition of the European amateur.",
            "So."
        ],
        [
            "So we see that Sue is almost as good as the DO algorithm, which will be optimally fitted.",
            "Mean that where we would use the optimal smoothness optimal metric, so you can see."
        ],
        [
            "Performance of soup on previous problem is almost as good as this, but better than the do is with a bad metric."
        ],
        [
            "And so yeah, I want to say that actually the case D = 0.",
            "So it means that set of functions for which there exists a metric that fits the smoothness of the function for which the equals zero is quite nontrivial is actually quite general, so we can see that it's all the functions such that locali around their maximum.",
            "They are equivalent to a polynomial like this of other Alpha, where Alpha is strictly larger than 0.",
            "An so because.",
            "Use the function is like that.",
            "Then we will use in the analysis metric you know that have the same shape and we will deduce that for such functions as I regret is also a stretched exponential and this actually extends to the situations where.",
            "We have different orders in different directions and maybe the directions are not even in line with the axis axis of the of the partitioning."
        ],
        [
            "More generally, it's actually the case where you can define a lower envelope, an upper envelope on the function, or around the maximum that have the same shape."
        ],
        [
            "So let me illustrate situations where D = 0.",
            "So we have already seen that for this function using this metric, we know that the D = 0."
        ],
        [
            "For this function, well using this metric.",
            "With square root of Euclidean metric, then again D = 0."
        ],
        [
            "For the Browning move.",
            "We don't really know, so we would like to use this metric.",
            "And it's actually an open question to whether or no or not.",
            "This near optimality dimension is 0 or is strictly positive."
        ],
        [
            "But an example where D is strictly larger than 0 means that there is no metric that will match perfectly the smoothness of the function at the maximum is for example this one, which is a function that oscillates between two curves.",
            "One is of shape of of other square root X and the other one is of quadratic shape.",
            "So because of that there is no better metric than just using the Euclidean metric to the power.",
            "1/2 to fit so that the function is still locali smooth, but then as a consequence the near optimality dimension is going to be strictly positive and we can improve that.",
            "In this situation there is no metric so that the near optimal dimension is strictly less than three half, and so as a consequence the regret of this algorithm is going to still decrease to 0, but at the polyneon at the polynomial rate and to the power minus to serve."
        ],
        [
            "OK, can compare Sue to director.",
            "We have a finite time energy.",
            "This is more general than direct.",
            "Also commented that Sue is a rank based algorithm, so you actually don't need the exact value of the function.",
            "You just need pairwise comparison between the values because the way you decide to split a cell or not is by comparing your value to other values.",
            "So it's called a rank based algorithm."
        ],
        [
            "OK, just in two slides how to handle noise?",
            "What happens now?",
            "If when you observe the function at the point you don't get the exact value but value Pattabhi?",
            "And by his noise so."
        ],
        [
            "What you can do is to do similar to SU, except that instead of choosing the sales according to the values of the function, since you don't know it, what you're going to do that you are going to sample several times.",
            "The cell.",
            "According to the SU algorithm.",
            "An each time you sample a cell, you're going to update its empirical meaner, and the way you're going to apply the SU algorithm is by selecting the cells not based on the values, but based on the Ucb's.",
            "Based on the upper confidence bounds on the values, so you have an empirical mean plus some confidence interval term.",
            "And you're going to apply same Sue algorithm, But using this you see bees and the only the second difference is that you're not going to split a cell each time you sample, and you point there you're going to wait.",
            "You're going to sample several times at least K times.",
            "So if the algorithm splits samples function K times at a given cell, then you will split the cell.",
            "Otherwise you don't split it.",
            "So at this point, this algorithm really looks like you city.",
            "Because you're designing to get one more sample at a given state based on those UCB terms that are very well the same as the one use, use it so it's very similar to use.",
            "It is.",
            "The only difference is is that we apply this at each level of the tree, so several cells can be selected simultaneously, so the same using the same ideas soup.",
            "OK, whereas UCT was not doing that and also a second second difference is that the cell is split only if we have observed in our values, whereas UCT was just putting a cell at each time just open or get a new value."
        ],
        [
            "OK so well, let me just say that the performance of these stochastic version of two, which is called so Sue is that under the same assumptions as before.",
            "Basically the regret and expectations, the loss in expectation is further one over square root N. Which is almost as good as the best known algorithm that require the knowledge of the metric and original function is so.",
            "So, whereas here we actually don't use it, don't use this knowledge in the algorithm."
        ],
        [
            "Maybe I can, I say like 30 seconds more.",
            "Just to say like, OK, I have just list rated these methods on Euclidean spaces.",
            "OK, no this.",
            "I mean there are a lot of metric spaces around in trees, graphs, social networks for example.",
            "Want to maximize the value assigned to a node.",
            "So you can define.",
            "So you need to be able to define some kind of similarity measure for this metric is really notion of similarities.",
            "So in many different problems and so basically in order to be able to apply this type of algorithm you need to.",
            "Well as this kind of measure, this similarity measure between two states or two things that you want to find and you need also some way to partition the space.",
            "We need a way to represent in New York.",
            "Call away your search space and so the main requirement is that this function F that you want to optimize processes some local smoothness property with respect to this metric.",
            "And so either you know the smoothness and then you can directly apply an algorithm and very good performance of, or if you don't know it, then we've seen that in some situations you can do almost as well as if you actually knew this."
        ],
        [
            "So as a conclusion.",
            "This type of approach provides some kind of a multiscale optimistic optimization processor that explores uniformly or Cassie uniform way.",
            "Initially, the search space and then focuses on the most interesting areas, and so this.",
            "It provides a kind of natural transition from global to local search, because once you have identified the global optimum then it will be as efficient as a local search algorithm and we've seen that the performance depends on the smoothness of the function around the maximum man and also the fact that we know this smoothness on it.",
            "Thank you for your attention.",
            "Sorry for the."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Oh, good morning everybody.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "I would like.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "To start this talk by giving you my initial motivation for being interested in it in this work, and this actually happened when I attended a talk by Amy Chrome who was presenting is A is work on a Monte Carlo go annual describing hold the so called Monte Carlo approach in computer goal improved a lot D. Evaluations of the current of the goal positions and made some progress in the quality of the computer go programs.",
                    "label": 0
                },
                {
                    "sent": "And so he was describing all this worked in order to estimate the value of a goal configuration.",
                    "label": 0
                },
                {
                    "sent": "So you start from this configuration and then you play what they called play out or rollouts which is just write stories where you Alternatively.",
                    "label": 0
                },
                {
                    "sent": "Put stones black and white until you reach a terminal position of the game.",
                    "label": 0
                },
                {
                    "sent": "Then you see who won you give a score to this time in all position and then you repeat many times.",
                    "label": 0
                },
                {
                    "sent": "Then you take the average of those cores and you assign this value to this configuration.",
                    "label": 0
                },
                {
                    "sent": "So maybe surprising that actually the value of this game which is the solution to a min Max.",
                    "label": 0
                },
                {
                    "sent": "Problem can be approximated actually by an average and so it was saying that actually instead of doing pure random with a uniform.",
                    "label": 0
                },
                {
                    "sent": "With uniform distribution assigned to all possible moves, it was saying maybe we can start with a uniform distribution, but then according to the rewards or the games that were that were played, maybe we should advise or sampling in order to put more weights on moves that yell good games.",
                    "label": 0
                },
                {
                    "sent": "So if we see for example at the root level, let's say at the beginning, we assign over samples uniformly over all possible immediate States and then based on the actual outcomes of the games.",
                    "label": 0
                },
                {
                    "sent": "Say for example if we win this, those games starting from this move nine times out of 10, whereas the other has lower score, then it makes sense to.",
                    "label": 0
                },
                {
                    "sent": "Uh, allocate more resources.",
                    "label": 0
                },
                {
                    "sent": "More samples in the next runs to this branch because it seems to be more interesting to explore.",
                    "label": 0
                },
                {
                    "sent": "And this as the effect of actually deepening the search into some.",
                    "label": 0
                },
                {
                    "sent": "Promising directions, so I want to attend this talk.",
                    "label": 0
                },
                {
                    "sent": "Well, I immediately thought that actually what was going on here is that you wanted to implement a bandit algorithm, so at each node of the tree, because if you look at the root node, for example at the beginning, it starts with a uniform exploration of the possible actions and then with time as a function of the feedback in gets, then we will spend more and more time.",
                    "label": 1
                },
                {
                    "sent": "To explore what seems to be the best action.",
                    "label": 0
                },
                {
                    "sent": "So if you do that at the root node and then all the resulting nodes, you will would like to actually implement a bandit algorithm at each node of history.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the simplest bandit algorithm that was available in the market was a so called UCB algorithm where you see stands for upper confidence bound.",
                    "label": 1
                },
                {
                    "sent": "It's been designed by Peter Hour Nicholas at Yankee and Paul Fisher in 2002 and the idea of this UCB algorithm is to assign AB value to all possible actions and the value is a sum of the empirical rewards observed when you play an arm plus some confidence interval.",
                    "label": 0
                },
                {
                    "sent": "It depends basically on the number of times you've played this on, and so if you apply this UCB in your Akiko in well in a year key.",
                    "label": 1
                },
                {
                    "sent": "So you assign a UCB algorithm to each node on this tree.",
                    "label": 0
                },
                {
                    "sent": "So basically, the way you can generate trajectories or paths in this tree is by following at each node the children know that has the highest value, so you will select the path where basically you optimize you look at.",
                    "label": 1
                },
                {
                    "sent": "At each iteration, what is the node children that has the highest value you select it and then you keep going on until the end of the tree so.",
                    "label": 0
                },
                {
                    "sent": "So we thought about this at the same time some workwear starting to also come out on the exactly same idea.",
                    "label": 0
                },
                {
                    "sent": "Notably the work by Lomaticc, Cistanche, Abbassi Perry.",
                    "label": 0
                },
                {
                    "sent": "What they call the UCT algorithm, where UCT means UCB applied to trees.",
                    "label": 1
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we started using this UCT algorithm and design on program and it happened that it was quite successful and this type of approach led to improvement in the performance of the computer go programs at that time.",
                    "label": 0
                },
                {
                    "sent": "So it was also a success in the sense that not only this Monte Carlo tree search and more precisely this city algorithm.",
                    "label": 0
                },
                {
                    "sent": "Where made the progress in this game, but also it was used in other games as well an in order optimization and planning problems.",
                    "label": 0
                },
                {
                    "sent": "So it seems that it was a 6 number equal success.",
                    "label": 0
                },
                {
                    "sent": "However, it turned out that.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In some problems.",
                    "label": 0
                },
                {
                    "sent": "The algorithm fails miserably.",
                    "label": 0
                },
                {
                    "sent": "And actually, we can prove that there is no like finite time analysis for this time for this kind of algorithms, and so we can build examples of trees where actually the algorithm is going to be misled and it's going to take a long long time before finding the optimal branch.",
                    "label": 0
                },
                {
                    "sent": "So let me illustrate this problem.",
                    "label": 0
                },
                {
                    "sent": "On this tree, where basically what happens is that.",
                    "label": 0
                },
                {
                    "sent": "Whenever you take the left action.",
                    "label": 1
                },
                {
                    "sent": "Well, the rewards are better than when you take right actions.",
                    "label": 0
                },
                {
                    "sent": "Until you well and the problem is that the optimal.",
                    "label": 0
                },
                {
                    "sent": "Pass is hidden in the area where the rewards are very low, so as long as you haven't found this optimal branch, then less branches seems to be better than right ones.",
                    "label": 1
                },
                {
                    "sent": "The problem is that the optimal branches part of those right branches and so.",
                    "label": 0
                },
                {
                    "sent": "So if we, if you're familiar with the UCB algorithm, you know that you know out of North samples, it assigns only log samples to the bad arms to the suboptimal arms.",
                    "label": 0
                },
                {
                    "sent": "And spends the rest of the samples to the optimal arm.",
                    "label": 0
                },
                {
                    "sent": "So what it means is that as long as this optimal branch has not been discovered, then out of N samples that are available, you will assign only Logan samples there.",
                    "label": 0
                },
                {
                    "sent": "Because this branch seems to be inferior to this one.",
                    "label": 1
                },
                {
                    "sent": "But out of Logan samples assigned here, there is only log log N samples assigned there and so on.",
                    "label": 0
                },
                {
                    "sent": "So you see that the time is it time it will take him too.",
                    "label": 0
                },
                {
                    "sent": "Actually find the optimal branch is going to be a function which is exponential of exponential D times.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is really catastrophic because Wendy's larger than four or five this is just infinite.",
                    "label": 0
                },
                {
                    "sent": "So actually this problem illustrates the fact that.",
                    "label": 0
                },
                {
                    "sent": "Having a clever algorithm like UCT can be very bad in some problems, in the sense that it's quite hard to, or it's probably impossible to find an algorithm that will be good on all problems.",
                    "label": 0
                },
                {
                    "sent": "And so, starting from this observation, we thought that well, of course maybe we cannot find an algorithm that will be good everywhere, But let's try to define classes of problems so that some algorithm will be able to solve functions in that class of problems and characterize this class.",
                    "label": 0
                },
                {
                    "sent": "The complexity of this class of problems.",
                    "label": 0
                },
                {
                    "sent": "So here you see that the problem is that this function is really unsmooth because.",
                    "label": 0
                },
                {
                    "sent": "Very close to the optimal path, there is one which is very bad.",
                    "label": 0
                },
                {
                    "sent": "So if you look at the neighborhood of the optimal path you see that there is a very poor pass an.",
                    "label": 0
                },
                {
                    "sent": "Of course, this algorithm is extremely bad for an algorithm like UCT because it's misleading at all levels, so it's going to spend a lot of time going there.",
                    "label": 0
                },
                {
                    "sent": "An out of these samples, you will spend a lot of time going there, and so on and so on.",
                    "label": 0
                },
                {
                    "sent": "An one of the reason if you think a little bit about the mathematics why this actually happens is that you city doesn't build values the B values assigned by use it.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We do not represent actually upper confidence bounds.",
                    "label": 0
                },
                {
                    "sent": "High protein UCB is that the reason is that also this works well in a regular bandit algorithm where the rewards are assumed to be IID drawn from some fixed distributions.",
                    "label": 0
                },
                {
                    "sent": "Here, the rewards obtained by crossing the node I depends on all the algorithm all the way the actually the rewards are going to be selected by successive.",
                    "label": 0
                },
                {
                    "sent": "Bandits and so.",
                    "label": 0
                },
                {
                    "sent": "The rewards obtained at a node I.",
                    "label": 0
                },
                {
                    "sent": "When you choose one action or no more, I know more independent and no more drawn from unique distribution.",
                    "label": 0
                },
                {
                    "sent": "So those be values have actually no reason to represent an upper bound on the true value of the nodes.",
                    "label": 0
                },
                {
                    "sent": "So we want to fix that.",
                    "label": 0
                },
                {
                    "sent": "OK, so that's I wanted the motivation for this work, and So what we're going to do know is, well, follow this.",
                    "label": 0
                },
                {
                    "sent": "So called optimism in the face of uncertainty, principles, principle, and, more precisely, we're going to try to solve well what I call in miracle exploration exploitation tradeoff, which is basically a search in simulation under the constraint that the quantity of resources that we want to use is finite.",
                    "label": 0
                },
                {
                    "sent": "So this is a reference to the usual exploration exploitation tradeoff in bandits.",
                    "label": 0
                },
                {
                    "sent": "Where you have an unknown environment that you are exploring so you spend time exploring the unknown parameters of your environment and then so that's exploration and then you do exploitation.",
                    "label": 0
                },
                {
                    "sent": "So according to your current belief or current knowledge of the environment, then you try to optimize whatever criterion you want to optimize.",
                    "label": 0
                },
                {
                    "sent": "So in a regular exploration exploitation tradeoff, you have a cost of exploring suboptimal actions cause your measure of performance is, for example, the cumulative, the sum of rewards you get, whereas in this scenario you actually don't suffer any cost by exploring suboptimal actions because everything is done in simulation.",
                    "label": 0
                },
                {
                    "sent": "The only thing you care about is after a given amount of resources where you can explore.",
                    "label": 0
                },
                {
                    "sent": "Freely your search space you should return a recommendation of what you think is the best solution.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So I'm going to follow these optimism in the face of uncertainty.",
                    "label": 1
                },
                {
                    "sent": "Animum cool.",
                    "label": 0
                },
                {
                    "sent": "Now apply it to the simple problem or function optimization so our goal is to find the optimum of a function given a finite numerical budget.",
                    "label": 0
                },
                {
                    "sent": "So I will start by very simple illustration of this principle.",
                    "label": 0
                },
                {
                    "sent": "When the function is deterministic, Ann is also Lipson.",
                    "label": 0
                },
                {
                    "sent": "And starting from this example, I will build on more sophisticated.",
                    "label": 0
                },
                {
                    "sent": "Techniques by considering four extensions.",
                    "label": 0
                },
                {
                    "sent": "The first is by extending by weakening the assumption on the function.",
                    "label": 1
                },
                {
                    "sent": "The second is by designing some tractable algorithm.",
                    "label": 0
                },
                {
                    "sent": "The third extension will be to extend this type of algorithm when the smoothness of the function may not be known.",
                    "label": 0
                },
                {
                    "sent": "And the last extension would be to the case of stochastic evaluations of the function.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So let me start with the problem of optimizing function assumed to be Lipschitz, so we have a metric space and the metric is written L and we just assume that the function is Lipschitz with respect to this metric, and so the protocol is as follows for end time steps we select the state we observe the value and we repeat.",
                    "label": 0
                },
                {
                    "sent": "So this end times.",
                    "label": 0
                },
                {
                    "sent": "And at the end, the algorithm should return the state FN and the algorithm is evaluated on the on the loss.",
                    "label": 0
                },
                {
                    "sent": "So the value of F at the return point compared to the optimum of F on the domain.",
                    "label": 0
                },
                {
                    "sent": "So let me know straight.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This.",
                    "label": 0
                },
                {
                    "sent": "On this picture.",
                    "label": 0
                },
                {
                    "sent": "So let's say we have a 1 dimensional function F. If a time T, we evaluate the function.",
                    "label": 0
                },
                {
                    "sent": "At this point we observe F of XT.",
                    "label": 0
                },
                {
                    "sent": "Then we can build a function.",
                    "label": 0
                },
                {
                    "sent": "Like piecewise linear this V function.",
                    "label": 0
                },
                {
                    "sent": "We whose slope is defined by the metric by the metric L. So basically by the Lipschitz constant and so.",
                    "label": 0
                },
                {
                    "sent": "And we have the properties that actually F cannot be above.",
                    "label": 0
                },
                {
                    "sent": "This this function let's just because we know that the function is Lipschitz, so its slope cannot be higher than the slope of this function.",
                    "label": 0
                },
                {
                    "sent": "And since the value of F at this point was there, so basically we can deduce that this V function is an upper bounding function of V. Of F sorry.",
                    "label": 1
                },
                {
                    "sent": "So what happens?",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So if we observe or function at a second point so.",
                    "label": 0
                },
                {
                    "sent": "We can actually take the minimum of those two V functions and define this W function, which is also an upper bound on F and it's a refinable.",
                    "label": 0
                },
                {
                    "sent": "We can keep.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Doing this when adding more points and so after a few evaluations of the function, we can plot this upper bounding function.",
                    "label": 0
                },
                {
                    "sent": "And it's also still an upper bounding and upper bound on the function everywhere.",
                    "label": 0
                },
                {
                    "sent": "And so if we apply the optimistic principle, which consists in selecting the States, has the possibility of being the best.",
                    "label": 0
                },
                {
                    "sent": "So then we will select the point that has the highest upper bound.",
                    "label": 1
                },
                {
                    "sent": "So in the next round, the optimistic strategy will consist in sampling the function at this point and we will get will observe the true value of the function there, and we refine the bound and so on, yes.",
                    "label": 0
                },
                {
                    "sent": "Sorry.",
                    "label": 0
                },
                {
                    "sent": "That's only bounded interval, yes, let's assume that we are an abundant interval so far.",
                    "label": 0
                },
                {
                    "sent": "So we can call this strategy optimism in the face of uncertainty.",
                    "label": 1
                },
                {
                    "sent": "But then certainty doesn't come from the fact that the environment is stochastic because everything is domestic here.",
                    "label": 0
                },
                {
                    "sent": "So we can call it partial observation and certainty is just uncertainty in the sensor.",
                    "label": 0
                },
                {
                    "sent": "Regular sense of the word.",
                    "label": 0
                },
                {
                    "sent": "So what happens is that the function is defined in the continuous space, and since we have a finite number of observations, then we can.",
                    "label": 0
                },
                {
                    "sent": "Build this upper confidence bound based on those observations, an or knowledge of the smoothness of the function.",
                    "label": 0
                },
                {
                    "sent": "And it's actually this strategies is quite nice and we will provide some bounds for this.",
                    "label": 0
                },
                {
                    "sent": "For this strategy.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "That was the illustration of the idea, but no, of course we want to extend this to more.",
                    "label": 0
                },
                {
                    "sent": "Interesting settings, and so we're going to consider four extensions.",
                    "label": 0
                },
                {
                    "sent": "First, we're going to extend these two functions that do not satisfy Lipschitz assumption everywhere, because Lipschitz assigned assumption assumption is too strong is way too strong.",
                    "label": 1
                },
                {
                    "sent": "And maybe it's not needed.",
                    "label": 0
                },
                {
                    "sent": "OK, so we're going to try to define another assumption, which is much weaker than this Lipschitz assumption, and still allows us to do the same strategy.",
                    "label": 0
                },
                {
                    "sent": "So can't we want also to find method that is actually numerically?",
                    "label": 0
                },
                {
                    "sent": "Efficient because only.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Well, in one dimension is not such a big problem, but just the way of the computational problem.",
                    "label": 0
                },
                {
                    "sent": "Finding the maximum of this upper bounding function may be hard in higher dimensions.",
                    "label": 0
                },
                {
                    "sent": "So we want to.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Find a way to represent or upper bounding functions so that this.",
                    "label": 0
                },
                {
                    "sent": "Processes problem of finding the place where the upper bound is the highest is just simple.",
                    "label": 0
                },
                {
                    "sent": "And then we're going to extend this problem this algorithm to the settings where maybe we don't know perfectly symmetric L. So what happens if we don't know the metric L right now?",
                    "label": 1
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we heavily rely on the knowledge of this metric in order to be able to.",
                    "label": 0
                },
                {
                    "sent": "To compute this upper bounding function if we don't know the metric, then it's quite.",
                    "label": 0
                },
                {
                    "sent": "It's another problem.",
                    "label": 0
                },
                {
                    "sent": "It seems harder.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then in the end we will handle the case of.",
                    "label": 0
                },
                {
                    "sent": "The case when the functions are not observed exactly, but the observations are perturbed by some noise.",
                    "label": 0
                },
                {
                    "sent": "So first issue ought to weekend this Lipschitz.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Assumption.",
                    "label": 0
                },
                {
                    "sent": "So we get a weekend it in this way we're going to make an assumption that the function is locally smooth, so we call it local is moves around its maximum with respect to some metric L. So what it means is exactly that.",
                    "label": 1
                },
                {
                    "sent": "It means that for all X we require that the function at its maximum minus F of X is bounded by L of XX star.",
                    "label": 0
                },
                {
                    "sent": "So it looks a little bit like Lipschitz condition, except that the Lipschitz condition was true for any X&Y.",
                    "label": 0
                },
                {
                    "sent": "Whereas here we only required to be true around X star.",
                    "label": 0
                },
                {
                    "sent": "And So what it means?",
                    "label": 0
                },
                {
                    "sent": "So if you look at the function, so here is an example to illustrate this property.",
                    "label": 0
                },
                {
                    "sent": "Here is a function F. Here I plotted.",
                    "label": 0
                },
                {
                    "sent": "This picky function is F of X star minus LFXX star.",
                    "label": 0
                },
                {
                    "sent": "So what this means is that F is above this week.",
                    "label": 0
                },
                {
                    "sent": "Earth effect is larger than F of X star minus a lot of extra so.",
                    "label": 0
                },
                {
                    "sent": "So we have the property just says that the function should be above this piggy function, so in particular, as of this property doesn't say anything about the smoothness of the function when you are far from the optimum.",
                    "label": 0
                },
                {
                    "sent": "So this this this condition contract constraints a function mainly around the optimum of the function.",
                    "label": 1
                },
                {
                    "sent": "It has to be true for all X, but you see, for example, if X is.",
                    "label": 0
                },
                {
                    "sent": "Less than this quantity, then this doesn't.",
                    "label": 0
                },
                {
                    "sent": "Pose any constraint on the function F. We just need that the function is above this big so it can be anything.",
                    "label": 0
                },
                {
                    "sent": "It cannot be below.",
                    "label": 0
                },
                {
                    "sent": "It cannot be below this week, but there it can be even discontinuous if we want it doesn't matter, so we don't care about the smoothness of the function where it's far from extra.",
                    "label": 0
                },
                {
                    "sent": "And So what I'm saying here is that this condition is the only condition that we need to satisfy in order to apply the previous strategy.",
                    "label": 0
                },
                {
                    "sent": "So let.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Ministrat this.",
                    "label": 0
                },
                {
                    "sent": "So let's use this function and we say we have evaluated this function at the set of points and we build the upper bounding function as before, and So what you observe is that at some places, for example here, the upper bounding function is actually below the true function, so it's not an upper bounding function on F anymore, but it has a property that it is an upper bound.",
                    "label": 0
                },
                {
                    "sent": "On F at extra.",
                    "label": 0
                },
                {
                    "sent": "So what we care is only that the upper bounding function is actually above F. At the maximum and why?",
                    "label": 1
                },
                {
                    "sent": "Well, that's simply because if we are in the setting where the upper bounding function is below the function at suboptimal areas of state space, that means that's even better than before, because then we're going to.",
                    "label": 0
                },
                {
                    "sent": "We're not going to even explore those areas because the upper bounding function is low.",
                    "label": 0
                },
                {
                    "sent": "That's exactly what we want to do.",
                    "label": 0
                },
                {
                    "sent": "We don't care about exploring the function there, we only care about exploring the function.",
                    "label": 0
                },
                {
                    "sent": "Around its maximum.",
                    "label": 0
                },
                {
                    "sent": "So that's the assumption that we're going to make in the rest of this talk.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, second point is to design an efficient implementation implementation of the algorithm.",
                    "label": 1
                },
                {
                    "sent": "So a possible way to do so is to consider a year kickel partitioning of the domain.",
                    "label": 1
                },
                {
                    "sent": "So let me explain this.",
                    "label": 0
                },
                {
                    "sent": "The idea is to simply well consider a partition of the space into cells an assigned to each cell UCB.",
                    "label": 0
                },
                {
                    "sent": "That is going to be constant in each cell.",
                    "label": 0
                },
                {
                    "sent": "And the UCB there are confidence bound is going to be defined as the value of the function at one point of the cell plus the diameter of the cell expressed in terms of the metric L. And so because of the smooth, locali smooth properties that we had, well, basically we are the properties that for a cell that contains the optimum next are these upper bound on the cell is going to be above F of X star.",
                    "label": 0
                },
                {
                    "sent": "And so implementing the previous algorithm would be OK.",
                    "label": 0
                },
                {
                    "sent": "I'll start with the.",
                    "label": 0
                },
                {
                    "sent": "Discretization of my of my of my domain I assigned to each cell UCB value of the value, then at its wrong I'm going to select the cell that has the highest value I'm going to split it.",
                    "label": 1
                },
                {
                    "sent": "And then evaluate the function at the resulting subsets an and repeat an after NA valuation to the function.",
                    "label": 0
                },
                {
                    "sent": "I just return the point that had the highest evaluation, so let me illustrate this function is algorithm.",
                    "label": 0
                },
                {
                    "sent": "On small simulation in Dimension 1.",
                    "label": 0
                },
                {
                    "sent": "OK so here is my function.",
                    "label": 0
                },
                {
                    "sent": "My domain is just 01.",
                    "label": 0
                },
                {
                    "sent": "Let's evaluate my function at the center of the cell.",
                    "label": 0
                },
                {
                    "sent": "So at the beginning of cell is just the interval 01.",
                    "label": 0
                },
                {
                    "sent": "Observe this value.",
                    "label": 0
                },
                {
                    "sent": "Then I split the corresponding cell.",
                    "label": 0
                },
                {
                    "sent": "Let's say for example, I split it in three.",
                    "label": 0
                },
                {
                    "sent": "Boxes, so now I have $2 new boxes to evaluate.",
                    "label": 0
                },
                {
                    "sent": "Evaluate the function there and there, and then at each of these at this round I assign AB value to those three cells which do not show up because there are above this window.",
                    "label": 0
                },
                {
                    "sent": "But basically this is going to be this seller is going to have that has the highest value, so I'm going to split this cell.",
                    "label": 0
                },
                {
                    "sent": "This iteration, so I split it in three.",
                    "label": 1
                },
                {
                    "sent": "Next, according to the P values, this cell has to be split.",
                    "label": 0
                },
                {
                    "sent": "And then I repeat, so let me do this algorithm filtration so we start or we don't see anything.",
                    "label": 0
                },
                {
                    "sent": "OK, so if you I don't know if you see something, those small lines which are apparently not not in the right color, but the number so represents the UCB for each for each for each cell, and so the algorithm is just selecting the sellers as the highest recipe.",
                    "label": 0
                },
                {
                    "sent": "So let me run this algorithm for a few iteration.",
                    "label": 0
                },
                {
                    "sent": "And So what you see is that is going to be the beginning.",
                    "label": 0
                },
                {
                    "sent": "Start with kind of a uniform discretization and then it focus on basically those two areas and the actual maximum of the function is there, so it's going to really refine the discretization around the maximum of the function.",
                    "label": 0
                },
                {
                    "sent": "So for this simulation I use Lipschitz constant, so I use this metric Euclidean metric with the Lipschitz with constant concern that somehow is close to the true value of the Lipschitz function of this of this function.",
                    "label": 0
                },
                {
                    "sent": "So now let me show you what happens if I change the lipstick Lipschitz constant.",
                    "label": 0
                },
                {
                    "sent": "So basically I just change my metric and I take a higher value of the Lipschitz constant.",
                    "label": 0
                },
                {
                    "sent": "So what happens is that because of that?",
                    "label": 0
                },
                {
                    "sent": "The algorithm is going to be exploring much more than previously, and it actually at the beginning you will explore almost uniformly.",
                    "label": 0
                },
                {
                    "sent": "All the search space you see here at this point discretization is his uniform.",
                    "label": 0
                },
                {
                    "sent": "What happens is that actually because the fact that my Lipschitz constant is 2 is another estimation of the true smoothness of my function.",
                    "label": 0
                },
                {
                    "sent": "I chose the upper bounds, dominates the true value of the function, and so whenever there is a cell, it has not been split.",
                    "label": 0
                },
                {
                    "sent": "It's UCB is very large, so just select this cell and it splits, but eventually the algorithm will focus more and more on the good part of the space.",
                    "label": 0
                },
                {
                    "sent": "But So what we see is that it is spending too much time on the initial exploration of space, yes.",
                    "label": 0
                },
                {
                    "sent": "Yeah, that's exactly what I was going to do.",
                    "label": 0
                },
                {
                    "sent": "That's a very good thing to think.",
                    "label": 0
                },
                {
                    "sent": "An what happens is that.",
                    "label": 0
                },
                {
                    "sent": "So here I have a list constant that is very small and it's under the true value of the illusion.",
                    "label": 0
                },
                {
                    "sent": "So what happens here?",
                    "label": 0
                },
                {
                    "sent": "For example, you see this upper bound is below the value of the function, even at the maximum, so that's bad.",
                    "label": 1
                },
                {
                    "sent": "So that means that it thinks that the function is below this, so it will not refine the function there anymore, whereas here the upper bound is higher.",
                    "label": 0
                },
                {
                    "sent": "So what we see is that after a few iteration converges to a suboptimal solution.",
                    "label": 0
                },
                {
                    "sent": "So it will fail to find the global optimum or the function because it focuses too rapidly to low, possibly local maximum.",
                    "label": 0
                },
                {
                    "sent": "So we see that this algorithm is really depends heavily on our knowledge of the smoothness of the function.",
                    "label": 0
                },
                {
                    "sent": "So let me know provide some analysis for this algorithm.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In I'm going to get a bound on the loss as a function of N, so the loss will decrease to zero in good situations an the speed at which goes to zero will depend on something that we're going to call the near optimality dimension.",
                    "label": 0
                },
                {
                    "sent": "And it's a measure of the quantity of near optimal states, so it's the local measure.",
                    "label": 0
                },
                {
                    "sent": "It tells you around the global optimum.",
                    "label": 0
                },
                {
                    "sent": "Basically a quantity of how many states that are near optimal, and the precise definition is the following.",
                    "label": 0
                },
                {
                    "sent": "So for any possible epsilon we look at the set of states.",
                    "label": 0
                },
                {
                    "sent": "That are based on optimal.",
                    "label": 0
                },
                {
                    "sent": "So it's a subset of the state space, and now we look at how many balls.",
                    "label": 0
                },
                {
                    "sent": "Using my metric L, it takes to cover this subset.",
                    "label": 0
                },
                {
                    "sent": "And how many balls of size epsilon forgot to say that?",
                    "label": 0
                },
                {
                    "sent": "And so if it takes something of order epsilon to the power minus D balls of size epsilon to cover the set of states that are epsilon optimal, then we say that the near optimality dimension of F. Easy.",
                    "label": 1
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "Epsilon is not necessarily convex, yes, right?",
                    "label": 0
                },
                {
                    "sent": "And I have something to say.",
                    "label": 0
                },
                {
                    "sent": "You should notice that the near optimality dimension of F is a property of not only F but also L metric.",
                    "label": 0
                },
                {
                    "sent": "Because you are using elbows to cover set of epsilon optimal state.",
                    "label": 0
                },
                {
                    "sent": "Let me list.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This new commodity dimension in some examples.",
                    "label": 0
                },
                {
                    "sent": "So the first example, let's assume that the function is.",
                    "label": 1
                },
                {
                    "sent": "Piecewise linear around this maximum.",
                    "label": 0
                },
                {
                    "sent": "So if you look at the set of epsilon, learn optimal states basically is the set of size folder epsilon.",
                    "label": 0
                },
                {
                    "sent": "So it takes a constant number of balls.",
                    "label": 0
                },
                {
                    "sent": "Off size epsilon to cover this set.",
                    "label": 0
                },
                {
                    "sent": "And so constant is just excellent to the power zero, and so it means that D = 0.",
                    "label": 0
                },
                {
                    "sent": "So the near optimality dimension of this function.",
                    "label": 0
                },
                {
                    "sent": "Here is zero an.",
                    "label": 0
                },
                {
                    "sent": "Notice that here we have used the Euclidean metric.",
                    "label": 0
                },
                {
                    "sent": "Now, what happens if the funk?",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And is smoother than previously.",
                    "label": 0
                },
                {
                    "sent": "So for example, let's say its function is locally quadratic around its maximum.",
                    "label": 1
                },
                {
                    "sent": "Then the set of near optimal states is or Father squared epsilon.",
                    "label": 1
                },
                {
                    "sent": "And so how many balls it takes to cover this set?",
                    "label": 1
                },
                {
                    "sent": "With balls of size epsilon.",
                    "label": 0
                },
                {
                    "sent": "Scores of children is much larger than epsilon, so it takes one over square root epsilon balls of size epsilon to cover this side.",
                    "label": 0
                },
                {
                    "sent": "So epsilon to the power minus 1 / 1 / 2 one half, and if that's in dimension one, if we're in space of dimension capital D, so if the ambient dimension is D, then it will take epsilon to the power minus dealer 2 balls of radius epsilon to cover this set, and so the near optimality dimension is capital D / 2.",
                    "label": 0
                },
                {
                    "sent": "And here again we have used the Euclidean metric in our computation and we will see that.",
                    "label": 0
                },
                {
                    "sent": "The performance.",
                    "label": 0
                },
                {
                    "sent": "Deteriorates with the so the lower D the bear.",
                    "label": 0
                },
                {
                    "sent": "If it is for the algorithm.",
                    "label": 0
                },
                {
                    "sent": "So from that it seems that here we have a near optimality dimension, which is strictly positive, whereas for the previous function we have a near optimality dimension which was equal to 0.",
                    "label": 0
                },
                {
                    "sent": "So using this function is harder to optimize than the previous one.",
                    "label": 0
                },
                {
                    "sent": "It appears.",
                    "label": 0
                },
                {
                    "sent": "You shouldn't believe me.",
                    "label": 0
                },
                {
                    "sent": "And it's point.",
                    "label": 0
                },
                {
                    "sent": "Well, actually what's your OK?",
                    "label": 0
                },
                {
                    "sent": "Who says who thinks that this function is actually harder to solve?",
                    "label": 0
                },
                {
                    "sent": "If you're talking about finding out to more just getting your graph, yes, getting my regret bump my last bound.",
                    "label": 0
                },
                {
                    "sent": "Yes, that's very good solution.",
                    "label": 0
                },
                {
                    "sent": "It's not.",
                    "label": 0
                },
                {
                    "sent": "Maybe it's harder to find the point of optimum because the function is smaller.",
                    "label": 0
                },
                {
                    "sent": "There is quite more difficult to find, but in terms of loss, probably is not so much different OK?",
                    "label": 0
                },
                {
                    "sent": "And I actually true.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And the way to to see that is true is by actually changing the way we look at this function around it's optimum.",
                    "label": 0
                },
                {
                    "sent": "So let's say that instead of using the Euclidean metric, we consider another metric.",
                    "label": 0
                },
                {
                    "sent": "The metric Euclidean metric squared.",
                    "label": 0
                },
                {
                    "sent": "Which is not a metric anymore, it's a semi metric, but all goes everything goes through with a symmetric, then a bowl of size.",
                    "label": 0
                },
                {
                    "sent": "Epsilon, using this metric is of size square root epsilon.",
                    "label": 0
                },
                {
                    "sent": "Using the Euclidean metric and so now this thing is can be covered by one bowl or a constant number of balls of size epsilon.",
                    "label": 0
                },
                {
                    "sent": "Using this metric.",
                    "label": 0
                },
                {
                    "sent": "And so again we recover the fact that number of balls doesn't depend on epsilon and so the near optimality dimension is 0.",
                    "label": 0
                },
                {
                    "sent": "And so we see that.",
                    "label": 0
                },
                {
                    "sent": "The near optimality dimension is really an iteration that the fact that this depends on both the function and the metric.",
                    "label": 0
                },
                {
                    "sent": "And what happens is that if we.",
                    "label": 0
                },
                {
                    "sent": "Are able to know the behavior of the function around its maximum.",
                    "label": 1
                },
                {
                    "sent": "Then maybe we can choose.",
                    "label": 0
                },
                {
                    "sent": "The metric accordingly, in order that the near optimality dimension is 0.",
                    "label": 0
                },
                {
                    "sent": "So it may not be true for all functions, but we can take a look at class of functions that will satisfy this property.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For example, if you think about this function, so let's define this function so that local behavior here is further.",
                    "label": 0
                },
                {
                    "sent": "Like a square root function.",
                    "label": 0
                },
                {
                    "sent": "So the set of states no that are epsilon optimal well is a mass epsilon squared and can be covered.",
                    "label": 0
                },
                {
                    "sent": "Actually buy this.",
                    "label": 0
                },
                {
                    "sent": "New metric.",
                    "label": 0
                },
                {
                    "sent": "By a constant number of balls or size epsilon.",
                    "label": 0
                },
                {
                    "sent": "So by choosing the metric according to the smoothness of the function, we get the property that the near optimality dimension function with respect to this metric easier.",
                    "label": 0
                },
                {
                    "sent": "You can, no, you cannot have.",
                    "label": 0
                },
                {
                    "sent": "You can have.",
                    "label": 0
                },
                {
                    "sent": "I think you cannot have a negative.",
                    "label": 0
                },
                {
                    "sent": "Well, yes, I think you cannot have negative.",
                    "label": 0
                },
                {
                    "sent": "Yeah you.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I don't have a negative D because you still assume that the function satisfies this property this property.",
                    "label": 0
                },
                {
                    "sent": "Here, if the function doesn't satisfy this property, you can even think a function that will have a you know negativity, but if it is a function satisfies this property.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "By defining the near optimal and I mentioned like that your D is always larger or equal to 0.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So generalization of what I've just said is that if the function has behavior around the maximum, which is something like the distance in some metric to the optimum to the power Alpha where Alpha is strictly larger than 0.",
                    "label": 0
                },
                {
                    "sent": "Then an if you choose as a metric.",
                    "label": 0
                },
                {
                    "sent": "This norm, to borrow some beta.",
                    "label": 0
                },
                {
                    "sent": "And so if you know Alpha then you should set beta equal to Alpha and so you match the exact smoothness of the function and so you get a new optimality dimension or zero.",
                    "label": 0
                },
                {
                    "sent": "But if you choose a beta that is strictly less than Alpha, for example, if you don't know the true value of Alpha an, maybe you try to estimate it and so the beta that you choose underestimates the true smoothness of the function.",
                    "label": 0
                },
                {
                    "sent": "Then as a consequence you have.",
                    "label": 0
                },
                {
                    "sent": "Uh, near optimality dimension is going to be strictly positive.",
                    "label": 0
                },
                {
                    "sent": "And know if it happens that you overestimate the true smoothness of the function.",
                    "label": 0
                },
                {
                    "sent": "Then what happens is that the function is not locally smooth anymore than satisfies the local smoothness assumption with respect to the metric L. So that's exactly what we'll straighten in the simulation.",
                    "label": 1
                },
                {
                    "sent": "And we have the right smoothness.",
                    "label": 0
                },
                {
                    "sent": "Then we have good algorithm when we over when we underestimate the smoothness then we explore more of the needle and as a consequence our performance is not so good and but the worst case is actually when you overestimate the true smoothness and in that case.",
                    "label": 0
                },
                {
                    "sent": "So you don't have this property anymore, and so you may not converge to the global optimum function.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So now the result is as follows.",
                    "label": 0
                },
                {
                    "sent": "Let's assume.",
                    "label": 0
                },
                {
                    "sent": "Some properties of the diameter of the sales, so I don't want to go this technical, but the idea is that if you look at the diameters of the cells measure in terms of metric.",
                    "label": 0
                },
                {
                    "sent": "Basically as a function of the depth, the number of times you split the sales.",
                    "label": 0
                },
                {
                    "sent": "Basically the diameter should shrinks, should shrink in an exponential way.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So that's usually the case when your search space as finite dimension.",
                    "label": 0
                },
                {
                    "sent": "So if your search spaces of space of bounded space of finite dimension, then this is the case.",
                    "label": 0
                },
                {
                    "sent": "And So what happens when this happens?",
                    "label": 0
                },
                {
                    "sent": "Then we have a bound on the loss of this algorithm called do for deterministic optimistic optimization, which is a constant Times 10 to the power minus 1 / D when D is strictly positive.",
                    "label": 1
                },
                {
                    "sent": "So you see that the smaller D well the better.",
                    "label": 0
                },
                {
                    "sent": "An when D = 0.",
                    "label": 0
                },
                {
                    "sent": "Then we have an exponential rate.",
                    "label": 0
                },
                {
                    "sent": "So we have gamma.",
                    "label": 0
                },
                {
                    "sent": "Gamma is constantly strictly less than one, so we have exponential of minus N times a constant and all the constants can be made explicit here.",
                    "label": 0
                },
                {
                    "sent": "So that's why we really want to.",
                    "label": 0
                },
                {
                    "sent": "To use a metric such that the function is going to be locally smooth with respect to this metric, Ann has an ear optimality dimension D equal to 0.",
                    "label": 0
                },
                {
                    "sent": "But we should be careful because.",
                    "label": 0
                },
                {
                    "sent": "If we don't know the true smoothness of the function, then maybe your choice of the metric is is hard.",
                    "label": 1
                },
                {
                    "sent": "And of course the choice of the metric is.",
                    "label": 0
                },
                {
                    "sent": "The metric is used in the algorithm.",
                    "label": 0
                },
                {
                    "sent": "Remember I told you the diameter of the cells was computed using the metrics, so the choice of our metric really impact the algorithm.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so the consequence we see that do heavily depends on our knowledge of the true local smoothness of the function.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So now let's show you OK, so maybe I can illustrate once more here I can use the same function with two different metrics, either the the one that use the fact that the function is globally Lipschitz.",
                    "label": 1
                },
                {
                    "sent": "Or the one that use the fact that the function is locally quadratic.",
                    "label": 1
                },
                {
                    "sent": "So on the example I've shown you before, if you use a metric like that then we have a new optimized dimensional half.",
                    "label": 0
                },
                {
                    "sent": "If you use quite local quatic quadratic property of the function, then D = 0 and so.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "What happens, for example, so that the tree resulting for the discretization obtained after a certain number of iterations?",
                    "label": 0
                },
                {
                    "sent": "When we consider this metric based on the... property of the function, we see that basically explores more around those three parts.",
                    "label": 0
                },
                {
                    "sent": "Then in other parts.",
                    "label": 0
                },
                {
                    "sent": "But when we use the.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The other metric.",
                    "label": 0
                },
                {
                    "sent": "We see that it can.",
                    "label": 0
                },
                {
                    "sent": "Really go much deeper, faster by using the local property of local quadratic property of the function there, and so the quality of the solution is going to be.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Much better and numerically speaking, so after 150 iterations, if you use a Lipschitz metric then that's the quality of your of your approximation of the maximum, but using the quadratic then you are a way better, and both algorithm anyway are better than the uniform discretization.",
                    "label": 0
                },
                {
                    "sent": "Distance from the Max Max basically outside on the Y axis is difference between the function and the maximum function and the function the function evaluated at the point returned by the algorithm.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So now we want to move on.",
                    "label": 0
                },
                {
                    "sent": "As I say, the algorithm is very sensitive to our knowledge of the smoothness.",
                    "label": 1
                },
                {
                    "sent": "So what happens if we don't know the smoothness and the question we want to ask is whether or not it's possible to implement an optimistic principle when this smoothness is unknown so?",
                    "label": 1
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the idea is to start from an old algorithm.",
                    "label": 0
                },
                {
                    "sent": "Which is called direct algorithm.",
                    "label": 0
                },
                {
                    "sent": "Which is Lipschitz and Lipschitz optimization algorithm where the Lipschitz constant is unknown?",
                    "label": 1
                },
                {
                    "sent": "So what happens if you know the function is Lipschitz but the constant is unknown?",
                    "label": 0
                },
                {
                    "sent": "So the idea of the direct algorithm is to expand all nodes such that there exists Lipschitz constant L such that under this this with this Lipschitz constant, this node is highest as the highest UCB.",
                    "label": 0
                },
                {
                    "sent": "So let me look straight.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is on the function here, so again, we don't very see we will do colors, but for this choice of the Lipschitz constant here I've plotted the upper bound computed by the Department function based on this discretization and we see that for this value of L. I mean, this cell has the highest upper bound and so this cell is going to be the one that should be splitted next.",
                    "label": 0
                },
                {
                    "sent": "But what have?",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is that if we choose another Lipschitz constant, then it's actually this cell that has the highest value, and so this one should be some sample splitted next according to our optimistic algorithm.",
                    "label": 0
                },
                {
                    "sent": "And so since we don't know the value of L well, we just played simultaneously those two cells.",
                    "label": 0
                },
                {
                    "sent": "So that's the idea.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Of the direct algorithm, the problem of directed at.",
                    "label": 0
                },
                {
                    "sent": "First, there is no finding time analysis of the loss and also it makes a very strong assumption that the function is globally Lipschitz.",
                    "label": 0
                },
                {
                    "sent": "And so we want to extend the same idea, but to any function that is only locally smooth with respect to some metric and true for any possible symmetric L and provide performance bonds.",
                    "label": 1
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the algorithm is called simultaneous optimistic optimization, and the idea is to split several cells simultaneously.",
                    "label": 1
                },
                {
                    "sent": "An you're going to split a cell.",
                    "label": 0
                },
                {
                    "sent": "Given size only if the value is larger than the values of all the other sales of same size or higher size.",
                    "label": 1
                },
                {
                    "sent": "On lower depths.",
                    "label": 0
                },
                {
                    "sent": "So that.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Absolute code and administrate.",
                    "label": 0
                },
                {
                    "sent": "The algorithm.",
                    "label": 0
                },
                {
                    "sent": "So here you do.",
                    "label": 0
                },
                {
                    "sent": "Yes, I don't have an upper bound, so I'm going to decide to split a cell on Earth based on the value of the function.",
                    "label": 0
                },
                {
                    "sent": "Yes, so I'm not going to use the diameter of the cells because I don't know the metric, so let me illustrate this.",
                    "label": 0
                },
                {
                    "sent": "On the previous function.",
                    "label": 0
                },
                {
                    "sent": "So at the beginning I split the first sale.",
                    "label": 0
                },
                {
                    "sent": "So no, I have three possible sales and I'm going to just split the one which has the highest value.",
                    "label": 0
                },
                {
                    "sent": "OK, no next round.",
                    "label": 0
                },
                {
                    "sent": "I have two cells of this size.",
                    "label": 0
                },
                {
                    "sent": "And so for this size of sales, I decide which node to split.",
                    "label": 0
                },
                {
                    "sent": "So this has the highest value.",
                    "label": 0
                },
                {
                    "sent": "So I'm going to put this one and now among all those three cells of this size, I'm going to split this one because it has the highest value among these three, and also because it has value that is larger than this one, because if the value there were above this one, I will not split this one.",
                    "label": 0
                },
                {
                    "sent": "But here I will split it.",
                    "label": 0
                },
                {
                    "sent": "And so at this round will split two cells simultaneously.",
                    "label": 0
                },
                {
                    "sent": "So basically I split the cell when its value is not dominated by the value of a cell of same size or lower size.",
                    "label": 0
                },
                {
                    "sent": "No same depth or lower depth, same size or higher size.",
                    "label": 0
                },
                {
                    "sent": "OK so I can repeat this algorithm so I did this round.",
                    "label": 0
                },
                {
                    "sent": "I will split.",
                    "label": 0
                },
                {
                    "sent": "This cell because it has.",
                    "label": 0
                },
                {
                    "sent": "There is only one remaining cell of this size, so anyway I'm going to split it and then one cell of this size is split and this one of this size is split.",
                    "label": 0
                },
                {
                    "sent": "OK, and I can repeat this and after a few iterations you see how the algorithm works.",
                    "label": 0
                },
                {
                    "sent": "So basically it's going to spend more time splitting around area where the function is high, but you can also notice that actually the algorithm will eventually split all the cells.",
                    "label": 0
                },
                {
                    "sent": "That's because you know the first sale that is not.",
                    "label": 0
                },
                {
                    "sent": "The you always beat a cell of lower depth, whatever its value is, and So what happens is that OK, so we gonna split everywhere.",
                    "label": 0
                },
                {
                    "sent": "But of course it's going to spend more time splitting around the interesting part of the space so you can see this algorithm as kind of an optimistic algorithm at all different scales at different scales.",
                    "label": 0
                },
                {
                    "sent": "So let me just write this algorithm on another function.",
                    "label": 0
                },
                {
                    "sent": "So for example, this function, so the function as many peaks the picks are up for square root shape and there are several optimums are close to each other.",
                    "label": 0
                },
                {
                    "sent": "And so after a few iterations.",
                    "label": 0
                },
                {
                    "sent": "That's the way it doesn't work.",
                    "label": 0
                },
                {
                    "sent": "And so.",
                    "label": 0
                },
                {
                    "sent": "Let me in straight.",
                    "label": 0
                },
                {
                    "sent": "What happens?",
                    "label": 0
                },
                {
                    "sent": "If I run the algorithm on.",
                    "label": 0
                },
                {
                    "sent": "A function sample of a Brownian motion.",
                    "label": 0
                },
                {
                    "sent": "So I choose a function which is a sample of a Brownian motion, and then I fix it.",
                    "label": 0
                },
                {
                    "sent": "And I optimize it so it's deterministic function once it's fine.",
                    "label": 0
                },
                {
                    "sent": "Well, if you can ever define it.",
                    "label": 0
                },
                {
                    "sent": "But so this type of function is quite hard to optimize.",
                    "label": 0
                },
                {
                    "sent": "If you were to use a gradient method, for example, but here so well, we don't see the resolution is not very good, but the higher speak is there.",
                    "label": 0
                },
                {
                    "sent": "Yeah, you start to see that no, you found the local team 'em and is going to focus there.",
                    "label": 0
                },
                {
                    "sent": "OK, so that's that's it's for simulations.",
                    "label": 0
                },
                {
                    "sent": "Let me go back.",
                    "label": 0
                },
                {
                    "sent": "There.",
                    "label": 0
                },
                {
                    "sent": "Sorry.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "I.",
                    "label": 0
                },
                {
                    "sent": "5 minutes.",
                    "label": 0
                },
                {
                    "sent": "OK, I just want to mention that this of course extend to several other to other dimensions as well.",
                    "label": 0
                },
                {
                    "sent": "If you decide to split in a way, for example spit in One Direction and then the other direction and so on.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the performance of the algorithm is as follows, so the result and we state like this if there exists a metric L such that the function is local is most respect to L. The diameter of the sales decreases exponentially fast, and the near optimality dimension of F with respect to L 0, then the regret of or the loss of this algorithm is going to be almost exponential.",
                    "label": 1
                },
                {
                    "sent": "It's a stretch, exponential loss or damage to the power square root, and it's not exponential of anything special of square root N. And you have similar results if the best possible near optimal time dimension is strictly positive, then you have up to log terms.",
                    "label": 0
                },
                {
                    "sent": "This loss of 10 to the power minus one of its OK.",
                    "label": 0
                },
                {
                    "sent": "So what you see here is that the analysis, since the algorithm doesn't use the metric, this analysis is true for any possible metric, and so you just choose the best possible one and in particular choose the matrix such that D = 0 if it's possible.",
                    "label": 0
                },
                {
                    "sent": "Max.",
                    "label": 0
                },
                {
                    "sent": "It's a parameter of the algorithm, so you you bound the number of the depth of your tree by a function that is the parameter of the algorithm.",
                    "label": 0
                },
                {
                    "sent": "So here you're mounting by square root N, for example.",
                    "label": 0
                },
                {
                    "sent": "So the algorithm is depends on some parameter that I didn't describe, which is the maximal depth you allow the algorithm to expand nodes at a certain time.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "Space cruise breaks.",
                    "label": 0
                },
                {
                    "sent": "Does it constancy?",
                    "label": 0
                },
                {
                    "sent": "No, actually when the dimension of X grow, so it really depends on the smoothness of the function, so there is no like general rules.",
                    "label": 0
                },
                {
                    "sent": "But I mean you can see see's something that depends on not only local properties of the function but global one.",
                    "label": 0
                },
                {
                    "sent": "So it could be that C will depend on the dimension of your ambient dimension of your of your problem.",
                    "label": 0
                },
                {
                    "sent": "I didn't mention the definition of C, but it was defined in the definition of the the near.",
                    "label": 0
                },
                {
                    "sent": "Did I mention also used a constant so number of balls required to?",
                    "label": 0
                },
                {
                    "sent": "Yeah, so that's a constant that appears in the definition of the European amateur.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we see that Sue is almost as good as the DO algorithm, which will be optimally fitted.",
                    "label": 0
                },
                {
                    "sent": "Mean that where we would use the optimal smoothness optimal metric, so you can see.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Performance of soup on previous problem is almost as good as this, but better than the do is with a bad metric.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And so yeah, I want to say that actually the case D = 0.",
                    "label": 1
                },
                {
                    "sent": "So it means that set of functions for which there exists a metric that fits the smoothness of the function for which the equals zero is quite nontrivial is actually quite general, so we can see that it's all the functions such that locali around their maximum.",
                    "label": 0
                },
                {
                    "sent": "They are equivalent to a polynomial like this of other Alpha, where Alpha is strictly larger than 0.",
                    "label": 0
                },
                {
                    "sent": "An so because.",
                    "label": 0
                },
                {
                    "sent": "Use the function is like that.",
                    "label": 0
                },
                {
                    "sent": "Then we will use in the analysis metric you know that have the same shape and we will deduce that for such functions as I regret is also a stretched exponential and this actually extends to the situations where.",
                    "label": 1
                },
                {
                    "sent": "We have different orders in different directions and maybe the directions are not even in line with the axis axis of the of the partitioning.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "More generally, it's actually the case where you can define a lower envelope, an upper envelope on the function, or around the maximum that have the same shape.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So let me illustrate situations where D = 0.",
                    "label": 0
                },
                {
                    "sent": "So we have already seen that for this function using this metric, we know that the D = 0.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For this function, well using this metric.",
                    "label": 0
                },
                {
                    "sent": "With square root of Euclidean metric, then again D = 0.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For the Browning move.",
                    "label": 0
                },
                {
                    "sent": "We don't really know, so we would like to use this metric.",
                    "label": 0
                },
                {
                    "sent": "And it's actually an open question to whether or no or not.",
                    "label": 0
                },
                {
                    "sent": "This near optimality dimension is 0 or is strictly positive.",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "But an example where D is strictly larger than 0 means that there is no metric that will match perfectly the smoothness of the function at the maximum is for example this one, which is a function that oscillates between two curves.",
                    "label": 0
                },
                {
                    "sent": "One is of shape of of other square root X and the other one is of quadratic shape.",
                    "label": 1
                },
                {
                    "sent": "So because of that there is no better metric than just using the Euclidean metric to the power.",
                    "label": 0
                },
                {
                    "sent": "1/2 to fit so that the function is still locali smooth, but then as a consequence the near optimality dimension is going to be strictly positive and we can improve that.",
                    "label": 0
                },
                {
                    "sent": "In this situation there is no metric so that the near optimal dimension is strictly less than three half, and so as a consequence the regret of this algorithm is going to still decrease to 0, but at the polyneon at the polynomial rate and to the power minus to serve.",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, can compare Sue to director.",
                    "label": 0
                },
                {
                    "sent": "We have a finite time energy.",
                    "label": 0
                },
                {
                    "sent": "This is more general than direct.",
                    "label": 1
                },
                {
                    "sent": "Also commented that Sue is a rank based algorithm, so you actually don't need the exact value of the function.",
                    "label": 0
                },
                {
                    "sent": "You just need pairwise comparison between the values because the way you decide to split a cell or not is by comparing your value to other values.",
                    "label": 0
                },
                {
                    "sent": "So it's called a rank based algorithm.",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, just in two slides how to handle noise?",
                    "label": 1
                },
                {
                    "sent": "What happens now?",
                    "label": 0
                },
                {
                    "sent": "If when you observe the function at the point you don't get the exact value but value Pattabhi?",
                    "label": 0
                },
                {
                    "sent": "And by his noise so.",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "What you can do is to do similar to SU, except that instead of choosing the sales according to the values of the function, since you don't know it, what you're going to do that you are going to sample several times.",
                    "label": 0
                },
                {
                    "sent": "The cell.",
                    "label": 0
                },
                {
                    "sent": "According to the SU algorithm.",
                    "label": 1
                },
                {
                    "sent": "An each time you sample a cell, you're going to update its empirical meaner, and the way you're going to apply the SU algorithm is by selecting the cells not based on the values, but based on the Ucb's.",
                    "label": 1
                },
                {
                    "sent": "Based on the upper confidence bounds on the values, so you have an empirical mean plus some confidence interval term.",
                    "label": 0
                },
                {
                    "sent": "And you're going to apply same Sue algorithm, But using this you see bees and the only the second difference is that you're not going to split a cell each time you sample, and you point there you're going to wait.",
                    "label": 0
                },
                {
                    "sent": "You're going to sample several times at least K times.",
                    "label": 0
                },
                {
                    "sent": "So if the algorithm splits samples function K times at a given cell, then you will split the cell.",
                    "label": 0
                },
                {
                    "sent": "Otherwise you don't split it.",
                    "label": 1
                },
                {
                    "sent": "So at this point, this algorithm really looks like you city.",
                    "label": 0
                },
                {
                    "sent": "Because you're designing to get one more sample at a given state based on those UCB terms that are very well the same as the one use, use it so it's very similar to use.",
                    "label": 0
                },
                {
                    "sent": "It is.",
                    "label": 0
                },
                {
                    "sent": "The only difference is is that we apply this at each level of the tree, so several cells can be selected simultaneously, so the same using the same ideas soup.",
                    "label": 0
                },
                {
                    "sent": "OK, whereas UCT was not doing that and also a second second difference is that the cell is split only if we have observed in our values, whereas UCT was just putting a cell at each time just open or get a new value.",
                    "label": 1
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK so well, let me just say that the performance of these stochastic version of two, which is called so Sue is that under the same assumptions as before.",
                    "label": 0
                },
                {
                    "sent": "Basically the regret and expectations, the loss in expectation is further one over square root N. Which is almost as good as the best known algorithm that require the knowledge of the metric and original function is so.",
                    "label": 1
                },
                {
                    "sent": "So, whereas here we actually don't use it, don't use this knowledge in the algorithm.",
                    "label": 0
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Maybe I can, I say like 30 seconds more.",
                    "label": 0
                },
                {
                    "sent": "Just to say like, OK, I have just list rated these methods on Euclidean spaces.",
                    "label": 1
                },
                {
                    "sent": "OK, no this.",
                    "label": 0
                },
                {
                    "sent": "I mean there are a lot of metric spaces around in trees, graphs, social networks for example.",
                    "label": 1
                },
                {
                    "sent": "Want to maximize the value assigned to a node.",
                    "label": 0
                },
                {
                    "sent": "So you can define.",
                    "label": 0
                },
                {
                    "sent": "So you need to be able to define some kind of similarity measure for this metric is really notion of similarities.",
                    "label": 0
                },
                {
                    "sent": "So in many different problems and so basically in order to be able to apply this type of algorithm you need to.",
                    "label": 0
                },
                {
                    "sent": "Well as this kind of measure, this similarity measure between two states or two things that you want to find and you need also some way to partition the space.",
                    "label": 0
                },
                {
                    "sent": "We need a way to represent in New York.",
                    "label": 1
                },
                {
                    "sent": "Call away your search space and so the main requirement is that this function F that you want to optimize processes some local smoothness property with respect to this metric.",
                    "label": 0
                },
                {
                    "sent": "And so either you know the smoothness and then you can directly apply an algorithm and very good performance of, or if you don't know it, then we've seen that in some situations you can do almost as well as if you actually knew this.",
                    "label": 0
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So as a conclusion.",
                    "label": 0
                },
                {
                    "sent": "This type of approach provides some kind of a multiscale optimistic optimization processor that explores uniformly or Cassie uniform way.",
                    "label": 0
                },
                {
                    "sent": "Initially, the search space and then focuses on the most interesting areas, and so this.",
                    "label": 1
                },
                {
                    "sent": "It provides a kind of natural transition from global to local search, because once you have identified the global optimum then it will be as efficient as a local search algorithm and we've seen that the performance depends on the smoothness of the function around the maximum man and also the fact that we know this smoothness on it.",
                    "label": 1
                },
                {
                    "sent": "Thank you for your attention.",
                    "label": 0
                },
                {
                    "sent": "Sorry for the.",
                    "label": 0
                }
            ]
        }
    }
}