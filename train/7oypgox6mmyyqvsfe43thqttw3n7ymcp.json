{
    "id": "7oypgox6mmyyqvsfe43thqttw3n7ymcp",
    "title": "Online Relation Alignment for Linked Datasets",
    "info": {
        "author": [
            "Maria Koutraki, Institute of Applied Informatics and Formal Description Methods (AIFB), Karlsruhe Institute of Technology (KIT)"
        ],
        "published": "July 10, 2017",
        "recorded": "May 2017",
        "category": [
            "Top->Computer Science->Big Data",
            "Top->Computer Science->Semantic Web"
        ]
    },
    "url": "http://videolectures.net/eswc2017_koutraki_linked_datasets/",
    "segmentation": [
        [
            "Hello, thank you very much for being here.",
            "My name is Maria Jackie.",
            "I'm a postdoctoral researcher at Cursor Institute of Technology and member of its cars, Real Leibnitz Institute.",
            "So the work that I will present you today's entitled online relation alignment for linked data set and what we do more or less in this world work is that we try to discover links for relations for disparate RDF data sources and those alignments for their relations would be either equivalences or.",
            "Submissions."
        ],
        [
            "And let me start, sorry.",
            "By an example.",
            "So let's say that we have a user who is interested to answer some questions about your favorite singer.",
            "She is well aware of the scheme of DB Pedia in this case, and she decides to pose the queries there in DB pedia.",
            "So as we see here for the 1st and the second question, the user successfully gets back the result that she should get.",
            "But unfortunately for the last question, there is no a response because simply the pedia doesn't contain the information of what is.",
            "The education that Adele received so the natural solution here would be for the user to sell as well elsewhere, so this elsewhere could be another RDF source, for example like Jago or Freebase.",
            "And here is where we face the main challenge, since if the user is not aware of the scheme as well, we see that there is different.",
            "There are different ways to represent same type of information, for example in DB pedia the relation is called education, the relation about.",
            "Education in yoga is called graduated from while in Freebase is called Person Dot Education."
        ],
        [
            "So why does this problem really exist?",
            "The problem of relation alignment persisting linked open data cloud and the reason is because of the size of linked open data cloud, so there are thousands of data set right now there and every year we have or more an more, and there are inherently diverse in terms of domains.",
            "Language is an structure.",
            "Moreover there are different ways over mechanics to publish and export those data.",
            "For example, we could have RDF dumps.",
            "Or sparkly end points.",
            "Another point is that the alignment there they are centralized towards a knowledge base is like the pedia which tends to be in the center of this cloud and usually those alignments are in the level of instances which means same as links since it's also one of the requirements.",
            "If you want to publish your data in this linked open data Cloud."
        ],
        [
            "But the difficulty remains, so we cannot answer our query an hardness.",
            "This complementary nature of linked open data, since the classes and relations remain mostly unaligned."
        ],
        [
            "And let's talk about some numbers.",
            "So currently there are more than 600 different schemas and vocabularies in are linked open data cloud representing information of course of diverse quality.",
            "Their duplicate representations, similar concept relations or classes.",
            "I, Needless to say that there are almost or not more than 2% of those schemas explicitly aligned.",
            "So still the problem is that we have this integrated data set landscape here."
        ],
        [
            "So this particular problem already addressed in the related literature by ontology alignment approaches.",
            "So instances also have gathered a lot of attention by many works, as as far as it concerns the schema, the majority of the works focus on classes and less works on relations.",
            "And those are they focus on relations there.",
            "Most of them focus on computing similarity or equivalence relationships between those relations and really very few works are focused on computing some Sumption relationships.",
            "So the object."
        ],
        [
            "It appeared in this work is that given two RDF data set data sources that they are linked in the level of instances, so through same as links.",
            "The goal is that we want to compute alignments for the relations that could.",
            "They would be subscriptions or equivalences."
        ],
        [
            "We follow an instance based approach, so we are all based on the actual data that they are there.",
            "The instances of the knowledge basis and another thing that we do is that we want to align those knowledge bases that they are published or exported through sparkle endpoints.",
            "Because what we want to do in this work is everything is computed through sparkling points.",
            "We don't want to download and store and performance snapshots of on the knowledge base is because we want also to take advantage of this.",
            "Property of the linked open Data cloud that gives us of the up-to-date information that it stores.",
            "Another point here is that we don't want to consider the full data sets, but we want to make an efficient approach where on a minimal set of entities we will perform the alignments and last we will use a supervised model where the features are computed on the level of the actual instances of the knowledge base."
        ],
        [
            "So this is the basic architecture of our system.",
            "So as input we have two sources.",
            "Knowledge are the sources sorcery target an.",
            "The output is the relation allow."
        ],
        [
            "Moments, and this happens in two steps.",
            "The first step is the candidate generation and the second step is the supervised model.",
            "So."
        ],
        [
            "Let me start with the first step.",
            "Let's say that we have this source knowledge base and a source relation there.",
            "In this knowledge base.",
            "So first, what do we do weekly?"
        ],
        [
            "84 instances of this artist, though, so the source knowledge base.",
            "Those resources."
        ],
        [
            "And why they should have their corresponding X prime and Y prime that they are connected through same as link links in the target knowledge base?",
            "And then then."
        ],
        [
            "Next step is that we created this time the target knowledge base and we obtain their relations that they hold between those instances.",
            "The direct and inverse relay."
        ],
        [
            "Features and in this way we update our candidate sets for alignments that looks like like this like the one in the bottom."
        ],
        [
            "So, as I mentioned before, one of the Big cautions that we undertake in this work.",
            "This with efficiency issues.",
            "Yes, of course we don't want to perform on Snapchat, so we don't want to have locali the data, but we want to query them.",
            "But yet again we don't want through queries to download the full data because then we face many other challenges that they come along.",
            "Like first is the cost in terms of bandwidth.",
            "If you want to throw queries to download all those sources and 2nd these other issues that they come along with the sparkling points like timeout issues.",
            "So our approach here is to reduce the data transfer and retrieve a subject of instances for the source relation, where on the we're going to compute the set of candidates that I just presented.",
            "So here we propose three sampling strategies.",
            "Let's say for this work we test them so.",
            "The first one is called First N. It's a, let's say, a naive solution where it just returns the 1st and let's say first 100 entities.",
            "This is of course a very fast strategy, but it's not fair.",
            "It's not doesn't give a representative sample, since it will always return the same entities, the same N or 100 entities with the way the same way that they were added in the knowledge base.",
            "So the second one that we tested was the random.",
            "So here we make use of the Rand function of sparkwell.",
            "This sample here is more representative.",
            "But to give to get even a more representative sample, we performed stratified sampling.",
            "Here, in a stratified sampling we make use of the class taxonomy of DP pedia and what we do more or less is that for a relation we check the entities that they are correspond to the subjects of those of this relation.",
            "And the classification in which they belong.",
            "And then, depending on the size, we take a representative sample for each of those classes.",
            "So if an entity belongs in the class of artists which is in the third level, let's say here we're not going to obtain it.",
            "Of course, in the second level, which is person and we do stratified sampling up to a certain level each time."
        ],
        [
            "So in this point we have already computed our candidate relations for the alignment by using.",
            "Also the efficient methods of sampling.",
            "And in this point we have now to decide if those alignments actually are correct or incorrect, and for that we use supervised model where we apply some features that they serve us measures.",
            "This is a very common term in there related literature for ontology alignment.",
            "So here we have three groups of features.",
            "The first group is called Inductive Logic Programming, and here we make use of some features that they already in their nature is to compute some functions of relations.",
            "The second group of features is called general Statistics and there are some statistics that we we computed on the instances of knowledge basis and the last is lexical, which is just simple string comparison of the labels of their relations."
        ],
        [
            "So let me start with the first group of features.",
            "the LP features.",
            "So the first group here is called CWA and it's nothing more than the closed world assumption where according to that, for a relation, are the knowledge base contains all the facts that is translated to the formula over there.",
            "And that means that whatever missing it's missing from the knowledge base is considers counterexample in this case.",
            "So for this."
        ],
        [
            "Example that we have here, the result is 0.4 according to.",
            "Hi icwa measure.",
            "So this way measure is a.",
            "Precise tool, let's say because whenever it gives high scores then it leads to precise results.",
            "But the disadvantage here is that it penalizes a lot for missing or absent data, so it suffers a lot in terms of recall."
        ],
        [
            "That's why we use also another feature.",
            "This feature is called PCA.",
            "It's more based on the open world assumption, so it's called partial completeness assumption, and according to this, for a subject X and the relation are the knowledge base contains either all or none of the facts.",
            "And this is translated into the following formula.",
            "So if we."
        ],
        [
            "Take again the same example that we have here with the two knowledge basis here as counterexample, we consider only the one with the red arrow.",
            "So the result here of the PCA would be 0.66."
        ],
        [
            "This is our next feature in this group is concerns about the relation functionality, the functionality of the relation.",
            "So what does it mean?",
            "Functionality here?",
            "So for election our functionality means that for its subject of this relation we should have only one object.",
            "So if we for its subject we have only one object, then we have a perfectly functional relation and this discord here is equal to 1.",
            "But if we have something less then we apply this away.",
            "Use this ratio in order to compute how functional is a relation, and we use this feature having the intuition where the target relation.",
            "So if we want a relation to be subsumed into another relation, then the target direct relation should have a better coverage of fact.",
            "So the functionality of the target relation should be.",
            "Lower than that source relation relation."
        ],
        [
            "So inspired now from the PCA confidence, which is a nice measure if we have only functional relations because it performs very well.",
            "But it penalizes the non functional relations.",
            "So we decided to transform it slightly and you consider also the notion of functionality here.",
            "So the idea is that if I have missing data from a relation that is highly functional then there yes I should penalize a lot, but if I have missing data from the relation that is non functional.",
            "Then maybe I should be more relaxed and not penalized that much."
        ],
        [
            "We're done with it.",
            "I LP features and I will just explain you the features here about the general statistics.",
            "So the first feature is the type distribution similarity between the source and the target relation.",
            "So as we see in this example, those relations, they are highly similar in terms of types of the types that they're instances have, so the intuition here is that if I have high similarity, it's highly possible that they I have some equivalence relations.",
            "Here."
        ],
        [
            "But since I am more interested in computing some assumption of relationships, we also introduced the dissimilarity.",
            "So the dissimilarity here works as the ratio of the types in the source relation that they do not exist in the target relation.",
            "So here for example, we say that there is a type like paintings where almost half 50% of the entities are represented and this type does not exist at all in the target.",
            "So here we have high dissimilarity and this is.",
            "A strong insight that probably this there some Sumption relationship in this direction should not hold."
        ],
        [
            "And let me pass in the experimental setup.",
            "So just to tell you that for the completeness of the features, you can have a look on the paper.",
            "And as far as it concerns the experimental setup, this system is implemented and tested with.",
            "Three different major knowledge bases Jago DP pedia.",
            "Anna Freebase here you can see the number of the relations that we tested from its knowledge base.",
            "Those are only the subject relation there.",
            "Yeah.",
            "Their relations.",
            "As baselines for this system, we use CWA, which is also used in Paris and Paris, is considers us the recent state of the art in a in this field and also PCA, which is used in another recent system called Rosa.",
            "So as I said, this is a supervised approach.",
            "An in this setup we use logistic regression for these experiments, but to my knowledge any other supervised model can be applied here.",
            "So as far as it concerns the ground truth construction, it was manually constructed by expert annotators in this case, as expert annotators are the three authors of the paper.",
            "And to decide we took into account the relation labels and also the semantics of the relations, meaning the instances and we really checked into the data to decide.",
            "And also we did our majority voting in in the end."
        ],
        [
            "So I decided to show you how to use case scenarios so the first is when we when we take into account the full data of the knowledge bases that we test in the last column.",
            "It's about sorry, our approach an in the two other columns is about Rosa that implements PCA and Paris that implements CWA.",
            "As you see in Paris and Rosa, there are some thresholds there.",
            "Those approaches are not supervised approach approaches, so they work with.",
            "Thresholds and to be fair with them, what we did is that on the full data we computed the results with all the possible thresholds from 0.121.",
            "And these are the ones that they performed the the best.",
            "So here we see that in terms of F1 score, we outperform both competitors and we managed to arrive in our best score as as far as it concerns, the precision to be a 92%."
        ],
        [
            "So the second use case scenario I want to show you here, we don't use the full data, but we use sampled data.",
            "So here we used only 500 entity samples by the sampling technique was stratified in Level 3.",
            "Again we use the same thresholds for their competitors.",
            "PCA and CWA.",
            "Compare again, we outperform.",
            "Almost in every case the competitors, but we have a drop in terms of F score of 5%.",
            "This is because of the recall.",
            "We have a drop-in recall.",
            "Since this is a sampling technique, it is possible that we really missed some of the possible candidates there.",
            "But if you see this result."
        ],
        [
            "With this slide, which is hard to do about the efficiency of the approach, maybe we have a tradeoff between the loss in terms of precision and what we are in time an kilobytes.",
            "So as we can see the first one, so the first one is the sampling time, so the time that we need to query the knowledge basis, and if we want to query for 500 entities here we have something less than we need, something less than two 2.5.",
            "Seconds and as far as it concerns the bandwidth usage for the same 500 entities, we need something more than 60 kilobytes.",
            "So."
        ],
        [
            "To conclude, then summarize I presented you an instance based relation alignment approach to discover subsumption so far relationships.",
            "So we use a set of lightweight features to decide for the correctness of the subscriptions.",
            "We managed to overcome main drawbacks of existing schema matching.",
            "Approach approach is through the efficient alignment algorithms that we propose an through this with this work as well, we could harness more the complementarity of the linked open data sources.",
            "If we can apply this relation alignment at query time.",
            "So that was for me.",
            "Thank you all for your attention and thank you."
        ],
        [
            "What is the effect on the fact that you have restrictions of sparkle?",
            "The end points that they go down, that there may be slow.",
            "Will it affect your system or solution if you have something like triple pattern fragments or something like that or so?",
            "The idea was that you I didn't want to have them localy stored, because if you have them local storage, of course you download one.",
            "You can compute your.",
            "You can apply your approach and compute everything, but then you are losing all the other.",
            "All the updates that you might have.",
            "So I wanted to have something that we could use all those features.",
            "Actually that the link data offer.",
            "Like the sparkle where I suppose they threw the end point they we have the oldest update information so.",
            "So if I understand correctly, then your approach really critically depends on having instances.",
            "Yes, So what do you do if you don't have that?",
            "It doesn't work.",
            "Yeah, it's an instance based approach and also the main requirement is that we need same as links.",
            "But since same as link to have same as links is one of the main.",
            "Let's say you should have them if you want to be part of the linked open data Cloud and also according to many studies that they have done, there exists up to now there.",
            "The problem is considered almost solved.",
            "Of course you can never say that it's solved, but we really have a lot of."
        ],
        [
            "Same as links and here for example, you can see if the question was.",
            "About the linking in the level of instances, this is the.",
            "These are the numbers of the same as links for the sources that I used.",
            "So the problem of course of mapping.",
            "Mining relationships is also, of course, a traditional topic in ontology alignment, but there of course very often you don't have the Insta shared instances.",
            "So so and then then essentially means your approach can.",
            "It doesn't easily carry over to that, so then you could use it as complementary with another approach that like one of those the famous systems that they compute the same as links.",
            "But yes, it is an instance based approach and we are based on the.",
            "Same as links.",
            "Any other remarks, questions, comments?",
            "I have just a small question, but not lining properties.",
            "Sometimes the properties property hierarchy in some that set is not one to one hierarchy with the other desert.",
            "Have you?",
            "My question is just what's your experience about facing that?",
            "Was the common problems and did you manage to?",
            "So if you say that they are not equivalent?",
            "Yes, it's.",
            "That's why I also wanted to work on Subsumption's because this is a real problem.",
            "You cannot assume that we live in this ideal work where all their relations from the different sources they are equivalent to each other.",
            "For example, if you see ya, Gandhi pedia more or less, they contain the same information.",
            "Maybe not the same number of entities, but the same information Jago in one hand has 63 relations, while the Pedia has 560 something relations.",
            "So for sure, we cannot say that the relations there they are equivalent, so that's why I also wanted to work on the subsumption and not directly on the equivalence.",
            "But if your question was if I worked on the one too many.",
            "Right, that's yeah, for the moment the work is a one to one relation.",
            "But yes, this is also a problem and you can find it to have also want too many.",
            "Maybe not that often that one to one, but yes, it exists as a problem, yes?",
            "Any other comments, remarks?",
            "Kaden, thank you very much."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Hello, thank you very much for being here.",
                    "label": 0
                },
                {
                    "sent": "My name is Maria Jackie.",
                    "label": 0
                },
                {
                    "sent": "I'm a postdoctoral researcher at Cursor Institute of Technology and member of its cars, Real Leibnitz Institute.",
                    "label": 1
                },
                {
                    "sent": "So the work that I will present you today's entitled online relation alignment for linked data set and what we do more or less in this world work is that we try to discover links for relations for disparate RDF data sources and those alignments for their relations would be either equivalences or.",
                    "label": 1
                },
                {
                    "sent": "Submissions.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And let me start, sorry.",
                    "label": 0
                },
                {
                    "sent": "By an example.",
                    "label": 0
                },
                {
                    "sent": "So let's say that we have a user who is interested to answer some questions about your favorite singer.",
                    "label": 0
                },
                {
                    "sent": "She is well aware of the scheme of DB Pedia in this case, and she decides to pose the queries there in DB pedia.",
                    "label": 0
                },
                {
                    "sent": "So as we see here for the 1st and the second question, the user successfully gets back the result that she should get.",
                    "label": 0
                },
                {
                    "sent": "But unfortunately for the last question, there is no a response because simply the pedia doesn't contain the information of what is.",
                    "label": 0
                },
                {
                    "sent": "The education that Adele received so the natural solution here would be for the user to sell as well elsewhere, so this elsewhere could be another RDF source, for example like Jago or Freebase.",
                    "label": 0
                },
                {
                    "sent": "And here is where we face the main challenge, since if the user is not aware of the scheme as well, we see that there is different.",
                    "label": 0
                },
                {
                    "sent": "There are different ways to represent same type of information, for example in DB pedia the relation is called education, the relation about.",
                    "label": 0
                },
                {
                    "sent": "Education in yoga is called graduated from while in Freebase is called Person Dot Education.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So why does this problem really exist?",
                    "label": 0
                },
                {
                    "sent": "The problem of relation alignment persisting linked open data cloud and the reason is because of the size of linked open data cloud, so there are thousands of data set right now there and every year we have or more an more, and there are inherently diverse in terms of domains.",
                    "label": 1
                },
                {
                    "sent": "Language is an structure.",
                    "label": 0
                },
                {
                    "sent": "Moreover there are different ways over mechanics to publish and export those data.",
                    "label": 1
                },
                {
                    "sent": "For example, we could have RDF dumps.",
                    "label": 0
                },
                {
                    "sent": "Or sparkly end points.",
                    "label": 0
                },
                {
                    "sent": "Another point is that the alignment there they are centralized towards a knowledge base is like the pedia which tends to be in the center of this cloud and usually those alignments are in the level of instances which means same as links since it's also one of the requirements.",
                    "label": 0
                },
                {
                    "sent": "If you want to publish your data in this linked open data Cloud.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But the difficulty remains, so we cannot answer our query an hardness.",
                    "label": 0
                },
                {
                    "sent": "This complementary nature of linked open data, since the classes and relations remain mostly unaligned.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And let's talk about some numbers.",
                    "label": 0
                },
                {
                    "sent": "So currently there are more than 600 different schemas and vocabularies in are linked open data cloud representing information of course of diverse quality.",
                    "label": 0
                },
                {
                    "sent": "Their duplicate representations, similar concept relations or classes.",
                    "label": 0
                },
                {
                    "sent": "I, Needless to say that there are almost or not more than 2% of those schemas explicitly aligned.",
                    "label": 0
                },
                {
                    "sent": "So still the problem is that we have this integrated data set landscape here.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this particular problem already addressed in the related literature by ontology alignment approaches.",
                    "label": 0
                },
                {
                    "sent": "So instances also have gathered a lot of attention by many works, as as far as it concerns the schema, the majority of the works focus on classes and less works on relations.",
                    "label": 0
                },
                {
                    "sent": "And those are they focus on relations there.",
                    "label": 0
                },
                {
                    "sent": "Most of them focus on computing similarity or equivalence relationships between those relations and really very few works are focused on computing some Sumption relationships.",
                    "label": 0
                },
                {
                    "sent": "So the object.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "It appeared in this work is that given two RDF data set data sources that they are linked in the level of instances, so through same as links.",
                    "label": 0
                },
                {
                    "sent": "The goal is that we want to compute alignments for the relations that could.",
                    "label": 1
                },
                {
                    "sent": "They would be subscriptions or equivalences.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We follow an instance based approach, so we are all based on the actual data that they are there.",
                    "label": 0
                },
                {
                    "sent": "The instances of the knowledge basis and another thing that we do is that we want to align those knowledge bases that they are published or exported through sparkle endpoints.",
                    "label": 0
                },
                {
                    "sent": "Because what we want to do in this work is everything is computed through sparkling points.",
                    "label": 0
                },
                {
                    "sent": "We don't want to download and store and performance snapshots of on the knowledge base is because we want also to take advantage of this.",
                    "label": 0
                },
                {
                    "sent": "Property of the linked open Data cloud that gives us of the up-to-date information that it stores.",
                    "label": 0
                },
                {
                    "sent": "Another point here is that we don't want to consider the full data sets, but we want to make an efficient approach where on a minimal set of entities we will perform the alignments and last we will use a supervised model where the features are computed on the level of the actual instances of the knowledge base.",
                    "label": 1
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is the basic architecture of our system.",
                    "label": 0
                },
                {
                    "sent": "So as input we have two sources.",
                    "label": 0
                },
                {
                    "sent": "Knowledge are the sources sorcery target an.",
                    "label": 0
                },
                {
                    "sent": "The output is the relation allow.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Moments, and this happens in two steps.",
                    "label": 0
                },
                {
                    "sent": "The first step is the candidate generation and the second step is the supervised model.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Let me start with the first step.",
                    "label": 0
                },
                {
                    "sent": "Let's say that we have this source knowledge base and a source relation there.",
                    "label": 0
                },
                {
                    "sent": "In this knowledge base.",
                    "label": 0
                },
                {
                    "sent": "So first, what do we do weekly?",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "84 instances of this artist, though, so the source knowledge base.",
                    "label": 0
                },
                {
                    "sent": "Those resources.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And why they should have their corresponding X prime and Y prime that they are connected through same as link links in the target knowledge base?",
                    "label": 0
                },
                {
                    "sent": "And then then.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Next step is that we created this time the target knowledge base and we obtain their relations that they hold between those instances.",
                    "label": 0
                },
                {
                    "sent": "The direct and inverse relay.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Features and in this way we update our candidate sets for alignments that looks like like this like the one in the bottom.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So, as I mentioned before, one of the Big cautions that we undertake in this work.",
                    "label": 0
                },
                {
                    "sent": "This with efficiency issues.",
                    "label": 0
                },
                {
                    "sent": "Yes, of course we don't want to perform on Snapchat, so we don't want to have locali the data, but we want to query them.",
                    "label": 0
                },
                {
                    "sent": "But yet again we don't want through queries to download the full data because then we face many other challenges that they come along.",
                    "label": 0
                },
                {
                    "sent": "Like first is the cost in terms of bandwidth.",
                    "label": 0
                },
                {
                    "sent": "If you want to throw queries to download all those sources and 2nd these other issues that they come along with the sparkling points like timeout issues.",
                    "label": 0
                },
                {
                    "sent": "So our approach here is to reduce the data transfer and retrieve a subject of instances for the source relation, where on the we're going to compute the set of candidates that I just presented.",
                    "label": 1
                },
                {
                    "sent": "So here we propose three sampling strategies.",
                    "label": 0
                },
                {
                    "sent": "Let's say for this work we test them so.",
                    "label": 0
                },
                {
                    "sent": "The first one is called First N. It's a, let's say, a naive solution where it just returns the 1st and let's say first 100 entities.",
                    "label": 0
                },
                {
                    "sent": "This is of course a very fast strategy, but it's not fair.",
                    "label": 0
                },
                {
                    "sent": "It's not doesn't give a representative sample, since it will always return the same entities, the same N or 100 entities with the way the same way that they were added in the knowledge base.",
                    "label": 0
                },
                {
                    "sent": "So the second one that we tested was the random.",
                    "label": 0
                },
                {
                    "sent": "So here we make use of the Rand function of sparkwell.",
                    "label": 0
                },
                {
                    "sent": "This sample here is more representative.",
                    "label": 0
                },
                {
                    "sent": "But to give to get even a more representative sample, we performed stratified sampling.",
                    "label": 0
                },
                {
                    "sent": "Here, in a stratified sampling we make use of the class taxonomy of DP pedia and what we do more or less is that for a relation we check the entities that they are correspond to the subjects of those of this relation.",
                    "label": 0
                },
                {
                    "sent": "And the classification in which they belong.",
                    "label": 1
                },
                {
                    "sent": "And then, depending on the size, we take a representative sample for each of those classes.",
                    "label": 0
                },
                {
                    "sent": "So if an entity belongs in the class of artists which is in the third level, let's say here we're not going to obtain it.",
                    "label": 0
                },
                {
                    "sent": "Of course, in the second level, which is person and we do stratified sampling up to a certain level each time.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So in this point we have already computed our candidate relations for the alignment by using.",
                    "label": 0
                },
                {
                    "sent": "Also the efficient methods of sampling.",
                    "label": 0
                },
                {
                    "sent": "And in this point we have now to decide if those alignments actually are correct or incorrect, and for that we use supervised model where we apply some features that they serve us measures.",
                    "label": 1
                },
                {
                    "sent": "This is a very common term in there related literature for ontology alignment.",
                    "label": 0
                },
                {
                    "sent": "So here we have three groups of features.",
                    "label": 1
                },
                {
                    "sent": "The first group is called Inductive Logic Programming, and here we make use of some features that they already in their nature is to compute some functions of relations.",
                    "label": 0
                },
                {
                    "sent": "The second group of features is called general Statistics and there are some statistics that we we computed on the instances of knowledge basis and the last is lexical, which is just simple string comparison of the labels of their relations.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So let me start with the first group of features.",
                    "label": 0
                },
                {
                    "sent": "the LP features.",
                    "label": 0
                },
                {
                    "sent": "So the first group here is called CWA and it's nothing more than the closed world assumption where according to that, for a relation, are the knowledge base contains all the facts that is translated to the formula over there.",
                    "label": 1
                },
                {
                    "sent": "And that means that whatever missing it's missing from the knowledge base is considers counterexample in this case.",
                    "label": 0
                },
                {
                    "sent": "So for this.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Example that we have here, the result is 0.4 according to.",
                    "label": 0
                },
                {
                    "sent": "Hi icwa measure.",
                    "label": 0
                },
                {
                    "sent": "So this way measure is a.",
                    "label": 0
                },
                {
                    "sent": "Precise tool, let's say because whenever it gives high scores then it leads to precise results.",
                    "label": 0
                },
                {
                    "sent": "But the disadvantage here is that it penalizes a lot for missing or absent data, so it suffers a lot in terms of recall.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "That's why we use also another feature.",
                    "label": 0
                },
                {
                    "sent": "This feature is called PCA.",
                    "label": 0
                },
                {
                    "sent": "It's more based on the open world assumption, so it's called partial completeness assumption, and according to this, for a subject X and the relation are the knowledge base contains either all or none of the facts.",
                    "label": 1
                },
                {
                    "sent": "And this is translated into the following formula.",
                    "label": 0
                },
                {
                    "sent": "So if we.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Take again the same example that we have here with the two knowledge basis here as counterexample, we consider only the one with the red arrow.",
                    "label": 0
                },
                {
                    "sent": "So the result here of the PCA would be 0.66.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This is our next feature in this group is concerns about the relation functionality, the functionality of the relation.",
                    "label": 0
                },
                {
                    "sent": "So what does it mean?",
                    "label": 0
                },
                {
                    "sent": "Functionality here?",
                    "label": 0
                },
                {
                    "sent": "So for election our functionality means that for its subject of this relation we should have only one object.",
                    "label": 0
                },
                {
                    "sent": "So if we for its subject we have only one object, then we have a perfectly functional relation and this discord here is equal to 1.",
                    "label": 0
                },
                {
                    "sent": "But if we have something less then we apply this away.",
                    "label": 0
                },
                {
                    "sent": "Use this ratio in order to compute how functional is a relation, and we use this feature having the intuition where the target relation.",
                    "label": 0
                },
                {
                    "sent": "So if we want a relation to be subsumed into another relation, then the target direct relation should have a better coverage of fact.",
                    "label": 1
                },
                {
                    "sent": "So the functionality of the target relation should be.",
                    "label": 0
                },
                {
                    "sent": "Lower than that source relation relation.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So inspired now from the PCA confidence, which is a nice measure if we have only functional relations because it performs very well.",
                    "label": 0
                },
                {
                    "sent": "But it penalizes the non functional relations.",
                    "label": 1
                },
                {
                    "sent": "So we decided to transform it slightly and you consider also the notion of functionality here.",
                    "label": 0
                },
                {
                    "sent": "So the idea is that if I have missing data from a relation that is highly functional then there yes I should penalize a lot, but if I have missing data from the relation that is non functional.",
                    "label": 0
                },
                {
                    "sent": "Then maybe I should be more relaxed and not penalized that much.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We're done with it.",
                    "label": 0
                },
                {
                    "sent": "I LP features and I will just explain you the features here about the general statistics.",
                    "label": 0
                },
                {
                    "sent": "So the first feature is the type distribution similarity between the source and the target relation.",
                    "label": 1
                },
                {
                    "sent": "So as we see in this example, those relations, they are highly similar in terms of types of the types that they're instances have, so the intuition here is that if I have high similarity, it's highly possible that they I have some equivalence relations.",
                    "label": 0
                },
                {
                    "sent": "Here.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "But since I am more interested in computing some assumption of relationships, we also introduced the dissimilarity.",
                    "label": 0
                },
                {
                    "sent": "So the dissimilarity here works as the ratio of the types in the source relation that they do not exist in the target relation.",
                    "label": 1
                },
                {
                    "sent": "So here for example, we say that there is a type like paintings where almost half 50% of the entities are represented and this type does not exist at all in the target.",
                    "label": 1
                },
                {
                    "sent": "So here we have high dissimilarity and this is.",
                    "label": 0
                },
                {
                    "sent": "A strong insight that probably this there some Sumption relationship in this direction should not hold.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And let me pass in the experimental setup.",
                    "label": 1
                },
                {
                    "sent": "So just to tell you that for the completeness of the features, you can have a look on the paper.",
                    "label": 0
                },
                {
                    "sent": "And as far as it concerns the experimental setup, this system is implemented and tested with.",
                    "label": 1
                },
                {
                    "sent": "Three different major knowledge bases Jago DP pedia.",
                    "label": 0
                },
                {
                    "sent": "Anna Freebase here you can see the number of the relations that we tested from its knowledge base.",
                    "label": 0
                },
                {
                    "sent": "Those are only the subject relation there.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Their relations.",
                    "label": 0
                },
                {
                    "sent": "As baselines for this system, we use CWA, which is also used in Paris and Paris, is considers us the recent state of the art in a in this field and also PCA, which is used in another recent system called Rosa.",
                    "label": 0
                },
                {
                    "sent": "So as I said, this is a supervised approach.",
                    "label": 0
                },
                {
                    "sent": "An in this setup we use logistic regression for these experiments, but to my knowledge any other supervised model can be applied here.",
                    "label": 1
                },
                {
                    "sent": "So as far as it concerns the ground truth construction, it was manually constructed by expert annotators in this case, as expert annotators are the three authors of the paper.",
                    "label": 0
                },
                {
                    "sent": "And to decide we took into account the relation labels and also the semantics of the relations, meaning the instances and we really checked into the data to decide.",
                    "label": 0
                },
                {
                    "sent": "And also we did our majority voting in in the end.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So I decided to show you how to use case scenarios so the first is when we when we take into account the full data of the knowledge bases that we test in the last column.",
                    "label": 0
                },
                {
                    "sent": "It's about sorry, our approach an in the two other columns is about Rosa that implements PCA and Paris that implements CWA.",
                    "label": 0
                },
                {
                    "sent": "As you see in Paris and Rosa, there are some thresholds there.",
                    "label": 0
                },
                {
                    "sent": "Those approaches are not supervised approach approaches, so they work with.",
                    "label": 0
                },
                {
                    "sent": "Thresholds and to be fair with them, what we did is that on the full data we computed the results with all the possible thresholds from 0.121.",
                    "label": 0
                },
                {
                    "sent": "And these are the ones that they performed the the best.",
                    "label": 0
                },
                {
                    "sent": "So here we see that in terms of F1 score, we outperform both competitors and we managed to arrive in our best score as as far as it concerns, the precision to be a 92%.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the second use case scenario I want to show you here, we don't use the full data, but we use sampled data.",
                    "label": 0
                },
                {
                    "sent": "So here we used only 500 entity samples by the sampling technique was stratified in Level 3.",
                    "label": 0
                },
                {
                    "sent": "Again we use the same thresholds for their competitors.",
                    "label": 0
                },
                {
                    "sent": "PCA and CWA.",
                    "label": 0
                },
                {
                    "sent": "Compare again, we outperform.",
                    "label": 0
                },
                {
                    "sent": "Almost in every case the competitors, but we have a drop in terms of F score of 5%.",
                    "label": 0
                },
                {
                    "sent": "This is because of the recall.",
                    "label": 0
                },
                {
                    "sent": "We have a drop-in recall.",
                    "label": 0
                },
                {
                    "sent": "Since this is a sampling technique, it is possible that we really missed some of the possible candidates there.",
                    "label": 0
                },
                {
                    "sent": "But if you see this result.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "With this slide, which is hard to do about the efficiency of the approach, maybe we have a tradeoff between the loss in terms of precision and what we are in time an kilobytes.",
                    "label": 0
                },
                {
                    "sent": "So as we can see the first one, so the first one is the sampling time, so the time that we need to query the knowledge basis, and if we want to query for 500 entities here we have something less than we need, something less than two 2.5.",
                    "label": 0
                },
                {
                    "sent": "Seconds and as far as it concerns the bandwidth usage for the same 500 entities, we need something more than 60 kilobytes.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "To conclude, then summarize I presented you an instance based relation alignment approach to discover subsumption so far relationships.",
                    "label": 0
                },
                {
                    "sent": "So we use a set of lightweight features to decide for the correctness of the subscriptions.",
                    "label": 1
                },
                {
                    "sent": "We managed to overcome main drawbacks of existing schema matching.",
                    "label": 1
                },
                {
                    "sent": "Approach approach is through the efficient alignment algorithms that we propose an through this with this work as well, we could harness more the complementarity of the linked open data sources.",
                    "label": 0
                },
                {
                    "sent": "If we can apply this relation alignment at query time.",
                    "label": 0
                },
                {
                    "sent": "So that was for me.",
                    "label": 0
                },
                {
                    "sent": "Thank you all for your attention and thank you.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "What is the effect on the fact that you have restrictions of sparkle?",
                    "label": 0
                },
                {
                    "sent": "The end points that they go down, that there may be slow.",
                    "label": 0
                },
                {
                    "sent": "Will it affect your system or solution if you have something like triple pattern fragments or something like that or so?",
                    "label": 0
                },
                {
                    "sent": "The idea was that you I didn't want to have them localy stored, because if you have them local storage, of course you download one.",
                    "label": 0
                },
                {
                    "sent": "You can compute your.",
                    "label": 0
                },
                {
                    "sent": "You can apply your approach and compute everything, but then you are losing all the other.",
                    "label": 0
                },
                {
                    "sent": "All the updates that you might have.",
                    "label": 0
                },
                {
                    "sent": "So I wanted to have something that we could use all those features.",
                    "label": 0
                },
                {
                    "sent": "Actually that the link data offer.",
                    "label": 0
                },
                {
                    "sent": "Like the sparkle where I suppose they threw the end point they we have the oldest update information so.",
                    "label": 0
                },
                {
                    "sent": "So if I understand correctly, then your approach really critically depends on having instances.",
                    "label": 0
                },
                {
                    "sent": "Yes, So what do you do if you don't have that?",
                    "label": 0
                },
                {
                    "sent": "It doesn't work.",
                    "label": 0
                },
                {
                    "sent": "Yeah, it's an instance based approach and also the main requirement is that we need same as links.",
                    "label": 0
                },
                {
                    "sent": "But since same as link to have same as links is one of the main.",
                    "label": 0
                },
                {
                    "sent": "Let's say you should have them if you want to be part of the linked open data Cloud and also according to many studies that they have done, there exists up to now there.",
                    "label": 0
                },
                {
                    "sent": "The problem is considered almost solved.",
                    "label": 0
                },
                {
                    "sent": "Of course you can never say that it's solved, but we really have a lot of.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Same as links and here for example, you can see if the question was.",
                    "label": 0
                },
                {
                    "sent": "About the linking in the level of instances, this is the.",
                    "label": 0
                },
                {
                    "sent": "These are the numbers of the same as links for the sources that I used.",
                    "label": 0
                },
                {
                    "sent": "So the problem of course of mapping.",
                    "label": 0
                },
                {
                    "sent": "Mining relationships is also, of course, a traditional topic in ontology alignment, but there of course very often you don't have the Insta shared instances.",
                    "label": 0
                },
                {
                    "sent": "So so and then then essentially means your approach can.",
                    "label": 0
                },
                {
                    "sent": "It doesn't easily carry over to that, so then you could use it as complementary with another approach that like one of those the famous systems that they compute the same as links.",
                    "label": 1
                },
                {
                    "sent": "But yes, it is an instance based approach and we are based on the.",
                    "label": 0
                },
                {
                    "sent": "Same as links.",
                    "label": 0
                },
                {
                    "sent": "Any other remarks, questions, comments?",
                    "label": 0
                },
                {
                    "sent": "I have just a small question, but not lining properties.",
                    "label": 0
                },
                {
                    "sent": "Sometimes the properties property hierarchy in some that set is not one to one hierarchy with the other desert.",
                    "label": 0
                },
                {
                    "sent": "Have you?",
                    "label": 0
                },
                {
                    "sent": "My question is just what's your experience about facing that?",
                    "label": 0
                },
                {
                    "sent": "Was the common problems and did you manage to?",
                    "label": 0
                },
                {
                    "sent": "So if you say that they are not equivalent?",
                    "label": 0
                },
                {
                    "sent": "Yes, it's.",
                    "label": 0
                },
                {
                    "sent": "That's why I also wanted to work on Subsumption's because this is a real problem.",
                    "label": 0
                },
                {
                    "sent": "You cannot assume that we live in this ideal work where all their relations from the different sources they are equivalent to each other.",
                    "label": 0
                },
                {
                    "sent": "For example, if you see ya, Gandhi pedia more or less, they contain the same information.",
                    "label": 0
                },
                {
                    "sent": "Maybe not the same number of entities, but the same information Jago in one hand has 63 relations, while the Pedia has 560 something relations.",
                    "label": 0
                },
                {
                    "sent": "So for sure, we cannot say that the relations there they are equivalent, so that's why I also wanted to work on the subsumption and not directly on the equivalence.",
                    "label": 1
                },
                {
                    "sent": "But if your question was if I worked on the one too many.",
                    "label": 0
                },
                {
                    "sent": "Right, that's yeah, for the moment the work is a one to one relation.",
                    "label": 0
                },
                {
                    "sent": "But yes, this is also a problem and you can find it to have also want too many.",
                    "label": 0
                },
                {
                    "sent": "Maybe not that often that one to one, but yes, it exists as a problem, yes?",
                    "label": 0
                },
                {
                    "sent": "Any other comments, remarks?",
                    "label": 0
                },
                {
                    "sent": "Kaden, thank you very much.",
                    "label": 0
                }
            ]
        }
    }
}