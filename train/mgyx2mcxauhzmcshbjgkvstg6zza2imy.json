{
    "id": "mgyx2mcxauhzmcshbjgkvstg6zza2imy",
    "title": "System for extracting data (facts) from large amount of unstructured documents",
    "info": {
        "author": [
            "Luka Brade\u0161ko, Department of Knowledge Technologies, Jo\u017eef Stefan Institute"
        ],
        "published": "July 12, 2007",
        "recorded": "July 2007",
        "category": [
            "Top->Computer Science->Text Mining",
            "Top->Computer Science->Information Extraction"
        ]
    },
    "url": "http://videolectures.net/bootcamp07_bradesko_sfe/",
    "segmentation": [
        [
            "So I'm looking at the desk when I come from your Steven Institute from Slovenia.",
            "And I will present you on the system for extracting facts from the Internet.",
            "We're developing this system because we want to have a tool for automatic ontology building to populating ontologies automatically.",
            "On so the original idea.",
            "Was presented by Ordinates Yoni in his paper web scale information extraction.",
            "In know it all.",
            "So I at first I tried.",
            "I was trying to implement his idea and I did it and then I do some changes and."
        ],
        [
            "Improvements.",
            "So for user of this program, it will be ideal to just enter the class.",
            "Of his interest like he wants to search for Nobel Prize winners, these are just typing Nobel Prize winner an Explorer version.",
            "And it's even better if you type more synonyms because you got more results than.",
            "And for better under high, and because I'm I have to present this idea of knowitall.",
            "Because I am building on it, I will for better understanding I will use.",
            "I will build our presentation on the example of Nobel Prize winners.",
            "So let's say we are searching for Nobel Prize winners."
        ],
        [
            "First thing we did we do is to type in class name and 11 synonym and also the plural versions of them.",
            "And so that's what that's what is input of the program.",
            "One of the most important things inside the system are these extraction rules.",
            "There are predefined.",
            "You can see three of them here.",
            "They are predefined and their domain independent.",
            "So you can search for anything.",
            "Um?",
            "And they're just simple patterns.",
            "And as you can see with the slots with them, this with empty slots for very put class and where you expect candidates then.",
            "So here you put class.",
            "You have example here instead of Claire schemes, Nobel Prize winners and instead of NP list is* and that is that is extraction query and you put this down to search engine."
        ],
        [
            "So I was for example, I was using Google and if you put this to Google you got this snippet out.",
            "And here is the first difference I made in my system because originally they were parsing all the web pages and checking for the for those for those sentences inside, I just use the snippets because I think all the data is already here and it's really faster if I don't have to parse every page."
        ],
        [
            "So following the example of, you take the snippet and find the sentence with this pattern inside.",
            "And then with the extraction reconstruct.",
            "Candidates for for the Nobel Prize winner."
        ],
        [
            "And after this step.",
            "After that step, it wasn't the last slide.",
            "You have a large list of candidates, but you don't know which are true candidates in which are some, just some fresh or random names, or something else.",
            "So we have to assess them somehow.",
            "And here we use again the extraction rules, but this time we transfer them to discriminators.",
            "It's quite the same data extraction or just instead of the class class slot it have class already inside?",
            "And then with for each instance you have.",
            "Then let's say here is a free examples, but you have let's say 20 or 10 of those discriminators, and then reaches instance you combine the instance in the discriminators.",
            "And you got you get some discriminator queries.",
            "Then you put them again on Google, but this time you don't parse anything.",
            "Just check the hits.",
            "How many hits does it return?",
            "That's how you can.",
            "You can calculate some sort of point while mutual information.",
            "Oh which is which can be later used as, so every hit every candidate have let's say 20 of those numbers point you can see here how it's calculated.",
            "You just divide hits of discriminator divided by hits of instance itself.",
            "And those numbers are then can be used as features for some learning algorithms."
        ],
        [
            "But if you if you want to train some learning algorithm we have, we must have set of positive and set of negative examples which we don't have at the beginning.",
            "So here the bootstrapping.",
            "And.",
            "I'm at 4 because it's faster.",
            "At the beginning.",
            "We don't.",
            "We don't assess all the all the candidates, but we just select any of them.",
            "Let's say at this example we take two hundreds of candidates which which we don't know if they are.",
            "If they are Nobel Prize winners or if they are not.",
            "And then, with the help of discriminators we calculate those PMI numbers on them and then we do the average an.",
            "Then we take, let's say, 50 candidates with the best, but with the highest average PMI and with decided those are positive and the worst M candidates with the lowest average PMI are negative and here for negative classic.",
            "And also we can also take positive classes for with positive instances.",
            "We from some other class from previous search or from I know if previous previously we were searching for.",
            "Terrorists then we can put terrorist as negative examples.",
            "After we have those, took those two sets.",
            "We will put those.",
            "We assess discriminators with those with those.",
            "Training examples.",
            "And so.",
            "And we select the K best discriminators and this we do in that way that if if an discriminate the discriminator which can divide better from from positive from negative examples here better Mark, let's say one discriminator for all positive instance candidates, say their positive and for all negative it says that they are negative.",
            "It's then the best of the best discriminator.",
            "So in this way we say like best discriminators.",
            "That's how we do some sort of features feature selection.",
            "So we don't have to use all the discriminators because some of them are not useful and they're not important.",
            "And then when we have those K discriminators will evaluate all candidates.",
            "And we got those PMI numbers and so we have features.",
            "Fullering algorithm."
        ],
        [
            "This is the pseudocode for previous light is the same, it's just written more like problem."
        ],
        [
            "One one of the interesting problems with this approach was because the.",
            "Search engine scale.",
            "Usually only 1000 results limit.",
            "You can only get 1000 results per search and it's really nice way to avoid this.",
            "Let's say if you have a query, you search for it and you got thousand 1090 results and for this you must have a predefined list of most frequent words in English.",
            "Let's say if you're searching in English.",
            "So what you do here?",
            "And then when you have too much results, you take the first word.",
            "The most frequent word in English, and search again, and then in such again with minus that word.",
            "So you divide, you divide those two queries onto resultsets.",
            "And let's say this one is OK, you can parse it because it's only 700, but this one is not OK.",
            "So you do it again.",
            "But now with second word.",
            "So we have two plus Vienna plus W2.",
            "And that's how you divide all queries until you came to Denton you have all the results.",
            "So here is the example.",
            "It's really a nice way.",
            "I liked it too."
        ],
        [
            "Here are some other difficulties I found while when I was working on this.",
            "So one of the biggest was because this PMI measure it didn't always give the needed information.",
            "Sometimes when some when, let's say for Nobel Prize winner.",
            "Somebody mistyped the name or.",
            "Something like that and it was the only the only it was mentioned only once.",
            "This pair, my probability goes very high and that's why usually best few PMI results usually was not were not good so I couldn't train the learning algorithms because the first few examples were not OK.",
            "So what I found.",
            "Instead of despair, might he be my I was using, I would just counting how many times I found some candidates from different or else.",
            "And so if some.",
            "I found number.",
            "Let's say I found Albert Einstein on this page and let them in in 10 pages.",
            "This redundancy number is then 10 and it happens that this redundancy number is always OK and you can say almost for 100% that the hits with high redundancy number will be will be OK. Will be correcting instance of the class.",
            "It was also hard to calculate precision, 'cause I don't know if I was searching for cities or for some other things.",
            "You can't know how you don't have the real results so you can't compare and the problem was also because of the time because fetching those web pages and assessing all the time, it's time consuming.",
            "Yesterday I tried example on the citizen it today in the morning it was still running with but it found more than 10,000 cities.",
            "In in time.",
            "So, but if you use this in the redundancy number, you don't have to write that lot.",
            "You just parse those snippets and that's it.",
            "You have results in few minutes, which which are."
        ],
        [
            "Also quite good.",
            "So this is again the future problem here.",
            "Here is the distribution distribution of features or all two features have the same distribution.",
            "PMI and this redundancy number it have two tails.",
            "And here here is example of PMI.",
            "Nii did I did 2 examples so I was searching once for American presidents and once for Noble prize winners.",
            "So I think those two are mistyped with the highest probability and this type.",
            "These two are totally wrong, so it's obvious that it's not doing very well in the middle.",
            "It was OK. At the end it is normal that it's something something strange.",
            "Yeah, that's what this fight I get after running."
        ],
        [
            "So here is the this redundancy number feature.",
            "The distribution is the same, but the top top.",
            "Most hits are usually OK, the middle is the same, band entail is the same."
        ],
        [
            "Here I calculated some precision and recall on both features.",
            "Um, BMI based search was.",
            "Like this and redundancy based search with threshold, I didn't learn any algorithm.",
            "I just said threshold at the end was like that, but the recall was was not that good because the I said threshold to let redundancy number 40 and then then here there is a cut.",
            "So the solution would be to somehow use both feature or even more features.",
            "And somehow wait them.",
            "And I think this would be the best.",
            "Precision event"
        ],
        [
            "Also, here are conclusions I already told him.",
            "With this redundancy number, you can if you set the threshold high, you can be 100% almost 100% sure that this positive classes are really positive.",
            "On and even then, because I was not using this this function I told for avoiding 1001 thousand limit.",
            "So all the examples were from 1000 limit.",
            "So even if I would use more more than 1000 hits, the precision precision would not drop because of that.",
            "And because for automatic ontology, populating precision is more important than the call.",
            "This feature is also OK for that."
        ],
        [
            "So this is some further work I have to to put that algorithm in and multithreading because you can query multiple search engines at the same time and it goes faster.",
            "So I can play with learning methods because now I have data sets and everything.",
            "And the important thing is database, because otherwise you have to wait a lot for the results.",
            "But if you have database wait only once and then you can play because you have you are caching Google results or search engine results.",
            "Home, so that's it.",
            "I can show also a quick example because we don't have that much time.",
            "I decided to.",
            "To show to search for friends swimmers.",
            "Because I know from here from Boot camp that friends don't like to swim.",
            "Um?",
            "So here is my input.",
            "And that's it.",
            "It will be fast because I think only three or four people.",
            "So these are those 4 results, one is 1 is mistyped.",
            "I think this one with plus.",
            "I can say it.",
            "I can bet that she's a swimmer.",
            "He I think it's she.",
            "But for for for other three I don't know.",
            "I should use PMI for others free.",
            "I can also.",
            "Try example for rhino searching for Italian cars.",
            "Just have to put that rule out.",
            "So these are those rules.",
            "Here for extracting.",
            "Hi, it's him.",
            "So this would process I can.",
            "I'm quite sure that they're they're really Italian cars.",
            "For others I'm not sure.",
            "Um?",
            "So Italian you are there.",
            "So that's it.",
            "I can, I don't know if somebody wants to try searching something.",
            "You can do it later.",
            "I don't know if I have time now.",
            "If you search for some bigger classes, it's usually you need more time, 10 minutes or 5 minutes or something and it depends."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So I'm looking at the desk when I come from your Steven Institute from Slovenia.",
                    "label": 0
                },
                {
                    "sent": "And I will present you on the system for extracting facts from the Internet.",
                    "label": 1
                },
                {
                    "sent": "We're developing this system because we want to have a tool for automatic ontology building to populating ontologies automatically.",
                    "label": 0
                },
                {
                    "sent": "On so the original idea.",
                    "label": 1
                },
                {
                    "sent": "Was presented by Ordinates Yoni in his paper web scale information extraction.",
                    "label": 0
                },
                {
                    "sent": "In know it all.",
                    "label": 0
                },
                {
                    "sent": "So I at first I tried.",
                    "label": 0
                },
                {
                    "sent": "I was trying to implement his idea and I did it and then I do some changes and.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Improvements.",
                    "label": 0
                },
                {
                    "sent": "So for user of this program, it will be ideal to just enter the class.",
                    "label": 0
                },
                {
                    "sent": "Of his interest like he wants to search for Nobel Prize winners, these are just typing Nobel Prize winner an Explorer version.",
                    "label": 1
                },
                {
                    "sent": "And it's even better if you type more synonyms because you got more results than.",
                    "label": 0
                },
                {
                    "sent": "And for better under high, and because I'm I have to present this idea of knowitall.",
                    "label": 0
                },
                {
                    "sent": "Because I am building on it, I will for better understanding I will use.",
                    "label": 0
                },
                {
                    "sent": "I will build our presentation on the example of Nobel Prize winners.",
                    "label": 0
                },
                {
                    "sent": "So let's say we are searching for Nobel Prize winners.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "First thing we did we do is to type in class name and 11 synonym and also the plural versions of them.",
                    "label": 0
                },
                {
                    "sent": "And so that's what that's what is input of the program.",
                    "label": 0
                },
                {
                    "sent": "One of the most important things inside the system are these extraction rules.",
                    "label": 0
                },
                {
                    "sent": "There are predefined.",
                    "label": 0
                },
                {
                    "sent": "You can see three of them here.",
                    "label": 0
                },
                {
                    "sent": "They are predefined and their domain independent.",
                    "label": 0
                },
                {
                    "sent": "So you can search for anything.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "And they're just simple patterns.",
                    "label": 0
                },
                {
                    "sent": "And as you can see with the slots with them, this with empty slots for very put class and where you expect candidates then.",
                    "label": 0
                },
                {
                    "sent": "So here you put class.",
                    "label": 0
                },
                {
                    "sent": "You have example here instead of Claire schemes, Nobel Prize winners and instead of NP list is* and that is that is extraction query and you put this down to search engine.",
                    "label": 1
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So I was for example, I was using Google and if you put this to Google you got this snippet out.",
                    "label": 0
                },
                {
                    "sent": "And here is the first difference I made in my system because originally they were parsing all the web pages and checking for the for those for those sentences inside, I just use the snippets because I think all the data is already here and it's really faster if I don't have to parse every page.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So following the example of, you take the snippet and find the sentence with this pattern inside.",
                    "label": 0
                },
                {
                    "sent": "And then with the extraction reconstruct.",
                    "label": 0
                },
                {
                    "sent": "Candidates for for the Nobel Prize winner.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And after this step.",
                    "label": 0
                },
                {
                    "sent": "After that step, it wasn't the last slide.",
                    "label": 0
                },
                {
                    "sent": "You have a large list of candidates, but you don't know which are true candidates in which are some, just some fresh or random names, or something else.",
                    "label": 0
                },
                {
                    "sent": "So we have to assess them somehow.",
                    "label": 0
                },
                {
                    "sent": "And here we use again the extraction rules, but this time we transfer them to discriminators.",
                    "label": 0
                },
                {
                    "sent": "It's quite the same data extraction or just instead of the class class slot it have class already inside?",
                    "label": 0
                },
                {
                    "sent": "And then with for each instance you have.",
                    "label": 1
                },
                {
                    "sent": "Then let's say here is a free examples, but you have let's say 20 or 10 of those discriminators, and then reaches instance you combine the instance in the discriminators.",
                    "label": 1
                },
                {
                    "sent": "And you got you get some discriminator queries.",
                    "label": 0
                },
                {
                    "sent": "Then you put them again on Google, but this time you don't parse anything.",
                    "label": 0
                },
                {
                    "sent": "Just check the hits.",
                    "label": 0
                },
                {
                    "sent": "How many hits does it return?",
                    "label": 0
                },
                {
                    "sent": "That's how you can.",
                    "label": 0
                },
                {
                    "sent": "You can calculate some sort of point while mutual information.",
                    "label": 0
                },
                {
                    "sent": "Oh which is which can be later used as, so every hit every candidate have let's say 20 of those numbers point you can see here how it's calculated.",
                    "label": 0
                },
                {
                    "sent": "You just divide hits of discriminator divided by hits of instance itself.",
                    "label": 0
                },
                {
                    "sent": "And those numbers are then can be used as features for some learning algorithms.",
                    "label": 1
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "But if you if you want to train some learning algorithm we have, we must have set of positive and set of negative examples which we don't have at the beginning.",
                    "label": 0
                },
                {
                    "sent": "So here the bootstrapping.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "I'm at 4 because it's faster.",
                    "label": 0
                },
                {
                    "sent": "At the beginning.",
                    "label": 0
                },
                {
                    "sent": "We don't.",
                    "label": 0
                },
                {
                    "sent": "We don't assess all the all the candidates, but we just select any of them.",
                    "label": 0
                },
                {
                    "sent": "Let's say at this example we take two hundreds of candidates which which we don't know if they are.",
                    "label": 0
                },
                {
                    "sent": "If they are Nobel Prize winners or if they are not.",
                    "label": 0
                },
                {
                    "sent": "And then, with the help of discriminators we calculate those PMI numbers on them and then we do the average an.",
                    "label": 0
                },
                {
                    "sent": "Then we take, let's say, 50 candidates with the best, but with the highest average PMI and with decided those are positive and the worst M candidates with the lowest average PMI are negative and here for negative classic.",
                    "label": 1
                },
                {
                    "sent": "And also we can also take positive classes for with positive instances.",
                    "label": 0
                },
                {
                    "sent": "We from some other class from previous search or from I know if previous previously we were searching for.",
                    "label": 0
                },
                {
                    "sent": "Terrorists then we can put terrorist as negative examples.",
                    "label": 0
                },
                {
                    "sent": "After we have those, took those two sets.",
                    "label": 0
                },
                {
                    "sent": "We will put those.",
                    "label": 0
                },
                {
                    "sent": "We assess discriminators with those with those.",
                    "label": 0
                },
                {
                    "sent": "Training examples.",
                    "label": 0
                },
                {
                    "sent": "And so.",
                    "label": 0
                },
                {
                    "sent": "And we select the K best discriminators and this we do in that way that if if an discriminate the discriminator which can divide better from from positive from negative examples here better Mark, let's say one discriminator for all positive instance candidates, say their positive and for all negative it says that they are negative.",
                    "label": 0
                },
                {
                    "sent": "It's then the best of the best discriminator.",
                    "label": 0
                },
                {
                    "sent": "So in this way we say like best discriminators.",
                    "label": 0
                },
                {
                    "sent": "That's how we do some sort of features feature selection.",
                    "label": 0
                },
                {
                    "sent": "So we don't have to use all the discriminators because some of them are not useful and they're not important.",
                    "label": 0
                },
                {
                    "sent": "And then when we have those K discriminators will evaluate all candidates.",
                    "label": 0
                },
                {
                    "sent": "And we got those PMI numbers and so we have features.",
                    "label": 0
                },
                {
                    "sent": "Fullering algorithm.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is the pseudocode for previous light is the same, it's just written more like problem.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "One one of the interesting problems with this approach was because the.",
                    "label": 0
                },
                {
                    "sent": "Search engine scale.",
                    "label": 0
                },
                {
                    "sent": "Usually only 1000 results limit.",
                    "label": 0
                },
                {
                    "sent": "You can only get 1000 results per search and it's really nice way to avoid this.",
                    "label": 1
                },
                {
                    "sent": "Let's say if you have a query, you search for it and you got thousand 1090 results and for this you must have a predefined list of most frequent words in English.",
                    "label": 1
                },
                {
                    "sent": "Let's say if you're searching in English.",
                    "label": 0
                },
                {
                    "sent": "So what you do here?",
                    "label": 0
                },
                {
                    "sent": "And then when you have too much results, you take the first word.",
                    "label": 0
                },
                {
                    "sent": "The most frequent word in English, and search again, and then in such again with minus that word.",
                    "label": 0
                },
                {
                    "sent": "So you divide, you divide those two queries onto resultsets.",
                    "label": 0
                },
                {
                    "sent": "And let's say this one is OK, you can parse it because it's only 700, but this one is not OK.",
                    "label": 0
                },
                {
                    "sent": "So you do it again.",
                    "label": 0
                },
                {
                    "sent": "But now with second word.",
                    "label": 0
                },
                {
                    "sent": "So we have two plus Vienna plus W2.",
                    "label": 0
                },
                {
                    "sent": "And that's how you divide all queries until you came to Denton you have all the results.",
                    "label": 0
                },
                {
                    "sent": "So here is the example.",
                    "label": 0
                },
                {
                    "sent": "It's really a nice way.",
                    "label": 0
                },
                {
                    "sent": "I liked it too.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Here are some other difficulties I found while when I was working on this.",
                    "label": 0
                },
                {
                    "sent": "So one of the biggest was because this PMI measure it didn't always give the needed information.",
                    "label": 1
                },
                {
                    "sent": "Sometimes when some when, let's say for Nobel Prize winner.",
                    "label": 0
                },
                {
                    "sent": "Somebody mistyped the name or.",
                    "label": 0
                },
                {
                    "sent": "Something like that and it was the only the only it was mentioned only once.",
                    "label": 0
                },
                {
                    "sent": "This pair, my probability goes very high and that's why usually best few PMI results usually was not were not good so I couldn't train the learning algorithms because the first few examples were not OK.",
                    "label": 0
                },
                {
                    "sent": "So what I found.",
                    "label": 0
                },
                {
                    "sent": "Instead of despair, might he be my I was using, I would just counting how many times I found some candidates from different or else.",
                    "label": 0
                },
                {
                    "sent": "And so if some.",
                    "label": 0
                },
                {
                    "sent": "I found number.",
                    "label": 0
                },
                {
                    "sent": "Let's say I found Albert Einstein on this page and let them in in 10 pages.",
                    "label": 0
                },
                {
                    "sent": "This redundancy number is then 10 and it happens that this redundancy number is always OK and you can say almost for 100% that the hits with high redundancy number will be will be OK. Will be correcting instance of the class.",
                    "label": 1
                },
                {
                    "sent": "It was also hard to calculate precision, 'cause I don't know if I was searching for cities or for some other things.",
                    "label": 0
                },
                {
                    "sent": "You can't know how you don't have the real results so you can't compare and the problem was also because of the time because fetching those web pages and assessing all the time, it's time consuming.",
                    "label": 1
                },
                {
                    "sent": "Yesterday I tried example on the citizen it today in the morning it was still running with but it found more than 10,000 cities.",
                    "label": 0
                },
                {
                    "sent": "In in time.",
                    "label": 0
                },
                {
                    "sent": "So, but if you use this in the redundancy number, you don't have to write that lot.",
                    "label": 0
                },
                {
                    "sent": "You just parse those snippets and that's it.",
                    "label": 0
                },
                {
                    "sent": "You have results in few minutes, which which are.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Also quite good.",
                    "label": 0
                },
                {
                    "sent": "So this is again the future problem here.",
                    "label": 0
                },
                {
                    "sent": "Here is the distribution distribution of features or all two features have the same distribution.",
                    "label": 0
                },
                {
                    "sent": "PMI and this redundancy number it have two tails.",
                    "label": 0
                },
                {
                    "sent": "And here here is example of PMI.",
                    "label": 0
                },
                {
                    "sent": "Nii did I did 2 examples so I was searching once for American presidents and once for Noble prize winners.",
                    "label": 0
                },
                {
                    "sent": "So I think those two are mistyped with the highest probability and this type.",
                    "label": 0
                },
                {
                    "sent": "These two are totally wrong, so it's obvious that it's not doing very well in the middle.",
                    "label": 0
                },
                {
                    "sent": "It was OK. At the end it is normal that it's something something strange.",
                    "label": 0
                },
                {
                    "sent": "Yeah, that's what this fight I get after running.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here is the this redundancy number feature.",
                    "label": 0
                },
                {
                    "sent": "The distribution is the same, but the top top.",
                    "label": 0
                },
                {
                    "sent": "Most hits are usually OK, the middle is the same, band entail is the same.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here I calculated some precision and recall on both features.",
                    "label": 0
                },
                {
                    "sent": "Um, BMI based search was.",
                    "label": 0
                },
                {
                    "sent": "Like this and redundancy based search with threshold, I didn't learn any algorithm.",
                    "label": 0
                },
                {
                    "sent": "I just said threshold at the end was like that, but the recall was was not that good because the I said threshold to let redundancy number 40 and then then here there is a cut.",
                    "label": 0
                },
                {
                    "sent": "So the solution would be to somehow use both feature or even more features.",
                    "label": 0
                },
                {
                    "sent": "And somehow wait them.",
                    "label": 0
                },
                {
                    "sent": "And I think this would be the best.",
                    "label": 0
                },
                {
                    "sent": "Precision event",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Also, here are conclusions I already told him.",
                    "label": 0
                },
                {
                    "sent": "With this redundancy number, you can if you set the threshold high, you can be 100% almost 100% sure that this positive classes are really positive.",
                    "label": 1
                },
                {
                    "sent": "On and even then, because I was not using this this function I told for avoiding 1001 thousand limit.",
                    "label": 0
                },
                {
                    "sent": "So all the examples were from 1000 limit.",
                    "label": 0
                },
                {
                    "sent": "So even if I would use more more than 1000 hits, the precision precision would not drop because of that.",
                    "label": 1
                },
                {
                    "sent": "And because for automatic ontology, populating precision is more important than the call.",
                    "label": 1
                },
                {
                    "sent": "This feature is also OK for that.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this is some further work I have to to put that algorithm in and multithreading because you can query multiple search engines at the same time and it goes faster.",
                    "label": 1
                },
                {
                    "sent": "So I can play with learning methods because now I have data sets and everything.",
                    "label": 0
                },
                {
                    "sent": "And the important thing is database, because otherwise you have to wait a lot for the results.",
                    "label": 0
                },
                {
                    "sent": "But if you have database wait only once and then you can play because you have you are caching Google results or search engine results.",
                    "label": 0
                },
                {
                    "sent": "Home, so that's it.",
                    "label": 0
                },
                {
                    "sent": "I can show also a quick example because we don't have that much time.",
                    "label": 0
                },
                {
                    "sent": "I decided to.",
                    "label": 0
                },
                {
                    "sent": "To show to search for friends swimmers.",
                    "label": 0
                },
                {
                    "sent": "Because I know from here from Boot camp that friends don't like to swim.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "So here is my input.",
                    "label": 0
                },
                {
                    "sent": "And that's it.",
                    "label": 0
                },
                {
                    "sent": "It will be fast because I think only three or four people.",
                    "label": 0
                },
                {
                    "sent": "So these are those 4 results, one is 1 is mistyped.",
                    "label": 0
                },
                {
                    "sent": "I think this one with plus.",
                    "label": 0
                },
                {
                    "sent": "I can say it.",
                    "label": 0
                },
                {
                    "sent": "I can bet that she's a swimmer.",
                    "label": 0
                },
                {
                    "sent": "He I think it's she.",
                    "label": 0
                },
                {
                    "sent": "But for for for other three I don't know.",
                    "label": 0
                },
                {
                    "sent": "I should use PMI for others free.",
                    "label": 0
                },
                {
                    "sent": "I can also.",
                    "label": 0
                },
                {
                    "sent": "Try example for rhino searching for Italian cars.",
                    "label": 0
                },
                {
                    "sent": "Just have to put that rule out.",
                    "label": 0
                },
                {
                    "sent": "So these are those rules.",
                    "label": 0
                },
                {
                    "sent": "Here for extracting.",
                    "label": 0
                },
                {
                    "sent": "Hi, it's him.",
                    "label": 0
                },
                {
                    "sent": "So this would process I can.",
                    "label": 0
                },
                {
                    "sent": "I'm quite sure that they're they're really Italian cars.",
                    "label": 0
                },
                {
                    "sent": "For others I'm not sure.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "So Italian you are there.",
                    "label": 0
                },
                {
                    "sent": "So that's it.",
                    "label": 0
                },
                {
                    "sent": "I can, I don't know if somebody wants to try searching something.",
                    "label": 0
                },
                {
                    "sent": "You can do it later.",
                    "label": 0
                },
                {
                    "sent": "I don't know if I have time now.",
                    "label": 0
                },
                {
                    "sent": "If you search for some bigger classes, it's usually you need more time, 10 minutes or 5 minutes or something and it depends.",
                    "label": 0
                }
            ]
        }
    }
}