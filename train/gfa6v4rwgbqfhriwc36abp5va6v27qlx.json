{
    "id": "gfa6v4rwgbqfhriwc36abp5va6v27qlx",
    "title": "Semantic Annotation of Data Processing Pipelines in Scientific Publications",
    "info": {
        "author": [
            "Sepideh Mesbah, Faculty of Electrical Engineering, Mathematics and Computer Science, Delft University of Technology (TU Delft)"
        ],
        "published": "July 10, 2017",
        "recorded": "May 2017",
        "category": [
            "Top->Computer Science->Big Data",
            "Top->Computer Science->Semantic Web"
        ]
    },
    "url": "http://videolectures.net/eswc2017_mesbah_scientific_publications/",
    "segmentation": [
        [
            "Hello everybody, I'm secretary.",
            "I'm from the web Information System group of Delft University of Technology from the Netherlands and my topic is about semantic annotation of data processing pipelines in scientific publications."
        ],
        [
            "And as you already know and you have heard it a lot during these days, especially during the keynote yesterday and data is everywhere and data science is becoming one of the main challenges that every organization has to face with.",
            "So there are a lot of people trying to find.",
            "The different ways, in order to somehow analyze the data and also find ways to make sense of this and make some value out of this data and to face the challenges we need to create some knowledge about how to process this big data and also defined some data processing pipelines which are sequences of operations over this data.",
            "Um, however, this knowledge is not readily accessible an it's latent in the mind of the people who are doing them or and also in the artifacts that they produce and wouldn't be nice in order.",
            "If we find ways to.",
            "Capture this knowledge about how to process big data and translate them into machine processable knowledge.",
            "For instance, it.",
            "In this way we can better understand like an example when it's the right moment to apply a fancy deep learning method on a particular data set.",
            "So this is the vision of my PhD project in general.",
            "In order to capture knowledge about data processing pipelines, how to process the data and make it available for everybody to use it.",
            "This knowledge is encoded in the into the different digital artifacts and our goal.",
            "Our vision is to make this knowledge explicit an make it into a machine processable way which users can make use of it."
        ],
        [
            "So there are if you look at the main information objects that are related to data processing.",
            "Pipelines are exactly the datasets that we're dealing with which are used to be analyzed and there are the methods that are used to analyze and process the data and also the implementation of those methods.",
            "For instance, we see that in an experiment that which they are, they are.",
            "They want to try to classify images.",
            "For instance an some experiment.",
            "The scientists they use.",
            "For instance imagenes datasets, and they apply some LSM.",
            "Deep learning methods and then which is which they use.",
            "For instance, the implementation using the tensor flow for instance, and they just get some results.",
            "And if we translate this kind of knowledge into machine processable knowledge."
        ],
        [
            "Then we will enable a set of use cases which which can be very interesting."
        ],
        [
            "For instance, we will allow data scientists to answer a set of information needs, like for instance a data scientist in the field of urban planning might be interesting in finding discovering the state of the art.",
            "Methods for point of interest, that recommendation that have been applied to geolocated social media data with, for instance, good accuracy results.",
            "Right now there is no system able to answer this kind of queries with a very exact short answer.",
            "And in order to make this possible, we need to extract knowledge about the data processing pipelines from different sources and for instance we can extract knowledge about.",
            "Data processing pipelines from scientific publications, which is a very rich source where scientists describe the pipeline that they have used for processing the data or other sources like the code repositories or data set repository's.",
            "And if we extract knowledge from different sources and try to link them together, we are also enabled.",
            "Besides answering some information needs, we are also."
        ],
        [
            "Able to better explore digital libraries.",
            "Since we are extracting knowledge from scientific publication and also the automatic assessment of big data processing.",
            "So this is the vision of my PhD project and it's good that.",
            "Still I have three years to go and maybe hopefully some more academic years in front of me."
        ],
        [
            "And so.",
            "The for this work we decided to focus on the data that the extracting knowledge about data processing pipelines from papers so, but the main challenges that here is that this knowledge is distributed among a vast repository of natural language documents, and also we're dealing with named entities which are very rare and very domain specific.",
            "And usually there is no.",
            "Link to the existing knowledge base is So what do we need?",
            "We need the 1st way to encode and describe the properties of data processing pipelines in a machine readable way.",
            "And then we need methodology's for the extraction of this knowledge from papers.",
            "And also a way how to consume this extracted knowledge."
        ],
        [
            "So first I want to talk about how we can describe the knowledge about data processing pipelines.",
            "This is a work that we already tackled in our previous paper where we tried to design."
        ],
        [
            "Ontology for the description of the data processing pipelines for.",
            "I won't go much into the details, I just quickly just mentioned it that we use the try to interview the practitioners at the industry and also some data scientists at the University in order to find the relevant terms related to data processing pipelines and try to identify terms.",
            "And also we relied on the existing ontologies and made use of them when.",
            "As possible, and finally we try to conceptualize or model.",
            "This is a very abstract view of of the ontology which is related to this part of the discussion that I want to talk about.",
            "So the main concepts are data set method and software an in each publication that scientists they describe the pipeline that they have used in by means of an experiment where each experiment uses some data set methods.",
            "For software for a given objective, and they produce at the end some results.",
            "So after."
        ],
        [
            "Having this ontology, we want to find ways how to populate this ontology.",
            "So we want to find ways how to automatically extract knowledge about.",
            "Dataset, software, method, objective and results over the five main concepts which are named the ontology DMZ model.",
            "So the five main concepts of the model we want to find ways how to extract this knowledge from scientific publications."
        ],
        [
            "An as an example, I would sure like to show you a part of the text of a paper that shows that, for instance, in a paper, scientists describe the data set that they have used.",
            "And did they describe the method that they have applied on the data set for a given objective?",
            "And also they have some information about this software's that you have used and also the results that they produce, for instance here they say that they use the Twitter data set and the objective is to annotate mobility data for instance.",
            "And for doing that they use the kernel density estimation.",
            "And at the end they got some results, like by measuring the precision and recall.",
            "Anne.",
            "By applying the method on a data set.",
            "So this is exactly the information that the data scientists might need so."
        ],
        [
            "In order to get this knowledge, we just have a very simple approach various baseline approach.",
            "This is a summary of our approach in this figure where we try to identify the rhetorical mentions of a DMZ main class, which, as I mentioned, data set methods, software result and objectives.",
            "Which we try to identify the rich parts of the text which contain a mention of those five main classes, and then in the next step from those rhetorical sentences we try to extract named entities.",
            "And after extracting name density and trying to filter out there irrelevant ones and also a linking linking them to the existing knowledge basis when it's possible.",
            "We use the extracted named entities and the sentences classified with respect to the five.",
            "The Ms main classes in order to populate the ontology and create the final knowledge repository."
        ],
        [
            "And the first step is to, given a sentence, we want to classify it with respect to the 5D Ms main classes."
        ],
        [
            "So of course we can use the traditional way and try to use a supervised approach where we try can label all the sentences of publication by using the expert feedback and label all the sentences and use them as a training data for training the classifier.",
            "However, in our previous work we saw that annotating manually annotating the sentences was very time consuming, so it was not scalable and each publication it took around 30 minutes for them to.",
            "Annotate them and also it was not that.",
            "Reliable an, so we decided to go for a distant supervision approach where we try to label the sentences of a publication using a very noisy dictionary based approach, and in this case we can get a lot of training data in order to train a classifier on top of it."
        ],
        [
            "So for creating for enabling this distance to provision approach, we need to make a dictionary.",
            "We created the dictionary and this dictionary helps us to cheaply generate some noisy training data for creating the dictionary.",
            "Used some generic scientific rhetorical phrases.",
            "We looked into some papers which were giving some advice on how to write the different sections of papers.",
            "An they give some advice so common phrases which scientists use in order to describe the different sections of the paper Academy text.",
            "And in addition to that, we try to manually refine and adapt the rest of the terms to the DMZ main domain.",
            "So we looked into papers from different conferences, for instance 2020 papers, and I looked into them and tried to find OK. How are they?",
            "The scientists are describing the different sections, for instance, how they describe the data set that use which common terms they use usually.",
            "And using the terms in the dictionary, I tried to label the sentences of the publication and in several iteration I checked with also some annotators to check if they are the words in the dictionary.",
            "There are really related or not.",
            "For instance, I saw that if I just use the word data, there are usually these sentences are not related to data set.",
            "But for instance if I combine data from, it's more related to a data set.",
            "So after several iterations.",
            "I've created a dictionary, simple dictionary which this is an example that OK if a sentence contains a word like this research or we aim is mostly related to an objective."
        ],
        [
            "And after.",
            "Several iterations of refinement of this dictionary we try to label the sentences of the publication and try to make a training data for.",
            "Learn learning a binary classifier with some simple TF IDF features.",
            "And.",
            "With this approach, we can generate training data in a very scalable large amount of data, so it's very easier.",
            "It's of course it's very noisy, but still I will show you because we got some reasonable results, and after classifying all the sentences in the publications, we want to extract."
        ],
        [
            "Named entities related to those extracted from those sentences which are related to the DMZ main class."
        ],
        [
            "As you can see here, for instance, a sentence, we utilized Twitter data set this.",
            "A sentence is labeled as data set, for instance, and if we use some named entity extractors in order to extract named entities out of them, we will label also the entities related to those sentences labeled as a data set.",
            "Also, as a data set and for extracting named entities, I use the existing named Entity Extractor takes Razor API, which given a text you can identify text out of it.",
            "And for filtering out the irrelevant words, I tried to use award net and try to filter out the common English words out of the sentences and only keep the domain specific.",
            "Named entities"
        ],
        [
            "The final step was to use the classified sentences and named entities in order to populate the ontology and create the final knowledge repository."
        ],
        [
            "Which is the whole picture is shown here."
        ],
        [
            "And for evaluation we use the around 4000 papers published in different conferences like the Yes WCI C WSM, which is related to social media analytics, VLDB related to databases and www.itsofcourse web, and we generate it's 500 manually annotated sentences which was labeled by two annotators, and we give a set of.",
            "100 sentences from each of the classes, and ask the annotators to check if they are related to the.",
            "Given class or not, and the interactive meant score between them for the average for all the sentences was around 60%.",
            "So it's still even between the annotated sources, not that hide agreement.",
            "And so this is the initial results of our approach.",
            "Given a simple approach, we still got reasonable results, which shows that for different classes we might get different results.",
            "For instance some some classes.",
            "It worked well, but in some other classes it didn't work well.",
            "For instance, for method we got an F score of 0.71, which shows that I think that the.",
            "Language used to describe the medicine sentences more specific in compared to, for instance, the software where it's more easy to make misclassifications so the language used to describe, for instance, data set or software is more complex than compared to the method.",
            "And we also tried to if."
        ],
        [
            "Look at the quality of the extracted named entities where we try to manually check the top 100 entities ranked by the class specific TF IDF where we checked the for instance how many times the entity was labeled as a specific class compared to the ones appeared in the overall sentences.",
            "And then we got again for the method, the highest precision for the objective we were not.",
            "Able to detect some good to results because we saw that objectives are usually not represented well by single entity that you really need this whole sentence or even a paragraph to identify what the objective of the paper is about."
        ],
        [
            "So.",
            "Now that I have talked about what we have done.",
            "Doing in this paper that we published it in.",
            "Yes, I will see I also want to show some examples about how we can make use of this extracted knowledge."
        ],
        [
            "This is a work.",
            "This is under submission, but I wanted to show it show it here so we also follow up research we want.",
            "We worked on a domain specific to topic modeling.",
            "We saw that for the method.",
            "Class we got good results, so we use those.",
            "Entities in order to use it for more effective search for analyzing the digital libraries on.",
            "Also understanding the current trends and developments.",
            "For instance, we tried to as a very quick.",
            "I think that I want to say what we did was try to subsume facet terms.",
            "By facets, I mean the five DMZ main classes based on their semantic similarity which we used the Co occurrence.",
            "And so."
        ],
        [
            "These are some cool applications examples that if we try to do that, we can.",
            "Track the trends of the methods across the different constant conferences and then here is the across the years for we can see, for instance, machine learning and semantic web technologies are gaining more popularity over the time.",
            "However, XML databases at last.",
            "This popular popularity is not popular anymore and another application could be some facet search.",
            "For instance, if you give a query like which methods are commonly applied to IMDb data set?",
            "By giving the spark query we are able to extract some information out of it.",
            "And for future."
        ],
        [
            "Work we saw that some some of the entity named entity extractors for different classes.",
            "It didn't work well.",
            "So are we.",
            "I'm currently working on trying to train and you named entity extractor for detecting data set mentions out of publications and also results and software of course.",
            "And also we would like to because our approach was very simple approach.",
            "We were not focusing on using very complex machine learning algorithms.",
            "We just wanted to check the feasibility of the whole approach.",
            "So I will also want to check with more complex machine learning classifiers.",
            "And feature sets like for instance word emitting an.",
            "Of course at the end.",
            "I also want Briseid scientific publications to use other sources of information to extract knowledge about data processing pipelines from scientific publications.",
            "From about state processing site so."
        ],
        [
            "Thank you and any questions.",
            "Hey, you talked about distant supervision by the talk.",
            "I didn't really get what the distant part would be.",
            "Idea of distance supervision is that you train its classifier using some noisy training data.",
            "This is the idea of distant supervision.",
            "Is not like this tense?",
            "OK, I mean initially you also have some external knowledge base which you use in order not to label all the data and manually sorry, and usually you have some sort of external knowledge base which you use in order not to label the data manually, but you made it in a different way.",
            "Here I assume yes, so I use.",
            "I created a dictionary in order to.",
            "Generate some noisy training data data to train the classifier.",
            "Yeah, first of all, my question relates to that, but I wanted to say this is a very very cool application and great research project.",
            "I would I would love that we had something like that to use for, you know, for related work research.",
            "My question actually relates to that, so use this in supervision, but you actually use this dictionary to label the examples.",
            "So presumably in the dictionary you have some patterns of force is already associated with these classes of sentences, right?",
            "So basically if you see better and then this should be this class.",
            "So then you had results up for the algorithm trained on these on the data labeled with this dictionary.",
            "So what would happen?",
            "What is the baseline would happen if I just use the dictionary to classify sentences?",
            "Because you apparently can just directly apply it without training anything?",
            "Of course, yes, I have the results on any paper, so we used a simple classifier in order to make it more to make the recall a little bit higher to make it more general, generalizable.",
            "But still the dictionary based classifier and the machine learning way.",
            "The results were very close to each other.",
            "Sometimes the recall in the machine learning base was higher, but after that we are now trying on using more features and also more.",
            "Complex classifiers we're getting much better results compared to the dictionary based approach.",
            "I was just wondering, are you making any distinction between how the data set is being used, mean, whether the data set is derived from something else, or the paper is about producing that specific data set and that kind of things work?",
            "No, we just we are looking for dimension of the data set like but that's also part of the.",
            "Then they put it there.",
            "I want to work on it starting next year, which I want to also get more properties of the data set about how it was created and also the date, the properties of the data set itself.",
            "So this is part of the future work that I want to work on.",
            "We have time for other questions here.",
            "Any other questions?",
            "No, OK, so let's thank again our speaker."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Hello everybody, I'm secretary.",
                    "label": 0
                },
                {
                    "sent": "I'm from the web Information System group of Delft University of Technology from the Netherlands and my topic is about semantic annotation of data processing pipelines in scientific publications.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And as you already know and you have heard it a lot during these days, especially during the keynote yesterday and data is everywhere and data science is becoming one of the main challenges that every organization has to face with.",
                    "label": 0
                },
                {
                    "sent": "So there are a lot of people trying to find.",
                    "label": 0
                },
                {
                    "sent": "The different ways, in order to somehow analyze the data and also find ways to make sense of this and make some value out of this data and to face the challenges we need to create some knowledge about how to process this big data and also defined some data processing pipelines which are sequences of operations over this data.",
                    "label": 0
                },
                {
                    "sent": "Um, however, this knowledge is not readily accessible an it's latent in the mind of the people who are doing them or and also in the artifacts that they produce and wouldn't be nice in order.",
                    "label": 0
                },
                {
                    "sent": "If we find ways to.",
                    "label": 0
                },
                {
                    "sent": "Capture this knowledge about how to process big data and translate them into machine processable knowledge.",
                    "label": 1
                },
                {
                    "sent": "For instance, it.",
                    "label": 0
                },
                {
                    "sent": "In this way we can better understand like an example when it's the right moment to apply a fancy deep learning method on a particular data set.",
                    "label": 0
                },
                {
                    "sent": "So this is the vision of my PhD project in general.",
                    "label": 1
                },
                {
                    "sent": "In order to capture knowledge about data processing pipelines, how to process the data and make it available for everybody to use it.",
                    "label": 1
                },
                {
                    "sent": "This knowledge is encoded in the into the different digital artifacts and our goal.",
                    "label": 0
                },
                {
                    "sent": "Our vision is to make this knowledge explicit an make it into a machine processable way which users can make use of it.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So there are if you look at the main information objects that are related to data processing.",
                    "label": 0
                },
                {
                    "sent": "Pipelines are exactly the datasets that we're dealing with which are used to be analyzed and there are the methods that are used to analyze and process the data and also the implementation of those methods.",
                    "label": 0
                },
                {
                    "sent": "For instance, we see that in an experiment that which they are, they are.",
                    "label": 0
                },
                {
                    "sent": "They want to try to classify images.",
                    "label": 0
                },
                {
                    "sent": "For instance an some experiment.",
                    "label": 0
                },
                {
                    "sent": "The scientists they use.",
                    "label": 0
                },
                {
                    "sent": "For instance imagenes datasets, and they apply some LSM.",
                    "label": 0
                },
                {
                    "sent": "Deep learning methods and then which is which they use.",
                    "label": 0
                },
                {
                    "sent": "For instance, the implementation using the tensor flow for instance, and they just get some results.",
                    "label": 0
                },
                {
                    "sent": "And if we translate this kind of knowledge into machine processable knowledge.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Then we will enable a set of use cases which which can be very interesting.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "For instance, we will allow data scientists to answer a set of information needs, like for instance a data scientist in the field of urban planning might be interesting in finding discovering the state of the art.",
                    "label": 0
                },
                {
                    "sent": "Methods for point of interest, that recommendation that have been applied to geolocated social media data with, for instance, good accuracy results.",
                    "label": 1
                },
                {
                    "sent": "Right now there is no system able to answer this kind of queries with a very exact short answer.",
                    "label": 0
                },
                {
                    "sent": "And in order to make this possible, we need to extract knowledge about the data processing pipelines from different sources and for instance we can extract knowledge about.",
                    "label": 0
                },
                {
                    "sent": "Data processing pipelines from scientific publications, which is a very rich source where scientists describe the pipeline that they have used for processing the data or other sources like the code repositories or data set repository's.",
                    "label": 0
                },
                {
                    "sent": "And if we extract knowledge from different sources and try to link them together, we are also enabled.",
                    "label": 0
                },
                {
                    "sent": "Besides answering some information needs, we are also.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Able to better explore digital libraries.",
                    "label": 1
                },
                {
                    "sent": "Since we are extracting knowledge from scientific publication and also the automatic assessment of big data processing.",
                    "label": 1
                },
                {
                    "sent": "So this is the vision of my PhD project and it's good that.",
                    "label": 0
                },
                {
                    "sent": "Still I have three years to go and maybe hopefully some more academic years in front of me.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And so.",
                    "label": 0
                },
                {
                    "sent": "The for this work we decided to focus on the data that the extracting knowledge about data processing pipelines from papers so, but the main challenges that here is that this knowledge is distributed among a vast repository of natural language documents, and also we're dealing with named entities which are very rare and very domain specific.",
                    "label": 0
                },
                {
                    "sent": "And usually there is no.",
                    "label": 0
                },
                {
                    "sent": "Link to the existing knowledge base is So what do we need?",
                    "label": 1
                },
                {
                    "sent": "We need the 1st way to encode and describe the properties of data processing pipelines in a machine readable way.",
                    "label": 1
                },
                {
                    "sent": "And then we need methodology's for the extraction of this knowledge from papers.",
                    "label": 1
                },
                {
                    "sent": "And also a way how to consume this extracted knowledge.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So first I want to talk about how we can describe the knowledge about data processing pipelines.",
                    "label": 0
                },
                {
                    "sent": "This is a work that we already tackled in our previous paper where we tried to design.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Ontology for the description of the data processing pipelines for.",
                    "label": 1
                },
                {
                    "sent": "I won't go much into the details, I just quickly just mentioned it that we use the try to interview the practitioners at the industry and also some data scientists at the University in order to find the relevant terms related to data processing pipelines and try to identify terms.",
                    "label": 0
                },
                {
                    "sent": "And also we relied on the existing ontologies and made use of them when.",
                    "label": 0
                },
                {
                    "sent": "As possible, and finally we try to conceptualize or model.",
                    "label": 0
                },
                {
                    "sent": "This is a very abstract view of of the ontology which is related to this part of the discussion that I want to talk about.",
                    "label": 1
                },
                {
                    "sent": "So the main concepts are data set method and software an in each publication that scientists they describe the pipeline that they have used in by means of an experiment where each experiment uses some data set methods.",
                    "label": 0
                },
                {
                    "sent": "For software for a given objective, and they produce at the end some results.",
                    "label": 0
                },
                {
                    "sent": "So after.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Having this ontology, we want to find ways how to populate this ontology.",
                    "label": 0
                },
                {
                    "sent": "So we want to find ways how to automatically extract knowledge about.",
                    "label": 1
                },
                {
                    "sent": "Dataset, software, method, objective and results over the five main concepts which are named the ontology DMZ model.",
                    "label": 0
                },
                {
                    "sent": "So the five main concepts of the model we want to find ways how to extract this knowledge from scientific publications.",
                    "label": 1
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "An as an example, I would sure like to show you a part of the text of a paper that shows that, for instance, in a paper, scientists describe the data set that they have used.",
                    "label": 0
                },
                {
                    "sent": "And did they describe the method that they have applied on the data set for a given objective?",
                    "label": 0
                },
                {
                    "sent": "And also they have some information about this software's that you have used and also the results that they produce, for instance here they say that they use the Twitter data set and the objective is to annotate mobility data for instance.",
                    "label": 0
                },
                {
                    "sent": "And for doing that they use the kernel density estimation.",
                    "label": 0
                },
                {
                    "sent": "And at the end they got some results, like by measuring the precision and recall.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "By applying the method on a data set.",
                    "label": 0
                },
                {
                    "sent": "So this is exactly the information that the data scientists might need so.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In order to get this knowledge, we just have a very simple approach various baseline approach.",
                    "label": 0
                },
                {
                    "sent": "This is a summary of our approach in this figure where we try to identify the rhetorical mentions of a DMZ main class, which, as I mentioned, data set methods, software result and objectives.",
                    "label": 0
                },
                {
                    "sent": "Which we try to identify the rich parts of the text which contain a mention of those five main classes, and then in the next step from those rhetorical sentences we try to extract named entities.",
                    "label": 0
                },
                {
                    "sent": "And after extracting name density and trying to filter out there irrelevant ones and also a linking linking them to the existing knowledge basis when it's possible.",
                    "label": 0
                },
                {
                    "sent": "We use the extracted named entities and the sentences classified with respect to the five.",
                    "label": 0
                },
                {
                    "sent": "The Ms main classes in order to populate the ontology and create the final knowledge repository.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And the first step is to, given a sentence, we want to classify it with respect to the 5D Ms main classes.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So of course we can use the traditional way and try to use a supervised approach where we try can label all the sentences of publication by using the expert feedback and label all the sentences and use them as a training data for training the classifier.",
                    "label": 0
                },
                {
                    "sent": "However, in our previous work we saw that annotating manually annotating the sentences was very time consuming, so it was not scalable and each publication it took around 30 minutes for them to.",
                    "label": 0
                },
                {
                    "sent": "Annotate them and also it was not that.",
                    "label": 0
                },
                {
                    "sent": "Reliable an, so we decided to go for a distant supervision approach where we try to label the sentences of a publication using a very noisy dictionary based approach, and in this case we can get a lot of training data in order to train a classifier on top of it.",
                    "label": 1
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So for creating for enabling this distance to provision approach, we need to make a dictionary.",
                    "label": 0
                },
                {
                    "sent": "We created the dictionary and this dictionary helps us to cheaply generate some noisy training data for creating the dictionary.",
                    "label": 1
                },
                {
                    "sent": "Used some generic scientific rhetorical phrases.",
                    "label": 1
                },
                {
                    "sent": "We looked into some papers which were giving some advice on how to write the different sections of papers.",
                    "label": 0
                },
                {
                    "sent": "An they give some advice so common phrases which scientists use in order to describe the different sections of the paper Academy text.",
                    "label": 0
                },
                {
                    "sent": "And in addition to that, we try to manually refine and adapt the rest of the terms to the DMZ main domain.",
                    "label": 0
                },
                {
                    "sent": "So we looked into papers from different conferences, for instance 2020 papers, and I looked into them and tried to find OK. How are they?",
                    "label": 0
                },
                {
                    "sent": "The scientists are describing the different sections, for instance, how they describe the data set that use which common terms they use usually.",
                    "label": 0
                },
                {
                    "sent": "And using the terms in the dictionary, I tried to label the sentences of the publication and in several iteration I checked with also some annotators to check if they are the words in the dictionary.",
                    "label": 0
                },
                {
                    "sent": "There are really related or not.",
                    "label": 0
                },
                {
                    "sent": "For instance, I saw that if I just use the word data, there are usually these sentences are not related to data set.",
                    "label": 0
                },
                {
                    "sent": "But for instance if I combine data from, it's more related to a data set.",
                    "label": 1
                },
                {
                    "sent": "So after several iterations.",
                    "label": 0
                },
                {
                    "sent": "I've created a dictionary, simple dictionary which this is an example that OK if a sentence contains a word like this research or we aim is mostly related to an objective.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And after.",
                    "label": 0
                },
                {
                    "sent": "Several iterations of refinement of this dictionary we try to label the sentences of the publication and try to make a training data for.",
                    "label": 0
                },
                {
                    "sent": "Learn learning a binary classifier with some simple TF IDF features.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "With this approach, we can generate training data in a very scalable large amount of data, so it's very easier.",
                    "label": 1
                },
                {
                    "sent": "It's of course it's very noisy, but still I will show you because we got some reasonable results, and after classifying all the sentences in the publications, we want to extract.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Named entities related to those extracted from those sentences which are related to the DMZ main class.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "As you can see here, for instance, a sentence, we utilized Twitter data set this.",
                    "label": 1
                },
                {
                    "sent": "A sentence is labeled as data set, for instance, and if we use some named entity extractors in order to extract named entities out of them, we will label also the entities related to those sentences labeled as a data set.",
                    "label": 0
                },
                {
                    "sent": "Also, as a data set and for extracting named entities, I use the existing named Entity Extractor takes Razor API, which given a text you can identify text out of it.",
                    "label": 0
                },
                {
                    "sent": "And for filtering out the irrelevant words, I tried to use award net and try to filter out the common English words out of the sentences and only keep the domain specific.",
                    "label": 0
                },
                {
                    "sent": "Named entities",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The final step was to use the classified sentences and named entities in order to populate the ontology and create the final knowledge repository.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Which is the whole picture is shown here.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And for evaluation we use the around 4000 papers published in different conferences like the Yes WCI C WSM, which is related to social media analytics, VLDB related to databases and www.itsofcourse web, and we generate it's 500 manually annotated sentences which was labeled by two annotators, and we give a set of.",
                    "label": 1
                },
                {
                    "sent": "100 sentences from each of the classes, and ask the annotators to check if they are related to the.",
                    "label": 0
                },
                {
                    "sent": "Given class or not, and the interactive meant score between them for the average for all the sentences was around 60%.",
                    "label": 0
                },
                {
                    "sent": "So it's still even between the annotated sources, not that hide agreement.",
                    "label": 0
                },
                {
                    "sent": "And so this is the initial results of our approach.",
                    "label": 0
                },
                {
                    "sent": "Given a simple approach, we still got reasonable results, which shows that for different classes we might get different results.",
                    "label": 0
                },
                {
                    "sent": "For instance some some classes.",
                    "label": 0
                },
                {
                    "sent": "It worked well, but in some other classes it didn't work well.",
                    "label": 0
                },
                {
                    "sent": "For instance, for method we got an F score of 0.71, which shows that I think that the.",
                    "label": 0
                },
                {
                    "sent": "Language used to describe the medicine sentences more specific in compared to, for instance, the software where it's more easy to make misclassifications so the language used to describe, for instance, data set or software is more complex than compared to the method.",
                    "label": 0
                },
                {
                    "sent": "And we also tried to if.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Look at the quality of the extracted named entities where we try to manually check the top 100 entities ranked by the class specific TF IDF where we checked the for instance how many times the entity was labeled as a specific class compared to the ones appeared in the overall sentences.",
                    "label": 1
                },
                {
                    "sent": "And then we got again for the method, the highest precision for the objective we were not.",
                    "label": 1
                },
                {
                    "sent": "Able to detect some good to results because we saw that objectives are usually not represented well by single entity that you really need this whole sentence or even a paragraph to identify what the objective of the paper is about.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Now that I have talked about what we have done.",
                    "label": 0
                },
                {
                    "sent": "Doing in this paper that we published it in.",
                    "label": 0
                },
                {
                    "sent": "Yes, I will see I also want to show some examples about how we can make use of this extracted knowledge.",
                    "label": 1
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This is a work.",
                    "label": 0
                },
                {
                    "sent": "This is under submission, but I wanted to show it show it here so we also follow up research we want.",
                    "label": 0
                },
                {
                    "sent": "We worked on a domain specific to topic modeling.",
                    "label": 0
                },
                {
                    "sent": "We saw that for the method.",
                    "label": 0
                },
                {
                    "sent": "Class we got good results, so we use those.",
                    "label": 0
                },
                {
                    "sent": "Entities in order to use it for more effective search for analyzing the digital libraries on.",
                    "label": 1
                },
                {
                    "sent": "Also understanding the current trends and developments.",
                    "label": 1
                },
                {
                    "sent": "For instance, we tried to as a very quick.",
                    "label": 0
                },
                {
                    "sent": "I think that I want to say what we did was try to subsume facet terms.",
                    "label": 0
                },
                {
                    "sent": "By facets, I mean the five DMZ main classes based on their semantic similarity which we used the Co occurrence.",
                    "label": 1
                },
                {
                    "sent": "And so.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "These are some cool applications examples that if we try to do that, we can.",
                    "label": 0
                },
                {
                    "sent": "Track the trends of the methods across the different constant conferences and then here is the across the years for we can see, for instance, machine learning and semantic web technologies are gaining more popularity over the time.",
                    "label": 0
                },
                {
                    "sent": "However, XML databases at last.",
                    "label": 0
                },
                {
                    "sent": "This popular popularity is not popular anymore and another application could be some facet search.",
                    "label": 0
                },
                {
                    "sent": "For instance, if you give a query like which methods are commonly applied to IMDb data set?",
                    "label": 1
                },
                {
                    "sent": "By giving the spark query we are able to extract some information out of it.",
                    "label": 0
                },
                {
                    "sent": "And for future.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Work we saw that some some of the entity named entity extractors for different classes.",
                    "label": 0
                },
                {
                    "sent": "It didn't work well.",
                    "label": 0
                },
                {
                    "sent": "So are we.",
                    "label": 0
                },
                {
                    "sent": "I'm currently working on trying to train and you named entity extractor for detecting data set mentions out of publications and also results and software of course.",
                    "label": 0
                },
                {
                    "sent": "And also we would like to because our approach was very simple approach.",
                    "label": 0
                },
                {
                    "sent": "We were not focusing on using very complex machine learning algorithms.",
                    "label": 0
                },
                {
                    "sent": "We just wanted to check the feasibility of the whole approach.",
                    "label": 0
                },
                {
                    "sent": "So I will also want to check with more complex machine learning classifiers.",
                    "label": 1
                },
                {
                    "sent": "And feature sets like for instance word emitting an.",
                    "label": 0
                },
                {
                    "sent": "Of course at the end.",
                    "label": 0
                },
                {
                    "sent": "I also want Briseid scientific publications to use other sources of information to extract knowledge about data processing pipelines from scientific publications.",
                    "label": 1
                },
                {
                    "sent": "From about state processing site so.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Thank you and any questions.",
                    "label": 0
                },
                {
                    "sent": "Hey, you talked about distant supervision by the talk.",
                    "label": 0
                },
                {
                    "sent": "I didn't really get what the distant part would be.",
                    "label": 0
                },
                {
                    "sent": "Idea of distance supervision is that you train its classifier using some noisy training data.",
                    "label": 0
                },
                {
                    "sent": "This is the idea of distant supervision.",
                    "label": 0
                },
                {
                    "sent": "Is not like this tense?",
                    "label": 0
                },
                {
                    "sent": "OK, I mean initially you also have some external knowledge base which you use in order not to label all the data and manually sorry, and usually you have some sort of external knowledge base which you use in order not to label the data manually, but you made it in a different way.",
                    "label": 0
                },
                {
                    "sent": "Here I assume yes, so I use.",
                    "label": 0
                },
                {
                    "sent": "I created a dictionary in order to.",
                    "label": 0
                },
                {
                    "sent": "Generate some noisy training data data to train the classifier.",
                    "label": 0
                },
                {
                    "sent": "Yeah, first of all, my question relates to that, but I wanted to say this is a very very cool application and great research project.",
                    "label": 0
                },
                {
                    "sent": "I would I would love that we had something like that to use for, you know, for related work research.",
                    "label": 0
                },
                {
                    "sent": "My question actually relates to that, so use this in supervision, but you actually use this dictionary to label the examples.",
                    "label": 0
                },
                {
                    "sent": "So presumably in the dictionary you have some patterns of force is already associated with these classes of sentences, right?",
                    "label": 0
                },
                {
                    "sent": "So basically if you see better and then this should be this class.",
                    "label": 0
                },
                {
                    "sent": "So then you had results up for the algorithm trained on these on the data labeled with this dictionary.",
                    "label": 0
                },
                {
                    "sent": "So what would happen?",
                    "label": 0
                },
                {
                    "sent": "What is the baseline would happen if I just use the dictionary to classify sentences?",
                    "label": 0
                },
                {
                    "sent": "Because you apparently can just directly apply it without training anything?",
                    "label": 0
                },
                {
                    "sent": "Of course, yes, I have the results on any paper, so we used a simple classifier in order to make it more to make the recall a little bit higher to make it more general, generalizable.",
                    "label": 0
                },
                {
                    "sent": "But still the dictionary based classifier and the machine learning way.",
                    "label": 0
                },
                {
                    "sent": "The results were very close to each other.",
                    "label": 0
                },
                {
                    "sent": "Sometimes the recall in the machine learning base was higher, but after that we are now trying on using more features and also more.",
                    "label": 0
                },
                {
                    "sent": "Complex classifiers we're getting much better results compared to the dictionary based approach.",
                    "label": 0
                },
                {
                    "sent": "I was just wondering, are you making any distinction between how the data set is being used, mean, whether the data set is derived from something else, or the paper is about producing that specific data set and that kind of things work?",
                    "label": 0
                },
                {
                    "sent": "No, we just we are looking for dimension of the data set like but that's also part of the.",
                    "label": 0
                },
                {
                    "sent": "Then they put it there.",
                    "label": 0
                },
                {
                    "sent": "I want to work on it starting next year, which I want to also get more properties of the data set about how it was created and also the date, the properties of the data set itself.",
                    "label": 0
                },
                {
                    "sent": "So this is part of the future work that I want to work on.",
                    "label": 0
                },
                {
                    "sent": "We have time for other questions here.",
                    "label": 0
                },
                {
                    "sent": "Any other questions?",
                    "label": 0
                },
                {
                    "sent": "No, OK, so let's thank again our speaker.",
                    "label": 0
                }
            ]
        }
    }
}