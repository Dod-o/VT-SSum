{
    "id": "775vvskzxhof3az5vdfbizo4plsdjo5u",
    "title": "Simplifying Complexity with Quantum Mechanics",
    "info": {
        "author": [
            "Mile Gu, Centre for Quantum Technologies"
        ],
        "published": "April 3, 2017",
        "recorded": "March 2017",
        "category": [
            "Top->Science->Complexity Science",
            "Top->Computer Science",
            "Top->Data Science",
            "Top->Mathematics",
            "Top->Physics"
        ]
    },
    "url": "http://videolectures.net/NTUcomplexity2017_gu_quantum_mechanics/",
    "segmentation": [
        [
            "Thank you very much.",
            "So yeah, how many people here was at my talking paradigms.",
            "First of all, OK, so not too many.",
            "So for those who are there, that's So what I want to do in this talk is to sort of in that talk.",
            "It was kind of overwhelming amount of information, so in this one, what I want to do is focus on sort of some of the more specific stuff, and to sort of look at.",
            "Look at this idea of look at this idea of complexity in detail.",
            "So I'm not going to talk too much about quantum mechanics, what I want."
        ],
        [
            "To do here is again give a broad overview of the field of information theory, and so maybe touch up on how to SIM."
        ],
        [
            "Fiatt with quantum mechanics at the very end, and so that information theory, I think it's really at the heart of a lot of quantitative science, so tough when people first hear sort of my dual affiliation.",
            "So the first with the Complexity Institute and with the Center for Quantum Technologies.",
            "That sounds sort of like quite a strange combination because these two Sciences seem well could not be further apart.",
            "I mean on one side when we think about complexity, we think about massive macroscopic systems, networks off.",
            "Interacting components sort of at the everyday level with some people think about quantum science.",
            "They tend to think about things at the level of photons and atoms, and at first you know we see that these two theories happen in very different regimes, and it's strange to sort of have any synergy between these two fields at all.",
            "In fact, the main reason why so much of the techniques between the two fields map to each other is because a lot of a major component of these fields deals with the propagation.",
            "Understanding of information.",
            "And so the heart of really what this talk is going to be about is about information, and I think we've heard so that people briefly talk about that sort of thing.",
            "Brian Asses, talk earlier and stewards talk last week where people have sort of mentioned this idea of information propagation innovation.",
            "So what I want to do is go beyond these buzzwords and still give you a formal idea of what information theory means and how it can be used to understand reality so."
        ],
        [
            "Begin with something that maybe is probably the most accessible notion of information the movie The matrix.",
            "So who he has seen the matrix?",
            "Anyone not seeing the matrix?",
            "OK, pretty much right, so I don't have to worry about spoiling this movie for anybody.",
            "So here's the guy, the star of the Matrix."
        ],
        [
            "And as you know them, the basic premise is that where you know that his lands in this world where everything appears real, he can touch and he can feel everything thinks he's living in reality.",
            "But in actuality he."
        ],
        [
            "Living in this digital computer simulation where everything is in terms of birds.",
            "Now this sort of this was a science fiction movie, but it's actually a bit closer to the truth than we think.",
            "Well, we orderly think in fact some very prominent."
        ],
        [
            "Scientists USS Lloyd from MIT black of a drought from here in Singapore.",
            "Actually, as well as Oxford.",
            "They're both written books on this stuff.",
            "Programming reality, the coding or decoding reality program with the universe, and there are sort of this increasing amount of evidence that whether not the universe, whether not it is not, whether or not it is simulated, could be simulated.",
            "This sort of all physical measurements so far haven't really isolated out the possibility that we are living in a simulated universe.",
            "And so things like the holographic principle, that sort of we hear about with all about this idea of sort of the universe is really encoding the simulation.",
            "And the reason why at the heart of this is because when we think about it."
        ],
        [
            "And I think we take this for granted, so I think we're sort of in the afternoons.",
            "You're simulating various things like flight networks.",
            "We've talked about simulating all sorts of different phenomena so far in this winter school, and sort of when you think about, it's quite strange weather you take the LHC so that works on the nuclear weak nuclear strong force, particle physics.",
            "You look at fluid mechanics, which operates sort of using sort of electromagnetic forces and gravity.",
            "You look at cosmology, which is in the macroscopic scale using the force of gravity.",
            "All these things very different forces.",
            "Very different physical systems, and yet we can always simulate well.",
            "We always try to it at least, and we always believe that we can in principle simulate them on computer.",
            "Now what at the heart is a computer?",
            "Well, a computer doesn't run gravity, and it certainly doesn't run on.",
            "Sort of.",
            "The stronger the weak nuclear forces it runs, mainly on the electromagnetic force.",
            "So somehow, despite the fact that these are very different architectures using very different physical systems.",
            "We can all understand them using sort of the humble computer, and I think this point is often overlooked and underappreciated, even those that have we do that every day, and it's.",
            "And it's really a very strange property of the universe that we can do this when you think about it.",
            "This your computers of sitting there in front of you, and you can simulate anything you like with it.",
            "And this, in fact, is actually a law.",
            "It's called the church.",
            "The Deutsch Church, Turing principle, and it basically states that.",
            "For some reason, in our reality, every physically reasonable process can be simulated by universal computing device.",
            "Now for the purpose of this talk, you can think about the universal computing devices.",
            "Just your notebook computer, so it's slightly more sophisticated, but it's essentially is basically a piece of computing hardware, and I think this is one of the sort of this is one of the laws that one cannot mathematically prove it.",
            "And it just happens to be true for our universe, and that's the reason why we are really here talking about how we can simulate and understand reality using certain agent based models and using all sorts of other sort of sophisticated computer programming languages as because of this interesting fact.",
            "And so."
        ],
        [
            "What this really means is that when we think about understanding the universe, we can think about it in two different pictures.",
            "So the traditional picture.",
            "I think this is sort of many quantitative science, especially physics up tell about the 1960s, is this idea of sort of you do experiment so you have some information describing how you set up this experiment, and then you climb a tower like the Leaning Tower pizza in your drop these two balls down, see how they fall.",
            "That's your physical process.",
            "We harness something in physics.",
            "Oh, or something in reality.",
            "And then afterwards we observe the outcome and.",
            "This is a standard view, however, we can think about everything really as information processing because the experimental setup, well, we just described that using information we can write down how we're going to set up the experiment, what all the initial conditions are then the.",
            "Actual physical process by the Church Turing thesis can be simulated by on a computer.",
            "It's equivalent, in essence, to processing the input information and then afterwards we take what happens in our physical system.",
            "Of course, is we observe the output and record that also in terms of information we write down what we have observed.",
            "And that's really just output information information processor.",
            "So these two views of reality are actually essentially equivalent.",
            "We can think about ourselves as sort of performing physical tasks.",
            "We set something up.",
            "We look at how involved we do experiment with user results, but when we're doing that, we're essentially performing a computation using a particular physical device.",
            "And similarly, when we run a simulation or computer, what we're really doing is we're configuring the computer in some initial state where getting the computer to run a physical process, and then we're doing some sort of measurement on it by observing the output on the screen.",
            "So these two pictures.",
            "A very very similar and it gives us a new way of understanding reality.",
            "Because this picture here you see applies to any experiment we can do in the real world, and so if we can understand how information evolves and if we can understand the properties of how we can process information, then that sort of gives us general understanding about sort of what sort of 4th physical processes are possible and how we can model these physical processes.",
            "So this I think is the main theme of this talk and this is what we shall explore."
        ],
        [
            "So to give you an idea of sort of how powerful sort of what sort of.",
            "What sort of things we can meet here come up using this framework.",
            "There was as famous questions asked by Philip Anderson, Nobel Laureate in 1972.",
            "Well, I think he might have gotten Nobel Laureates Nobel Prize a little earlier, but he probably he published his question in 1972, which is that can all properties he asked can, all macroscopic properties be explained by their macroscopic components?",
            "So Phillip Anderson will sort of accountants matter physicist, and at that time most people.",
            "Most scientists thought that we could reduce everything in reality to sort of a fundamental theory of fundamental particles.",
            "So once we understand how electrons and how photons involved, we can use that to build up a picture of our atoms will react, we can use that to build up a picture of chemistry.",
            "Biology, explain human society, etc.",
            "So it was a very rosy picture and it was captured by sort of Ernest Rutherford, who said that everything is physics or stamp collecting.",
            "So you either don't real science.",
            "Oh, just collecting a bunch of facts.",
            "So Phillip Anderson was one of the first prominent physicist to challenge this view because he didn't believe that condensed matter theory so that the loss or macroscopic matter can be explained by fundamental principles.",
            "So he posed this question come all properties of a macroscopic system be really understood by its microscopic constituents.",
            "So can we sort of take, for example, fluid mechanics, and we look at the interactions between every individual Atom and use that to sort of understand.",
            "And arrives at the Navier Stokes equation."
        ],
        [
            "And this is sort of the view.",
            "Now we using sort of language of information theory.",
            "We can have a good answer to it.",
            "Because what we find is that.",
            "In computer science, there's this notion called the halting problem, which says that if I have a computer program.",
            "And I want to know what it's going to do that.",
            "So what is long-term behavior is?",
            "For example, is that going to halt is they're going to run for a set amount of time and eventually stop?",
            "Or is there kind of going into infinite loop and never end so this?",
            "What's called the halting problem, and it turns out that one can prove mathematically that if once given the general program, there's no systematic way to know whether or not it will eventually stop running.",
            "So there are long-term behaviors of computer programs that we cannot ever sort of formally compute.",
            "But if we start thinking about a computer program as a physical system, then this automatic."
        ],
        [
            "Also set a even if we were able to find a fundamental theory of everything, the certain properties about that physical system, sort of certain macroscopic properties about that physical system that we can never sort of evaluate, and so have this one sort of highlighted in this article in nature in 2009, in the sense that it was the first sort of formal proof of innocence emergence that even if we had a fundamental understanding of macroscopic particles because of the nature.",
            "Of information processing, then, it's still formally noncomputable to find that older macroscopic properties that when you sort of put together a lot of these particles well, how they will behave and this sort of sort of captures this idea that information and physics is deeply intertwined and by understanding how information evolves and sort of what our capabilities are in looking at computer programs, we can understand ultimately properties about the physical universe.",
            "And I guess coming from the perspective of physicists, this is what I find the most interesting about information theory."
        ],
        [
            "And so this is really the theme about this talk and specifically what I want to tell you today is about how information theory can help us sort of understand structure and complexity.",
            "And so I'm going to take her information theoretic point of view and look at complex processes as information processing and one of the frameworks to do that is this sort of subfield of complexity theory known as computational mechanics.",
            "So in this lecture what I will do is I will sort of introduce computation mechanics.",
            "I'll give a simple example.",
            "I'll introduce sort of how we quantify information, and I will sort of demonstrate sort of what it means to explain something more simply in terms of information.",
            "Theory and this gives us this idea of how to actually quantify structure in complex systems.",
            "And finally, if I have time, I'll talk about how these notions all change once we get to the world of quantum mechanics."
        ],
        [
            "So the basic idea is if we had some physical system out there.",
            "So what we are observing from it is bit of data.",
            "What we observing is information.",
            "We record pieces of information we never really do.",
            "Anything else doesn't record information.",
            "When we do experiment, we make a management.",
            "It's all information.",
            "So basically every physical system you can think about it as a black box.",
            "Let's just throwing out bits of data and what we are."
        ],
        [
            "Thing to do when we try to understand something or model something.",
            "We're trying to build a model that replicates that data.",
            "So we got the statistics out there and we want to sort of understand.",
            "OK, can we sort of describe it in some sort of model?",
            "Hopefully this model, then we can put sort of input into our computer so we can write down the initial conditions and then we can see what is how it's going to behave in the future.",
            "So really, the process of quantitative science is a process of mathematical abstraction.",
            "We want to try to represent.",
            "So observations in terms of equations, agent based models only, other mechanism for taking past information and using it to generate future behavior."
        ],
        [
            "And what happens is when we do this, there are many different possible models.",
            "So the."
        ],
        [
            "We can have many different ways of getting the same behavior, and the idea is that we want to sort of once we've given sort of many different models and safe to give the same behavior, then the question will be OK.",
            "Which model gives us a simplest understanding?",
            "Which model is which model do we prefer?",
            "Is there sort of?",
            "How do we sort of a judge sort of whether one explanation or one model of the system is better than other?",
            "So which one is more captures more?",
            "Of sort of what they observe or captures the essence of what we observe."
        ],
        [
            "And what I want to do to get some intuition on this is to go through a very simple example first.",
            "So imagine we had a system like this and we had a sequence of data, and once you know we do a lot of measurements, we find that the distinguishing feature about the sequence of data is that two consecutive bits always the verb roughly by a probability of 0.2.",
            "So we look at sort of two bit correlations and we look down.",
            "We see ha, which probably 0.2.",
            "Each part is different from its previous, but so we have sort of.",
            "We have sort of object that that does this and we want to be the model and so so to make some simple for you we have given sort of."
        ],
        [
            "Possible models as this is sort of our first day at work I suppose.",
            "So the first model year something like this we take a box and we have a single coincided and we shake this box so that with probability 0.2 the coin flips.",
            "You can zero in one and then we just output the state of the coin so you can see that this process is definitely going to generate the right statistics if we if it sometimes that we got zero then there's always going to be the probability of 0.2 that we flip.",
            "So we can go OK. One way of sort of modeling this behavior is to think about it as a box with a single coin inside which we just flip and we program this on a computer and we get the right statistics.",
            "We can think about another model, maybe some other person came up with this model.",
            "She said yeah, but I have a different idea.",
            "Why don't like a 2 boxes and have a coin in each box and what I'm going to do is at each time step I'm going to choose one of these boxes at random and I'm going to flip it with probability 0.2 and then I'm going to compare the coins and if they have the same, I'm going to output one, and if they are different I'm going to output 0.",
            "Now if you think about it fairly carefully this the output statistics of this system is exactly the same as the outlets that fixes that system, so they both.",
            "Equally valid models of the observer behavior.",
            "But could I get hands upon who prefers the first model?",
            "Who prefers the second model?",
            "OK, great so uh OK so most of us I think except maybe a few exceptions like models which are simpler.",
            "Of course I guess this is probably more fun to Bude, but usually we tend to.",
            "We tend to take the lazy approach right where we are writing a computer program like this is going to take like 30 lines of code and this might only take 10 and we tend to think OK, this just when I look at this I immediately see what's going on, what's going to happen when I look at this model.",
            "I have to think a bit harder about it so."
        ],
        [
            "Generally this seems better and this is sort of a intuition that we want to capture using information theory, because ultimately, I mean I'm a physicist and what physicists do is they want to capture intuition in terms of mathematics, and I think that really captures the heart of what physics is about.",
            "It's sort of.",
            "We've got some concept out there like energy which you know 1000 years ago.",
            "People just said a laugh is more powerful than you rock because he can punch a hole in this rock.",
            "And I mean that's a good measure.",
            "But when we want to understand energy and power later.",
            "In physics sort of defines or stuff like Watts and Joules so that we are better able to quantify it, and we want to quantify this notion of seemingly better as well.",
            "And to do that we need a quantifier of information theory."
        ],
        [
            "So how do we formalize this intuition?"
        ],
        [
            "The way to think about formalizing this intuition is from the perspective of oh comes razor, so so comes razor is sort of the words first proposed by Guy by the name of William Welcome.",
            "He was the first to think deeply about this problem.",
            "He was thinking, well, OK, plurality should not be sort of positives of necessity.",
            "Now this is a bit of a mouthful, so I prefer this notion by Isaac Newton, who said OK, we should know more causes of natural things in both true, insufficient to explain their appearances.",
            "So what these guys were getting at is that the notion of being better in this case is the idea that.",
            "Model is simpler if it uses less information about sort of.",
            "It requires us to posture less information about what has happened before.",
            "To be able explain these statistics.",
            "So in the cases previous we had one coin or two coins and the one point some simpler and to allow."
        ],
        [
            "Straight is more generally, here we have another case of a newtons falling Apple and the reason why we like Newton's laws which they have allows us to basically compute the trajectory of the Apple by knowing it's only initial position velocity and the reason we like this is because if we can formulate alternative."
        ],
        [
            "I'll say it, sort of.",
            "We can certainly formulate alternative models like using the entire path trajectory of this Apple.",
            "Also the path."
        ],
        [
            "Play some pool to the ground by some invisible appendages of a flying spaghetti monster, but we tend to think about these inferior because they require us to store or more information about the world than is necessary.",
            "You have the store sort of at the entire path project of this Apple, like who picked it, which Orchard was growing?",
            "If we can predict the future without knowing this information, then there shouldn't be any reason why we want to store it inside our model."
        ],
        [
            "And so, as you can see with this intuition here, we can see that the first model looks superior because it requires only one bit of information, whereas the second model seems to require 2 coins.",
            "So 2 bits of information.",
            "And so let's formalize this further, what do we mean by a bit of information?"
        ],
        [
            "A sort of what we can we so formalize this idea of this interest?"
        ],
        [
            "And let's see."
        ],
        [
            "Do that.",
            "To give a quick crash course on quantifying information.",
            "So this is the idea of Shannon entropy, who here has heard of Shannon entropy before.",
            "And he has worked with Shannon entropy.",
            "OK, great, so let's let's quickly go through such an engine because I think this stuff is really important in so many different fields.",
            "From artificial intelligence to physics, thermodynamics.",
            "So it's really good to sort of know it regardless."
        ],
        [
            "And so the basic idea of Shannon entropy is it's a quantifier of information.",
            "When it boils down to it, what information is is about answering questions, yes or no, and in particular we can boil that down to a unit of information with answering yes and no questions, and what Shannon entropy is capturing is how many sort of saying OK, if we have a random variable, the amount of information contains is how many yes or no questions on average.",
            "I have to ask to know the value of that random variable and the best way to illustrate this is by example.",
            "So here we have a very simple example.",
            "We have sort of a random variable that can take on two values, zero and one with probability of 0.5 each time.",
            "And so the best way sort of one way of sort of asking the question in the the best way, and probably the only way because it's such a simple example used to ask OK is X0 is X one.",
            "So this is a yes, no question.",
            "If someone answers yes you know it is zero.",
            "You someone else is now you know X is equal to 1 and so we see that this one yes or no question.",
            "So a point fair coin contains 1 bit of information, so so that.",
            "So what that captures is that if you don't know what the state of random coin tosses then then you can ask one question to know what that is.",
            "So the state of a random coin toss contains exactly 1 bit of information.",
            "Or if you don't know what it is, it contains 1 bit of uncertainty and so this is the basic idea behind Shannon entropy.",
            "So let's do a slightly more complicated example.",
            "Suppose we have random variables that can take four different values.",
            "012 and three always probability of 1/4.",
            "Then you want to guess how many bits of information this contains.",
            "No need to be shy, could guess.",
            "2.",
            "The reason is that we can come up with this sort of a example.",
            "We can sort of ask.",
            "First of all, is the ex even, and that tells us OK with it's 02 or with this one or three and depending on sort of answered the first question, we ask the correct second question and then what happens is that we can now isolate down to each of these four possibilities.",
            "So we end up with two bits of information.",
            "And indeed if you have.",
            "Random variable that takes a even distribution of sort of two to the end different probabilities.",
            "So you can imagine you can just scale this tree and so so any random variable is 2 to the end.",
            "Different possibilities takes exactly inputs contains exactly in bits of information, or it has a Shannon entropy of N. Now we can also think about random variables where the probabilities are non uniform.",
            "So here's another sort of example here.",
            "We still have 4 probabilities, but now the coin.",
            "Has a higher chance of being zero than any of the other.",
            "And then any of the other possibilities.",
            "And so this turns out to be able to modify the average number of questions that we need to ask so tough.",
            "So let's walk through this question in detail.",
            "So what has different ways of doing this?",
            "Let's work with this.",
            "So.",
            "We can of course, naively goes through the same example as we did before, so we can still use this strategy here, but we can see that that will require two questions.",
            "Does anyone have any ideas of?"
        ],
        [
            "How to do better than two questions and you want to try?",
            "No need to be a shark.",
            "OK, I'm going to point somebody out.",
            "So how about you do what first question would you ask?",
            "Yes or no questions.",
            "Other, Even so, we could do that.",
            "So if we had other events, so let's say X Even so, what we end up here is we've got zero, yes, then we've got 02, one or three.",
            "But now we kind of stuck always asking the second question right because we don't know if it's 02 here.",
            "We don't know whether it's one or three here, so we have to always ask the second question.",
            "So we end up asking 2 questions.",
            "Is it possible to reduce that on average so that the only way to do that is if one does not someone else have idea?",
            "Listen now.",
            "So is it zero?",
            "Yeah, great.",
            "So instead of asking is X even we're going to ask.",
            "I'm going to waste paper here, so hopefully no one will not video type too much for this.",
            "OK, so X is X0.",
            "So now if it is 0 so if this is yes then we get zero and we're done.",
            "We don't have to ask anymore and here now we have three possibilities though 1, two or three.",
            "So what's the next question someone wants to ask?",
            "Is that one OK?",
            "So let's ask is at one.",
            "So here we have one and then we have two or three here.",
            "So of course we have to ask is at 2 and if we ask is a two and then we get yes or no?",
            "And then we can get two or three.",
            "So now we get this tree 0123 and now it looks a little.",
            "It looks like sometimes we asking 3 questions, so it's not so good, but if we look at this tree here and indeed this is the correct re, what happens?",
            "Is that because zero is very likely there is a good chance that we can finish with just one question, which is great.",
            "And because two and three are unlikely, there's not that much chance that we're going to end up asking 3 questions, and indeed one can sort of calculators.",
            "I just waiting the number of questions with the probability that we will ask them so, so it's probably half will ask a single question with probably 1/4.",
            "Will ask two questions.",
            "What was probably 1/8 will ask three questions and with another probability one it will ask three questions.",
            "And if we compute that as equal to 1.75.",
            "So we are able to sort of compress the number of questions we need to ask instead of asking a whole 2 questions, we can ask 1.75 questions and in fact this sort of encoding process is used all the time in terms of basic communication theory, because when we look at, say, the English language for example, the letters do not all occur with equal probability, so that the letter E occurs much more often than says the letter X and anyone can play Scrabble will know this.",
            "You know you get way more points.",
            "If you sort of come up with the word with Xposed unit, So what this means is that when we are storing this sort of information, computer Western bits of data and what each bread contains is just a yes or no question.",
            "So the first bit could sort of content use this letter of Al.",
            "Or is that a consonant, for example, and that could be one.",
            "But that's stored, and So what we're doing is we're transforming this, let Alphabet into a stream of bits of data, and each breath is one of these.",
            "Yes, no questions.",
            "So for example, if we wanted to encode.",
            "In Code 10 here we can write 00 yes and if we want to record one, we do right now yes, and that would be a way of sort of encoding this data in a sequence of yes or no questions, and that's all what a computer does, and if we can find more efficient encodings, then we can transmit the same information using less data.",
            "So this is a fundamental foundations of sort of information communication and that all sort of gives us is captures intrinsic property of how many bits of information or random variable contains.",
            "And this this quantity turns out to be very useful for us, so let's."
        ],
        [
            "Write down the actual equation.",
            "I think we pretty much have a good idea now, because what we've done is we've taken the probability of a random variable being a particular value X and we multiplied by the log.",
            "If we think carefully about this, this is log of one over the probability of that happening.",
            "So for example when we when it happened 1/8 of the time, we're taking the log base two of a. I should mention that this log is allowed based 2 information theory because we're dealing with bits, the logarithms is always taken base two, SO 2 to the power of three is equal to 8.",
            "So the log of eight is equal to three, and we have three here, and we know that log of 1 / P X is just equal to minus of log of PX, so this we can get this general equation for the Shannon entropy is just equal to the sum of all possible values that X can take.",
            "One of the product of the probability it takes that value versus a log of that probability."
        ],
        [
            "So we have this idea of Shannon entropy and this is sort of the tool that we use to be able to stuff, say which model uses more information or which model uses less information."
        ],
        [
            "And so, in general, here's a picture of anatomy of a bit of how much information it contains, so we've ascertained that when we have an equal distribution, we get sort of an average.",
            "We only ask a single question if of course if we are at the top or at the bottom.",
            "So if something is always at zero and something is always at one.",
            "Then we don't need to ask any questions, so the entropy is 0.",
            "And as we get more biased towards so, if we had a probability to distribution that is biased towards zero bias towards one.",
            "That the entropy kind of slides continuously between one and zero, and this corresponds to the idea that if we had, if we had many sort of many of those random variables, so it turns out that to be able to set up to communicate all the information they contain, we can actually compress the number of yes, no questions using sort of a slightly more sophisticated technique, But essentially this sort of decision tree, and so this is a very nice part about Shannon entropy, and indeed for a binary variable we get this equation here.",
            "And we get sort of this slide with the brightest point.",
            "Here, higher entropy is in the in the middle with the lowest entropy at the sides.",
            "So this is all I will say about entropy."
        ],
        [
            "And we can now go back to sort of our understanding models.",
            "So here are model A that was just a single variable that happened with equal probability.",
            "So it has an entropy of 1.",
            "Here we have a model where we had two coins and all four possibilities happen with equal probability.",
            "So communicate the state of the two coins.",
            "When the two yes or no questions and so we can see that just from this formal information theoretic perspective, this model is simpler distance model that replicates the future using less information and so.",
            "In general, what's considered the preferred model and using this framework of information theory?",
            "We can now formalize the idea of occum's razor in the language of mathematics.",
            "We could say that if two models make statistically identical predictions, then the model that requires the least amount of input information or the least amount of information about its internal state is preferred."
        ],
        [
            "And and we've kind of went over this just before, but I'd like to reiterate.",
            "So the relation between this simulation physics because the reason why we prefer these simpler models is because.",
            "If we had, if any model to be able to execute it, we need to run it on a computer, and so if our model requires inputs with a certain amount of entropy, there are physical system must have at least that much memory to be able to execute the simulation.",
            "So the task of building simpler models allows us to store less information and therefore set up to be able to simulate.",
            "View the simulation using sort of less memory."
        ],
        [
            "And this can be summarized again, going back to the Matrix and matrix problem.",
            "So now the idea is a computer overlords have taken over the world an you they've captured you and your task to build the ultimate simulation for sale bending spoon and the question is how do we do this while stirring the least amount of information about the past?",
            "Because these computer overlords are actually quite stingy and solar power is limited.",
            "Since you know we well human battery power is limited I guess.",
            "So how do we sort of do this?",
            "At least amount of hard drive space?"
        ],
        [
            "And what I want to sort of discuss in formalizes how much time do I have, by the way.",
            "OK, great, so we have plenty of time to do this so that I want to solve discusses quickly in the context of sort of the example that motivated this whole situation, which is a case which is basically special example of a class of problems where we have we have a subject there.",
            "And we can see it so that we can sort of measure the discrete points in time and the question is how much information do we need to record about the past to be able to generate a good statistical replication of the future?",
            "And the idea is we want to store everything about the past in the present inside our model, so we can discard the past and so we can sort of generate the future purely from this stuff in this box and we can capture the complexity of our model or how good it is by the entropy of this box, which is just this.",
            "Defined by the Shannon entropy of the box, so the box can take various states with certain probabilities.",
            "From that we can sort of capture how much information we need to be able to store the contents of the box."
        ],
        [
            "And in particular, in our special case with the case where when we looked at each one of these random variables, consecutive ones deferred by a probability of Scipy which was equal to 0.2.",
            "Now let's let's take a look."
        ],
        [
            "So the way to do this?",
            "OK, the brute force method of causes to record and type fast.",
            "We can always sort of replicate the right future statistics if we just recorded everything about the past, but we see that that's going to take a lot of information, and that's probably not a good idea.",
            "So let's see if we can do something simpler and turns out that computational mechanics gives a very systematic way of building these simple models the way it is is that say, if we had two paths, imagine that their conditional future at the same.",
            "So the probability of the future condition with the password.",
            "X1 or X2 identical.",
            "Then we can reason that for the purposes of predicting the future, we really don't need to tell the difference between whether it's X one X2.",
            "So any information that's used to distinguish between these two possibilities is wasted, so we shouldn't distinguish them though.",
            "So why don't we take the set of all paths and we divided into subsets or what's called equivalence classes, such that two paths lie."
        ],
        [
            "In the same equivalence class, if they have the same conditional future and this allows us to come up with a machine which has inside itself one possible configuration for each possible equivalence class of the past.",
            "And so do I."
        ],
        [
            "This machine is that provider is that only has a single state for each of these equivalence classes, and by doing that it kind of forgets about all the past information that is unnecessary for the purposes future prediction it only stores which causes take the process is.",
            "I should say that these equivalence classes are referred to electric in literature as causal states because there and I mean the reason why they came up with this word is because.",
            "When you have a state of the machine, that's all the information you need to do to explain the future behavior.",
            "So instance captured all of the causal information from the past."
        ],
        [
            "And then once we have one of these machines, one can reduce the dynamics of once the stochastic processes completely to transition probabilities on these causal state.",
            "So we just need to know the probability of system with the past, you know certain causal stable transition to a pass in some other causal state, and that's all the information we ever need to keep.",
            "And so this really."
        ],
        [
            "This amount of memory because all we need to do now is to store, which causes state machines and that's just given by the Shannon entropy of Pi here with the P is the probability that the passes.",
            "You know particular causal state and two sort of.",
            "So they understand what improvement this is.",
            "Consider simulating completely random process.",
            "So with a completely random process, if we were to sort of stored entire path, we need to store sort of unbounded amount of information because every past occurs.",
            "So imagine I'm taking a coin.",
            "I'm sort of costing that randomly, so every possible past occur.",
            "So to store that we need bounded amount of information.",
            "However, if we look at it in this picture, we realize that every part because the past is uncorrelated the future.",
            "Every path is the same conditional future, so we can.",
            "We only have a single Pi that is non 0.",
            "So we.",
            "So what happens is that we only have let's see.",
            "So what happens is that we only have a single past with the probability of it happening being equal to 1.",
            "So when we look through we workout Shannon.",
            "Information theory is just log of 1 which is equal to 0 and so the idea is that if a system is always in the same state.",
            "Then we don't need any information to be able to store which state it is.",
            "We don't learn anything more when we find out that the state that's always zero is zero, and this sort of captures the idea that if we have a completely random process.",
            "It only takes the amount of information that's needed to model.",
            "It is exactly 0 bits and this technique can start to be completely general.",
            "An Epson machines don't start to be sort of the so-called simplest classical models, and this was proven by Crutchfield in this paper in 1989 and so."
        ],
        [
            "Crutchfield because of this he considered the amount of memory these these optimal models require.",
            "So these circle after models required to be in transit measure of the complexity of a process and the rationale is we don't really need to know how process works.",
            "We just take a process.",
            "We look at this output behavior and we go OK. We have no idea how this process working, but we know that to be able to generate the right statistics we need at least as much memory.",
            "And so people can, you know, go and measure a neuron.",
            "They can measure sequence of data from a single neuron and they can say OK, I have no idea how the brain works, but it probably contains at least 7 bits of information.",
            "OK, so it's a really bad lower bound, but one can sort of get these lower bounds by sort of without any knowledge about how the system works on inside, just by purely looking at sort of what's the minimum amount of information required to capture their correct output behavior.",
            "This has been adopted as a quantifier of complexity and quite a popular quantifier because it satisfies a lot of our intuition about how complexity should behave."
        ],
        [
            "And this is illustrated by this coffee Cup example.",
            "So here we have a Cup.",
            "Imagine that we mixing milk with a coffee at the beginning.",
            "The milk is on top and the coffee is at the bottom.",
            "We tend to think about the system is being pretty simple, fairly easy to describe.",
            "At the end point, the milk in the coffee is all randomized and again looks like a pretty simple system that is homogeneous and it doesn't look very exciting.",
            "But in the middle was in mixing.",
            "You know, there's turbulence is all sorts of weird stuff going on highly nonlinear system.",
            "We have no idea how to describe it accurately.",
            "And this is the path where complexity happens and it's also captured by sort of the historical development of science.",
            "The first system that we could understand were highly ordered systems like pendulums.",
            "So these systems require only you know the position and the velocity and such.",
            "They were very, very easy to model.",
            "Then subsequently we develop models for things that were very noisy, like ideal gases where despite the fact that we had no idea how individual particles move, we can still stop predict their macroscopic behavior.",
            "With a few variables like pressure and temperature and volume, but stuff in between like license talk markers, these are the stuff where we need a lot of information to capture what's going on now and we still don't have a very good idea of how to predict the future statistics and this sort of captures the idea that when we have highly ordered systems, the amount of information we need to describe them in small, we have highly disordered systems to protect their future is small, but somewhere in between things are messy and this is exactly what statistical complexity captures.",
            "Because."
        ],
        [
            "When we have a bunch of bits that are uniformly 0, so we don't need to record any information to know what's going to happen in the future, it's just going to be 0 for all time with.",
            "If we had something that is completely random, again, we don't need to capture any information because nothing we record now will have any relevance to the future.",
            "And So what happens is that its value of complexity only takes finite nonzero values somewhere in between, and such and such that sort of captures this notion.",
            "Of complexity in the form of how much information do I need about the past of this process to be able to replicate its use?"
        ],
        [
            "Behavior, so let's go back to sort of that case study of that process with this box with a coin that was shaking, and we can sort of see that with this whole framework is fairly easy to understand.",
            "Here we had this box and we had this coin and with with sort of probability with every time step we should have checked this box.",
            "So it's probably PS lips or it does not slope.",
            "And we can see that the path that the future of this process depends only on the state of the coin to current point in time.",
            "So when we look at this causal states of this process, we see that we can devise a set of paths into the set of paths with the coin was previously heads and the set of paths with the coin was previously entails.",
            "Once we know that information, the future weekend, all the information we could possibly get about the future, and on the other hand the future does behave differently depending on whether the coin is currently in.",
            "Kids are currently entails, so we can't discard this information so that so there are two possible cause of States and and we have to record these so the amount of information that we need is exactly 1 bit.",
            "And we can sort of write down transition and so we can sort of write down Markov machines that replicate the state of this coin using two states.",
            "We have a State 0.",
            "And we have a state one, and we can just sort of iterate between these with a probability of 0.2 with a probability of 0.2 and then here we have 0.8 and 0.8 and we can see that this simple Markov machine completely describes the state of that stochastic process and the amount of memory that's required to store to sort of communicate the status.",
            "Is Markov machines exactly 1?",
            "But so if I stored one but you my computer?",
            "I can then go through this machine and click generate the right future statistics and this sort of captures this idea of sort of building the simplest model."
        ],
        [
            "And so here we have this box with a single coin inside that is exactly the simplest classical model for this process."
        ],
        [
            "And so, as a quick exercise, here's a here's a process.",
            "It's a fairly simple process, is just 012012012.",
            "Does anyone want to take again that sort of?",
            "That's sort of the complexity of this process.",
            "So we have this process and we observe it.",
            "It's just a box and all it does is it outputs 012012012012.",
            "It's not particularly complicated, so if we want to analyze this so we what we would do is we would look at the set of possible paths that we could observe.",
            "Well, there's really only three possible paths that we can observe.",
            "We can either observe sort of something that ends in 012 so the last observations two, or we can observe something that ends in sort of.",
            "This is 201 or observe something that ends in.",
            "Let's see never very good at alternating these sequences.",
            "This sort of 120.",
            "So we have these sort of theater.",
            "The three types of paths we can observe, and as soon as we know which one of these it is, we know exactly what's going to happen in the future.",
            "We know that after two that should be 0 after one after one, it should be a two after zero it should be a one, etc.",
            "So we can think about the past that's being divided.",
            "Into these three States and since it's three states are equally likely, the amount of information that's needed is equal to log 2 / 3, which is a statistical complexity of sort of this this process, and using that we can say that OK, there are many different ways of generating this data, But the simplest way of generating it, and the minimum amount of memory that I'm going to need the minimum amount of information I need to store about the past more precisely, is given by log 2.",
            "Phase three and this is just a Shannon entropy of a random variable.",
            "That sort of takes these three possibilities with equal probability."
        ],
        [
            "And so I think I probably have around about.",
            "Let's see about 5 minutes, so I'll give you a real quick spiel about how things may happen in quantum mechanics.",
            "OK, I'll I'll try 5.",
            "I don't want to bore people with too much of the details or maybe advertiser paralyze, talk back in time so."
        ],
        [
            "The basic idea is that things happened differently in quantum mechanics.",
            "So in classical E we had these birds that were either 01 but quantum mechanically what we get is is what we get is something that's motivated by the double slit experiment.",
            "So many of you probably seen this experiment in high school.",
            "I found it very boring.",
            "You guys, probably the two, but it's actually more interesting here.",
            "Once we put quantum unit.",
            "So here's a simple experiment.",
            "We have a light source.",
            "There's a barrier with two slits inside it, and if we were to propagate this light.",
            "Down these, toothless what we're going to see.",
            "This interference pattern now this interference pattern is fairly easy to explain if we think about light as a wave, because what happens is that you have these waveforms coming in and you get constructive interference.",
            "When sort of this point on, the screens equal distance from these two slots, but if it's sort of 1/2 integer wavelength offset then you get destructive interference and that sort of cancels out the amplitude and we get a dark fringe and so have we understand it's pretty simply using the wave theory of light.",
            "But we know that light is not just a waste of Einstein.",
            "In 1904 published his famous paper called the Photoelectric Effect, which stated that light with the particle and if light was a particle, then things become stranger because particles.",
            "We generally don't think about as interfering, and in fact you can make the source of light so weak that only a single part of photon transmits features is ever exist between the screen and the barrier at the same time.",
            "So there's no way that photon can interfere with another photo.",
            "And so if we do this experiment, though, and we collect the data, what we find is."
        ],
        [
            "That still, if we collect the data line, if we just record where each photon hits the screen, eventually we're going to build up.",
            "While these interference fringes.",
            "So this was very troubling to people who first studied this back in the early 20th century, because how can this particle you know just one of it interfere?",
            "What's at interfering with people were just very confused by this."
        ],
        [
            "I mean the way I mean, why they're confused as you can think about the soccer field, right?",
            "Here is the soccer kicking soccer balls is 2 barriers.",
            "You think OK, the ball should be here in here, but then they end up with this interfere with interference friend and you like what is going on?",
            "It's kind of crazy an."
        ],
        [
            "People have done this so experimentally was electrons with photons with atoms and more recently with these buckyballs which are basically molecules 60 carbon atoms.",
            "So people can do this with a whole range of different stuff.",
            "All these microscopic particles seem to display this sort of interference behavior."
        ],
        [
            "So what really is going on?",
            "It was proposed by Schroedinger.",
            "Is this theory of quantum mechanics so Schroedinger said?",
            "Look, the only way to explain this is if we think about a particle as being in can be in multiple places at the same time yourself.",
            "Thinking with the passive going through one slit, we have to think about it going.",
            "It's going through two slits simultaneously, because that's the only way I could generate this interference pattern.",
            "Only if there's a probability amplitude wave that describes where it's going to be an only if that wave interferes service itself, the so called wavefunction can we end up with the right interference pattern.",
            "So he postulated this idea of wave mechanics and the famous shorting this equation, which I won't get into, but the basic idea is classically we have a state zero in the statement, but quantum mechanically we can get these states, which is a quantum superposition of their own one.",
            "Don't worry too much about the braces notation, it's just a quirk of quantum physicist.",
            "They love using this notation.",
            "You can think about this is just zero and one.",
            "And so the particle can go through two slits simultaneously, and what's even stranger is that a physicist immediately asked, well, I don't believe he goes through two sets at once."
        ],
        [
            "Why don't we just put a detector here?",
            "Why don't we just put this detector and just see whether or not it goes through one whole another?",
            "And if we do that, what happens is that indeed each time we see the path goes going through only one slip.",
            "But the caveat is now the interference pattern is destroyed.",
            "We just get 2 bright fringes that where the sources in the first call now behaves exactly like a particle, not away.",
            "And this is this idea of a passport duality and a special case that the Heisenberg uncertainty principle in the sense that we can either choose to observe which slit the path goes through, or we can choose to observe the interference.",
            "We can't do both at the same time.",
            "And this sort of captures is heart of quantum theory, and it also gave a new way of understanding information, because we can think about a path going up and down as the two states of a classical bit that is either one or zero.",
            "And what quantum information allows us to do is to have a superposition of 01.",
            "This gives us a lot more freedom and."
        ],
        [
            "Gives a lot more power.",
            "It also confuse the hell out of physicists so have a. Niels Bohr was one person said OK they recently call Real can no longer be sort of a air isn't everything we call real is made up of things that cannot be regarded as real.",
            "If quantum mechanics hasn't profoundly shocked you so you haven't understood it yet and this is what gave birth to the idea of shorting this cap."
        ],
        [
            "And now sort of.",
            "We go back to our picture and probably we're running out of time.",
            "So let's go back quickly to our picture and normally we sort of thought about this as a classical information processor.",
            "But because reality is fundamentally quantum mechanical, what the correct way of thinking about things is ready to think."
        ],
        [
            "But as a quantum information processor, we're still recording classical bits of information we're still describing are experimenting of classical bits of information, but the way it can transform in the middle, that state can take on multiple different values at the same time, so we can write down.",
            "We shoot photos up this way, and that's a well defined experimental setup, and we can say we record that the photon hit the barrier here.",
            "That's classical information, but in the middle where we don't observe it, it can do multiple things.",
            "At the same time."
        ],
        [
            "And this is what gives quantum information is power, because classically we are constrained to our probability spaces constrained to this line here.",
            "But quantum."
        ],
        [
            "Currently you can get sort of Schrodinger's cat states, which is called 0 + 1, or you can actually get a different sort of interference pattern and you can get sort of 0 -- 1 so you can actually get many different forms of alive plus.",
            "Then I won't go through the details, but essentially the state space becomes a lot larger.",
            "Incense or 1 dimensional line.",
            "We end up with three dimensional sphere with the entire surface of the sphere."
        ],
        [
            "A valid sort of definitive quantum States and because of that there seems to be much more greater degrees of freedom of recall."
        ],
        [
            "The information and so we can do sort of experiments on this.",
            "We can still take that model that I've shown you before, and you can sort of encode it inside a quantum sort of a quantum device which inside photons which exhibit this sort of simultaneous simultaneous."
        ],
        [
            "And what we get is that we can improve over the classical model when the classical model always requires one bit of information to generate that perturb coin.",
            "Example that I told you earlier, the quantum one can actually get it down all the way to 0 depending on how hard we shake the system and this sort of captures the idea that.",
            "Ultimately, things can look simpler quantum mechanically.",
            "That's something that takes a lot of memory to simulate.",
            "Classically, can take a lot less dissimilar quantum mechanically."
        ],
        [
            "You can go and generalize this two different things instead of just looking at system that outputs sort of a bunch of statistics, you can look at more general systems that actually adapt their behavior to sort of the output differently depending on sort of how you kick it.",
            "So these so called input output processes, and so ultimately what sort of this work shows, is that there are many different levels of complexity that when we look at the object and we want to understand it, so one of the ways of sort of understanding that is to look at."
        ],
        [
            "One of the ways of understanding it to look at how much information we need to be able to sort of replicate the process, and this can be captured by the idea of Shannon entropy.",
            "Now the basic idea of some complexity theorem of sort of computation mechanics.",
            "You should say that now we understand this quantifiable information.",
            "We can use it to quantify exactly how much information it takes to simulate the process.",
            "And using that we get this measure of complexity, statistical complexity.",
            "And once we get this measure, though, this measure can actually behave quite differently depending on whether we are able to process information classically or quantum mechanically.",
            "So I think that I will basically stop there and leave."
        ],
        [
            "This is final.",
            "Take home message.",
            "If you didn't get anything analysis, the take home message everything looks in our world as a physical object.",
            "When we first think about things, we think about things as physical objects.",
            "But if you."
        ],
        [
            "We'll take our current view.",
            "You step back and look at this information theory, and especially if you start thinking about it in terms of quantum information theory then."
        ],
        [
            "You can end up doing incredible things, maybe not stop bullets, but since that are well, not quite as exciting as stopping bullets, but still quite exciting nonetheless.",
            "Thank you very much."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Thank you very much.",
                    "label": 0
                },
                {
                    "sent": "So yeah, how many people here was at my talking paradigms.",
                    "label": 0
                },
                {
                    "sent": "First of all, OK, so not too many.",
                    "label": 0
                },
                {
                    "sent": "So for those who are there, that's So what I want to do in this talk is to sort of in that talk.",
                    "label": 0
                },
                {
                    "sent": "It was kind of overwhelming amount of information, so in this one, what I want to do is focus on sort of some of the more specific stuff, and to sort of look at.",
                    "label": 0
                },
                {
                    "sent": "Look at this idea of look at this idea of complexity in detail.",
                    "label": 0
                },
                {
                    "sent": "So I'm not going to talk too much about quantum mechanics, what I want.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To do here is again give a broad overview of the field of information theory, and so maybe touch up on how to SIM.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Fiatt with quantum mechanics at the very end, and so that information theory, I think it's really at the heart of a lot of quantitative science, so tough when people first hear sort of my dual affiliation.",
                    "label": 0
                },
                {
                    "sent": "So the first with the Complexity Institute and with the Center for Quantum Technologies.",
                    "label": 0
                },
                {
                    "sent": "That sounds sort of like quite a strange combination because these two Sciences seem well could not be further apart.",
                    "label": 0
                },
                {
                    "sent": "I mean on one side when we think about complexity, we think about massive macroscopic systems, networks off.",
                    "label": 0
                },
                {
                    "sent": "Interacting components sort of at the everyday level with some people think about quantum science.",
                    "label": 0
                },
                {
                    "sent": "They tend to think about things at the level of photons and atoms, and at first you know we see that these two theories happen in very different regimes, and it's strange to sort of have any synergy between these two fields at all.",
                    "label": 0
                },
                {
                    "sent": "In fact, the main reason why so much of the techniques between the two fields map to each other is because a lot of a major component of these fields deals with the propagation.",
                    "label": 0
                },
                {
                    "sent": "Understanding of information.",
                    "label": 0
                },
                {
                    "sent": "And so the heart of really what this talk is going to be about is about information, and I think we've heard so that people briefly talk about that sort of thing.",
                    "label": 0
                },
                {
                    "sent": "Brian Asses, talk earlier and stewards talk last week where people have sort of mentioned this idea of information propagation innovation.",
                    "label": 0
                },
                {
                    "sent": "So what I want to do is go beyond these buzzwords and still give you a formal idea of what information theory means and how it can be used to understand reality so.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Begin with something that maybe is probably the most accessible notion of information the movie The matrix.",
                    "label": 0
                },
                {
                    "sent": "So who he has seen the matrix?",
                    "label": 0
                },
                {
                    "sent": "Anyone not seeing the matrix?",
                    "label": 0
                },
                {
                    "sent": "OK, pretty much right, so I don't have to worry about spoiling this movie for anybody.",
                    "label": 0
                },
                {
                    "sent": "So here's the guy, the star of the Matrix.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And as you know them, the basic premise is that where you know that his lands in this world where everything appears real, he can touch and he can feel everything thinks he's living in reality.",
                    "label": 0
                },
                {
                    "sent": "But in actuality he.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Living in this digital computer simulation where everything is in terms of birds.",
                    "label": 0
                },
                {
                    "sent": "Now this sort of this was a science fiction movie, but it's actually a bit closer to the truth than we think.",
                    "label": 0
                },
                {
                    "sent": "Well, we orderly think in fact some very prominent.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Scientists USS Lloyd from MIT black of a drought from here in Singapore.",
                    "label": 0
                },
                {
                    "sent": "Actually, as well as Oxford.",
                    "label": 0
                },
                {
                    "sent": "They're both written books on this stuff.",
                    "label": 0
                },
                {
                    "sent": "Programming reality, the coding or decoding reality program with the universe, and there are sort of this increasing amount of evidence that whether not the universe, whether not it is not, whether or not it is simulated, could be simulated.",
                    "label": 1
                },
                {
                    "sent": "This sort of all physical measurements so far haven't really isolated out the possibility that we are living in a simulated universe.",
                    "label": 0
                },
                {
                    "sent": "And so things like the holographic principle, that sort of we hear about with all about this idea of sort of the universe is really encoding the simulation.",
                    "label": 0
                },
                {
                    "sent": "And the reason why at the heart of this is because when we think about it.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And I think we take this for granted, so I think we're sort of in the afternoons.",
                    "label": 0
                },
                {
                    "sent": "You're simulating various things like flight networks.",
                    "label": 0
                },
                {
                    "sent": "We've talked about simulating all sorts of different phenomena so far in this winter school, and sort of when you think about, it's quite strange weather you take the LHC so that works on the nuclear weak nuclear strong force, particle physics.",
                    "label": 0
                },
                {
                    "sent": "You look at fluid mechanics, which operates sort of using sort of electromagnetic forces and gravity.",
                    "label": 0
                },
                {
                    "sent": "You look at cosmology, which is in the macroscopic scale using the force of gravity.",
                    "label": 0
                },
                {
                    "sent": "All these things very different forces.",
                    "label": 0
                },
                {
                    "sent": "Very different physical systems, and yet we can always simulate well.",
                    "label": 0
                },
                {
                    "sent": "We always try to it at least, and we always believe that we can in principle simulate them on computer.",
                    "label": 0
                },
                {
                    "sent": "Now what at the heart is a computer?",
                    "label": 0
                },
                {
                    "sent": "Well, a computer doesn't run gravity, and it certainly doesn't run on.",
                    "label": 0
                },
                {
                    "sent": "Sort of.",
                    "label": 0
                },
                {
                    "sent": "The stronger the weak nuclear forces it runs, mainly on the electromagnetic force.",
                    "label": 0
                },
                {
                    "sent": "So somehow, despite the fact that these are very different architectures using very different physical systems.",
                    "label": 0
                },
                {
                    "sent": "We can all understand them using sort of the humble computer, and I think this point is often overlooked and underappreciated, even those that have we do that every day, and it's.",
                    "label": 0
                },
                {
                    "sent": "And it's really a very strange property of the universe that we can do this when you think about it.",
                    "label": 0
                },
                {
                    "sent": "This your computers of sitting there in front of you, and you can simulate anything you like with it.",
                    "label": 0
                },
                {
                    "sent": "And this, in fact, is actually a law.",
                    "label": 0
                },
                {
                    "sent": "It's called the church.",
                    "label": 0
                },
                {
                    "sent": "The Deutsch Church, Turing principle, and it basically states that.",
                    "label": 0
                },
                {
                    "sent": "For some reason, in our reality, every physically reasonable process can be simulated by universal computing device.",
                    "label": 1
                },
                {
                    "sent": "Now for the purpose of this talk, you can think about the universal computing devices.",
                    "label": 0
                },
                {
                    "sent": "Just your notebook computer, so it's slightly more sophisticated, but it's essentially is basically a piece of computing hardware, and I think this is one of the sort of this is one of the laws that one cannot mathematically prove it.",
                    "label": 0
                },
                {
                    "sent": "And it just happens to be true for our universe, and that's the reason why we are really here talking about how we can simulate and understand reality using certain agent based models and using all sorts of other sort of sophisticated computer programming languages as because of this interesting fact.",
                    "label": 0
                },
                {
                    "sent": "And so.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "What this really means is that when we think about understanding the universe, we can think about it in two different pictures.",
                    "label": 0
                },
                {
                    "sent": "So the traditional picture.",
                    "label": 0
                },
                {
                    "sent": "I think this is sort of many quantitative science, especially physics up tell about the 1960s, is this idea of sort of you do experiment so you have some information describing how you set up this experiment, and then you climb a tower like the Leaning Tower pizza in your drop these two balls down, see how they fall.",
                    "label": 0
                },
                {
                    "sent": "That's your physical process.",
                    "label": 0
                },
                {
                    "sent": "We harness something in physics.",
                    "label": 0
                },
                {
                    "sent": "Oh, or something in reality.",
                    "label": 0
                },
                {
                    "sent": "And then afterwards we observe the outcome and.",
                    "label": 0
                },
                {
                    "sent": "This is a standard view, however, we can think about everything really as information processing because the experimental setup, well, we just described that using information we can write down how we're going to set up the experiment, what all the initial conditions are then the.",
                    "label": 0
                },
                {
                    "sent": "Actual physical process by the Church Turing thesis can be simulated by on a computer.",
                    "label": 1
                },
                {
                    "sent": "It's equivalent, in essence, to processing the input information and then afterwards we take what happens in our physical system.",
                    "label": 0
                },
                {
                    "sent": "Of course, is we observe the output and record that also in terms of information we write down what we have observed.",
                    "label": 0
                },
                {
                    "sent": "And that's really just output information information processor.",
                    "label": 1
                },
                {
                    "sent": "So these two views of reality are actually essentially equivalent.",
                    "label": 0
                },
                {
                    "sent": "We can think about ourselves as sort of performing physical tasks.",
                    "label": 0
                },
                {
                    "sent": "We set something up.",
                    "label": 0
                },
                {
                    "sent": "We look at how involved we do experiment with user results, but when we're doing that, we're essentially performing a computation using a particular physical device.",
                    "label": 0
                },
                {
                    "sent": "And similarly, when we run a simulation or computer, what we're really doing is we're configuring the computer in some initial state where getting the computer to run a physical process, and then we're doing some sort of measurement on it by observing the output on the screen.",
                    "label": 0
                },
                {
                    "sent": "So these two pictures.",
                    "label": 0
                },
                {
                    "sent": "A very very similar and it gives us a new way of understanding reality.",
                    "label": 0
                },
                {
                    "sent": "Because this picture here you see applies to any experiment we can do in the real world, and so if we can understand how information evolves and if we can understand the properties of how we can process information, then that sort of gives us general understanding about sort of what sort of 4th physical processes are possible and how we can model these physical processes.",
                    "label": 0
                },
                {
                    "sent": "So this I think is the main theme of this talk and this is what we shall explore.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So to give you an idea of sort of how powerful sort of what sort of.",
                    "label": 0
                },
                {
                    "sent": "What sort of things we can meet here come up using this framework.",
                    "label": 0
                },
                {
                    "sent": "There was as famous questions asked by Philip Anderson, Nobel Laureate in 1972.",
                    "label": 1
                },
                {
                    "sent": "Well, I think he might have gotten Nobel Laureates Nobel Prize a little earlier, but he probably he published his question in 1972, which is that can all properties he asked can, all macroscopic properties be explained by their macroscopic components?",
                    "label": 1
                },
                {
                    "sent": "So Phillip Anderson will sort of accountants matter physicist, and at that time most people.",
                    "label": 0
                },
                {
                    "sent": "Most scientists thought that we could reduce everything in reality to sort of a fundamental theory of fundamental particles.",
                    "label": 0
                },
                {
                    "sent": "So once we understand how electrons and how photons involved, we can use that to build up a picture of our atoms will react, we can use that to build up a picture of chemistry.",
                    "label": 0
                },
                {
                    "sent": "Biology, explain human society, etc.",
                    "label": 0
                },
                {
                    "sent": "So it was a very rosy picture and it was captured by sort of Ernest Rutherford, who said that everything is physics or stamp collecting.",
                    "label": 0
                },
                {
                    "sent": "So you either don't real science.",
                    "label": 0
                },
                {
                    "sent": "Oh, just collecting a bunch of facts.",
                    "label": 0
                },
                {
                    "sent": "So Phillip Anderson was one of the first prominent physicist to challenge this view because he didn't believe that condensed matter theory so that the loss or macroscopic matter can be explained by fundamental principles.",
                    "label": 0
                },
                {
                    "sent": "So he posed this question come all properties of a macroscopic system be really understood by its microscopic constituents.",
                    "label": 0
                },
                {
                    "sent": "So can we sort of take, for example, fluid mechanics, and we look at the interactions between every individual Atom and use that to sort of understand.",
                    "label": 0
                },
                {
                    "sent": "And arrives at the Navier Stokes equation.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And this is sort of the view.",
                    "label": 0
                },
                {
                    "sent": "Now we using sort of language of information theory.",
                    "label": 0
                },
                {
                    "sent": "We can have a good answer to it.",
                    "label": 0
                },
                {
                    "sent": "Because what we find is that.",
                    "label": 0
                },
                {
                    "sent": "In computer science, there's this notion called the halting problem, which says that if I have a computer program.",
                    "label": 0
                },
                {
                    "sent": "And I want to know what it's going to do that.",
                    "label": 0
                },
                {
                    "sent": "So what is long-term behavior is?",
                    "label": 0
                },
                {
                    "sent": "For example, is that going to halt is they're going to run for a set amount of time and eventually stop?",
                    "label": 0
                },
                {
                    "sent": "Or is there kind of going into infinite loop and never end so this?",
                    "label": 0
                },
                {
                    "sent": "What's called the halting problem, and it turns out that one can prove mathematically that if once given the general program, there's no systematic way to know whether or not it will eventually stop running.",
                    "label": 1
                },
                {
                    "sent": "So there are long-term behaviors of computer programs that we cannot ever sort of formally compute.",
                    "label": 0
                },
                {
                    "sent": "But if we start thinking about a computer program as a physical system, then this automatic.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Also set a even if we were able to find a fundamental theory of everything, the certain properties about that physical system, sort of certain macroscopic properties about that physical system that we can never sort of evaluate, and so have this one sort of highlighted in this article in nature in 2009, in the sense that it was the first sort of formal proof of innocence emergence that even if we had a fundamental understanding of macroscopic particles because of the nature.",
                    "label": 0
                },
                {
                    "sent": "Of information processing, then, it's still formally noncomputable to find that older macroscopic properties that when you sort of put together a lot of these particles well, how they will behave and this sort of sort of captures this idea that information and physics is deeply intertwined and by understanding how information evolves and sort of what our capabilities are in looking at computer programs, we can understand ultimately properties about the physical universe.",
                    "label": 0
                },
                {
                    "sent": "And I guess coming from the perspective of physicists, this is what I find the most interesting about information theory.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And so this is really the theme about this talk and specifically what I want to tell you today is about how information theory can help us sort of understand structure and complexity.",
                    "label": 0
                },
                {
                    "sent": "And so I'm going to take her information theoretic point of view and look at complex processes as information processing and one of the frameworks to do that is this sort of subfield of complexity theory known as computational mechanics.",
                    "label": 0
                },
                {
                    "sent": "So in this lecture what I will do is I will sort of introduce computation mechanics.",
                    "label": 0
                },
                {
                    "sent": "I'll give a simple example.",
                    "label": 1
                },
                {
                    "sent": "I'll introduce sort of how we quantify information, and I will sort of demonstrate sort of what it means to explain something more simply in terms of information.",
                    "label": 0
                },
                {
                    "sent": "Theory and this gives us this idea of how to actually quantify structure in complex systems.",
                    "label": 0
                },
                {
                    "sent": "And finally, if I have time, I'll talk about how these notions all change once we get to the world of quantum mechanics.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the basic idea is if we had some physical system out there.",
                    "label": 0
                },
                {
                    "sent": "So what we are observing from it is bit of data.",
                    "label": 0
                },
                {
                    "sent": "What we observing is information.",
                    "label": 0
                },
                {
                    "sent": "We record pieces of information we never really do.",
                    "label": 0
                },
                {
                    "sent": "Anything else doesn't record information.",
                    "label": 0
                },
                {
                    "sent": "When we do experiment, we make a management.",
                    "label": 0
                },
                {
                    "sent": "It's all information.",
                    "label": 0
                },
                {
                    "sent": "So basically every physical system you can think about it as a black box.",
                    "label": 0
                },
                {
                    "sent": "Let's just throwing out bits of data and what we are.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Thing to do when we try to understand something or model something.",
                    "label": 0
                },
                {
                    "sent": "We're trying to build a model that replicates that data.",
                    "label": 0
                },
                {
                    "sent": "So we got the statistics out there and we want to sort of understand.",
                    "label": 0
                },
                {
                    "sent": "OK, can we sort of describe it in some sort of model?",
                    "label": 0
                },
                {
                    "sent": "Hopefully this model, then we can put sort of input into our computer so we can write down the initial conditions and then we can see what is how it's going to behave in the future.",
                    "label": 0
                },
                {
                    "sent": "So really, the process of quantitative science is a process of mathematical abstraction.",
                    "label": 0
                },
                {
                    "sent": "We want to try to represent.",
                    "label": 0
                },
                {
                    "sent": "So observations in terms of equations, agent based models only, other mechanism for taking past information and using it to generate future behavior.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And what happens is when we do this, there are many different possible models.",
                    "label": 0
                },
                {
                    "sent": "So the.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We can have many different ways of getting the same behavior, and the idea is that we want to sort of once we've given sort of many different models and safe to give the same behavior, then the question will be OK.",
                    "label": 1
                },
                {
                    "sent": "Which model gives us a simplest understanding?",
                    "label": 0
                },
                {
                    "sent": "Which model is which model do we prefer?",
                    "label": 0
                },
                {
                    "sent": "Is there sort of?",
                    "label": 0
                },
                {
                    "sent": "How do we sort of a judge sort of whether one explanation or one model of the system is better than other?",
                    "label": 0
                },
                {
                    "sent": "So which one is more captures more?",
                    "label": 0
                },
                {
                    "sent": "Of sort of what they observe or captures the essence of what we observe.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And what I want to do to get some intuition on this is to go through a very simple example first.",
                    "label": 1
                },
                {
                    "sent": "So imagine we had a system like this and we had a sequence of data, and once you know we do a lot of measurements, we find that the distinguishing feature about the sequence of data is that two consecutive bits always the verb roughly by a probability of 0.2.",
                    "label": 1
                },
                {
                    "sent": "So we look at sort of two bit correlations and we look down.",
                    "label": 0
                },
                {
                    "sent": "We see ha, which probably 0.2.",
                    "label": 0
                },
                {
                    "sent": "Each part is different from its previous, but so we have sort of.",
                    "label": 0
                },
                {
                    "sent": "We have sort of object that that does this and we want to be the model and so so to make some simple for you we have given sort of.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Possible models as this is sort of our first day at work I suppose.",
                    "label": 0
                },
                {
                    "sent": "So the first model year something like this we take a box and we have a single coincided and we shake this box so that with probability 0.2 the coin flips.",
                    "label": 1
                },
                {
                    "sent": "You can zero in one and then we just output the state of the coin so you can see that this process is definitely going to generate the right statistics if we if it sometimes that we got zero then there's always going to be the probability of 0.2 that we flip.",
                    "label": 0
                },
                {
                    "sent": "So we can go OK. One way of sort of modeling this behavior is to think about it as a box with a single coin inside which we just flip and we program this on a computer and we get the right statistics.",
                    "label": 0
                },
                {
                    "sent": "We can think about another model, maybe some other person came up with this model.",
                    "label": 0
                },
                {
                    "sent": "She said yeah, but I have a different idea.",
                    "label": 0
                },
                {
                    "sent": "Why don't like a 2 boxes and have a coin in each box and what I'm going to do is at each time step I'm going to choose one of these boxes at random and I'm going to flip it with probability 0.2 and then I'm going to compare the coins and if they have the same, I'm going to output one, and if they are different I'm going to output 0.",
                    "label": 1
                },
                {
                    "sent": "Now if you think about it fairly carefully this the output statistics of this system is exactly the same as the outlets that fixes that system, so they both.",
                    "label": 0
                },
                {
                    "sent": "Equally valid models of the observer behavior.",
                    "label": 0
                },
                {
                    "sent": "But could I get hands upon who prefers the first model?",
                    "label": 0
                },
                {
                    "sent": "Who prefers the second model?",
                    "label": 0
                },
                {
                    "sent": "OK, great so uh OK so most of us I think except maybe a few exceptions like models which are simpler.",
                    "label": 0
                },
                {
                    "sent": "Of course I guess this is probably more fun to Bude, but usually we tend to.",
                    "label": 0
                },
                {
                    "sent": "We tend to take the lazy approach right where we are writing a computer program like this is going to take like 30 lines of code and this might only take 10 and we tend to think OK, this just when I look at this I immediately see what's going on, what's going to happen when I look at this model.",
                    "label": 0
                },
                {
                    "sent": "I have to think a bit harder about it so.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Generally this seems better and this is sort of a intuition that we want to capture using information theory, because ultimately, I mean I'm a physicist and what physicists do is they want to capture intuition in terms of mathematics, and I think that really captures the heart of what physics is about.",
                    "label": 0
                },
                {
                    "sent": "It's sort of.",
                    "label": 0
                },
                {
                    "sent": "We've got some concept out there like energy which you know 1000 years ago.",
                    "label": 0
                },
                {
                    "sent": "People just said a laugh is more powerful than you rock because he can punch a hole in this rock.",
                    "label": 0
                },
                {
                    "sent": "And I mean that's a good measure.",
                    "label": 0
                },
                {
                    "sent": "But when we want to understand energy and power later.",
                    "label": 0
                },
                {
                    "sent": "In physics sort of defines or stuff like Watts and Joules so that we are better able to quantify it, and we want to quantify this notion of seemingly better as well.",
                    "label": 0
                },
                {
                    "sent": "And to do that we need a quantifier of information theory.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So how do we formalize this intuition?",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The way to think about formalizing this intuition is from the perspective of oh comes razor, so so comes razor is sort of the words first proposed by Guy by the name of William Welcome.",
                    "label": 0
                },
                {
                    "sent": "He was the first to think deeply about this problem.",
                    "label": 0
                },
                {
                    "sent": "He was thinking, well, OK, plurality should not be sort of positives of necessity.",
                    "label": 0
                },
                {
                    "sent": "Now this is a bit of a mouthful, so I prefer this notion by Isaac Newton, who said OK, we should know more causes of natural things in both true, insufficient to explain their appearances.",
                    "label": 1
                },
                {
                    "sent": "So what these guys were getting at is that the notion of being better in this case is the idea that.",
                    "label": 0
                },
                {
                    "sent": "Model is simpler if it uses less information about sort of.",
                    "label": 0
                },
                {
                    "sent": "It requires us to posture less information about what has happened before.",
                    "label": 0
                },
                {
                    "sent": "To be able explain these statistics.",
                    "label": 0
                },
                {
                    "sent": "So in the cases previous we had one coin or two coins and the one point some simpler and to allow.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Straight is more generally, here we have another case of a newtons falling Apple and the reason why we like Newton's laws which they have allows us to basically compute the trajectory of the Apple by knowing it's only initial position velocity and the reason we like this is because if we can formulate alternative.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I'll say it, sort of.",
                    "label": 0
                },
                {
                    "sent": "We can certainly formulate alternative models like using the entire path trajectory of this Apple.",
                    "label": 0
                },
                {
                    "sent": "Also the path.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Play some pool to the ground by some invisible appendages of a flying spaghetti monster, but we tend to think about these inferior because they require us to store or more information about the world than is necessary.",
                    "label": 1
                },
                {
                    "sent": "You have the store sort of at the entire path project of this Apple, like who picked it, which Orchard was growing?",
                    "label": 0
                },
                {
                    "sent": "If we can predict the future without knowing this information, then there shouldn't be any reason why we want to store it inside our model.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And so, as you can see with this intuition here, we can see that the first model looks superior because it requires only one bit of information, whereas the second model seems to require 2 coins.",
                    "label": 0
                },
                {
                    "sent": "So 2 bits of information.",
                    "label": 0
                },
                {
                    "sent": "And so let's formalize this further, what do we mean by a bit of information?",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "A sort of what we can we so formalize this idea of this interest?",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And let's see.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Do that.",
                    "label": 0
                },
                {
                    "sent": "To give a quick crash course on quantifying information.",
                    "label": 0
                },
                {
                    "sent": "So this is the idea of Shannon entropy, who here has heard of Shannon entropy before.",
                    "label": 0
                },
                {
                    "sent": "And he has worked with Shannon entropy.",
                    "label": 0
                },
                {
                    "sent": "OK, great, so let's let's quickly go through such an engine because I think this stuff is really important in so many different fields.",
                    "label": 0
                },
                {
                    "sent": "From artificial intelligence to physics, thermodynamics.",
                    "label": 0
                },
                {
                    "sent": "So it's really good to sort of know it regardless.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And so the basic idea of Shannon entropy is it's a quantifier of information.",
                    "label": 0
                },
                {
                    "sent": "When it boils down to it, what information is is about answering questions, yes or no, and in particular we can boil that down to a unit of information with answering yes and no questions, and what Shannon entropy is capturing is how many sort of saying OK, if we have a random variable, the amount of information contains is how many yes or no questions on average.",
                    "label": 0
                },
                {
                    "sent": "I have to ask to know the value of that random variable and the best way to illustrate this is by example.",
                    "label": 1
                },
                {
                    "sent": "So here we have a very simple example.",
                    "label": 0
                },
                {
                    "sent": "We have sort of a random variable that can take on two values, zero and one with probability of 0.5 each time.",
                    "label": 0
                },
                {
                    "sent": "And so the best way sort of one way of sort of asking the question in the the best way, and probably the only way because it's such a simple example used to ask OK is X0 is X one.",
                    "label": 1
                },
                {
                    "sent": "So this is a yes, no question.",
                    "label": 0
                },
                {
                    "sent": "If someone answers yes you know it is zero.",
                    "label": 0
                },
                {
                    "sent": "You someone else is now you know X is equal to 1 and so we see that this one yes or no question.",
                    "label": 0
                },
                {
                    "sent": "So a point fair coin contains 1 bit of information, so so that.",
                    "label": 0
                },
                {
                    "sent": "So what that captures is that if you don't know what the state of random coin tosses then then you can ask one question to know what that is.",
                    "label": 1
                },
                {
                    "sent": "So the state of a random coin toss contains exactly 1 bit of information.",
                    "label": 0
                },
                {
                    "sent": "Or if you don't know what it is, it contains 1 bit of uncertainty and so this is the basic idea behind Shannon entropy.",
                    "label": 0
                },
                {
                    "sent": "So let's do a slightly more complicated example.",
                    "label": 0
                },
                {
                    "sent": "Suppose we have random variables that can take four different values.",
                    "label": 1
                },
                {
                    "sent": "012 and three always probability of 1/4.",
                    "label": 0
                },
                {
                    "sent": "Then you want to guess how many bits of information this contains.",
                    "label": 0
                },
                {
                    "sent": "No need to be shy, could guess.",
                    "label": 0
                },
                {
                    "sent": "2.",
                    "label": 0
                },
                {
                    "sent": "The reason is that we can come up with this sort of a example.",
                    "label": 0
                },
                {
                    "sent": "We can sort of ask.",
                    "label": 0
                },
                {
                    "sent": "First of all, is the ex even, and that tells us OK with it's 02 or with this one or three and depending on sort of answered the first question, we ask the correct second question and then what happens is that we can now isolate down to each of these four possibilities.",
                    "label": 0
                },
                {
                    "sent": "So we end up with two bits of information.",
                    "label": 0
                },
                {
                    "sent": "And indeed if you have.",
                    "label": 0
                },
                {
                    "sent": "Random variable that takes a even distribution of sort of two to the end different probabilities.",
                    "label": 0
                },
                {
                    "sent": "So you can imagine you can just scale this tree and so so any random variable is 2 to the end.",
                    "label": 0
                },
                {
                    "sent": "Different possibilities takes exactly inputs contains exactly in bits of information, or it has a Shannon entropy of N. Now we can also think about random variables where the probabilities are non uniform.",
                    "label": 0
                },
                {
                    "sent": "So here's another sort of example here.",
                    "label": 0
                },
                {
                    "sent": "We still have 4 probabilities, but now the coin.",
                    "label": 0
                },
                {
                    "sent": "Has a higher chance of being zero than any of the other.",
                    "label": 0
                },
                {
                    "sent": "And then any of the other possibilities.",
                    "label": 0
                },
                {
                    "sent": "And so this turns out to be able to modify the average number of questions that we need to ask so tough.",
                    "label": 0
                },
                {
                    "sent": "So let's walk through this question in detail.",
                    "label": 0
                },
                {
                    "sent": "So what has different ways of doing this?",
                    "label": 0
                },
                {
                    "sent": "Let's work with this.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "We can of course, naively goes through the same example as we did before, so we can still use this strategy here, but we can see that that will require two questions.",
                    "label": 0
                },
                {
                    "sent": "Does anyone have any ideas of?",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "How to do better than two questions and you want to try?",
                    "label": 0
                },
                {
                    "sent": "No need to be a shark.",
                    "label": 1
                },
                {
                    "sent": "OK, I'm going to point somebody out.",
                    "label": 0
                },
                {
                    "sent": "So how about you do what first question would you ask?",
                    "label": 0
                },
                {
                    "sent": "Yes or no questions.",
                    "label": 0
                },
                {
                    "sent": "Other, Even so, we could do that.",
                    "label": 0
                },
                {
                    "sent": "So if we had other events, so let's say X Even so, what we end up here is we've got zero, yes, then we've got 02, one or three.",
                    "label": 0
                },
                {
                    "sent": "But now we kind of stuck always asking the second question right because we don't know if it's 02 here.",
                    "label": 0
                },
                {
                    "sent": "We don't know whether it's one or three here, so we have to always ask the second question.",
                    "label": 0
                },
                {
                    "sent": "So we end up asking 2 questions.",
                    "label": 0
                },
                {
                    "sent": "Is it possible to reduce that on average so that the only way to do that is if one does not someone else have idea?",
                    "label": 0
                },
                {
                    "sent": "Listen now.",
                    "label": 0
                },
                {
                    "sent": "So is it zero?",
                    "label": 0
                },
                {
                    "sent": "Yeah, great.",
                    "label": 0
                },
                {
                    "sent": "So instead of asking is X even we're going to ask.",
                    "label": 0
                },
                {
                    "sent": "I'm going to waste paper here, so hopefully no one will not video type too much for this.",
                    "label": 0
                },
                {
                    "sent": "OK, so X is X0.",
                    "label": 0
                },
                {
                    "sent": "So now if it is 0 so if this is yes then we get zero and we're done.",
                    "label": 0
                },
                {
                    "sent": "We don't have to ask anymore and here now we have three possibilities though 1, two or three.",
                    "label": 1
                },
                {
                    "sent": "So what's the next question someone wants to ask?",
                    "label": 0
                },
                {
                    "sent": "Is that one OK?",
                    "label": 0
                },
                {
                    "sent": "So let's ask is at one.",
                    "label": 0
                },
                {
                    "sent": "So here we have one and then we have two or three here.",
                    "label": 0
                },
                {
                    "sent": "So of course we have to ask is at 2 and if we ask is a two and then we get yes or no?",
                    "label": 0
                },
                {
                    "sent": "And then we can get two or three.",
                    "label": 0
                },
                {
                    "sent": "So now we get this tree 0123 and now it looks a little.",
                    "label": 0
                },
                {
                    "sent": "It looks like sometimes we asking 3 questions, so it's not so good, but if we look at this tree here and indeed this is the correct re, what happens?",
                    "label": 0
                },
                {
                    "sent": "Is that because zero is very likely there is a good chance that we can finish with just one question, which is great.",
                    "label": 0
                },
                {
                    "sent": "And because two and three are unlikely, there's not that much chance that we're going to end up asking 3 questions, and indeed one can sort of calculators.",
                    "label": 0
                },
                {
                    "sent": "I just waiting the number of questions with the probability that we will ask them so, so it's probably half will ask a single question with probably 1/4.",
                    "label": 0
                },
                {
                    "sent": "Will ask two questions.",
                    "label": 0
                },
                {
                    "sent": "What was probably 1/8 will ask three questions and with another probability one it will ask three questions.",
                    "label": 0
                },
                {
                    "sent": "And if we compute that as equal to 1.75.",
                    "label": 0
                },
                {
                    "sent": "So we are able to sort of compress the number of questions we need to ask instead of asking a whole 2 questions, we can ask 1.75 questions and in fact this sort of encoding process is used all the time in terms of basic communication theory, because when we look at, say, the English language for example, the letters do not all occur with equal probability, so that the letter E occurs much more often than says the letter X and anyone can play Scrabble will know this.",
                    "label": 0
                },
                {
                    "sent": "You know you get way more points.",
                    "label": 0
                },
                {
                    "sent": "If you sort of come up with the word with Xposed unit, So what this means is that when we are storing this sort of information, computer Western bits of data and what each bread contains is just a yes or no question.",
                    "label": 0
                },
                {
                    "sent": "So the first bit could sort of content use this letter of Al.",
                    "label": 0
                },
                {
                    "sent": "Or is that a consonant, for example, and that could be one.",
                    "label": 0
                },
                {
                    "sent": "But that's stored, and So what we're doing is we're transforming this, let Alphabet into a stream of bits of data, and each breath is one of these.",
                    "label": 0
                },
                {
                    "sent": "Yes, no questions.",
                    "label": 0
                },
                {
                    "sent": "So for example, if we wanted to encode.",
                    "label": 0
                },
                {
                    "sent": "In Code 10 here we can write 00 yes and if we want to record one, we do right now yes, and that would be a way of sort of encoding this data in a sequence of yes or no questions, and that's all what a computer does, and if we can find more efficient encodings, then we can transmit the same information using less data.",
                    "label": 0
                },
                {
                    "sent": "So this is a fundamental foundations of sort of information communication and that all sort of gives us is captures intrinsic property of how many bits of information or random variable contains.",
                    "label": 1
                },
                {
                    "sent": "And this this quantity turns out to be very useful for us, so let's.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Write down the actual equation.",
                    "label": 0
                },
                {
                    "sent": "I think we pretty much have a good idea now, because what we've done is we've taken the probability of a random variable being a particular value X and we multiplied by the log.",
                    "label": 1
                },
                {
                    "sent": "If we think carefully about this, this is log of one over the probability of that happening.",
                    "label": 0
                },
                {
                    "sent": "So for example when we when it happened 1/8 of the time, we're taking the log base two of a. I should mention that this log is allowed based 2 information theory because we're dealing with bits, the logarithms is always taken base two, SO 2 to the power of three is equal to 8.",
                    "label": 0
                },
                {
                    "sent": "So the log of eight is equal to three, and we have three here, and we know that log of 1 / P X is just equal to minus of log of PX, so this we can get this general equation for the Shannon entropy is just equal to the sum of all possible values that X can take.",
                    "label": 0
                },
                {
                    "sent": "One of the product of the probability it takes that value versus a log of that probability.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we have this idea of Shannon entropy and this is sort of the tool that we use to be able to stuff, say which model uses more information or which model uses less information.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And so, in general, here's a picture of anatomy of a bit of how much information it contains, so we've ascertained that when we have an equal distribution, we get sort of an average.",
                    "label": 0
                },
                {
                    "sent": "We only ask a single question if of course if we are at the top or at the bottom.",
                    "label": 0
                },
                {
                    "sent": "So if something is always at zero and something is always at one.",
                    "label": 0
                },
                {
                    "sent": "Then we don't need to ask any questions, so the entropy is 0.",
                    "label": 0
                },
                {
                    "sent": "And as we get more biased towards so, if we had a probability to distribution that is biased towards zero bias towards one.",
                    "label": 0
                },
                {
                    "sent": "That the entropy kind of slides continuously between one and zero, and this corresponds to the idea that if we had, if we had many sort of many of those random variables, so it turns out that to be able to set up to communicate all the information they contain, we can actually compress the number of yes, no questions using sort of a slightly more sophisticated technique, But essentially this sort of decision tree, and so this is a very nice part about Shannon entropy, and indeed for a binary variable we get this equation here.",
                    "label": 0
                },
                {
                    "sent": "And we get sort of this slide with the brightest point.",
                    "label": 0
                },
                {
                    "sent": "Here, higher entropy is in the in the middle with the lowest entropy at the sides.",
                    "label": 0
                },
                {
                    "sent": "So this is all I will say about entropy.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And we can now go back to sort of our understanding models.",
                    "label": 0
                },
                {
                    "sent": "So here are model A that was just a single variable that happened with equal probability.",
                    "label": 0
                },
                {
                    "sent": "So it has an entropy of 1.",
                    "label": 0
                },
                {
                    "sent": "Here we have a model where we had two coins and all four possibilities happen with equal probability.",
                    "label": 0
                },
                {
                    "sent": "So communicate the state of the two coins.",
                    "label": 0
                },
                {
                    "sent": "When the two yes or no questions and so we can see that just from this formal information theoretic perspective, this model is simpler distance model that replicates the future using less information and so.",
                    "label": 0
                },
                {
                    "sent": "In general, what's considered the preferred model and using this framework of information theory?",
                    "label": 0
                },
                {
                    "sent": "We can now formalize the idea of occum's razor in the language of mathematics.",
                    "label": 0
                },
                {
                    "sent": "We could say that if two models make statistically identical predictions, then the model that requires the least amount of input information or the least amount of information about its internal state is preferred.",
                    "label": 1
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And and we've kind of went over this just before, but I'd like to reiterate.",
                    "label": 0
                },
                {
                    "sent": "So the relation between this simulation physics because the reason why we prefer these simpler models is because.",
                    "label": 0
                },
                {
                    "sent": "If we had, if any model to be able to execute it, we need to run it on a computer, and so if our model requires inputs with a certain amount of entropy, there are physical system must have at least that much memory to be able to execute the simulation.",
                    "label": 1
                },
                {
                    "sent": "So the task of building simpler models allows us to store less information and therefore set up to be able to simulate.",
                    "label": 0
                },
                {
                    "sent": "View the simulation using sort of less memory.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And this can be summarized again, going back to the Matrix and matrix problem.",
                    "label": 0
                },
                {
                    "sent": "So now the idea is a computer overlords have taken over the world an you they've captured you and your task to build the ultimate simulation for sale bending spoon and the question is how do we do this while stirring the least amount of information about the past?",
                    "label": 0
                },
                {
                    "sent": "Because these computer overlords are actually quite stingy and solar power is limited.",
                    "label": 0
                },
                {
                    "sent": "Since you know we well human battery power is limited I guess.",
                    "label": 0
                },
                {
                    "sent": "So how do we sort of do this?",
                    "label": 1
                },
                {
                    "sent": "At least amount of hard drive space?",
                    "label": 1
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And what I want to sort of discuss in formalizes how much time do I have, by the way.",
                    "label": 0
                },
                {
                    "sent": "OK, great, so we have plenty of time to do this so that I want to solve discusses quickly in the context of sort of the example that motivated this whole situation, which is a case which is basically special example of a class of problems where we have we have a subject there.",
                    "label": 0
                },
                {
                    "sent": "And we can see it so that we can sort of measure the discrete points in time and the question is how much information do we need to record about the past to be able to generate a good statistical replication of the future?",
                    "label": 0
                },
                {
                    "sent": "And the idea is we want to store everything about the past in the present inside our model, so we can discard the past and so we can sort of generate the future purely from this stuff in this box and we can capture the complexity of our model or how good it is by the entropy of this box, which is just this.",
                    "label": 0
                },
                {
                    "sent": "Defined by the Shannon entropy of the box, so the box can take various states with certain probabilities.",
                    "label": 0
                },
                {
                    "sent": "From that we can sort of capture how much information we need to be able to store the contents of the box.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And in particular, in our special case with the case where when we looked at each one of these random variables, consecutive ones deferred by a probability of Scipy which was equal to 0.2.",
                    "label": 0
                },
                {
                    "sent": "Now let's let's take a look.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the way to do this?",
                    "label": 0
                },
                {
                    "sent": "OK, the brute force method of causes to record and type fast.",
                    "label": 0
                },
                {
                    "sent": "We can always sort of replicate the right future statistics if we just recorded everything about the past, but we see that that's going to take a lot of information, and that's probably not a good idea.",
                    "label": 0
                },
                {
                    "sent": "So let's see if we can do something simpler and turns out that computational mechanics gives a very systematic way of building these simple models the way it is is that say, if we had two paths, imagine that their conditional future at the same.",
                    "label": 0
                },
                {
                    "sent": "So the probability of the future condition with the password.",
                    "label": 1
                },
                {
                    "sent": "X1 or X2 identical.",
                    "label": 0
                },
                {
                    "sent": "Then we can reason that for the purposes of predicting the future, we really don't need to tell the difference between whether it's X one X2.",
                    "label": 1
                },
                {
                    "sent": "So any information that's used to distinguish between these two possibilities is wasted, so we shouldn't distinguish them though.",
                    "label": 1
                },
                {
                    "sent": "So why don't we take the set of all paths and we divided into subsets or what's called equivalence classes, such that two paths lie.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In the same equivalence class, if they have the same conditional future and this allows us to come up with a machine which has inside itself one possible configuration for each possible equivalence class of the past.",
                    "label": 0
                },
                {
                    "sent": "And so do I.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This machine is that provider is that only has a single state for each of these equivalence classes, and by doing that it kind of forgets about all the past information that is unnecessary for the purposes future prediction it only stores which causes take the process is.",
                    "label": 0
                },
                {
                    "sent": "I should say that these equivalence classes are referred to electric in literature as causal states because there and I mean the reason why they came up with this word is because.",
                    "label": 1
                },
                {
                    "sent": "When you have a state of the machine, that's all the information you need to do to explain the future behavior.",
                    "label": 0
                },
                {
                    "sent": "So instance captured all of the causal information from the past.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And then once we have one of these machines, one can reduce the dynamics of once the stochastic processes completely to transition probabilities on these causal state.",
                    "label": 1
                },
                {
                    "sent": "So we just need to know the probability of system with the past, you know certain causal stable transition to a pass in some other causal state, and that's all the information we ever need to keep.",
                    "label": 0
                },
                {
                    "sent": "And so this really.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This amount of memory because all we need to do now is to store, which causes state machines and that's just given by the Shannon entropy of Pi here with the P is the probability that the passes.",
                    "label": 0
                },
                {
                    "sent": "You know particular causal state and two sort of.",
                    "label": 1
                },
                {
                    "sent": "So they understand what improvement this is.",
                    "label": 0
                },
                {
                    "sent": "Consider simulating completely random process.",
                    "label": 0
                },
                {
                    "sent": "So with a completely random process, if we were to sort of stored entire path, we need to store sort of unbounded amount of information because every past occurs.",
                    "label": 0
                },
                {
                    "sent": "So imagine I'm taking a coin.",
                    "label": 0
                },
                {
                    "sent": "I'm sort of costing that randomly, so every possible past occur.",
                    "label": 0
                },
                {
                    "sent": "So to store that we need bounded amount of information.",
                    "label": 0
                },
                {
                    "sent": "However, if we look at it in this picture, we realize that every part because the past is uncorrelated the future.",
                    "label": 0
                },
                {
                    "sent": "Every path is the same conditional future, so we can.",
                    "label": 1
                },
                {
                    "sent": "We only have a single Pi that is non 0.",
                    "label": 0
                },
                {
                    "sent": "So we.",
                    "label": 0
                },
                {
                    "sent": "So what happens is that we only have let's see.",
                    "label": 0
                },
                {
                    "sent": "So what happens is that we only have a single past with the probability of it happening being equal to 1.",
                    "label": 0
                },
                {
                    "sent": "So when we look through we workout Shannon.",
                    "label": 0
                },
                {
                    "sent": "Information theory is just log of 1 which is equal to 0 and so the idea is that if a system is always in the same state.",
                    "label": 0
                },
                {
                    "sent": "Then we don't need any information to be able to store which state it is.",
                    "label": 0
                },
                {
                    "sent": "We don't learn anything more when we find out that the state that's always zero is zero, and this sort of captures the idea that if we have a completely random process.",
                    "label": 0
                },
                {
                    "sent": "It only takes the amount of information that's needed to model.",
                    "label": 1
                },
                {
                    "sent": "It is exactly 0 bits and this technique can start to be completely general.",
                    "label": 1
                },
                {
                    "sent": "An Epson machines don't start to be sort of the so-called simplest classical models, and this was proven by Crutchfield in this paper in 1989 and so.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Crutchfield because of this he considered the amount of memory these these optimal models require.",
                    "label": 0
                },
                {
                    "sent": "So these circle after models required to be in transit measure of the complexity of a process and the rationale is we don't really need to know how process works.",
                    "label": 1
                },
                {
                    "sent": "We just take a process.",
                    "label": 0
                },
                {
                    "sent": "We look at this output behavior and we go OK. We have no idea how this process working, but we know that to be able to generate the right statistics we need at least as much memory.",
                    "label": 0
                },
                {
                    "sent": "And so people can, you know, go and measure a neuron.",
                    "label": 0
                },
                {
                    "sent": "They can measure sequence of data from a single neuron and they can say OK, I have no idea how the brain works, but it probably contains at least 7 bits of information.",
                    "label": 0
                },
                {
                    "sent": "OK, so it's a really bad lower bound, but one can sort of get these lower bounds by sort of without any knowledge about how the system works on inside, just by purely looking at sort of what's the minimum amount of information required to capture their correct output behavior.",
                    "label": 0
                },
                {
                    "sent": "This has been adopted as a quantifier of complexity and quite a popular quantifier because it satisfies a lot of our intuition about how complexity should behave.",
                    "label": 1
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And this is illustrated by this coffee Cup example.",
                    "label": 0
                },
                {
                    "sent": "So here we have a Cup.",
                    "label": 0
                },
                {
                    "sent": "Imagine that we mixing milk with a coffee at the beginning.",
                    "label": 0
                },
                {
                    "sent": "The milk is on top and the coffee is at the bottom.",
                    "label": 0
                },
                {
                    "sent": "We tend to think about the system is being pretty simple, fairly easy to describe.",
                    "label": 0
                },
                {
                    "sent": "At the end point, the milk in the coffee is all randomized and again looks like a pretty simple system that is homogeneous and it doesn't look very exciting.",
                    "label": 0
                },
                {
                    "sent": "But in the middle was in mixing.",
                    "label": 0
                },
                {
                    "sent": "You know, there's turbulence is all sorts of weird stuff going on highly nonlinear system.",
                    "label": 0
                },
                {
                    "sent": "We have no idea how to describe it accurately.",
                    "label": 0
                },
                {
                    "sent": "And this is the path where complexity happens and it's also captured by sort of the historical development of science.",
                    "label": 0
                },
                {
                    "sent": "The first system that we could understand were highly ordered systems like pendulums.",
                    "label": 0
                },
                {
                    "sent": "So these systems require only you know the position and the velocity and such.",
                    "label": 0
                },
                {
                    "sent": "They were very, very easy to model.",
                    "label": 0
                },
                {
                    "sent": "Then subsequently we develop models for things that were very noisy, like ideal gases where despite the fact that we had no idea how individual particles move, we can still stop predict their macroscopic behavior.",
                    "label": 0
                },
                {
                    "sent": "With a few variables like pressure and temperature and volume, but stuff in between like license talk markers, these are the stuff where we need a lot of information to capture what's going on now and we still don't have a very good idea of how to predict the future statistics and this sort of captures the idea that when we have highly ordered systems, the amount of information we need to describe them in small, we have highly disordered systems to protect their future is small, but somewhere in between things are messy and this is exactly what statistical complexity captures.",
                    "label": 0
                },
                {
                    "sent": "Because.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "When we have a bunch of bits that are uniformly 0, so we don't need to record any information to know what's going to happen in the future, it's just going to be 0 for all time with.",
                    "label": 0
                },
                {
                    "sent": "If we had something that is completely random, again, we don't need to capture any information because nothing we record now will have any relevance to the future.",
                    "label": 0
                },
                {
                    "sent": "And So what happens is that its value of complexity only takes finite nonzero values somewhere in between, and such and such that sort of captures this notion.",
                    "label": 0
                },
                {
                    "sent": "Of complexity in the form of how much information do I need about the past of this process to be able to replicate its use?",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Behavior, so let's go back to sort of that case study of that process with this box with a coin that was shaking, and we can sort of see that with this whole framework is fairly easy to understand.",
                    "label": 0
                },
                {
                    "sent": "Here we had this box and we had this coin and with with sort of probability with every time step we should have checked this box.",
                    "label": 0
                },
                {
                    "sent": "So it's probably PS lips or it does not slope.",
                    "label": 0
                },
                {
                    "sent": "And we can see that the path that the future of this process depends only on the state of the coin to current point in time.",
                    "label": 1
                },
                {
                    "sent": "So when we look at this causal states of this process, we see that we can devise a set of paths into the set of paths with the coin was previously heads and the set of paths with the coin was previously entails.",
                    "label": 0
                },
                {
                    "sent": "Once we know that information, the future weekend, all the information we could possibly get about the future, and on the other hand the future does behave differently depending on whether the coin is currently in.",
                    "label": 0
                },
                {
                    "sent": "Kids are currently entails, so we can't discard this information so that so there are two possible cause of States and and we have to record these so the amount of information that we need is exactly 1 bit.",
                    "label": 0
                },
                {
                    "sent": "And we can sort of write down transition and so we can sort of write down Markov machines that replicate the state of this coin using two states.",
                    "label": 0
                },
                {
                    "sent": "We have a State 0.",
                    "label": 0
                },
                {
                    "sent": "And we have a state one, and we can just sort of iterate between these with a probability of 0.2 with a probability of 0.2 and then here we have 0.8 and 0.8 and we can see that this simple Markov machine completely describes the state of that stochastic process and the amount of memory that's required to store to sort of communicate the status.",
                    "label": 0
                },
                {
                    "sent": "Is Markov machines exactly 1?",
                    "label": 0
                },
                {
                    "sent": "But so if I stored one but you my computer?",
                    "label": 0
                },
                {
                    "sent": "I can then go through this machine and click generate the right future statistics and this sort of captures this idea of sort of building the simplest model.",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And so here we have this box with a single coin inside that is exactly the simplest classical model for this process.",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And so, as a quick exercise, here's a here's a process.",
                    "label": 0
                },
                {
                    "sent": "It's a fairly simple process, is just 012012012.",
                    "label": 0
                },
                {
                    "sent": "Does anyone want to take again that sort of?",
                    "label": 0
                },
                {
                    "sent": "That's sort of the complexity of this process.",
                    "label": 0
                },
                {
                    "sent": "So we have this process and we observe it.",
                    "label": 0
                },
                {
                    "sent": "It's just a box and all it does is it outputs 012012012012.",
                    "label": 0
                },
                {
                    "sent": "It's not particularly complicated, so if we want to analyze this so we what we would do is we would look at the set of possible paths that we could observe.",
                    "label": 0
                },
                {
                    "sent": "Well, there's really only three possible paths that we can observe.",
                    "label": 0
                },
                {
                    "sent": "We can either observe sort of something that ends in 012 so the last observations two, or we can observe something that ends in sort of.",
                    "label": 0
                },
                {
                    "sent": "This is 201 or observe something that ends in.",
                    "label": 0
                },
                {
                    "sent": "Let's see never very good at alternating these sequences.",
                    "label": 0
                },
                {
                    "sent": "This sort of 120.",
                    "label": 0
                },
                {
                    "sent": "So we have these sort of theater.",
                    "label": 0
                },
                {
                    "sent": "The three types of paths we can observe, and as soon as we know which one of these it is, we know exactly what's going to happen in the future.",
                    "label": 0
                },
                {
                    "sent": "We know that after two that should be 0 after one after one, it should be a two after zero it should be a one, etc.",
                    "label": 0
                },
                {
                    "sent": "So we can think about the past that's being divided.",
                    "label": 0
                },
                {
                    "sent": "Into these three States and since it's three states are equally likely, the amount of information that's needed is equal to log 2 / 3, which is a statistical complexity of sort of this this process, and using that we can say that OK, there are many different ways of generating this data, But the simplest way of generating it, and the minimum amount of memory that I'm going to need the minimum amount of information I need to store about the past more precisely, is given by log 2.",
                    "label": 0
                },
                {
                    "sent": "Phase three and this is just a Shannon entropy of a random variable.",
                    "label": 0
                },
                {
                    "sent": "That sort of takes these three possibilities with equal probability.",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And so I think I probably have around about.",
                    "label": 0
                },
                {
                    "sent": "Let's see about 5 minutes, so I'll give you a real quick spiel about how things may happen in quantum mechanics.",
                    "label": 0
                },
                {
                    "sent": "OK, I'll I'll try 5.",
                    "label": 0
                },
                {
                    "sent": "I don't want to bore people with too much of the details or maybe advertiser paralyze, talk back in time so.",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The basic idea is that things happened differently in quantum mechanics.",
                    "label": 0
                },
                {
                    "sent": "So in classical E we had these birds that were either 01 but quantum mechanically what we get is is what we get is something that's motivated by the double slit experiment.",
                    "label": 0
                },
                {
                    "sent": "So many of you probably seen this experiment in high school.",
                    "label": 0
                },
                {
                    "sent": "I found it very boring.",
                    "label": 0
                },
                {
                    "sent": "You guys, probably the two, but it's actually more interesting here.",
                    "label": 0
                },
                {
                    "sent": "Once we put quantum unit.",
                    "label": 0
                },
                {
                    "sent": "So here's a simple experiment.",
                    "label": 0
                },
                {
                    "sent": "We have a light source.",
                    "label": 0
                },
                {
                    "sent": "There's a barrier with two slits inside it, and if we were to propagate this light.",
                    "label": 0
                },
                {
                    "sent": "Down these, toothless what we're going to see.",
                    "label": 0
                },
                {
                    "sent": "This interference pattern now this interference pattern is fairly easy to explain if we think about light as a wave, because what happens is that you have these waveforms coming in and you get constructive interference.",
                    "label": 0
                },
                {
                    "sent": "When sort of this point on, the screens equal distance from these two slots, but if it's sort of 1/2 integer wavelength offset then you get destructive interference and that sort of cancels out the amplitude and we get a dark fringe and so have we understand it's pretty simply using the wave theory of light.",
                    "label": 0
                },
                {
                    "sent": "But we know that light is not just a waste of Einstein.",
                    "label": 0
                },
                {
                    "sent": "In 1904 published his famous paper called the Photoelectric Effect, which stated that light with the particle and if light was a particle, then things become stranger because particles.",
                    "label": 0
                },
                {
                    "sent": "We generally don't think about as interfering, and in fact you can make the source of light so weak that only a single part of photon transmits features is ever exist between the screen and the barrier at the same time.",
                    "label": 0
                },
                {
                    "sent": "So there's no way that photon can interfere with another photo.",
                    "label": 0
                },
                {
                    "sent": "And so if we do this experiment, though, and we collect the data, what we find is.",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That still, if we collect the data line, if we just record where each photon hits the screen, eventually we're going to build up.",
                    "label": 0
                },
                {
                    "sent": "While these interference fringes.",
                    "label": 0
                },
                {
                    "sent": "So this was very troubling to people who first studied this back in the early 20th century, because how can this particle you know just one of it interfere?",
                    "label": 0
                },
                {
                    "sent": "What's at interfering with people were just very confused by this.",
                    "label": 0
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I mean the way I mean, why they're confused as you can think about the soccer field, right?",
                    "label": 0
                },
                {
                    "sent": "Here is the soccer kicking soccer balls is 2 barriers.",
                    "label": 0
                },
                {
                    "sent": "You think OK, the ball should be here in here, but then they end up with this interfere with interference friend and you like what is going on?",
                    "label": 0
                },
                {
                    "sent": "It's kind of crazy an.",
                    "label": 0
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "People have done this so experimentally was electrons with photons with atoms and more recently with these buckyballs which are basically molecules 60 carbon atoms.",
                    "label": 0
                },
                {
                    "sent": "So people can do this with a whole range of different stuff.",
                    "label": 0
                },
                {
                    "sent": "All these microscopic particles seem to display this sort of interference behavior.",
                    "label": 0
                }
            ]
        },
        "clip_55": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So what really is going on?",
                    "label": 0
                },
                {
                    "sent": "It was proposed by Schroedinger.",
                    "label": 0
                },
                {
                    "sent": "Is this theory of quantum mechanics so Schroedinger said?",
                    "label": 0
                },
                {
                    "sent": "Look, the only way to explain this is if we think about a particle as being in can be in multiple places at the same time yourself.",
                    "label": 0
                },
                {
                    "sent": "Thinking with the passive going through one slit, we have to think about it going.",
                    "label": 0
                },
                {
                    "sent": "It's going through two slits simultaneously, because that's the only way I could generate this interference pattern.",
                    "label": 0
                },
                {
                    "sent": "Only if there's a probability amplitude wave that describes where it's going to be an only if that wave interferes service itself, the so called wavefunction can we end up with the right interference pattern.",
                    "label": 0
                },
                {
                    "sent": "So he postulated this idea of wave mechanics and the famous shorting this equation, which I won't get into, but the basic idea is classically we have a state zero in the statement, but quantum mechanically we can get these states, which is a quantum superposition of their own one.",
                    "label": 0
                },
                {
                    "sent": "Don't worry too much about the braces notation, it's just a quirk of quantum physicist.",
                    "label": 0
                },
                {
                    "sent": "They love using this notation.",
                    "label": 0
                },
                {
                    "sent": "You can think about this is just zero and one.",
                    "label": 0
                },
                {
                    "sent": "And so the particle can go through two slits simultaneously, and what's even stranger is that a physicist immediately asked, well, I don't believe he goes through two sets at once.",
                    "label": 1
                }
            ]
        },
        "clip_56": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Why don't we just put a detector here?",
                    "label": 0
                },
                {
                    "sent": "Why don't we just put this detector and just see whether or not it goes through one whole another?",
                    "label": 0
                },
                {
                    "sent": "And if we do that, what happens is that indeed each time we see the path goes going through only one slip.",
                    "label": 0
                },
                {
                    "sent": "But the caveat is now the interference pattern is destroyed.",
                    "label": 0
                },
                {
                    "sent": "We just get 2 bright fringes that where the sources in the first call now behaves exactly like a particle, not away.",
                    "label": 0
                },
                {
                    "sent": "And this is this idea of a passport duality and a special case that the Heisenberg uncertainty principle in the sense that we can either choose to observe which slit the path goes through, or we can choose to observe the interference.",
                    "label": 0
                },
                {
                    "sent": "We can't do both at the same time.",
                    "label": 0
                },
                {
                    "sent": "And this sort of captures is heart of quantum theory, and it also gave a new way of understanding information, because we can think about a path going up and down as the two states of a classical bit that is either one or zero.",
                    "label": 0
                },
                {
                    "sent": "And what quantum information allows us to do is to have a superposition of 01.",
                    "label": 0
                },
                {
                    "sent": "This gives us a lot more freedom and.",
                    "label": 0
                }
            ]
        },
        "clip_57": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Gives a lot more power.",
                    "label": 0
                },
                {
                    "sent": "It also confuse the hell out of physicists so have a. Niels Bohr was one person said OK they recently call Real can no longer be sort of a air isn't everything we call real is made up of things that cannot be regarded as real.",
                    "label": 1
                },
                {
                    "sent": "If quantum mechanics hasn't profoundly shocked you so you haven't understood it yet and this is what gave birth to the idea of shorting this cap.",
                    "label": 1
                }
            ]
        },
        "clip_58": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And now sort of.",
                    "label": 0
                },
                {
                    "sent": "We go back to our picture and probably we're running out of time.",
                    "label": 0
                },
                {
                    "sent": "So let's go back quickly to our picture and normally we sort of thought about this as a classical information processor.",
                    "label": 1
                },
                {
                    "sent": "But because reality is fundamentally quantum mechanical, what the correct way of thinking about things is ready to think.",
                    "label": 0
                }
            ]
        },
        "clip_59": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "But as a quantum information processor, we're still recording classical bits of information we're still describing are experimenting of classical bits of information, but the way it can transform in the middle, that state can take on multiple different values at the same time, so we can write down.",
                    "label": 0
                },
                {
                    "sent": "We shoot photos up this way, and that's a well defined experimental setup, and we can say we record that the photon hit the barrier here.",
                    "label": 0
                },
                {
                    "sent": "That's classical information, but in the middle where we don't observe it, it can do multiple things.",
                    "label": 1
                },
                {
                    "sent": "At the same time.",
                    "label": 0
                }
            ]
        },
        "clip_60": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And this is what gives quantum information is power, because classically we are constrained to our probability spaces constrained to this line here.",
                    "label": 0
                },
                {
                    "sent": "But quantum.",
                    "label": 0
                }
            ]
        },
        "clip_61": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Currently you can get sort of Schrodinger's cat states, which is called 0 + 1, or you can actually get a different sort of interference pattern and you can get sort of 0 -- 1 so you can actually get many different forms of alive plus.",
                    "label": 1
                },
                {
                    "sent": "Then I won't go through the details, but essentially the state space becomes a lot larger.",
                    "label": 0
                },
                {
                    "sent": "Incense or 1 dimensional line.",
                    "label": 0
                },
                {
                    "sent": "We end up with three dimensional sphere with the entire surface of the sphere.",
                    "label": 0
                }
            ]
        },
        "clip_62": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "A valid sort of definitive quantum States and because of that there seems to be much more greater degrees of freedom of recall.",
                    "label": 0
                }
            ]
        },
        "clip_63": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The information and so we can do sort of experiments on this.",
                    "label": 0
                },
                {
                    "sent": "We can still take that model that I've shown you before, and you can sort of encode it inside a quantum sort of a quantum device which inside photons which exhibit this sort of simultaneous simultaneous.",
                    "label": 0
                }
            ]
        },
        "clip_64": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And what we get is that we can improve over the classical model when the classical model always requires one bit of information to generate that perturb coin.",
                    "label": 0
                },
                {
                    "sent": "Example that I told you earlier, the quantum one can actually get it down all the way to 0 depending on how hard we shake the system and this sort of captures the idea that.",
                    "label": 0
                },
                {
                    "sent": "Ultimately, things can look simpler quantum mechanically.",
                    "label": 0
                },
                {
                    "sent": "That's something that takes a lot of memory to simulate.",
                    "label": 0
                },
                {
                    "sent": "Classically, can take a lot less dissimilar quantum mechanically.",
                    "label": 0
                }
            ]
        },
        "clip_65": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You can go and generalize this two different things instead of just looking at system that outputs sort of a bunch of statistics, you can look at more general systems that actually adapt their behavior to sort of the output differently depending on sort of how you kick it.",
                    "label": 0
                },
                {
                    "sent": "So these so called input output processes, and so ultimately what sort of this work shows, is that there are many different levels of complexity that when we look at the object and we want to understand it, so one of the ways of sort of understanding that is to look at.",
                    "label": 0
                }
            ]
        },
        "clip_66": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "One of the ways of understanding it to look at how much information we need to be able to sort of replicate the process, and this can be captured by the idea of Shannon entropy.",
                    "label": 0
                },
                {
                    "sent": "Now the basic idea of some complexity theorem of sort of computation mechanics.",
                    "label": 0
                },
                {
                    "sent": "You should say that now we understand this quantifiable information.",
                    "label": 0
                },
                {
                    "sent": "We can use it to quantify exactly how much information it takes to simulate the process.",
                    "label": 0
                },
                {
                    "sent": "And using that we get this measure of complexity, statistical complexity.",
                    "label": 0
                },
                {
                    "sent": "And once we get this measure, though, this measure can actually behave quite differently depending on whether we are able to process information classically or quantum mechanically.",
                    "label": 0
                },
                {
                    "sent": "So I think that I will basically stop there and leave.",
                    "label": 0
                }
            ]
        },
        "clip_67": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is final.",
                    "label": 0
                },
                {
                    "sent": "Take home message.",
                    "label": 0
                },
                {
                    "sent": "If you didn't get anything analysis, the take home message everything looks in our world as a physical object.",
                    "label": 0
                },
                {
                    "sent": "When we first think about things, we think about things as physical objects.",
                    "label": 0
                },
                {
                    "sent": "But if you.",
                    "label": 0
                }
            ]
        },
        "clip_68": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We'll take our current view.",
                    "label": 0
                },
                {
                    "sent": "You step back and look at this information theory, and especially if you start thinking about it in terms of quantum information theory then.",
                    "label": 0
                }
            ]
        },
        "clip_69": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You can end up doing incredible things, maybe not stop bullets, but since that are well, not quite as exciting as stopping bullets, but still quite exciting nonetheless.",
                    "label": 0
                },
                {
                    "sent": "Thank you very much.",
                    "label": 0
                }
            ]
        },
        "clip_70": {
            "is_summarization_sample": false,
            "summarization_data": []
        }
    }
}