{
    "id": "deayp2orywcqtczqmv53uynbvir4mdmc",
    "title": "Probabilistic numerics for deep learning",
    "info": {
        "author": [
            "Michael Osborne, Department of Engineering Science, University of Oxford"
        ],
        "published": "July 27, 2017",
        "recorded": "June 2017",
        "category": [
            "Top->Computer Science->Machine Learning->Deep Learning",
            "Top->Computer Science->Machine Learning->Reinforcement Learning",
            "Top->Computer Science->Machine Learning->Unsupervised Learning"
        ]
    },
    "url": "http://videolectures.net/deeplearning2017_osborne_probabilistic_numerics/",
    "segmentation": [
        [
            "So good morning everyone.",
            "I guess I'd start out by just recognize the contribution to this talk made by Filipeni.",
            "He's not here today, but with whom I'm writing a book on probabilistic matrix to be out either later this year or next year.",
            "So a lot of the slides here come from Phillip thanks to him.",
            "Right, so I thought I'd start by trying to find what it is we do in machine learning.",
            "At least you know to my way of thinking, which is to join up a model which is the thing we really want to deal with to another kind of component, which is the computation.",
            "So within computation we do things like well, optimization, quadrotor really to me computation is about numerics and of course the problem we face is that the kind of models we want usually aren't amenable to the computation we have, right?",
            "We've got all this beautiful theory, universality, probability theory.",
            "But at the end of the day, the things we actually most desire aren't actually going to work on the computation we have.",
            "So to tackle that problem, I think the normal way of doing things.",
            "In fact, the way that Yoshi was speaking to most eloquently earlier, is to think about the computation we have, so you know the kind of optimization that we can actually do.",
            "The gradients that it needs and use those considerations to drive the constructions of the models in the 1st place, which is absolutely a very powerful way of approaching things.",
            "That's led to a lot of success, but the big, beautiful idea.",
            "At the heart of probabilistic numerics is to take that information transmission the other way around.",
            "So within probabilistic numerics we try to take the things we're most interested in achieving.",
            "So let's take probability theory that suite of tools and apply them to computation.",
            "So probabilistic numerics is really about applying the lens of probability theory to numerics to the kind of computational cores at the heart of what it is we want to achieve.",
            "So."
        ],
        [
            "With that framing, I thought I'd first of all mention to you that we have a whole website on this topic.",
            "It's called probabilistic numerics.org, and if you're going to have to compress this talk down to what 11 characters?",
            "I guess there."
        ],
        [
            "Even characters I would like you to compress down to aproblem.org so the website is got."
        ],
        [
            "A whole host of things up there.",
            "It's got like an up-to-date list of all the meetings and workshops and conferences arranged on probabilistic numerics.",
            "In fact, there was a big summer school, organized what just last week in Italy on probabilistic numerics."
        ],
        [
            "It's also got a list of all the literature that's being pumped out now, and probabilistic numerics.",
            "So in fact probabilistic numerics is quite an old field.",
            "The oldest paper on this list is point carriers from 1896.",
            "I'm wearing a francophone city, so I apologize if I said point carrying correctly, But anyway, so the field is taking awhile to get going.",
            "I guess there are a bunch of papers out in the 80s from Diaconis from Ohagan, but it's really only in the last couple of years that we've.",
            "Began to realize the real potential of the field, I think, so you know, this is being very.",
            "Recently and frequently updated now these papers are coming out.",
            "Do keep an eye on it.",
            "And for the purpose of begin."
        ],
        [
            "The talk I thought I'd talk about, not the whole suite of numeric problems, of which, of course there are many integration optimization, ODS solving linear algebra, but focus instead on global optimization, which for the purpose of this torcal definers the requirement of numerically optimizing a function which is multimodal and very often expensive to evaluate.",
            "So one evaluation of this function might take something like several hours of computation it might take.",
            "The drilling of a new oil well, for instance, or the you know, an entire drug trial which might take months and sort of millions of dollars.",
            "And just to be absolutely clear, the kind of problems we're going to be taking, at least in the first part of the talk, are relatively low dimensional, so we're talking about problems that are probably not more than, say, 20 or 30 dimensions, just to be absolutely clear about it."
        ],
        [
            "Right, so thinking about the optimization numerically function that looked like this.",
            "People very often test out their algorithms, benchmark on a standard suite of test problems, and perhaps the most Canonical of them all is the rosenbrock called banana function, and I thought I might just put up on the slide it's expression.",
            "So I've counted correctly.",
            "This mathematical expression contains no more than 17 characters.",
            "So in a sense, we know it really, really well, right?",
            "I mean, it's not a complicated expression just looking at that expression you can immediately see that it's going to have certain behaviors.",
            "So the fact that it's the combination of two sums of real numbers means that this is going to be positive.",
            "That's quite an interesting thing to know already, just from its mathematical expression.",
            "And of course, this can be evaluated in literally microseconds on any standard laptop.",
            "So in all those sensors, this is a function that we know really, really well, but in another sense we don't know it and that sense is that just from that mathematical expression, there's no easy way of arriving at its global minimum.",
            "So that's quite a weird thing, right?",
            "So in one sense, this is a really well characterized object, but in a numerical sense it's completely unknown.",
            "And."
        ],
        [
            "The reason for that lack of knowledge is really that notion of computation.",
            "So in a world in which we had infinite high precision computation, in fact, that whole issue would not arise.",
            "So we could simply do a grid search of this test function of the rosenbrock at really high granularity.",
            "We would get its value everywhere in the two dimensional domain and then we would have its global minimum.",
            "It would be known, but in reality of course we don't have that infinite amount of computation and that induces this epistemic uncertainty about what its minimum is."
        ],
        [
            "So in light of that uncertainty about the minimum of this function.",
            "The kind of central inside of probabilistic numerics is to bring to bear the best tools we have for dealing with uncertainty.",
            "Which are, you know, probability theory and decision theory.",
            "So in particular, the first part of the contribution of probabilistic numerics is to treat something that isn't a sense well known, like that rosenbrock function as unknown and model it with probabilistic model.",
            "So in the case of optimization, we're going to treat F of XY, the function itself as a random variable and apply to it all the tools we have from probability theory.",
            "So that's the first component of probabilistic marks, the second component that allows us to really get to grips with the fact that we have a finite computational budget is to bring to bear all the tools of decision theory.",
            "That is, to a probabilistic.",
            "Numerous cyst computation is a finite resource.",
            "That we want to use as best as possible to achieve our ends, which in the case of optimization might be something like finding the minimum to the greatest degree of accuracy possible.",
            "So right from here, the talk is going to kind of diverge.",
            "I'm going to separate out those two components, probabilistic numerics, the probabilistic modeling and the decision theory and the 1st."
        ],
        [
            "Is obviously going to be probability theory.",
            "That's what is the underpinning for everything else in particular in this first part of the talk I'm going to talk about the probabilistic modeling of functions.",
            "Now I'm sure that you've all met probability theory before, and the mechanics of it fairly uncontroversial and easy to grasp."
        ],
        [
            "But I thought I might try to drive home the way that.",
            "Question.",
            "Not sure is is my voice being picked up by the microphone.",
            "I apologize if any of that was unclear.",
            "Is that better?",
            "OK, so any questions then, given that you may not have heard the entire first part of the talk.",
            "Should I repeat ahead or?",
            "Let's just assume that was all totally clear.",
            "Is that right?",
            "OK?",
            "Right, so yeah, as Graham said, I.",
            "Hand on heart.",
            "Really not a deep learning person.",
            "For which I apologize, instead I. Anna Bayesian and I might just draw this little vertical line down my chest.",
            "That's the conditioning bar.",
            "That's the sign of Bayesians.",
            "And the way Bayesians think about probability theory is a little bit different to how other people use it.",
            "So to a real card carrying Bayesian probability is an epistemic degree of belief.",
            "So probability in answer to the question that was asked yesterday actually is taken as an expression of confidence in a proposition.",
            "So.",
            "One proposition in particular we might want to consider is the probability that it will rain.",
            "And.",
            "Yes, so traditional yeah, think about that kind of proposition.",
            "It's usual to position probability theories being an extension of traditional deductive logic.",
            "So deductive logic would allow us to say if it was raining.",
            "It must with absolute certainty be cloudy.",
            "Probability theory allows you to quantify the inverse relationship, so it allows you to say, given that we've observed that it's cloudy, what is our belief that it might also be raining?",
            "And the way."
        ],
        [
            "We do that mechanically.",
            "In probability theory is to construct these conditional distributions, so the particular object of interest.",
            "If you're thinking about whether or not it will rain, is the probability of it raining.",
            "Given that is conditioned on an observation that it's cloudy.",
            "And as I said, this probability is an epistemic degree of relief, and it's important to emphasize that."
        ],
        [
            "When we talk about this being epistemic, it means that it's personal.",
            "It's bespoke to a particular agent, and whenever we're dealing with probability theory, it's essential to be clear about what that agent is.",
            "So usually in machine learning, we're talking about the agent being kind of a machine learning model, but I seem to have gone into that plane mode, which the portion.",
            "Could also be a human.",
            "We might try to model A human with."
        ],
        [
            "Conditional probability distribution.",
            "Or it could also be something like a pigeon in my PhD work.",
            "Actually we were using probability theory to model the navigation behaviors of pigeon, which is why I put that on the slide.",
            "OK, I would like to buy that auto advancing.",
            "Let me see if I can get out of it.",
            "Not great.",
            "OK, so."
        ],
        [
            "How to find out that I was on the right hand side of that condition bar and coming back to my previous point about this probability distribution being particular to a chosen agent, the eye specifies that agent, so we use I as context which defines the particular agent at hand, and another way of talking about eyes.",
            "That's the prior information available to that agent.",
            "Now.",
            "Sorry.",
            "That's really going to bother me.",
            "Sorry.",
            "What is the shortcut I need to press so that doesn't do that?",
            "Auto advancing.",
            "I'll buy you a Mars bar if you tell me what it is.",
            "No one, no one uses PowerPoint.",
            "Good for you.",
            "We just try and bear with it I guess.",
            "OK, so yeah it is.",
            "It is pretty bad, yeah?",
            "I am using PowerPoint.",
            "Yeah.",
            "Right click and.",
            "Screen spot displays not immediately seeing this non order dance.",
            "Anyway, let's bear with it.",
            "I apologize for that.",
            "Thank you Simone to my rescue, hopefully.",
            "OK, so in machine learning it doesn't make sense to talk about an agent that's out there in the world.",
            "In a sense, we're building an agent, right?",
            "And so.",
            "Our goal is to select the right priors for the task at hand that I is available under our control.",
            "And so in a sense, in this decision theoretic sort of way, we want to pick the prior that is most appropriate to the particular problem we're trying to solve in the particular computation that we have available to us."
        ],
        [
            "And in particular, prior that's almost ubiquitous across probability theory in general, but in particular in probabilistic numerics is the Gaussian.",
            "And of course, you've met the Gaussian many times in the past, but I thought it might just flag up why it's such a useful object for us, and some might do that by putting up on the slide a bivariate Gaussian.",
            "This kind of two dimensional Gaussian as illustrated by the contours on the slide.",
            "Again, it's order advancing, which is annoying.",
            "Anne and.",
            "What we might want from that bivariate Gaussian is one of two distributions, one of which is a marginal distribution.",
            "That is, given a distribution over Y2 and Y1, we might want the distribution over just Y one alone.",
            "And.",
            "How many computer scientists does it take to fix this?",
            "Is anyone here actually from Microsoft?",
            "Never microphones feedback.",
            "Let's try and bear with it.",
            "With apologies.",
            "So one thing we might want out of this bivariate Gaussian is the.",
            "The marginal distribution for Y1 alone, that is, the distribution for just one of those variables and actually a super useful property of the Gaussian, is that that marginal distribution contributed in closed form really easily, and in fact, that marginal distribution is itself Gaussians.",
            "That's the blue curve at the bottom of the slide.",
            "Another distribution we might want is a conditional distribution.",
            "So in a Bayesian sense that conditional distribution might represent, for instance, the.",
            "Posterior probability of Y1 given that we've observed that Y two is equal to minus five and again for the Gaussian.",
            "We have this amazing property that it can be computed in closed form, and it is again a Gaussian.",
            "So in a sense this Gaussian is closed under both conditioning and marginalization, which is super super useful and I'll tell you in a couple of slides why exactly that is in the case of doing inference about functions.",
            "Let's try and get to that point.",
            "I want to represent that conditional distribution the Y one given Y two in a slightly different way, and that's what we've got on the right hand side of the slide.",
            "So what it shows is the distribution for Y one in the first column, conditional on the observation of Y2, which is represented in the second column with kind of a drag Delta function, because in fact the posterior distribution for Y1 and Y2 that joint conditional on the observation that Y two is equal to minus 5.",
            "Has a marginal for Y2, which is, you know, perfectly certain.",
            "We've observed that Y 2.",
            "That was a bit of a mouthful, but hopefully you get what I'm trying to represent that this is a joint distribution for Y1 and Y2 conditional on Y2.",
            "Represented rather than in that kind of bivariate way in these two columns.",
            "And if you're happy without representation, hopefully you're also happy with me."
        ],
        [
            "Making the generalization to not just two variables but say 10K, it seems like that's been fixed.",
            "Thank you very much and if you're happy with that, you might be happy with me generalizing from 10 variables to a potentially infinite number of variables.",
            "Now that generalization to that potentially infinite number of variables gives us a very special object, which is called a Gaussian process, can just ask for a show of hands from who was heard of the Gaussian process before.",
            "Most people have, which is great, in which case I apologize for wasting your time to some degree.",
            "But um, yeah, what that Gaussian process gives us?",
            "Then by considering that limit squishing that not just finite number of variables but potentially infinite number of variables infinitesimally close together is a way of doing inference about functions, which you can think of as being kind of represented by an infinite dimensional length vector.",
            "So on this slide I've got a cartoon of water.",
            "Gaussian process might look like."
        ],
        [
            "The posterior distribution for Y as a function of X where we observed Y at 5 different points.",
            "And the beating heart of a Gaussian process is what's known as its mean and covariance functions, which are just the generalization of the mean vector and covariance matrix that define a usual multivariate Gaussian distribution.",
            "And."
        ],
        [
            "Without saying too much about it, the important thing to know about that covariance function, if you haven't encountered it before, is that it really is quite a very.",
            "It is very flexible way of modeling functions there.",
            "All kinds of things we can bake into a covariance function to encode properties to define its prior suitable to the kind of functions with which we're dealing.",
            "So in particular might want to bake into a covariance function.",
            "Knowledge that signal is periodic, and that periodicity could be combined with some longer term drifts.",
            "We can define covariance functions for multiple tasks or multiple time series that might be correlated to some degree, but have delays between them all.",
            "This is possible and more.",
            "But"
        ],
        [
            "Anne.",
            "You know, obviously this is deep learning summer school, so I wanted to bring out some of the differences between thinking about functions in a Gaussian process way from thinking about them through modeling with neural networks.",
            "So first thing that this Gaussian process framework gives us is a move away from doing inference by optimization.",
            "So the weights in a Gaussian process kind of implicit and are in Ferd not through having to optimize them, but in fact through linear algebra.",
            "Which is in a sense better because linear algebra is perhaps.",
            "Better behaved.",
            "And also it means that through that linear process we get not just an optimized value for those weights, but in fact implicitly an integral over all possible values for them, which is quite nice.",
            "Return to that topic later in the talk, but that integral over all possible setting for the weights gives us a means of modeling functions that is quite robust to overfitting.",
            "So here is me trying to model a quadratic with the Gaussian process and you."
        ],
        [
            "I think that given a sufficient number of observations, we should learn this quadratic perfectly, right?",
            "In fact, we are learning it pretty well, but crucially, for the particular covariance function that we've chosen, we don't."
        ],
        [
            "Overfitted, we haven't.",
            "You know reduced our variance to infinitesimal amounts between the observations.",
            "We're maintaining a reasonable amount of epistemic uncertainty in regions where the function hasn't been evaluated, because this gas and process doesn't know that the functions modeling is a quadratic."
        ],
        [
            "OK."
        ],
        [
            "So that was the first part of probabilistic numerics.",
            "As I say, these Gaussian process is kind of equetus across the entirety of the field, but there only one component of what it is we do within probabilistic matrix, and the second component as I was trying to raise earlier, is thinking about that use of computation in a decision theoretic way."
        ],
        [
            "I would like to return to global optimization.",
            "And of course, the use of computation we make with in global optimization is the evaluation of the objective.",
            "So each objective evaluation as it was trying to get out earlier might require something like the training of a model which uses several hours of computation.",
            "It might take a drug trial which takes millions of dollars, so those are costs that we want to take very seriously in thinking about how to do this optimization process in an optimal way."
        ],
        [
            "So.",
            "In particular.",
            "We're going to try and represent within the probabilistic numeric way of thinking about global optimization, which is called Bayesian optimization, not particularly originally.",
            "By representing the two core components of our loss function here, the first of which is that kostman valuation, which on this slide are represented with an Australian $100 notes interesting facts.",
            "the Australian dollar is now almost one one parity with the Canadian dollar, so that is 100 Canadian dollars.",
            "Actually that wasn't that interesting.",
            "I apologize for mentioning it.",
            "But the other term in our loss function, of course is the degree of uncertainty we have in the object of interest, and we need to bring both of those into our loss function in some sort of way."
        ],
        [
            "So.",
            "There are many ways of coming up with loss functions for Bayesian optimization.",
            "Here I'm just going to present one of them, the one that I think is most intuitive.",
            "It's known by many names.",
            "Expected improvement is perhaps the most ubiquitous.",
            "But essentially what it does is to say let's ignore the cost of computation through the means of just limiting ourselves with finite budget of evaluations.",
            "So we're going to say that.",
            "We have some evaluations available to us to find the optimum of this function.",
            "And in particular, in expected improvements, we're going to take the quite severe myopic approximation that we have only one such evaluation remaining.",
            "So in that myopic approximation, the loss that we'll get is.",
            "Actually, the best function value we have after that next evaluation is spent.",
            "So at this point I should apologize for the fact that optimization is usually framed as a minimization problem rather than as a maximization problem.",
            "When I've said that the loss is the lowest function value found after next valuation, that might have sounded a bit unintuitive, but if you think about it the other way around, that is of course as an or decision theory can frame it either as an minimization of loss or a maximization of utility.",
            "The equivalent utility function to this would say the utility we get after the next in function evaluation is the highest function value.",
            "There you know that we've been obtained, which to me seems a little bit easier to understand.",
            "But either way, what that means is that there are two possibilities.",
            "Either the next function value Huawei is better than the best that we've got so far, which we call Eater, in which case our losses that why otherwise we can fall back to the best value that we obtained so far, which gives us just data.",
            "So this is kind of like a rectified linear unit.",
            "In fact, this loss.",
            "Did you see how connected that's deep learning?",
            "Was that satisfying?",
            "Anne, right."
        ],
        [
            "So of course, in decision theory, the objective on which we actually act is an expected loss.",
            "So now what we have to bring to bear is that probabilistic model that I was talking about in the early part of the talk.",
            "So what we need to do is to compute the expectation of that loss function on the previous slide against the probability distribution for what next function value will be.",
            "So that choice of loss function and the choice of Gaussian process to represent the Gaussian marginal over the next function value.",
            "Gives us a loss function that is actually tractable.",
            "And the way of thinking about it, that expected loss is the.",
            "Expected lowest value of the function out the expected lowest value of the function.",
            "We've gone after that next valuation."
        ],
        [
            "So let's go into a kind of cartoon process of Bayesian optimization.",
            "In which we've chosen a Gaussian process to model our objective function and that simple expected improvement loss function.",
            "So let's imagine we start with just a single evaluation of a loss function, which is given in the dots.",
            "So you can see that it's bimodal.",
            "The evaluation is the cross and on the basis of that cross we've produced a Gaussian process posterior kind of pink sausage here, which has got a posterior mean in the red line and a posterior variance in the plus or minus single stand deviation.",
            "Credibility intervals plotted on the slide.",
            "And on the basis of that Gaussian process posterior, we can do that integral on the previous slide to compute what the expected losses of evaluating this function anywhere else in its domain.",
            "And that's the blue curve.",
            "So have a look what it's telling us.",
            "It's saying that as I said earlier, the expected best value of the function we've got is going to be low if we evaluate anywhere else in this domain other than close to where we've already evaluated.",
            "Because in those regions removed from our current valuation, there's some probability, even if small, of getting a function value that's actually significantly better than what we've seen so far, so the expected loss has these dips.",
            "Either side of the evaluation closely evaluation we get high expected loss that's not likely to give us anything better, so the best next action is the diamond.",
            "That's where we're going to evaluate the function.",
            "If we do, we get the second cross on the slide.",
            "Which you know, it was really surprisingly good.",
            "If you go back."
        ],
        [
            "So the credibility intervals from this slides and notes where the function value actually ended up.",
            "We got something that was way better than we were expecting to see.",
            "So on that basis we update our posterior belief over the function and on the basis of that posterior we can compute a new expected loss and look how different its behavior is now.",
            "So now the sorry I can't be seen on that side on camera.",
            "Apparently I better go to this side.",
            "It's got now two lobes, one either side of the current best evaluation.",
            "Leading us not to kind of explore further afield, but instead to move to what we call an exploitative behavior.",
            "In which we want to evaluate quite close to the existing evaluation becausw it would have been extraordinarily lucky had we found an evaluation that was truly at the best function value in that particular neighborhood.",
            "If it was at a local mode.",
            "Instead, we think it's quite likely to find a function value that's even better if we just exploit a little bit harder.",
            "So if we do that, we fine."
        ],
        [
            "Another function value, which is in fact a little bit better and then subsequent to that we exploit again by going in between those two evaluations and at that point we've more or less found all the information there is to be had in that local region.",
            "Now I expected loss is telling us there's not much value left in spending further evaluations in that particular local region.",
            "We've more or less resolved our uncertainty to the degree that we have to.",
            "So at this point we switch to what's known as an exploratory mode.",
            "Image."
        ],
        [
            "The greatest value is going to be achieved by trying to track down some of those big regions of uncertainty further out to the right and left so little Blue Diamond now tells us to perform an explore move.",
            "We do that.",
            "We do it again and."
        ],
        [
            "That second time round, we get another lucky break.",
            "We find another function value which was a lot better than what we expected to see."
        ],
        [
            "At that point, we switch again into an exploitive mode, and in doing so, we."
        ],
        [
            "Quickly discover what turns out to be the true global minimum of this function near enough, and having done."
        ],
        [
            "The remainder of our budget of valuations is going to be spent in really tracking down all remaining regions of uncertainty.",
            "So what I hope that cartoon is illustrated is that through this quite simple model of the function and Gaussian process and a simple decision rule, we get emergent behavior that's remarkably intelligent.",
            "Question it back.",
            "Discussion process model.",
            "OK, so that is a question not about Gaussian processes, but about covariance functions.",
            "Actually, because within a Gaussian process you can certainly come up with covariance functions that are very non smooth.",
            "But you're right in fact that the most commonly used covariance functions doing code some degree of smoothness.",
            "But to me that makes a lot of sense.",
            "I mean in fact optimization in particular is impossible unless there is some smoothness in this function.",
            "So the challenge is.",
            "In finding out what degree of smoothness is most appropriate to the particular objective we have at hand, and we get that, in a sense, magically from the Bayesian engine in kind of working out what the best high parameters are for a particular covariance function.",
            "Hiking.",
            "So this was a question about the degree to which Gaussian processes can be used in high dimensions.",
            "And you're absolutely right that the state of the art in GPS does not scale up well with dimension.",
            "That's a whole another talk really about how you get them to do that, and you know there is kind of cutting edge work that gives us stuff that does actually work even in a million dimensions for the purpose of this talk, I'm going to say only that there are really interesting problems in only 20 dimensions.",
            "There are a lot of hyperparameter tuning problems in particular.",
            "In which you might only have 20 high parameters to tune, and you want to spend a lot of computing getting them as well as possible.",
            "In motion.",
            "Like you're looking for smooth transition.",
            "Yeah, so the question was in Brownian motion.",
            "Obviously we get non smooth functions, non differentiable functions.",
            "Local places.",
            "Yeah, I think yeah, let's talk about this later.",
            "I mean really all for this talk I want to get across is that there are many different covariance functions you can choose later in the talk.",
            "Hopefully I'll get to tell you about how we might pick the covariance function that is best suited to the particular numeric problem in hand.",
            "You know what?",
            "I'm just going to give you a little advertisement for that one.",
            "Super interesting thing about numeric problems, which is different from almost any other type of problem of learning, is that the object is available to us, right?",
            "So in a numeric problem, the objective function might be like that rosenbrock function in which we have a clear, concise mathematical expression.",
            "It might be expressed in source code, which we can go and inspect.",
            "So probabilistic numerics may be distinct from any other part of learning.",
            "We do actually have a really strong basis for building those priors, right?",
            "We can look at the mathematical expression for an objective.",
            "We can inspect the sports, support the source code of the particular.",
            "Model that we're trying to optimize and use that construct the prior that is most suited to the problem."
        ],
        [
            "Right so."
        ],
        [
            "How?",
            "Why this Mail?",
            "Pick approximate widely?",
            "Finding this blue loss function and use the myopic approximation with this notion provide this magical way to to explore and discover the job opportunities explained that inclusion or the reason why it works.",
            "So the question was why does this myopic strategy nonetheless give that something that kind of looks magic?",
            "So actually I wouldn't recommend the myopic strategy in particular, and you get even.",
            "More interesting behavior by trying to think further steps into the future, and we've done some work in relaxing that mark approximation, but I think it is interesting that even with this really quite severe approximation, we do get this quite powerful behavior out.",
            "Why is that?",
            "It's because there's been all this work under the hood in thinking very seriously about uncertainty, so even considering only a single evaluation into the future, we still are trying, you know, that's built on the back of reasoning of.",
            "You know just how confident we can be about this function anywhere else, so there is still that motivation to try and track down regions in which there hasn't been any evaluation so far.",
            "So even though we're only considering one step into the future, there is still an incentive to find regions of high uncertainty due to the kind of mechanics underpinning the Gaussian process.",
            "Was that an answer to my question?",
            "Can I say that?",
            "The North function called somehow encode the uncertainty inside no no.",
            "So the question was, does the loss function encode the uncertainty?",
            "The loss function is independent of the probabilistic model.",
            "It's the probabilistic model that reflects the uncertainty.",
            "It's our statement about our epistemic beliefs about the function.",
            "Question.",
            "Like this?",
            "Excellent question about the fact that these Gaussian processes themselves have hyperparameters.",
            "In fact, that's kind of the next part of the talk, But yeah, so it's important to recognize this kind of infinite recurse we often experience in probabilistic numeric switches in bringing a probabilistic model to numerics problem.",
            "That probabilistic model itself will require.",
            "Numerics problems in order to actually fit it to a function, what we normally do is kind of go down the chain of numerics so the usual kind of hierarchy of numerics problems is integration, which is really hard optimization, which is perhaps less hard.",
            "Linear algebra is less hard again, and what we've done to deal with the hyperparameters of this Gaussian process is a kind of approximation to the true integration we need to do over its values.",
            "In fact, we do a kind of akin to Laplace approximation, which just requires linear algebra, so yeah.",
            "At some point you do have to move to a numerics problem, which is slightly easier.",
            "In order to get something that works in practice.",
            "I'm not sure if that's an answer to question, but the next part of the talk is all about the tuning of high parameters using Bayesian optimization, so maybe we'll move on to that now.",
            "Great so."
        ],
        [
            "Yeah, Fortunately for this talk you brought up yesterday, the use of Bayesian optimization for tuning the high parameters of neural networks.",
            "I've already had that nice intro."
        ],
        [
            "Action, but in fact tuning is problem across all of machine learning and I thought it might give you an example from Gaussian process is so during my PhD another data set I was trying to model is weather sensor network data and one of the things that our weather sensor network was able to model was title data.",
            "Which is not particularly difficult to predict.",
            "It's relatively periodic.",
            "But the reason I've chosen edge is because it gives these really nice log likelihood surfaces as a function of one of the high parameters of the model, which is the log.",
            "So of course if you're trying to fiddle periodic or quasiperiodic model to data that is in fact periodic, the likelihood service is going to have this kind of periodic shape reflecting the fact that the true.",
            "Which for tides is half a day corresponds to a really big peak and likelihood space.",
            "But they're going to be all these other peaks associated with harmonics of that true.",
            "That is, a period of one day or two days is also going to look like a pretty good explanation for the data.",
            "But real likelihoods have all these other really quite nasty behaviors, So what you're seeing over to the left here are harmonics of the sampling period of the data, which also show up as peaks in the likelihood function.",
            "So.",
            "In fact, tuning these parameters is not necessarily all that easy, and in fact, in doing maximum likelihood or least squares estimation for a lot of these problems, we do need to think seriously about not just local optimization, but global optimization.",
            "We don't get trapped in any of those little local modes.",
            "And so that is certainly a reasonable heuristic for exploring that likelihood function."
        ],
        [
            "And it's one to which probabilistic numerics has a lot to say, because in fact arguably the state of the art for these kind of hyperparameter tuning problems is Bayesian optimization, because what it gives us is that really quite flexible way of modeling nasty multimodal likelihood surface.",
            "And on the basis of that probabilistic model, we can spend the computation we have intelligently."
        ],
        [
            "So he was quite modest yesterday and not mentioning that he really published one of the landmark papers in this space.",
            "So NIPS in 2012 was called practical Bayesian optimization and machine learning algorithms or something like that.",
            "And in particular, in that paper they showed how you know, simple application, relatively Speaking of Bayesian optimization, using again that myopic loss, the expected improvement acquisition function gave better than state of the arts for particular neural network on Sci-fi 10, which was pretty impressive.",
            "But coming back to the theme of the talk that.",
            "You know one of the advantages of probabilistic numerics is that it allows you to define the right prior in subsequent work.",
            "In fact, in collaboration with Jasper, Snoek who's on this paper, we showed how that.",
            "By thinking a little bit more deeply about the type of structure of neural networks, we can design even more effective Bayesian optimizers to tune the hyperparameters.",
            "So in particular, in dealing with.",
            "New networks within.",
            "Variable number of hidden layers.",
            "We need to reflect the fact that some of the hyperparameters of the neural network don't have any significance unless the associated hidden layer is switched on.",
            "That is, if you have a variable number of hidden layers and you're also trying to optimize over the number of hidden layers, the number of hidden units per layer, the number of hidden units for the fifth layer aren't important unless you've got more than four layers, right?",
            "So if you're defining the parameter space over which to search, you can't just create a really long vector which contains all the number of units per layer.",
            "For any arbitrarily large number of layers.",
            "In fact, you want to have some sort of structure baked into your optimizer that reflects the fact that some of those parameters aren't significant unless other parameters like the number of hidden layers have particular values.",
            "Does that make sense?",
            "Or in particular, here the structure of this space is conditional, that is, the significance of some of the parameters is conditional on the setting of other parameters.",
            "So in this workshop paper we designed a new covariance function which we called the art covariance, which reflects that particular conditional behavior, capturing the kind of hierarchy that exists amongst these parameters and by just plugging and playing with it, putting it into a bog standard Bayesian optimizer.",
            "We're able to get really again quite interesting.",
            "Behavior out of our optimization strategy."
        ],
        [
            "So in particular, in learning all these parameters over both MNIST and sci-fi term, we saw that our optimizer was searching much deeper models than standard Bayesian optimization never would.",
            "So the plots on the right here shows the number of evaluations that are optimized with spending it variable number of variable numbers of layers, and you can see that our Arc GP novel model spent a lot more of its budget on those deeper architectures, which.",
            "Was interesting and gave in fact much better performance overall.",
            "OK, so that was my first attempt at making probabilistic numerics relevant to neural networks.",
            "Here's another one."
        ],
        [
            "Which is to say that this particular numerical techniques so ubiquitous across deep learning stochastic optimization also has an interesting interpretation within this Bayesian optimization framework."
        ],
        [
            "So here's how I think about stochastic optimization.",
            "And again, I'm going to think about this in the context of learning the hyperparameters of a model for a function.",
            "So on the left I've got.",
            "Data represented by little red dots, of which I'm taking three different subsets.",
            "Three different mini batches.",
            "If you like in the three different plots, so function is Y of T, the red dots are observations of it.",
            "And in each case I'm going to consider two possible settings of the hyper parameters of the model.",
            "For that function, one of which induces a really flat function.",
            "That's the kind of yellow posterior belief, another of which another setting for high parameters induces a much wiggle.",
            "Your function encoding the fact that there could be sort of short term fluctuations in it.",
            "That's the sort of cyan setting for the high parameters and on the right of Maps those hyperparameters to their likelihood.",
            "In light of the particular setting for the subset of data, so for the first 2 subsets it looks like the green model.",
            "The Scion model is much better, because there does indeed seem to be some sort of short-term wiggle in the function, in which case that setting for the high parameters, which favors that short-term wiggling is preferred.",
            "But for other subsets other mini batches.",
            "The setting of the high parameters which induces longer term structure might look better, such as the subset of chosen at the back here, in which case a flat function is actually pretty plausable explanation of the data.",
            "So that's stochastic optimization through a kind of Bayesian lens.",
            "In particular when we evaluate."
        ],
        [
            "On a mini batch we get a likelihood evaluation that is noisy.",
            "But in fact, within Bayesian optimization, noisy evaluations aren't really a problem.",
            "We've already put all this work into treating our objective function as a random variable.",
            "So if there's additional noise in that random variable, that is, if there's uncertainty in it, not just to our epistemic beliefs.",
            "The fact that we can't afford all the computation would like.",
            "But if there's additional uncertainty due to some sort of fundamental noise process, we don't really have to change our way of thinking.",
            "We can just slap on additional noise likelihood to complement everything that's come before, and we can more or less use exactly the same models that we've used in the past to optimize such noisy objectives.",
            "Now."
        ],
        [
            "Well, not just can we reproduce that kind of optimization in the presence of noise in the objective we can actually use the decision theoretic tools that have introduced to go one step better than standard stochastic optimization.",
            "So here I want to talk about the fact that.",
            "Usually the reason that we do stochastic optimization is because we can't afford an evaluation on the entire data set, right, so?",
            "There is a cost associated with evaluating on a larger subset of the data, so that has some scaling in the number of data.",
            "For Gaussian process it's usually honorific N ^3.",
            "So really, we want to tell the optimize that we're using to search over the high parameters of that model about that scaling in the number of data.",
            "In particular, if we encode that cost as a function of the number of data, we can get the Bayesian optimization strategy strategy to attend intelligently choose the size of data that it needs at runtime in order to best optimize the function overall.",
            "So we've implemented that and it does more or less what you'd expect.",
            "That is, it tends to spend the first evaluations of the function it has with a very small subset of the data.",
            "Really small mini batches because at that point you're just trying to be really explore it.",
            "If you're trying to get a few evaluations everywhere in the domain of the hyperparameters, tracking down which regions can be ruled out almost immediately, and then as time goes on, you spend more of.",
            "More and more of your time with larger batches because towards the end of your optimization run you really want to be more exploitative and hone in on regions that you've already learned pretty good.",
            "Now this leads to really quite impressive improvements in performance as measured now, not just by the number of evaluations that have been used, but actually by Wall Clock time that is relative to standard Bayesian optimization, which uses batches of a fixed size.",
            "Even if you are reasonably sensible about what that that should be.",
            "In our approach and I should say that there are two papers that came out this year which do vaguely similar things.",
            "One was from our Group One was from Stuttgard.",
            "In the other of these approaches, you get substantially better performance by allowing that batch size to vary in response to the needs of the particular point in the optimization, and we get really quite remarkable speed up in wall Clock time, and I say it's remarkable because remember that the overhead we've introduced in doing Bayesian optimization is not trivial.",
            "That is, our optimizer requires the fitting of a Gaussian process, which, as I mentioned earlier, has this quite nasty N cubed scaling, at least naively in the number of valuations of the objective.",
            "And we're also doing some additional computation to deal with the hyperparameters of that model, and then we have to optimize the acquisition function.",
            "There's all this overhead associated with Bayesian optimization, which is captured in that X axis.",
            "The wall Clock time that's actually expanded, and even in doing more of that by using the.",
            "Early stages of our optimization process on smaller subsets and hence getting more evaluations, were still able to do better than a naive approach which maybe does less Bayesian optimization on more expensive evaluations.",
            "Okie dokie"
        ],
        [
            "So thanks very much for your patience so far.",
            "I thought now might be a good time to sort of spark you up with a quiz.",
            "So do these quizzes in my lectures all the time, then multiple choice and the way I'd like you to answer them is not by raising a hand at the appropriate point, but instead by raising a number of fingers with the answer that you think is correct.",
            "So if you think answer one is correct to raise one finger.",
            "If you think 2 is correct, you raise two fingers.",
            "I apologize to anyone who doesn't have four fingers.",
            "And so the question here is which of these sequences is truly random?",
            "And here of course I'm motivated by the fact that usually those subsets in stochastic optimization is selected randomly.",
            "So I've got four choices.",
            "Hopefully by now you've had time to consider them.",
            "Now we just about ready to make our stab, at which answer you think is correct.",
            "OK, so in the count of three, please hands in the air 321 hands in the air.",
            "So I'm getting a lot of force, a lot of twos, everyone hands in the air.",
            "Please come on.",
            "Put some guts into it.",
            "Alright so.",
            "Now on to the answer."
        ],
        [
            "I apologize, that was a trick question in a sense.",
            "So in fact, none of those four sequences was truly random and I'll come to my point.",
            "Let's consider each of the four in turn, so the first sequence was generated by rolling a D6, a 6 sided die, but then duplicating the I throw lifetimes.",
            "So in a sense that is truly random, but that sequence would fail.",
            "Almost all normal tests of randomness, because there is that structure in the sequence, so that's not really random.",
            "OK, the second sequence is the 41st to 70th digits of \u03c0.",
            "So now is your chance for glory.",
            "Did anyone actually know those digits hands in the air if you did?",
            "I'm kind of relieved that now and is the third sequence was generated by the Von Neumann method, and that's the standard kind of pseudorandom number generator.",
            "So in a sense, that is random enough, but gotcha.",
            "I've told you the seed the seed was 900 and 8344, so now you know the seed.",
            "You can render each successive term in this sequence completely deterministically.",
            "There's no uncertainty left.",
            "It's not truly random now, which is kind of weird when you think about it, right?",
            "So it was kind of random, but now I'm told you this additional bit of information is not random anymore.",
            "So the final sequence was taken from a CD ROM published by George Massaglia.",
            "Can't say his name correctly.",
            "Probably in the 90s of random numbers, random binary digits, and again this sequence would pass most tests of randomness.",
            "But now I've told you where I got it, and again, it's deterministic by virtue of just getting that CD ROM and looking up the sequence and finding out what the next digit was.",
            "So the point I'm trying to make here is that.",
            "Anne."
        ],
        [
            "Here we go.",
            "I've got three points.",
            "So a random number is in some senses, at least for the purposes of numerics, epistemic.",
            "Randomness is a statement about what we know.",
            "If you know the random seed.",
            "The pseudorandom number generator is no longer random.",
            "So in a sense that makes sense for numerics, because computation should always be conditional on prior information.",
            "As I've been trying to say.",
            "But choosing the random seed as the particular bit of prior information that is most relevant to whether or not your numerics procedure succeeds seems pretty weird to me.",
            "The second reason you might want to use random numbers is if you're trying to foil a malicious adversary right.",
            "So if you're trying to play some game in which someone is out to get you, maybe it makes sense to choose a random number so they can never predict what you're going to do.",
            "That actually, I think that's a very poor choice for numerics problem when trying to let me just finish this slide in doing optimization in doing integration, doing linear algebra.",
            "There's not really someone out there who's trying to throw the worst possible objective function at me or the worst possible integrand out me.",
            "Instead, I'm just trying to do the best I can on the type of functions I think are most likely to occur.",
            "And the third reason, I think pseudorandom number generators and random number generators are a poor choice for numerics, is that thinking about a numerics problem in a decision theoretic way that is taking the evaluation, taking the action that minimizes our expected loss.",
            "Assuming a random or random number generator is never going to give us the minimizer of that expected loss, the only expected loss function which is going to be minimized by a random number is 1, which is totally flat and hence is totally uninteresting.",
            "Any model that is solved by a pseudorandom number generator is innocence uninteresting.",
            "OK, so that was a fairly provocative slide.",
            "Any questions?",
            "What does epistemic alright?",
            "Sorry for the purpose of this talk.",
            "Take epistemic mean personal.",
            "You know particular to a particular agent spoke to an agent.",
            "Yeah.",
            "No other questions or points.",
            "Great, everyone agrees with me.",
            "That was easy.",
            "Thank you very much.",
            "No question here.",
            "That means something out there is actually trying to be prudent and worst possible, yeah, but.",
            "But I mean, if you have a dumb oversight, maybe trying to randomize them, tell you, and then I'm just saying this because I'm coming from from.",
            "Proving that some rest of gastric learning or some some randomized learning can actually convert to that baby for their malicious oversized underwear.",
            "For once we're done random adversary, they might work and it might be more robust, so I think that's also another view that could be useful for.",
            "For making use of random numbers so you have a summer study that is, yeah.",
            "Why are systematic regarding some way to carry lot with randomized control?",
            "You can get game robots.",
            "Yeah, OK, so I mean if there is an adversary, this slide concedes that maybe randomness makes sense.",
            "Whether or not it's casting, maybe want to be unpredictable in a way that foils the plans of our adversary, but that what I'm saying is that when we use random numbers in numeric procedure, it's a bit odd, because there is no such adversary, right?",
            "There's no one playing optimization against me, there is just a family of objective functions out there in the world that.",
            "Need to try and do inference over.",
            "OK, so."
        ],
        [
            "Now I've got I think half an hour left.",
            "Is that right?",
            "So the final part of the slide is in fact even more provocative innocence.",
            "And what I'm going to say is that actually in machine learning normally what we want to do is not optimization.",
            "In fact, normally what we should be doing is integration."
        ],
        [
            "So.",
            "Yeah, this is a contrived example, for which I apologize, but let's imagine we're trying to fit a 7th order polynomial to a function that is quadratic.",
            "So in that case, as I'm sure you're all aware, if we were to optimize the coefficients of the 7th order polynomial, it's very easy to overfit.",
            "Now."
        ],
        [
            "One way out of that problem is in fact do the correct Bayesian thing, which is instead of optimizing over those coefficients, averaging over those possible settings, each of them weighted by their likelihood in light of the data that's been received.",
            "So here I've done a simple.",
            "Gaussian prior on each of the coefficients of this quadratic and we get something that is already not just a better predictor that has a more honest representation of uncertainty of what that quadratic is doing between regions.",
            "So the."
        ],
        [
            "Reason that integration is the right thing to do comes back to a really simple rearrangement of Bayes rule.",
            "So Bayes rule totally uncontroversial.",
            "But usually when we want to use Bayes rule to, say, compute the posterior for a product and F star, that is the particular thing we're trying to predict for, like a particular class label, a particular image.",
            "Conditional on a particular set of data or training set, whatever.",
            "We then use Bayes rule in the following sense as just a ratio of the joint of F star.",
            "Indeed, the product and the data divided by the evidence PFD.",
            "Of course, this gets more complicated when there are parameters involved, so in the presence of parameters which influence not just the predictions we make, that is F star given D and Theta, but also the predictions made for the data.",
            "If you like, which gives us the likelihood we end up having to do integrals over the possible settings of that parameter.",
            "So I'm.",
            "The particular setting for Bayes rule likely to keep in mind is the following.",
            "That is, by this simple rearrangement of the joint of the product dance of the training data as the marginal over that product and the data in the parameters we integrate or marginalized over Theta.",
            "By breaking it apart into these three conditional distributions, the prior over the parameters, the likelihood of the parameters and the predictions for that test point.",
            "You can see that.",
            "What we really want to do is an integral over the likelihood, that is, the probability of the data given the parameters.",
            "Weighted by the prior of those parameters and by the different possible predictions we get given each of those parameters.",
            "Is that OK?",
            "All good."
        ],
        [
            "So I'm coming back to that example I showed you earlier and I'm trying to deal with the period high parameter of a periodic Gaussian process.",
            "Many of the same difficulties of doing.",
            "Optimization emerged when we try and do integration, so in particular trying to do the integral of this function is quite difficult for exactly the same reasons it was difficult to optimize.",
            "It's got many different modes and it's difficult to explore."
        ],
        [
            "So instead what we have to do in practice is numerical integration, otherwise known as quadrature.",
            "And.",
            "I. I thought I might again just give a probabilistic numeric spin on quadrature, so take the simple example.",
            "Of integrating the function X above sign, sorry - three X ^2 -- X ^2 again a super simple function representable in a small number of mathematical operations.",
            "It's one that just looking at it.",
            "You can say is going to have certain behaviors.",
            "There's a trigonometric function in there, so it's going to have some sort of trigonometric behavior.",
            "But nonetheless, despite all that that we know about it, we don't know what its integral is over the particular domain minus three to three.",
            "At least.",
            "I hope we don't know what it is because I've been giving this talk for many years now and I've been wrong all that time.",
            "It would be very embarrassing.",
            "So instead we treat that integrand that F of X as an unknown object, which we apply probabilistic modeling and can do the basic white thing.",
            "But going a little bit further back before your new probabilistic numerics, what you might have done to deal with the numerical.",
            "Integration problem like this is something like the trapezoid rule or the trapezium rule.",
            "So all that trapezoid rule is doing is linear interpolation between your observations.",
            "So we get a grid of evaluations of the integrand.",
            "We just make that little red line interpolate in a linear way between each of them, and then we would use that linear interpolation to come up with the best guess for what the integral is."
        ],
        [
            "Now I'm.",
            "Thinking about its integration being the right thing to do, hopefully it's immediately obvious why optimization is the wrong thing to do.",
            "That is firstly.",
            "If we've.",
            "Optimized this likelihood function and spent an enormous portion of our computational budget in evaluating that integrand at a wide range of different valuations.",
            "It seems like a super weird thing to do to throw away all those valuable evaluations of the objective except for the single one that gave us the best likelihood.",
            "So thinking about this in that probabilistic numeric way, that seems super wasteful, right?",
            "All that effort.",
            "All that computation spent is thrown in the bin, which is a bit weird, but the other weird thing about optimization is having reduced your information set to just that single evaluation.",
            "Normally what we do is then approximate that integrand with a Dirac Delta function that is, in averaging over all the possible settings for this parameter, we're going to pretend that.",
            "The only one that is of any significance whatsoever is the one that gave us the highest possible likelihoods.",
            "So in a sense, we're doing integration by pretending that this likelihood is just a Dirac Delta function against which we can actually integrate, so you can see that that approximation is super strong and is very unreliable for any integrand that is not just multi multimodal, but even a little bit broad, right?"
        ],
        [
            "So.",
            "Picking up on some of the ideas that Hugo was talking about yesterday, I think that's why there has been this kind of resurgence of interest in the deep learning community in optimization that has some sort of preference for, you know.",
            "Brawds minima rather than really tight narrow minima.",
            "That is, it's the broad minima that are ultimately going to be a better representation of the integrals.",
            "We actually should be doing right.",
            "So you're going to force yourself into this super limiting kind of scenario, in which you throw away all the evaluations except for a single one, and then pretend that your likelihood is a drag Delta.",
            "You want to at least be picking the evaluation.",
            "That is like this one on the right, which has most of the probability mass that big pink region in it rather than the one on the left.",
            "So that's why I think you know the methods that prefer these kind of regions work better than that one.",
            "But Even so, I think there's a lot more work to be done to actually push further towards what should be done anyway."
        ],
        [
            "OK, so the probabilistic numeric approach to.",
            "Quarter to symmetrical integration is actually very similar to the probabilistic numerical approach to global optimization.",
            "So just as in global optimization is in Bayesian optimization, we modeled an objective function with the Gaussian process.",
            "In Bayesian quadrature, we model an integrand.",
            "The function over which we're trying to integrate with the Gaussian process.",
            "So here an interesting aside, if you're doing Bayesian optimization to tune the hyperparameters of a machine learning model.",
            "Within that Bayesian optimization process you've already built this Gaussian process.",
            "You've already learned a model of the likelihood as a function of its parameters.",
            "So really what I'm trying to say is having got that Gaussian process maybe should instead do the right thing, which is the integration problem rather than the slightly less right thing.",
            "Which is optimization anyway.",
            "So I'm.",
            "With this"
        ],
        [
            "Gaussian process we can do some pretty cool things and the reason for that harks back to another super useful property of the multivariate Gaussian.",
            "So this property is that.",
            "Let's say we've got some bivariate Gaussian, so a Gaussian over 2 variables X2 and X1.",
            "Either of those variables.",
            "So either X2 or X1 is joint Gaussian distributed with any affine transformation of those variables.",
            "That is, regardless of the parameters AB&C that you pick X2 and indeed X one is going to be joint Gaussian with that F line transformation.",
            "This is, in a sense, the most profound property of a Gaussian, at least as far as I'm concerned, and in a sense, that's why Gaussians come up so much in probabilistic numerics because.",
            "Numerics has a long history of people trying to make algorithms as efficient as possible, right to work on the computers that people actually had even 50 years ago.",
            "And what is the most efficient thing you can do?",
            "Well, it's linear operations, so the kind of numerical procedures that people have come up with are those that innocence lend themselves to reinterpretation as Gaussian inference.",
            "OK, so let."
        ],
        [
            "Come back to this example of integration.",
            "So.",
            "In Bayesian quadrature, we've modeled that Integrand X is a function of TC with a Gaussian process, and in fact the thing we're most interested in is a linear projection of that random variable.",
            "The function, if you like the integrand, and it's the linear projection that gives us the integral.",
            "So an integral if you like is just a generalization of a sum, so hopefully that seems reasonably intuitive, but the fact that it's linear allows us to use this beautiful property of the Gaussian.",
            "In particular, if we've got a Gaussian process over the integrand.",
            "That all the function values of the integrand are joint Gaussian with the integral.",
            "So what does that?"
        ],
        [
            "And in practice, it means that.",
            "We can very quickly computes a posterior distribution for the integral conditioned on any set of evaluations of the function.",
            "And here's the cartoon showing how that works in practice.",
            "So imagine I'm trying to do the integral of L over its input X, and I've got 3 evaluations, about 3 crosses, and I modeled it with the Gaussian process, the green sausage.",
            "So, given that Gaussian process, I can enclose form compute the Gaussian univariate Gaussian posterior for the integral which I've called zed.",
            "And sort of give some intuition for what that distribution Fizz Ed tells us.",
            "We're taking three draws from the Gaussian process.",
            "Purple, blue and Reds and the purple, which has a large excursion upwards.",
            "Gives you know it's integral is larger, but of course the fact that it's got a large excursion in it makes it less probable.",
            "So it's somewhere up here on that distribution for the integral values Ed.",
            "Draws which have a large excursion downwards are again quite improbable, but are associated with a value for the integral, which is much smaller than the mode of that gas in posterior distribution.",
            "That's a super neat property.",
            "Having produced this Gaussian process function almost for free, we get the Gaussian distribution for its integral.",
            "Right, so now onto perhaps the most mathematically."
        ],
        [
            "Difficult bit of the whole talk.",
            "Let's try and spend a little bit of time in this.",
            "So I was telling you before about the trapezoid rule or the trapezium rule.",
            "So let's return to that and return to the particular integrand.",
            "The expert - 3X or squared minus X ^2.",
            "And what I'm going to do is to imagine doing the trapezoid rule with a variable number of nodes of variable number of evaluations, where at each step of the process I'm going to throw away all the evaluations I had before and start with a new grid of evaluations which is slightly finer.",
            "Does that make sense?",
            "So at each iteration and get a slightly finer set?",
            "And what I've done is on the top of the slide show the trapezoid rule in dark red line on the bottom of the slide on the left and the little red dots.",
            "I've showed the empirical convergence of the trapezoid rule to the ground truth, where the ground truth here is actually just obtained by running the trapezoid rule for a really really long time.",
            "So you can see that it does converge, which is reassuring.",
            "We get these little up and down behaviors in it.",
            "That's because of the fact that you know, as I increment from one grid to the next, I might throw away an evaluation that was actually quite useful in the previous increment.",
            "It's not that important.",
            "The thing I want to say about this is that it's order N to the minus two, which is pretty good.",
            "But in a sense, that's bad because the predicted theoretical convergence for the trapezoid rule is 1 / N. So the theoretical convergence for the trapezoid rule is not well calibrated to the empirical convergence of the trapezoid rule.",
            "So the other problem is that even if we knew the convergence was 1 / N ^2, we couldn't say exactly what our error was at any particular point in time, right?",
            "Because we don't know what the constant is at the front or we know is that the error is going down.",
            "This 1 / N ^2 we don't know what its absolute value is for any N. So that's the trapezoid rule.",
            "Now I want to say something that I hope will blow your mind.",
            "Which is that the trapezoid rule is in fact drumroll please.",
            "Thank you very much, that's great feel very indulged.",
            "Thank you.",
            "The trapezoid rule is actually Bayesian quadrature.",
            "Which I find truly remarkable.",
            "So remember that I was trying to tell you that what goes into probabilistic numerics.",
            "This Gaussian process is dependent on the choice of covariance function.",
            "And it just so happens that you can choose a covariance function.",
            "It's the one's integrated vena process type of slide spline player.",
            "Gives you a Gaussian process posterior mean, which is exactly the same as that kind of linear interpolation assumed by the trapezoidal rule.",
            "So if you then do Bayesian quadrature with that particular covariance function, you get a posterior belief for the integral.",
            "That is an estimate for the integral.",
            "Which is identical to that you get from the trapezoid rule.",
            "When I say identical, I mean that if you were to implement in code that particular formulation of Bayesian quadrature, you would do it with exactly the same code.",
            "That you would use for the trapezoid rule.",
            "That's an important point because it makes the point that Bayesian quadrature, probabilistic numerics in general need not be computationally expensive because the trapezoid rule is super cheap, and in fact if you get the choice of covariance function right, you can do these numerics procedures with exactly the same cost as their kind of traditional alternatives.",
            "And if you like, you can put a little bit of overhead on top to get the uncertainty out.",
            "Of that probabilistic numerics procedure to supplement just the best guess.",
            "So let's turn to that question at the back.",
            "Is there some optionality argument for why?",
            "And so in fact, when we're trying to match the numerics procedure to a covariance function there, there are just particular covariance functions which are identical.",
            "It's not that you even need to define a notion of similarity.",
            "You can get something that gives exactly the same behavior regardless of the notion of similarity, but.",
            "So that's a super interesting question.",
            "I'll turn to that in just a second you give me to commit me to wait.",
            "So anyway, what I was just about to say is that the other thing that probabilistic numerics gives us beyond traditional numerics is a much more coherent way of thinking about error about uncertainty.",
            "So as I said, that theoretical error bounds for the trapezoid rule are innocence wrong for this function there 1 / N when the empirical covariance is 1 / N ^2.",
            "And they don't even tell us what the actual error is, only what the rate is.",
            "But if you do Bayesian quadrature with that particular covariance function, you get not just.",
            "The estimate for the entry you also get this full posterior distribution.",
            "And the other thing I'm showing in the bottom slide here and the little red lines.",
            "Is the.",
            "Posterior standard deviation of that Gaussian posterior.",
            "As a function of the number of valuations, it turns out you can actually evaluate it in closed form and you'll see that while it has the same problematic convergence behavior as trapezoid rule, which is in a sense not surprising because this particular covariance function is just re implemented that trapezoid rule, it does have the really nice property now that we can pick which the best of those red lines actually is, because now the particular posterior distribution that's relevant to the function at hand.",
            "Is specified by the hyperparameters of that covariance function, and we can learn those hyperparameters.",
            "That's what we do every day in machine learning.",
            "Given the particular set of evaluations with obtained, we can actually infer what that setting the high parameter should be in there by pick the convergence rate for the error, which is best suited to the function at hand.",
            "OK, so now we want to return to the question that was asked before, which is why should we use the trapezoid rule against perhaps another alternative and those other alternatives within a Bayesian quadrature formalism?",
            "I just different covariance functions.",
            "And looking at this integrand.",
            "I note that not only is it smooth, it's infinitely differentiable.",
            "It's super smooth, and if there's one thing that Gaussian processes are good at capturing its smoothness.",
            "So the standard the most ubiquitous covariance function within Gaussian processes is known by many names, including the exponentiated quadratic, the squared exponential, the RBF, the normal, all of them.",
            "In code this property that the function is infinitely differentiable.",
            "So an obvious thing to do is to use that covariance function for this integrand, and that's what we've got on the right hand side of the plot.",
            "Let's try and give some intuition for.",
            "Yeah, so the orange lines here give the posterior mean of the Gaussian process fitted to those evaluations.",
            "The orange sighting gives the posterior error estimate if you like.",
            "But we've also shown on either the left or the right draws from the two different posteriors as the kind of slightly lighter dark lines, and hopefully that makes it clear why the squared exponential on the riot is a better choice than that on the left.",
            "That is why the once integrated Vina process is continuous, it's not differentiable even once.",
            "So if you take draws from it, you get things like the jagged edge Gray lines there in the jagged red lines which are very unrepresentative.",
            "That integrand on the right we get draws which are much more representative.",
            "So then as you will have seen in the bottom right.",
            "If we run basic works are forwards.",
            "From that point we get way better behavior.",
            "We get convergence, which is not only faster.",
            "And when I say faster.",
            "We can actually prove theoretically this is supra exponential in N. Say that again, Supra exponential not just exponential like exponential of exponential NN, which is pretty awesome, but we also get error estimates that it perfectly calibrated.",
            "To the actual error that we get, which is really nice, so you know really problematic numerics gives this way of thinking about numeric problems, which allows you to do way way better by incorporating into your numerics procedure.",
            "What you really do know.",
            "So I'm now the final quiz for this."
        ],
        [
            "Talk.",
            "What is the convergence rate of Monte Carlo?",
            "Many people know this, so I don't want to give too long to think about it, but there are four options.",
            "Explains in X minus and minus 1/2.",
            "Into minus one into the minus 1/2.",
            "Don't Google, it's OK so 321.",
            "Please hands in the air.",
            "What do you think the right answer is?",
            "Have a stab.",
            "Come on 321 hands in the air what do you think it is?",
            "All hands up please come on.",
            "Haven't had a guess.",
            "Have a guess.",
            "I'm still seeing not that many hands up.",
            "OK, so maybe that's as good as we're going to get, but reassuringly most people did in fact pick the right answer, which was N."
        ],
        [
            "3 -- 1/2 well done to those of you who got it right.",
            "And I just wanted to comment on that, because remember the convergence rate for the trapezoid rule, which is in a sense the dumbest thing you could do for numerical integration.",
            "It's sometimes taught in high school, has a convergence rate, which is 1 / N. Monte Carlo, which is kind of a state of the arts in Bayesian inference, is way worse than that.",
            "It's one over square root in.",
            "And.",
            "The reasons for why it's so bad really kind of eloquently put in this paper from Tony O'hagan from 1988 with a fantastic title of Monte Carlo is fundamentally unsound.",
            "So I'm you know this is not a stats talk, so I won't go any deeper into that, but I do recommend you read that paper if you want to learn why you should never use Monte Carlo.",
            "But in short, the reason for it is kind of easy to grasp, which is that the S."
        ],
        [
            "Meant that one of the reasons for it is that one color constructs as its estimate for the integral.",
            "The unweighted average of all the function evaluations, so it just takes all the evaluations of the integrand and add them up and divide by N. Which means that the evaluation that has the highest value for the likelihood, for instance, has no better weight than the lowest value for the likelihoods.",
            "It's also not capturing the fact that if you take an evaluation, that's right next to another one, which of course you might do in Monte Carlo because its valuations are chosen stochastically, which just to remind you, I think is a really dumb idea.",
            "So if you've got 2 evaluations which chosen right next to each other, they both got exactly the same weight as an evaluation very far away and very informative.",
            "That is, even though these evaluations are redundant, they're treated exactly the same as any other evaluations.",
            "So if you actually run Monte Carlo on that same problem, the X - three X ^2 -- X ^2 you get terrible formance, which is unsurprising.",
            "I wanted to say one thing.",
            "I was a bit unfair to the trapezoid rule on the previous slide.",
            "In fact there is theory which establishes why you get 1 / N ^2 for that type of integrand.",
            "Which is that.",
            "In fact, if the integrand is differentiable, you can show that it's 1 / N ^2.",
            "But anyway, that's neither here nor there."
        ],
        [
            "OK, so I think I've got just a couple minutes to conclude and I wanted to just round out this story for integration.",
            "So far I've just talked about the probabilistic modeling component of integration that is basing quadrotor.",
            "But of course, the other component of probabilistic numerics is the decision theory, and for basing quadrature that decision theory is relevant to selecting which integrante value to evaluate next.",
            "So.",
            "The way we do that, as you might guess, is fairly similar to Bayesian optimization.",
            "We define a loss function for the case of Bayesian quadrature.",
            "That loss function encodes how much uncertainty there is in the article, which is quite natural.",
            "And then we crank the handle of expected loss to pick the successive evaluations of the integrand that are most useful to us.",
            "And here's a cartoon of how that works in practice.",
            "It's kind of a complicated plots, so each of these successive rows represents the expected loss after a different number of samples have been chosen, so it begin with, we've got five samples.",
            "Here's our expected loss in green.",
            "And you can see the little red dot is telling us we want to evaluate just between these two samples.",
            "That ruined brand is at the top of the slide and you can see between those two samples is on the upward slope of this big peek out to the right.",
            "So this was a pretty sensible choice.",
            "Having evaluated the integrand there.",
            "And having discovered that this big mode out to the right exists, we then choose another kind of exploitive evaluation to resolve it a little bit better.",
            "Keep doing that until we've worked out everything we need to know about this particular mode, in which case we switch to evaluating further out to the left, and soon enough we capture this mode as well, so we get exactly the same kind of emergent behavior that we saw for Bayesian optimization through a really simple choice of loss function by simply choosing a loss that is, the uncertainty in the interval.",
            "Is that a question?",
            "With great pleasure decision theory which came with expected loss here, so why would be that we we could stay in base in like probabilistic domain as well in decision making, like for example here for selecting sample people?",
            "Realistic actual.",
            "Why should we come with these expected loss with these deterministic?",
            "So the question was, isn't using expected loss innocence the sacrifice of the Bayesian approach?",
            "And I would argue absolutely not.",
            "So I think what you're arguing is that given just a probabilistic model, we could do selection probabilistic Lee, which I think you mean by which I think you mean stochastically.",
            "That is, I think you're thinking about generating pseudorandom numbers from saying integrand to represent the evaluations we should take sequentially.",
            "Is that what?",
            "You're ugly, so actually the point I was trying to make earlier in the talk is that that's a really bad idea.",
            "In fact, you know stochastically is not the right approach.",
            "For making decisions when there's actually something we want to achieve, like resolving an integral as well as we can in light of a fixed computational budget, decision theory, which is really a natural partner to probability theory given a particular set of costs is the right thing to do if we're being stochastic.",
            "We're leaving value on the table because in a stochastic setting there's always going to be some probability of, for instance, going back and evaluating a function added.",
            "Exactly or pretty close to the same location at which with evaluated in the past, which is always going to be wasteful.",
            "A stochastic approach to numerics is always going to leave value on the table, and we can pick up that value by being more decision theoretic.",
            "Add.",
            "Question.",
            "Welcome people.",
            "Saying basically that if you are automating everything and we must choose one, and if you want to prove that once you get cremated with that and then you are losing information.",
            "Yes, I mean this is the whole framework.",
            "Of course it is.",
            "The whole idea of going racialization is get into instead of just having one and then trying to improve that.",
            "Like yeah, yeah.",
            "This is related to the cause of sample.",
            "We can measure values in function evaluation, so we just need to have been doing that for a long time.",
            "But then suppose we want to do this with a hole deep network with, so some of parameters yes and then for representative visits are problem here with the space complexity in the center representing the distribution of functions is far more expensive than just having one.",
            "So if you do have one.",
            "So we can.",
            "We can move around and this is a very bad idea, but we can do that and you can do that fast enough that making non compatible with representing a family of function and doing this update here.",
            "So I mean I understand.",
            "OK so I think the question was is this a sensible approach given that you know for your purposes you actually wanted optimization in a really high dimensional spaces that originally so to that I would say the kind of Bayesian optimization I've told you about so far.",
            "Not be the right choice because as I say, we don't yet have the tools for standard Gaussian processes to scalloping dimensions.",
            "But there's a whole another branch of probabilistic numerics which focuses not on global optimization, but instead local optimization, and even on reinterpretations of like SGD, which does scale up exactly as well as any other type of local optimization.",
            "And for that I would point you to the recent work from Phillip Annequin tuning in.",
            "Yeah, so there are approaches probabilistic numerical nature which can be used in that setting as well.",
            "I think there's a question over here before.",
            "Simple question point of this is to estimate.",
            "Shadow prices for data.",
            "If you have a big constraint that is at that point, then to estimate the marginal value of a bit of data.",
            "Yeah, precisely.",
            "Back to where you are, I think you are using this process for evaluating hyperparameters with respect to control.",
            "The likelihood is that you get the same result of finding a wider area if your cost function was not sampling function within the expected value, but some sort of notion of risk are or mini Max or something like that for that.",
            "OK, so I've just realized we're out of time.",
            "I answer this last question, then very quickly conclude if that's OK so.",
            "The question was, what about other notions of loss, mini Max?",
            "For instance, in a sense I'm relatively agnostic to the loss function that's chosen here.",
            "We chose one for integration that I think that makes sense, which is reducing the variance.",
            "But of course probability Max is open to any other choice of loss function.",
            "Max might be one of them, so thanks for your patience.",
            "If I'll just if you just let me very briefly conclude one point on this is that if your decision theoretically select the samples."
        ],
        [
            "You do way way better and by way better.",
            "I mean in Wall Clock time, not just in the number of valuations."
        ],
        [
            "But then."
        ],
        [
            "To conclude, I just wanted to remind."
        ],
        [
            "You that there is this website problem.org it's got all the up-to-date material on all the branches, probabilistic numerics, not just global optimization and integration really do check it out and if you've got any work you've done yourself which might fit into this realm, let us know.",
            "Send me an email listed up on the site.",
            "So thanks very much for attention.",
            "Very happy to take questions offline."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So good morning everyone.",
                    "label": 0
                },
                {
                    "sent": "I guess I'd start out by just recognize the contribution to this talk made by Filipeni.",
                    "label": 0
                },
                {
                    "sent": "He's not here today, but with whom I'm writing a book on probabilistic matrix to be out either later this year or next year.",
                    "label": 0
                },
                {
                    "sent": "So a lot of the slides here come from Phillip thanks to him.",
                    "label": 0
                },
                {
                    "sent": "Right, so I thought I'd start by trying to find what it is we do in machine learning.",
                    "label": 0
                },
                {
                    "sent": "At least you know to my way of thinking, which is to join up a model which is the thing we really want to deal with to another kind of component, which is the computation.",
                    "label": 0
                },
                {
                    "sent": "So within computation we do things like well, optimization, quadrotor really to me computation is about numerics and of course the problem we face is that the kind of models we want usually aren't amenable to the computation we have, right?",
                    "label": 0
                },
                {
                    "sent": "We've got all this beautiful theory, universality, probability theory.",
                    "label": 0
                },
                {
                    "sent": "But at the end of the day, the things we actually most desire aren't actually going to work on the computation we have.",
                    "label": 0
                },
                {
                    "sent": "So to tackle that problem, I think the normal way of doing things.",
                    "label": 0
                },
                {
                    "sent": "In fact, the way that Yoshi was speaking to most eloquently earlier, is to think about the computation we have, so you know the kind of optimization that we can actually do.",
                    "label": 0
                },
                {
                    "sent": "The gradients that it needs and use those considerations to drive the constructions of the models in the 1st place, which is absolutely a very powerful way of approaching things.",
                    "label": 0
                },
                {
                    "sent": "That's led to a lot of success, but the big, beautiful idea.",
                    "label": 0
                },
                {
                    "sent": "At the heart of probabilistic numerics is to take that information transmission the other way around.",
                    "label": 0
                },
                {
                    "sent": "So within probabilistic numerics we try to take the things we're most interested in achieving.",
                    "label": 1
                },
                {
                    "sent": "So let's take probability theory that suite of tools and apply them to computation.",
                    "label": 0
                },
                {
                    "sent": "So probabilistic numerics is really about applying the lens of probability theory to numerics to the kind of computational cores at the heart of what it is we want to achieve.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "With that framing, I thought I'd first of all mention to you that we have a whole website on this topic.",
                    "label": 0
                },
                {
                    "sent": "It's called probabilistic numerics.org, and if you're going to have to compress this talk down to what 11 characters?",
                    "label": 0
                },
                {
                    "sent": "I guess there.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Even characters I would like you to compress down to aproblem.org so the website is got.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "A whole host of things up there.",
                    "label": 0
                },
                {
                    "sent": "It's got like an up-to-date list of all the meetings and workshops and conferences arranged on probabilistic numerics.",
                    "label": 0
                },
                {
                    "sent": "In fact, there was a big summer school, organized what just last week in Italy on probabilistic numerics.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "It's also got a list of all the literature that's being pumped out now, and probabilistic numerics.",
                    "label": 0
                },
                {
                    "sent": "So in fact probabilistic numerics is quite an old field.",
                    "label": 1
                },
                {
                    "sent": "The oldest paper on this list is point carriers from 1896.",
                    "label": 0
                },
                {
                    "sent": "I'm wearing a francophone city, so I apologize if I said point carrying correctly, But anyway, so the field is taking awhile to get going.",
                    "label": 0
                },
                {
                    "sent": "I guess there are a bunch of papers out in the 80s from Diaconis from Ohagan, but it's really only in the last couple of years that we've.",
                    "label": 0
                },
                {
                    "sent": "Began to realize the real potential of the field, I think, so you know, this is being very.",
                    "label": 0
                },
                {
                    "sent": "Recently and frequently updated now these papers are coming out.",
                    "label": 0
                },
                {
                    "sent": "Do keep an eye on it.",
                    "label": 0
                },
                {
                    "sent": "And for the purpose of begin.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The talk I thought I'd talk about, not the whole suite of numeric problems, of which, of course there are many integration optimization, ODS solving linear algebra, but focus instead on global optimization, which for the purpose of this torcal definers the requirement of numerically optimizing a function which is multimodal and very often expensive to evaluate.",
                    "label": 1
                },
                {
                    "sent": "So one evaluation of this function might take something like several hours of computation it might take.",
                    "label": 0
                },
                {
                    "sent": "The drilling of a new oil well, for instance, or the you know, an entire drug trial which might take months and sort of millions of dollars.",
                    "label": 0
                },
                {
                    "sent": "And just to be absolutely clear, the kind of problems we're going to be taking, at least in the first part of the talk, are relatively low dimensional, so we're talking about problems that are probably not more than, say, 20 or 30 dimensions, just to be absolutely clear about it.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Right, so thinking about the optimization numerically function that looked like this.",
                    "label": 0
                },
                {
                    "sent": "People very often test out their algorithms, benchmark on a standard suite of test problems, and perhaps the most Canonical of them all is the rosenbrock called banana function, and I thought I might just put up on the slide it's expression.",
                    "label": 0
                },
                {
                    "sent": "So I've counted correctly.",
                    "label": 0
                },
                {
                    "sent": "This mathematical expression contains no more than 17 characters.",
                    "label": 0
                },
                {
                    "sent": "So in a sense, we know it really, really well, right?",
                    "label": 0
                },
                {
                    "sent": "I mean, it's not a complicated expression just looking at that expression you can immediately see that it's going to have certain behaviors.",
                    "label": 0
                },
                {
                    "sent": "So the fact that it's the combination of two sums of real numbers means that this is going to be positive.",
                    "label": 0
                },
                {
                    "sent": "That's quite an interesting thing to know already, just from its mathematical expression.",
                    "label": 0
                },
                {
                    "sent": "And of course, this can be evaluated in literally microseconds on any standard laptop.",
                    "label": 0
                },
                {
                    "sent": "So in all those sensors, this is a function that we know really, really well, but in another sense we don't know it and that sense is that just from that mathematical expression, there's no easy way of arriving at its global minimum.",
                    "label": 0
                },
                {
                    "sent": "So that's quite a weird thing, right?",
                    "label": 0
                },
                {
                    "sent": "So in one sense, this is a really well characterized object, but in a numerical sense it's completely unknown.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The reason for that lack of knowledge is really that notion of computation.",
                    "label": 0
                },
                {
                    "sent": "So in a world in which we had infinite high precision computation, in fact, that whole issue would not arise.",
                    "label": 0
                },
                {
                    "sent": "So we could simply do a grid search of this test function of the rosenbrock at really high granularity.",
                    "label": 0
                },
                {
                    "sent": "We would get its value everywhere in the two dimensional domain and then we would have its global minimum.",
                    "label": 0
                },
                {
                    "sent": "It would be known, but in reality of course we don't have that infinite amount of computation and that induces this epistemic uncertainty about what its minimum is.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So in light of that uncertainty about the minimum of this function.",
                    "label": 0
                },
                {
                    "sent": "The kind of central inside of probabilistic numerics is to bring to bear the best tools we have for dealing with uncertainty.",
                    "label": 0
                },
                {
                    "sent": "Which are, you know, probability theory and decision theory.",
                    "label": 0
                },
                {
                    "sent": "So in particular, the first part of the contribution of probabilistic numerics is to treat something that isn't a sense well known, like that rosenbrock function as unknown and model it with probabilistic model.",
                    "label": 0
                },
                {
                    "sent": "So in the case of optimization, we're going to treat F of XY, the function itself as a random variable and apply to it all the tools we have from probability theory.",
                    "label": 0
                },
                {
                    "sent": "So that's the first component of probabilistic marks, the second component that allows us to really get to grips with the fact that we have a finite computational budget is to bring to bear all the tools of decision theory.",
                    "label": 0
                },
                {
                    "sent": "That is, to a probabilistic.",
                    "label": 0
                },
                {
                    "sent": "Numerous cyst computation is a finite resource.",
                    "label": 0
                },
                {
                    "sent": "That we want to use as best as possible to achieve our ends, which in the case of optimization might be something like finding the minimum to the greatest degree of accuracy possible.",
                    "label": 0
                },
                {
                    "sent": "So right from here, the talk is going to kind of diverge.",
                    "label": 0
                },
                {
                    "sent": "I'm going to separate out those two components, probabilistic numerics, the probabilistic modeling and the decision theory and the 1st.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is obviously going to be probability theory.",
                    "label": 0
                },
                {
                    "sent": "That's what is the underpinning for everything else in particular in this first part of the talk I'm going to talk about the probabilistic modeling of functions.",
                    "label": 0
                },
                {
                    "sent": "Now I'm sure that you've all met probability theory before, and the mechanics of it fairly uncontroversial and easy to grasp.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "But I thought I might try to drive home the way that.",
                    "label": 0
                },
                {
                    "sent": "Question.",
                    "label": 0
                },
                {
                    "sent": "Not sure is is my voice being picked up by the microphone.",
                    "label": 0
                },
                {
                    "sent": "I apologize if any of that was unclear.",
                    "label": 0
                },
                {
                    "sent": "Is that better?",
                    "label": 0
                },
                {
                    "sent": "OK, so any questions then, given that you may not have heard the entire first part of the talk.",
                    "label": 0
                },
                {
                    "sent": "Should I repeat ahead or?",
                    "label": 0
                },
                {
                    "sent": "Let's just assume that was all totally clear.",
                    "label": 0
                },
                {
                    "sent": "Is that right?",
                    "label": 0
                },
                {
                    "sent": "OK?",
                    "label": 0
                },
                {
                    "sent": "Right, so yeah, as Graham said, I.",
                    "label": 0
                },
                {
                    "sent": "Hand on heart.",
                    "label": 0
                },
                {
                    "sent": "Really not a deep learning person.",
                    "label": 0
                },
                {
                    "sent": "For which I apologize, instead I. Anna Bayesian and I might just draw this little vertical line down my chest.",
                    "label": 0
                },
                {
                    "sent": "That's the conditioning bar.",
                    "label": 0
                },
                {
                    "sent": "That's the sign of Bayesians.",
                    "label": 0
                },
                {
                    "sent": "And the way Bayesians think about probability theory is a little bit different to how other people use it.",
                    "label": 0
                },
                {
                    "sent": "So to a real card carrying Bayesian probability is an epistemic degree of belief.",
                    "label": 0
                },
                {
                    "sent": "So probability in answer to the question that was asked yesterday actually is taken as an expression of confidence in a proposition.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "One proposition in particular we might want to consider is the probability that it will rain.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "Yes, so traditional yeah, think about that kind of proposition.",
                    "label": 0
                },
                {
                    "sent": "It's usual to position probability theories being an extension of traditional deductive logic.",
                    "label": 1
                },
                {
                    "sent": "So deductive logic would allow us to say if it was raining.",
                    "label": 0
                },
                {
                    "sent": "It must with absolute certainty be cloudy.",
                    "label": 0
                },
                {
                    "sent": "Probability theory allows you to quantify the inverse relationship, so it allows you to say, given that we've observed that it's cloudy, what is our belief that it might also be raining?",
                    "label": 0
                },
                {
                    "sent": "And the way.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We do that mechanically.",
                    "label": 0
                },
                {
                    "sent": "In probability theory is to construct these conditional distributions, so the particular object of interest.",
                    "label": 0
                },
                {
                    "sent": "If you're thinking about whether or not it will rain, is the probability of it raining.",
                    "label": 0
                },
                {
                    "sent": "Given that is conditioned on an observation that it's cloudy.",
                    "label": 0
                },
                {
                    "sent": "And as I said, this probability is an epistemic degree of relief, and it's important to emphasize that.",
                    "label": 1
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "When we talk about this being epistemic, it means that it's personal.",
                    "label": 0
                },
                {
                    "sent": "It's bespoke to a particular agent, and whenever we're dealing with probability theory, it's essential to be clear about what that agent is.",
                    "label": 0
                },
                {
                    "sent": "So usually in machine learning, we're talking about the agent being kind of a machine learning model, but I seem to have gone into that plane mode, which the portion.",
                    "label": 0
                },
                {
                    "sent": "Could also be a human.",
                    "label": 0
                },
                {
                    "sent": "We might try to model A human with.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Conditional probability distribution.",
                    "label": 0
                },
                {
                    "sent": "Or it could also be something like a pigeon in my PhD work.",
                    "label": 1
                },
                {
                    "sent": "Actually we were using probability theory to model the navigation behaviors of pigeon, which is why I put that on the slide.",
                    "label": 0
                },
                {
                    "sent": "OK, I would like to buy that auto advancing.",
                    "label": 0
                },
                {
                    "sent": "Let me see if I can get out of it.",
                    "label": 0
                },
                {
                    "sent": "Not great.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "How to find out that I was on the right hand side of that condition bar and coming back to my previous point about this probability distribution being particular to a chosen agent, the eye specifies that agent, so we use I as context which defines the particular agent at hand, and another way of talking about eyes.",
                    "label": 0
                },
                {
                    "sent": "That's the prior information available to that agent.",
                    "label": 1
                },
                {
                    "sent": "Now.",
                    "label": 0
                },
                {
                    "sent": "Sorry.",
                    "label": 0
                },
                {
                    "sent": "That's really going to bother me.",
                    "label": 0
                },
                {
                    "sent": "Sorry.",
                    "label": 0
                },
                {
                    "sent": "What is the shortcut I need to press so that doesn't do that?",
                    "label": 1
                },
                {
                    "sent": "Auto advancing.",
                    "label": 0
                },
                {
                    "sent": "I'll buy you a Mars bar if you tell me what it is.",
                    "label": 0
                },
                {
                    "sent": "No one, no one uses PowerPoint.",
                    "label": 0
                },
                {
                    "sent": "Good for you.",
                    "label": 0
                },
                {
                    "sent": "We just try and bear with it I guess.",
                    "label": 0
                },
                {
                    "sent": "OK, so yeah it is.",
                    "label": 0
                },
                {
                    "sent": "It is pretty bad, yeah?",
                    "label": 0
                },
                {
                    "sent": "I am using PowerPoint.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Right click and.",
                    "label": 0
                },
                {
                    "sent": "Screen spot displays not immediately seeing this non order dance.",
                    "label": 0
                },
                {
                    "sent": "Anyway, let's bear with it.",
                    "label": 0
                },
                {
                    "sent": "I apologize for that.",
                    "label": 0
                },
                {
                    "sent": "Thank you Simone to my rescue, hopefully.",
                    "label": 1
                },
                {
                    "sent": "OK, so in machine learning it doesn't make sense to talk about an agent that's out there in the world.",
                    "label": 0
                },
                {
                    "sent": "In a sense, we're building an agent, right?",
                    "label": 0
                },
                {
                    "sent": "And so.",
                    "label": 0
                },
                {
                    "sent": "Our goal is to select the right priors for the task at hand that I is available under our control.",
                    "label": 0
                },
                {
                    "sent": "And so in a sense, in this decision theoretic sort of way, we want to pick the prior that is most appropriate to the particular problem we're trying to solve in the particular computation that we have available to us.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And in particular, prior that's almost ubiquitous across probability theory in general, but in particular in probabilistic numerics is the Gaussian.",
                    "label": 1
                },
                {
                    "sent": "And of course, you've met the Gaussian many times in the past, but I thought it might just flag up why it's such a useful object for us, and some might do that by putting up on the slide a bivariate Gaussian.",
                    "label": 0
                },
                {
                    "sent": "This kind of two dimensional Gaussian as illustrated by the contours on the slide.",
                    "label": 0
                },
                {
                    "sent": "Again, it's order advancing, which is annoying.",
                    "label": 0
                },
                {
                    "sent": "Anne and.",
                    "label": 0
                },
                {
                    "sent": "What we might want from that bivariate Gaussian is one of two distributions, one of which is a marginal distribution.",
                    "label": 0
                },
                {
                    "sent": "That is, given a distribution over Y2 and Y1, we might want the distribution over just Y one alone.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "How many computer scientists does it take to fix this?",
                    "label": 0
                },
                {
                    "sent": "Is anyone here actually from Microsoft?",
                    "label": 0
                },
                {
                    "sent": "Never microphones feedback.",
                    "label": 0
                },
                {
                    "sent": "Let's try and bear with it.",
                    "label": 0
                },
                {
                    "sent": "With apologies.",
                    "label": 0
                },
                {
                    "sent": "So one thing we might want out of this bivariate Gaussian is the.",
                    "label": 0
                },
                {
                    "sent": "The marginal distribution for Y1 alone, that is, the distribution for just one of those variables and actually a super useful property of the Gaussian, is that that marginal distribution contributed in closed form really easily, and in fact, that marginal distribution is itself Gaussians.",
                    "label": 0
                },
                {
                    "sent": "That's the blue curve at the bottom of the slide.",
                    "label": 0
                },
                {
                    "sent": "Another distribution we might want is a conditional distribution.",
                    "label": 0
                },
                {
                    "sent": "So in a Bayesian sense that conditional distribution might represent, for instance, the.",
                    "label": 0
                },
                {
                    "sent": "Posterior probability of Y1 given that we've observed that Y two is equal to minus five and again for the Gaussian.",
                    "label": 0
                },
                {
                    "sent": "We have this amazing property that it can be computed in closed form, and it is again a Gaussian.",
                    "label": 0
                },
                {
                    "sent": "So in a sense this Gaussian is closed under both conditioning and marginalization, which is super super useful and I'll tell you in a couple of slides why exactly that is in the case of doing inference about functions.",
                    "label": 0
                },
                {
                    "sent": "Let's try and get to that point.",
                    "label": 0
                },
                {
                    "sent": "I want to represent that conditional distribution the Y one given Y two in a slightly different way, and that's what we've got on the right hand side of the slide.",
                    "label": 0
                },
                {
                    "sent": "So what it shows is the distribution for Y one in the first column, conditional on the observation of Y2, which is represented in the second column with kind of a drag Delta function, because in fact the posterior distribution for Y1 and Y2 that joint conditional on the observation that Y two is equal to minus 5.",
                    "label": 0
                },
                {
                    "sent": "Has a marginal for Y2, which is, you know, perfectly certain.",
                    "label": 0
                },
                {
                    "sent": "We've observed that Y 2.",
                    "label": 0
                },
                {
                    "sent": "That was a bit of a mouthful, but hopefully you get what I'm trying to represent that this is a joint distribution for Y1 and Y2 conditional on Y2.",
                    "label": 0
                },
                {
                    "sent": "Represented rather than in that kind of bivariate way in these two columns.",
                    "label": 0
                },
                {
                    "sent": "And if you're happy without representation, hopefully you're also happy with me.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Making the generalization to not just two variables but say 10K, it seems like that's been fixed.",
                    "label": 0
                },
                {
                    "sent": "Thank you very much and if you're happy with that, you might be happy with me generalizing from 10 variables to a potentially infinite number of variables.",
                    "label": 1
                },
                {
                    "sent": "Now that generalization to that potentially infinite number of variables gives us a very special object, which is called a Gaussian process, can just ask for a show of hands from who was heard of the Gaussian process before.",
                    "label": 0
                },
                {
                    "sent": "Most people have, which is great, in which case I apologize for wasting your time to some degree.",
                    "label": 0
                },
                {
                    "sent": "But um, yeah, what that Gaussian process gives us?",
                    "label": 0
                },
                {
                    "sent": "Then by considering that limit squishing that not just finite number of variables but potentially infinite number of variables infinitesimally close together is a way of doing inference about functions, which you can think of as being kind of represented by an infinite dimensional length vector.",
                    "label": 0
                },
                {
                    "sent": "So on this slide I've got a cartoon of water.",
                    "label": 1
                },
                {
                    "sent": "Gaussian process might look like.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The posterior distribution for Y as a function of X where we observed Y at 5 different points.",
                    "label": 0
                },
                {
                    "sent": "And the beating heart of a Gaussian process is what's known as its mean and covariance functions, which are just the generalization of the mean vector and covariance matrix that define a usual multivariate Gaussian distribution.",
                    "label": 1
                },
                {
                    "sent": "And.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Without saying too much about it, the important thing to know about that covariance function, if you haven't encountered it before, is that it really is quite a very.",
                    "label": 0
                },
                {
                    "sent": "It is very flexible way of modeling functions there.",
                    "label": 0
                },
                {
                    "sent": "All kinds of things we can bake into a covariance function to encode properties to define its prior suitable to the kind of functions with which we're dealing.",
                    "label": 0
                },
                {
                    "sent": "So in particular might want to bake into a covariance function.",
                    "label": 1
                },
                {
                    "sent": "Knowledge that signal is periodic, and that periodicity could be combined with some longer term drifts.",
                    "label": 0
                },
                {
                    "sent": "We can define covariance functions for multiple tasks or multiple time series that might be correlated to some degree, but have delays between them all.",
                    "label": 0
                },
                {
                    "sent": "This is possible and more.",
                    "label": 0
                },
                {
                    "sent": "But",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "You know, obviously this is deep learning summer school, so I wanted to bring out some of the differences between thinking about functions in a Gaussian process way from thinking about them through modeling with neural networks.",
                    "label": 0
                },
                {
                    "sent": "So first thing that this Gaussian process framework gives us is a move away from doing inference by optimization.",
                    "label": 0
                },
                {
                    "sent": "So the weights in a Gaussian process kind of implicit and are in Ferd not through having to optimize them, but in fact through linear algebra.",
                    "label": 0
                },
                {
                    "sent": "Which is in a sense better because linear algebra is perhaps.",
                    "label": 0
                },
                {
                    "sent": "Better behaved.",
                    "label": 0
                },
                {
                    "sent": "And also it means that through that linear process we get not just an optimized value for those weights, but in fact implicitly an integral over all possible values for them, which is quite nice.",
                    "label": 0
                },
                {
                    "sent": "Return to that topic later in the talk, but that integral over all possible setting for the weights gives us a means of modeling functions that is quite robust to overfitting.",
                    "label": 1
                },
                {
                    "sent": "So here is me trying to model a quadratic with the Gaussian process and you.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I think that given a sufficient number of observations, we should learn this quadratic perfectly, right?",
                    "label": 0
                },
                {
                    "sent": "In fact, we are learning it pretty well, but crucially, for the particular covariance function that we've chosen, we don't.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Overfitted, we haven't.",
                    "label": 0
                },
                {
                    "sent": "You know reduced our variance to infinitesimal amounts between the observations.",
                    "label": 0
                },
                {
                    "sent": "We're maintaining a reasonable amount of epistemic uncertainty in regions where the function hasn't been evaluated, because this gas and process doesn't know that the functions modeling is a quadratic.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So that was the first part of probabilistic numerics.",
                    "label": 0
                },
                {
                    "sent": "As I say, these Gaussian process is kind of equetus across the entirety of the field, but there only one component of what it is we do within probabilistic matrix, and the second component as I was trying to raise earlier, is thinking about that use of computation in a decision theoretic way.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I would like to return to global optimization.",
                    "label": 0
                },
                {
                    "sent": "And of course, the use of computation we make with in global optimization is the evaluation of the objective.",
                    "label": 0
                },
                {
                    "sent": "So each objective evaluation as it was trying to get out earlier might require something like the training of a model which uses several hours of computation.",
                    "label": 0
                },
                {
                    "sent": "It might take a drug trial which takes millions of dollars, so those are costs that we want to take very seriously in thinking about how to do this optimization process in an optimal way.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "In particular.",
                    "label": 0
                },
                {
                    "sent": "We're going to try and represent within the probabilistic numeric way of thinking about global optimization, which is called Bayesian optimization, not particularly originally.",
                    "label": 0
                },
                {
                    "sent": "By representing the two core components of our loss function here, the first of which is that kostman valuation, which on this slide are represented with an Australian $100 notes interesting facts.",
                    "label": 0
                },
                {
                    "sent": "the Australian dollar is now almost one one parity with the Canadian dollar, so that is 100 Canadian dollars.",
                    "label": 0
                },
                {
                    "sent": "Actually that wasn't that interesting.",
                    "label": 0
                },
                {
                    "sent": "I apologize for mentioning it.",
                    "label": 0
                },
                {
                    "sent": "But the other term in our loss function, of course is the degree of uncertainty we have in the object of interest, and we need to bring both of those into our loss function in some sort of way.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "There are many ways of coming up with loss functions for Bayesian optimization.",
                    "label": 0
                },
                {
                    "sent": "Here I'm just going to present one of them, the one that I think is most intuitive.",
                    "label": 0
                },
                {
                    "sent": "It's known by many names.",
                    "label": 0
                },
                {
                    "sent": "Expected improvement is perhaps the most ubiquitous.",
                    "label": 0
                },
                {
                    "sent": "But essentially what it does is to say let's ignore the cost of computation through the means of just limiting ourselves with finite budget of evaluations.",
                    "label": 0
                },
                {
                    "sent": "So we're going to say that.",
                    "label": 0
                },
                {
                    "sent": "We have some evaluations available to us to find the optimum of this function.",
                    "label": 0
                },
                {
                    "sent": "And in particular, in expected improvements, we're going to take the quite severe myopic approximation that we have only one such evaluation remaining.",
                    "label": 0
                },
                {
                    "sent": "So in that myopic approximation, the loss that we'll get is.",
                    "label": 0
                },
                {
                    "sent": "Actually, the best function value we have after that next evaluation is spent.",
                    "label": 0
                },
                {
                    "sent": "So at this point I should apologize for the fact that optimization is usually framed as a minimization problem rather than as a maximization problem.",
                    "label": 0
                },
                {
                    "sent": "When I've said that the loss is the lowest function value found after next valuation, that might have sounded a bit unintuitive, but if you think about it the other way around, that is of course as an or decision theory can frame it either as an minimization of loss or a maximization of utility.",
                    "label": 0
                },
                {
                    "sent": "The equivalent utility function to this would say the utility we get after the next in function evaluation is the highest function value.",
                    "label": 0
                },
                {
                    "sent": "There you know that we've been obtained, which to me seems a little bit easier to understand.",
                    "label": 0
                },
                {
                    "sent": "But either way, what that means is that there are two possibilities.",
                    "label": 0
                },
                {
                    "sent": "Either the next function value Huawei is better than the best that we've got so far, which we call Eater, in which case our losses that why otherwise we can fall back to the best value that we obtained so far, which gives us just data.",
                    "label": 0
                },
                {
                    "sent": "So this is kind of like a rectified linear unit.",
                    "label": 0
                },
                {
                    "sent": "In fact, this loss.",
                    "label": 0
                },
                {
                    "sent": "Did you see how connected that's deep learning?",
                    "label": 0
                },
                {
                    "sent": "Was that satisfying?",
                    "label": 0
                },
                {
                    "sent": "Anne, right.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So of course, in decision theory, the objective on which we actually act is an expected loss.",
                    "label": 0
                },
                {
                    "sent": "So now what we have to bring to bear is that probabilistic model that I was talking about in the early part of the talk.",
                    "label": 0
                },
                {
                    "sent": "So what we need to do is to compute the expectation of that loss function on the previous slide against the probability distribution for what next function value will be.",
                    "label": 0
                },
                {
                    "sent": "So that choice of loss function and the choice of Gaussian process to represent the Gaussian marginal over the next function value.",
                    "label": 0
                },
                {
                    "sent": "Gives us a loss function that is actually tractable.",
                    "label": 1
                },
                {
                    "sent": "And the way of thinking about it, that expected loss is the.",
                    "label": 0
                },
                {
                    "sent": "Expected lowest value of the function out the expected lowest value of the function.",
                    "label": 0
                },
                {
                    "sent": "We've gone after that next valuation.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So let's go into a kind of cartoon process of Bayesian optimization.",
                    "label": 0
                },
                {
                    "sent": "In which we've chosen a Gaussian process to model our objective function and that simple expected improvement loss function.",
                    "label": 0
                },
                {
                    "sent": "So let's imagine we start with just a single evaluation of a loss function, which is given in the dots.",
                    "label": 0
                },
                {
                    "sent": "So you can see that it's bimodal.",
                    "label": 0
                },
                {
                    "sent": "The evaluation is the cross and on the basis of that cross we've produced a Gaussian process posterior kind of pink sausage here, which has got a posterior mean in the red line and a posterior variance in the plus or minus single stand deviation.",
                    "label": 0
                },
                {
                    "sent": "Credibility intervals plotted on the slide.",
                    "label": 0
                },
                {
                    "sent": "And on the basis of that Gaussian process posterior, we can do that integral on the previous slide to compute what the expected losses of evaluating this function anywhere else in its domain.",
                    "label": 0
                },
                {
                    "sent": "And that's the blue curve.",
                    "label": 0
                },
                {
                    "sent": "So have a look what it's telling us.",
                    "label": 0
                },
                {
                    "sent": "It's saying that as I said earlier, the expected best value of the function we've got is going to be low if we evaluate anywhere else in this domain other than close to where we've already evaluated.",
                    "label": 1
                },
                {
                    "sent": "Because in those regions removed from our current valuation, there's some probability, even if small, of getting a function value that's actually significantly better than what we've seen so far, so the expected loss has these dips.",
                    "label": 1
                },
                {
                    "sent": "Either side of the evaluation closely evaluation we get high expected loss that's not likely to give us anything better, so the best next action is the diamond.",
                    "label": 0
                },
                {
                    "sent": "That's where we're going to evaluate the function.",
                    "label": 0
                },
                {
                    "sent": "If we do, we get the second cross on the slide.",
                    "label": 0
                },
                {
                    "sent": "Which you know, it was really surprisingly good.",
                    "label": 0
                },
                {
                    "sent": "If you go back.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the credibility intervals from this slides and notes where the function value actually ended up.",
                    "label": 0
                },
                {
                    "sent": "We got something that was way better than we were expecting to see.",
                    "label": 0
                },
                {
                    "sent": "So on that basis we update our posterior belief over the function and on the basis of that posterior we can compute a new expected loss and look how different its behavior is now.",
                    "label": 0
                },
                {
                    "sent": "So now the sorry I can't be seen on that side on camera.",
                    "label": 0
                },
                {
                    "sent": "Apparently I better go to this side.",
                    "label": 0
                },
                {
                    "sent": "It's got now two lobes, one either side of the current best evaluation.",
                    "label": 0
                },
                {
                    "sent": "Leading us not to kind of explore further afield, but instead to move to what we call an exploitative behavior.",
                    "label": 0
                },
                {
                    "sent": "In which we want to evaluate quite close to the existing evaluation becausw it would have been extraordinarily lucky had we found an evaluation that was truly at the best function value in that particular neighborhood.",
                    "label": 0
                },
                {
                    "sent": "If it was at a local mode.",
                    "label": 0
                },
                {
                    "sent": "Instead, we think it's quite likely to find a function value that's even better if we just exploit a little bit harder.",
                    "label": 0
                },
                {
                    "sent": "So if we do that, we fine.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Another function value, which is in fact a little bit better and then subsequent to that we exploit again by going in between those two evaluations and at that point we've more or less found all the information there is to be had in that local region.",
                    "label": 0
                },
                {
                    "sent": "Now I expected loss is telling us there's not much value left in spending further evaluations in that particular local region.",
                    "label": 0
                },
                {
                    "sent": "We've more or less resolved our uncertainty to the degree that we have to.",
                    "label": 0
                },
                {
                    "sent": "So at this point we switch to what's known as an exploratory mode.",
                    "label": 0
                },
                {
                    "sent": "Image.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The greatest value is going to be achieved by trying to track down some of those big regions of uncertainty further out to the right and left so little Blue Diamond now tells us to perform an explore move.",
                    "label": 0
                },
                {
                    "sent": "We do that.",
                    "label": 0
                },
                {
                    "sent": "We do it again and.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That second time round, we get another lucky break.",
                    "label": 0
                },
                {
                    "sent": "We find another function value which was a lot better than what we expected to see.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "At that point, we switch again into an exploitive mode, and in doing so, we.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Quickly discover what turns out to be the true global minimum of this function near enough, and having done.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The remainder of our budget of valuations is going to be spent in really tracking down all remaining regions of uncertainty.",
                    "label": 0
                },
                {
                    "sent": "So what I hope that cartoon is illustrated is that through this quite simple model of the function and Gaussian process and a simple decision rule, we get emergent behavior that's remarkably intelligent.",
                    "label": 0
                },
                {
                    "sent": "Question it back.",
                    "label": 0
                },
                {
                    "sent": "Discussion process model.",
                    "label": 0
                },
                {
                    "sent": "OK, so that is a question not about Gaussian processes, but about covariance functions.",
                    "label": 0
                },
                {
                    "sent": "Actually, because within a Gaussian process you can certainly come up with covariance functions that are very non smooth.",
                    "label": 0
                },
                {
                    "sent": "But you're right in fact that the most commonly used covariance functions doing code some degree of smoothness.",
                    "label": 0
                },
                {
                    "sent": "But to me that makes a lot of sense.",
                    "label": 0
                },
                {
                    "sent": "I mean in fact optimization in particular is impossible unless there is some smoothness in this function.",
                    "label": 0
                },
                {
                    "sent": "So the challenge is.",
                    "label": 0
                },
                {
                    "sent": "In finding out what degree of smoothness is most appropriate to the particular objective we have at hand, and we get that, in a sense, magically from the Bayesian engine in kind of working out what the best high parameters are for a particular covariance function.",
                    "label": 0
                },
                {
                    "sent": "Hiking.",
                    "label": 0
                },
                {
                    "sent": "So this was a question about the degree to which Gaussian processes can be used in high dimensions.",
                    "label": 0
                },
                {
                    "sent": "And you're absolutely right that the state of the art in GPS does not scale up well with dimension.",
                    "label": 0
                },
                {
                    "sent": "That's a whole another talk really about how you get them to do that, and you know there is kind of cutting edge work that gives us stuff that does actually work even in a million dimensions for the purpose of this talk, I'm going to say only that there are really interesting problems in only 20 dimensions.",
                    "label": 0
                },
                {
                    "sent": "There are a lot of hyperparameter tuning problems in particular.",
                    "label": 0
                },
                {
                    "sent": "In which you might only have 20 high parameters to tune, and you want to spend a lot of computing getting them as well as possible.",
                    "label": 0
                },
                {
                    "sent": "In motion.",
                    "label": 0
                },
                {
                    "sent": "Like you're looking for smooth transition.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so the question was in Brownian motion.",
                    "label": 0
                },
                {
                    "sent": "Obviously we get non smooth functions, non differentiable functions.",
                    "label": 0
                },
                {
                    "sent": "Local places.",
                    "label": 0
                },
                {
                    "sent": "Yeah, I think yeah, let's talk about this later.",
                    "label": 0
                },
                {
                    "sent": "I mean really all for this talk I want to get across is that there are many different covariance functions you can choose later in the talk.",
                    "label": 0
                },
                {
                    "sent": "Hopefully I'll get to tell you about how we might pick the covariance function that is best suited to the particular numeric problem in hand.",
                    "label": 0
                },
                {
                    "sent": "You know what?",
                    "label": 0
                },
                {
                    "sent": "I'm just going to give you a little advertisement for that one.",
                    "label": 0
                },
                {
                    "sent": "Super interesting thing about numeric problems, which is different from almost any other type of problem of learning, is that the object is available to us, right?",
                    "label": 0
                },
                {
                    "sent": "So in a numeric problem, the objective function might be like that rosenbrock function in which we have a clear, concise mathematical expression.",
                    "label": 0
                },
                {
                    "sent": "It might be expressed in source code, which we can go and inspect.",
                    "label": 0
                },
                {
                    "sent": "So probabilistic numerics may be distinct from any other part of learning.",
                    "label": 0
                },
                {
                    "sent": "We do actually have a really strong basis for building those priors, right?",
                    "label": 0
                },
                {
                    "sent": "We can look at the mathematical expression for an objective.",
                    "label": 0
                },
                {
                    "sent": "We can inspect the sports, support the source code of the particular.",
                    "label": 0
                },
                {
                    "sent": "Model that we're trying to optimize and use that construct the prior that is most suited to the problem.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Right so.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "How?",
                    "label": 0
                },
                {
                    "sent": "Why this Mail?",
                    "label": 0
                },
                {
                    "sent": "Pick approximate widely?",
                    "label": 0
                },
                {
                    "sent": "Finding this blue loss function and use the myopic approximation with this notion provide this magical way to to explore and discover the job opportunities explained that inclusion or the reason why it works.",
                    "label": 0
                },
                {
                    "sent": "So the question was why does this myopic strategy nonetheless give that something that kind of looks magic?",
                    "label": 0
                },
                {
                    "sent": "So actually I wouldn't recommend the myopic strategy in particular, and you get even.",
                    "label": 0
                },
                {
                    "sent": "More interesting behavior by trying to think further steps into the future, and we've done some work in relaxing that mark approximation, but I think it is interesting that even with this really quite severe approximation, we do get this quite powerful behavior out.",
                    "label": 0
                },
                {
                    "sent": "Why is that?",
                    "label": 0
                },
                {
                    "sent": "It's because there's been all this work under the hood in thinking very seriously about uncertainty, so even considering only a single evaluation into the future, we still are trying, you know, that's built on the back of reasoning of.",
                    "label": 0
                },
                {
                    "sent": "You know just how confident we can be about this function anywhere else, so there is still that motivation to try and track down regions in which there hasn't been any evaluation so far.",
                    "label": 0
                },
                {
                    "sent": "So even though we're only considering one step into the future, there is still an incentive to find regions of high uncertainty due to the kind of mechanics underpinning the Gaussian process.",
                    "label": 0
                },
                {
                    "sent": "Was that an answer to my question?",
                    "label": 0
                },
                {
                    "sent": "Can I say that?",
                    "label": 0
                },
                {
                    "sent": "The North function called somehow encode the uncertainty inside no no.",
                    "label": 0
                },
                {
                    "sent": "So the question was, does the loss function encode the uncertainty?",
                    "label": 0
                },
                {
                    "sent": "The loss function is independent of the probabilistic model.",
                    "label": 0
                },
                {
                    "sent": "It's the probabilistic model that reflects the uncertainty.",
                    "label": 0
                },
                {
                    "sent": "It's our statement about our epistemic beliefs about the function.",
                    "label": 0
                },
                {
                    "sent": "Question.",
                    "label": 0
                },
                {
                    "sent": "Like this?",
                    "label": 0
                },
                {
                    "sent": "Excellent question about the fact that these Gaussian processes themselves have hyperparameters.",
                    "label": 0
                },
                {
                    "sent": "In fact, that's kind of the next part of the talk, But yeah, so it's important to recognize this kind of infinite recurse we often experience in probabilistic numeric switches in bringing a probabilistic model to numerics problem.",
                    "label": 0
                },
                {
                    "sent": "That probabilistic model itself will require.",
                    "label": 0
                },
                {
                    "sent": "Numerics problems in order to actually fit it to a function, what we normally do is kind of go down the chain of numerics so the usual kind of hierarchy of numerics problems is integration, which is really hard optimization, which is perhaps less hard.",
                    "label": 0
                },
                {
                    "sent": "Linear algebra is less hard again, and what we've done to deal with the hyperparameters of this Gaussian process is a kind of approximation to the true integration we need to do over its values.",
                    "label": 0
                },
                {
                    "sent": "In fact, we do a kind of akin to Laplace approximation, which just requires linear algebra, so yeah.",
                    "label": 0
                },
                {
                    "sent": "At some point you do have to move to a numerics problem, which is slightly easier.",
                    "label": 0
                },
                {
                    "sent": "In order to get something that works in practice.",
                    "label": 0
                },
                {
                    "sent": "I'm not sure if that's an answer to question, but the next part of the talk is all about the tuning of high parameters using Bayesian optimization, so maybe we'll move on to that now.",
                    "label": 0
                },
                {
                    "sent": "Great so.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Yeah, Fortunately for this talk you brought up yesterday, the use of Bayesian optimization for tuning the high parameters of neural networks.",
                    "label": 0
                },
                {
                    "sent": "I've already had that nice intro.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Action, but in fact tuning is problem across all of machine learning and I thought it might give you an example from Gaussian process is so during my PhD another data set I was trying to model is weather sensor network data and one of the things that our weather sensor network was able to model was title data.",
                    "label": 0
                },
                {
                    "sent": "Which is not particularly difficult to predict.",
                    "label": 0
                },
                {
                    "sent": "It's relatively periodic.",
                    "label": 0
                },
                {
                    "sent": "But the reason I've chosen edge is because it gives these really nice log likelihood surfaces as a function of one of the high parameters of the model, which is the log.",
                    "label": 0
                },
                {
                    "sent": "So of course if you're trying to fiddle periodic or quasiperiodic model to data that is in fact periodic, the likelihood service is going to have this kind of periodic shape reflecting the fact that the true.",
                    "label": 0
                },
                {
                    "sent": "Which for tides is half a day corresponds to a really big peak and likelihood space.",
                    "label": 0
                },
                {
                    "sent": "But they're going to be all these other peaks associated with harmonics of that true.",
                    "label": 0
                },
                {
                    "sent": "That is, a period of one day or two days is also going to look like a pretty good explanation for the data.",
                    "label": 0
                },
                {
                    "sent": "But real likelihoods have all these other really quite nasty behaviors, So what you're seeing over to the left here are harmonics of the sampling period of the data, which also show up as peaks in the likelihood function.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "In fact, tuning these parameters is not necessarily all that easy, and in fact, in doing maximum likelihood or least squares estimation for a lot of these problems, we do need to think seriously about not just local optimization, but global optimization.",
                    "label": 0
                },
                {
                    "sent": "We don't get trapped in any of those little local modes.",
                    "label": 0
                },
                {
                    "sent": "And so that is certainly a reasonable heuristic for exploring that likelihood function.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And it's one to which probabilistic numerics has a lot to say, because in fact arguably the state of the art for these kind of hyperparameter tuning problems is Bayesian optimization, because what it gives us is that really quite flexible way of modeling nasty multimodal likelihood surface.",
                    "label": 0
                },
                {
                    "sent": "And on the basis of that probabilistic model, we can spend the computation we have intelligently.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So he was quite modest yesterday and not mentioning that he really published one of the landmark papers in this space.",
                    "label": 0
                },
                {
                    "sent": "So NIPS in 2012 was called practical Bayesian optimization and machine learning algorithms or something like that.",
                    "label": 0
                },
                {
                    "sent": "And in particular, in that paper they showed how you know, simple application, relatively Speaking of Bayesian optimization, using again that myopic loss, the expected improvement acquisition function gave better than state of the arts for particular neural network on Sci-fi 10, which was pretty impressive.",
                    "label": 0
                },
                {
                    "sent": "But coming back to the theme of the talk that.",
                    "label": 0
                },
                {
                    "sent": "You know one of the advantages of probabilistic numerics is that it allows you to define the right prior in subsequent work.",
                    "label": 0
                },
                {
                    "sent": "In fact, in collaboration with Jasper, Snoek who's on this paper, we showed how that.",
                    "label": 0
                },
                {
                    "sent": "By thinking a little bit more deeply about the type of structure of neural networks, we can design even more effective Bayesian optimizers to tune the hyperparameters.",
                    "label": 0
                },
                {
                    "sent": "So in particular, in dealing with.",
                    "label": 0
                },
                {
                    "sent": "New networks within.",
                    "label": 0
                },
                {
                    "sent": "Variable number of hidden layers.",
                    "label": 0
                },
                {
                    "sent": "We need to reflect the fact that some of the hyperparameters of the neural network don't have any significance unless the associated hidden layer is switched on.",
                    "label": 0
                },
                {
                    "sent": "That is, if you have a variable number of hidden layers and you're also trying to optimize over the number of hidden layers, the number of hidden units per layer, the number of hidden units for the fifth layer aren't important unless you've got more than four layers, right?",
                    "label": 0
                },
                {
                    "sent": "So if you're defining the parameter space over which to search, you can't just create a really long vector which contains all the number of units per layer.",
                    "label": 0
                },
                {
                    "sent": "For any arbitrarily large number of layers.",
                    "label": 0
                },
                {
                    "sent": "In fact, you want to have some sort of structure baked into your optimizer that reflects the fact that some of those parameters aren't significant unless other parameters like the number of hidden layers have particular values.",
                    "label": 0
                },
                {
                    "sent": "Does that make sense?",
                    "label": 0
                },
                {
                    "sent": "Or in particular, here the structure of this space is conditional, that is, the significance of some of the parameters is conditional on the setting of other parameters.",
                    "label": 0
                },
                {
                    "sent": "So in this workshop paper we designed a new covariance function which we called the art covariance, which reflects that particular conditional behavior, capturing the kind of hierarchy that exists amongst these parameters and by just plugging and playing with it, putting it into a bog standard Bayesian optimizer.",
                    "label": 0
                },
                {
                    "sent": "We're able to get really again quite interesting.",
                    "label": 0
                },
                {
                    "sent": "Behavior out of our optimization strategy.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So in particular, in learning all these parameters over both MNIST and sci-fi term, we saw that our optimizer was searching much deeper models than standard Bayesian optimization never would.",
                    "label": 0
                },
                {
                    "sent": "So the plots on the right here shows the number of evaluations that are optimized with spending it variable number of variable numbers of layers, and you can see that our Arc GP novel model spent a lot more of its budget on those deeper architectures, which.",
                    "label": 0
                },
                {
                    "sent": "Was interesting and gave in fact much better performance overall.",
                    "label": 0
                },
                {
                    "sent": "OK, so that was my first attempt at making probabilistic numerics relevant to neural networks.",
                    "label": 0
                },
                {
                    "sent": "Here's another one.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Which is to say that this particular numerical techniques so ubiquitous across deep learning stochastic optimization also has an interesting interpretation within this Bayesian optimization framework.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here's how I think about stochastic optimization.",
                    "label": 0
                },
                {
                    "sent": "And again, I'm going to think about this in the context of learning the hyperparameters of a model for a function.",
                    "label": 0
                },
                {
                    "sent": "So on the left I've got.",
                    "label": 0
                },
                {
                    "sent": "Data represented by little red dots, of which I'm taking three different subsets.",
                    "label": 0
                },
                {
                    "sent": "Three different mini batches.",
                    "label": 0
                },
                {
                    "sent": "If you like in the three different plots, so function is Y of T, the red dots are observations of it.",
                    "label": 0
                },
                {
                    "sent": "And in each case I'm going to consider two possible settings of the hyper parameters of the model.",
                    "label": 0
                },
                {
                    "sent": "For that function, one of which induces a really flat function.",
                    "label": 0
                },
                {
                    "sent": "That's the kind of yellow posterior belief, another of which another setting for high parameters induces a much wiggle.",
                    "label": 0
                },
                {
                    "sent": "Your function encoding the fact that there could be sort of short term fluctuations in it.",
                    "label": 0
                },
                {
                    "sent": "That's the sort of cyan setting for the high parameters and on the right of Maps those hyperparameters to their likelihood.",
                    "label": 0
                },
                {
                    "sent": "In light of the particular setting for the subset of data, so for the first 2 subsets it looks like the green model.",
                    "label": 0
                },
                {
                    "sent": "The Scion model is much better, because there does indeed seem to be some sort of short-term wiggle in the function, in which case that setting for the high parameters, which favors that short-term wiggling is preferred.",
                    "label": 0
                },
                {
                    "sent": "But for other subsets other mini batches.",
                    "label": 0
                },
                {
                    "sent": "The setting of the high parameters which induces longer term structure might look better, such as the subset of chosen at the back here, in which case a flat function is actually pretty plausable explanation of the data.",
                    "label": 0
                },
                {
                    "sent": "So that's stochastic optimization through a kind of Bayesian lens.",
                    "label": 0
                },
                {
                    "sent": "In particular when we evaluate.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "On a mini batch we get a likelihood evaluation that is noisy.",
                    "label": 1
                },
                {
                    "sent": "But in fact, within Bayesian optimization, noisy evaluations aren't really a problem.",
                    "label": 0
                },
                {
                    "sent": "We've already put all this work into treating our objective function as a random variable.",
                    "label": 0
                },
                {
                    "sent": "So if there's additional noise in that random variable, that is, if there's uncertainty in it, not just to our epistemic beliefs.",
                    "label": 0
                },
                {
                    "sent": "The fact that we can't afford all the computation would like.",
                    "label": 0
                },
                {
                    "sent": "But if there's additional uncertainty due to some sort of fundamental noise process, we don't really have to change our way of thinking.",
                    "label": 0
                },
                {
                    "sent": "We can just slap on additional noise likelihood to complement everything that's come before, and we can more or less use exactly the same models that we've used in the past to optimize such noisy objectives.",
                    "label": 0
                },
                {
                    "sent": "Now.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Well, not just can we reproduce that kind of optimization in the presence of noise in the objective we can actually use the decision theoretic tools that have introduced to go one step better than standard stochastic optimization.",
                    "label": 0
                },
                {
                    "sent": "So here I want to talk about the fact that.",
                    "label": 0
                },
                {
                    "sent": "Usually the reason that we do stochastic optimization is because we can't afford an evaluation on the entire data set, right, so?",
                    "label": 0
                },
                {
                    "sent": "There is a cost associated with evaluating on a larger subset of the data, so that has some scaling in the number of data.",
                    "label": 0
                },
                {
                    "sent": "For Gaussian process it's usually honorific N ^3.",
                    "label": 0
                },
                {
                    "sent": "So really, we want to tell the optimize that we're using to search over the high parameters of that model about that scaling in the number of data.",
                    "label": 0
                },
                {
                    "sent": "In particular, if we encode that cost as a function of the number of data, we can get the Bayesian optimization strategy strategy to attend intelligently choose the size of data that it needs at runtime in order to best optimize the function overall.",
                    "label": 1
                },
                {
                    "sent": "So we've implemented that and it does more or less what you'd expect.",
                    "label": 0
                },
                {
                    "sent": "That is, it tends to spend the first evaluations of the function it has with a very small subset of the data.",
                    "label": 0
                },
                {
                    "sent": "Really small mini batches because at that point you're just trying to be really explore it.",
                    "label": 0
                },
                {
                    "sent": "If you're trying to get a few evaluations everywhere in the domain of the hyperparameters, tracking down which regions can be ruled out almost immediately, and then as time goes on, you spend more of.",
                    "label": 0
                },
                {
                    "sent": "More and more of your time with larger batches because towards the end of your optimization run you really want to be more exploitative and hone in on regions that you've already learned pretty good.",
                    "label": 0
                },
                {
                    "sent": "Now this leads to really quite impressive improvements in performance as measured now, not just by the number of evaluations that have been used, but actually by Wall Clock time that is relative to standard Bayesian optimization, which uses batches of a fixed size.",
                    "label": 0
                },
                {
                    "sent": "Even if you are reasonably sensible about what that that should be.",
                    "label": 0
                },
                {
                    "sent": "In our approach and I should say that there are two papers that came out this year which do vaguely similar things.",
                    "label": 0
                },
                {
                    "sent": "One was from our Group One was from Stuttgard.",
                    "label": 0
                },
                {
                    "sent": "In the other of these approaches, you get substantially better performance by allowing that batch size to vary in response to the needs of the particular point in the optimization, and we get really quite remarkable speed up in wall Clock time, and I say it's remarkable because remember that the overhead we've introduced in doing Bayesian optimization is not trivial.",
                    "label": 0
                },
                {
                    "sent": "That is, our optimizer requires the fitting of a Gaussian process, which, as I mentioned earlier, has this quite nasty N cubed scaling, at least naively in the number of valuations of the objective.",
                    "label": 0
                },
                {
                    "sent": "And we're also doing some additional computation to deal with the hyperparameters of that model, and then we have to optimize the acquisition function.",
                    "label": 0
                },
                {
                    "sent": "There's all this overhead associated with Bayesian optimization, which is captured in that X axis.",
                    "label": 0
                },
                {
                    "sent": "The wall Clock time that's actually expanded, and even in doing more of that by using the.",
                    "label": 0
                },
                {
                    "sent": "Early stages of our optimization process on smaller subsets and hence getting more evaluations, were still able to do better than a naive approach which maybe does less Bayesian optimization on more expensive evaluations.",
                    "label": 0
                },
                {
                    "sent": "Okie dokie",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So thanks very much for your patience so far.",
                    "label": 0
                },
                {
                    "sent": "I thought now might be a good time to sort of spark you up with a quiz.",
                    "label": 0
                },
                {
                    "sent": "So do these quizzes in my lectures all the time, then multiple choice and the way I'd like you to answer them is not by raising a hand at the appropriate point, but instead by raising a number of fingers with the answer that you think is correct.",
                    "label": 0
                },
                {
                    "sent": "So if you think answer one is correct to raise one finger.",
                    "label": 0
                },
                {
                    "sent": "If you think 2 is correct, you raise two fingers.",
                    "label": 0
                },
                {
                    "sent": "I apologize to anyone who doesn't have four fingers.",
                    "label": 0
                },
                {
                    "sent": "And so the question here is which of these sequences is truly random?",
                    "label": 0
                },
                {
                    "sent": "And here of course I'm motivated by the fact that usually those subsets in stochastic optimization is selected randomly.",
                    "label": 0
                },
                {
                    "sent": "So I've got four choices.",
                    "label": 0
                },
                {
                    "sent": "Hopefully by now you've had time to consider them.",
                    "label": 0
                },
                {
                    "sent": "Now we just about ready to make our stab, at which answer you think is correct.",
                    "label": 0
                },
                {
                    "sent": "OK, so in the count of three, please hands in the air 321 hands in the air.",
                    "label": 0
                },
                {
                    "sent": "So I'm getting a lot of force, a lot of twos, everyone hands in the air.",
                    "label": 0
                },
                {
                    "sent": "Please come on.",
                    "label": 0
                },
                {
                    "sent": "Put some guts into it.",
                    "label": 0
                },
                {
                    "sent": "Alright so.",
                    "label": 0
                },
                {
                    "sent": "Now on to the answer.",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I apologize, that was a trick question in a sense.",
                    "label": 0
                },
                {
                    "sent": "So in fact, none of those four sequences was truly random and I'll come to my point.",
                    "label": 0
                },
                {
                    "sent": "Let's consider each of the four in turn, so the first sequence was generated by rolling a D6, a 6 sided die, but then duplicating the I throw lifetimes.",
                    "label": 0
                },
                {
                    "sent": "So in a sense that is truly random, but that sequence would fail.",
                    "label": 0
                },
                {
                    "sent": "Almost all normal tests of randomness, because there is that structure in the sequence, so that's not really random.",
                    "label": 0
                },
                {
                    "sent": "OK, the second sequence is the 41st to 70th digits of \u03c0.",
                    "label": 0
                },
                {
                    "sent": "So now is your chance for glory.",
                    "label": 0
                },
                {
                    "sent": "Did anyone actually know those digits hands in the air if you did?",
                    "label": 0
                },
                {
                    "sent": "I'm kind of relieved that now and is the third sequence was generated by the Von Neumann method, and that's the standard kind of pseudorandom number generator.",
                    "label": 0
                },
                {
                    "sent": "So in a sense, that is random enough, but gotcha.",
                    "label": 1
                },
                {
                    "sent": "I've told you the seed the seed was 900 and 8344, so now you know the seed.",
                    "label": 0
                },
                {
                    "sent": "You can render each successive term in this sequence completely deterministically.",
                    "label": 0
                },
                {
                    "sent": "There's no uncertainty left.",
                    "label": 0
                },
                {
                    "sent": "It's not truly random now, which is kind of weird when you think about it, right?",
                    "label": 0
                },
                {
                    "sent": "So it was kind of random, but now I'm told you this additional bit of information is not random anymore.",
                    "label": 0
                },
                {
                    "sent": "So the final sequence was taken from a CD ROM published by George Massaglia.",
                    "label": 0
                },
                {
                    "sent": "Can't say his name correctly.",
                    "label": 0
                },
                {
                    "sent": "Probably in the 90s of random numbers, random binary digits, and again this sequence would pass most tests of randomness.",
                    "label": 0
                },
                {
                    "sent": "But now I've told you where I got it, and again, it's deterministic by virtue of just getting that CD ROM and looking up the sequence and finding out what the next digit was.",
                    "label": 0
                },
                {
                    "sent": "So the point I'm trying to make here is that.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here we go.",
                    "label": 0
                },
                {
                    "sent": "I've got three points.",
                    "label": 0
                },
                {
                    "sent": "So a random number is in some senses, at least for the purposes of numerics, epistemic.",
                    "label": 0
                },
                {
                    "sent": "Randomness is a statement about what we know.",
                    "label": 0
                },
                {
                    "sent": "If you know the random seed.",
                    "label": 0
                },
                {
                    "sent": "The pseudorandom number generator is no longer random.",
                    "label": 0
                },
                {
                    "sent": "So in a sense that makes sense for numerics, because computation should always be conditional on prior information.",
                    "label": 0
                },
                {
                    "sent": "As I've been trying to say.",
                    "label": 0
                },
                {
                    "sent": "But choosing the random seed as the particular bit of prior information that is most relevant to whether or not your numerics procedure succeeds seems pretty weird to me.",
                    "label": 0
                },
                {
                    "sent": "The second reason you might want to use random numbers is if you're trying to foil a malicious adversary right.",
                    "label": 0
                },
                {
                    "sent": "So if you're trying to play some game in which someone is out to get you, maybe it makes sense to choose a random number so they can never predict what you're going to do.",
                    "label": 0
                },
                {
                    "sent": "That actually, I think that's a very poor choice for numerics problem when trying to let me just finish this slide in doing optimization in doing integration, doing linear algebra.",
                    "label": 0
                },
                {
                    "sent": "There's not really someone out there who's trying to throw the worst possible objective function at me or the worst possible integrand out me.",
                    "label": 0
                },
                {
                    "sent": "Instead, I'm just trying to do the best I can on the type of functions I think are most likely to occur.",
                    "label": 0
                },
                {
                    "sent": "And the third reason, I think pseudorandom number generators and random number generators are a poor choice for numerics, is that thinking about a numerics problem in a decision theoretic way that is taking the evaluation, taking the action that minimizes our expected loss.",
                    "label": 0
                },
                {
                    "sent": "Assuming a random or random number generator is never going to give us the minimizer of that expected loss, the only expected loss function which is going to be minimized by a random number is 1, which is totally flat and hence is totally uninteresting.",
                    "label": 0
                },
                {
                    "sent": "Any model that is solved by a pseudorandom number generator is innocence uninteresting.",
                    "label": 0
                },
                {
                    "sent": "OK, so that was a fairly provocative slide.",
                    "label": 0
                },
                {
                    "sent": "Any questions?",
                    "label": 0
                },
                {
                    "sent": "What does epistemic alright?",
                    "label": 0
                },
                {
                    "sent": "Sorry for the purpose of this talk.",
                    "label": 0
                },
                {
                    "sent": "Take epistemic mean personal.",
                    "label": 0
                },
                {
                    "sent": "You know particular to a particular agent spoke to an agent.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "No other questions or points.",
                    "label": 0
                },
                {
                    "sent": "Great, everyone agrees with me.",
                    "label": 0
                },
                {
                    "sent": "That was easy.",
                    "label": 0
                },
                {
                    "sent": "Thank you very much.",
                    "label": 0
                },
                {
                    "sent": "No question here.",
                    "label": 0
                },
                {
                    "sent": "That means something out there is actually trying to be prudent and worst possible, yeah, but.",
                    "label": 0
                },
                {
                    "sent": "But I mean, if you have a dumb oversight, maybe trying to randomize them, tell you, and then I'm just saying this because I'm coming from from.",
                    "label": 0
                },
                {
                    "sent": "Proving that some rest of gastric learning or some some randomized learning can actually convert to that baby for their malicious oversized underwear.",
                    "label": 0
                },
                {
                    "sent": "For once we're done random adversary, they might work and it might be more robust, so I think that's also another view that could be useful for.",
                    "label": 0
                },
                {
                    "sent": "For making use of random numbers so you have a summer study that is, yeah.",
                    "label": 0
                },
                {
                    "sent": "Why are systematic regarding some way to carry lot with randomized control?",
                    "label": 0
                },
                {
                    "sent": "You can get game robots.",
                    "label": 0
                },
                {
                    "sent": "Yeah, OK, so I mean if there is an adversary, this slide concedes that maybe randomness makes sense.",
                    "label": 0
                },
                {
                    "sent": "Whether or not it's casting, maybe want to be unpredictable in a way that foils the plans of our adversary, but that what I'm saying is that when we use random numbers in numeric procedure, it's a bit odd, because there is no such adversary, right?",
                    "label": 0
                },
                {
                    "sent": "There's no one playing optimization against me, there is just a family of objective functions out there in the world that.",
                    "label": 0
                },
                {
                    "sent": "Need to try and do inference over.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now I've got I think half an hour left.",
                    "label": 0
                },
                {
                    "sent": "Is that right?",
                    "label": 0
                },
                {
                    "sent": "So the final part of the slide is in fact even more provocative innocence.",
                    "label": 0
                },
                {
                    "sent": "And what I'm going to say is that actually in machine learning normally what we want to do is not optimization.",
                    "label": 0
                },
                {
                    "sent": "In fact, normally what we should be doing is integration.",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Yeah, this is a contrived example, for which I apologize, but let's imagine we're trying to fit a 7th order polynomial to a function that is quadratic.",
                    "label": 0
                },
                {
                    "sent": "So in that case, as I'm sure you're all aware, if we were to optimize the coefficients of the 7th order polynomial, it's very easy to overfit.",
                    "label": 0
                },
                {
                    "sent": "Now.",
                    "label": 0
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "One way out of that problem is in fact do the correct Bayesian thing, which is instead of optimizing over those coefficients, averaging over those possible settings, each of them weighted by their likelihood in light of the data that's been received.",
                    "label": 0
                },
                {
                    "sent": "So here I've done a simple.",
                    "label": 0
                },
                {
                    "sent": "Gaussian prior on each of the coefficients of this quadratic and we get something that is already not just a better predictor that has a more honest representation of uncertainty of what that quadratic is doing between regions.",
                    "label": 0
                },
                {
                    "sent": "So the.",
                    "label": 0
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Reason that integration is the right thing to do comes back to a really simple rearrangement of Bayes rule.",
                    "label": 0
                },
                {
                    "sent": "So Bayes rule totally uncontroversial.",
                    "label": 0
                },
                {
                    "sent": "But usually when we want to use Bayes rule to, say, compute the posterior for a product and F star, that is the particular thing we're trying to predict for, like a particular class label, a particular image.",
                    "label": 0
                },
                {
                    "sent": "Conditional on a particular set of data or training set, whatever.",
                    "label": 0
                },
                {
                    "sent": "We then use Bayes rule in the following sense as just a ratio of the joint of F star.",
                    "label": 0
                },
                {
                    "sent": "Indeed, the product and the data divided by the evidence PFD.",
                    "label": 0
                },
                {
                    "sent": "Of course, this gets more complicated when there are parameters involved, so in the presence of parameters which influence not just the predictions we make, that is F star given D and Theta, but also the predictions made for the data.",
                    "label": 0
                },
                {
                    "sent": "If you like, which gives us the likelihood we end up having to do integrals over the possible settings of that parameter.",
                    "label": 0
                },
                {
                    "sent": "So I'm.",
                    "label": 0
                },
                {
                    "sent": "The particular setting for Bayes rule likely to keep in mind is the following.",
                    "label": 0
                },
                {
                    "sent": "That is, by this simple rearrangement of the joint of the product dance of the training data as the marginal over that product and the data in the parameters we integrate or marginalized over Theta.",
                    "label": 0
                },
                {
                    "sent": "By breaking it apart into these three conditional distributions, the prior over the parameters, the likelihood of the parameters and the predictions for that test point.",
                    "label": 0
                },
                {
                    "sent": "You can see that.",
                    "label": 0
                },
                {
                    "sent": "What we really want to do is an integral over the likelihood, that is, the probability of the data given the parameters.",
                    "label": 0
                },
                {
                    "sent": "Weighted by the prior of those parameters and by the different possible predictions we get given each of those parameters.",
                    "label": 0
                },
                {
                    "sent": "Is that OK?",
                    "label": 0
                },
                {
                    "sent": "All good.",
                    "label": 0
                }
            ]
        },
        "clip_55": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So I'm coming back to that example I showed you earlier and I'm trying to deal with the period high parameter of a periodic Gaussian process.",
                    "label": 0
                },
                {
                    "sent": "Many of the same difficulties of doing.",
                    "label": 0
                },
                {
                    "sent": "Optimization emerged when we try and do integration, so in particular trying to do the integral of this function is quite difficult for exactly the same reasons it was difficult to optimize.",
                    "label": 0
                },
                {
                    "sent": "It's got many different modes and it's difficult to explore.",
                    "label": 0
                }
            ]
        },
        "clip_56": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So instead what we have to do in practice is numerical integration, otherwise known as quadrature.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "I. I thought I might again just give a probabilistic numeric spin on quadrature, so take the simple example.",
                    "label": 0
                },
                {
                    "sent": "Of integrating the function X above sign, sorry - three X ^2 -- X ^2 again a super simple function representable in a small number of mathematical operations.",
                    "label": 0
                },
                {
                    "sent": "It's one that just looking at it.",
                    "label": 0
                },
                {
                    "sent": "You can say is going to have certain behaviors.",
                    "label": 0
                },
                {
                    "sent": "There's a trigonometric function in there, so it's going to have some sort of trigonometric behavior.",
                    "label": 0
                },
                {
                    "sent": "But nonetheless, despite all that that we know about it, we don't know what its integral is over the particular domain minus three to three.",
                    "label": 0
                },
                {
                    "sent": "At least.",
                    "label": 0
                },
                {
                    "sent": "I hope we don't know what it is because I've been giving this talk for many years now and I've been wrong all that time.",
                    "label": 0
                },
                {
                    "sent": "It would be very embarrassing.",
                    "label": 0
                },
                {
                    "sent": "So instead we treat that integrand that F of X as an unknown object, which we apply probabilistic modeling and can do the basic white thing.",
                    "label": 0
                },
                {
                    "sent": "But going a little bit further back before your new probabilistic numerics, what you might have done to deal with the numerical.",
                    "label": 0
                },
                {
                    "sent": "Integration problem like this is something like the trapezoid rule or the trapezium rule.",
                    "label": 1
                },
                {
                    "sent": "So all that trapezoid rule is doing is linear interpolation between your observations.",
                    "label": 0
                },
                {
                    "sent": "So we get a grid of evaluations of the integrand.",
                    "label": 1
                },
                {
                    "sent": "We just make that little red line interpolate in a linear way between each of them, and then we would use that linear interpolation to come up with the best guess for what the integral is.",
                    "label": 0
                }
            ]
        },
        "clip_57": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now I'm.",
                    "label": 0
                },
                {
                    "sent": "Thinking about its integration being the right thing to do, hopefully it's immediately obvious why optimization is the wrong thing to do.",
                    "label": 0
                },
                {
                    "sent": "That is firstly.",
                    "label": 0
                },
                {
                    "sent": "If we've.",
                    "label": 0
                },
                {
                    "sent": "Optimized this likelihood function and spent an enormous portion of our computational budget in evaluating that integrand at a wide range of different valuations.",
                    "label": 0
                },
                {
                    "sent": "It seems like a super weird thing to do to throw away all those valuable evaluations of the objective except for the single one that gave us the best likelihood.",
                    "label": 0
                },
                {
                    "sent": "So thinking about this in that probabilistic numeric way, that seems super wasteful, right?",
                    "label": 0
                },
                {
                    "sent": "All that effort.",
                    "label": 0
                },
                {
                    "sent": "All that computation spent is thrown in the bin, which is a bit weird, but the other weird thing about optimization is having reduced your information set to just that single evaluation.",
                    "label": 0
                },
                {
                    "sent": "Normally what we do is then approximate that integrand with a Dirac Delta function that is, in averaging over all the possible settings for this parameter, we're going to pretend that.",
                    "label": 0
                },
                {
                    "sent": "The only one that is of any significance whatsoever is the one that gave us the highest possible likelihoods.",
                    "label": 0
                },
                {
                    "sent": "So in a sense, we're doing integration by pretending that this likelihood is just a Dirac Delta function against which we can actually integrate, so you can see that that approximation is super strong and is very unreliable for any integrand that is not just multi multimodal, but even a little bit broad, right?",
                    "label": 0
                }
            ]
        },
        "clip_58": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Picking up on some of the ideas that Hugo was talking about yesterday, I think that's why there has been this kind of resurgence of interest in the deep learning community in optimization that has some sort of preference for, you know.",
                    "label": 0
                },
                {
                    "sent": "Brawds minima rather than really tight narrow minima.",
                    "label": 0
                },
                {
                    "sent": "That is, it's the broad minima that are ultimately going to be a better representation of the integrals.",
                    "label": 0
                },
                {
                    "sent": "We actually should be doing right.",
                    "label": 0
                },
                {
                    "sent": "So you're going to force yourself into this super limiting kind of scenario, in which you throw away all the evaluations except for a single one, and then pretend that your likelihood is a drag Delta.",
                    "label": 0
                },
                {
                    "sent": "You want to at least be picking the evaluation.",
                    "label": 0
                },
                {
                    "sent": "That is like this one on the right, which has most of the probability mass that big pink region in it rather than the one on the left.",
                    "label": 0
                },
                {
                    "sent": "So that's why I think you know the methods that prefer these kind of regions work better than that one.",
                    "label": 0
                },
                {
                    "sent": "But Even so, I think there's a lot more work to be done to actually push further towards what should be done anyway.",
                    "label": 0
                }
            ]
        },
        "clip_59": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so the probabilistic numeric approach to.",
                    "label": 0
                },
                {
                    "sent": "Quarter to symmetrical integration is actually very similar to the probabilistic numerical approach to global optimization.",
                    "label": 0
                },
                {
                    "sent": "So just as in global optimization is in Bayesian optimization, we modeled an objective function with the Gaussian process.",
                    "label": 0
                },
                {
                    "sent": "In Bayesian quadrature, we model an integrand.",
                    "label": 0
                },
                {
                    "sent": "The function over which we're trying to integrate with the Gaussian process.",
                    "label": 0
                },
                {
                    "sent": "So here an interesting aside, if you're doing Bayesian optimization to tune the hyperparameters of a machine learning model.",
                    "label": 0
                },
                {
                    "sent": "Within that Bayesian optimization process you've already built this Gaussian process.",
                    "label": 0
                },
                {
                    "sent": "You've already learned a model of the likelihood as a function of its parameters.",
                    "label": 1
                },
                {
                    "sent": "So really what I'm trying to say is having got that Gaussian process maybe should instead do the right thing, which is the integration problem rather than the slightly less right thing.",
                    "label": 0
                },
                {
                    "sent": "Which is optimization anyway.",
                    "label": 0
                },
                {
                    "sent": "So I'm.",
                    "label": 0
                },
                {
                    "sent": "With this",
                    "label": 0
                }
            ]
        },
        "clip_60": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Gaussian process we can do some pretty cool things and the reason for that harks back to another super useful property of the multivariate Gaussian.",
                    "label": 0
                },
                {
                    "sent": "So this property is that.",
                    "label": 0
                },
                {
                    "sent": "Let's say we've got some bivariate Gaussian, so a Gaussian over 2 variables X2 and X1.",
                    "label": 0
                },
                {
                    "sent": "Either of those variables.",
                    "label": 0
                },
                {
                    "sent": "So either X2 or X1 is joint Gaussian distributed with any affine transformation of those variables.",
                    "label": 0
                },
                {
                    "sent": "That is, regardless of the parameters AB&C that you pick X2 and indeed X one is going to be joint Gaussian with that F line transformation.",
                    "label": 0
                },
                {
                    "sent": "This is, in a sense, the most profound property of a Gaussian, at least as far as I'm concerned, and in a sense, that's why Gaussians come up so much in probabilistic numerics because.",
                    "label": 1
                },
                {
                    "sent": "Numerics has a long history of people trying to make algorithms as efficient as possible, right to work on the computers that people actually had even 50 years ago.",
                    "label": 0
                },
                {
                    "sent": "And what is the most efficient thing you can do?",
                    "label": 0
                },
                {
                    "sent": "Well, it's linear operations, so the kind of numerical procedures that people have come up with are those that innocence lend themselves to reinterpretation as Gaussian inference.",
                    "label": 0
                },
                {
                    "sent": "OK, so let.",
                    "label": 0
                }
            ]
        },
        "clip_61": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Come back to this example of integration.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "In Bayesian quadrature, we've modeled that Integrand X is a function of TC with a Gaussian process, and in fact the thing we're most interested in is a linear projection of that random variable.",
                    "label": 0
                },
                {
                    "sent": "The function, if you like the integrand, and it's the linear projection that gives us the integral.",
                    "label": 0
                },
                {
                    "sent": "So an integral if you like is just a generalization of a sum, so hopefully that seems reasonably intuitive, but the fact that it's linear allows us to use this beautiful property of the Gaussian.",
                    "label": 0
                },
                {
                    "sent": "In particular, if we've got a Gaussian process over the integrand.",
                    "label": 0
                },
                {
                    "sent": "That all the function values of the integrand are joint Gaussian with the integral.",
                    "label": 1
                },
                {
                    "sent": "So what does that?",
                    "label": 0
                }
            ]
        },
        "clip_62": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And in practice, it means that.",
                    "label": 0
                },
                {
                    "sent": "We can very quickly computes a posterior distribution for the integral conditioned on any set of evaluations of the function.",
                    "label": 0
                },
                {
                    "sent": "And here's the cartoon showing how that works in practice.",
                    "label": 0
                },
                {
                    "sent": "So imagine I'm trying to do the integral of L over its input X, and I've got 3 evaluations, about 3 crosses, and I modeled it with the Gaussian process, the green sausage.",
                    "label": 0
                },
                {
                    "sent": "So, given that Gaussian process, I can enclose form compute the Gaussian univariate Gaussian posterior for the integral which I've called zed.",
                    "label": 0
                },
                {
                    "sent": "And sort of give some intuition for what that distribution Fizz Ed tells us.",
                    "label": 0
                },
                {
                    "sent": "We're taking three draws from the Gaussian process.",
                    "label": 1
                },
                {
                    "sent": "Purple, blue and Reds and the purple, which has a large excursion upwards.",
                    "label": 0
                },
                {
                    "sent": "Gives you know it's integral is larger, but of course the fact that it's got a large excursion in it makes it less probable.",
                    "label": 0
                },
                {
                    "sent": "So it's somewhere up here on that distribution for the integral values Ed.",
                    "label": 0
                },
                {
                    "sent": "Draws which have a large excursion downwards are again quite improbable, but are associated with a value for the integral, which is much smaller than the mode of that gas in posterior distribution.",
                    "label": 0
                },
                {
                    "sent": "That's a super neat property.",
                    "label": 0
                },
                {
                    "sent": "Having produced this Gaussian process function almost for free, we get the Gaussian distribution for its integral.",
                    "label": 0
                },
                {
                    "sent": "Right, so now onto perhaps the most mathematically.",
                    "label": 0
                }
            ]
        },
        "clip_63": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Difficult bit of the whole talk.",
                    "label": 0
                },
                {
                    "sent": "Let's try and spend a little bit of time in this.",
                    "label": 0
                },
                {
                    "sent": "So I was telling you before about the trapezoid rule or the trapezium rule.",
                    "label": 0
                },
                {
                    "sent": "So let's return to that and return to the particular integrand.",
                    "label": 0
                },
                {
                    "sent": "The expert - 3X or squared minus X ^2.",
                    "label": 0
                },
                {
                    "sent": "And what I'm going to do is to imagine doing the trapezoid rule with a variable number of nodes of variable number of evaluations, where at each step of the process I'm going to throw away all the evaluations I had before and start with a new grid of evaluations which is slightly finer.",
                    "label": 0
                },
                {
                    "sent": "Does that make sense?",
                    "label": 0
                },
                {
                    "sent": "So at each iteration and get a slightly finer set?",
                    "label": 0
                },
                {
                    "sent": "And what I've done is on the top of the slide show the trapezoid rule in dark red line on the bottom of the slide on the left and the little red dots.",
                    "label": 0
                },
                {
                    "sent": "I've showed the empirical convergence of the trapezoid rule to the ground truth, where the ground truth here is actually just obtained by running the trapezoid rule for a really really long time.",
                    "label": 0
                },
                {
                    "sent": "So you can see that it does converge, which is reassuring.",
                    "label": 0
                },
                {
                    "sent": "We get these little up and down behaviors in it.",
                    "label": 0
                },
                {
                    "sent": "That's because of the fact that you know, as I increment from one grid to the next, I might throw away an evaluation that was actually quite useful in the previous increment.",
                    "label": 0
                },
                {
                    "sent": "It's not that important.",
                    "label": 0
                },
                {
                    "sent": "The thing I want to say about this is that it's order N to the minus two, which is pretty good.",
                    "label": 0
                },
                {
                    "sent": "But in a sense, that's bad because the predicted theoretical convergence for the trapezoid rule is 1 / N. So the theoretical convergence for the trapezoid rule is not well calibrated to the empirical convergence of the trapezoid rule.",
                    "label": 0
                },
                {
                    "sent": "So the other problem is that even if we knew the convergence was 1 / N ^2, we couldn't say exactly what our error was at any particular point in time, right?",
                    "label": 0
                },
                {
                    "sent": "Because we don't know what the constant is at the front or we know is that the error is going down.",
                    "label": 0
                },
                {
                    "sent": "This 1 / N ^2 we don't know what its absolute value is for any N. So that's the trapezoid rule.",
                    "label": 0
                },
                {
                    "sent": "Now I want to say something that I hope will blow your mind.",
                    "label": 0
                },
                {
                    "sent": "Which is that the trapezoid rule is in fact drumroll please.",
                    "label": 0
                },
                {
                    "sent": "Thank you very much, that's great feel very indulged.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                },
                {
                    "sent": "The trapezoid rule is actually Bayesian quadrature.",
                    "label": 0
                },
                {
                    "sent": "Which I find truly remarkable.",
                    "label": 0
                },
                {
                    "sent": "So remember that I was trying to tell you that what goes into probabilistic numerics.",
                    "label": 0
                },
                {
                    "sent": "This Gaussian process is dependent on the choice of covariance function.",
                    "label": 0
                },
                {
                    "sent": "And it just so happens that you can choose a covariance function.",
                    "label": 0
                },
                {
                    "sent": "It's the one's integrated vena process type of slide spline player.",
                    "label": 0
                },
                {
                    "sent": "Gives you a Gaussian process posterior mean, which is exactly the same as that kind of linear interpolation assumed by the trapezoidal rule.",
                    "label": 0
                },
                {
                    "sent": "So if you then do Bayesian quadrature with that particular covariance function, you get a posterior belief for the integral.",
                    "label": 0
                },
                {
                    "sent": "That is an estimate for the integral.",
                    "label": 0
                },
                {
                    "sent": "Which is identical to that you get from the trapezoid rule.",
                    "label": 0
                },
                {
                    "sent": "When I say identical, I mean that if you were to implement in code that particular formulation of Bayesian quadrature, you would do it with exactly the same code.",
                    "label": 0
                },
                {
                    "sent": "That you would use for the trapezoid rule.",
                    "label": 0
                },
                {
                    "sent": "That's an important point because it makes the point that Bayesian quadrature, probabilistic numerics in general need not be computationally expensive because the trapezoid rule is super cheap, and in fact if you get the choice of covariance function right, you can do these numerics procedures with exactly the same cost as their kind of traditional alternatives.",
                    "label": 0
                },
                {
                    "sent": "And if you like, you can put a little bit of overhead on top to get the uncertainty out.",
                    "label": 0
                },
                {
                    "sent": "Of that probabilistic numerics procedure to supplement just the best guess.",
                    "label": 1
                },
                {
                    "sent": "So let's turn to that question at the back.",
                    "label": 0
                },
                {
                    "sent": "Is there some optionality argument for why?",
                    "label": 0
                },
                {
                    "sent": "And so in fact, when we're trying to match the numerics procedure to a covariance function there, there are just particular covariance functions which are identical.",
                    "label": 0
                },
                {
                    "sent": "It's not that you even need to define a notion of similarity.",
                    "label": 0
                },
                {
                    "sent": "You can get something that gives exactly the same behavior regardless of the notion of similarity, but.",
                    "label": 0
                },
                {
                    "sent": "So that's a super interesting question.",
                    "label": 0
                },
                {
                    "sent": "I'll turn to that in just a second you give me to commit me to wait.",
                    "label": 0
                },
                {
                    "sent": "So anyway, what I was just about to say is that the other thing that probabilistic numerics gives us beyond traditional numerics is a much more coherent way of thinking about error about uncertainty.",
                    "label": 0
                },
                {
                    "sent": "So as I said, that theoretical error bounds for the trapezoid rule are innocence wrong for this function there 1 / N when the empirical covariance is 1 / N ^2.",
                    "label": 0
                },
                {
                    "sent": "And they don't even tell us what the actual error is, only what the rate is.",
                    "label": 0
                },
                {
                    "sent": "But if you do Bayesian quadrature with that particular covariance function, you get not just.",
                    "label": 0
                },
                {
                    "sent": "The estimate for the entry you also get this full posterior distribution.",
                    "label": 0
                },
                {
                    "sent": "And the other thing I'm showing in the bottom slide here and the little red lines.",
                    "label": 0
                },
                {
                    "sent": "Is the.",
                    "label": 0
                },
                {
                    "sent": "Posterior standard deviation of that Gaussian posterior.",
                    "label": 0
                },
                {
                    "sent": "As a function of the number of valuations, it turns out you can actually evaluate it in closed form and you'll see that while it has the same problematic convergence behavior as trapezoid rule, which is in a sense not surprising because this particular covariance function is just re implemented that trapezoid rule, it does have the really nice property now that we can pick which the best of those red lines actually is, because now the particular posterior distribution that's relevant to the function at hand.",
                    "label": 0
                },
                {
                    "sent": "Is specified by the hyperparameters of that covariance function, and we can learn those hyperparameters.",
                    "label": 0
                },
                {
                    "sent": "That's what we do every day in machine learning.",
                    "label": 0
                },
                {
                    "sent": "Given the particular set of evaluations with obtained, we can actually infer what that setting the high parameter should be in there by pick the convergence rate for the error, which is best suited to the function at hand.",
                    "label": 0
                },
                {
                    "sent": "OK, so now we want to return to the question that was asked before, which is why should we use the trapezoid rule against perhaps another alternative and those other alternatives within a Bayesian quadrature formalism?",
                    "label": 0
                },
                {
                    "sent": "I just different covariance functions.",
                    "label": 0
                },
                {
                    "sent": "And looking at this integrand.",
                    "label": 0
                },
                {
                    "sent": "I note that not only is it smooth, it's infinitely differentiable.",
                    "label": 0
                },
                {
                    "sent": "It's super smooth, and if there's one thing that Gaussian processes are good at capturing its smoothness.",
                    "label": 0
                },
                {
                    "sent": "So the standard the most ubiquitous covariance function within Gaussian processes is known by many names, including the exponentiated quadratic, the squared exponential, the RBF, the normal, all of them.",
                    "label": 0
                },
                {
                    "sent": "In code this property that the function is infinitely differentiable.",
                    "label": 0
                },
                {
                    "sent": "So an obvious thing to do is to use that covariance function for this integrand, and that's what we've got on the right hand side of the plot.",
                    "label": 0
                },
                {
                    "sent": "Let's try and give some intuition for.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so the orange lines here give the posterior mean of the Gaussian process fitted to those evaluations.",
                    "label": 0
                },
                {
                    "sent": "The orange sighting gives the posterior error estimate if you like.",
                    "label": 0
                },
                {
                    "sent": "But we've also shown on either the left or the right draws from the two different posteriors as the kind of slightly lighter dark lines, and hopefully that makes it clear why the squared exponential on the riot is a better choice than that on the left.",
                    "label": 0
                },
                {
                    "sent": "That is why the once integrated Vina process is continuous, it's not differentiable even once.",
                    "label": 0
                },
                {
                    "sent": "So if you take draws from it, you get things like the jagged edge Gray lines there in the jagged red lines which are very unrepresentative.",
                    "label": 0
                },
                {
                    "sent": "That integrand on the right we get draws which are much more representative.",
                    "label": 0
                },
                {
                    "sent": "So then as you will have seen in the bottom right.",
                    "label": 0
                },
                {
                    "sent": "If we run basic works are forwards.",
                    "label": 0
                },
                {
                    "sent": "From that point we get way better behavior.",
                    "label": 0
                },
                {
                    "sent": "We get convergence, which is not only faster.",
                    "label": 0
                },
                {
                    "sent": "And when I say faster.",
                    "label": 0
                },
                {
                    "sent": "We can actually prove theoretically this is supra exponential in N. Say that again, Supra exponential not just exponential like exponential of exponential NN, which is pretty awesome, but we also get error estimates that it perfectly calibrated.",
                    "label": 0
                },
                {
                    "sent": "To the actual error that we get, which is really nice, so you know really problematic numerics gives this way of thinking about numeric problems, which allows you to do way way better by incorporating into your numerics procedure.",
                    "label": 0
                },
                {
                    "sent": "What you really do know.",
                    "label": 0
                },
                {
                    "sent": "So I'm now the final quiz for this.",
                    "label": 0
                }
            ]
        },
        "clip_64": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Talk.",
                    "label": 0
                },
                {
                    "sent": "What is the convergence rate of Monte Carlo?",
                    "label": 0
                },
                {
                    "sent": "Many people know this, so I don't want to give too long to think about it, but there are four options.",
                    "label": 0
                },
                {
                    "sent": "Explains in X minus and minus 1/2.",
                    "label": 0
                },
                {
                    "sent": "Into minus one into the minus 1/2.",
                    "label": 0
                },
                {
                    "sent": "Don't Google, it's OK so 321.",
                    "label": 0
                },
                {
                    "sent": "Please hands in the air.",
                    "label": 0
                },
                {
                    "sent": "What do you think the right answer is?",
                    "label": 0
                },
                {
                    "sent": "Have a stab.",
                    "label": 0
                },
                {
                    "sent": "Come on 321 hands in the air what do you think it is?",
                    "label": 0
                },
                {
                    "sent": "All hands up please come on.",
                    "label": 0
                },
                {
                    "sent": "Haven't had a guess.",
                    "label": 0
                },
                {
                    "sent": "Have a guess.",
                    "label": 0
                },
                {
                    "sent": "I'm still seeing not that many hands up.",
                    "label": 0
                },
                {
                    "sent": "OK, so maybe that's as good as we're going to get, but reassuringly most people did in fact pick the right answer, which was N.",
                    "label": 0
                }
            ]
        },
        "clip_65": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "3 -- 1/2 well done to those of you who got it right.",
                    "label": 0
                },
                {
                    "sent": "And I just wanted to comment on that, because remember the convergence rate for the trapezoid rule, which is in a sense the dumbest thing you could do for numerical integration.",
                    "label": 0
                },
                {
                    "sent": "It's sometimes taught in high school, has a convergence rate, which is 1 / N. Monte Carlo, which is kind of a state of the arts in Bayesian inference, is way worse than that.",
                    "label": 0
                },
                {
                    "sent": "It's one over square root in.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "The reasons for why it's so bad really kind of eloquently put in this paper from Tony O'hagan from 1988 with a fantastic title of Monte Carlo is fundamentally unsound.",
                    "label": 1
                },
                {
                    "sent": "So I'm you know this is not a stats talk, so I won't go any deeper into that, but I do recommend you read that paper if you want to learn why you should never use Monte Carlo.",
                    "label": 0
                },
                {
                    "sent": "But in short, the reason for it is kind of easy to grasp, which is that the S.",
                    "label": 0
                }
            ]
        },
        "clip_66": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Meant that one of the reasons for it is that one color constructs as its estimate for the integral.",
                    "label": 0
                },
                {
                    "sent": "The unweighted average of all the function evaluations, so it just takes all the evaluations of the integrand and add them up and divide by N. Which means that the evaluation that has the highest value for the likelihood, for instance, has no better weight than the lowest value for the likelihoods.",
                    "label": 0
                },
                {
                    "sent": "It's also not capturing the fact that if you take an evaluation, that's right next to another one, which of course you might do in Monte Carlo because its valuations are chosen stochastically, which just to remind you, I think is a really dumb idea.",
                    "label": 0
                },
                {
                    "sent": "So if you've got 2 evaluations which chosen right next to each other, they both got exactly the same weight as an evaluation very far away and very informative.",
                    "label": 0
                },
                {
                    "sent": "That is, even though these evaluations are redundant, they're treated exactly the same as any other evaluations.",
                    "label": 0
                },
                {
                    "sent": "So if you actually run Monte Carlo on that same problem, the X - three X ^2 -- X ^2 you get terrible formance, which is unsurprising.",
                    "label": 0
                },
                {
                    "sent": "I wanted to say one thing.",
                    "label": 0
                },
                {
                    "sent": "I was a bit unfair to the trapezoid rule on the previous slide.",
                    "label": 0
                },
                {
                    "sent": "In fact there is theory which establishes why you get 1 / N ^2 for that type of integrand.",
                    "label": 0
                },
                {
                    "sent": "Which is that.",
                    "label": 0
                },
                {
                    "sent": "In fact, if the integrand is differentiable, you can show that it's 1 / N ^2.",
                    "label": 0
                },
                {
                    "sent": "But anyway, that's neither here nor there.",
                    "label": 0
                }
            ]
        },
        "clip_67": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so I think I've got just a couple minutes to conclude and I wanted to just round out this story for integration.",
                    "label": 0
                },
                {
                    "sent": "So far I've just talked about the probabilistic modeling component of integration that is basing quadrotor.",
                    "label": 0
                },
                {
                    "sent": "But of course, the other component of probabilistic numerics is the decision theory, and for basing quadrature that decision theory is relevant to selecting which integrante value to evaluate next.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "The way we do that, as you might guess, is fairly similar to Bayesian optimization.",
                    "label": 0
                },
                {
                    "sent": "We define a loss function for the case of Bayesian quadrature.",
                    "label": 0
                },
                {
                    "sent": "That loss function encodes how much uncertainty there is in the article, which is quite natural.",
                    "label": 0
                },
                {
                    "sent": "And then we crank the handle of expected loss to pick the successive evaluations of the integrand that are most useful to us.",
                    "label": 0
                },
                {
                    "sent": "And here's a cartoon of how that works in practice.",
                    "label": 0
                },
                {
                    "sent": "It's kind of a complicated plots, so each of these successive rows represents the expected loss after a different number of samples have been chosen, so it begin with, we've got five samples.",
                    "label": 0
                },
                {
                    "sent": "Here's our expected loss in green.",
                    "label": 0
                },
                {
                    "sent": "And you can see the little red dot is telling us we want to evaluate just between these two samples.",
                    "label": 0
                },
                {
                    "sent": "That ruined brand is at the top of the slide and you can see between those two samples is on the upward slope of this big peek out to the right.",
                    "label": 0
                },
                {
                    "sent": "So this was a pretty sensible choice.",
                    "label": 0
                },
                {
                    "sent": "Having evaluated the integrand there.",
                    "label": 0
                },
                {
                    "sent": "And having discovered that this big mode out to the right exists, we then choose another kind of exploitive evaluation to resolve it a little bit better.",
                    "label": 0
                },
                {
                    "sent": "Keep doing that until we've worked out everything we need to know about this particular mode, in which case we switch to evaluating further out to the left, and soon enough we capture this mode as well, so we get exactly the same kind of emergent behavior that we saw for Bayesian optimization through a really simple choice of loss function by simply choosing a loss that is, the uncertainty in the interval.",
                    "label": 0
                },
                {
                    "sent": "Is that a question?",
                    "label": 0
                },
                {
                    "sent": "With great pleasure decision theory which came with expected loss here, so why would be that we we could stay in base in like probabilistic domain as well in decision making, like for example here for selecting sample people?",
                    "label": 0
                },
                {
                    "sent": "Realistic actual.",
                    "label": 0
                },
                {
                    "sent": "Why should we come with these expected loss with these deterministic?",
                    "label": 0
                },
                {
                    "sent": "So the question was, isn't using expected loss innocence the sacrifice of the Bayesian approach?",
                    "label": 0
                },
                {
                    "sent": "And I would argue absolutely not.",
                    "label": 0
                },
                {
                    "sent": "So I think what you're arguing is that given just a probabilistic model, we could do selection probabilistic Lee, which I think you mean by which I think you mean stochastically.",
                    "label": 0
                },
                {
                    "sent": "That is, I think you're thinking about generating pseudorandom numbers from saying integrand to represent the evaluations we should take sequentially.",
                    "label": 0
                },
                {
                    "sent": "Is that what?",
                    "label": 0
                },
                {
                    "sent": "You're ugly, so actually the point I was trying to make earlier in the talk is that that's a really bad idea.",
                    "label": 0
                },
                {
                    "sent": "In fact, you know stochastically is not the right approach.",
                    "label": 0
                },
                {
                    "sent": "For making decisions when there's actually something we want to achieve, like resolving an integral as well as we can in light of a fixed computational budget, decision theory, which is really a natural partner to probability theory given a particular set of costs is the right thing to do if we're being stochastic.",
                    "label": 0
                },
                {
                    "sent": "We're leaving value on the table because in a stochastic setting there's always going to be some probability of, for instance, going back and evaluating a function added.",
                    "label": 0
                },
                {
                    "sent": "Exactly or pretty close to the same location at which with evaluated in the past, which is always going to be wasteful.",
                    "label": 0
                },
                {
                    "sent": "A stochastic approach to numerics is always going to leave value on the table, and we can pick up that value by being more decision theoretic.",
                    "label": 0
                },
                {
                    "sent": "Add.",
                    "label": 0
                },
                {
                    "sent": "Question.",
                    "label": 0
                },
                {
                    "sent": "Welcome people.",
                    "label": 0
                },
                {
                    "sent": "Saying basically that if you are automating everything and we must choose one, and if you want to prove that once you get cremated with that and then you are losing information.",
                    "label": 0
                },
                {
                    "sent": "Yes, I mean this is the whole framework.",
                    "label": 0
                },
                {
                    "sent": "Of course it is.",
                    "label": 0
                },
                {
                    "sent": "The whole idea of going racialization is get into instead of just having one and then trying to improve that.",
                    "label": 0
                },
                {
                    "sent": "Like yeah, yeah.",
                    "label": 0
                },
                {
                    "sent": "This is related to the cause of sample.",
                    "label": 0
                },
                {
                    "sent": "We can measure values in function evaluation, so we just need to have been doing that for a long time.",
                    "label": 0
                },
                {
                    "sent": "But then suppose we want to do this with a hole deep network with, so some of parameters yes and then for representative visits are problem here with the space complexity in the center representing the distribution of functions is far more expensive than just having one.",
                    "label": 0
                },
                {
                    "sent": "So if you do have one.",
                    "label": 0
                },
                {
                    "sent": "So we can.",
                    "label": 0
                },
                {
                    "sent": "We can move around and this is a very bad idea, but we can do that and you can do that fast enough that making non compatible with representing a family of function and doing this update here.",
                    "label": 0
                },
                {
                    "sent": "So I mean I understand.",
                    "label": 0
                },
                {
                    "sent": "OK so I think the question was is this a sensible approach given that you know for your purposes you actually wanted optimization in a really high dimensional spaces that originally so to that I would say the kind of Bayesian optimization I've told you about so far.",
                    "label": 0
                },
                {
                    "sent": "Not be the right choice because as I say, we don't yet have the tools for standard Gaussian processes to scalloping dimensions.",
                    "label": 0
                },
                {
                    "sent": "But there's a whole another branch of probabilistic numerics which focuses not on global optimization, but instead local optimization, and even on reinterpretations of like SGD, which does scale up exactly as well as any other type of local optimization.",
                    "label": 0
                },
                {
                    "sent": "And for that I would point you to the recent work from Phillip Annequin tuning in.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so there are approaches probabilistic numerical nature which can be used in that setting as well.",
                    "label": 0
                },
                {
                    "sent": "I think there's a question over here before.",
                    "label": 0
                },
                {
                    "sent": "Simple question point of this is to estimate.",
                    "label": 0
                },
                {
                    "sent": "Shadow prices for data.",
                    "label": 0
                },
                {
                    "sent": "If you have a big constraint that is at that point, then to estimate the marginal value of a bit of data.",
                    "label": 0
                },
                {
                    "sent": "Yeah, precisely.",
                    "label": 0
                },
                {
                    "sent": "Back to where you are, I think you are using this process for evaluating hyperparameters with respect to control.",
                    "label": 0
                },
                {
                    "sent": "The likelihood is that you get the same result of finding a wider area if your cost function was not sampling function within the expected value, but some sort of notion of risk are or mini Max or something like that for that.",
                    "label": 0
                },
                {
                    "sent": "OK, so I've just realized we're out of time.",
                    "label": 0
                },
                {
                    "sent": "I answer this last question, then very quickly conclude if that's OK so.",
                    "label": 0
                },
                {
                    "sent": "The question was, what about other notions of loss, mini Max?",
                    "label": 0
                },
                {
                    "sent": "For instance, in a sense I'm relatively agnostic to the loss function that's chosen here.",
                    "label": 0
                },
                {
                    "sent": "We chose one for integration that I think that makes sense, which is reducing the variance.",
                    "label": 0
                },
                {
                    "sent": "But of course probability Max is open to any other choice of loss function.",
                    "label": 0
                },
                {
                    "sent": "Max might be one of them, so thanks for your patience.",
                    "label": 0
                },
                {
                    "sent": "If I'll just if you just let me very briefly conclude one point on this is that if your decision theoretically select the samples.",
                    "label": 0
                }
            ]
        },
        "clip_68": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You do way way better and by way better.",
                    "label": 0
                },
                {
                    "sent": "I mean in Wall Clock time, not just in the number of valuations.",
                    "label": 0
                }
            ]
        },
        "clip_69": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But then.",
                    "label": 0
                }
            ]
        },
        "clip_70": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To conclude, I just wanted to remind.",
                    "label": 0
                }
            ]
        },
        "clip_71": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You that there is this website problem.org it's got all the up-to-date material on all the branches, probabilistic numerics, not just global optimization and integration really do check it out and if you've got any work you've done yourself which might fit into this realm, let us know.",
                    "label": 0
                },
                {
                    "sent": "Send me an email listed up on the site.",
                    "label": 0
                },
                {
                    "sent": "So thanks very much for attention.",
                    "label": 0
                },
                {
                    "sent": "Very happy to take questions offline.",
                    "label": 0
                }
            ]
        }
    }
}