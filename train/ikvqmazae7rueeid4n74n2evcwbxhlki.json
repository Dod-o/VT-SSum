{
    "id": "ikvqmazae7rueeid4n74n2evcwbxhlki",
    "title": "HiBISCuS: Hypergraph-Based Source Selection for SPARQL Endpoint Federation",
    "info": {
        "author": [
            "Muhammad Saleem, Agile Knowledge Engineering and Semantic Web (AKSW), University of Leipzig"
        ],
        "published": "July 30, 2014",
        "recorded": "May 2014",
        "category": [
            "Top->Computer Science->Semantic Web",
            "Top->Computer Science->Big Data"
        ]
    },
    "url": "http://videolectures.net/eswc2014_saleem_endpoint_federation/",
    "segmentation": [
        [
            "Hello everybody, my my name is Mohammed Salim, from a CSW University of logic in Germany and today I'm going to present hibiscus hypergraph based source selection for Sparkle Endpoint Federation.",
            "So first I would like to ask."
        ],
        [
            "Learn the whole idea, how the Federation Sparkle Query Federation works.",
            "So this is the slide for that.",
            "So given a sparkle query and we have a Sparkle engine which is shown in this box, this is a Federated engine.",
            "So given a sparkle query from user what the Federation engine do is the first thing is that it powers the query, so parsing means this is all just want to make it clear this is a very general diagram, so the parsing means get individual triple patterns in the query.",
            "So once you get that and then the second step is the source selection.",
            "Which means that for each individual triple pattern you need to identify what are the capable sources.",
            "So by sources I mean here is sparkle and points.",
            "So what are the sparkle back end points that can answer that specific triple pattern affect query?",
            "And once we have this source selection then the next step is the federator and optimizer step.",
            "So here we make small sub queries of the original query and then once we get the small sub queries an get some execution plan.",
            "Then we need to.",
            "We need to execute this query to the corresponding sparkle and points and then once we send these queries to the corresponding sparkle and points we get the results back from each subquery and then once we get this results back we need to integrate or merge them the results so."
        ],
        [
            "So here we get merging results and this is the final results which we got for each for the given sparkle query and this is."
        ],
        [
            "Is then forwarded to the the user.",
            "So this was a very general architecture.",
            "How the Sparkle Endpoint Federation works."
        ],
        [
            "So where is our contribution?",
            "It's on the specific part of this Federated Sparkle query processing, which is source selection.",
            "So how efficiently we can identify the set of capable sources or sparkle and points against the individual triple pattern of inquiry?"
        ],
        [
            "So here is the motivation given a feedback."
        ],
        [
            "Great if it benches, benchmark for Federated SPARQL query processing which is based on the real data set.",
            "So we collected an example query which is L. D3.",
            "The link data query #3 invested that return for all US President Dear Party membership in the news pages about them.",
            "So in this query we have five triple patterns from TP12TP2.",
            "In all, in the Fed bench we have 9 datasets or sparkle and points given below and let me name it from S1 to S nine source, one source, two to source 9.",
            "And let's suppose we have a source selection algorithm in the middle.",
            "So I want to remind you again what the source selection algorithm will do is to identify the capable sources against individual triple patterns so.",
            "Let's suppose we have a first triple pattern which is RDF type and we send a sparkle ask query to all of the nine sources in only DB pedia, which is more case S1 is capable of answering this triple pattern and then the same.",
            "We send the second triple pattern to each of the units particle endpoint in ask using the ASK where we can get that OK. D Pedia is the only one that can answer this.",
            "Cool pattern and again DB pedia and then in the 4th one is the New York Times which is capable of until now.",
            "The fifth triple pattern is very common one all same is so if you submit to, you know sparkle as query to majority of the Europe sparkle endpoints so many of them.",
            "Will you not say yes I can answer this triple pattern so here in case of Fed bench there are eight sources that can answer this triple pattern.",
            "So now if I sum of the total sources against individual triple patterns or one for the 4th first four triple pattern and then eight for the 5th one, so totalled triple pattern voice source sources selected is 12 in that case, and how many Spark Alaska request we used because we have five people pattern in which we sent each of the triple pattern to each of the data source.",
            "So 9 multiply by 5 is equal to 45.",
            "Sparkle, ask where these are used.",
            "But here is the problem.",
            "In sort selection, even we use, you know one of the best methods like using Sparkle, ask queries you can get the real things, But here is again a problem.",
            "We overestimated some sources.",
            "And I will explain how we overestimated these sources.",
            "Now if we look at the triple pattern #4 and triple #5 here, there is a joint between these two right?",
            "So which means whatever results we get for the old, same as we need to make a join with the Navy Yard Time Topic page.",
            "So this result will be presented, you know to the final user.",
            "So clearly we can see that if whatever results we get from the rest of the seven sources for all semis, but when we make a join with the New York Time data set, so the final results will only come from the New York time.",
            "So which means that the even we use sparkle ask queries, but we overestimated seven sources for these two triple patterns because the final answers are only we received the final answer only from New York Times, and the rest are all you know.",
            "We need to exclude it, so here is this problem.",
            "Actually, all of these sources this from S1S2 S these are not relevant.",
            "Because of this you know join.",
            "And only New York time, which is source #4, is relevant for that.",
            "So instead of selecting the eight sources for the last triple pattern, the best way is to only select you know New York time for the last people pattern, and still you will you achieve the hundred person recall.",
            "So this is the problem.",
            "Actually, the optimal number of triple pattern wise sources select should be 5, but we use sparkle, ask queries and still be selected.",
            "12 number of sparkle and points.",
            "Now what's the problem?",
            "With this?",
            "We overestimated the sources.",
            "So what is the problem with this overestimation?"
        ],
        [
            "The problem is that since we selected, you know extra sources there, which means that resources are wasted in.",
            "Of course, query runtime will be increased because you need to query something which will not produce any resulting to the final you know result set.",
            "So it's just a waste of, you know network traffic as well.",
            "So this is the problem.",
            "Now the question is this, how do we perform this?",
            "Join aware triple pattern voice or selection in a time efficient way.",
            "So by time efficient way I mean that in the previous example I use 4045 Sparkle ask queries as well.",
            "So of course each query will take some time as well and then the rest of the you know because of this overestimation, the network traffic in the extra time will be also added into the final query.",
            "So this is the problem.",
            "How I can deal with this so that I use minimum number of sparkle as an?",
            "I still, you know, achieve you know close to optimal source selection.",
            "So for this way pro."
        ],
        [
            "Suppose he biscus, which is a hypergraph based source selection approach.",
            "What does Hibiscus do is so the first thing he biscuits do is to to model each of the sparkle query is a hypergraph.",
            "Now I will explain how we need how we model this since here subject, predicate and object in each ripple pattern.",
            "So here for each of these subject predicate an object we have a node.",
            "So this president and then I have we have another node and then we have 1/3 node.",
            "So this represents the subject.",
            "This represent the predicate in this represent the object.",
            "Now, which one is the hyper edge?",
            "So the last two becomes the tail of the hyper edge in the top, the first one, the subject becomes the head of the hyperedge, so this is actually hyperedge.",
            "So we do the same for the second triple pattern.",
            "President, DB Pedia, nationality and baby.",
            "United States and then for the third one.",
            "We start from DB pedia this and so the 4th one is start from X and then.",
            "Topic page and then the final one is X all same as president.",
            "So now we come up.",
            "You'll be model.",
            "The Sparkle Query is a hypergraph.",
            "So here I would like to mention three things this blue and represent the start node astar node is 1 in which which has only outgoing hyper edges but no incoming.",
            "So here you can see only outgoing hyper edges, and there's green on is the path.",
            "Note.",
            "So sorry, hybrid mode, hybrid node is the one which has you know incoming edges as well and outgoing edges as well.",
            "So it has three outgoing hyperedges anwan incoming.",
            "A hyperedge so this president became the hybrid node.",
            "So I will explain how and where we will use this.",
            "Notice you know this representation, the star in hybrid and this is the simple one is the rest of the node."
        ],
        [
            "So Hibiscuses make use of the data summaries to perform join aware people, pattern, voice or selection.",
            "In short, what our summary contains, we get for each of the data source we get the set of distinct predicate in their data source.",
            "So like here, let's suppose DB Pedia is our source.",
            "So we get the set of distance predicate like DB pedia parties.",
            "One predicate RDF type is another.",
            "And DB Pedia Postal code is another.",
            "So we get all of the distinct predicate.",
            "And for each district predicate we need to get the subject authority, which means that for this predicate we need to get all of the subject you are I and then make then get the distinct you know authorities from the subject you are I so it store here like DB Pedia, Orgs.",
            "And then we get the object authority as well.",
            "For each of these predicate, so later I will show how and where we will use this information.",
            "So this is the first thing that that's about the data summaries of each data source.",
            "Now we come up to the triple pattern."
        ],
        [
            "Ice or selection.",
            "How we will do the triple pattern by source selection.",
            "So here is our first ripple pattern, president RDF type in DB pedia presidents.",
            "So if you look at our index we can see that RDF type is recorded there and we have the set of you know object UI as well.",
            "So using these two information using our index we can say that only DB PEDIA is capable of answering this.",
            "I would like to mention here what is our goal here since like a hyper graph is built here but there are no labels to the hyper edges, so we need to label this in these levels.",
            "Are the capable sources right?",
            "So here first we labeled OK this this hyper edge should be labeled with DB pedia.",
            "Using our data summary and then the second one is again DB PEDIA and 3rd one is again DB pedia and 4th one is New York time.",
            "But we come up with the same problem that I explain.",
            "If we look at our index here, we can see that the same 8 number of sources are selected again.",
            "So this was our first step of the source selection using our index find you know the set of triple patterns.",
            "Find a set of sources related to each triple pattern.",
            "But here again we overestimated.",
            "So then we come up to the second step of our source selection, in which we need to prune.",
            "By pruning, I means we need to, you know, remove the the sources that are not relevant to the final result sets.",
            "So we are now going to the second step and how we need to.",
            "To prove this, how we can skip some of the sources from here?",
            "So here's what we get.",
            "Our algorithms start, you know, work on each note which are either star node, are richer.",
            "Either hybrid node are here.",
            "There is no part note but there is what other partners as well.",
            "So partner has one incoming edge in one outgoing edge.",
            "But in this case we don't have any part node so our algorithm start from this node and then get all of the subject authority for this for this outgoing.",
            "Age so here we got the New York time and then the for the this one we get this subject authorities right and for each of the hybrid node we need to get subject authority for outgoing edges and we need to get object authority for the incoming edges.",
            "So that's why for this green one we have this subject authority.",
            "In this we have object authority.",
            "Once we get this from the our index then the next step is very simple.",
            "We just need to make a you know, intersection of these authorities so the blue authorities here is then we are taipan.",
            "Here is only present New York time is present here.",
            "So if we make intersection of this so this source is this.",
            "This is all our will be skipped because these tools only make the intersection with each other.",
            "So for this hybrid hybrid H."
        ],
        [
            "We will only select New York Times using the intersections of the authorities.",
            "Now we will.",
            "Now since this is changed now because only need your time is selected, so we need to only select New York time here as well.",
            "So we prune the rest of the sources and it becomes ordinary water.",
            "Now we come to the hybrid.",
            "So here we need to again make the intersection of the authorities.",
            "So here's the period.. And here is the Navy Yard time.",
            "So if we come up, the intersection is here.",
            "The DB pedia.",
            "So it means that New York time is skipped from here.",
            "So here is the final.",
            "Answer So we label each of the edges with Debbie.",
            "E. E pedia NVR tab NVR time.",
            "Which means that the set of total triple pattern wise sources selected is 5 in all of this operation.",
            "We don't need any sparkle.",
            "You know ask very weak and completely use our index to you know do perform the source selection."
        ],
        [
            "So now I come up to the experimental."
        ],
        [
            "Set up what we use.",
            "We use a Fed bench for our evaluation while we use FedEx because it's based on real datasets collected from, you know real and it has a real queries in which shows the typical request on that is not synthetic data and it's like the real thing and we use all of the 25 queries to be more complete and what we did, we extended these systems.",
            "These three system, FedEx, Dark and splendid.",
            "With a hibiscus by extension means we only replace the source selection part.",
            "And then the rest of the query execution time remains the same.",
            "So so once we extended this with Hibiscus and we also included in app Set version twelve 2013 with Hibiscus without Hibiscus extension but so."
        ],
        [
            "Here are the matrices that we used for our comparison.",
            "We calculated the index generation time, the index size and total number of triple pattern by sources selected.",
            "Total number of US request Usan source selection time in the query execution."
        ],
        [
            "Damn.",
            "So here is the result for the generation index generation term and compression ratio.",
            "So here Hibiscuses second to the in app set an address it is and then the compression ratio which is given 1 minus index size by total data dump size is quite high 99.99.",
            "So here is the."
        ],
        [
            "The result of the source selection.",
            "So in in result of the source selection.",
            "Here this represent the number of total triple pattern by sources selected.",
            "This is the number of ASK request use and this is the source selection time in milliseconds.",
            "So you can clearly see Hibiscus outperform all of the state of the art systems in terms of triple pattern by sources selected in terms of number of ASK request to use."
        ],
        [
            "So here is the another result for the evaluation.",
            "That's for the query execution time.",
            "So what we did, we compare each of the extension with the original system.",
            "So here is the result for the FedEx extension with Hibiscus and we improved 2520 queries out of 25 and the net performance improvement was 24.66 and here is the result for SP."
        ],
        [
            "When did we improved splendid in all of the 25 queries with the net performance improvement of 82?"
        ],
        [
            "Person, and here is the extension for here.",
            "The result for the dark extension, so we got improvement of 21 queries because some of the queries are not supported by dark.",
            "And net performance improvement was 92.22."
        ],
        [
            "As I mentioned that we didn't extend the in app set, but we compared our best Journal system with the BISCUS and we can see that like we have improvement, which is our best one is the hibiscus plus splendid.",
            "So here we get an improvement in 25 out of 24 out of 24 queries with Annette performance improvement of 98."
        ],
        [
            "Saint so conclusion.",
            "An overestimation of triple pattern.",
            "Why source selection can be expensive?",
            "Becausw resources are wasted, network traffic are extra generated in query execution time is increased and you get nothing new at the end you'll get the same result.",
            "Join aware triple pattern voice or selection is more efficient than simple triple pattern wise source selection.",
            "So here is the performance improvement what we achieve and what we.",
            "What we are targeting in the future to have a new benchmark for this position for data sparkle query processing which are based on real queries in real data and which contains like more simple queries and complex variety of queries as well.",
            "Because currently the FedEx only contains simple query in the execution time is very like small so this is on the road map.",
            "Thank."
        ],
        [
            "For your anticipation, so here is the source code for the hibiscuses available.",
            "You can check out and there are some other statistics and detailed information about this paper can be about this can be found in the paper.",
            "Thank you.",
            "I would have two questions.",
            "One would be about flat bench fit.",
            "Bench has some strange properties that you actually need very little.",
            "It's it's very focused benchmark.",
            "If you thought about using other Federation benchmarks to do.",
            "Yeah, because as I mentioned, it's a bit simple, but I'm more interested in real data in real datasets.",
            "Fed Bench is the only one that is available.",
            "So because the previous work shows that, like synthetic benchmark doesn't reflect the reality, so that's what I want to test my system with real scenario, so only this one was available at that time, which is really the other question I would have.",
            "I mean, as I understand it, the core improvement comes from the fact that you make an assumption, and that assumption is that you have an authority clearly dedicated to a particular endpoint and which is of course the assumption you do in linked data.",
            "Wealth of course.",
            "Then you don't have an endpoint usually, but it's not the assumption that's made in general in RDF stores.",
            "If I correctly understand your question, it's like you mean that you are I authority because we make a use of the distinct urri authorities from different writers.",
            "Authority applies to link data, but it does not apply to RDF endpoints in general.",
            "Yeah, so it's like if there is like the if the UI authorities are the same.",
            "Like let's suppose data is provided by the same, you know winter and it's like is distributed in more than one sparkle endpoint.",
            "Then at that case hibiscus is not that much efficient and we are like this in the future how we can improve in such scenarios as well.",
            "Thanks for this presentation.",
            "I have a slightly similar question.",
            "If you have services like same as org which produce which provide only links.",
            "Between datasets and nothing more, how can you incorporate those into your approach?",
            "Because it seems to me at first glance that they wouldn't be selected as a source feelings.",
            "Sorry I didn't get your question.",
            "Can you forget that there are services that just provide links between two datasets and nothing more, just like say, Missouri?",
            "How do you incorporate those into your server?",
            "Actually I know here is like this was in this example.",
            "It was only all same as but there are like other as well.",
            "So let's suppose RDF type which is very common as well.",
            "So there are so many common predicates that usually come in the sparkle endpoints, so we need to deal with this.",
            "But if we are using only a triple pattern voice or selection.",
            "We only look for this specific triple pattern wise and we don't look for the joint, so we will anyway overestimate the sources.",
            "So it's not about only all semis, but that example was only regarded to the old simmers, but in fact bench you if you see the complete result.",
            "There are so many queries you can see that there is no SMS, but still we overestimated resources.",
            "I'm not very sure if I have understood well what you mean by indexing.",
            "You mean indexing the content of the of the data sources or you just index the your eyes of their sparkle endpoints.",
            "And if you mean what if you meant the first one which is indexing the content of the data sources?",
            "In this case, why didn't you just use caching structure to index on the go just like FedEx does?",
            "Yeah, that's a good question.",
            "So what we are storing is we're only storing the summary of the sparkle endpoints, so we get only the distinct predicates, which are usually very small for anyone for DB pedia, the maximum is 1000 predicates, but for rest like 2030, so we only store the data summaries.",
            "We're not storing this complete things, so using the cash is, you know, because it's all.",
            "If I'm using cash, it means that it is in alternative index as well, because if I'm storing the sparkle ask request.",
            "They're so it's still a small, you know index and I need to load it and I need to, you know, look for that as well so it's like it will be the same, but the disadvantage is that we don't.",
            "In that case we don't have this.",
            "You know the UI part which we used.",
            "You know intelligently for the source keeping.",
            "So if I simply, you know, like in FedEx if we only store the sparkle, ask queries, then I don't cannot do this source selection thing, which I've done in that.",
            "I understand that your selection approach reduced the number of requests ending to the data set, but I'm not quite sure about how your approach can reduce the query processing time, and I mean, for example, FedEx use multiple threads to executing to execute this queries.",
            "So if you have more.",
            "The data source is just increase the number of requests for this data source, but it doesn't increase the processing time since they are all running in parallel.",
            "OK, So what the answer to your question is that first thing is that if you are using sparkle, ask queries that are, you know, time consuming.",
            "Definitely it's a select query without any result, right?",
            "So that's the one thing we removed it and now we don't use any sparkle ask query.",
            "So that was of course the time.",
            "Consumed by the sparkle ask where is that?",
            "Are you know reduce so that example was based on the FedEx FedEx make use of the unit sparkle ask query so which means that we skipped 45 queries for the.",
            "Another thing is that if you are selecting some you know.",
            "Sources which are not capable, which means that you are wasting network traffic because you need to connect the to contact them anyway, right?",
            "Even if it's parallel but you need to contact them and maybe if it's lower than the rest in response.",
            "So if it's in parallel is still, it's like a waste of time and network traffic, and maybe if you get some intermediate results from them you know even after join it will be skipped but you got the intermediate results.",
            "So there's an extra processing as well.",
            "So so if I understand correctly, if assuming.",
            "All the data sets have the same speed of connection, so I mean your approach won't reduce the processing time Mark, but in reality is like gold sparkle and point doesn't have the same speed of your connection, so it's like different than it's like located in different areas.",
            "So it depends where they are located.",
            "Thank you very much."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Hello everybody, my my name is Mohammed Salim, from a CSW University of logic in Germany and today I'm going to present hibiscus hypergraph based source selection for Sparkle Endpoint Federation.",
                    "label": 0
                },
                {
                    "sent": "So first I would like to ask.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Learn the whole idea, how the Federation Sparkle Query Federation works.",
                    "label": 0
                },
                {
                    "sent": "So this is the slide for that.",
                    "label": 0
                },
                {
                    "sent": "So given a sparkle query and we have a Sparkle engine which is shown in this box, this is a Federated engine.",
                    "label": 0
                },
                {
                    "sent": "So given a sparkle query from user what the Federation engine do is the first thing is that it powers the query, so parsing means this is all just want to make it clear this is a very general diagram, so the parsing means get individual triple patterns in the query.",
                    "label": 1
                },
                {
                    "sent": "So once you get that and then the second step is the source selection.",
                    "label": 0
                },
                {
                    "sent": "Which means that for each individual triple pattern you need to identify what are the capable sources.",
                    "label": 0
                },
                {
                    "sent": "So by sources I mean here is sparkle and points.",
                    "label": 0
                },
                {
                    "sent": "So what are the sparkle back end points that can answer that specific triple pattern affect query?",
                    "label": 0
                },
                {
                    "sent": "And once we have this source selection then the next step is the federator and optimizer step.",
                    "label": 0
                },
                {
                    "sent": "So here we make small sub queries of the original query and then once we get the small sub queries an get some execution plan.",
                    "label": 1
                },
                {
                    "sent": "Then we need to.",
                    "label": 0
                },
                {
                    "sent": "We need to execute this query to the corresponding sparkle and points and then once we send these queries to the corresponding sparkle and points we get the results back from each subquery and then once we get this results back we need to integrate or merge them the results so.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here we get merging results and this is the final results which we got for each for the given sparkle query and this is.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is then forwarded to the the user.",
                    "label": 0
                },
                {
                    "sent": "So this was a very general architecture.",
                    "label": 0
                },
                {
                    "sent": "How the Sparkle Endpoint Federation works.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So where is our contribution?",
                    "label": 1
                },
                {
                    "sent": "It's on the specific part of this Federated Sparkle query processing, which is source selection.",
                    "label": 0
                },
                {
                    "sent": "So how efficiently we can identify the set of capable sources or sparkle and points against the individual triple pattern of inquiry?",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here is the motivation given a feedback.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Great if it benches, benchmark for Federated SPARQL query processing which is based on the real data set.",
                    "label": 0
                },
                {
                    "sent": "So we collected an example query which is L. D3.",
                    "label": 0
                },
                {
                    "sent": "The link data query #3 invested that return for all US President Dear Party membership in the news pages about them.",
                    "label": 1
                },
                {
                    "sent": "So in this query we have five triple patterns from TP12TP2.",
                    "label": 0
                },
                {
                    "sent": "In all, in the Fed bench we have 9 datasets or sparkle and points given below and let me name it from S1 to S nine source, one source, two to source 9.",
                    "label": 0
                },
                {
                    "sent": "And let's suppose we have a source selection algorithm in the middle.",
                    "label": 0
                },
                {
                    "sent": "So I want to remind you again what the source selection algorithm will do is to identify the capable sources against individual triple patterns so.",
                    "label": 0
                },
                {
                    "sent": "Let's suppose we have a first triple pattern which is RDF type and we send a sparkle ask query to all of the nine sources in only DB pedia, which is more case S1 is capable of answering this triple pattern and then the same.",
                    "label": 0
                },
                {
                    "sent": "We send the second triple pattern to each of the units particle endpoint in ask using the ASK where we can get that OK. D Pedia is the only one that can answer this.",
                    "label": 0
                },
                {
                    "sent": "Cool pattern and again DB pedia and then in the 4th one is the New York Times which is capable of until now.",
                    "label": 0
                },
                {
                    "sent": "The fifth triple pattern is very common one all same is so if you submit to, you know sparkle as query to majority of the Europe sparkle endpoints so many of them.",
                    "label": 0
                },
                {
                    "sent": "Will you not say yes I can answer this triple pattern so here in case of Fed bench there are eight sources that can answer this triple pattern.",
                    "label": 0
                },
                {
                    "sent": "So now if I sum of the total sources against individual triple patterns or one for the 4th first four triple pattern and then eight for the 5th one, so totalled triple pattern voice source sources selected is 12 in that case, and how many Spark Alaska request we used because we have five people pattern in which we sent each of the triple pattern to each of the data source.",
                    "label": 0
                },
                {
                    "sent": "So 9 multiply by 5 is equal to 45.",
                    "label": 0
                },
                {
                    "sent": "Sparkle, ask where these are used.",
                    "label": 0
                },
                {
                    "sent": "But here is the problem.",
                    "label": 0
                },
                {
                    "sent": "In sort selection, even we use, you know one of the best methods like using Sparkle, ask queries you can get the real things, But here is again a problem.",
                    "label": 0
                },
                {
                    "sent": "We overestimated some sources.",
                    "label": 0
                },
                {
                    "sent": "And I will explain how we overestimated these sources.",
                    "label": 0
                },
                {
                    "sent": "Now if we look at the triple pattern #4 and triple #5 here, there is a joint between these two right?",
                    "label": 0
                },
                {
                    "sent": "So which means whatever results we get for the old, same as we need to make a join with the Navy Yard Time Topic page.",
                    "label": 0
                },
                {
                    "sent": "So this result will be presented, you know to the final user.",
                    "label": 0
                },
                {
                    "sent": "So clearly we can see that if whatever results we get from the rest of the seven sources for all semis, but when we make a join with the New York Time data set, so the final results will only come from the New York time.",
                    "label": 0
                },
                {
                    "sent": "So which means that the even we use sparkle ask queries, but we overestimated seven sources for these two triple patterns because the final answers are only we received the final answer only from New York Times, and the rest are all you know.",
                    "label": 0
                },
                {
                    "sent": "We need to exclude it, so here is this problem.",
                    "label": 0
                },
                {
                    "sent": "Actually, all of these sources this from S1S2 S these are not relevant.",
                    "label": 0
                },
                {
                    "sent": "Because of this you know join.",
                    "label": 0
                },
                {
                    "sent": "And only New York time, which is source #4, is relevant for that.",
                    "label": 0
                },
                {
                    "sent": "So instead of selecting the eight sources for the last triple pattern, the best way is to only select you know New York time for the last people pattern, and still you will you achieve the hundred person recall.",
                    "label": 0
                },
                {
                    "sent": "So this is the problem.",
                    "label": 0
                },
                {
                    "sent": "Actually, the optimal number of triple pattern wise sources select should be 5, but we use sparkle, ask queries and still be selected.",
                    "label": 0
                },
                {
                    "sent": "12 number of sparkle and points.",
                    "label": 0
                },
                {
                    "sent": "Now what's the problem?",
                    "label": 0
                },
                {
                    "sent": "With this?",
                    "label": 0
                },
                {
                    "sent": "We overestimated the sources.",
                    "label": 0
                },
                {
                    "sent": "So what is the problem with this overestimation?",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The problem is that since we selected, you know extra sources there, which means that resources are wasted in.",
                    "label": 0
                },
                {
                    "sent": "Of course, query runtime will be increased because you need to query something which will not produce any resulting to the final you know result set.",
                    "label": 0
                },
                {
                    "sent": "So it's just a waste of, you know network traffic as well.",
                    "label": 0
                },
                {
                    "sent": "So this is the problem.",
                    "label": 0
                },
                {
                    "sent": "Now the question is this, how do we perform this?",
                    "label": 1
                },
                {
                    "sent": "Join aware triple pattern voice or selection in a time efficient way.",
                    "label": 1
                },
                {
                    "sent": "So by time efficient way I mean that in the previous example I use 4045 Sparkle ask queries as well.",
                    "label": 0
                },
                {
                    "sent": "So of course each query will take some time as well and then the rest of the you know because of this overestimation, the network traffic in the extra time will be also added into the final query.",
                    "label": 0
                },
                {
                    "sent": "So this is the problem.",
                    "label": 0
                },
                {
                    "sent": "How I can deal with this so that I use minimum number of sparkle as an?",
                    "label": 0
                },
                {
                    "sent": "I still, you know, achieve you know close to optimal source selection.",
                    "label": 0
                },
                {
                    "sent": "So for this way pro.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Suppose he biscus, which is a hypergraph based source selection approach.",
                    "label": 0
                },
                {
                    "sent": "What does Hibiscus do is so the first thing he biscuits do is to to model each of the sparkle query is a hypergraph.",
                    "label": 0
                },
                {
                    "sent": "Now I will explain how we need how we model this since here subject, predicate and object in each ripple pattern.",
                    "label": 0
                },
                {
                    "sent": "So here for each of these subject predicate an object we have a node.",
                    "label": 0
                },
                {
                    "sent": "So this president and then I have we have another node and then we have 1/3 node.",
                    "label": 0
                },
                {
                    "sent": "So this represents the subject.",
                    "label": 0
                },
                {
                    "sent": "This represent the predicate in this represent the object.",
                    "label": 0
                },
                {
                    "sent": "Now, which one is the hyper edge?",
                    "label": 0
                },
                {
                    "sent": "So the last two becomes the tail of the hyper edge in the top, the first one, the subject becomes the head of the hyperedge, so this is actually hyperedge.",
                    "label": 0
                },
                {
                    "sent": "So we do the same for the second triple pattern.",
                    "label": 0
                },
                {
                    "sent": "President, DB Pedia, nationality and baby.",
                    "label": 0
                },
                {
                    "sent": "United States and then for the third one.",
                    "label": 0
                },
                {
                    "sent": "We start from DB pedia this and so the 4th one is start from X and then.",
                    "label": 0
                },
                {
                    "sent": "Topic page and then the final one is X all same as president.",
                    "label": 0
                },
                {
                    "sent": "So now we come up.",
                    "label": 0
                },
                {
                    "sent": "You'll be model.",
                    "label": 0
                },
                {
                    "sent": "The Sparkle Query is a hypergraph.",
                    "label": 0
                },
                {
                    "sent": "So here I would like to mention three things this blue and represent the start node astar node is 1 in which which has only outgoing hyper edges but no incoming.",
                    "label": 0
                },
                {
                    "sent": "So here you can see only outgoing hyper edges, and there's green on is the path.",
                    "label": 0
                },
                {
                    "sent": "Note.",
                    "label": 0
                },
                {
                    "sent": "So sorry, hybrid mode, hybrid node is the one which has you know incoming edges as well and outgoing edges as well.",
                    "label": 0
                },
                {
                    "sent": "So it has three outgoing hyperedges anwan incoming.",
                    "label": 0
                },
                {
                    "sent": "A hyperedge so this president became the hybrid node.",
                    "label": 0
                },
                {
                    "sent": "So I will explain how and where we will use this.",
                    "label": 0
                },
                {
                    "sent": "Notice you know this representation, the star in hybrid and this is the simple one is the rest of the node.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So Hibiscuses make use of the data summaries to perform join aware people, pattern, voice or selection.",
                    "label": 0
                },
                {
                    "sent": "In short, what our summary contains, we get for each of the data source we get the set of distinct predicate in their data source.",
                    "label": 0
                },
                {
                    "sent": "So like here, let's suppose DB Pedia is our source.",
                    "label": 0
                },
                {
                    "sent": "So we get the set of distance predicate like DB pedia parties.",
                    "label": 0
                },
                {
                    "sent": "One predicate RDF type is another.",
                    "label": 0
                },
                {
                    "sent": "And DB Pedia Postal code is another.",
                    "label": 0
                },
                {
                    "sent": "So we get all of the distinct predicate.",
                    "label": 0
                },
                {
                    "sent": "And for each district predicate we need to get the subject authority, which means that for this predicate we need to get all of the subject you are I and then make then get the distinct you know authorities from the subject you are I so it store here like DB Pedia, Orgs.",
                    "label": 0
                },
                {
                    "sent": "And then we get the object authority as well.",
                    "label": 1
                },
                {
                    "sent": "For each of these predicate, so later I will show how and where we will use this information.",
                    "label": 1
                },
                {
                    "sent": "So this is the first thing that that's about the data summaries of each data source.",
                    "label": 0
                },
                {
                    "sent": "Now we come up to the triple pattern.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Ice or selection.",
                    "label": 0
                },
                {
                    "sent": "How we will do the triple pattern by source selection.",
                    "label": 0
                },
                {
                    "sent": "So here is our first ripple pattern, president RDF type in DB pedia presidents.",
                    "label": 0
                },
                {
                    "sent": "So if you look at our index we can see that RDF type is recorded there and we have the set of you know object UI as well.",
                    "label": 0
                },
                {
                    "sent": "So using these two information using our index we can say that only DB PEDIA is capable of answering this.",
                    "label": 0
                },
                {
                    "sent": "I would like to mention here what is our goal here since like a hyper graph is built here but there are no labels to the hyper edges, so we need to label this in these levels.",
                    "label": 0
                },
                {
                    "sent": "Are the capable sources right?",
                    "label": 0
                },
                {
                    "sent": "So here first we labeled OK this this hyper edge should be labeled with DB pedia.",
                    "label": 0
                },
                {
                    "sent": "Using our data summary and then the second one is again DB PEDIA and 3rd one is again DB pedia and 4th one is New York time.",
                    "label": 0
                },
                {
                    "sent": "But we come up with the same problem that I explain.",
                    "label": 0
                },
                {
                    "sent": "If we look at our index here, we can see that the same 8 number of sources are selected again.",
                    "label": 0
                },
                {
                    "sent": "So this was our first step of the source selection using our index find you know the set of triple patterns.",
                    "label": 0
                },
                {
                    "sent": "Find a set of sources related to each triple pattern.",
                    "label": 0
                },
                {
                    "sent": "But here again we overestimated.",
                    "label": 0
                },
                {
                    "sent": "So then we come up to the second step of our source selection, in which we need to prune.",
                    "label": 0
                },
                {
                    "sent": "By pruning, I means we need to, you know, remove the the sources that are not relevant to the final result sets.",
                    "label": 0
                },
                {
                    "sent": "So we are now going to the second step and how we need to.",
                    "label": 0
                },
                {
                    "sent": "To prove this, how we can skip some of the sources from here?",
                    "label": 0
                },
                {
                    "sent": "So here's what we get.",
                    "label": 0
                },
                {
                    "sent": "Our algorithms start, you know, work on each note which are either star node, are richer.",
                    "label": 0
                },
                {
                    "sent": "Either hybrid node are here.",
                    "label": 0
                },
                {
                    "sent": "There is no part note but there is what other partners as well.",
                    "label": 0
                },
                {
                    "sent": "So partner has one incoming edge in one outgoing edge.",
                    "label": 0
                },
                {
                    "sent": "But in this case we don't have any part node so our algorithm start from this node and then get all of the subject authority for this for this outgoing.",
                    "label": 0
                },
                {
                    "sent": "Age so here we got the New York time and then the for the this one we get this subject authorities right and for each of the hybrid node we need to get subject authority for outgoing edges and we need to get object authority for the incoming edges.",
                    "label": 0
                },
                {
                    "sent": "So that's why for this green one we have this subject authority.",
                    "label": 0
                },
                {
                    "sent": "In this we have object authority.",
                    "label": 0
                },
                {
                    "sent": "Once we get this from the our index then the next step is very simple.",
                    "label": 0
                },
                {
                    "sent": "We just need to make a you know, intersection of these authorities so the blue authorities here is then we are taipan.",
                    "label": 0
                },
                {
                    "sent": "Here is only present New York time is present here.",
                    "label": 0
                },
                {
                    "sent": "So if we make intersection of this so this source is this.",
                    "label": 0
                },
                {
                    "sent": "This is all our will be skipped because these tools only make the intersection with each other.",
                    "label": 0
                },
                {
                    "sent": "So for this hybrid hybrid H.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We will only select New York Times using the intersections of the authorities.",
                    "label": 0
                },
                {
                    "sent": "Now we will.",
                    "label": 0
                },
                {
                    "sent": "Now since this is changed now because only need your time is selected, so we need to only select New York time here as well.",
                    "label": 0
                },
                {
                    "sent": "So we prune the rest of the sources and it becomes ordinary water.",
                    "label": 0
                },
                {
                    "sent": "Now we come to the hybrid.",
                    "label": 0
                },
                {
                    "sent": "So here we need to again make the intersection of the authorities.",
                    "label": 0
                },
                {
                    "sent": "So here's the period.. And here is the Navy Yard time.",
                    "label": 0
                },
                {
                    "sent": "So if we come up, the intersection is here.",
                    "label": 0
                },
                {
                    "sent": "The DB pedia.",
                    "label": 0
                },
                {
                    "sent": "So it means that New York time is skipped from here.",
                    "label": 0
                },
                {
                    "sent": "So here is the final.",
                    "label": 0
                },
                {
                    "sent": "Answer So we label each of the edges with Debbie.",
                    "label": 0
                },
                {
                    "sent": "E. E pedia NVR tab NVR time.",
                    "label": 0
                },
                {
                    "sent": "Which means that the set of total triple pattern wise sources selected is 5 in all of this operation.",
                    "label": 0
                },
                {
                    "sent": "We don't need any sparkle.",
                    "label": 0
                },
                {
                    "sent": "You know ask very weak and completely use our index to you know do perform the source selection.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So now I come up to the experimental.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Set up what we use.",
                    "label": 0
                },
                {
                    "sent": "We use a Fed bench for our evaluation while we use FedEx because it's based on real datasets collected from, you know real and it has a real queries in which shows the typical request on that is not synthetic data and it's like the real thing and we use all of the 25 queries to be more complete and what we did, we extended these systems.",
                    "label": 0
                },
                {
                    "sent": "These three system, FedEx, Dark and splendid.",
                    "label": 0
                },
                {
                    "sent": "With a hibiscus by extension means we only replace the source selection part.",
                    "label": 1
                },
                {
                    "sent": "And then the rest of the query execution time remains the same.",
                    "label": 1
                },
                {
                    "sent": "So so once we extended this with Hibiscus and we also included in app Set version twelve 2013 with Hibiscus without Hibiscus extension but so.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Here are the matrices that we used for our comparison.",
                    "label": 0
                },
                {
                    "sent": "We calculated the index generation time, the index size and total number of triple pattern by sources selected.",
                    "label": 1
                },
                {
                    "sent": "Total number of US request Usan source selection time in the query execution.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Damn.",
                    "label": 0
                },
                {
                    "sent": "So here is the result for the generation index generation term and compression ratio.",
                    "label": 1
                },
                {
                    "sent": "So here Hibiscuses second to the in app set an address it is and then the compression ratio which is given 1 minus index size by total data dump size is quite high 99.99.",
                    "label": 0
                },
                {
                    "sent": "So here is the.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The result of the source selection.",
                    "label": 0
                },
                {
                    "sent": "So in in result of the source selection.",
                    "label": 0
                },
                {
                    "sent": "Here this represent the number of total triple pattern by sources selected.",
                    "label": 0
                },
                {
                    "sent": "This is the number of ASK request use and this is the source selection time in milliseconds.",
                    "label": 0
                },
                {
                    "sent": "So you can clearly see Hibiscus outperform all of the state of the art systems in terms of triple pattern by sources selected in terms of number of ASK request to use.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So here is the another result for the evaluation.",
                    "label": 0
                },
                {
                    "sent": "That's for the query execution time.",
                    "label": 1
                },
                {
                    "sent": "So what we did, we compare each of the extension with the original system.",
                    "label": 0
                },
                {
                    "sent": "So here is the result for the FedEx extension with Hibiscus and we improved 2520 queries out of 25 and the net performance improvement was 24.66 and here is the result for SP.",
                    "label": 1
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "When did we improved splendid in all of the 25 queries with the net performance improvement of 82?",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Person, and here is the extension for here.",
                    "label": 0
                },
                {
                    "sent": "The result for the dark extension, so we got improvement of 21 queries because some of the queries are not supported by dark.",
                    "label": 1
                },
                {
                    "sent": "And net performance improvement was 92.22.",
                    "label": 1
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "As I mentioned that we didn't extend the in app set, but we compared our best Journal system with the BISCUS and we can see that like we have improvement, which is our best one is the hibiscus plus splendid.",
                    "label": 0
                },
                {
                    "sent": "So here we get an improvement in 25 out of 24 out of 24 queries with Annette performance improvement of 98.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Saint so conclusion.",
                    "label": 0
                },
                {
                    "sent": "An overestimation of triple pattern.",
                    "label": 1
                },
                {
                    "sent": "Why source selection can be expensive?",
                    "label": 1
                },
                {
                    "sent": "Becausw resources are wasted, network traffic are extra generated in query execution time is increased and you get nothing new at the end you'll get the same result.",
                    "label": 0
                },
                {
                    "sent": "Join aware triple pattern voice or selection is more efficient than simple triple pattern wise source selection.",
                    "label": 1
                },
                {
                    "sent": "So here is the performance improvement what we achieve and what we.",
                    "label": 0
                },
                {
                    "sent": "What we are targeting in the future to have a new benchmark for this position for data sparkle query processing which are based on real queries in real data and which contains like more simple queries and complex variety of queries as well.",
                    "label": 0
                },
                {
                    "sent": "Because currently the FedEx only contains simple query in the execution time is very like small so this is on the road map.",
                    "label": 0
                },
                {
                    "sent": "Thank.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "For your anticipation, so here is the source code for the hibiscuses available.",
                    "label": 1
                },
                {
                    "sent": "You can check out and there are some other statistics and detailed information about this paper can be about this can be found in the paper.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                },
                {
                    "sent": "I would have two questions.",
                    "label": 0
                },
                {
                    "sent": "One would be about flat bench fit.",
                    "label": 0
                },
                {
                    "sent": "Bench has some strange properties that you actually need very little.",
                    "label": 0
                },
                {
                    "sent": "It's it's very focused benchmark.",
                    "label": 0
                },
                {
                    "sent": "If you thought about using other Federation benchmarks to do.",
                    "label": 0
                },
                {
                    "sent": "Yeah, because as I mentioned, it's a bit simple, but I'm more interested in real data in real datasets.",
                    "label": 0
                },
                {
                    "sent": "Fed Bench is the only one that is available.",
                    "label": 0
                },
                {
                    "sent": "So because the previous work shows that, like synthetic benchmark doesn't reflect the reality, so that's what I want to test my system with real scenario, so only this one was available at that time, which is really the other question I would have.",
                    "label": 0
                },
                {
                    "sent": "I mean, as I understand it, the core improvement comes from the fact that you make an assumption, and that assumption is that you have an authority clearly dedicated to a particular endpoint and which is of course the assumption you do in linked data.",
                    "label": 0
                },
                {
                    "sent": "Wealth of course.",
                    "label": 0
                },
                {
                    "sent": "Then you don't have an endpoint usually, but it's not the assumption that's made in general in RDF stores.",
                    "label": 0
                },
                {
                    "sent": "If I correctly understand your question, it's like you mean that you are I authority because we make a use of the distinct urri authorities from different writers.",
                    "label": 0
                },
                {
                    "sent": "Authority applies to link data, but it does not apply to RDF endpoints in general.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so it's like if there is like the if the UI authorities are the same.",
                    "label": 0
                },
                {
                    "sent": "Like let's suppose data is provided by the same, you know winter and it's like is distributed in more than one sparkle endpoint.",
                    "label": 0
                },
                {
                    "sent": "Then at that case hibiscus is not that much efficient and we are like this in the future how we can improve in such scenarios as well.",
                    "label": 0
                },
                {
                    "sent": "Thanks for this presentation.",
                    "label": 0
                },
                {
                    "sent": "I have a slightly similar question.",
                    "label": 0
                },
                {
                    "sent": "If you have services like same as org which produce which provide only links.",
                    "label": 0
                },
                {
                    "sent": "Between datasets and nothing more, how can you incorporate those into your approach?",
                    "label": 0
                },
                {
                    "sent": "Because it seems to me at first glance that they wouldn't be selected as a source feelings.",
                    "label": 0
                },
                {
                    "sent": "Sorry I didn't get your question.",
                    "label": 0
                },
                {
                    "sent": "Can you forget that there are services that just provide links between two datasets and nothing more, just like say, Missouri?",
                    "label": 0
                },
                {
                    "sent": "How do you incorporate those into your server?",
                    "label": 0
                },
                {
                    "sent": "Actually I know here is like this was in this example.",
                    "label": 0
                },
                {
                    "sent": "It was only all same as but there are like other as well.",
                    "label": 0
                },
                {
                    "sent": "So let's suppose RDF type which is very common as well.",
                    "label": 0
                },
                {
                    "sent": "So there are so many common predicates that usually come in the sparkle endpoints, so we need to deal with this.",
                    "label": 0
                },
                {
                    "sent": "But if we are using only a triple pattern voice or selection.",
                    "label": 0
                },
                {
                    "sent": "We only look for this specific triple pattern wise and we don't look for the joint, so we will anyway overestimate the sources.",
                    "label": 0
                },
                {
                    "sent": "So it's not about only all semis, but that example was only regarded to the old simmers, but in fact bench you if you see the complete result.",
                    "label": 0
                },
                {
                    "sent": "There are so many queries you can see that there is no SMS, but still we overestimated resources.",
                    "label": 0
                },
                {
                    "sent": "I'm not very sure if I have understood well what you mean by indexing.",
                    "label": 0
                },
                {
                    "sent": "You mean indexing the content of the of the data sources or you just index the your eyes of their sparkle endpoints.",
                    "label": 0
                },
                {
                    "sent": "And if you mean what if you meant the first one which is indexing the content of the data sources?",
                    "label": 0
                },
                {
                    "sent": "In this case, why didn't you just use caching structure to index on the go just like FedEx does?",
                    "label": 0
                },
                {
                    "sent": "Yeah, that's a good question.",
                    "label": 0
                },
                {
                    "sent": "So what we are storing is we're only storing the summary of the sparkle endpoints, so we get only the distinct predicates, which are usually very small for anyone for DB pedia, the maximum is 1000 predicates, but for rest like 2030, so we only store the data summaries.",
                    "label": 0
                },
                {
                    "sent": "We're not storing this complete things, so using the cash is, you know, because it's all.",
                    "label": 0
                },
                {
                    "sent": "If I'm using cash, it means that it is in alternative index as well, because if I'm storing the sparkle ask request.",
                    "label": 0
                },
                {
                    "sent": "They're so it's still a small, you know index and I need to load it and I need to, you know, look for that as well so it's like it will be the same, but the disadvantage is that we don't.",
                    "label": 0
                },
                {
                    "sent": "In that case we don't have this.",
                    "label": 0
                },
                {
                    "sent": "You know the UI part which we used.",
                    "label": 0
                },
                {
                    "sent": "You know intelligently for the source keeping.",
                    "label": 0
                },
                {
                    "sent": "So if I simply, you know, like in FedEx if we only store the sparkle, ask queries, then I don't cannot do this source selection thing, which I've done in that.",
                    "label": 0
                },
                {
                    "sent": "I understand that your selection approach reduced the number of requests ending to the data set, but I'm not quite sure about how your approach can reduce the query processing time, and I mean, for example, FedEx use multiple threads to executing to execute this queries.",
                    "label": 0
                },
                {
                    "sent": "So if you have more.",
                    "label": 0
                },
                {
                    "sent": "The data source is just increase the number of requests for this data source, but it doesn't increase the processing time since they are all running in parallel.",
                    "label": 0
                },
                {
                    "sent": "OK, So what the answer to your question is that first thing is that if you are using sparkle, ask queries that are, you know, time consuming.",
                    "label": 0
                },
                {
                    "sent": "Definitely it's a select query without any result, right?",
                    "label": 0
                },
                {
                    "sent": "So that's the one thing we removed it and now we don't use any sparkle ask query.",
                    "label": 0
                },
                {
                    "sent": "So that was of course the time.",
                    "label": 0
                },
                {
                    "sent": "Consumed by the sparkle ask where is that?",
                    "label": 0
                },
                {
                    "sent": "Are you know reduce so that example was based on the FedEx FedEx make use of the unit sparkle ask query so which means that we skipped 45 queries for the.",
                    "label": 0
                },
                {
                    "sent": "Another thing is that if you are selecting some you know.",
                    "label": 0
                },
                {
                    "sent": "Sources which are not capable, which means that you are wasting network traffic because you need to connect the to contact them anyway, right?",
                    "label": 0
                },
                {
                    "sent": "Even if it's parallel but you need to contact them and maybe if it's lower than the rest in response.",
                    "label": 0
                },
                {
                    "sent": "So if it's in parallel is still, it's like a waste of time and network traffic, and maybe if you get some intermediate results from them you know even after join it will be skipped but you got the intermediate results.",
                    "label": 0
                },
                {
                    "sent": "So there's an extra processing as well.",
                    "label": 0
                },
                {
                    "sent": "So so if I understand correctly, if assuming.",
                    "label": 0
                },
                {
                    "sent": "All the data sets have the same speed of connection, so I mean your approach won't reduce the processing time Mark, but in reality is like gold sparkle and point doesn't have the same speed of your connection, so it's like different than it's like located in different areas.",
                    "label": 0
                },
                {
                    "sent": "So it depends where they are located.",
                    "label": 0
                },
                {
                    "sent": "Thank you very much.",
                    "label": 0
                }
            ]
        }
    }
}