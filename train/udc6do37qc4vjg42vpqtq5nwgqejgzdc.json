{
    "id": "udc6do37qc4vjg42vpqtq5nwgqejgzdc",
    "title": "MDL Tutorial",
    "info": {
        "author": [
            "Peter Gr\u00fcnwald, Centrum Wiskunde & Informatica (CWI)"
        ],
        "published": "Aug. 12, 2008",
        "recorded": "July 2008",
        "category": [
            "Top->Computer Science->Machine Learning"
        ]
    },
    "url": "http://videolectures.net/icml08_grunwald_mld/",
    "segmentation": [
        [
            "Thanks very much.",
            "Poetry and thanks for.",
            "Having me here in Helsinki.",
            "So this will be a tutorial which starts from scratch, so I do not assume that you know any information theory.",
            "And for this reason, for some people here in the room, I know no information theory, so I apologize to them because a large part of the tutorial will be about some basic information theoretic notions.",
            "Please feel free to interrupt me if you have any technical questions.",
            "If you have, say, more questions about philosophy, complicated questions, you can also write them down and then hand them over to Tim Tim from elephant.",
            "Because in the afternoon we will have a panel discussion and actually we hope that some people will bring up some interesting issues to talk about them, so keep that in mind when you listen to this.",
            "So this talk is called introduction to modern MD El Universal modeling, and this is something which still many people don't know.",
            "That Emil comes from something comes from an ocean in information theory called universal coding or Universal Modeling, and that is what I'm going to talk about.",
            "Most actually."
        ],
        [
            "So what I'm going to do the following.",
            "First I give you a general introduction to.",
            "General introduction.",
            "About the ideas underlying MDL an.",
            "Then, in order to introduce this concept of universal coding and Universal Modeling, I need to say something and that's the information theory part about how probability distributions relate to code lengths and vice versa.",
            "Then I'll introduce this universal models and then I can define MDL model selection and then I'll talk about four different ways to interpret it and I'll end with a brief overview of some of the new developments in MDL that will be discussed later today."
        ],
        [
            "So first introduction.",
            "So minimum description length is a method for learning from data statistics, machine learning.",
            "It has been mostly developed and suited for problems of model selection, but you can also use it to do prediction estimation or any of the other kinds.",
            "Of inference usually associated with statistics.",
            "So by model selection I mean the problem where you don't just try to learn parameters from the data, but also structure like you have X&Y data you're trying to find a function which describes the relationship between X&Y.",
            "And you want to find, for example, the best polynomial arbitrary degree.",
            "To fit the data.",
            "So then you always have to compromise the complexity of the model you're looking at and the goodness of fit.",
            "Otherwise you will be over fitting in a terrible way, and that's what M Neal does.",
            "It's kind of a generic way to avoid overfitting."
        ],
        [
            "And the underlying idea is based on a correspondence between regularity in data and ability to compress the data.",
            "So the idea is that the more you are able to compress a sequence of data, the more regularity you have detected in the data.",
            "So, for example, suppose I have a sequence of 300,000 zeros and ones and it's like 001001001, etc.",
            "So it's 100,000 fold repetition of 001.",
            "Now if this idea is to make any sense, then I should be able to describe the sequence in a very short way and the questions.",
            "Can I do that?",
            "Well, in fact, I've already done it because I've told you a recipe in just one sentence of natural language, which allows you to write out the sequence in full.",
            "But if you would write it out in full.",
            "Then it will take you the whole blackboard, so I've already compressed it using natural language.",
            "And of course if you want to do this with the computer, you have to use some computer language.",
            "But the idea is clear.",
            "If there is a pattern in a sequence, you can somehow exploit that pattern to compress the sequence.",
            "Now, on the other hand, again, if the idea is to make any sense, then what is intuitively a random sequence should not be compressible.",
            "So imagine that here are hundred thousands bits generated by independent throws of a fair coin.",
            "Then we should not be able to compress this data and as we will see in a moment, actually this is the case with very high probability.",
            "We cannot compress this data no matter what coding method we use.",
            "And I'll explain the.",
            "I'll explain the motive.",
            "I'll explain the reason why that is so in a moment, but the general thing to remember here is that if you have data samples completely randomly by fair coins, then no matter what coding method you use, you cannot compress it very much.",
            "So more formally, the probability that you can compress such a data sequence by more than K bits is smaller than two to the minus K, so even compressing it by 20 bits is probability smaller than two to the minus 20, which is one in a billion.",
            "So it goes down to zero very very quickly and in a moment."
        ],
        [
            "With that for you.",
            "So the next step is to say, then OK, we're going to.",
            "Equate finding regularity in data with compressing the data and then we say the more regularity we found, the more we've learned about the data.",
            "So inductive inference is seen here is trying to find regularity's in data and then of course in the next step you can use this to make predictions about future data."
        ],
        [
            "So that's the basic idea.",
            "And as I say set, this will mostly be applied to model selection problems, and I'll also focus on that in this talk.",
            "So suppose you have some data and various models, and the question is which model best explains the data.",
            "So this could be as I said, like trying to find the best polynomial which fits the data where if these are pairs actually of X&Y pairs, each outcome then and you have an outcomes.",
            "Then there will always be a polynomial of degree in which fits them perfectly, but you don't want to select that because it will probably give very bad predictions of future data.",
            "So somehow you need to trade off error and complexity of the models.",
            "MDL does that for you.",
            "Of course you can also use this to for example, try to find the best order of a Markov chain if your data is text and you want to model it using some Markov chain question Switch user 1st order model or a second order model with more dependencies.",
            "The higher the order, the more parameters you have.",
            "In MDL can be used to select the number of parameters."
        ],
        [
            "So you might have noticed this tutorial is called introduction to modern amneal so.",
            "There I should say something more about that.",
            "So what I'm referring to is what most people in the MDL community call MDL, and that was basically the first time stated.",
            "That way in an overview article by Baron, Reason and you from 1998.",
            "So recently is the founder of MDL and you can feel, for example, resonance.",
            "Older versions of MDL is kind of approximations of this modern type.",
            "So recent and actually introduced MDL in the 1970s.",
            "In the beginning with a rather simple instantiation.",
            "But the idea or similar ideas in fact, much older, so there's also something called minimum message length, which goes back to 1968, which is somewhat different, but the underlying idea trying to model by data compression is the same.",
            "And then there's also a version of MDL based on Kolmogorov complexity, which is also being called Ideal MDL, but which is actually quite different from what I'm going to talk about here."
        ],
        [
            "So now for the second part, in order to introduce me like first have to say how probabilities encode length 3."
        ],
        [
            "Date.",
            "So first I'm going to define to you what I mean by a code.",
            "So suppose I have some set of outcomes.",
            "Let's assume it's countable, so you can.",
            "Typically this will be actually the set of all vectors of some given length N in some particular space.",
            "So think of it as the space as possible outcomes of a statistical experiment with a given sample size.",
            "Now a code to encode such sequences of outcomes is a one to one map from the set of outcomes to the binary sequences of length one or longer.",
            "At.",
            "So this code C is a function which Maps every outcome or actually sequence of outcomes to a binary string.",
            "And that string is in the code of the original data.",
            "And the following notation is crucial.",
            "I always use this notation so if I once I have a coat, I use notation L, sub C of X to denote the number of bits needed to describe X.",
            "So if I encode X using a code word of five bits and this will be 5 for example, or if I use something with seven bits.",
            "It will be 7 right?",
            "So this is not the code word itself, but only its length."
        ],
        [
            "So.",
            "Now let's go back to.",
            "So let's say something about probability distributions on a countable sets.",
            "So.",
            "We know, of course, that the sum overall outcomes of the probability of an outcome of that outcome must be one and.",
            "Making it into a weaker statement, smaller, equal and one that holds for every probability distribution.",
            "So one way of thinking about that is that most outcomes must have very small probability.",
            "What do I mean by that?",
            "Well, you can have only two outcomes with probability at most 1/2 you can have only four outcomes with probability at most 1/4 you can have only eight outcomes with probability at most 1/8 etc right, because otherwise you don't sum to you don't sum to one.",
            "If you have more than eight outcomes probability 18 you some to something larger than one.",
            "So if you have, let's say 1024 outcomes, then almost all of them must have probability smaller equal and 1 / 1024.",
            "So now if we look at Coates, it turns out that a similar phenomenon occurs.",
            "So suppose we want to encode sequences of some length M binary sequences.",
            "So in this special case we met binary sequences to other binary sequences.",
            "Now of course there are only two sequences of length one only four sequences of length two, only eight of length three, etc.",
            "But there are two to the M sequences of length M, so the fraction of sequences that can be compressed to an encoding of length one is very small.",
            "Only two of the two 2D M sequences can be compressed to an encoding of length one.",
            "Only four can be compressed and encoding of length two etc.",
            "So in general, the fraction that can be compressed by more than K bits is less than the number of sequences with N -- K bits divided by the number of sequences with ambit.",
            "So that's two to the minus K. So in this sense, only very few symbols can have a small code length.",
            "So note that codes in this talk and any MD Ellen general quotes are always uniquely decodable codes, so this means that if we have encoded something, we must always be able to decode the original data from which the encoding came, so you cannot have two different data sequences mapping to the same code words, and therefore they can really be only two things with code word, one because you cannot map different things to the same code word.",
            "So now I can also explain to you the reasoning of the very first slide, where I said that if you have a random sequence generated by tosses of a fair coin that you cannot compress it with very high probability.",
            "You're suppose you have a sequence of data sequence of length M in binary.",
            "Now if that is generated by fair coin tosses, then the probability of each sequence will be the same.",
            "It will be 2 to the minus M. So then the probability of a subset of size 2 to the N -- K. Will be at most two to the minus K right?",
            "Because all of them have probably 2 to the minus M. If you take 2 to the N -- K of them, the total probability of such a set will be 2 to the minus K. So therefore the probability that the actual sequence you get is in a set which you can compress by K bits or more is at most two to the minus K. And this holds for every K, and this holds also for every code.",
            "If the distribution is uniform, then no matter what code you used.",
            "The data won't be compressible with very high probability.",
            "Because being able to compress means being able to map the set of all sequences to a very small subset thereof.",
            "So, but back to the probabilities.",
            "So we see that if you have a probability distributions, then most outcomes must have very small probability, and if you have a quote, the most outcomes must have a large code length.",
            "So this suggests some kind of."
        ],
        [
            "Knology and that analogy can actually be formalized, and that's the celebrated craft inequality which you write down here in a slightly different form from what is usual, but it's equivalent.",
            "It says the following.",
            "Suppose I have a uniquely decodable code, or for countable sets.",
            "Then no matter what the code is, there's always a distribution on outcomes such that for all outcomes, the number of bits I need to encode the outcome is minus lock.",
            "The probability of the outcome.",
            "A very simple example is when I use a uniform code.",
            "So for example, there are four possible outcomes and I encode each of these by two bits.",
            "So for example.",
            "The set of outcomes is this an I in code.",
            "AS00 and BA01.",
            "Etc.",
            "So then every outcome is 2 bits.",
            "And indeed, there exists a distribution for outcomes which has probability minus log 2, which is 1/4, right?",
            "I always use binary logarithm.",
            "So two is the number of bits.",
            "Then 1/4 is the probability, so I'm not making any claims here.",
            "The data are distributed according to this P. I'm just saying if I start with the code, I can always make a distribution such that this holds for all outcomes, yes?",
            "Sorry.",
            "Oh, I'm getting through that.",
            "So I cheated a little bit and that's it.",
            "May be that this code that this distribution is defective, which means that it doesn't sum to one but something smaller than one.",
            "So the crucial thing is that it never gets larger than one.",
            "An an actually defective more or less you get a defective distribution if the code is not efficient in a way if there exists a code which gives to every outcome.",
            "No outcome, a longer code length into some outcomes are strictly shorter code length then you.",
            "Then you will get a defective distribution.",
            "So the let's say the nontrivial thing about this is that this also holds if the codes are not uniform.",
            "So here we use a code which is the same code link for all outcomes.",
            "But this says that you can do this for all uniquely decodable codes, even if they don't assign the same code length to all outcomes, yes.",
            "Search for talking about at least supposed to be prefix free codes?",
            "Or is that not require?",
            "It's actually good question.",
            "Yes and no so.",
            "Everything gets much easier if you say they must be prefix free codes.",
            "But if you only require them to be uniquely decodable.",
            "Then it turns out that, but then you have to define in a very precise way what you mean by uniquely decodable.",
            "I just said uniquely decodable is 1 to one, but there's.",
            "You need a more restrictive definition.",
            "Then it turns out that if you that basically there is a one.",
            "So if you have a uniquely decodable code with certain lengths.",
            "For all outcomes, then there's also a prefix free code with the same length.",
            "So therefore.",
            "You can restrict to prefix free codes with.",
            "Without loss of generality.",
            "So let me brief you, briefly give you an example of a non where where you can see how this might work in a nonuniform case.",
            "So suppose we just have three outcomes.",
            "Then we might encounter like this say 10111.",
            "At least for me.",
            "Oh so.",
            "Does this help or?",
            "Or not.",
            "I'll do it.",
            "Sell it.",
            "OK.",
            "So here we have a quote which is uniquely decodable.",
            "Because the decoder can always decode when he sees this, what was the original code word?",
            "And you see here that.",
            "You need one bit to encode a.",
            "So then this will correspond to.",
            "Now it gets harder to OK.",
            "So here you get probability 1/2.",
            "And he will get probability 1/4.",
            "So you see that again you have 1/2 and 1/4 and 1/4 and it adds to one.",
            "So to this code there's also a corresponding distribution which always assigns.",
            "Such that for every outcome.",
            "Code length is minus log the probability.",
            "The Kraft inequality says you can always do that with uniquely decodable codes."
        ],
        [
            "But so now you can also go the other way.",
            "So now we start with a distribution on a countable set.",
            "And then no matter what distribution we start with, there always exist some code such that for all outcomes you have the number of bits you need to encode the outcomes.",
            "Is equal to minus log probability of the outcome rounded up to the nearest integers, because codes must always be bits."
        ],
        [
            "So if you combine these two things and this is really the most important insight.",
            "There is, in order to understand the Omni literature, there is so one to one correspondence between probability distributions and code link functions such that small probabilities correspond to large code lengths and vice versa.",
            "So now I'm looking at data sequences or forgiven length if I have a coat with some length function then there always is a distribution such that the lengths are equal to minus log probability.",
            "If I have a probability then there always is a code such that this holds."
        ],
        [
            "So, for example, suppose you have data and you look at some candidate explanation of the data, so you don't know if the data is generated by the distribution.",
            "You only think of it.",
            "Maybe that is a good distribution to explain my data.",
            "For example, of 1st order Markov chain.",
            "So now what happens is that distribution might fit the particular data you have more or less well.",
            "And basically.",
            "If you change the distribution to a coat, then the better the distribution fits the data, the shorter the corresponding code length will be.",
            "So every distribution gives you a prescription on how to make a certain code, and that code will give a short code length to those things.",
            "Which have a high likelihood under the distribution."
        ],
        [
            "So note, once again I keep saying it there is no assumption here that data are sampled from any distribution.",
            "This is a purely formal correspondence between two different mathematical notions.",
            "Namely, probability distributions.",
            "But here a probability distribution is simply a function on a space which is always non negative and which sums to one and code link functions.",
            "Second thing is you can also do this if you have continuous outcome spaces by discretizing inappropriate way.",
            "So I will gloss over all the details there and from now on in this talk when I refer to a distribution or actually a mass function, I will sometimes also mean a density by that.",
            "And then note that in a less light."
        ],
        [
            "I forgot about this integer requirement, so I didn't round up to the nearest integer.",
            "And this is something that is usually done and that can be justified, because usually if N is not one but a little bit larger than the probabilities you assign to sequences, they tend to decrease exponentially in N. So the minus log of the probability increases linearly, and then if you neglect this round off.",
            "Affect then the area makes at most one bit, which will typically be negligible compared to the total length.",
            "And if you do that, you get a much nicer mathematical theory and also you get a theory which becomes independent of the alphabet in which you encode things.",
            "So you would like a theory where there's a always an easy mapping between coding things in binary or coding things internally alphabet.",
            "And for this reason from now on we will neglect the integer requirement and we will talk about idealized codes.",
            "So these are codes we will if we start from arbitrary distribution, we will call.",
            "This still a code link function, even if it is non integer length.",
            "This is a common thing in information theory actually if you read information theory papers you sometimes see that people use the word quote and distribution simply interchangeably.",
            "And when they talk about codes and they speak about and they refer to distributions, they mean the distribution which is connected to the code by this equality."
        ],
        [
            "So this is about the correspondence between probability distributions and code link functions.",
            "And now we're going to use that to define universal models and to define you."
        ],
        [
            "First models we start with universal codes.",
            "So for the time being, forget forget that this is a talk about machine learning.",
            "We will only be talking about data compression for a few slides now.",
            "Anne.",
            "And we will talk basically about the method underlying most modern lossless data compressors, which is called universal coding.",
            "And the idea is as follows.",
            "So suppose you want to encode some data and you have a set of different codes available for doing that.",
            "And you want to compress the data as much as possible.",
            "That's your goal.",
            "You think that some of the quotes in the set Curly L, the set of candidate codes will actually do a good job.",
            "They will compress the data a lot.",
            "So now the goal is to encode the data using the minimum possible number of bits based on the set of candidate codes L. So how is she?"
        ],
        [
            "If we do that, well, the obvious idea is to simply code the data using the code in a set of codes which minimizes the code length of that particular data.",
            "So no, that's because I'm not interested in how the actual encoding is done.",
            "I identified the codes with their length functions, so this is this curly L is.",
            "I call it a set of codes, but really is, it's a set of length functions corresponding to these codes, which for each outcome give you the number of bits needed to encode that outcome.",
            "So the obvious idea to pick the code which minimizes the length doesn't work.",
            "Why doesn't it work well to see that you have to realize that coding and decoding can always be viewed as a game between an encoder and a decoder, where the encoder and a decoder meet before seeing any data to be encoded, and they agree on a protocol they agree on their quote.",
            "So after they've agreed on that, they split again and then the encoder sees the data he encodes it and he sends the encoded string to the decoder, and the decoder has to decode it again.",
            "So if you think of it in that way, then if the encoder would simply pick the code which minimizes the code length of the given data, it's clear that the decoder would not be able to decode the data because the decoder gets an encoded string, but the decoder doesn't know what code the encoder used, so if he doesn't know what code the encoder used mean, the decoder knows to set curly L, they might have agreed on that before seeing the data, but he doesn't know the element of L. It's best for the data because the decoder doesn't know the data.",
            "That's why it needs to decode it.",
            "So therefore the decoder cannot decode the message if the encoder encodes it like this.",
            "So now the question is, well, apparently we cannot do as well as this.",
            "But can we do nearly as well?",
            "And the answer is yes.",
            "So there exist codes such that no matter what date that you get.",
            "You always encode the sequence nearly as well as the best particular code for that particular sequence.",
            "And intuitively I'll give a formal definition later, but intuitively, codes with this property.",
            "Are called Universal codes, so universal is a bit strange here, because universal means universal relative to the universe.",
            "Curly L. So Curly Ellis is your universe.",
            "Your set of codes to which you compare yourself.",
            "You want to have a new quote which is no matter what data you get as good as or almost as good as the best code in curly L."
        ],
        [
            "So here's a simple code.",
            "Suppose a simple example.",
            "Suppose Curly L is finite.",
            "Then you always have some codes such that no matter what data you get, the number of bits you need to encode the data is smaller or equal than the number of bits you need to use any codes in the set plus a constant.",
            "So if N is large, then this constant will be negligible compared to this, because this as we said, typically increases linearly in N. So then you're actually doing a good job.",
            "Because this holds for all codes in the set also.",
            "In particular, it holds for the codes which minimizes the particular sequence you get.",
            "So how can you construct such a code?",
            "Well, it's very simple.",
            "You basically first encode, so you list.",
            "All the coats in here.",
            "Let's say there M of them.",
            "So then the list goes from one to M and then you first encode the number M using a uniform code and that takes you log N bits, right?",
            "If you do it the way we coded ABCD here with the same number of bits for each outcome, you can quote an element of a set with M elements by law gambits.",
            "So then K will be log M where M is the number of elements.",
            "In a set Curly L and then no matter what data you get your overhead compared to the best code for the data is log M and that holds no matter how long the data sequence is.",
            "So for long data sequence that's quite nice."
        ],
        [
            "So now we make the crucial jump from universal codes.",
            "So what has been called universal models?",
            "So suppose I have a set of probability distributions now and now we're getting a bit closer to statistics machine learning a probabilistic model.",
            "But for the moment we will still assume that it's finite.",
            "Later we will look at more realistic infinite models.",
            "So using basic notation I can describe my model like this.",
            "It is M Elements Theatre, one to see to M. So we've just seen that there always exists a code.",
            "Relative to a set of code such that I have overheads finite overheads.",
            "K compared to the best code in that set.",
            "So now what I'm going to do is I'm going to turn this set of distributions into a set of codes.",
            "By the trick I described earlier, so each of these distributions induces a quote, so set for all outcomes.",
            "The code length is minus lock.",
            "The probability of the outcome.",
            "So this means that if I turn this into a set of codes.",
            "I can now construct a new code.",
            "Which, no matter what outcomes I get the number of bits I need is more equal and minus log probability of the outcome according to any of these thetas plus K, where cable again be.",
            "For example log M. Um so.",
            "This is the universal code.",
            "And now I can also map this back again to distribution, and that is called a universal model or universal distribution and information theory literature.",
            "And what I do here is I met this code back to a distribution.",
            "So because for me I can do that for any code.",
            "There must also be a distribution such that fallout comes minus log probability of the outcome small equal to minus log probability of the outcome according to any theater plus a constant overhead.",
            "So if I exponentiate on both sides, this means that this distribution is actually dominates.",
            "This set of distributions there is some constant such that no matter what outcomes I get the probability assigned to this sequence is larger equal then the constant times the probability I assigned to theater for any theater in my model, and such a distribution which dominates the set of distribution is called a universal model or universal distribution for the sets M."
        ],
        [
            "So now something about terminology smaller sites, so there's some confusing here, because when I call this set Curly MA model, that's common terminology in statistics.",
            "So a model is a family of distributions, but information theory there weren't model is used to single distribution, and universal model is an information theoretic concept, so a universe.",
            "So there I use information theoretic terminology.",
            "So when I say a universal model, I really mean a single distribution.",
            "But this is single distribution which acts as a representative for a set of distributions and said that it dominates it and the set of distributions.",
            "Confusingly, I also call a model."
        ],
        [
            "So now we've already seen one example of universal models, and this was basically this worked.",
            "If you looked at it in terms of quotes by coding in two stages.",
            "First, you code an index of a set of quotes, and then you quote the data using the code with the index you just encode it.",
            "But, and this is a crucial inside, again, there are many more universal models and that is 2 part way of coding is just one way of doing it, and actually often not the cleverest way.",
            "So another way which may be familiar to most of you is coding by using a base in mixture.",
            "So suppose I have some prior distribution over my set for my model.",
            "My set of distributions.",
            "Then I can define the base and marginal distribution.",
            "Or marginal likelihood in this case, but it defines the distribution because if you sum it overall sequences it becomes one.",
            "So that's the weighted average of the probability of the data according to theater times the prior of the theater, right?",
            "This is the common vision way to define a distribution over sequence of data."
        ],
        [
            "No.",
            "This distribution defines a universal model relative to the set Curly M. Because we have the following for all outcomes, full length for all theater in a set curly M We have the code length.",
            "If you quoted data using the code corresponding to this basic distribution.",
            "So that's minus lock.",
            "The probability of this distribution is by definition minus log.",
            "The size of this sum this average.",
            "Now some is larger than each of its terms, so minus log of sum is smaller than each of its terms.",
            "So this must be smaller, equal and minus lock.",
            "The probability of the data according to particular Theta minus lock.",
            "The prior of theater.",
            "And this holds for all theater in your set.",
            "So this means that the code length if you code using the code corresponding to the base and distribution is smaller equal in the code length corresponding to any individual element in your set of distributions.",
            "Plus a term which does not depend on N, so this makes it universal again because if N is large this remains constant.",
            "And you see that in the end you're doing essentially as well as the best distribution in your model, because this holds for all theater, in particular, the theater which fits your data best, which gives the highest probability and therefore the smallest code length with hindsight."
        ],
        [
            "To your data.",
            "So let's compare this to the previous Universal Coach we've seen, in which we will now yes.",
            "Called the biggest fight was to motivate the mixture models for large men's teams.",
            "Not really, I'm just saying like the goal here is to compress data as as good as possible compared to some set of codes.",
            "And I'm saying you can do this in different ways.",
            "So one way is to code in two stages.",
            "First you code an index and then you code data with the code corresponding to that index and another way is to 1st define a mixture distribution.",
            "So the first map, the codes to distributions, then the final mixture distributions and then map that back to code.",
            "That's another way of achieving the same goal, and because what will happen now is we will see two more ways of achieving the same goal and then we will start comparing them.",
            "So now I'm comparing this Bayesian method for constructing a code with the two part method where you do it in two stages.",
            "And so of course you can extend this two part method also, so using a prior on the set of T tests, because each distribution on a set of theaters in user code for encoding the thetas with code length minus lock prior of Theta.",
            "So then if you quote the data by first coding the theater, which maximizes the probability of the data.",
            "So giving the index of this data and then coding the data using the Theta so with.",
            "With length minus log probability according to this theater head.",
            "Then the total length you get in this two part code will be minus lock the prior.",
            "Of the theater which fits the data best minus lock, the probability of the data according to the theater which fits the data best, and which therefore also gives the smallest code length to the data according to all seats are in your model.",
            "So know that if we use a uniform prior, this is just what we've seen before.",
            "For example, we have four distributions, then with a uniform prior, each one gets probability 1/4 and then minus log.",
            "1/4 is 2.",
            "We need 2 bits to encode each possible seater, but again we can do this for general priors."
        ],
        [
            "So.",
            "If you compare this to the basic code, you see that the base mixture is strictly better in the sense that it assigns larger probability and therefore smaller code linked to some outcomes and no.",
            "And never smaller probability to know outcomes.",
            "Why is that so well noted with the two part code, we need exactly this number of bits to code a sequel."
        ],
        [
            "But with the basing code.",
            "We need minus log of this.",
            "Some bits and at smaller equal than this.",
            "This is what we need with the two part code.",
            "Fertitta heads, but this holds for all theater, in particular for Theta Hat.",
            "So this means that here we have a smaller equal, and if the other terms in the sum are not zero, and actually this will be strictly the sum will be strictly larger than each of its terms, so this minus log of the sun will be strictly smaller than each of its terms.",
            "So then the basin coding using the basic distribution will give you strictly shorter code length encoding using the two part distribution.",
            "So then using base for coding.",
            "So again this works bye.",
            "Viewing the coaches distributions.",
            "Making a mixture distributions.",
            "An mapping that vector code that's strictly better than coding in two stages."
        ],
        [
            "So.",
            "But now we've seen that there.",
            "So there are two different ways of doing this.",
            "Universal coding.",
            "One of them seems to be better than the other.",
            "But now maybe we want to extend this further.",
            "Maybe there's even more ways to do universal coding and then we should also ask ourselves what do we really mean by better in general.",
            "And also we might want to know what prior should we use in general.",
            "Should we use a uniform prior or another prior and this depends of course on what we mean by what does it mean for a code to be better than?"
        ],
        [
            "I want.",
            "So.",
            "Now we're actually going to define better in a particular way, which I'm allies much of modern MDL, which is a minimax way.",
            "So if we have a model, a set of distributions.",
            "We can always look at given the data.",
            "What would have been the best code to use with hindsight after having seen the data?",
            "And that is the code corresponding to the maximum likelihood parameter for the data which maximizes the probability and therefore minimizes the code length.",
            "So this is the code in the beginning I told you.",
            "Suppose an encoder just simply sensor data using the code with which gives you the shortest coding for the data.",
            "That doesn't really work because the decoder doesn't know how to decode the data, but if he could do so counter factual, then you would get this code length.",
            "But this code length is not feasable.",
            "Instead you have to use a real code which can be decoded, and by this Kraft inequality we know that that also has to correspond to some distribution, so there must be some piece so.",
            "The code he uses correspond to some distribution piece star such that for each outcome the code length is equal to minus lock, P star of the data.",
            "And because this holds for each code.",
            "We have such a piece star finding the best code amounts to finding the best piece star and what we're going to do is.",
            "We're going to look for the P star such that the overhead you have compared to the best code with hindsight is as small as possible.",
            "In the worst case where the worst case is taken over all data sequences, so for each particular data sequence you can look at what is the worst possible overhead between this thing code you want to use and the code which is best with hindsight after having seen the data.",
            "So you can of course construct the code such that this number is negative for some data, so this code will give a smaller code linked to some data.",
            "Then the best code in your candidate sets, but then it will be very large for some other data, and in the worst case this must always be a positive number.",
            "So and now you look for the P star which minimizes this worst case quantity.",
            "So this piece starts when you transform into a quote is the minimax optimal universal model, or universal code to be used for coding data relative to the set of candidate codes?",
            "Now the question is, can you somehow compute?"
        ],
        [
            "HP star and surprisingly you can.",
            "At least you can get a nice formula for it, whether you can actually use that formula in practice is a quite different question.",
            "And it's it's called the start of our normalized maximum likelihood distribution.",
            "So it turns out that the solution.",
            "To this equation, the piece star which minimizes the worst case coding overhead.",
            "Is give as accurate as a unique solution?",
            "If this has a solution at all, if the worst case is not infinite, the solution looks like this, so it's a distribution over sequences.",
            "Which assigns to each sequence the probability of that sequence according to the maximum likelihood distribution.",
            "Of course, if you add this overall sequences, you get something larger than one.",
            "Because for each sequence you assign.",
            "The probability according to the best fitting distribution in the model.",
            "So if there's more than one distribution in your model, your set of distributions, if there's just one, this will sum to once.",
            "If there's more.",
            "I wanted to sum to something larger than one, which is again a restatement of the fact that you cannot quote by simply sending a distribution which best fits the data.",
            "So you need to normalize this and you do that simply by dividing this by the sum over all sequences of the probability of that sequence according to the best fitting distribution.",
            "For that sequence.",
            "And clearly if you normalize in this way, you get a distribution.",
            "If you now summit overall outcomes, it becomes one.",
            "Now, why does this solve this?",
            "Well, it's actually quite easy to see if you plug this in here you get minus log of this probability, and then because minus log of a fraction is minus log of this plus lock of this, plus luck of the denominator.",
            "So then the minus lock.",
            "This cancels with this if minus log, this minus minus look the same thing and what remains is the log of this song.",
            "So if you plug this in here you get the lock of this sum.",
            "And let some doesn't depend on the data itself, so it's constant over all possible data sequences.",
            "Now, if you would use any other distribution here.",
            "Then, um.",
            "Because the distribution must sum to one.",
            "If it's not the same distribution, it must give smaller probability to at least one sequence, and if it gives smaller probability to at least one sequence, then for that particular sequence.",
            "This must be larger, right?",
            "Because if you plug in this, it's a constant.",
            "So that's why this gives you the minimax optimal universal."
        ],
        [
            "What?",
            "So now I can finally find MDL.",
            "At least one version for model selection and that works where we just have two models and one M2.",
            "So think about these for example as a first order in a second order Markov model for your data.",
            "And now according to this modern version of MDL, if you want to select between those two models for the same data.",
            "You should pick the model for which the associated optimal universal model.",
            "So that's this normalized maximum likelihood model assigns the largest probability to the data, or equivalently, you pick the model which gives the smallest code link to the data.",
            "If you use the minimax optimal universal code relative to the model.",
            "So.",
            "I only did this for finite models, but exactly the same thing can be done for infinite models.",
            "In a moment we will see how and then this becomes actually practically useful thing to do."
        ],
        [
            "So let's look at this again.",
            "So we have two models and we select the one which minimizes the code length.",
            "According to this universal code.",
            "An so if we recall that this is a fraction.",
            "Of the probability according to the maximum likelihood divided by the sum over all sequences of the probability according to the maximum likelihood for that sequence.",
            "So the minus log of a fraction is equal to minus log of the numerator plus lock of the denominator.",
            "So we select the model for which this sum is smallest, and now you can think of this sum as the trade off which is familiar in other model selection methods.",
            "Like AIC MBC, a tradeoff between goodness of fits and complexity.",
            "So if the best fitting distribution in your model fits the data better, then this will be larger.",
            "So minus log of this will be smaller.",
            "On the other hand, if the complexity of your model.",
            "Is larger and complexity here means that it can fit more patterns?",
            "Well, that as we will see, roughly corresponds to how many parameters to model has.",
            "Then this term will get larger, so this term, the richer the model is, the more data patterns that can fit, and therefore the more risk you have overfitting the larger this term will be.",
            "So how large is this term for finite models, well?",
            "We've already seen if you have a finite model with M elements.",
            "This term must be bounded by the lock of the number of elements, because we've already seen, I can always quote the data with the two part code, where the overhead for each.",
            "Outcome is log M right?",
            "It's by simply encoding the index of the maximum likelihood distribution fees ahead by a uniform code which takes log N bits.",
            "So here we have the same overhead for every particular sequence because we know there's a code with overhead lock M. This particular overhead must be smaller than log M and in a moment."
        ],
        [
            "We'll see how much smaller.",
            "So another questions, of course.",
            "Does this make any sense this nor this?",
            "Using this normalized maximum likelihood distribution to compare models and to try to convince you that it does, I'll give four interpretations of it.",
            "And actually, the first interpretation I already gave.",
            "Basically what you do is if you believe as an axiom.",
            "This MDL idea that it's good to select the model which allows for the shortest code length of the data.",
            "Then I already have.",
            "I mean then you have to believe that.",
            "But if you believe that, then there's a clear motivation already.",
            "Because what we do here is exactly that we select the model which allows you for the most compression of the data.",
            "And to formalize that idea, we associate each model set of distributions with the code, and we do that in such a way that all distributions within the model are treated on an equal footing.",
            "Of course, we can associate a code to encode data with the model in an arbitrary way, but we did it in a way that's at the overhead we have.",
            "We have to whatever distribution in the model is a good code for the data is as small as possible, and note, and this makes it really different from any other approach to machine learning and statistics that I know of.",
            "This is done in a worst case setting not worst case over distributions that might generate the data, but worst case over data.",
            "So it's really important to realize that I haven't talked for one second about things which generate data.",
            "I have taken no expectations, they don't exist here.",
            "We use distributions only.",
            "To encode data and not as something from which data might come here.",
            "And we then look at how good these distributions are.",
            "In the worst case overall data sequences.",
            "So we make no assumptions about where the data comes from at all, at least when defining our model later, when we, when defining our method later, we're going to prove that the method works well in some cases.",
            "Then we will make such assumptions, but for now we haven't made those assumptions at all.",
            "We want to use codes which work well no matter what data we get.",
            "So now the second interpretation has something to do with this complexity term, and it turns out you can give that a kind."
        ],
        [
            "Accounting or geometric interpretation.",
            "So turns out you can think of this as something like the total fit your model assigns to the data, or equivalently the lock, not of the number of elements in your model.",
            "If the model is finite, it would be this M and we've already seen it's more equal than log of the number of elements, but something like the effectiveness."
        ],
        [
            "Distribution, So what is that?",
            "So if I look not at the lock of this complexity term, but the term itself.",
            "I can rewrite it this some in two separate terms I can take to some overall fetus in my model and then some offer old data for which that particular Theta fits the data best.",
            "The probability of the data according to this, and this is simply the same.",
            "So I partitioned the set of all sequences into those sequences which have the same maximum likelihood estimator.",
            "So now I can be right.",
            "This of course is to some overall theater.",
            "My model of the probability according to see to that I get a sequence for which theater is actually the maximum likelihood estimator.",
            "And this is of course the sum of all Theta of 1 minus the probability that I get a sequence for which data is not the maximum likelihood estimator.",
            "According to theater, so this is the probability according to theater, that the data look as if they do not come from theater.",
            "Think of a very simple model, let's say a Bernoulli model with just four elements.",
            "The probability of one is 0.2 zero point 4, zero point 6 or 0.8.",
            "If the frequency of ones is approximately 0.4.",
            "Then and you look at the terminus some with thetas .2, then this is the probability that you get some sequence, for example with the frequency of 0.4 or even larger such that the Theta hat is not equal to 0.2.",
            "So.",
            "Now this you can now pull this one out of the sum, and if this is a final, this is simply the number of distributions and here you get a strictly negative term.",
            "Which you might call the amount of confusion in your model.",
            "So this is the probability according to theater that the maximum likelihood estimator is not theater.",
            "The probability according to.",
            "See to that you get an atypical sequence with, which doesn't look like theater sums overall theater.",
            "And if N gets large and the set of distributions is finite, this will go to zero exponentially fast, and then this becomes dominant.",
            "And then this is equal to M and then this complexity is simply the number of distributions in your model, but.",
            "If the sample is not too large and some of the distributions are close to each other, for example, if you have one distribution is Bernoulli 0.5 and the other is 0.501, then they give almost the same probability to all data sequences.",
            "And then essentially, this term will be pretty large.",
            "And then this will become substantially smaller.",
            "Then M the number of distribution so and if two distributions are precisely the same.",
            "So if you have four distributions, but two of them are the same, then this will actually become equal to something smaller than three.",
            "So effectively this sum is not the number of distributions, but the number of effective distributions at the given sample size.",
            "The number of distributions which based on the data you can distinguish from each other with high probability, so that justifies calling it a complexity complexity of your model.",
            "And in fact, if you know the Rademacher complexity in computational learning theory, you see that there are some similarities there."
        ],
        [
            "This notion of complexity."
        ],
        [
            "So now we finally go to infinite models and we will see we can extend this idea of thinking of the complexity as a kind of log number of distributions to this infinite setting.",
            "So now think for example M is.",
            "A Markov chain of a particular order, and we compare Markov chains of different order or it's.",
            "Let's say Gaussian mixture of a particular order and we compare different number of mixture components.",
            "It turns out that under regularity conditions on these models, basically, if the parametrization is smoother, she if they're exponential families, then this holds.",
            "We can rewrite this as syntactically like this, so this is the thing we are comparing for different models.",
            "We take the model for which this is smallest.",
            "And for large and this turns out to be equal to this.",
            "So this is actually we've already seen this term, because this is just a fraction.",
            "And it's minus log.",
            "This plus lock of this enormous sum overall data sequences.",
            "So this is actually the lock of that enormous sum.",
            "So it turns out under assumptions on the model that this sum can be rewritten as K over to log in, where K is the number of free parameters.",
            "Plus lot of some complicated thing.",
            "Which I will not go into here in detail, but so I Theta is a quantity called the Fisher information.",
            "In statistics and what you do here is you integrate the Fisher information.",
            "Overall Theta over the model.",
            "And then there's a remainder term which goes to zero as N goes to Infinity.",
            "So note that this term does not depend on N, so as N gets large it becomes negligible compared to this term, which usually increases linearly and this term, which increases logarithmically.",
            "And note again this.",
            "So that means for large the complexity term, which is this plus this for large and in the complexity term the number of parameters becomes the dominant issue.",
            "The more parameters you have, the more degrees of freedom.",
            "The more complex the model."
        ],
        [
            "So now let's compare this to the BICS criterion, which is an approximation of base and model selection, which is used a lot in practice according to the BICS.",
            "Given a set of models.",
            "With different number of parameters you should select the model which minimizes minus log probability according to maximum likelihood plus K over to log in.",
            "So if you compare it to this, you see that it's almost the same, except for this last term.",
            "So first of all, this means that if you have two models with the same number of parameters which fit the date about equally well so that this term is about equal, you cannot use BSE to distinguish between them.",
            "Here you can use, you can use this to distinguish between them and you can get in general something very different, because this may be very different from model to model.",
            "So also the very first version of MDL, which unfortunately.",
            "Pete Petree specifically asked me to emphasize this.",
            "Unfortunately there are still people in Yuan and Acnl communities who do this and say it's MDL that was actually.",
            "I think already in 82 written and started doing other things, but so this is really very old.",
            "But you see it's kind of an approximation of this."
        ],
        [
            "So.",
            "Now it turns out that this term, how should we interpret it?",
            "This modification to the BI?",
            "See it's something like a curve."
        ],
        [
            "Your term.",
            "Let's see if I have a."
        ],
        [
            "Should we worry about the little old one?",
            "Yes.",
            "So in practice, I think you don't want to use this in practice.",
            "You want to actually calculate really calculate this or approximated because even though this is much more precise than the BI see, I've seen several examples where this little of 1 where basically for small sample sizes this is very bad approximation.",
            "So again, this is just to get insights an not to be used in practice.",
            "Although people use it in practice, but I tend to be skeptical about that.",
            "Sorry.",
            "German is also constant.",
            "Yeah, so for small N it does yes.",
            "You said that the little 01 goes to 0, then goes to Infinity, right?",
            "Not a little of one over end or something like that.",
            "Actually it is, I think so.",
            "I just wasn't precise about its large oh of 1 / N I think yes.",
            "But it's.",
            "I would have to check whether it's something like that, I think.",
            "Yeah, so let me say something about why this is called curvature term.",
            "App.",
            "Suppose.",
            "Suppose I have the binary data and I have a first order Markov model.",
            "So then I have two parameters.",
            "So this is the probability that the next outcome is a one, given that the previous outcome was a zero.",
            "And this is the probability that the next outcome is 1 given that the previous outcome was one that defines a first order Markov model.",
            "For binary sequence of data.",
            "And I can think of the Bernoulli model as a 1 dimensional sub model of this which looks like this.",
            "But because then both probabilities have to be the same for each Bernoulli model, the data independent according to some theater probability of 1 between zero and one.",
            "This is diagonal line.",
            "So here I have two parameter Maulana one parameter model.",
            "Now I can also define another one parameter model embedded in the 2nd order Markov model, which would look something like this.",
            "So this model also can be parameterized by just one real value parameter, so it is a one parameter model.",
            "But if you look at it you see that for every distribution in a second order in the 1st order model.",
            "The two parameters there is a one, an element of the one parameter model which is close to it, at least in Euclidean distance.",
            "So you would expect that this model.",
            "It's a lot more like the model with two parameters, then this model, so both have one parameter, But this one resembles the two parameters a lot more.",
            "An confit, random data, a lot better.",
            "So indeed, this normalized maximum likelihood term will be much larger for this model.",
            "And that will translate itself in this term being larger."
        ],
        [
            "So now let's compare this to base and model selection.",
            "So in base so called base factor model selection.",
            "If you ignore the priors on the models, which usually can.",
            "You simply pick the model which maximizes the marginal likelihood of the data.",
            "So you have this is this average we've seen before the integral, now over the probability of the data according to Theta integrated by the prior density of Theta.",
            "And you can look at that for each model and then you pick the model for which this.",
            "Integrated probabilities largest.",
            "So minus locally integrated probability smallest.",
            "That's what based on model selection does.",
            "So you can also approximate this by Laplace approximation, so it's basically a Taylor expansion.",
            "And if you do that and it turns out that again under conditions on the model, this turns out to be equal to this.",
            "So you see, it's almost the same as this, so base there's something very similar for minimum description length, so normalized maximum like Minimum Scription, Inc.",
            "In particular, you see that these terms they do not depend on the sample size.",
            "So for large N base will do the same as MDL if the number of models you compare.",
            "It's finite.",
            "So how does this term relate to this term then?",
            "Well, you see that in base what happens depends on your prior of course base depends on the prior.",
            "And basically what you see here.",
            "This is the prior.",
            "Of theater evaluated at the maximum likelihood an basically if you are lucky and the maximum likelihood turns out to be the region of parameter space to which you gave a high prior probability.",
            "So your prior assumptions were kind of correct.",
            "Then this term will be small because the prior density of the maximum likelihood parameter will be large and you will give a large probability to the data.",
            "If however, you are unlucky and you gave a small prior to what turns out to be the probability maximizing Theta, then this will be the probability will be smarter.",
            "Smaller and minus log probability will be larger, so this depends on your prior.",
            "And of course, some basins, so-called objective basis, have proposed priors which you can use if you don't have any clear prior knowledge."
        ],
        [
            "And the most famous of these is the so-called Jeffreys prior.",
            "Which is defined.",
            "By the square root of the determinant of the Fisher information matrix.",
            "Usually if you did, if you integrate it over all theater, it doesn't become one but something larger.",
            "So you have to normalize it to make it a probability.",
            "So this is what sometimes objective Bayesians advocate to user model selection.",
            "Or if you plug this in here.",
            "Then you see that you get minus lock.",
            "Of the square root of the Fisher information and they are here plus log of the square root of the fish information they cancel and what remains is plus log of the denominator.",
            "So you get plus lock of this.",
            "So then you see that they actually become the same up to small order of 1.",
            "So if you use Jeffreys prior, then asymptotically base and MDL based on normalized maximum likelihood become actually the same."
        ],
        [
            "So, Interestingly, this Jeffreys prior was proposed in 1939 as a kind of uniform prior not on the space of parameters, but on the space of distributions.",
            "So the space of parameters depends on your parameterization is essentially arbitrary.",
            "But the space of distributions can be defined in a more generic manner.",
            "Men are, and if you put a uniform prior on that and use base.",
            "You get essentially the same as MDL, at least in the simple setting we're talking about here.",
            "In more general settings, it turns out you don't always get the same.",
            "Because, for example if you have non parametric if using a non parametric settings then with some priors you will actually not compress your data.",
            "So then there are some instances of base which cannot be thought of as MDL.",
            "Because they don't lead to compression of the data."
        ],
        [
            "So, um.",
            "Given the time, I will skip these less so I will just talk about these two."
        ],
        [
            "So there's a certain very important interpretation of what we've been doing, which is the so called predictive or pre krenchel interpretation.",
            "So.",
            "If you quotes, you can always.",
            "You can also look at what happens outcome by outcome.",
            "And then you can think of the minus log probability assigned to an outcome as a loss function.",
            "So you can just think of probabilities as prediction strategies, and then one reasonable way to measure how good they are on a particular outcome is by looking at the minus log of the probability assigned to the outcome.",
            "If you assign probability one to the outcome, then minus log one is 0, so your loss is 0.",
            "If you assign probability zero, your loss will be infinite, but you can also think of this is.",
            "If you use the distribution as a code, then it's a number of bits you need to encode that particular outcome.",
            "So if your goal is compressed, the data as much as possible, this is a logical loss function to use.",
            "Now it turns out that if you use base to sequentially predict data.",
            "Anne.",
            "Then it turned.",
            "Then you get you can look at the cumulative loss.",
            "So that's the sum of these individual log losses.",
            "And it turns out that that is the same as the code length you need.",
            "If you code with base the whole data.",
            "So what does that mean?",
            "Well, this is what we've seen before you have the base universal code.",
            "So it's a basic mixture distribution.",
            "You can turn it into a code and then this is the code length you get for each particular outcome.",
            "Now you can also use base sequentially to predict outcomes, so you have you predict the first outcome using the base predictive distribution for that.",
            "Then you observe the first outcome.",
            "You predict the second outcome using the conditional distribution given the first outcome and you have a certain log loss.",
            "Then you predict the third outcome using the conditional distribution based on the 1st two outcomes, you predict the 4th outcome using the conditional distribution based on the 1st three outcomes etc.",
            "And you Add all the losses.",
            "So this is what you do.",
            "You add the sum of these losses, but you always predict using base condition on the previous outcomes.",
            "Of course, by the definition of logarithm closed, this is equal to this.",
            "Now, because the sum of a logarithm is the log of the product.",
            "And this condition is equal to this fraction.",
            "This is equal to this.",
            "And now if you write out this product it is infectors, then everything cancels.",
            "It's called telescoping.",
            "Because if you then on the diagonal all these things start canceling and this is the only thing that remains.",
            "So this means that the sum of the loss if you use base for sequential prediction is actually equal to the code length you get for the whole sequence if you encode it using the base encode."
        ],
        [
            "So no, an idea.",
            "Which goes back to 1984.",
            "Is you too Phil Davidson?",
            "Germer istenem.",
            "Is that if you look at what it is based in predictive distribution, you see that for large N it resembles more and more the maximum likelihood distribution.",
            "For example, if you use a uniform prior with the Bernoulli model and the maximum likelihood distribution given, let's say S once in a sample of N is as divided by N. So maximum likelihood would be this number of ones divided by the total number of outcomes and the base and predictive distribution would be S + 1 / N + 2.",
            "This is so cool.",
            "Also called in the plus estimator, so it's almost the same.",
            "So.",
            "Anne.",
            "This conditional distributions really starts to look like.",
            "The maximum likelihood distribution given the past.",
            "So this suggests that you can actually approximate this patient distribution by this distribution, or actually by any other reasonable estimator.",
            "It doesn't have to be the maximum likelihood estimator."
        ],
        [
            "And it turns out that you can do this.",
            "So in general there are some slight caveats here, which I'll skip.",
            "You can if you use the maximum likelihood at each point.",
            "And you sequentially predict the future and you Add all the losses.",
            "Then the total loss you get.",
            "Is equal to the best prediction you could have made with hindsight, so with hindsight, after you've seen all the data given your model, then you should have predicted with heat ahead all the time that would have given you the smallest.",
            "Total, the largest total probability.",
            "Therefore, the smallest total loss.",
            "But instead you used always the maximum likelihood estimator based on the past because she didn't see the future and the overhead you get by not knowing the future is K over to Logan plus order one.",
            "So this means the central term, which doesn't depend which depends on any still K over to Logan where case number of parameters.",
            "So this means that you can use this sequential maximum likelihood scheme.",
            "Also, as a universal code and you can try to do model selection based on this.",
            "Sequential prediction strategy.",
            "So another way to view this is that if you do M DL, it's something like selecting the model which has the smallest accumulated lock prediction error.",
            "If you use the model to sequentially predict the future given the past.",
            "This holds for all data sequences or in expectation this actually does not hold for all data sequences.",
            "So I've been a bit sloppier.",
            "This holds.",
            "It depends on what models you're using, but in general this this is a weaker statement.",
            "It holds an expectation if one of the distributions in your models is true.",
            "K is the number of parameters.",
            "Distributions.",
            "Well with the set, so this of course it's ahead test to something to do with the distributions.",
            "Um?",
            "So if you have a large set.",
            "K is larger then of course you will get a different different things will happen.",
            "You will overfit more.",
            "Right?",
            "And the number of parameters if that's the same level parameters, right?",
            "So the number of parameters is not so important for the complexity when the sample size is small, but if you fix the number of parameters and at the sample size goes to Infinity then it becomes dominant.",
            "In determining how many extra bits you need compared to the best.",
            "An distribution in your model to encode the data."
        ],
        [
            "So note that in this view the MDL procedure is very similar to cross validation.",
            "Leave one out cross validation with one essential difference and leave one out cross validation.",
            "You use the whole sample except one point to predict at one point.",
            "You do that for all points and you add the total loss you make and then you pick the model with the smallest total loss.",
            "Here you also predict all points, but at each time you only base your prediction on the past data and not on all other data.",
            "And Interestingly, you see that asymptotically leave one out cross validation works like AIC.",
            "It tends to select more complex models.",
            "Then then MD LR base.",
            "Where is this progression validation where you don't use the future, you only use the past to make your predictions.",
            "Well, we've already seen that.",
            "It's like MDL.",
            "So not surprisingly, it behaves like BIC."
        ],
        [
            "So final important thing is that in practice, of course we want to compare often an infinite number of models.",
            "Um?",
            "So if you do that, you cannot just pick the model maximizing this probability, or minimizing minus log of this probability, and so this is basically the final really crucial point to know very important.",
            "What we want.",
            "Is we want to cast?",
            "Learning in terms of data compression.",
            "So the way we do this in MPLS always we start by designing a coat which we can use to encode all data sequences.",
            "And then based on that code, we make inferences.",
            "Now, if our goal is not model selection but just prediction.",
            "We can start with the code, turned it into a probability distribution and then use that probability distribution for sequentially predicting the future given the path.",
            "That's what you've just seen.",
            "But if we want to learn actual models or parameters.",
            "Then we have to make sure that we don't just quote the data given those models, but we also quote the models themselves so.",
            "If we do this.",
            "If we want to select a model to explain the data, we should really minimize, not the code length of the data given the model.",
            "But the total code length code length of the data given the model plus code length of the model.",
            "If you only compare a finite number of models, then usually you take a uniform code because you want to be as honest as possible here.",
            "So then this thing will be the same for all models and it doesn't play any role in a minimization and you basically.",
            "Pick them all, minimizing this.",
            "That's what we've done so far.",
            "But if you have an infinite number of models than this, we can become important.",
            "So if you add this term then your procedure is actually based on a code for coding all data sequences.",
            "And so now in practice usually this term, even with an infinite set of models, will not have a large influence.",
            "But you can use quotes here, which for which the code length increases only very slowly with I, so something called the universal code for the integers for which this will be approximately log I + 2 log log.",
            "I.",
            "So that goes up.",
            "Very slowly.",
            "And then typically this.",
            "So if the model M Supply has I parameters, then there will be a term ioffer to log in here which will completely dominate this term.",
            "So then this is not really important, but in some cases it is important.",
            "For example, if you do variable selection in regression and sometimes the number of models you consider at a sample size of N. Is about 2 to the N rather than something smaller than N. And if it's two to the end, then this term can be really large and you really need to include it.",
            "So note now that with this addition.",
            "The whole procedure starts to look really quite like base, also because you can think of this L again as minus log of a prior.",
            "And basically what you want to do is you want to specify a prior or for models.",
            "And then you want to code the data using those models.",
            "But the big difference to base.",
            "Is that the way we specify quotes or the way we specify distributions doesn't necessarily have to go in terms of priors?",
            "But here, because we want to use a two part code here, it's natural to use a prior.",
            "But if we code the data given the model.",
            "Then there is no need to quote any parameters.",
            "Actually it's wasteful to code parameters, you're just interested in coding the data and then we want to basically say we want to integrate out the parameters, But then we might.",
            "We can do this in a basin with the prior, but we actually sometimes prefer to do it in other ways because they might save us some extra bits."
        ],
        [
            "So as I said, if you.",
            "Want to quote data given the models most, you could use that again using a two part code for your first explicitly called parameters and then the most given the parameters.",
            "But that's wasteful because we've seen that is normalized.",
            "Maximum likelihood could always give shorter code links and you want to minimize code lengths.",
            "But if you want to encode the model index, you have to use a two part code because the model index is what you want to instruct extract from your inference procedure.",
            "If you do model selection, you may not be interested in parameters.",
            "You're only interested in the model structure.",
            "Sometimes you are interested in parameters, then you want to encode them explicitly as well.",
            "But in order to make predictions, you don't need to know the parameters.",
            "It's enough to have these universal distributions because you can use them to make predictions of the future given the past."
        ],
        [
            "So now I'll end by saying."
        ],
        [
            "A bit about other things you'll see today.",
            "So anyway, I call this modern MDL, but by now it's more than 10 years old and in the last few years there have been quite a lot of new developments.",
            "Which basically put much of this story on its head, but there was no time to adjust the tutorial completely to that.",
            "And so one thing is that you of course you have noticed that this normalized maximum likelihood involves some offer enormously many terms.",
            "It's in the number of terms in the sum is exponential in the sample size.",
            "So it turns out nevertheless, that for some models you can actually compute the sum in time linear in a sample size, so that's nice and rather surprising.",
            "So this means you can actually do this.",
            "Which is of course important.",
            "So there is 1 talk.",
            "Of course you can do it anyway if you use approximations by this, for example, this prick wenczel method, but you predict sequential by maximum likelihood that can often be implemented, and it's a good approximation of MDL.",
            "But if you want to really the optimal thing and a mouse thing, you can do this in some cases as well.",
            "So patriarchy will talk about this today.",
            "So then the real big issue of all this was that for many even very simple model classes like, let's say linear regression, Gaussian models, this animal distribution is undefined.",
            "So this denominator, which is the sum or if you have continuous data, the integral over all data sequences of the probability according to maximum likelihood is infinite, and then it's undefined.",
            "So what do you do then?",
            "You can somehow do use a different sub optimal universal model, but Ascentia Lee in the last two years.",
            "Kind of generic solution has been found, that's the so called luckiness principle.",
            "I'll have one more slide about that.",
            "And then there is.",
            "Another way of dealing with this, which is called sequential, NML that's actually new development by your Morrison, but unfortunately he couldn't be here today, so I think Tommy Sealander will talk about that.",
            "Then there are some interesting developments in.",
            "If you use this for nonparametric inference with Gaussian process models.",
            "So basically you can use this to explain the success of some basic nonparametric models and also explain the failure of some other basic nonparametric models.",
            "And then there were some things I said which basically.",
            "Puts the whole thing on his head, so note that asymptotically this MDL behaves like BIC.",
            "Now it's well known that in some cases be icy is not the best model selection procedure there is.",
            "There are other model selection procedure which leads to better predictions of future data when used for prediction and they essentially a sense of asymptotically behave like AIC, another model selection criteria.",
            "So the question is, can you?",
            "What's going on here?",
            "Why is there another thing which is sometimes really better, and it turns out that this is something to do with the notion of universality we adopted.",
            "Here.",
            "We assign quotes to models so that no matter what data we get, we want to do as best as the best distribution in your model.",
            "And it turns out that if you try to be not if you try it, you can sometimes be even better than the best distribution in your model.",
            "And if you redefine universality in such a way that you can achieve that.",
            "Then you get different notion of up these procedures and my invite to talk, but I will cast it in non MDL terms to get a larger audience but my invited talk it called in UI tomorrow will be about that.",
            "Yeah, according to the schedule.",
            "Is that possible?",
            "I am I so when is my talk according to the Schedule 1040?",
            "OK then that's good to know.",
            "OK, so it's 1040 thanks.",
            "Well, better, better did I'm there earlier than that I'm there late, of course."
        ],
        [
            "So.",
            "Final slides.",
            "What if this MD else on this normalized maximum likelihood is undefined?",
            "So lots of solutions have been proposed in the literature for that, some better than others.",
            "But the question is, is there a generic solution?",
            "And it seems that there is and what we can do is we can say, OK, this is the ordinary normalized maximum likelihood.",
            "So we compare.",
            "We try to find a distribution which is as close as possible to the maximum likelihood distribution, which is the same thing as a distribution which minimizes the code length of hindsight.",
            "Now we say if the distribution doesn't exist which minimizes this coding overhead.",
            "In the worst case.",
            "We there might still exist some distribution which has a non uniform overhead, so the overhead is allowed to depend on the parameter.",
            "For some parameters you will be lucky and you get a small overhead if that parameter turns out to be the maximum likelihood parameter.",
            "For other parameters you will be unlocking, you get a larger overhead.",
            "So if we have some luckiness function which expresses how bad we feel about a certain theater being the maximum likelihood how bad that is for us.",
            "Then often this is defined after all.",
            "Again, if a theater is uniform, we get the origonal maximum likelihood normalized maximum likelihood bed.",
            "But if we take it non uniform then essentially you can do this for many models for which the ordinary normalized maximum likelihood is undefined and you get a luckiness normalized maximum likelihood distribution which looks like this and this again turns out to be asymptotically equivalent.",
            "To a Bayesian universal distribution, not with Jeffreys prior, but with some kind of tilted Jeffreys prior.",
            "So this place similar role to a subjective prior in basing statistics.",
            "But there are also some subtle differences because essentially there are many things you can do with priors in base which you're not allowed to do with this luckiness function here, and this luckiness function, it doesn't have to be to really describe a belief so high a theater doesn't really mean that you think theaters improbable.",
            "It may also mean that you think theater is not interesting.",
            "If the maximum likelihood is close to theater, then I don't care about my model anyway, because I cannot make good predictions with it, so I can forget about that Theta, so.",
            "A theater is like a prior, but there are some subtle differences.",
            "But still, if you introduce this subjective element, is a theater, you can essentially extend this definition of normalized maximum likelihood to arbitrary parametric and nonparametric models.",
            "So that's where I think a lot of future research will go to, so this is taken a bit.",
            "That's it.",
            "It's taking a bit longer than expected.",
            "But still, I think there's time for some questions here.",
            "So any questions at this point?",
            "As Peter said, if you want some some kind of.",
            "Issues that you would like to see us discuss during the panel goals with team here."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Thanks very much.",
                    "label": 0
                },
                {
                    "sent": "Poetry and thanks for.",
                    "label": 0
                },
                {
                    "sent": "Having me here in Helsinki.",
                    "label": 0
                },
                {
                    "sent": "So this will be a tutorial which starts from scratch, so I do not assume that you know any information theory.",
                    "label": 0
                },
                {
                    "sent": "And for this reason, for some people here in the room, I know no information theory, so I apologize to them because a large part of the tutorial will be about some basic information theoretic notions.",
                    "label": 0
                },
                {
                    "sent": "Please feel free to interrupt me if you have any technical questions.",
                    "label": 0
                },
                {
                    "sent": "If you have, say, more questions about philosophy, complicated questions, you can also write them down and then hand them over to Tim Tim from elephant.",
                    "label": 0
                },
                {
                    "sent": "Because in the afternoon we will have a panel discussion and actually we hope that some people will bring up some interesting issues to talk about them, so keep that in mind when you listen to this.",
                    "label": 0
                },
                {
                    "sent": "So this talk is called introduction to modern MD El Universal modeling, and this is something which still many people don't know.",
                    "label": 1
                },
                {
                    "sent": "That Emil comes from something comes from an ocean in information theory called universal coding or Universal Modeling, and that is what I'm going to talk about.",
                    "label": 0
                },
                {
                    "sent": "Most actually.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So what I'm going to do the following.",
                    "label": 0
                },
                {
                    "sent": "First I give you a general introduction to.",
                    "label": 0
                },
                {
                    "sent": "General introduction.",
                    "label": 0
                },
                {
                    "sent": "About the ideas underlying MDL an.",
                    "label": 0
                },
                {
                    "sent": "Then, in order to introduce this concept of universal coding and Universal Modeling, I need to say something and that's the information theory part about how probability distributions relate to code lengths and vice versa.",
                    "label": 0
                },
                {
                    "sent": "Then I'll introduce this universal models and then I can define MDL model selection and then I'll talk about four different ways to interpret it and I'll end with a brief overview of some of the new developments in MDL that will be discussed later today.",
                    "label": 1
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So first introduction.",
                    "label": 0
                },
                {
                    "sent": "So minimum description length is a method for learning from data statistics, machine learning.",
                    "label": 1
                },
                {
                    "sent": "It has been mostly developed and suited for problems of model selection, but you can also use it to do prediction estimation or any of the other kinds.",
                    "label": 0
                },
                {
                    "sent": "Of inference usually associated with statistics.",
                    "label": 0
                },
                {
                    "sent": "So by model selection I mean the problem where you don't just try to learn parameters from the data, but also structure like you have X&Y data you're trying to find a function which describes the relationship between X&Y.",
                    "label": 0
                },
                {
                    "sent": "And you want to find, for example, the best polynomial arbitrary degree.",
                    "label": 0
                },
                {
                    "sent": "To fit the data.",
                    "label": 0
                },
                {
                    "sent": "So then you always have to compromise the complexity of the model you're looking at and the goodness of fit.",
                    "label": 0
                },
                {
                    "sent": "Otherwise you will be over fitting in a terrible way, and that's what M Neal does.",
                    "label": 0
                },
                {
                    "sent": "It's kind of a generic way to avoid overfitting.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And the underlying idea is based on a correspondence between regularity in data and ability to compress the data.",
                    "label": 0
                },
                {
                    "sent": "So the idea is that the more you are able to compress a sequence of data, the more regularity you have detected in the data.",
                    "label": 0
                },
                {
                    "sent": "So, for example, suppose I have a sequence of 300,000 zeros and ones and it's like 001001001, etc.",
                    "label": 0
                },
                {
                    "sent": "So it's 100,000 fold repetition of 001.",
                    "label": 0
                },
                {
                    "sent": "Now if this idea is to make any sense, then I should be able to describe the sequence in a very short way and the questions.",
                    "label": 0
                },
                {
                    "sent": "Can I do that?",
                    "label": 0
                },
                {
                    "sent": "Well, in fact, I've already done it because I've told you a recipe in just one sentence of natural language, which allows you to write out the sequence in full.",
                    "label": 0
                },
                {
                    "sent": "But if you would write it out in full.",
                    "label": 0
                },
                {
                    "sent": "Then it will take you the whole blackboard, so I've already compressed it using natural language.",
                    "label": 0
                },
                {
                    "sent": "And of course if you want to do this with the computer, you have to use some computer language.",
                    "label": 0
                },
                {
                    "sent": "But the idea is clear.",
                    "label": 0
                },
                {
                    "sent": "If there is a pattern in a sequence, you can somehow exploit that pattern to compress the sequence.",
                    "label": 0
                },
                {
                    "sent": "Now, on the other hand, again, if the idea is to make any sense, then what is intuitively a random sequence should not be compressible.",
                    "label": 0
                },
                {
                    "sent": "So imagine that here are hundred thousands bits generated by independent throws of a fair coin.",
                    "label": 0
                },
                {
                    "sent": "Then we should not be able to compress this data and as we will see in a moment, actually this is the case with very high probability.",
                    "label": 0
                },
                {
                    "sent": "We cannot compress this data no matter what coding method we use.",
                    "label": 0
                },
                {
                    "sent": "And I'll explain the.",
                    "label": 0
                },
                {
                    "sent": "I'll explain the motive.",
                    "label": 0
                },
                {
                    "sent": "I'll explain the reason why that is so in a moment, but the general thing to remember here is that if you have data samples completely randomly by fair coins, then no matter what coding method you use, you cannot compress it very much.",
                    "label": 0
                },
                {
                    "sent": "So more formally, the probability that you can compress such a data sequence by more than K bits is smaller than two to the minus K, so even compressing it by 20 bits is probability smaller than two to the minus 20, which is one in a billion.",
                    "label": 0
                },
                {
                    "sent": "So it goes down to zero very very quickly and in a moment.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "With that for you.",
                    "label": 0
                },
                {
                    "sent": "So the next step is to say, then OK, we're going to.",
                    "label": 0
                },
                {
                    "sent": "Equate finding regularity in data with compressing the data and then we say the more regularity we found, the more we've learned about the data.",
                    "label": 0
                },
                {
                    "sent": "So inductive inference is seen here is trying to find regularity's in data and then of course in the next step you can use this to make predictions about future data.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So that's the basic idea.",
                    "label": 0
                },
                {
                    "sent": "And as I say set, this will mostly be applied to model selection problems, and I'll also focus on that in this talk.",
                    "label": 0
                },
                {
                    "sent": "So suppose you have some data and various models, and the question is which model best explains the data.",
                    "label": 1
                },
                {
                    "sent": "So this could be as I said, like trying to find the best polynomial which fits the data where if these are pairs actually of X&Y pairs, each outcome then and you have an outcomes.",
                    "label": 0
                },
                {
                    "sent": "Then there will always be a polynomial of degree in which fits them perfectly, but you don't want to select that because it will probably give very bad predictions of future data.",
                    "label": 1
                },
                {
                    "sent": "So somehow you need to trade off error and complexity of the models.",
                    "label": 0
                },
                {
                    "sent": "MDL does that for you.",
                    "label": 0
                },
                {
                    "sent": "Of course you can also use this to for example, try to find the best order of a Markov chain if your data is text and you want to model it using some Markov chain question Switch user 1st order model or a second order model with more dependencies.",
                    "label": 0
                },
                {
                    "sent": "The higher the order, the more parameters you have.",
                    "label": 0
                },
                {
                    "sent": "In MDL can be used to select the number of parameters.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So you might have noticed this tutorial is called introduction to modern amneal so.",
                    "label": 0
                },
                {
                    "sent": "There I should say something more about that.",
                    "label": 0
                },
                {
                    "sent": "So what I'm referring to is what most people in the MDL community call MDL, and that was basically the first time stated.",
                    "label": 0
                },
                {
                    "sent": "That way in an overview article by Baron, Reason and you from 1998.",
                    "label": 0
                },
                {
                    "sent": "So recently is the founder of MDL and you can feel, for example, resonance.",
                    "label": 0
                },
                {
                    "sent": "Older versions of MDL is kind of approximations of this modern type.",
                    "label": 0
                },
                {
                    "sent": "So recent and actually introduced MDL in the 1970s.",
                    "label": 0
                },
                {
                    "sent": "In the beginning with a rather simple instantiation.",
                    "label": 0
                },
                {
                    "sent": "But the idea or similar ideas in fact, much older, so there's also something called minimum message length, which goes back to 1968, which is somewhat different, but the underlying idea trying to model by data compression is the same.",
                    "label": 0
                },
                {
                    "sent": "And then there's also a version of MDL based on Kolmogorov complexity, which is also being called Ideal MDL, but which is actually quite different from what I'm going to talk about here.",
                    "label": 1
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So now for the second part, in order to introduce me like first have to say how probabilities encode length 3.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Date.",
                    "label": 0
                },
                {
                    "sent": "So first I'm going to define to you what I mean by a code.",
                    "label": 0
                },
                {
                    "sent": "So suppose I have some set of outcomes.",
                    "label": 0
                },
                {
                    "sent": "Let's assume it's countable, so you can.",
                    "label": 0
                },
                {
                    "sent": "Typically this will be actually the set of all vectors of some given length N in some particular space.",
                    "label": 0
                },
                {
                    "sent": "So think of it as the space as possible outcomes of a statistical experiment with a given sample size.",
                    "label": 0
                },
                {
                    "sent": "Now a code to encode such sequences of outcomes is a one to one map from the set of outcomes to the binary sequences of length one or longer.",
                    "label": 0
                },
                {
                    "sent": "At.",
                    "label": 0
                },
                {
                    "sent": "So this code C is a function which Maps every outcome or actually sequence of outcomes to a binary string.",
                    "label": 0
                },
                {
                    "sent": "And that string is in the code of the original data.",
                    "label": 0
                },
                {
                    "sent": "And the following notation is crucial.",
                    "label": 0
                },
                {
                    "sent": "I always use this notation so if I once I have a coat, I use notation L, sub C of X to denote the number of bits needed to describe X.",
                    "label": 1
                },
                {
                    "sent": "So if I encode X using a code word of five bits and this will be 5 for example, or if I use something with seven bits.",
                    "label": 0
                },
                {
                    "sent": "It will be 7 right?",
                    "label": 0
                },
                {
                    "sent": "So this is not the code word itself, but only its length.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Now let's go back to.",
                    "label": 0
                },
                {
                    "sent": "So let's say something about probability distributions on a countable sets.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "We know, of course, that the sum overall outcomes of the probability of an outcome of that outcome must be one and.",
                    "label": 0
                },
                {
                    "sent": "Making it into a weaker statement, smaller, equal and one that holds for every probability distribution.",
                    "label": 0
                },
                {
                    "sent": "So one way of thinking about that is that most outcomes must have very small probability.",
                    "label": 0
                },
                {
                    "sent": "What do I mean by that?",
                    "label": 0
                },
                {
                    "sent": "Well, you can have only two outcomes with probability at most 1/2 you can have only four outcomes with probability at most 1/4 you can have only eight outcomes with probability at most 1/8 etc right, because otherwise you don't sum to you don't sum to one.",
                    "label": 0
                },
                {
                    "sent": "If you have more than eight outcomes probability 18 you some to something larger than one.",
                    "label": 0
                },
                {
                    "sent": "So if you have, let's say 1024 outcomes, then almost all of them must have probability smaller equal and 1 / 1024.",
                    "label": 0
                },
                {
                    "sent": "So now if we look at Coates, it turns out that a similar phenomenon occurs.",
                    "label": 0
                },
                {
                    "sent": "So suppose we want to encode sequences of some length M binary sequences.",
                    "label": 0
                },
                {
                    "sent": "So in this special case we met binary sequences to other binary sequences.",
                    "label": 0
                },
                {
                    "sent": "Now of course there are only two sequences of length one only four sequences of length two, only eight of length three, etc.",
                    "label": 0
                },
                {
                    "sent": "But there are two to the M sequences of length M, so the fraction of sequences that can be compressed to an encoding of length one is very small.",
                    "label": 0
                },
                {
                    "sent": "Only two of the two 2D M sequences can be compressed to an encoding of length one.",
                    "label": 0
                },
                {
                    "sent": "Only four can be compressed and encoding of length two etc.",
                    "label": 0
                },
                {
                    "sent": "So in general, the fraction that can be compressed by more than K bits is less than the number of sequences with N -- K bits divided by the number of sequences with ambit.",
                    "label": 1
                },
                {
                    "sent": "So that's two to the minus K. So in this sense, only very few symbols can have a small code length.",
                    "label": 0
                },
                {
                    "sent": "So note that codes in this talk and any MD Ellen general quotes are always uniquely decodable codes, so this means that if we have encoded something, we must always be able to decode the original data from which the encoding came, so you cannot have two different data sequences mapping to the same code words, and therefore they can really be only two things with code word, one because you cannot map different things to the same code word.",
                    "label": 0
                },
                {
                    "sent": "So now I can also explain to you the reasoning of the very first slide, where I said that if you have a random sequence generated by tosses of a fair coin that you cannot compress it with very high probability.",
                    "label": 0
                },
                {
                    "sent": "You're suppose you have a sequence of data sequence of length M in binary.",
                    "label": 0
                },
                {
                    "sent": "Now if that is generated by fair coin tosses, then the probability of each sequence will be the same.",
                    "label": 0
                },
                {
                    "sent": "It will be 2 to the minus M. So then the probability of a subset of size 2 to the N -- K. Will be at most two to the minus K right?",
                    "label": 0
                },
                {
                    "sent": "Because all of them have probably 2 to the minus M. If you take 2 to the N -- K of them, the total probability of such a set will be 2 to the minus K. So therefore the probability that the actual sequence you get is in a set which you can compress by K bits or more is at most two to the minus K. And this holds for every K, and this holds also for every code.",
                    "label": 0
                },
                {
                    "sent": "If the distribution is uniform, then no matter what code you used.",
                    "label": 0
                },
                {
                    "sent": "The data won't be compressible with very high probability.",
                    "label": 0
                },
                {
                    "sent": "Because being able to compress means being able to map the set of all sequences to a very small subset thereof.",
                    "label": 0
                },
                {
                    "sent": "So, but back to the probabilities.",
                    "label": 1
                },
                {
                    "sent": "So we see that if you have a probability distributions, then most outcomes must have very small probability, and if you have a quote, the most outcomes must have a large code length.",
                    "label": 0
                },
                {
                    "sent": "So this suggests some kind of.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Knology and that analogy can actually be formalized, and that's the celebrated craft inequality which you write down here in a slightly different form from what is usual, but it's equivalent.",
                    "label": 0
                },
                {
                    "sent": "It says the following.",
                    "label": 0
                },
                {
                    "sent": "Suppose I have a uniquely decodable code, or for countable sets.",
                    "label": 1
                },
                {
                    "sent": "Then no matter what the code is, there's always a distribution on outcomes such that for all outcomes, the number of bits I need to encode the outcome is minus lock.",
                    "label": 0
                },
                {
                    "sent": "The probability of the outcome.",
                    "label": 0
                },
                {
                    "sent": "A very simple example is when I use a uniform code.",
                    "label": 0
                },
                {
                    "sent": "So for example, there are four possible outcomes and I encode each of these by two bits.",
                    "label": 0
                },
                {
                    "sent": "So for example.",
                    "label": 0
                },
                {
                    "sent": "The set of outcomes is this an I in code.",
                    "label": 0
                },
                {
                    "sent": "AS00 and BA01.",
                    "label": 0
                },
                {
                    "sent": "Etc.",
                    "label": 1
                },
                {
                    "sent": "So then every outcome is 2 bits.",
                    "label": 0
                },
                {
                    "sent": "And indeed, there exists a distribution for outcomes which has probability minus log 2, which is 1/4, right?",
                    "label": 0
                },
                {
                    "sent": "I always use binary logarithm.",
                    "label": 0
                },
                {
                    "sent": "So two is the number of bits.",
                    "label": 0
                },
                {
                    "sent": "Then 1/4 is the probability, so I'm not making any claims here.",
                    "label": 0
                },
                {
                    "sent": "The data are distributed according to this P. I'm just saying if I start with the code, I can always make a distribution such that this holds for all outcomes, yes?",
                    "label": 0
                },
                {
                    "sent": "Sorry.",
                    "label": 0
                },
                {
                    "sent": "Oh, I'm getting through that.",
                    "label": 0
                },
                {
                    "sent": "So I cheated a little bit and that's it.",
                    "label": 0
                },
                {
                    "sent": "May be that this code that this distribution is defective, which means that it doesn't sum to one but something smaller than one.",
                    "label": 0
                },
                {
                    "sent": "So the crucial thing is that it never gets larger than one.",
                    "label": 0
                },
                {
                    "sent": "An an actually defective more or less you get a defective distribution if the code is not efficient in a way if there exists a code which gives to every outcome.",
                    "label": 0
                },
                {
                    "sent": "No outcome, a longer code length into some outcomes are strictly shorter code length then you.",
                    "label": 0
                },
                {
                    "sent": "Then you will get a defective distribution.",
                    "label": 0
                },
                {
                    "sent": "So the let's say the nontrivial thing about this is that this also holds if the codes are not uniform.",
                    "label": 0
                },
                {
                    "sent": "So here we use a code which is the same code link for all outcomes.",
                    "label": 0
                },
                {
                    "sent": "But this says that you can do this for all uniquely decodable codes, even if they don't assign the same code length to all outcomes, yes.",
                    "label": 0
                },
                {
                    "sent": "Search for talking about at least supposed to be prefix free codes?",
                    "label": 0
                },
                {
                    "sent": "Or is that not require?",
                    "label": 0
                },
                {
                    "sent": "It's actually good question.",
                    "label": 0
                },
                {
                    "sent": "Yes and no so.",
                    "label": 0
                },
                {
                    "sent": "Everything gets much easier if you say they must be prefix free codes.",
                    "label": 0
                },
                {
                    "sent": "But if you only require them to be uniquely decodable.",
                    "label": 0
                },
                {
                    "sent": "Then it turns out that, but then you have to define in a very precise way what you mean by uniquely decodable.",
                    "label": 0
                },
                {
                    "sent": "I just said uniquely decodable is 1 to one, but there's.",
                    "label": 0
                },
                {
                    "sent": "You need a more restrictive definition.",
                    "label": 0
                },
                {
                    "sent": "Then it turns out that if you that basically there is a one.",
                    "label": 0
                },
                {
                    "sent": "So if you have a uniquely decodable code with certain lengths.",
                    "label": 0
                },
                {
                    "sent": "For all outcomes, then there's also a prefix free code with the same length.",
                    "label": 0
                },
                {
                    "sent": "So therefore.",
                    "label": 0
                },
                {
                    "sent": "You can restrict to prefix free codes with.",
                    "label": 0
                },
                {
                    "sent": "Without loss of generality.",
                    "label": 0
                },
                {
                    "sent": "So let me brief you, briefly give you an example of a non where where you can see how this might work in a nonuniform case.",
                    "label": 0
                },
                {
                    "sent": "So suppose we just have three outcomes.",
                    "label": 0
                },
                {
                    "sent": "Then we might encounter like this say 10111.",
                    "label": 0
                },
                {
                    "sent": "At least for me.",
                    "label": 0
                },
                {
                    "sent": "Oh so.",
                    "label": 0
                },
                {
                    "sent": "Does this help or?",
                    "label": 0
                },
                {
                    "sent": "Or not.",
                    "label": 0
                },
                {
                    "sent": "I'll do it.",
                    "label": 0
                },
                {
                    "sent": "Sell it.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So here we have a quote which is uniquely decodable.",
                    "label": 0
                },
                {
                    "sent": "Because the decoder can always decode when he sees this, what was the original code word?",
                    "label": 0
                },
                {
                    "sent": "And you see here that.",
                    "label": 0
                },
                {
                    "sent": "You need one bit to encode a.",
                    "label": 0
                },
                {
                    "sent": "So then this will correspond to.",
                    "label": 0
                },
                {
                    "sent": "Now it gets harder to OK.",
                    "label": 0
                },
                {
                    "sent": "So here you get probability 1/2.",
                    "label": 0
                },
                {
                    "sent": "And he will get probability 1/4.",
                    "label": 0
                },
                {
                    "sent": "So you see that again you have 1/2 and 1/4 and 1/4 and it adds to one.",
                    "label": 0
                },
                {
                    "sent": "So to this code there's also a corresponding distribution which always assigns.",
                    "label": 0
                },
                {
                    "sent": "Such that for every outcome.",
                    "label": 0
                },
                {
                    "sent": "Code length is minus log the probability.",
                    "label": 0
                },
                {
                    "sent": "The Kraft inequality says you can always do that with uniquely decodable codes.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "But so now you can also go the other way.",
                    "label": 0
                },
                {
                    "sent": "So now we start with a distribution on a countable set.",
                    "label": 1
                },
                {
                    "sent": "And then no matter what distribution we start with, there always exist some code such that for all outcomes you have the number of bits you need to encode the outcomes.",
                    "label": 1
                },
                {
                    "sent": "Is equal to minus log probability of the outcome rounded up to the nearest integers, because codes must always be bits.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So if you combine these two things and this is really the most important insight.",
                    "label": 0
                },
                {
                    "sent": "There is, in order to understand the Omni literature, there is so one to one correspondence between probability distributions and code link functions such that small probabilities correspond to large code lengths and vice versa.",
                    "label": 1
                },
                {
                    "sent": "So now I'm looking at data sequences or forgiven length if I have a coat with some length function then there always is a distribution such that the lengths are equal to minus log probability.",
                    "label": 0
                },
                {
                    "sent": "If I have a probability then there always is a code such that this holds.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So, for example, suppose you have data and you look at some candidate explanation of the data, so you don't know if the data is generated by the distribution.",
                    "label": 0
                },
                {
                    "sent": "You only think of it.",
                    "label": 0
                },
                {
                    "sent": "Maybe that is a good distribution to explain my data.",
                    "label": 0
                },
                {
                    "sent": "For example, of 1st order Markov chain.",
                    "label": 0
                },
                {
                    "sent": "So now what happens is that distribution might fit the particular data you have more or less well.",
                    "label": 0
                },
                {
                    "sent": "And basically.",
                    "label": 0
                },
                {
                    "sent": "If you change the distribution to a coat, then the better the distribution fits the data, the shorter the corresponding code length will be.",
                    "label": 0
                },
                {
                    "sent": "So every distribution gives you a prescription on how to make a certain code, and that code will give a short code length to those things.",
                    "label": 0
                },
                {
                    "sent": "Which have a high likelihood under the distribution.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So note, once again I keep saying it there is no assumption here that data are sampled from any distribution.",
                    "label": 1
                },
                {
                    "sent": "This is a purely formal correspondence between two different mathematical notions.",
                    "label": 0
                },
                {
                    "sent": "Namely, probability distributions.",
                    "label": 1
                },
                {
                    "sent": "But here a probability distribution is simply a function on a space which is always non negative and which sums to one and code link functions.",
                    "label": 0
                },
                {
                    "sent": "Second thing is you can also do this if you have continuous outcome spaces by discretizing inappropriate way.",
                    "label": 1
                },
                {
                    "sent": "So I will gloss over all the details there and from now on in this talk when I refer to a distribution or actually a mass function, I will sometimes also mean a density by that.",
                    "label": 0
                },
                {
                    "sent": "And then note that in a less light.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I forgot about this integer requirement, so I didn't round up to the nearest integer.",
                    "label": 0
                },
                {
                    "sent": "And this is something that is usually done and that can be justified, because usually if N is not one but a little bit larger than the probabilities you assign to sequences, they tend to decrease exponentially in N. So the minus log of the probability increases linearly, and then if you neglect this round off.",
                    "label": 0
                },
                {
                    "sent": "Affect then the area makes at most one bit, which will typically be negligible compared to the total length.",
                    "label": 0
                },
                {
                    "sent": "And if you do that, you get a much nicer mathematical theory and also you get a theory which becomes independent of the alphabet in which you encode things.",
                    "label": 0
                },
                {
                    "sent": "So you would like a theory where there's a always an easy mapping between coding things in binary or coding things internally alphabet.",
                    "label": 0
                },
                {
                    "sent": "And for this reason from now on we will neglect the integer requirement and we will talk about idealized codes.",
                    "label": 0
                },
                {
                    "sent": "So these are codes we will if we start from arbitrary distribution, we will call.",
                    "label": 0
                },
                {
                    "sent": "This still a code link function, even if it is non integer length.",
                    "label": 0
                },
                {
                    "sent": "This is a common thing in information theory actually if you read information theory papers you sometimes see that people use the word quote and distribution simply interchangeably.",
                    "label": 0
                },
                {
                    "sent": "And when they talk about codes and they speak about and they refer to distributions, they mean the distribution which is connected to the code by this equality.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is about the correspondence between probability distributions and code link functions.",
                    "label": 0
                },
                {
                    "sent": "And now we're going to use that to define universal models and to define you.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "First models we start with universal codes.",
                    "label": 1
                },
                {
                    "sent": "So for the time being, forget forget that this is a talk about machine learning.",
                    "label": 0
                },
                {
                    "sent": "We will only be talking about data compression for a few slides now.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "And we will talk basically about the method underlying most modern lossless data compressors, which is called universal coding.",
                    "label": 0
                },
                {
                    "sent": "And the idea is as follows.",
                    "label": 0
                },
                {
                    "sent": "So suppose you want to encode some data and you have a set of different codes available for doing that.",
                    "label": 0
                },
                {
                    "sent": "And you want to compress the data as much as possible.",
                    "label": 0
                },
                {
                    "sent": "That's your goal.",
                    "label": 1
                },
                {
                    "sent": "You think that some of the quotes in the set Curly L, the set of candidate codes will actually do a good job.",
                    "label": 0
                },
                {
                    "sent": "They will compress the data a lot.",
                    "label": 0
                },
                {
                    "sent": "So now the goal is to encode the data using the minimum possible number of bits based on the set of candidate codes L. So how is she?",
                    "label": 1
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "If we do that, well, the obvious idea is to simply code the data using the code in a set of codes which minimizes the code length of that particular data.",
                    "label": 0
                },
                {
                    "sent": "So no, that's because I'm not interested in how the actual encoding is done.",
                    "label": 0
                },
                {
                    "sent": "I identified the codes with their length functions, so this is this curly L is.",
                    "label": 0
                },
                {
                    "sent": "I call it a set of codes, but really is, it's a set of length functions corresponding to these codes, which for each outcome give you the number of bits needed to encode that outcome.",
                    "label": 0
                },
                {
                    "sent": "So the obvious idea to pick the code which minimizes the length doesn't work.",
                    "label": 0
                },
                {
                    "sent": "Why doesn't it work well to see that you have to realize that coding and decoding can always be viewed as a game between an encoder and a decoder, where the encoder and a decoder meet before seeing any data to be encoded, and they agree on a protocol they agree on their quote.",
                    "label": 0
                },
                {
                    "sent": "So after they've agreed on that, they split again and then the encoder sees the data he encodes it and he sends the encoded string to the decoder, and the decoder has to decode it again.",
                    "label": 0
                },
                {
                    "sent": "So if you think of it in that way, then if the encoder would simply pick the code which minimizes the code length of the given data, it's clear that the decoder would not be able to decode the data because the decoder gets an encoded string, but the decoder doesn't know what code the encoder used, so if he doesn't know what code the encoder used mean, the decoder knows to set curly L, they might have agreed on that before seeing the data, but he doesn't know the element of L. It's best for the data because the decoder doesn't know the data.",
                    "label": 0
                },
                {
                    "sent": "That's why it needs to decode it.",
                    "label": 0
                },
                {
                    "sent": "So therefore the decoder cannot decode the message if the encoder encodes it like this.",
                    "label": 0
                },
                {
                    "sent": "So now the question is, well, apparently we cannot do as well as this.",
                    "label": 0
                },
                {
                    "sent": "But can we do nearly as well?",
                    "label": 0
                },
                {
                    "sent": "And the answer is yes.",
                    "label": 0
                },
                {
                    "sent": "So there exist codes such that no matter what date that you get.",
                    "label": 0
                },
                {
                    "sent": "You always encode the sequence nearly as well as the best particular code for that particular sequence.",
                    "label": 0
                },
                {
                    "sent": "And intuitively I'll give a formal definition later, but intuitively, codes with this property.",
                    "label": 0
                },
                {
                    "sent": "Are called Universal codes, so universal is a bit strange here, because universal means universal relative to the universe.",
                    "label": 1
                },
                {
                    "sent": "Curly L. So Curly Ellis is your universe.",
                    "label": 0
                },
                {
                    "sent": "Your set of codes to which you compare yourself.",
                    "label": 0
                },
                {
                    "sent": "You want to have a new quote which is no matter what data you get as good as or almost as good as the best code in curly L.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So here's a simple code.",
                    "label": 0
                },
                {
                    "sent": "Suppose a simple example.",
                    "label": 0
                },
                {
                    "sent": "Suppose Curly L is finite.",
                    "label": 0
                },
                {
                    "sent": "Then you always have some codes such that no matter what data you get, the number of bits you need to encode the data is smaller or equal than the number of bits you need to use any codes in the set plus a constant.",
                    "label": 0
                },
                {
                    "sent": "So if N is large, then this constant will be negligible compared to this, because this as we said, typically increases linearly in N. So then you're actually doing a good job.",
                    "label": 0
                },
                {
                    "sent": "Because this holds for all codes in the set also.",
                    "label": 1
                },
                {
                    "sent": "In particular, it holds for the codes which minimizes the particular sequence you get.",
                    "label": 0
                },
                {
                    "sent": "So how can you construct such a code?",
                    "label": 1
                },
                {
                    "sent": "Well, it's very simple.",
                    "label": 0
                },
                {
                    "sent": "You basically first encode, so you list.",
                    "label": 0
                },
                {
                    "sent": "All the coats in here.",
                    "label": 0
                },
                {
                    "sent": "Let's say there M of them.",
                    "label": 0
                },
                {
                    "sent": "So then the list goes from one to M and then you first encode the number M using a uniform code and that takes you log N bits, right?",
                    "label": 0
                },
                {
                    "sent": "If you do it the way we coded ABCD here with the same number of bits for each outcome, you can quote an element of a set with M elements by law gambits.",
                    "label": 0
                },
                {
                    "sent": "So then K will be log M where M is the number of elements.",
                    "label": 0
                },
                {
                    "sent": "In a set Curly L and then no matter what data you get your overhead compared to the best code for the data is log M and that holds no matter how long the data sequence is.",
                    "label": 0
                },
                {
                    "sent": "So for long data sequence that's quite nice.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So now we make the crucial jump from universal codes.",
                    "label": 0
                },
                {
                    "sent": "So what has been called universal models?",
                    "label": 1
                },
                {
                    "sent": "So suppose I have a set of probability distributions now and now we're getting a bit closer to statistics machine learning a probabilistic model.",
                    "label": 1
                },
                {
                    "sent": "But for the moment we will still assume that it's finite.",
                    "label": 0
                },
                {
                    "sent": "Later we will look at more realistic infinite models.",
                    "label": 1
                },
                {
                    "sent": "So using basic notation I can describe my model like this.",
                    "label": 0
                },
                {
                    "sent": "It is M Elements Theatre, one to see to M. So we've just seen that there always exists a code.",
                    "label": 1
                },
                {
                    "sent": "Relative to a set of code such that I have overheads finite overheads.",
                    "label": 0
                },
                {
                    "sent": "K compared to the best code in that set.",
                    "label": 0
                },
                {
                    "sent": "So now what I'm going to do is I'm going to turn this set of distributions into a set of codes.",
                    "label": 0
                },
                {
                    "sent": "By the trick I described earlier, so each of these distributions induces a quote, so set for all outcomes.",
                    "label": 0
                },
                {
                    "sent": "The code length is minus lock.",
                    "label": 0
                },
                {
                    "sent": "The probability of the outcome.",
                    "label": 0
                },
                {
                    "sent": "So this means that if I turn this into a set of codes.",
                    "label": 0
                },
                {
                    "sent": "I can now construct a new code.",
                    "label": 0
                },
                {
                    "sent": "Which, no matter what outcomes I get the number of bits I need is more equal and minus log probability of the outcome according to any of these thetas plus K, where cable again be.",
                    "label": 0
                },
                {
                    "sent": "For example log M. Um so.",
                    "label": 1
                },
                {
                    "sent": "This is the universal code.",
                    "label": 0
                },
                {
                    "sent": "And now I can also map this back again to distribution, and that is called a universal model or universal distribution and information theory literature.",
                    "label": 0
                },
                {
                    "sent": "And what I do here is I met this code back to a distribution.",
                    "label": 1
                },
                {
                    "sent": "So because for me I can do that for any code.",
                    "label": 0
                },
                {
                    "sent": "There must also be a distribution such that fallout comes minus log probability of the outcome small equal to minus log probability of the outcome according to any theater plus a constant overhead.",
                    "label": 0
                },
                {
                    "sent": "So if I exponentiate on both sides, this means that this distribution is actually dominates.",
                    "label": 0
                },
                {
                    "sent": "This set of distributions there is some constant such that no matter what outcomes I get the probability assigned to this sequence is larger equal then the constant times the probability I assigned to theater for any theater in my model, and such a distribution which dominates the set of distribution is called a universal model or universal distribution for the sets M.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So now something about terminology smaller sites, so there's some confusing here, because when I call this set Curly MA model, that's common terminology in statistics.",
                    "label": 0
                },
                {
                    "sent": "So a model is a family of distributions, but information theory there weren't model is used to single distribution, and universal model is an information theoretic concept, so a universe.",
                    "label": 1
                },
                {
                    "sent": "So there I use information theoretic terminology.",
                    "label": 0
                },
                {
                    "sent": "So when I say a universal model, I really mean a single distribution.",
                    "label": 0
                },
                {
                    "sent": "But this is single distribution which acts as a representative for a set of distributions and said that it dominates it and the set of distributions.",
                    "label": 1
                },
                {
                    "sent": "Confusingly, I also call a model.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So now we've already seen one example of universal models, and this was basically this worked.",
                    "label": 1
                },
                {
                    "sent": "If you looked at it in terms of quotes by coding in two stages.",
                    "label": 0
                },
                {
                    "sent": "First, you code an index of a set of quotes, and then you quote the data using the code with the index you just encode it.",
                    "label": 0
                },
                {
                    "sent": "But, and this is a crucial inside, again, there are many more universal models and that is 2 part way of coding is just one way of doing it, and actually often not the cleverest way.",
                    "label": 0
                },
                {
                    "sent": "So another way which may be familiar to most of you is coding by using a base in mixture.",
                    "label": 0
                },
                {
                    "sent": "So suppose I have some prior distribution over my set for my model.",
                    "label": 0
                },
                {
                    "sent": "My set of distributions.",
                    "label": 0
                },
                {
                    "sent": "Then I can define the base and marginal distribution.",
                    "label": 1
                },
                {
                    "sent": "Or marginal likelihood in this case, but it defines the distribution because if you sum it overall sequences it becomes one.",
                    "label": 0
                },
                {
                    "sent": "So that's the weighted average of the probability of the data according to theater times the prior of the theater, right?",
                    "label": 0
                },
                {
                    "sent": "This is the common vision way to define a distribution over sequence of data.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "No.",
                    "label": 0
                },
                {
                    "sent": "This distribution defines a universal model relative to the set Curly M. Because we have the following for all outcomes, full length for all theater in a set curly M We have the code length.",
                    "label": 1
                },
                {
                    "sent": "If you quoted data using the code corresponding to this basic distribution.",
                    "label": 0
                },
                {
                    "sent": "So that's minus lock.",
                    "label": 0
                },
                {
                    "sent": "The probability of this distribution is by definition minus log.",
                    "label": 0
                },
                {
                    "sent": "The size of this sum this average.",
                    "label": 0
                },
                {
                    "sent": "Now some is larger than each of its terms, so minus log of sum is smaller than each of its terms.",
                    "label": 0
                },
                {
                    "sent": "So this must be smaller, equal and minus lock.",
                    "label": 0
                },
                {
                    "sent": "The probability of the data according to particular Theta minus lock.",
                    "label": 0
                },
                {
                    "sent": "The prior of theater.",
                    "label": 0
                },
                {
                    "sent": "And this holds for all theater in your set.",
                    "label": 0
                },
                {
                    "sent": "So this means that the code length if you code using the code corresponding to the base and distribution is smaller equal in the code length corresponding to any individual element in your set of distributions.",
                    "label": 0
                },
                {
                    "sent": "Plus a term which does not depend on N, so this makes it universal again because if N is large this remains constant.",
                    "label": 0
                },
                {
                    "sent": "And you see that in the end you're doing essentially as well as the best distribution in your model, because this holds for all theater, in particular, the theater which fits your data best, which gives the highest probability and therefore the smallest code length with hindsight.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "To your data.",
                    "label": 0
                },
                {
                    "sent": "So let's compare this to the previous Universal Coach we've seen, in which we will now yes.",
                    "label": 0
                },
                {
                    "sent": "Called the biggest fight was to motivate the mixture models for large men's teams.",
                    "label": 0
                },
                {
                    "sent": "Not really, I'm just saying like the goal here is to compress data as as good as possible compared to some set of codes.",
                    "label": 0
                },
                {
                    "sent": "And I'm saying you can do this in different ways.",
                    "label": 0
                },
                {
                    "sent": "So one way is to code in two stages.",
                    "label": 0
                },
                {
                    "sent": "First you code an index and then you code data with the code corresponding to that index and another way is to 1st define a mixture distribution.",
                    "label": 0
                },
                {
                    "sent": "So the first map, the codes to distributions, then the final mixture distributions and then map that back to code.",
                    "label": 0
                },
                {
                    "sent": "That's another way of achieving the same goal, and because what will happen now is we will see two more ways of achieving the same goal and then we will start comparing them.",
                    "label": 0
                },
                {
                    "sent": "So now I'm comparing this Bayesian method for constructing a code with the two part method where you do it in two stages.",
                    "label": 1
                },
                {
                    "sent": "And so of course you can extend this two part method also, so using a prior on the set of T tests, because each distribution on a set of theaters in user code for encoding the thetas with code length minus lock prior of Theta.",
                    "label": 0
                },
                {
                    "sent": "So then if you quote the data by first coding the theater, which maximizes the probability of the data.",
                    "label": 1
                },
                {
                    "sent": "So giving the index of this data and then coding the data using the Theta so with.",
                    "label": 0
                },
                {
                    "sent": "With length minus log probability according to this theater head.",
                    "label": 0
                },
                {
                    "sent": "Then the total length you get in this two part code will be minus lock the prior.",
                    "label": 0
                },
                {
                    "sent": "Of the theater which fits the data best minus lock, the probability of the data according to the theater which fits the data best, and which therefore also gives the smallest code length to the data according to all seats are in your model.",
                    "label": 0
                },
                {
                    "sent": "So know that if we use a uniform prior, this is just what we've seen before.",
                    "label": 0
                },
                {
                    "sent": "For example, we have four distributions, then with a uniform prior, each one gets probability 1/4 and then minus log.",
                    "label": 0
                },
                {
                    "sent": "1/4 is 2.",
                    "label": 0
                },
                {
                    "sent": "We need 2 bits to encode each possible seater, but again we can do this for general priors.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "If you compare this to the basic code, you see that the base mixture is strictly better in the sense that it assigns larger probability and therefore smaller code linked to some outcomes and no.",
                    "label": 1
                },
                {
                    "sent": "And never smaller probability to know outcomes.",
                    "label": 0
                },
                {
                    "sent": "Why is that so well noted with the two part code, we need exactly this number of bits to code a sequel.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But with the basing code.",
                    "label": 0
                },
                {
                    "sent": "We need minus log of this.",
                    "label": 0
                },
                {
                    "sent": "Some bits and at smaller equal than this.",
                    "label": 0
                },
                {
                    "sent": "This is what we need with the two part code.",
                    "label": 0
                },
                {
                    "sent": "Fertitta heads, but this holds for all theater, in particular for Theta Hat.",
                    "label": 0
                },
                {
                    "sent": "So this means that here we have a smaller equal, and if the other terms in the sum are not zero, and actually this will be strictly the sum will be strictly larger than each of its terms, so this minus log of the sun will be strictly smaller than each of its terms.",
                    "label": 0
                },
                {
                    "sent": "So then the basin coding using the basic distribution will give you strictly shorter code length encoding using the two part distribution.",
                    "label": 0
                },
                {
                    "sent": "So then using base for coding.",
                    "label": 0
                },
                {
                    "sent": "So again this works bye.",
                    "label": 0
                },
                {
                    "sent": "Viewing the coaches distributions.",
                    "label": 0
                },
                {
                    "sent": "Making a mixture distributions.",
                    "label": 0
                },
                {
                    "sent": "An mapping that vector code that's strictly better than coding in two stages.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "But now we've seen that there.",
                    "label": 0
                },
                {
                    "sent": "So there are two different ways of doing this.",
                    "label": 0
                },
                {
                    "sent": "Universal coding.",
                    "label": 0
                },
                {
                    "sent": "One of them seems to be better than the other.",
                    "label": 0
                },
                {
                    "sent": "But now maybe we want to extend this further.",
                    "label": 0
                },
                {
                    "sent": "Maybe there's even more ways to do universal coding and then we should also ask ourselves what do we really mean by better in general.",
                    "label": 1
                },
                {
                    "sent": "And also we might want to know what prior should we use in general.",
                    "label": 1
                },
                {
                    "sent": "Should we use a uniform prior or another prior and this depends of course on what we mean by what does it mean for a code to be better than?",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I want.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Now we're actually going to define better in a particular way, which I'm allies much of modern MDL, which is a minimax way.",
                    "label": 0
                },
                {
                    "sent": "So if we have a model, a set of distributions.",
                    "label": 0
                },
                {
                    "sent": "We can always look at given the data.",
                    "label": 0
                },
                {
                    "sent": "What would have been the best code to use with hindsight after having seen the data?",
                    "label": 0
                },
                {
                    "sent": "And that is the code corresponding to the maximum likelihood parameter for the data which maximizes the probability and therefore minimizes the code length.",
                    "label": 0
                },
                {
                    "sent": "So this is the code in the beginning I told you.",
                    "label": 0
                },
                {
                    "sent": "Suppose an encoder just simply sensor data using the code with which gives you the shortest coding for the data.",
                    "label": 0
                },
                {
                    "sent": "That doesn't really work because the decoder doesn't know how to decode the data, but if he could do so counter factual, then you would get this code length.",
                    "label": 0
                },
                {
                    "sent": "But this code length is not feasable.",
                    "label": 0
                },
                {
                    "sent": "Instead you have to use a real code which can be decoded, and by this Kraft inequality we know that that also has to correspond to some distribution, so there must be some piece so.",
                    "label": 0
                },
                {
                    "sent": "The code he uses correspond to some distribution piece star such that for each outcome the code length is equal to minus lock, P star of the data.",
                    "label": 0
                },
                {
                    "sent": "And because this holds for each code.",
                    "label": 0
                },
                {
                    "sent": "We have such a piece star finding the best code amounts to finding the best piece star and what we're going to do is.",
                    "label": 0
                },
                {
                    "sent": "We're going to look for the P star such that the overhead you have compared to the best code with hindsight is as small as possible.",
                    "label": 1
                },
                {
                    "sent": "In the worst case where the worst case is taken over all data sequences, so for each particular data sequence you can look at what is the worst possible overhead between this thing code you want to use and the code which is best with hindsight after having seen the data.",
                    "label": 0
                },
                {
                    "sent": "So you can of course construct the code such that this number is negative for some data, so this code will give a smaller code linked to some data.",
                    "label": 0
                },
                {
                    "sent": "Then the best code in your candidate sets, but then it will be very large for some other data, and in the worst case this must always be a positive number.",
                    "label": 1
                },
                {
                    "sent": "So and now you look for the P star which minimizes this worst case quantity.",
                    "label": 1
                },
                {
                    "sent": "So this piece starts when you transform into a quote is the minimax optimal universal model, or universal code to be used for coding data relative to the set of candidate codes?",
                    "label": 0
                },
                {
                    "sent": "Now the question is, can you somehow compute?",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "HP star and surprisingly you can.",
                    "label": 0
                },
                {
                    "sent": "At least you can get a nice formula for it, whether you can actually use that formula in practice is a quite different question.",
                    "label": 0
                },
                {
                    "sent": "And it's it's called the start of our normalized maximum likelihood distribution.",
                    "label": 1
                },
                {
                    "sent": "So it turns out that the solution.",
                    "label": 0
                },
                {
                    "sent": "To this equation, the piece star which minimizes the worst case coding overhead.",
                    "label": 0
                },
                {
                    "sent": "Is give as accurate as a unique solution?",
                    "label": 0
                },
                {
                    "sent": "If this has a solution at all, if the worst case is not infinite, the solution looks like this, so it's a distribution over sequences.",
                    "label": 0
                },
                {
                    "sent": "Which assigns to each sequence the probability of that sequence according to the maximum likelihood distribution.",
                    "label": 0
                },
                {
                    "sent": "Of course, if you add this overall sequences, you get something larger than one.",
                    "label": 0
                },
                {
                    "sent": "Because for each sequence you assign.",
                    "label": 0
                },
                {
                    "sent": "The probability according to the best fitting distribution in the model.",
                    "label": 0
                },
                {
                    "sent": "So if there's more than one distribution in your model, your set of distributions, if there's just one, this will sum to once.",
                    "label": 0
                },
                {
                    "sent": "If there's more.",
                    "label": 0
                },
                {
                    "sent": "I wanted to sum to something larger than one, which is again a restatement of the fact that you cannot quote by simply sending a distribution which best fits the data.",
                    "label": 0
                },
                {
                    "sent": "So you need to normalize this and you do that simply by dividing this by the sum over all sequences of the probability of that sequence according to the best fitting distribution.",
                    "label": 0
                },
                {
                    "sent": "For that sequence.",
                    "label": 0
                },
                {
                    "sent": "And clearly if you normalize in this way, you get a distribution.",
                    "label": 0
                },
                {
                    "sent": "If you now summit overall outcomes, it becomes one.",
                    "label": 0
                },
                {
                    "sent": "Now, why does this solve this?",
                    "label": 0
                },
                {
                    "sent": "Well, it's actually quite easy to see if you plug this in here you get minus log of this probability, and then because minus log of a fraction is minus log of this plus lock of this, plus luck of the denominator.",
                    "label": 0
                },
                {
                    "sent": "So then the minus lock.",
                    "label": 0
                },
                {
                    "sent": "This cancels with this if minus log, this minus minus look the same thing and what remains is the log of this song.",
                    "label": 0
                },
                {
                    "sent": "So if you plug this in here you get the lock of this sum.",
                    "label": 0
                },
                {
                    "sent": "And let some doesn't depend on the data itself, so it's constant over all possible data sequences.",
                    "label": 0
                },
                {
                    "sent": "Now, if you would use any other distribution here.",
                    "label": 0
                },
                {
                    "sent": "Then, um.",
                    "label": 0
                },
                {
                    "sent": "Because the distribution must sum to one.",
                    "label": 0
                },
                {
                    "sent": "If it's not the same distribution, it must give smaller probability to at least one sequence, and if it gives smaller probability to at least one sequence, then for that particular sequence.",
                    "label": 0
                },
                {
                    "sent": "This must be larger, right?",
                    "label": 0
                },
                {
                    "sent": "Because if you plug in this, it's a constant.",
                    "label": 1
                },
                {
                    "sent": "So that's why this gives you the minimax optimal universal.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "What?",
                    "label": 0
                },
                {
                    "sent": "So now I can finally find MDL.",
                    "label": 0
                },
                {
                    "sent": "At least one version for model selection and that works where we just have two models and one M2.",
                    "label": 0
                },
                {
                    "sent": "So think about these for example as a first order in a second order Markov model for your data.",
                    "label": 0
                },
                {
                    "sent": "And now according to this modern version of MDL, if you want to select between those two models for the same data.",
                    "label": 1
                },
                {
                    "sent": "You should pick the model for which the associated optimal universal model.",
                    "label": 1
                },
                {
                    "sent": "So that's this normalized maximum likelihood model assigns the largest probability to the data, or equivalently, you pick the model which gives the smallest code link to the data.",
                    "label": 1
                },
                {
                    "sent": "If you use the minimax optimal universal code relative to the model.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "I only did this for finite models, but exactly the same thing can be done for infinite models.",
                    "label": 0
                },
                {
                    "sent": "In a moment we will see how and then this becomes actually practically useful thing to do.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So let's look at this again.",
                    "label": 0
                },
                {
                    "sent": "So we have two models and we select the one which minimizes the code length.",
                    "label": 0
                },
                {
                    "sent": "According to this universal code.",
                    "label": 0
                },
                {
                    "sent": "An so if we recall that this is a fraction.",
                    "label": 0
                },
                {
                    "sent": "Of the probability according to the maximum likelihood divided by the sum over all sequences of the probability according to the maximum likelihood for that sequence.",
                    "label": 0
                },
                {
                    "sent": "So the minus log of a fraction is equal to minus log of the numerator plus lock of the denominator.",
                    "label": 0
                },
                {
                    "sent": "So we select the model for which this sum is smallest, and now you can think of this sum as the trade off which is familiar in other model selection methods.",
                    "label": 0
                },
                {
                    "sent": "Like AIC MBC, a tradeoff between goodness of fits and complexity.",
                    "label": 0
                },
                {
                    "sent": "So if the best fitting distribution in your model fits the data better, then this will be larger.",
                    "label": 0
                },
                {
                    "sent": "So minus log of this will be smaller.",
                    "label": 0
                },
                {
                    "sent": "On the other hand, if the complexity of your model.",
                    "label": 0
                },
                {
                    "sent": "Is larger and complexity here means that it can fit more patterns?",
                    "label": 0
                },
                {
                    "sent": "Well, that as we will see, roughly corresponds to how many parameters to model has.",
                    "label": 0
                },
                {
                    "sent": "Then this term will get larger, so this term, the richer the model is, the more data patterns that can fit, and therefore the more risk you have overfitting the larger this term will be.",
                    "label": 0
                },
                {
                    "sent": "So how large is this term for finite models, well?",
                    "label": 0
                },
                {
                    "sent": "We've already seen if you have a finite model with M elements.",
                    "label": 0
                },
                {
                    "sent": "This term must be bounded by the lock of the number of elements, because we've already seen, I can always quote the data with the two part code, where the overhead for each.",
                    "label": 0
                },
                {
                    "sent": "Outcome is log M right?",
                    "label": 1
                },
                {
                    "sent": "It's by simply encoding the index of the maximum likelihood distribution fees ahead by a uniform code which takes log N bits.",
                    "label": 0
                },
                {
                    "sent": "So here we have the same overhead for every particular sequence because we know there's a code with overhead lock M. This particular overhead must be smaller than log M and in a moment.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We'll see how much smaller.",
                    "label": 0
                },
                {
                    "sent": "So another questions, of course.",
                    "label": 0
                },
                {
                    "sent": "Does this make any sense this nor this?",
                    "label": 0
                },
                {
                    "sent": "Using this normalized maximum likelihood distribution to compare models and to try to convince you that it does, I'll give four interpretations of it.",
                    "label": 0
                },
                {
                    "sent": "And actually, the first interpretation I already gave.",
                    "label": 0
                },
                {
                    "sent": "Basically what you do is if you believe as an axiom.",
                    "label": 0
                },
                {
                    "sent": "This MDL idea that it's good to select the model which allows for the shortest code length of the data.",
                    "label": 0
                },
                {
                    "sent": "Then I already have.",
                    "label": 0
                },
                {
                    "sent": "I mean then you have to believe that.",
                    "label": 0
                },
                {
                    "sent": "But if you believe that, then there's a clear motivation already.",
                    "label": 0
                },
                {
                    "sent": "Because what we do here is exactly that we select the model which allows you for the most compression of the data.",
                    "label": 0
                },
                {
                    "sent": "And to formalize that idea, we associate each model set of distributions with the code, and we do that in such a way that all distributions within the model are treated on an equal footing.",
                    "label": 1
                },
                {
                    "sent": "Of course, we can associate a code to encode data with the model in an arbitrary way, but we did it in a way that's at the overhead we have.",
                    "label": 0
                },
                {
                    "sent": "We have to whatever distribution in the model is a good code for the data is as small as possible, and note, and this makes it really different from any other approach to machine learning and statistics that I know of.",
                    "label": 0
                },
                {
                    "sent": "This is done in a worst case setting not worst case over distributions that might generate the data, but worst case over data.",
                    "label": 0
                },
                {
                    "sent": "So it's really important to realize that I haven't talked for one second about things which generate data.",
                    "label": 0
                },
                {
                    "sent": "I have taken no expectations, they don't exist here.",
                    "label": 0
                },
                {
                    "sent": "We use distributions only.",
                    "label": 0
                },
                {
                    "sent": "To encode data and not as something from which data might come here.",
                    "label": 0
                },
                {
                    "sent": "And we then look at how good these distributions are.",
                    "label": 0
                },
                {
                    "sent": "In the worst case overall data sequences.",
                    "label": 0
                },
                {
                    "sent": "So we make no assumptions about where the data comes from at all, at least when defining our model later, when we, when defining our method later, we're going to prove that the method works well in some cases.",
                    "label": 0
                },
                {
                    "sent": "Then we will make such assumptions, but for now we haven't made those assumptions at all.",
                    "label": 0
                },
                {
                    "sent": "We want to use codes which work well no matter what data we get.",
                    "label": 0
                },
                {
                    "sent": "So now the second interpretation has something to do with this complexity term, and it turns out you can give that a kind.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Accounting or geometric interpretation.",
                    "label": 0
                },
                {
                    "sent": "So turns out you can think of this as something like the total fit your model assigns to the data, or equivalently the lock, not of the number of elements in your model.",
                    "label": 1
                },
                {
                    "sent": "If the model is finite, it would be this M and we've already seen it's more equal than log of the number of elements, but something like the effectiveness.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Distribution, So what is that?",
                    "label": 0
                },
                {
                    "sent": "So if I look not at the lock of this complexity term, but the term itself.",
                    "label": 0
                },
                {
                    "sent": "I can rewrite it this some in two separate terms I can take to some overall fetus in my model and then some offer old data for which that particular Theta fits the data best.",
                    "label": 0
                },
                {
                    "sent": "The probability of the data according to this, and this is simply the same.",
                    "label": 0
                },
                {
                    "sent": "So I partitioned the set of all sequences into those sequences which have the same maximum likelihood estimator.",
                    "label": 0
                },
                {
                    "sent": "So now I can be right.",
                    "label": 0
                },
                {
                    "sent": "This of course is to some overall theater.",
                    "label": 0
                },
                {
                    "sent": "My model of the probability according to see to that I get a sequence for which theater is actually the maximum likelihood estimator.",
                    "label": 0
                },
                {
                    "sent": "And this is of course the sum of all Theta of 1 minus the probability that I get a sequence for which data is not the maximum likelihood estimator.",
                    "label": 0
                },
                {
                    "sent": "According to theater, so this is the probability according to theater, that the data look as if they do not come from theater.",
                    "label": 0
                },
                {
                    "sent": "Think of a very simple model, let's say a Bernoulli model with just four elements.",
                    "label": 0
                },
                {
                    "sent": "The probability of one is 0.2 zero point 4, zero point 6 or 0.8.",
                    "label": 0
                },
                {
                    "sent": "If the frequency of ones is approximately 0.4.",
                    "label": 0
                },
                {
                    "sent": "Then and you look at the terminus some with thetas .2, then this is the probability that you get some sequence, for example with the frequency of 0.4 or even larger such that the Theta hat is not equal to 0.2.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Now this you can now pull this one out of the sum, and if this is a final, this is simply the number of distributions and here you get a strictly negative term.",
                    "label": 0
                },
                {
                    "sent": "Which you might call the amount of confusion in your model.",
                    "label": 1
                },
                {
                    "sent": "So this is the probability according to theater that the maximum likelihood estimator is not theater.",
                    "label": 0
                },
                {
                    "sent": "The probability according to.",
                    "label": 0
                },
                {
                    "sent": "See to that you get an atypical sequence with, which doesn't look like theater sums overall theater.",
                    "label": 0
                },
                {
                    "sent": "And if N gets large and the set of distributions is finite, this will go to zero exponentially fast, and then this becomes dominant.",
                    "label": 1
                },
                {
                    "sent": "And then this is equal to M and then this complexity is simply the number of distributions in your model, but.",
                    "label": 0
                },
                {
                    "sent": "If the sample is not too large and some of the distributions are close to each other, for example, if you have one distribution is Bernoulli 0.5 and the other is 0.501, then they give almost the same probability to all data sequences.",
                    "label": 0
                },
                {
                    "sent": "And then essentially, this term will be pretty large.",
                    "label": 0
                },
                {
                    "sent": "And then this will become substantially smaller.",
                    "label": 0
                },
                {
                    "sent": "Then M the number of distribution so and if two distributions are precisely the same.",
                    "label": 0
                },
                {
                    "sent": "So if you have four distributions, but two of them are the same, then this will actually become equal to something smaller than three.",
                    "label": 0
                },
                {
                    "sent": "So effectively this sum is not the number of distributions, but the number of effective distributions at the given sample size.",
                    "label": 0
                },
                {
                    "sent": "The number of distributions which based on the data you can distinguish from each other with high probability, so that justifies calling it a complexity complexity of your model.",
                    "label": 0
                },
                {
                    "sent": "And in fact, if you know the Rademacher complexity in computational learning theory, you see that there are some similarities there.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This notion of complexity.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So now we finally go to infinite models and we will see we can extend this idea of thinking of the complexity as a kind of log number of distributions to this infinite setting.",
                    "label": 0
                },
                {
                    "sent": "So now think for example M is.",
                    "label": 0
                },
                {
                    "sent": "A Markov chain of a particular order, and we compare Markov chains of different order or it's.",
                    "label": 0
                },
                {
                    "sent": "Let's say Gaussian mixture of a particular order and we compare different number of mixture components.",
                    "label": 0
                },
                {
                    "sent": "It turns out that under regularity conditions on these models, basically, if the parametrization is smoother, she if they're exponential families, then this holds.",
                    "label": 0
                },
                {
                    "sent": "We can rewrite this as syntactically like this, so this is the thing we are comparing for different models.",
                    "label": 0
                },
                {
                    "sent": "We take the model for which this is smallest.",
                    "label": 0
                },
                {
                    "sent": "And for large and this turns out to be equal to this.",
                    "label": 0
                },
                {
                    "sent": "So this is actually we've already seen this term, because this is just a fraction.",
                    "label": 0
                },
                {
                    "sent": "And it's minus log.",
                    "label": 0
                },
                {
                    "sent": "This plus lock of this enormous sum overall data sequences.",
                    "label": 0
                },
                {
                    "sent": "So this is actually the lock of that enormous sum.",
                    "label": 0
                },
                {
                    "sent": "So it turns out under assumptions on the model that this sum can be rewritten as K over to log in, where K is the number of free parameters.",
                    "label": 1
                },
                {
                    "sent": "Plus lot of some complicated thing.",
                    "label": 0
                },
                {
                    "sent": "Which I will not go into here in detail, but so I Theta is a quantity called the Fisher information.",
                    "label": 1
                },
                {
                    "sent": "In statistics and what you do here is you integrate the Fisher information.",
                    "label": 0
                },
                {
                    "sent": "Overall Theta over the model.",
                    "label": 0
                },
                {
                    "sent": "And then there's a remainder term which goes to zero as N goes to Infinity.",
                    "label": 0
                },
                {
                    "sent": "So note that this term does not depend on N, so as N gets large it becomes negligible compared to this term, which usually increases linearly and this term, which increases logarithmically.",
                    "label": 0
                },
                {
                    "sent": "And note again this.",
                    "label": 0
                },
                {
                    "sent": "So that means for large the complexity term, which is this plus this for large and in the complexity term the number of parameters becomes the dominant issue.",
                    "label": 0
                },
                {
                    "sent": "The more parameters you have, the more degrees of freedom.",
                    "label": 0
                },
                {
                    "sent": "The more complex the model.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So now let's compare this to the BICS criterion, which is an approximation of base and model selection, which is used a lot in practice according to the BICS.",
                    "label": 0
                },
                {
                    "sent": "Given a set of models.",
                    "label": 0
                },
                {
                    "sent": "With different number of parameters you should select the model which minimizes minus log probability according to maximum likelihood plus K over to log in.",
                    "label": 0
                },
                {
                    "sent": "So if you compare it to this, you see that it's almost the same, except for this last term.",
                    "label": 0
                },
                {
                    "sent": "So first of all, this means that if you have two models with the same number of parameters which fit the date about equally well so that this term is about equal, you cannot use BSE to distinguish between them.",
                    "label": 0
                },
                {
                    "sent": "Here you can use, you can use this to distinguish between them and you can get in general something very different, because this may be very different from model to model.",
                    "label": 0
                },
                {
                    "sent": "So also the very first version of MDL, which unfortunately.",
                    "label": 0
                },
                {
                    "sent": "Pete Petree specifically asked me to emphasize this.",
                    "label": 0
                },
                {
                    "sent": "Unfortunately there are still people in Yuan and Acnl communities who do this and say it's MDL that was actually.",
                    "label": 0
                },
                {
                    "sent": "I think already in 82 written and started doing other things, but so this is really very old.",
                    "label": 0
                },
                {
                    "sent": "But you see it's kind of an approximation of this.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Now it turns out that this term, how should we interpret it?",
                    "label": 0
                },
                {
                    "sent": "This modification to the BI?",
                    "label": 0
                },
                {
                    "sent": "See it's something like a curve.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Your term.",
                    "label": 0
                },
                {
                    "sent": "Let's see if I have a.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Should we worry about the little old one?",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "So in practice, I think you don't want to use this in practice.",
                    "label": 0
                },
                {
                    "sent": "You want to actually calculate really calculate this or approximated because even though this is much more precise than the BI see, I've seen several examples where this little of 1 where basically for small sample sizes this is very bad approximation.",
                    "label": 0
                },
                {
                    "sent": "So again, this is just to get insights an not to be used in practice.",
                    "label": 0
                },
                {
                    "sent": "Although people use it in practice, but I tend to be skeptical about that.",
                    "label": 0
                },
                {
                    "sent": "Sorry.",
                    "label": 0
                },
                {
                    "sent": "German is also constant.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so for small N it does yes.",
                    "label": 0
                },
                {
                    "sent": "You said that the little 01 goes to 0, then goes to Infinity, right?",
                    "label": 0
                },
                {
                    "sent": "Not a little of one over end or something like that.",
                    "label": 0
                },
                {
                    "sent": "Actually it is, I think so.",
                    "label": 0
                },
                {
                    "sent": "I just wasn't precise about its large oh of 1 / N I think yes.",
                    "label": 0
                },
                {
                    "sent": "But it's.",
                    "label": 0
                },
                {
                    "sent": "I would have to check whether it's something like that, I think.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so let me say something about why this is called curvature term.",
                    "label": 0
                },
                {
                    "sent": "App.",
                    "label": 0
                },
                {
                    "sent": "Suppose.",
                    "label": 0
                },
                {
                    "sent": "Suppose I have the binary data and I have a first order Markov model.",
                    "label": 0
                },
                {
                    "sent": "So then I have two parameters.",
                    "label": 0
                },
                {
                    "sent": "So this is the probability that the next outcome is a one, given that the previous outcome was a zero.",
                    "label": 0
                },
                {
                    "sent": "And this is the probability that the next outcome is 1 given that the previous outcome was one that defines a first order Markov model.",
                    "label": 0
                },
                {
                    "sent": "For binary sequence of data.",
                    "label": 0
                },
                {
                    "sent": "And I can think of the Bernoulli model as a 1 dimensional sub model of this which looks like this.",
                    "label": 0
                },
                {
                    "sent": "But because then both probabilities have to be the same for each Bernoulli model, the data independent according to some theater probability of 1 between zero and one.",
                    "label": 0
                },
                {
                    "sent": "This is diagonal line.",
                    "label": 0
                },
                {
                    "sent": "So here I have two parameter Maulana one parameter model.",
                    "label": 0
                },
                {
                    "sent": "Now I can also define another one parameter model embedded in the 2nd order Markov model, which would look something like this.",
                    "label": 0
                },
                {
                    "sent": "So this model also can be parameterized by just one real value parameter, so it is a one parameter model.",
                    "label": 0
                },
                {
                    "sent": "But if you look at it you see that for every distribution in a second order in the 1st order model.",
                    "label": 0
                },
                {
                    "sent": "The two parameters there is a one, an element of the one parameter model which is close to it, at least in Euclidean distance.",
                    "label": 0
                },
                {
                    "sent": "So you would expect that this model.",
                    "label": 0
                },
                {
                    "sent": "It's a lot more like the model with two parameters, then this model, so both have one parameter, But this one resembles the two parameters a lot more.",
                    "label": 0
                },
                {
                    "sent": "An confit, random data, a lot better.",
                    "label": 0
                },
                {
                    "sent": "So indeed, this normalized maximum likelihood term will be much larger for this model.",
                    "label": 0
                },
                {
                    "sent": "And that will translate itself in this term being larger.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So now let's compare this to base and model selection.",
                    "label": 0
                },
                {
                    "sent": "So in base so called base factor model selection.",
                    "label": 0
                },
                {
                    "sent": "If you ignore the priors on the models, which usually can.",
                    "label": 0
                },
                {
                    "sent": "You simply pick the model which maximizes the marginal likelihood of the data.",
                    "label": 0
                },
                {
                    "sent": "So you have this is this average we've seen before the integral, now over the probability of the data according to Theta integrated by the prior density of Theta.",
                    "label": 0
                },
                {
                    "sent": "And you can look at that for each model and then you pick the model for which this.",
                    "label": 0
                },
                {
                    "sent": "Integrated probabilities largest.",
                    "label": 0
                },
                {
                    "sent": "So minus locally integrated probability smallest.",
                    "label": 0
                },
                {
                    "sent": "That's what based on model selection does.",
                    "label": 1
                },
                {
                    "sent": "So you can also approximate this by Laplace approximation, so it's basically a Taylor expansion.",
                    "label": 0
                },
                {
                    "sent": "And if you do that and it turns out that again under conditions on the model, this turns out to be equal to this.",
                    "label": 0
                },
                {
                    "sent": "So you see, it's almost the same as this, so base there's something very similar for minimum description length, so normalized maximum like Minimum Scription, Inc.",
                    "label": 0
                },
                {
                    "sent": "In particular, you see that these terms they do not depend on the sample size.",
                    "label": 0
                },
                {
                    "sent": "So for large N base will do the same as MDL if the number of models you compare.",
                    "label": 1
                },
                {
                    "sent": "It's finite.",
                    "label": 0
                },
                {
                    "sent": "So how does this term relate to this term then?",
                    "label": 0
                },
                {
                    "sent": "Well, you see that in base what happens depends on your prior of course base depends on the prior.",
                    "label": 0
                },
                {
                    "sent": "And basically what you see here.",
                    "label": 0
                },
                {
                    "sent": "This is the prior.",
                    "label": 0
                },
                {
                    "sent": "Of theater evaluated at the maximum likelihood an basically if you are lucky and the maximum likelihood turns out to be the region of parameter space to which you gave a high prior probability.",
                    "label": 0
                },
                {
                    "sent": "So your prior assumptions were kind of correct.",
                    "label": 0
                },
                {
                    "sent": "Then this term will be small because the prior density of the maximum likelihood parameter will be large and you will give a large probability to the data.",
                    "label": 0
                },
                {
                    "sent": "If however, you are unlucky and you gave a small prior to what turns out to be the probability maximizing Theta, then this will be the probability will be smarter.",
                    "label": 0
                },
                {
                    "sent": "Smaller and minus log probability will be larger, so this depends on your prior.",
                    "label": 0
                },
                {
                    "sent": "And of course, some basins, so-called objective basis, have proposed priors which you can use if you don't have any clear prior knowledge.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And the most famous of these is the so-called Jeffreys prior.",
                    "label": 0
                },
                {
                    "sent": "Which is defined.",
                    "label": 0
                },
                {
                    "sent": "By the square root of the determinant of the Fisher information matrix.",
                    "label": 0
                },
                {
                    "sent": "Usually if you did, if you integrate it over all theater, it doesn't become one but something larger.",
                    "label": 0
                },
                {
                    "sent": "So you have to normalize it to make it a probability.",
                    "label": 0
                },
                {
                    "sent": "So this is what sometimes objective Bayesians advocate to user model selection.",
                    "label": 0
                },
                {
                    "sent": "Or if you plug this in here.",
                    "label": 0
                },
                {
                    "sent": "Then you see that you get minus lock.",
                    "label": 0
                },
                {
                    "sent": "Of the square root of the Fisher information and they are here plus log of the square root of the fish information they cancel and what remains is plus log of the denominator.",
                    "label": 0
                },
                {
                    "sent": "So you get plus lock of this.",
                    "label": 0
                },
                {
                    "sent": "So then you see that they actually become the same up to small order of 1.",
                    "label": 0
                },
                {
                    "sent": "So if you use Jeffreys prior, then asymptotically base and MDL based on normalized maximum likelihood become actually the same.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So, Interestingly, this Jeffreys prior was proposed in 1939 as a kind of uniform prior not on the space of parameters, but on the space of distributions.",
                    "label": 1
                },
                {
                    "sent": "So the space of parameters depends on your parameterization is essentially arbitrary.",
                    "label": 0
                },
                {
                    "sent": "But the space of distributions can be defined in a more generic manner.",
                    "label": 0
                },
                {
                    "sent": "Men are, and if you put a uniform prior on that and use base.",
                    "label": 0
                },
                {
                    "sent": "You get essentially the same as MDL, at least in the simple setting we're talking about here.",
                    "label": 0
                },
                {
                    "sent": "In more general settings, it turns out you don't always get the same.",
                    "label": 0
                },
                {
                    "sent": "Because, for example if you have non parametric if using a non parametric settings then with some priors you will actually not compress your data.",
                    "label": 0
                },
                {
                    "sent": "So then there are some instances of base which cannot be thought of as MDL.",
                    "label": 0
                },
                {
                    "sent": "Because they don't lead to compression of the data.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So, um.",
                    "label": 0
                },
                {
                    "sent": "Given the time, I will skip these less so I will just talk about these two.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So there's a certain very important interpretation of what we've been doing, which is the so called predictive or pre krenchel interpretation.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "If you quotes, you can always.",
                    "label": 0
                },
                {
                    "sent": "You can also look at what happens outcome by outcome.",
                    "label": 0
                },
                {
                    "sent": "And then you can think of the minus log probability assigned to an outcome as a loss function.",
                    "label": 0
                },
                {
                    "sent": "So you can just think of probabilities as prediction strategies, and then one reasonable way to measure how good they are on a particular outcome is by looking at the minus log of the probability assigned to the outcome.",
                    "label": 0
                },
                {
                    "sent": "If you assign probability one to the outcome, then minus log one is 0, so your loss is 0.",
                    "label": 0
                },
                {
                    "sent": "If you assign probability zero, your loss will be infinite, but you can also think of this is.",
                    "label": 0
                },
                {
                    "sent": "If you use the distribution as a code, then it's a number of bits you need to encode that particular outcome.",
                    "label": 0
                },
                {
                    "sent": "So if your goal is compressed, the data as much as possible, this is a logical loss function to use.",
                    "label": 0
                },
                {
                    "sent": "Now it turns out that if you use base to sequentially predict data.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "Then it turned.",
                    "label": 0
                },
                {
                    "sent": "Then you get you can look at the cumulative loss.",
                    "label": 0
                },
                {
                    "sent": "So that's the sum of these individual log losses.",
                    "label": 0
                },
                {
                    "sent": "And it turns out that that is the same as the code length you need.",
                    "label": 0
                },
                {
                    "sent": "If you code with base the whole data.",
                    "label": 0
                },
                {
                    "sent": "So what does that mean?",
                    "label": 0
                },
                {
                    "sent": "Well, this is what we've seen before you have the base universal code.",
                    "label": 0
                },
                {
                    "sent": "So it's a basic mixture distribution.",
                    "label": 0
                },
                {
                    "sent": "You can turn it into a code and then this is the code length you get for each particular outcome.",
                    "label": 0
                },
                {
                    "sent": "Now you can also use base sequentially to predict outcomes, so you have you predict the first outcome using the base predictive distribution for that.",
                    "label": 0
                },
                {
                    "sent": "Then you observe the first outcome.",
                    "label": 0
                },
                {
                    "sent": "You predict the second outcome using the conditional distribution given the first outcome and you have a certain log loss.",
                    "label": 0
                },
                {
                    "sent": "Then you predict the third outcome using the conditional distribution based on the 1st two outcomes, you predict the 4th outcome using the conditional distribution based on the 1st three outcomes etc.",
                    "label": 0
                },
                {
                    "sent": "And you Add all the losses.",
                    "label": 0
                },
                {
                    "sent": "So this is what you do.",
                    "label": 0
                },
                {
                    "sent": "You add the sum of these losses, but you always predict using base condition on the previous outcomes.",
                    "label": 0
                },
                {
                    "sent": "Of course, by the definition of logarithm closed, this is equal to this.",
                    "label": 0
                },
                {
                    "sent": "Now, because the sum of a logarithm is the log of the product.",
                    "label": 0
                },
                {
                    "sent": "And this condition is equal to this fraction.",
                    "label": 0
                },
                {
                    "sent": "This is equal to this.",
                    "label": 0
                },
                {
                    "sent": "And now if you write out this product it is infectors, then everything cancels.",
                    "label": 0
                },
                {
                    "sent": "It's called telescoping.",
                    "label": 0
                },
                {
                    "sent": "Because if you then on the diagonal all these things start canceling and this is the only thing that remains.",
                    "label": 0
                },
                {
                    "sent": "So this means that the sum of the loss if you use base for sequential prediction is actually equal to the code length you get for the whole sequence if you encode it using the base encode.",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So no, an idea.",
                    "label": 0
                },
                {
                    "sent": "Which goes back to 1984.",
                    "label": 0
                },
                {
                    "sent": "Is you too Phil Davidson?",
                    "label": 0
                },
                {
                    "sent": "Germer istenem.",
                    "label": 0
                },
                {
                    "sent": "Is that if you look at what it is based in predictive distribution, you see that for large N it resembles more and more the maximum likelihood distribution.",
                    "label": 1
                },
                {
                    "sent": "For example, if you use a uniform prior with the Bernoulli model and the maximum likelihood distribution given, let's say S once in a sample of N is as divided by N. So maximum likelihood would be this number of ones divided by the total number of outcomes and the base and predictive distribution would be S + 1 / N + 2.",
                    "label": 0
                },
                {
                    "sent": "This is so cool.",
                    "label": 0
                },
                {
                    "sent": "Also called in the plus estimator, so it's almost the same.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "This conditional distributions really starts to look like.",
                    "label": 0
                },
                {
                    "sent": "The maximum likelihood distribution given the past.",
                    "label": 0
                },
                {
                    "sent": "So this suggests that you can actually approximate this patient distribution by this distribution, or actually by any other reasonable estimator.",
                    "label": 0
                },
                {
                    "sent": "It doesn't have to be the maximum likelihood estimator.",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And it turns out that you can do this.",
                    "label": 1
                },
                {
                    "sent": "So in general there are some slight caveats here, which I'll skip.",
                    "label": 0
                },
                {
                    "sent": "You can if you use the maximum likelihood at each point.",
                    "label": 0
                },
                {
                    "sent": "And you sequentially predict the future and you Add all the losses.",
                    "label": 0
                },
                {
                    "sent": "Then the total loss you get.",
                    "label": 0
                },
                {
                    "sent": "Is equal to the best prediction you could have made with hindsight, so with hindsight, after you've seen all the data given your model, then you should have predicted with heat ahead all the time that would have given you the smallest.",
                    "label": 0
                },
                {
                    "sent": "Total, the largest total probability.",
                    "label": 0
                },
                {
                    "sent": "Therefore, the smallest total loss.",
                    "label": 0
                },
                {
                    "sent": "But instead you used always the maximum likelihood estimator based on the past because she didn't see the future and the overhead you get by not knowing the future is K over to Logan plus order one.",
                    "label": 0
                },
                {
                    "sent": "So this means the central term, which doesn't depend which depends on any still K over to Logan where case number of parameters.",
                    "label": 0
                },
                {
                    "sent": "So this means that you can use this sequential maximum likelihood scheme.",
                    "label": 1
                },
                {
                    "sent": "Also, as a universal code and you can try to do model selection based on this.",
                    "label": 0
                },
                {
                    "sent": "Sequential prediction strategy.",
                    "label": 0
                },
                {
                    "sent": "So another way to view this is that if you do M DL, it's something like selecting the model which has the smallest accumulated lock prediction error.",
                    "label": 0
                },
                {
                    "sent": "If you use the model to sequentially predict the future given the past.",
                    "label": 1
                },
                {
                    "sent": "This holds for all data sequences or in expectation this actually does not hold for all data sequences.",
                    "label": 0
                },
                {
                    "sent": "So I've been a bit sloppier.",
                    "label": 0
                },
                {
                    "sent": "This holds.",
                    "label": 0
                },
                {
                    "sent": "It depends on what models you're using, but in general this this is a weaker statement.",
                    "label": 0
                },
                {
                    "sent": "It holds an expectation if one of the distributions in your models is true.",
                    "label": 0
                },
                {
                    "sent": "K is the number of parameters.",
                    "label": 0
                },
                {
                    "sent": "Distributions.",
                    "label": 0
                },
                {
                    "sent": "Well with the set, so this of course it's ahead test to something to do with the distributions.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "So if you have a large set.",
                    "label": 0
                },
                {
                    "sent": "K is larger then of course you will get a different different things will happen.",
                    "label": 0
                },
                {
                    "sent": "You will overfit more.",
                    "label": 0
                },
                {
                    "sent": "Right?",
                    "label": 0
                },
                {
                    "sent": "And the number of parameters if that's the same level parameters, right?",
                    "label": 0
                },
                {
                    "sent": "So the number of parameters is not so important for the complexity when the sample size is small, but if you fix the number of parameters and at the sample size goes to Infinity then it becomes dominant.",
                    "label": 0
                },
                {
                    "sent": "In determining how many extra bits you need compared to the best.",
                    "label": 0
                },
                {
                    "sent": "An distribution in your model to encode the data.",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So note that in this view the MDL procedure is very similar to cross validation.",
                    "label": 0
                },
                {
                    "sent": "Leave one out cross validation with one essential difference and leave one out cross validation.",
                    "label": 0
                },
                {
                    "sent": "You use the whole sample except one point to predict at one point.",
                    "label": 0
                },
                {
                    "sent": "You do that for all points and you add the total loss you make and then you pick the model with the smallest total loss.",
                    "label": 0
                },
                {
                    "sent": "Here you also predict all points, but at each time you only base your prediction on the past data and not on all other data.",
                    "label": 0
                },
                {
                    "sent": "And Interestingly, you see that asymptotically leave one out cross validation works like AIC.",
                    "label": 0
                },
                {
                    "sent": "It tends to select more complex models.",
                    "label": 0
                },
                {
                    "sent": "Then then MD LR base.",
                    "label": 0
                },
                {
                    "sent": "Where is this progression validation where you don't use the future, you only use the past to make your predictions.",
                    "label": 0
                },
                {
                    "sent": "Well, we've already seen that.",
                    "label": 0
                },
                {
                    "sent": "It's like MDL.",
                    "label": 0
                },
                {
                    "sent": "So not surprisingly, it behaves like BIC.",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So final important thing is that in practice, of course we want to compare often an infinite number of models.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "So if you do that, you cannot just pick the model maximizing this probability, or minimizing minus log of this probability, and so this is basically the final really crucial point to know very important.",
                    "label": 0
                },
                {
                    "sent": "What we want.",
                    "label": 0
                },
                {
                    "sent": "Is we want to cast?",
                    "label": 0
                },
                {
                    "sent": "Learning in terms of data compression.",
                    "label": 0
                },
                {
                    "sent": "So the way we do this in MPLS always we start by designing a coat which we can use to encode all data sequences.",
                    "label": 0
                },
                {
                    "sent": "And then based on that code, we make inferences.",
                    "label": 0
                },
                {
                    "sent": "Now, if our goal is not model selection but just prediction.",
                    "label": 0
                },
                {
                    "sent": "We can start with the code, turned it into a probability distribution and then use that probability distribution for sequentially predicting the future given the path.",
                    "label": 0
                },
                {
                    "sent": "That's what you've just seen.",
                    "label": 0
                },
                {
                    "sent": "But if we want to learn actual models or parameters.",
                    "label": 0
                },
                {
                    "sent": "Then we have to make sure that we don't just quote the data given those models, but we also quote the models themselves so.",
                    "label": 0
                },
                {
                    "sent": "If we do this.",
                    "label": 0
                },
                {
                    "sent": "If we want to select a model to explain the data, we should really minimize, not the code length of the data given the model.",
                    "label": 0
                },
                {
                    "sent": "But the total code length code length of the data given the model plus code length of the model.",
                    "label": 0
                },
                {
                    "sent": "If you only compare a finite number of models, then usually you take a uniform code because you want to be as honest as possible here.",
                    "label": 0
                },
                {
                    "sent": "So then this thing will be the same for all models and it doesn't play any role in a minimization and you basically.",
                    "label": 0
                },
                {
                    "sent": "Pick them all, minimizing this.",
                    "label": 0
                },
                {
                    "sent": "That's what we've done so far.",
                    "label": 0
                },
                {
                    "sent": "But if you have an infinite number of models than this, we can become important.",
                    "label": 0
                },
                {
                    "sent": "So if you add this term then your procedure is actually based on a code for coding all data sequences.",
                    "label": 0
                },
                {
                    "sent": "And so now in practice usually this term, even with an infinite set of models, will not have a large influence.",
                    "label": 0
                },
                {
                    "sent": "But you can use quotes here, which for which the code length increases only very slowly with I, so something called the universal code for the integers for which this will be approximately log I + 2 log log.",
                    "label": 1
                },
                {
                    "sent": "I.",
                    "label": 0
                },
                {
                    "sent": "So that goes up.",
                    "label": 0
                },
                {
                    "sent": "Very slowly.",
                    "label": 0
                },
                {
                    "sent": "And then typically this.",
                    "label": 0
                },
                {
                    "sent": "So if the model M Supply has I parameters, then there will be a term ioffer to log in here which will completely dominate this term.",
                    "label": 0
                },
                {
                    "sent": "So then this is not really important, but in some cases it is important.",
                    "label": 0
                },
                {
                    "sent": "For example, if you do variable selection in regression and sometimes the number of models you consider at a sample size of N. Is about 2 to the N rather than something smaller than N. And if it's two to the end, then this term can be really large and you really need to include it.",
                    "label": 0
                },
                {
                    "sent": "So note now that with this addition.",
                    "label": 0
                },
                {
                    "sent": "The whole procedure starts to look really quite like base, also because you can think of this L again as minus log of a prior.",
                    "label": 0
                },
                {
                    "sent": "And basically what you want to do is you want to specify a prior or for models.",
                    "label": 0
                },
                {
                    "sent": "And then you want to code the data using those models.",
                    "label": 0
                },
                {
                    "sent": "But the big difference to base.",
                    "label": 0
                },
                {
                    "sent": "Is that the way we specify quotes or the way we specify distributions doesn't necessarily have to go in terms of priors?",
                    "label": 0
                },
                {
                    "sent": "But here, because we want to use a two part code here, it's natural to use a prior.",
                    "label": 0
                },
                {
                    "sent": "But if we code the data given the model.",
                    "label": 0
                },
                {
                    "sent": "Then there is no need to quote any parameters.",
                    "label": 0
                },
                {
                    "sent": "Actually it's wasteful to code parameters, you're just interested in coding the data and then we want to basically say we want to integrate out the parameters, But then we might.",
                    "label": 0
                },
                {
                    "sent": "We can do this in a basin with the prior, but we actually sometimes prefer to do it in other ways because they might save us some extra bits.",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So as I said, if you.",
                    "label": 0
                },
                {
                    "sent": "Want to quote data given the models most, you could use that again using a two part code for your first explicitly called parameters and then the most given the parameters.",
                    "label": 0
                },
                {
                    "sent": "But that's wasteful because we've seen that is normalized.",
                    "label": 0
                },
                {
                    "sent": "Maximum likelihood could always give shorter code links and you want to minimize code lengths.",
                    "label": 0
                },
                {
                    "sent": "But if you want to encode the model index, you have to use a two part code because the model index is what you want to instruct extract from your inference procedure.",
                    "label": 1
                },
                {
                    "sent": "If you do model selection, you may not be interested in parameters.",
                    "label": 0
                },
                {
                    "sent": "You're only interested in the model structure.",
                    "label": 0
                },
                {
                    "sent": "Sometimes you are interested in parameters, then you want to encode them explicitly as well.",
                    "label": 0
                },
                {
                    "sent": "But in order to make predictions, you don't need to know the parameters.",
                    "label": 0
                },
                {
                    "sent": "It's enough to have these universal distributions because you can use them to make predictions of the future given the past.",
                    "label": 0
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So now I'll end by saying.",
                    "label": 0
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "A bit about other things you'll see today.",
                    "label": 0
                },
                {
                    "sent": "So anyway, I call this modern MDL, but by now it's more than 10 years old and in the last few years there have been quite a lot of new developments.",
                    "label": 0
                },
                {
                    "sent": "Which basically put much of this story on its head, but there was no time to adjust the tutorial completely to that.",
                    "label": 0
                },
                {
                    "sent": "And so one thing is that you of course you have noticed that this normalized maximum likelihood involves some offer enormously many terms.",
                    "label": 0
                },
                {
                    "sent": "It's in the number of terms in the sum is exponential in the sample size.",
                    "label": 0
                },
                {
                    "sent": "So it turns out nevertheless, that for some models you can actually compute the sum in time linear in a sample size, so that's nice and rather surprising.",
                    "label": 0
                },
                {
                    "sent": "So this means you can actually do this.",
                    "label": 0
                },
                {
                    "sent": "Which is of course important.",
                    "label": 0
                },
                {
                    "sent": "So there is 1 talk.",
                    "label": 0
                },
                {
                    "sent": "Of course you can do it anyway if you use approximations by this, for example, this prick wenczel method, but you predict sequential by maximum likelihood that can often be implemented, and it's a good approximation of MDL.",
                    "label": 0
                },
                {
                    "sent": "But if you want to really the optimal thing and a mouse thing, you can do this in some cases as well.",
                    "label": 0
                },
                {
                    "sent": "So patriarchy will talk about this today.",
                    "label": 0
                },
                {
                    "sent": "So then the real big issue of all this was that for many even very simple model classes like, let's say linear regression, Gaussian models, this animal distribution is undefined.",
                    "label": 1
                },
                {
                    "sent": "So this denominator, which is the sum or if you have continuous data, the integral over all data sequences of the probability according to maximum likelihood is infinite, and then it's undefined.",
                    "label": 0
                },
                {
                    "sent": "So what do you do then?",
                    "label": 0
                },
                {
                    "sent": "You can somehow do use a different sub optimal universal model, but Ascentia Lee in the last two years.",
                    "label": 1
                },
                {
                    "sent": "Kind of generic solution has been found, that's the so called luckiness principle.",
                    "label": 0
                },
                {
                    "sent": "I'll have one more slide about that.",
                    "label": 0
                },
                {
                    "sent": "And then there is.",
                    "label": 0
                },
                {
                    "sent": "Another way of dealing with this, which is called sequential, NML that's actually new development by your Morrison, but unfortunately he couldn't be here today, so I think Tommy Sealander will talk about that.",
                    "label": 0
                },
                {
                    "sent": "Then there are some interesting developments in.",
                    "label": 0
                },
                {
                    "sent": "If you use this for nonparametric inference with Gaussian process models.",
                    "label": 0
                },
                {
                    "sent": "So basically you can use this to explain the success of some basic nonparametric models and also explain the failure of some other basic nonparametric models.",
                    "label": 0
                },
                {
                    "sent": "And then there were some things I said which basically.",
                    "label": 0
                },
                {
                    "sent": "Puts the whole thing on his head, so note that asymptotically this MDL behaves like BIC.",
                    "label": 0
                },
                {
                    "sent": "Now it's well known that in some cases be icy is not the best model selection procedure there is.",
                    "label": 0
                },
                {
                    "sent": "There are other model selection procedure which leads to better predictions of future data when used for prediction and they essentially a sense of asymptotically behave like AIC, another model selection criteria.",
                    "label": 0
                },
                {
                    "sent": "So the question is, can you?",
                    "label": 0
                },
                {
                    "sent": "What's going on here?",
                    "label": 1
                },
                {
                    "sent": "Why is there another thing which is sometimes really better, and it turns out that this is something to do with the notion of universality we adopted.",
                    "label": 0
                },
                {
                    "sent": "Here.",
                    "label": 0
                },
                {
                    "sent": "We assign quotes to models so that no matter what data we get, we want to do as best as the best distribution in your model.",
                    "label": 0
                },
                {
                    "sent": "And it turns out that if you try to be not if you try it, you can sometimes be even better than the best distribution in your model.",
                    "label": 0
                },
                {
                    "sent": "And if you redefine universality in such a way that you can achieve that.",
                    "label": 0
                },
                {
                    "sent": "Then you get different notion of up these procedures and my invite to talk, but I will cast it in non MDL terms to get a larger audience but my invited talk it called in UI tomorrow will be about that.",
                    "label": 0
                },
                {
                    "sent": "Yeah, according to the schedule.",
                    "label": 0
                },
                {
                    "sent": "Is that possible?",
                    "label": 0
                },
                {
                    "sent": "I am I so when is my talk according to the Schedule 1040?",
                    "label": 0
                },
                {
                    "sent": "OK then that's good to know.",
                    "label": 0
                },
                {
                    "sent": "OK, so it's 1040 thanks.",
                    "label": 0
                },
                {
                    "sent": "Well, better, better did I'm there earlier than that I'm there late, of course.",
                    "label": 0
                }
            ]
        },
        "clip_55": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Final slides.",
                    "label": 0
                },
                {
                    "sent": "What if this MD else on this normalized maximum likelihood is undefined?",
                    "label": 0
                },
                {
                    "sent": "So lots of solutions have been proposed in the literature for that, some better than others.",
                    "label": 0
                },
                {
                    "sent": "But the question is, is there a generic solution?",
                    "label": 0
                },
                {
                    "sent": "And it seems that there is and what we can do is we can say, OK, this is the ordinary normalized maximum likelihood.",
                    "label": 0
                },
                {
                    "sent": "So we compare.",
                    "label": 0
                },
                {
                    "sent": "We try to find a distribution which is as close as possible to the maximum likelihood distribution, which is the same thing as a distribution which minimizes the code length of hindsight.",
                    "label": 0
                },
                {
                    "sent": "Now we say if the distribution doesn't exist which minimizes this coding overhead.",
                    "label": 0
                },
                {
                    "sent": "In the worst case.",
                    "label": 0
                },
                {
                    "sent": "We there might still exist some distribution which has a non uniform overhead, so the overhead is allowed to depend on the parameter.",
                    "label": 0
                },
                {
                    "sent": "For some parameters you will be lucky and you get a small overhead if that parameter turns out to be the maximum likelihood parameter.",
                    "label": 0
                },
                {
                    "sent": "For other parameters you will be unlocking, you get a larger overhead.",
                    "label": 0
                },
                {
                    "sent": "So if we have some luckiness function which expresses how bad we feel about a certain theater being the maximum likelihood how bad that is for us.",
                    "label": 0
                },
                {
                    "sent": "Then often this is defined after all.",
                    "label": 0
                },
                {
                    "sent": "Again, if a theater is uniform, we get the origonal maximum likelihood normalized maximum likelihood bed.",
                    "label": 0
                },
                {
                    "sent": "But if we take it non uniform then essentially you can do this for many models for which the ordinary normalized maximum likelihood is undefined and you get a luckiness normalized maximum likelihood distribution which looks like this and this again turns out to be asymptotically equivalent.",
                    "label": 0
                },
                {
                    "sent": "To a Bayesian universal distribution, not with Jeffreys prior, but with some kind of tilted Jeffreys prior.",
                    "label": 0
                },
                {
                    "sent": "So this place similar role to a subjective prior in basing statistics.",
                    "label": 0
                },
                {
                    "sent": "But there are also some subtle differences because essentially there are many things you can do with priors in base which you're not allowed to do with this luckiness function here, and this luckiness function, it doesn't have to be to really describe a belief so high a theater doesn't really mean that you think theaters improbable.",
                    "label": 0
                },
                {
                    "sent": "It may also mean that you think theater is not interesting.",
                    "label": 0
                },
                {
                    "sent": "If the maximum likelihood is close to theater, then I don't care about my model anyway, because I cannot make good predictions with it, so I can forget about that Theta, so.",
                    "label": 0
                },
                {
                    "sent": "A theater is like a prior, but there are some subtle differences.",
                    "label": 0
                },
                {
                    "sent": "But still, if you introduce this subjective element, is a theater, you can essentially extend this definition of normalized maximum likelihood to arbitrary parametric and nonparametric models.",
                    "label": 0
                },
                {
                    "sent": "So that's where I think a lot of future research will go to, so this is taken a bit.",
                    "label": 0
                },
                {
                    "sent": "That's it.",
                    "label": 0
                },
                {
                    "sent": "It's taking a bit longer than expected.",
                    "label": 0
                },
                {
                    "sent": "But still, I think there's time for some questions here.",
                    "label": 0
                },
                {
                    "sent": "So any questions at this point?",
                    "label": 0
                },
                {
                    "sent": "As Peter said, if you want some some kind of.",
                    "label": 0
                },
                {
                    "sent": "Issues that you would like to see us discuss during the panel goals with team here.",
                    "label": 0
                }
            ]
        }
    }
}