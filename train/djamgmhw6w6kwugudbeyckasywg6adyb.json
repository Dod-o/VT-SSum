{
    "id": "djamgmhw6w6kwugudbeyckasywg6adyb",
    "title": "Deep learning in the brain",
    "info": {
        "author": [
            "Blake Aaron Richards, Centre for the Neurobiology of Stress (CNS), University of Toronto Scarborough"
        ],
        "published": "July 27, 2017",
        "recorded": "June 2017",
        "category": [
            "Top->Computer Science->Machine Learning->Deep Learning",
            "Top->Computer Science->Machine Learning->Reinforcement Learning",
            "Top->Computer Science->Machine Learning->Unsupervised Learning"
        ]
    },
    "url": "http://videolectures.net/deeplearning2017_richards_neuroscience/",
    "segmentation": [
        [
            "So yes, as Joshua said, we're going to have a bit of a change of pace here this morning, because we're going to start.",
            "I know we've done a little bit of it.",
            "I saw riches talk, but we're going to start to focus a little bit more this morning on the actual brain as opposed to just artificial brains.",
            "Though of course the focus will be on trying to understand what unites both the artificial intelligence that we are all interested in here and the natural intelligence that sits in our skulls.",
            "So."
        ],
        [
            "I obviously the recent success of deep learning and artificial intelligence means that for most people, if you mention deep learning, they're going to think about AI.",
            "It's natural when you read news article after news article about how it's changing the world of artificial intelligence.",
            "But one of the things that I think many people often.",
            "Don't really know people who aren't involved in the area is that one of the goals of some components of deep learning.",
            "Research was always to understand how our own brains work.",
            "The researchers who really helped to resuscitate neural networks research in the 1980s, the parallel distributed processing Group wanted to understand human intelligence and wanted to understand how the brain works.",
            "So in this session.",
            "And sort of the ones in the early 2000s.",
            "That's right.",
            "So it wasn't just that if you look at, in fact, let's, let's be clear here.",
            "If you look at the people who really pushed deep learning forward in the 2000s, like Yoshua and Jeff and Jan and stuff they are interested in how the brain works so deep learning is not just about.",
            "AI it's also about your brain.",
            "I'm going to talk to you today a little bit about how current research is looking into how deep learning could be implemented in the real brain."
        ],
        [
            "Now let me just motivate this a little bit more.",
            "One of the other interesting things that's come out in neuroscience over the last couple of years is that deep learning models actually are a better fit to neocortical representations that we record, either in a functional magnetic resonance imaging system, or using tetrodes and monkeys.",
            "Then any of the existing models developed by neuro scientists to explain the brain, and that's, I think, a very interesting fact.",
            "So what you're looking at here is on this plot the.",
            "X axis is the categorization accuracy of different visual processing models on.",
            "I forget which data set it might have been cifar 10 or something like that.",
            "And on the Y axis you have a measurement of the resemblance.",
            "Between the representations in that computational model in that neural network and the representations that were actually recorded either in human inferotemporal cortex on the top or in monkey inferotemporal cortex on the bottom.",
            "And one of the first things that of course should jump out at you is that there is a correlation between how well the models do on categorizing different images and how similar their representations are to what we actually measure in the brain of primates.",
            "But the second thing I'll point out is that so each dot here represents a different model, A different computational model, be it a neural network or some other model, and the colored dots represent different layers of a deep convolutional neural network.",
            "So here at the top you see Layer 7 of a deep convolutional neural network.",
            "It's of course doing better at categorization of the images than any of the other models that we all know.",
            "That's why you're all here.",
            "But also, Interestingly, it is more similar to the representations observed in inferior temporal cortex of humans brains.",
            "And that's pretty remarkable, so the little numbers are.",
            "The little numbers are each a different model that a neuro scientist has proposed to explain how visual processing works in the brain and that is their results on categorizing cifar 10 and their similarity to human cortex.",
            "What is that paper?",
            "Oh, I'm sorry, I didn't cite that paper.",
            "My apologies, I will send Gram updated slides with that citation.",
            "All the other citations are in the talk.",
            "Excuse me, I was working on a DARPA grant this week.",
            "The this was by Nicholas Cortez Lab at Cambridge, but I will I will be sure to update the slides so you can look this paper up as well.",
            "My apologies so anyway.",
            "The underlying message is that it looks like we have more questions, yeah?",
            "I'm here now.",
            "That's correct.",
            "Category yes.",
            "Anymore.",
            "That categorisation will.",
            "A.",
            "The dish.",
            "That no, that's not actually trivially the case.",
            "So for example, one of the interesting things that came out of this paper.",
            "It's a good point though.",
            "Sorry yes.",
            "So let me try to paraphrase what you said.",
            "Given that we're looking so so you know inferior temporal cortex is a region of the brain that's particularly concerned with the categories of different objects that you're looking at, and So what was pointed out is that if you have a model that is principally concerned with categorization, and you look at the upper layers where all the categorization is going on, inevitably it's going to be a better match to region of the brain that is doing categorization.",
            "Is that roughly correct?",
            "Yeah.",
            "Right?",
            "Sure, yes.",
            "However, here's what's interesting.",
            "So one of the things that this paper showed was alright.",
            "So one of the differences between one between what human brains seem to be doing and what a lot of the other models seem to be doing is that there are, Interestingly enough, very large distances between the representations for animate and inanimate objects.",
            "In the human brain, and that doesn't pop out of the existing neuroscience models.",
            "It only comes out of these deep learning models.",
            "Once they've been trained to categorize that, but that's not necessarily always going to be the case per say, like you could imagine a system which is perfectly good at doing categorization but doesn't have larger distances between inanimate, inanimate objects, then it does different categories of animate objects, for example.",
            "Now what I will say though, where I think you're very right is look the reason that these deep neural networks are ultimately coming to resemble this part of the brain is in part because we're training them on a categorization task.",
            "But what's interesting is if you train deep neural networks on other things as well or even on categorization tasks, there's even still better matches in lower parts of the visual hierarchy that are principally responding to category.",
            "What I the other thing I'll add to this though, is I think that the reason it comes out is simply because the correct answer to doing these categorization tasks.",
            "Is in fact to have the distances between the different categories that the human brain does, because that is the result of cost function optimization will come back to that though.",
            "But anyway, yes, thank you.",
            "That's a very good point."
        ],
        [
            "So.",
            "Anyway, what I was trying to do there ultimately is just motivate the idea that our brains are doing something like deep learning.",
            "And.",
            "Let's just be clear on what we actually mean by that.",
            "So of course the key to deep learning.",
            "Is the ability to improve learning by adding hitting layers if you if you look at ultimately what distinguishes the modern approaches in neural networks to other approaches and machine and machine learning or machine vision, etc.",
            "It is the addition of all these layers to the model.",
            "So.",
            "If you're going to use a model that has many hidden layers to it.",
            "The issue that you're going to be presented with.",
            "Is what's known as the credit assignment problem.",
            "So the credit assignment problem is is this, which you're probably familiar with.",
            "If I'm a neuron in a hidden layer.",
            "And I need to update my weights in order to optimize on some cost function.",
            "I need to know how much credit and or blame I should get for the current results that the network is getting on the cost function for the current behavior of the network.",
            "So.",
            "We need some way of assigning to each neuron in each synapse in the hidden layer its contribution to the output of the network."
        ],
        [
            "Now, the obvious way to do this, of course, is backpropagation.",
            "So backpropagation has been invented multiple times by different groups, and the reason is that it is kind of like if you're addressing this question of how am I going to do credit assignment in the hidden layers.",
            "It's it's kind of a nice, clear, obvious way of doing it, so of course you all know, but we're just going to review here very quickly that the principle behind backpropagation.",
            "Is that we're taking the partial derivative of our cost function with respect to the synaptic weights in the hidden layers?",
            "So if we have a neural network here with input X hidden layer activities H, output Y target T. We can define the error as being the difference between the output of the network and the target.",
            "Our loss function is then just the squared error, and if we take the partial derivative of this loss function with respect to the weights and the hidden layers, we get this expression.",
            "Just using the chain rule.",
            "So this equation then for a one layer hidden 1 hidden layer neural network and I'm going to stick to this just for say covies.",
            "In this talk, but it everything I say should ultimately apply to more layers.",
            "If you, if you have this equation, this is your weight update for the synapses in the hidden layer."
        ],
        [
            "Now let's unpick this a bit.",
            "So here's the equation we need to do.",
            "We need all this information to update our synapses in the hidden layer of the neural network, and so let's just start to pick it apart.",
            "Let's look at what the brain would actually have to calculate in order to do back propagation, right?",
            "Like if we're saying the brains doing something like deep learning and most of our deep learning systems use backpropagation, does our brain do something like backpropagation and so?",
            "Let's see what the brain would have to calculate to do that.",
            "Well, of course the first thing is you need the error term, so you need the difference between the output generated by a forward pass through the network and some target that has been assigned to the network.",
            "You're going to multiply that by the transpose of the downstream weights, so you've got a set of synaptic weights from the hidden layer to the output layer, and that's got to be there in your equation multiplied by your error term.",
            "Additionally, you need the derivative of the hidden unit activation function.",
            "And.",
            "Ultimately, all of this, both the error and the derivative of that hidden unit activity, depends on you having an initial forward pass through the network, and then theoretically a backward pass where you're calculating this.",
            "So we've got these four elements that we need for this equation to work.",
            "You also need, of course, the input, but we're assuming that that's trivially available to the brain.",
            "So we need these four things we need.",
            "Our error term.",
            "We need the transpose of the downstream weights.",
            "We need the derivative of the activation function and we need separate forward and backward passes.",
            "Alright, well The thing is that all of these are problematic for the brain.",
            "And it is, in fact, why neuroscientists, for many years, largely dismissed the idea that the brain does anything like backdrop.",
            "Because if you're an intelligent biologist and you understand what these terms are, and you understand how you could calculate them, you take a strong look at it.",
            "You're like, well, this is just bonkers.",
            "The brain can't do this.",
            "So let's run through each one.",
            "So at least in the neocortex, so the brain can calculate error terms.",
            "That's not actually the biggest unit of itself, but the specific error term, the difference between a forward pass.",
            "And some target that you've received.",
            "There's no evidence for anything like that in the neocortex.",
            "And of course, the neocortex is the region of the brain that we're interested in here.",
            "Sorry, I didn't say that earlier.",
            "We're interested in it, not only because it has good matches to deep learning models, as I showed you with the previous result, but also because.",
            "To the best of what neuroscientists concede, the neocortex is the closest thing to a kind of general purpose learning machine, akin to the artificial neural networks we learned we use in AI.",
            "Now some other parts of the brain can definitely learn, but they are often crafted towards more specific purposes.",
            "Your neocortex is really this incredible, just general purpose, homogeneous learning machine.",
            "So there's no clear implementation of those kind of error terms in the neocortex, and that's problematic.",
            "The second one, an one that's been arguably more traditionally like a total nonstarter for many neuroscientists, is this issue of the transpose of the downstream weights.",
            "If you are a neuron early in visual processing stream, so let's say you have a neuron in your primary visual cortex.",
            "The idea that it would know the synaptic connections all throughout the rest of your visual processing stream is just crazy.",
            "We know of no physiological mechanism by which that could be the case now.",
            "Alternatively, you could have a situation where you've got feedback weights that are perfectly symmetric, and we'll talk about that in a moment, but that in and of itself is also problematic, so experiments show if you take any two neurons and you look at whether they are connected to each other there is.",
            "Not only no guarantee that the synaptic weights between them will be similar, there's no guarantee that they will both be connected reciprocally to each other.",
            "So it's a totally non trivial matter to have backwards projections that are symmetric with your forward projections.",
            "And this was something that Francis Crick pointed out in an article back in the 1980s when people first got excited about back propagation in kind of cognitive science.",
            "An ever since that point, most neuroscientists have dismissed the idea of anything like this occurring in the brain.",
            "Now.",
            "The other thing you need is the derivative of the activation function so.",
            "That's fine when you've got a sigmoid activation function applied to a linear term.",
            "But in real neurons, this is actually difficult, so real neurons don't actually communicate analog signals to each other.",
            "They communicate with something known as spikes, which we'll talk about a little bit more in a couple of slides, and spikes are all or none events.",
            "They can be thought of as effectively yes or no.",
            "And the problem is that when you've got an all or none event, it's not clear how you take the derivative of that.",
            "So that's another problem.",
            "For this I would just say that yeah there are.",
            "There's there are groups that have shown that you can train spiking known networks.",
            "Oh yeah, we're going to cover one of those papers.",
            "Yeah, it's not actually a problem.",
            "I'm going through the logic of why neuroscientists haven't bought back prop in the brain.",
            "In fact, the rest of this talk is going to be me knocking down each of these points.",
            "So.",
            "The other issue is that there's no evidence for separate forward and backwards passes, right?",
            "Like when we look at the activity in your brain, it's not the case that like light hits your retina and then there's a sweep of electrical activity forward through your visual processing stream and then after that a sweep backwards of electrical activity from.",
            "I don't know, your prefrontal cortex or something like that.",
            "Your entire brain is always active.",
            "It's always chattering amongst itself and.",
            "The idea of separate forwards and backwards passes at face value seems problematic.",
            "OK, but as I was saying over the last couple of years, we've seen a lot of progress in addressing all four of these issues, and I'm going to try to bring you up to date on that and just maybe convince you that it is in fact possible that our brains do something like backpropagation."
        ],
        [
            "OK, so let's start with that first one the error term.",
            "So the brain, as I said, can definitely Calculator terms.",
            "Your motor system is full of error terms and they're really important for helping to correct motor control that you're doing online.",
            "But as I said, you know there's no evidence for something like this sort of error term that we want for backpropagation.",
            "For many of the things that you need, Cortex learns.",
            "So let's say, for example, when you're learning to speak right, there's no evidence that you try to speak as a kid and then somehow a target is formed in your brain based upon what your parents are saying, what you did, and what your parents say gets subtracted from each other and then not subtraction somehow gets propagated through your brain.",
            "There's no evidence for anything like that.",
            "Now, but it is the case that you do have your parents talking around you and giving you an example of how to speak.",
            "So even though you don't have this explicit comparison between what you did and what you should do, you probably do have something that's kind of pushing you towards the right answer some of the time.",
            "And so ideally, what we'd like is we'd like a network which has these sort of."
        ],
        [
            "Just like nudging signals so that the network just occasionally gets pushed by environmental feedback towards something that is more like the right answer than what you had done previously, and that theoretically possible given the stimulus we received in the environment.",
            "So, um."
        ],
        [
            "This is something that Yahshua and his postdoc is Benjamin New postdoc.",
            "PhD student and his PhD student Benjamin have been working on an they released this year of paper on system they call equilibrium propagation.",
            "And Yashua, feel free to correct me if I got any of this wrong, I know.",
            "So.",
            "What they what they do in this system?",
            "Excuse me what they do in this system is.",
            "Rather than having a forward pass and then explicit calculation of an error between that forward pass and some target that you have, they've got two different phases for their network, so here's an image of the basic idea for a network that's going to do something like backdrop.",
            "Though this algorithm works with many different network architectures, not just this stacked architecture.",
            "I'll just mention a change of variables here, so we're still referring to our input is X.",
            "Our output is Y&R hidden layers is H but now you here is going to refer to the entire set of units activities.",
            "Uh and D is our target.",
            "Now the idea is that what you have is you have a phase where there is no kind of nudging from the external environment, so this would be like your parent who's speaking correctly in front of you right?",
            "And so sometimes you don't have your parent there and there is no external nudging signal, but sometimes you do and they use this term here beta to indicate the difference between those situations, so they call.",
            "When beta is equal to 0, that's the free phase, and that's when there is no nudging on the system from the environment.",
            "When beta is greater than zero, the system is being pushed towards the right answer by the environment and they call this the weekly clamped phase.",
            "The to get a full clamping like is done in actual artificial neural networks.",
            "You would have beta equal to Infinity and then the system is just kind of like a standard neural network and that during that clamped phase it is getting the correct answer forced on it.",
            "But as long as betas, non infinite, but we've got is weak clamping and so the system is just kind of getting nudged towards the right answer.",
            "And So what they?",
            "What they show?",
            "I'm not going to run through all the derivations and stuff.",
            "I leave you to look it up in this paper here.",
            "So they develop energy terms for this network so that they can know what the networks going to settle to.",
            "Both with the nudging term and without the nudging term.",
            "And then.",
            "By taking the derivative.",
            "Of their energy terms, they can get out this synaptic weight update.",
            "So this synaptic weight update basically says if you've got any two neurons that are Co active together during the point in time in which the nudging factor was present, you want to increase the weight between those two neurons.",
            "And if you have any two neurons that were Co active during the point when the when it was in free phase, you want to decrease the weight between those two neurons.",
            "And this difference is then going to give you your weight update, and in fact what Benjamin and Joshua Show is that this can implement stochastic gradient descent on the standard loss function.",
            "Just the error between D&Y.",
            "Now, this is reminiscent for those of you who do know this kind of stuff of things like contrastive divergent's or Boltzmann machine training in that you are kind of looking at.",
            "Yeah, he's actually not just squared error, but any laws that any losses differential OK, right right where the loss is defined by how your what your target is right, yeah, OK.",
            "Right cool.",
            "I so.",
            "What what's very interesting about this then, is so, like I said, it's got a flavor kind of like contrast convergence, kind of like Boltzmann machines, etc.",
            "But critically, they're not.",
            "Really just clamping the correct answer on the system.",
            "There is no point in time at which the system is forced to have the correct answer.",
            "Instead of just getting nudged towards the correct answer, which is something probably more like what your brain actually has and is less problematic than the error term that is typically passed around in backpropagation, I think.",
            "Now the other thing that's very interest."
        ],
        [
            "About this is it predicts a classic set of experiments known as spike timing dependent plasticity.",
            "So let me unpack this a little bit for you.",
            "So here you've got an illustration of two neurons.",
            "These are the yellow dots.",
            "That's what neurons look like.",
            "And they are connected by a synapse, so we've got a presynaptic neuron jayanna postsynaptic neuron I and we can look at the time at which these two neurons are act."
        ],
        [
            "Excuse me, I'm going to do that.",
            "We can look at the time."
        ],
        [
            "These two neurons are active, so here we've got a little plot neuron.",
            "J is active at this point in time and Neuron I is active.",
            "At this point in time.",
            "And when I say active I mean firing a spike.",
            "And what researchers have shown, not just in the neocortex, but in a remarkable number of brain regions.",
            "Is that if you look at the difference in time.",
            "So if you take 2 neurons that are connected and you repeatedly get them to spike with some temporal difference between them.",
            "So let's say we always get the red neuron to spike just before the green neuron, then you're going to get a particular change in the synapse and the change in the synapse is going to be dependent upon that difference in time between the presynaptic and postsynaptic spikes.",
            "So that's what's actually plotted here on the X axis on the X axis is the difference in time between the presynaptic spike and the postsynaptic spike.",
            "Where it's TJ minus TI.",
            "So if TJ is greater than T wherein the negative phase.",
            "Sorry if it's less than T were in the negative phase he ran.",
            "If TJ is greater than T were in the positive phase here.",
            "So in other words this half of the plot is where T the J neurons spiked before the eye neuron and this half of the plot is where the I neurons spike before the Jane, Ron and these dots are actual experimental.",
            "Recordings of so on the Y axis were plotting the change in the synaptic connection between them, and you see this very clear relationship between the temporal difference between those spikes and how much the synapse between those two neurons change.",
            "And neuro scientists got very excited about this result when it was when it first was discovered, and especially when it continued to be discovered in a number of brain regions because.",
            "It's the closest thing they had kind of ever gotten to a clear learning rule for how synapses are updated in response to patterns of activity.",
            "And you can show that it has some interesting properties.",
            "It seems to be, for example, training neuron J to predict the activity of neuron I.",
            "It has a kind of causal flavor to it.",
            "But what's interesting?"
        ],
        [
            "Is so Joshua and Benjamin showed that in fact.",
            "You can get STD P out of a set like out of a learning algorithm that has this relationship where the change over time of your weights is a function of your postsynaptic activation times.",
            "The temporal derivative of your presynaptic activation.",
            "That was the original 1 right?",
            "And then you can modify this to instead be the derivative of the full activation function.",
            "Right?",
            "Anne, what they also show is that this relationship does in fact hold for their equilibrium propagation algorithm.",
            "And so.",
            "In other words, their algorithm, though it's ultimately designed to be doing gradient descent on these cost functions.",
            "Spits out STD P. If you were.",
            "If you were, if you imagine that there we had a neural network learning by this algorithm and then you were an experimentalist testing for the learning algorithm in it, and you ran the STP experiments, you would get the same results that real neuroscientists got in the brain, so that's a very interesting finding and very exciting in many ways.",
            "But Yep.",
            "Can you deal?",
            "There's a little more precise about this experiment, so like sure TJM TI are you like?",
            "Would be that?",
            "You're directly manipulating the voltage potential of these two neurons independently, correct?",
            "And then how do you measure this change in the synaptic connectivity?",
            "Sure, OK, so the way you do these experiments is you perform what's called a Patch clamp recording on both these neurons, so a Patch clamp recording is where you go with a tiny little glass pipette.",
            "And you literally suction onto the neuron and then you burst a hole in its membrane so that you can record its intracellular electrical activity.",
            "And So what they do is in these experiments is they'll Patch 2 neurons and then they can determine whether they are synaptically coupled by injecting current into the neurons and seeing if it induces a response in the other neuron.",
            "That is to say, if they inject current, say into neuron J and they cause it to spike, do they see a postsynaptic response in neuron I with their Patch clamp recording?",
            "And So what they do is they will then if they find 2 neurons that are synaptically coupled, they will inject current into neuron J and inject current into neuron.",
            "I at slightly different times to create this pattern of a spike in neuron J and spiking neuron I at different times and they do that many, many times over.",
            "Now the way that they measured the synaptic strength is a measure that postsynaptic response to neuron J spiking.",
            "So when you cause neuron Jada Spike at first, you're going to get some response.",
            "In neuron I you can measure that and then after you do this protocol, you can do that again and you can see how that postsynaptic response changed.",
            "Yep.",
            "Right?",
            "Summarize.",
            "So well, I was having trouble with your last bit there, but the first question was I if I take it correctly, was to what extent to these networks suffer from the same capacity issues that Hopfield networks suffer from?",
            "Is that roughly right?",
            "OK, I don't know the answer to that.",
            "Do you want to address that?",
            "They don't.",
            "They have the same capacity as the normal people, right?",
            "Yeah, 'cause there ultimately, although you're right, the flavor is similar in terms of the use of an energy function and stuff like that.",
            "Limited capacity is because they don't have hidden units.",
            "That's the problem, right?",
            "Connection is basically stored only well order of endangered.",
            "It's because they can't increase capacity, but here you can put as many hidden units as you want, right?",
            "OK. Any other questions?",
            "If you are very similar to how people answer anyways, yeah.",
            "So another number, yeah?",
            "So how does the temporal groups come in here?",
            "Sorry, yeah, that's a good question, thank you.",
            "So OK, the idea is that.",
            "Alright, if at all.",
            "If you if you consider the what's happening to, the voltage is in the neurons.",
            "At the point in time in which you're running these STP experiments, right, presumably.",
            "As when neuron I is excuse me.",
            "Now in fact, now that I'm looking at this equation, I. I&J are reversed.",
            "That's right, excuse me so ING reversed.",
            "Uh, so.",
            "You'll have to excuse me, let's.",
            "Well, I don't yeah.",
            "Let's make that.",
            "Oh, I shouldn't actually be doing this.",
            "'cause I'm on camera, but so let's let's let's reverse it.",
            "So if it's.",
            "I UJ Anthy, sorry UI.",
            "Yes.",
            "It should be like this.",
            "Right, 'cause it's the temporal derivative of the postsynaptic neuron that we're interested in, yes, so the way this works is, let's imagine that neuron.",
            "Jr presynaptic neuron is active.",
            "Right here and at that same time neuron IR postsynaptic neuron has an increasing voltage, so the temporal derivative of its voltage is positive.",
            "That is probably a moment just before neuron I is going to spike.",
            "So if you, if you're doing this protocol, the derivative of neurons are neuron eyes, voltage at the time of.",
            "Of the input from neuron J is positive and so this relationship, not this one.",
            "Another error for my slides to correct excuse me is going to give you potentiation and that's what you see right here.",
            "In contrast, if you have the postsynaptic neuron spike before the presynaptic neuron, then the derivative of the postsynaptic neurons voltage is going to be going down at the time that the presynaptic inputs arrive, and so that's going to give you a negative term, and you're going to decrease the weights.",
            "OK.",
            "So."
        ],
        [
            "I we can do back prop without explicit error terms an we can just kind of have a system where the neural network is nudged towards the right answer by the external environment.",
            "And Interestingly it seems to match experimental data on spike timing dependent plasticity, so that's cool item number one down.",
            "Alright, now transpose the weights so.",
            "That previous model that I showed you is still depending upon symmetric weights in the network, and the idea that the neurons somehow have access to the transpose of the downstream weights, which is problematic.",
            "And as I said, that is."
        ],
        [
            "In fact, one of the biggest issues as far as neuro scientists are concerned.",
            "So let's draw out what it would actually have to look like.",
            "So here we've got a neural network, some hypothetical neural network that exists in our brain with input hidden unit output.",
            "And the colors here represent the synapses onto neurons in the output layer an.",
            "In order to calculate my weight updates in my hidden layer theoretically, what I need is I need a pathway that's going to send the error term back.",
            "And do so with synapses that exactly mirror the synapses here.",
            "And this, as I said, is what most neuroscientists consider to be bonkers, because that's a very difficult setup.",
            "And certainly it's nothing you should assume exists in the brain.",
            "And experimental data suggests that it most definitely does not exist in the brain.",
            "Although.",
            "There are feedback connections, it's just that there's the evidence suggests that they're not perfectly symmetric.",
            "Like I said earlier, that.",
            "For some pairs of neurons, there aren't any feedback connections.",
            "That's correct, yes.",
            "Backpack.",
            "That's right, so it could be that they are connected indirectly via a couple of different neurons, but then it makes the question of having symmetric synapses even harder.",
            "So it's a very difficult problem.",
            "Now let's just simplify this illustration a little bit, so the idea is that here we've got synapses W, not here.",
            "We've got synapses W one, and then we've got feedback projections from the output layer to the hidden layer that are somehow just the transpose of W. One.",
            "That's the original idea of backpropagation.",
            "And like I said, it leads many neuroscientists to dismiss it.",
            "Now The thing is though, so Tim Lillicrap, who's researcher at Google DeepMind now.",
            "He and I we we took Jeff Hinton's neural networks courses, undergrads together long ago, and we both drank his Kool aid and we.",
            "We were convinced that the brain did backdrop at the time.",
            "That was a very controversial idea.",
            "It certainly wasn't in Vogue, and but he and I and I were sure it did something like that.",
            "So we had had many discussions about.",
            "OK, well, even if you're not guaranteed symmetric weights, how could you maybe learn how to have symmetric weights?",
            "So could you design A learning algorithm where you could actually train the feedback connections so that they will eventually give you this metric weights that allow you to do back propagation?",
            "And Tim decided that he was going to try to.",
            "He's going to jump into it.",
            "I was a young father doing a postdoc at the time, and I was like, yeah, whatever you go ahead, he's he's going to jump into.",
            "So he's going to train a learning algorithm to learn these backwards weights now."
        ],
        [
            "He had an algorithm that he was interested in and to test his algorithm he wanted to develop a control case.",
            "Now the obvious control case was to use a condition where rather than sending the error back through the weights that he's trying to train, he sends the error back through some random matrix B, which he leaves fixed, so he doesn't train the backwards weights, you just send the error back through a random matrix and updates using."
        ],
        [
            "This random matrix B in place of the transpose of the feedforward matrix.",
            "And so theoretically that should be crap.",
            "And that's going to be his control case to compare his learning algorithm to which should be doing well.",
            "But weirdly."
        ],
        [
            "Enough, the control condition learned quite well.",
            "It worked better than his.",
            "He he came back.",
            "He called me on the phone that week he came right back to his simulations and he saw it and he ran it a couple more times and.",
            "He called me.",
            "He was like I have this weird really really weird result.",
            "I don't know what's going on.",
            "My control condition is learning better than my than the learning algorithm was trying to design.",
            "I think it must be a bug, but I'm going to run it again and again and again and he did it again and again and again.",
            "It always came back.",
            "The control condition learned better than his learning algorithm learn quite well.",
            "And so in fact.",
            "So what he called this situation where you're just pumping back through a random matrix.",
            "He called this feedback alignment and you'll explain why in a second.",
            "Here I'm showing you a plot of the test error that he gets out on Em Nest in a 1 hidden layer neural network.",
            "So just a fully connected neural Network 1 hidden layer.",
            "Well, the shallow network is is no hidden layer, so that's as expected.",
            "This is why we're all at a deep learning summer school because the shallow network sucks.",
            "But then here is back prop.",
            "And just running vanilla backdrop on amnesty and a fully connected network, you'll get down to like 2.4%.",
            "And here's his algorithm using the random matrix and it's actually doing a little bit better than backpropagation in this network, which is weird.",
            "What's going on?",
            "So it turns out that the reason this was working is that the forward weights actually align themselves with those random backwards weights.",
            "So here's what I'm plotting here.",
            "This is so you can look at the weight updates that are prescribed by this feedback alignment algorithm and the weight updates that are prescribed by backpropagation for the hidden layer.",
            "And both of these are just vectors that we can measure the angle between, right?",
            "So feedback alignment this using the random matrix is going to push the weights in a particular direction and wait space back propagation is going to push it in another direction in the weight space.",
            "And if you have any two vectors in a very high dimensional space, just random vectors in high dimensional space, they're going to be orthogonal to each other.",
            "So if these two algorithms were doing something quite different, they should be these two.",
            "The angle between these two things should be 90 degrees.",
            "And indeed, that's what happens when you first start running the algorithm.",
            "It may be hard to see here, but the first point, so we're plotting across training examples.",
            "The angle between what backpropagation is prescribing and what his feedback alignment algorithm with the random matrix was prescribing.",
            "And it starts off orthogonal and then it rapidly drops down.",
            "So the system is actually coming to prescribe weight updates now like this is just below 45 degrees here, but in a high dimensional environment that's actually pretty much in the right direction.",
            "It's getting pushed yeah, and it's going down and it's going down right?",
            "Yes?",
            "So in other words, what the network is doing is it's actually learning over the first few training examples to basically approximate backpropagation.",
            "And the way it's doing that is.",
            "What Tim shows in the paper, which you can read here, is that this.",
            "Weight matrix is coming to be.",
            "In fact the pseudo inverse of the random backwards projection.",
            "And so that's why the system actually learns quite well because it's actually approximating something 2nd order because it's not just the transpose, it's coming to approximate the pseudoinverse.",
            "Um?",
            "So."
        ],
        [
            "That was surprising, and it means that we can do back prop without the transpose of the weights, yeah?",
            "1 Hidden layer order.",
            "This is just an observation.",
            "It seems that the weights will converge towards metric OK, right?",
            "Right, yes, and so let me just say something to that."
        ],
        [
            "Fact, I think that.",
            "So with this algorithm, what Tim's result illustrates is that.",
            "You don't need to have symmetric weights to get things up and running, but that is not to say that the feedback weights are not learning and learning in a way to help make credit assignment on a cost function better.",
            "So I think you know we do know that the backwards projections in our brains are plastic.",
            "And they are probably learning, unlike in this case, but nonetheless what this tells us, and that's what you was getting at, is if you have an auto encoder, it will learn to give you the right sort of weights for backdrop.",
            "So if our brains say or stacked autoencoders, then we could effectively be doing backdrop through that system.",
            "But the point is, and this is what's reassuring for me.",
            "Is a neuro scientist, even if it doesn't get it perfect.",
            "So even if it doesn't have ideally symmetric weights.",
            "The system is still going to learn quite well in fact, and it means that we are no longer faced by the strict requirement that we have symmetric feedback weights to do back propagation in the brain.",
            "So they also get some experiments on a deeper version of the network that the results were very convincing.",
            "As far as I'm concerned, right?",
            "This extends to yeah, so this is yeah, so I left that point out, but that's true.",
            "The extent to which this generalizes to ever deeper networks is questionable, and so I think to get to networks with many hidden layers, you probably need some kind of training on the feedback system to have it work.",
            "Yeah, is there some linear algebra reason why the.",
            "Back propagated error signal which is soon by the transpose should be have a positive inner product or less than 90 degrees angle with the feedback if the feedback was impacted by a pseudoinverse like are, the suit is the output of the pseudoinverse in the output of the transpose for some reason going to be aligned?",
            "Yes, I mean so.",
            "The extent to which the output from running it through the pseudoinverse versus running it through the transpose, the extent to which they are aligned is obviously going to depend upon the extent to which the transpose in the pseudoinverse are similar matrices to each other.",
            "Similar linear transformations and.",
            "I mean here I don't want to expect.",
            "I don't want to comment too much because I haven't actually analyzed this, but they're going to be roughly in agreement for many matrices right?",
            "Many random matrices, right, I guess.",
            "I thought I could find some inputs to these two operators such that the output would be anticorrelated.",
            "You know, kind of proven 90 degree angle.",
            "That's a, that's a good question.",
            "I you know I'm going to have to say that I don't have a good intuition for why that cannot be the case.",
            "I don't know if you do.",
            "Yeah yeah.",
            "I mean, that's certainly true most of the time, but why do we never see it pop above 90 degrees?",
            "Well, I mean so it might have something to do with the the inputs to the.",
            "Whatever you want to call it back way as well, Yep.",
            "That's a good question.",
            "I I'm going to think about that more.",
            "OK, so sorry, just to yet another question.",
            "Wait?",
            "My.",
            "My.",
            "Problem with feedback is that if the backwards way Sir are frozen for all time, that's also so much biologically improbable.",
            "Oh yes, changes all the time.",
            "Yes, yes, it's not like.",
            "A way to distinguish in particular synaptic weight as backwards or forwards, and that one should freeze and that one should not well, OK. That second statement is not true.",
            "There is a way to determine which weights are the backwards and forwards weights in fact, but I take your larger point and we'll talk about that in a second, but I take your larger point that backwards weights in the real brain are undoubtedly not frozen.",
            "Like I said, in fact, we know experimentally that they are changing.",
            "I.",
            "But again, the reason that this is satisfying is not because I think the brain is learning with frozen backwards weights.",
            "It's a demonstration that the explicit symmetry that was assumed to be required to do stochastic gradient descent in a multilayer neural network is not in fact required for that, and that means that the brain doesn't have to meet the stringent symmetry requirements.",
            "That led many neuroscientists to dismiss the idea of backdrop in the brain.",
            "Yep.",
            "Presentation generated so yeah.",
            "To be aligned with the random matrix and the neurons.",
            "One thing.",
            "Well, no, OK.",
            "So let's clarify it."
        ],
        [
            "W 0 doesn't align with the random matrix W one does now.",
            "In fact, what W 0 ends up doing is producing a set of weights that separate the representations for the different inputs in a manner that respects the separation that the error term imposes on them.",
            "So if you look at the representations, it's a good question.",
            "If you look at the representations in a network that's trained with feedback alignment.",
            "What it does is in the hidden layers it separates the different categories onto different manifolds in fact.",
            "So if you run T sne on the representations in the hidden layer.",
            "You will find that your categories are in fact pulled apart from each other and lie on clean different manifolds much more so than in the input.",
            "Sure, yeah, it learns exactly the same type of features that something like backpropagation does, which as you've seen from the number of talks, an papers and stuff often look like many of the features that we see in the brain, edge detection, etc.",
            "So on a single neuron level it matches intuitions, and on on the vector level it also matches intuitions.",
            "Surprisingly.",
            "When you have like this feature representation and you project, that will basically run the matrix and you get correct location.",
            "Well, so the key is that the representations that are getting learned here are going to separate out the different categories because your still your error term is going to give you information on how the different categories should be separated and even when you run that through a random matrix you've still got that information available to you.",
            "So in order to respect the.",
            "Information that the feedback is sending this hidden layer will develop a set of representations that separate out the categories and now the goal of this weight matrix is basically just to figure out what the transformation is from those representations to the output space, which is in fact to do the inverse of B.",
            "That's why it learns to align itself.",
            "That's right, yeah.",
            "So this is what we were just talking about.",
            "Is the pseudoinverse in the transpose are not going to be identical to each other, but they're going to provide?",
            "At least empirically, we see that given a large number of different random matrices that you select for B, they actually provide the same direction of push on the hidden layer.",
            "But we can imagine matrices like if we design B to give us a big difference between the pseudoinverse in this and the transpose, then maybe we could push back prop and feedback alignment away from each other.",
            "Yep.",
            "That's not directly connect.",
            "You need the news, yeah?",
            "Yes.",
            "At the same time, well, OK, so that's a good question.",
            "These are one of the many unsolved issues, so dealing with the all of the many different delays that exist in the brain and figuring out how you do credit assignment appropriately.",
            "Given all of those different delays is not a trivial thing to workout, but I think the important thing, and this is what?",
            "I always say to neuroscientists is the point is not that these models solve all the problems for us.",
            "They're not telling us exactly how the brains doing it.",
            "They're here to illustrate that what we thought was a problem is not, in fact, a problem.",
            "Now the delays is still a problem, but there will be other ways to deal with that.",
            "Now I think I'm going to."
        ],
        [
            "For the next section, I think I'm going to because I'm running out of time here and I want to have time for questions.",
            "With all due respect to Syria, I'm going to skip the stuff on Syria's spike prop, 'cause I think he said he was going to talk a little bit about it.",
            "So what?"
        ],
        [
            "I'll just say is issue 3 that I was going to talk about is how do you deal with the fact that we have these all or none action potentials and we want to take the derivative of the activation function with these.",
            "Discrete events which seems problematic.",
            "And I'll just note that."
        ],
        [
            "So.",
            "Surya Ganguly's lab, particularly with Frederick Zenke.",
            "They've designed the system, which you can read about here, that does affectively backpropagation on very precise spike trains by just defining a different loss function.",
            "That is the difference between the spike trains convolved with this temporal convolution kernel, and then replacing this nasty term with.",
            "A."
        ],
        [
            "Nice auxiliary function that they can take the derivative of.",
            "And also I'm not going to."
        ],
        [
            "So the math 'cause I want to move on to the next topic.",
            "But here you can see that what they can do with that system is they can actually say to the neurons.",
            "OK, we want you to Spike at this moment this moment this moment, this moment.",
            "So here you're looking at the spikes in the input layer to the neural network.",
            "So actually here."
        ],
        [
            "Move to this one here we've got hidden units, so here's the spikes in the input layer.",
            "Here are the hidden unit voltages, and here is the output.",
            "An initially.",
            "We tell the network you should spike here, here, here, here.",
            "It doesn't do it, but over the course of training you can get it to give you exactly this pattern of spikes.",
            "So it is in fact possible to do training with a hidden layer with spikes, but I'll let Syria tell you a little bit more about that.",
            "So what I'd like."
        ],
        [
            "To move to, so I'll just say item three.",
            "Yes, we can do back prop with precise spike trains.",
            "And it's it's actually quite an elegant solution, I think."
        ],
        [
            "So I want to get to the 4th issue which is so near and dear to my heart and will maybe be more novel for for some of you.",
            "So as I mentioned, the 4th issue is this issue of doing forwards and backwards passes to do back prop in a neural network.",
            "The idea is that you need to do an initial forward pass through the network Calculator error back, propagate that error and that forward pass needs to be kind of clean as it were, it shouldn't be incorporating feedback at the moment of the forward pass, it should be just communicating whatever the feedforward weights are calculating on the input.",
            "But our own brains don't seem to exhibit this sort of forward pass backward pass nonsense.",
            "They're just kind of chattering away.",
            "And there's all these feedback connections, so presumably for your neurons in, say, primary visual cortex, they will always be receiving feedback from higher order regions anyway.",
            "And then you left with the question, if well, how can you actually do some of these calculations, given that they all assume that you had a forward pass initially to figure out how the networks transforming your input."
        ],
        [
            "Well, what's interesting is that in the neocortex, and this comes back to your question about, you know it can't know what's a feedback synapse and what's not.",
            "What's interesting is that the brain actually does treat feedback synapses differently from bottom up synapses.",
            "So in your neocortex, which again is the region of the brain that we're interested in here.",
            "The majority of the cells are a particular type of cell known as a pyramidal neuron, which is illustrated on the left here.",
            "They're called pyramidal neurons because the cell body, which is here is shaped a bit like a pyramid, but really the entire thing resembles big tree more accurately.",
            "So what's interesting about this structure is basically so these pyramidal neurons will have their cell body deeper in your neocortex, and they have a whole host of dendritic branches that come out around the cell body that are known as the basal dendrites, and they're kind of like the roots.",
            "Of a tree.",
            "And then they send up one unique dendrite called the apical shaft.",
            "Which goes up up up, whoops, sorry.",
            "This is the frustrating thing about not using a pointer is on here.",
            "I don't laptop.",
            "You can move your slides.",
            "It goes up up, up towards the surface of the brain and then so that's kind of like the trunk of your tree.",
            "And then as it approaches the surface of the brain, it branches again, just like the branches of a big tree and those those upper branches are known as the apical dendrites.",
            "Now, the reason I'm telling you about this structure is what's interesting is that anatomical work has shown that, generally speaking, you know nothing is a hard and fast rule in biology, but generally speaking."
        ],
        [
            "The apical dendrites are receiving top down feedback from higher order regions of the brain, whereas the basal dendrites are receiving bottom up.",
            "Sensory information coming in from your eyes, your skin, your nose, etc.",
            "So the neurons in the neocortex actually spatially segregate.",
            "The bottom up and the top down connections to the neurons.",
            "And.",
            "This segregation of the inputs is.",
            "Particularly weird when you first look at it because of how far the apical dendrites are from the cell body.",
            "So like when I first saw this structure, I just kind of 'cause I had originally been trained in AI, and then I went into neuroscience.",
            "And when I first saw this structure, I just kind of registered in my brain as well.",
            "That's weird, but it got we."
        ],
        [
            "Later, when I learned about the work of Matthew Larcom.",
            "So Matthew Larcom did throughout the late 2000s these heroic experiments where he would record from different parts of the apical dendrites in these pyramidal neurons.",
            "So this is an illustration of some of the experiments that he ran.",
            "He's got a electrode that he's recording the voltage in the dendrite from at this point in the apical dendrite, just at the start of the apical shaft.",
            "And then he's got another electrode illustrated in red here, up at one of the higher branches in these apical dendrites.",
            "And then he puffs sucrose onto this upper branch, which causes electrical activity in the branch.",
            "Now what you're looking at here, these are the traces of the membrane potential of the voltage that was recorded by those two different electrodes during this experiment.",
            "So we can see the response to the sucrose on the red trace.",
            "All these little like bumps up this is it zoomed in.",
            "All these little bumps up.",
            "Excuse me are excitatory postsynaptic potentials they are the dendrite responding to that sucrose.",
            "But notice that on the blue electrode, not a lot's happening.",
            "That is because the distance along that cable.",
            "So you can think of these dendrites as being like electrical cables.",
            "They have actually a fairly high resistance along them and it is not trivial for current to travel down those cables, and in fact what Matthews result shows is that by the time the current gets down to that apical trunk.",
            "It's basically gone, or at least it's severely attenuated.",
            "So this is actually a plot of four different distances along the dendrite.",
            "How much was the initial input to the dendrite attenuated?",
            "And what you can see is that by the time you get like a 400 micro meter distance, which if you look at, here's the scale bar so you can see this entire thing is like a millimetre long out of 400 micro meter distance you basically out of 40.",
            "40% to 1040 times attenuation of your EPS P. Now that's really weird, because like I said, the top down signals are coming into these apical dendrites, so the neuron, so one of the other things for those of you who aren't by all, don't have a biology background that I should mention is the activity of the neuron.",
            "The spikes are ultimately driven by the Axon hillock, which is just off the cell body here.",
            "So that means that the site on the neuron where the activity is being generated, the activity that's going to be transmitted to the rest of the network.",
            "Is so far from the dendrites, where the top down feedback arrives that the top down feedback would in fact not be altering the activity of the neuron in most circumstances.",
            "Which is very seems a very strange thing to do.",
            "WHI would you have top down feedback that's not driving the cell?",
            "Well, Interestingly, what Matthew then showed in and."
        ],
        [
            "Other set of experiments is that the top down feedback can drive the cell, but only in these discrete moments driven by nonlinear events called plateau potentials.",
            "So this is a similar experimental setup.",
            "He's got a red electrode in the higher apical dendrites here.",
            "A blue electrode on the shaft and then he's got a third electrode on the cell body and we've got four different recordings showing the voltage recorded on those different electrodes.",
            "Where it's color coded for the specific electrodes.",
            "Now so.",
            "What you can see here in B is that when he provides a stimulation to the red electrode, you get a response on the red electrode.",
            "And almost nothing on the blue electrode an nothing at all on the black electrode because it's not propagating.",
            "You can ignore C for a second.",
            "That's there for the neuroscience audience for a specific reason.",
            "But what's interesting is D&E here.",
            "So what he showed is that if you get sufficient activation of the apical trunk here.",
            "Either because you're injecting current at the cell body at the same time, or you just inject enough current into the red guy, you get this huge nonlinear event in the apical dendrites.",
            "It's kind of like a spike in fact, except it last longer, and for those of you who care about this kind of stuff, it's actually driven by voltage gated calcium channels rather than sodium channels.",
            "But here, on the red and blue traces we see this big nonlinear event, and these are called plateau potentials because they last for this long period of time.",
            "And what's interesting is these plateau potentials can then drive bursts of spikes at the cell body.",
            "At the Axon hillock.",
            "And that means that it is possible for the top down feedback to drive activity here, but only when there is sufficient topdown activity to activate this nonlinear function.",
            "And what that means effectively is that most of the time the cell is going to be in feedforward mode.",
            "It will be receiving inputs to its basal dendrites.",
            "Which it can then oops excuse me which it can then communicate to other neurons.",
            "But occasionally it will respond to feedback when the feedback successfully triggers one of these nonlinear actions, yeah.",
            "This attenuation thing happening also fairly outgoing.",
            "No, so axons do not suffer from this attenuation issue because they are in fact designed by evolution, not too so they are rich with nonlinear voltage gated channels that help to regenerate the currents as they travel through the Axon.",
            "That's right, and that's what that's what happens with these nonlinear events here as well.",
            "Now so."
        ],
        [
            "My lab got interested in this because we said, well if that's the case, if you've got this situation where most of the time the neurons are effectively in a feedforward mode, and then sometimes they receive this nonlinear signal from the top down system, maybe you could basically do back prop without having explicit forward passes and backwards passes, just instead by incorporating this segregation that exists in the actual dendrites.",
            "So we built this kind of simplified model of pyramidal neurons.",
            "My student Jordan who's here an together with Tim Lillicrap.",
            "Where we had neurons that are now no longer the point neurons that we use usually in artificial neural networks, but instead are neurons with three compartments.",
            "A basal dendrite compartment that's receiving feedforward inputs and apical dendrite compartment that's receiving feedback inputs Anecelle body that's responsible for generating spikes.",
            "And what we did is based on Matthew Larcom's data.",
            "We had it that the cell body is largely responding to the inputs to the basal dendrites.",
            "Most of the time.",
            "Which you can see here.",
            "So this is the voltage in the cell body.",
            "Is the voltage in the basal dendrites, and here's the voltage in the apical dendrite and most of the time, the cell body is ignoring what's happening in the apical dendrite.",
            "But occasionally the apical dendrite can trigger nonlinear plateau potential, which we then just take as the average of the voltage over the past 30 seconds.",
            "30 sorry, 30 milliseconds for the apical dendrite and that can then get communicated to the rest of the cell.",
            "And so."
        ],
        [
            "So what we do is.",
            "Kind of similar to equilibrium propagation, but nowhere as elegant.",
            "We have a forward phase where there is no feedback from the environment and the network just runs.",
            "We presented with an image.",
            "An activity propagates through the network.",
            "And then a plateau potential occurs.",
            "One of these nonlinear events where the feedback is actually transmitted to the rest of the neurons.",
            "Then we engage in a phase where we have some external pressure that's nudging the system towards the correct answer.",
            "And excuse me.",
            "An we allow activity to propagate through the network both upwards and backwards, except of course again the backwards flow is effectively cut off because of the segregation of the apical dendrite.",
            "And then we generated another plateau potential.",
            "And what we do is we update our weights using the difference between these two plateau potentials, which is affectively a way of doing feedback alignment.",
            "In fact, because we use random weights for our backwards weights here.",
            "And by taking the difference between these two plateau potentials, then we are we have a system which is going to learn to do backpropagation in fact."
        ],
        [
            "So you can see that here.",
            "So we just tested the basic result first.",
            "That kind of like with feedback alignment.",
            "We wanted to see that if we added hidden layers to this network, we got improved performance.",
            "So this is classification on amnist.",
            "Obviously these actual numbers suck, so I call it deep learning light.",
            "But 'cause we're running biophysical simulation with voltages and stuff and getting those numbers doing the parameter search to get those numbers down as.",
            "Tricky, we've got some initial some more data showing that those can get better, but the important point is that as we add hidden layers to the network, it does seem to get better.",
            "Though as Joshua mentioned, for as with feedback alignment, we find that there are diminishing returns.",
            "You can't just create ever deeper networks.",
            "But the more important principle here is that we're doing this without explicit forward and backwards passes.",
            "The entire system is just allowed to kind of chatter at itself in whatever direction, and the way that we're implementing an effective forward pass is by using that segregation of the apical dendrite, which is something that we actually see in the real neocortex."
        ],
        [
            "So this is just a demonstration that we're getting that same basic feedback alignment effect.",
            "So this is the angle between what our algorithm asks for and what backpropagation asks for overtraining epox.",
            "If we send back the actual voltages through the backward connections, we get really good agreement between them.",
            "If we use the spikes, we get better than orthogonal, but not perfect, but nonetheless in a very high dimensional space, that's still roughly the same direction.",
            "And so if you look at the receptive fields that are generated by our learning rule, that's just using these plateau potentials to learn an what backpropagation learns.",
            "So these are receptive fields in the hidden layer of the network.",
            "You see very similar features pop out, so it seems to be learning something very similar, but again done without an explicit forward and backwards pass."
        ],
        [
            "Now.",
            "One of the issues with our model though is that we are using these rather artificial plateau potentials, and it's not clear that.",
            "That's actually something that would be used by the neurons.",
            "What we should really be incorporating?"
        ],
        [
            "Is.",
            "These bursts of action potentials that Matthew Larcom recorded because that's what's going to ultimately drive activity throughout all the dendrites in the cell and what's really going to be the key to communicating it to other neurons in the system as well for doing properly deep learning.",
            "So what I wanted to show you in the very."
        ],
        [
            "Hospet before I just take some questions is.",
            "There are some exciting results out from Richard Nodes Lab at the University of Ottawa.",
            "Unfortunately, this is unpublished.",
            "It'll be up on archive at some point soon, so I just recommend looking up now and specular if you're interested in this in a month or so.",
            "So what they did is they ran some biophysical simulations of pyramidal neurons.",
            "So these are these are simulations of pyramidal neurons with asamaan that long apical dendrite.",
            "I was telling you about.",
            "And they fit their biophysical simulations to actual experimental data.",
            "And then they looked at what the?",
            "Cells activity is communicating whether it's communicating top down signals to the apical dendrite or whether it's commuting bottom up signals to the dendrites around the soma.",
            "What they do in particular though, which is very interesting, is they.",
            "Basically just look at the number of events, so here you can see a spike and here you can see a burst and they treat both bursts and spikes as just an event.",
            "And then they look at both the rate of events and the probability that a Bearss.",
            "Sorry that an event is a burst.",
            "And what's interesting is that if you look at so here they are providing a decreasing current to the dendrite to the apical dendrite and an increasing current to the soma.",
            "And what you see is that the event rate is a function, so that is the rate at which both burst send spikes occur is a function of the input.",
            "The bottom up input to the soma.",
            "Whereas the probability that an event is a burst is a function of the topdown input to the dendrites.",
            "And if you do this same thing, so you provide two different currents overtime.",
            "We see this same result Pop out here.",
            "So if you just count the rate of spiking in these neurons, you don't see much of anything.",
            "But if you look at the event rate, you see the bottom up input to the soma, and if you look at the burst probability you see the top down input to the dendritic inputs.",
            "Sorry to the apical dendrites.",
            "And that's very exciting, because what that means is that pyramidal neurons.",
            "Are effectively multiplexing their top down and bottom up signals constantly, so the neurons in your brain have two different signals, one that communicates the bottom up information that's coming from your sensory systems, and another signal that communicates the top down information that's coming from the higher order regions of the neocortex.",
            "And theoretically these two different signals could then be used to do something like backpropagation without having to have separate forward and backwards passes.",
            "Because the entire system is actually keeping those two streams of information separately as it travels through the network.",
            "So what's also interesting."
        ],
        [
            "But this is we see that there are subtypes of neurons in the neocortex.",
            "That have synapses that respond to bursts quite differently.",
            "So some neurons have what are called short term depressing synapses, which means that they don't actually respond to burst differently than spikes, because when the first action potential occurs, the synapses depress rapidly, and so they don't respond to the subsequent spikes.",
            "And there are other synapses called short term facilitating synapses which don't really respond much to the first spike, but respond very well if you get multiple spikes in a row via burst.",
            "And so what's interesting about that is we see that there are different types of neurons in the neocortex, and I don't have time to go through the different types.",
            "I'll just tell you that there are two different types of neurons in neocortex.",
            "That have short term depressing synapses and short term facilitating synopses.",
            "And that means that theoretically, we've got two different pools of neurons, one that is explicitly listening to the bottom up signals and one that is explicitly listening to the top down signals.",
            "And again, that would allow the system to engage in a backpropagation like calculation without separate forward and backwards passes, which I think is a very exciting result and potentially the key to understanding how some of this unfolds."
        ],
        [
            "So to summarize.",
            "Item number 4 doesn't seem to be an issue either, because your brain actually seems to be designed specifically to do simultaneous forward and backwards passes and to carry that information with different signals.",
            "So it's in fact very plausable that you could do learning without these separate passes."
        ],
        [
            "So to end off here, I began this talk by identifying the kind of issues with this equation and the things that made neuro scientists very sceptical for a long time that we could do deep learning in the brain.",
            "But over the last two years, we've kind of seen how you can systematically just pull apart each one of these, and it turns out that they're not.",
            "None of them are a big issue now.",
            "There are other issues that are going to rise, whether it be the delay time constants or questions of how you do recurrence.",
            "And I'll get to that in one second, but at the end of the day, I think they're all going to be surmountable."
        ],
        [
            "Of course, the final remaining one, which I just mentioned, the elephant in the room for us, is back prop through time by Prop.",
            "Through time is really, really critical for training recurrent neural networks, but doing backdrop through time in a biologically realistic way is pretty difficult."
        ],
        [
            "So of course, the way back property time works right is if we have are currently connected set of neurons, we unroll the neurons through time such that we treat early time points as being like the initial layers of a neural network and later time points as being the higher layers.",
            "And then you just run back, prop through it as if you had a standard stock neural network.",
            "That's great for training and neural network, but if you're going to try to do this in a biologically realistic fashion, you have to somehow have a record across time of the activity patterns in the inputs at each time point, and you have to have those all time stamped and matched up with each other.",
            "And we just have no way of seeing how the brain can do that.",
            "Right now I have some ideas about how this might work, but I'll leave that for another time and maybe for you guys to resolve in your work.",
            "If you work in this area.",
            "So."
        ],
        [
            "What I will say is this though.",
            "To finish off, there's a very good reason that deep learning is taken over AI, and that is that it works.",
            "And the reasons that it works apply equally.",
            "To our own brains, that is to say that if you're going to try to optimize a huge number of parameters so you're working in a very high dimensional space and you're trying to optimize some cost function, doing gradient descent or stochastic gradient descent is a really good way of solving that problem, and it seems very likely.",
            "I would argue because we don't really know of another good way to do that, right like to my knowledge, no one's ever demonstrated an equally powerful mechanism.",
            "For learning in these high dimensional spaces, it seems entirely likely that our brains.",
            "Did through the course of you know evolution, settle appana similar solution?",
            "Something like stochastic gradient descent?",
            "And I think that until neuro scientists are able to articulate an alternative way of learning these high dimensional spaces, we have to take very seriously the idea that our brains are doing something like backdrop.",
            "And that's particularly true because as we saw the old objections don't hold water anymore, and I suspect that the additional objections that are going to be raised will not hold water for very long either.",
            "I."
        ],
        [
            "And so the last, very last thing I'll leave you with is the following kind of wacky thought, and this is an absurd bit of bullshit on my part, but.",
            "Whatever, it's fun.",
            "Let's say for a second that our brains are doing gradient descent, and let's say that we were able as neuro scientists to identify where those signals are.",
            "If they are the top down signals into the apical dendrite that are guiding the like telling the neurons about the gradient or something like that.",
            "Theoretically, if we could get a sufficiently good neural prosthesis such that we could actually tap into these signals that are communicating the gradient to the neurons.",
            "You could have a system where you have an external cost function in some neural network and you back prop through that system and into the brain.",
            "OK, that's very scary, yes.",
            "And so then you could have a truly seamless AI brain interface where you actually update your brain in order to maximize the cost functions of your external prostheses.",
            "Which.",
            "Updates.",
            "That's what I'm saying.",
            "I think it should.",
            "Yes exactly, you want to be able to send back the signals to the neurons that tell them what the gradient is of that external cost function.",
            "And that will guide them in their synaptic weight updates.",
            "Yes, just doing it.",
            "That's right, we're doing it through very slow channel.",
            "That's right.",
            "So the other thing is though, you're sort of doing it insofar as there, you still have to construct the cost function internally for yourself, right?",
            "Like you have that cost function by virtue of your internal goals with your phone.",
            "But if you had a system where you could literally take any cost function and propagate that back through the brain.",
            "It wouldn't have to be the things that you're explicitly interested in.",
            "Yes.",
            "Yeah, I was working at DARPA.",
            "Not, not really, don't."
        ],
        [
            "Anyway, that's that I'm sorry we only have a couple of minutes for questions, but thank you very much."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So yes, as Joshua said, we're going to have a bit of a change of pace here this morning, because we're going to start.",
                    "label": 0
                },
                {
                    "sent": "I know we've done a little bit of it.",
                    "label": 0
                },
                {
                    "sent": "I saw riches talk, but we're going to start to focus a little bit more this morning on the actual brain as opposed to just artificial brains.",
                    "label": 0
                },
                {
                    "sent": "Though of course the focus will be on trying to understand what unites both the artificial intelligence that we are all interested in here and the natural intelligence that sits in our skulls.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I obviously the recent success of deep learning and artificial intelligence means that for most people, if you mention deep learning, they're going to think about AI.",
                    "label": 1
                },
                {
                    "sent": "It's natural when you read news article after news article about how it's changing the world of artificial intelligence.",
                    "label": 1
                },
                {
                    "sent": "But one of the things that I think many people often.",
                    "label": 0
                },
                {
                    "sent": "Don't really know people who aren't involved in the area is that one of the goals of some components of deep learning.",
                    "label": 0
                },
                {
                    "sent": "Research was always to understand how our own brains work.",
                    "label": 1
                },
                {
                    "sent": "The researchers who really helped to resuscitate neural networks research in the 1980s, the parallel distributed processing Group wanted to understand human intelligence and wanted to understand how the brain works.",
                    "label": 0
                },
                {
                    "sent": "So in this session.",
                    "label": 0
                },
                {
                    "sent": "And sort of the ones in the early 2000s.",
                    "label": 0
                },
                {
                    "sent": "That's right.",
                    "label": 0
                },
                {
                    "sent": "So it wasn't just that if you look at, in fact, let's, let's be clear here.",
                    "label": 0
                },
                {
                    "sent": "If you look at the people who really pushed deep learning forward in the 2000s, like Yoshua and Jeff and Jan and stuff they are interested in how the brain works so deep learning is not just about.",
                    "label": 0
                },
                {
                    "sent": "AI it's also about your brain.",
                    "label": 0
                },
                {
                    "sent": "I'm going to talk to you today a little bit about how current research is looking into how deep learning could be implemented in the real brain.",
                    "label": 1
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now let me just motivate this a little bit more.",
                    "label": 0
                },
                {
                    "sent": "One of the other interesting things that's come out in neuroscience over the last couple of years is that deep learning models actually are a better fit to neocortical representations that we record, either in a functional magnetic resonance imaging system, or using tetrodes and monkeys.",
                    "label": 1
                },
                {
                    "sent": "Then any of the existing models developed by neuro scientists to explain the brain, and that's, I think, a very interesting fact.",
                    "label": 0
                },
                {
                    "sent": "So what you're looking at here is on this plot the.",
                    "label": 0
                },
                {
                    "sent": "X axis is the categorization accuracy of different visual processing models on.",
                    "label": 0
                },
                {
                    "sent": "I forget which data set it might have been cifar 10 or something like that.",
                    "label": 0
                },
                {
                    "sent": "And on the Y axis you have a measurement of the resemblance.",
                    "label": 0
                },
                {
                    "sent": "Between the representations in that computational model in that neural network and the representations that were actually recorded either in human inferotemporal cortex on the top or in monkey inferotemporal cortex on the bottom.",
                    "label": 0
                },
                {
                    "sent": "And one of the first things that of course should jump out at you is that there is a correlation between how well the models do on categorizing different images and how similar their representations are to what we actually measure in the brain of primates.",
                    "label": 0
                },
                {
                    "sent": "But the second thing I'll point out is that so each dot here represents a different model, A different computational model, be it a neural network or some other model, and the colored dots represent different layers of a deep convolutional neural network.",
                    "label": 0
                },
                {
                    "sent": "So here at the top you see Layer 7 of a deep convolutional neural network.",
                    "label": 0
                },
                {
                    "sent": "It's of course doing better at categorization of the images than any of the other models that we all know.",
                    "label": 0
                },
                {
                    "sent": "That's why you're all here.",
                    "label": 0
                },
                {
                    "sent": "But also, Interestingly, it is more similar to the representations observed in inferior temporal cortex of humans brains.",
                    "label": 0
                },
                {
                    "sent": "And that's pretty remarkable, so the little numbers are.",
                    "label": 0
                },
                {
                    "sent": "The little numbers are each a different model that a neuro scientist has proposed to explain how visual processing works in the brain and that is their results on categorizing cifar 10 and their similarity to human cortex.",
                    "label": 0
                },
                {
                    "sent": "What is that paper?",
                    "label": 0
                },
                {
                    "sent": "Oh, I'm sorry, I didn't cite that paper.",
                    "label": 0
                },
                {
                    "sent": "My apologies, I will send Gram updated slides with that citation.",
                    "label": 0
                },
                {
                    "sent": "All the other citations are in the talk.",
                    "label": 0
                },
                {
                    "sent": "Excuse me, I was working on a DARPA grant this week.",
                    "label": 0
                },
                {
                    "sent": "The this was by Nicholas Cortez Lab at Cambridge, but I will I will be sure to update the slides so you can look this paper up as well.",
                    "label": 0
                },
                {
                    "sent": "My apologies so anyway.",
                    "label": 0
                },
                {
                    "sent": "The underlying message is that it looks like we have more questions, yeah?",
                    "label": 0
                },
                {
                    "sent": "I'm here now.",
                    "label": 0
                },
                {
                    "sent": "That's correct.",
                    "label": 0
                },
                {
                    "sent": "Category yes.",
                    "label": 0
                },
                {
                    "sent": "Anymore.",
                    "label": 0
                },
                {
                    "sent": "That categorisation will.",
                    "label": 0
                },
                {
                    "sent": "A.",
                    "label": 0
                },
                {
                    "sent": "The dish.",
                    "label": 0
                },
                {
                    "sent": "That no, that's not actually trivially the case.",
                    "label": 0
                },
                {
                    "sent": "So for example, one of the interesting things that came out of this paper.",
                    "label": 0
                },
                {
                    "sent": "It's a good point though.",
                    "label": 0
                },
                {
                    "sent": "Sorry yes.",
                    "label": 0
                },
                {
                    "sent": "So let me try to paraphrase what you said.",
                    "label": 0
                },
                {
                    "sent": "Given that we're looking so so you know inferior temporal cortex is a region of the brain that's particularly concerned with the categories of different objects that you're looking at, and So what was pointed out is that if you have a model that is principally concerned with categorization, and you look at the upper layers where all the categorization is going on, inevitably it's going to be a better match to region of the brain that is doing categorization.",
                    "label": 0
                },
                {
                    "sent": "Is that roughly correct?",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Right?",
                    "label": 0
                },
                {
                    "sent": "Sure, yes.",
                    "label": 0
                },
                {
                    "sent": "However, here's what's interesting.",
                    "label": 0
                },
                {
                    "sent": "So one of the things that this paper showed was alright.",
                    "label": 0
                },
                {
                    "sent": "So one of the differences between one between what human brains seem to be doing and what a lot of the other models seem to be doing is that there are, Interestingly enough, very large distances between the representations for animate and inanimate objects.",
                    "label": 1
                },
                {
                    "sent": "In the human brain, and that doesn't pop out of the existing neuroscience models.",
                    "label": 0
                },
                {
                    "sent": "It only comes out of these deep learning models.",
                    "label": 0
                },
                {
                    "sent": "Once they've been trained to categorize that, but that's not necessarily always going to be the case per say, like you could imagine a system which is perfectly good at doing categorization but doesn't have larger distances between inanimate, inanimate objects, then it does different categories of animate objects, for example.",
                    "label": 0
                },
                {
                    "sent": "Now what I will say though, where I think you're very right is look the reason that these deep neural networks are ultimately coming to resemble this part of the brain is in part because we're training them on a categorization task.",
                    "label": 0
                },
                {
                    "sent": "But what's interesting is if you train deep neural networks on other things as well or even on categorization tasks, there's even still better matches in lower parts of the visual hierarchy that are principally responding to category.",
                    "label": 0
                },
                {
                    "sent": "What I the other thing I'll add to this though, is I think that the reason it comes out is simply because the correct answer to doing these categorization tasks.",
                    "label": 0
                },
                {
                    "sent": "Is in fact to have the distances between the different categories that the human brain does, because that is the result of cost function optimization will come back to that though.",
                    "label": 0
                },
                {
                    "sent": "But anyway, yes, thank you.",
                    "label": 0
                },
                {
                    "sent": "That's a very good point.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Anyway, what I was trying to do there ultimately is just motivate the idea that our brains are doing something like deep learning.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "Let's just be clear on what we actually mean by that.",
                    "label": 0
                },
                {
                    "sent": "So of course the key to deep learning.",
                    "label": 1
                },
                {
                    "sent": "Is the ability to improve learning by adding hitting layers if you if you look at ultimately what distinguishes the modern approaches in neural networks to other approaches and machine and machine learning or machine vision, etc.",
                    "label": 1
                },
                {
                    "sent": "It is the addition of all these layers to the model.",
                    "label": 1
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "If you're going to use a model that has many hidden layers to it.",
                    "label": 0
                },
                {
                    "sent": "The issue that you're going to be presented with.",
                    "label": 0
                },
                {
                    "sent": "Is what's known as the credit assignment problem.",
                    "label": 0
                },
                {
                    "sent": "So the credit assignment problem is is this, which you're probably familiar with.",
                    "label": 0
                },
                {
                    "sent": "If I'm a neuron in a hidden layer.",
                    "label": 0
                },
                {
                    "sent": "And I need to update my weights in order to optimize on some cost function.",
                    "label": 0
                },
                {
                    "sent": "I need to know how much credit and or blame I should get for the current results that the network is getting on the cost function for the current behavior of the network.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "We need some way of assigning to each neuron in each synapse in the hidden layer its contribution to the output of the network.",
                    "label": 1
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now, the obvious way to do this, of course, is backpropagation.",
                    "label": 1
                },
                {
                    "sent": "So backpropagation has been invented multiple times by different groups, and the reason is that it is kind of like if you're addressing this question of how am I going to do credit assignment in the hidden layers.",
                    "label": 0
                },
                {
                    "sent": "It's it's kind of a nice, clear, obvious way of doing it, so of course you all know, but we're just going to review here very quickly that the principle behind backpropagation.",
                    "label": 0
                },
                {
                    "sent": "Is that we're taking the partial derivative of our cost function with respect to the synaptic weights in the hidden layers?",
                    "label": 1
                },
                {
                    "sent": "So if we have a neural network here with input X hidden layer activities H, output Y target T. We can define the error as being the difference between the output of the network and the target.",
                    "label": 0
                },
                {
                    "sent": "Our loss function is then just the squared error, and if we take the partial derivative of this loss function with respect to the weights and the hidden layers, we get this expression.",
                    "label": 0
                },
                {
                    "sent": "Just using the chain rule.",
                    "label": 0
                },
                {
                    "sent": "So this equation then for a one layer hidden 1 hidden layer neural network and I'm going to stick to this just for say covies.",
                    "label": 0
                },
                {
                    "sent": "In this talk, but it everything I say should ultimately apply to more layers.",
                    "label": 0
                },
                {
                    "sent": "If you, if you have this equation, this is your weight update for the synapses in the hidden layer.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now let's unpick this a bit.",
                    "label": 0
                },
                {
                    "sent": "So here's the equation we need to do.",
                    "label": 0
                },
                {
                    "sent": "We need all this information to update our synapses in the hidden layer of the neural network, and so let's just start to pick it apart.",
                    "label": 0
                },
                {
                    "sent": "Let's look at what the brain would actually have to calculate in order to do back propagation, right?",
                    "label": 0
                },
                {
                    "sent": "Like if we're saying the brains doing something like deep learning and most of our deep learning systems use backpropagation, does our brain do something like backpropagation and so?",
                    "label": 0
                },
                {
                    "sent": "Let's see what the brain would have to calculate to do that.",
                    "label": 0
                },
                {
                    "sent": "Well, of course the first thing is you need the error term, so you need the difference between the output generated by a forward pass through the network and some target that has been assigned to the network.",
                    "label": 0
                },
                {
                    "sent": "You're going to multiply that by the transpose of the downstream weights, so you've got a set of synaptic weights from the hidden layer to the output layer, and that's got to be there in your equation multiplied by your error term.",
                    "label": 0
                },
                {
                    "sent": "Additionally, you need the derivative of the hidden unit activation function.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "Ultimately, all of this, both the error and the derivative of that hidden unit activity, depends on you having an initial forward pass through the network, and then theoretically a backward pass where you're calculating this.",
                    "label": 0
                },
                {
                    "sent": "So we've got these four elements that we need for this equation to work.",
                    "label": 0
                },
                {
                    "sent": "You also need, of course, the input, but we're assuming that that's trivially available to the brain.",
                    "label": 0
                },
                {
                    "sent": "So we need these four things we need.",
                    "label": 0
                },
                {
                    "sent": "Our error term.",
                    "label": 0
                },
                {
                    "sent": "We need the transpose of the downstream weights.",
                    "label": 1
                },
                {
                    "sent": "We need the derivative of the activation function and we need separate forward and backward passes.",
                    "label": 1
                },
                {
                    "sent": "Alright, well The thing is that all of these are problematic for the brain.",
                    "label": 0
                },
                {
                    "sent": "And it is, in fact, why neuroscientists, for many years, largely dismissed the idea that the brain does anything like backdrop.",
                    "label": 0
                },
                {
                    "sent": "Because if you're an intelligent biologist and you understand what these terms are, and you understand how you could calculate them, you take a strong look at it.",
                    "label": 0
                },
                {
                    "sent": "You're like, well, this is just bonkers.",
                    "label": 0
                },
                {
                    "sent": "The brain can't do this.",
                    "label": 0
                },
                {
                    "sent": "So let's run through each one.",
                    "label": 0
                },
                {
                    "sent": "So at least in the neocortex, so the brain can calculate error terms.",
                    "label": 0
                },
                {
                    "sent": "That's not actually the biggest unit of itself, but the specific error term, the difference between a forward pass.",
                    "label": 0
                },
                {
                    "sent": "And some target that you've received.",
                    "label": 0
                },
                {
                    "sent": "There's no evidence for anything like that in the neocortex.",
                    "label": 0
                },
                {
                    "sent": "And of course, the neocortex is the region of the brain that we're interested in here.",
                    "label": 0
                },
                {
                    "sent": "Sorry, I didn't say that earlier.",
                    "label": 0
                },
                {
                    "sent": "We're interested in it, not only because it has good matches to deep learning models, as I showed you with the previous result, but also because.",
                    "label": 0
                },
                {
                    "sent": "To the best of what neuroscientists concede, the neocortex is the closest thing to a kind of general purpose learning machine, akin to the artificial neural networks we learned we use in AI.",
                    "label": 0
                },
                {
                    "sent": "Now some other parts of the brain can definitely learn, but they are often crafted towards more specific purposes.",
                    "label": 0
                },
                {
                    "sent": "Your neocortex is really this incredible, just general purpose, homogeneous learning machine.",
                    "label": 1
                },
                {
                    "sent": "So there's no clear implementation of those kind of error terms in the neocortex, and that's problematic.",
                    "label": 0
                },
                {
                    "sent": "The second one, an one that's been arguably more traditionally like a total nonstarter for many neuroscientists, is this issue of the transpose of the downstream weights.",
                    "label": 0
                },
                {
                    "sent": "If you are a neuron early in visual processing stream, so let's say you have a neuron in your primary visual cortex.",
                    "label": 0
                },
                {
                    "sent": "The idea that it would know the synaptic connections all throughout the rest of your visual processing stream is just crazy.",
                    "label": 0
                },
                {
                    "sent": "We know of no physiological mechanism by which that could be the case now.",
                    "label": 0
                },
                {
                    "sent": "Alternatively, you could have a situation where you've got feedback weights that are perfectly symmetric, and we'll talk about that in a moment, but that in and of itself is also problematic, so experiments show if you take any two neurons and you look at whether they are connected to each other there is.",
                    "label": 0
                },
                {
                    "sent": "Not only no guarantee that the synaptic weights between them will be similar, there's no guarantee that they will both be connected reciprocally to each other.",
                    "label": 0
                },
                {
                    "sent": "So it's a totally non trivial matter to have backwards projections that are symmetric with your forward projections.",
                    "label": 0
                },
                {
                    "sent": "And this was something that Francis Crick pointed out in an article back in the 1980s when people first got excited about back propagation in kind of cognitive science.",
                    "label": 0
                },
                {
                    "sent": "An ever since that point, most neuroscientists have dismissed the idea of anything like this occurring in the brain.",
                    "label": 0
                },
                {
                    "sent": "Now.",
                    "label": 0
                },
                {
                    "sent": "The other thing you need is the derivative of the activation function so.",
                    "label": 0
                },
                {
                    "sent": "That's fine when you've got a sigmoid activation function applied to a linear term.",
                    "label": 0
                },
                {
                    "sent": "But in real neurons, this is actually difficult, so real neurons don't actually communicate analog signals to each other.",
                    "label": 0
                },
                {
                    "sent": "They communicate with something known as spikes, which we'll talk about a little bit more in a couple of slides, and spikes are all or none events.",
                    "label": 0
                },
                {
                    "sent": "They can be thought of as effectively yes or no.",
                    "label": 0
                },
                {
                    "sent": "And the problem is that when you've got an all or none event, it's not clear how you take the derivative of that.",
                    "label": 0
                },
                {
                    "sent": "So that's another problem.",
                    "label": 0
                },
                {
                    "sent": "For this I would just say that yeah there are.",
                    "label": 0
                },
                {
                    "sent": "There's there are groups that have shown that you can train spiking known networks.",
                    "label": 0
                },
                {
                    "sent": "Oh yeah, we're going to cover one of those papers.",
                    "label": 0
                },
                {
                    "sent": "Yeah, it's not actually a problem.",
                    "label": 0
                },
                {
                    "sent": "I'm going through the logic of why neuroscientists haven't bought back prop in the brain.",
                    "label": 0
                },
                {
                    "sent": "In fact, the rest of this talk is going to be me knocking down each of these points.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "The other issue is that there's no evidence for separate forward and backwards passes, right?",
                    "label": 0
                },
                {
                    "sent": "Like when we look at the activity in your brain, it's not the case that like light hits your retina and then there's a sweep of electrical activity forward through your visual processing stream and then after that a sweep backwards of electrical activity from.",
                    "label": 0
                },
                {
                    "sent": "I don't know, your prefrontal cortex or something like that.",
                    "label": 0
                },
                {
                    "sent": "Your entire brain is always active.",
                    "label": 0
                },
                {
                    "sent": "It's always chattering amongst itself and.",
                    "label": 0
                },
                {
                    "sent": "The idea of separate forwards and backwards passes at face value seems problematic.",
                    "label": 0
                },
                {
                    "sent": "OK, but as I was saying over the last couple of years, we've seen a lot of progress in addressing all four of these issues, and I'm going to try to bring you up to date on that and just maybe convince you that it is in fact possible that our brains do something like backpropagation.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so let's start with that first one the error term.",
                    "label": 0
                },
                {
                    "sent": "So the brain, as I said, can definitely Calculator terms.",
                    "label": 1
                },
                {
                    "sent": "Your motor system is full of error terms and they're really important for helping to correct motor control that you're doing online.",
                    "label": 0
                },
                {
                    "sent": "But as I said, you know there's no evidence for something like this sort of error term that we want for backpropagation.",
                    "label": 0
                },
                {
                    "sent": "For many of the things that you need, Cortex learns.",
                    "label": 0
                },
                {
                    "sent": "So let's say, for example, when you're learning to speak right, there's no evidence that you try to speak as a kid and then somehow a target is formed in your brain based upon what your parents are saying, what you did, and what your parents say gets subtracted from each other and then not subtraction somehow gets propagated through your brain.",
                    "label": 1
                },
                {
                    "sent": "There's no evidence for anything like that.",
                    "label": 1
                },
                {
                    "sent": "Now, but it is the case that you do have your parents talking around you and giving you an example of how to speak.",
                    "label": 0
                },
                {
                    "sent": "So even though you don't have this explicit comparison between what you did and what you should do, you probably do have something that's kind of pushing you towards the right answer some of the time.",
                    "label": 0
                },
                {
                    "sent": "And so ideally, what we'd like is we'd like a network which has these sort of.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Just like nudging signals so that the network just occasionally gets pushed by environmental feedback towards something that is more like the right answer than what you had done previously, and that theoretically possible given the stimulus we received in the environment.",
                    "label": 0
                },
                {
                    "sent": "So, um.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This is something that Yahshua and his postdoc is Benjamin New postdoc.",
                    "label": 0
                },
                {
                    "sent": "PhD student and his PhD student Benjamin have been working on an they released this year of paper on system they call equilibrium propagation.",
                    "label": 1
                },
                {
                    "sent": "And Yashua, feel free to correct me if I got any of this wrong, I know.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "What they what they do in this system?",
                    "label": 0
                },
                {
                    "sent": "Excuse me what they do in this system is.",
                    "label": 0
                },
                {
                    "sent": "Rather than having a forward pass and then explicit calculation of an error between that forward pass and some target that you have, they've got two different phases for their network, so here's an image of the basic idea for a network that's going to do something like backdrop.",
                    "label": 0
                },
                {
                    "sent": "Though this algorithm works with many different network architectures, not just this stacked architecture.",
                    "label": 0
                },
                {
                    "sent": "I'll just mention a change of variables here, so we're still referring to our input is X.",
                    "label": 0
                },
                {
                    "sent": "Our output is Y&R hidden layers is H but now you here is going to refer to the entire set of units activities.",
                    "label": 0
                },
                {
                    "sent": "Uh and D is our target.",
                    "label": 0
                },
                {
                    "sent": "Now the idea is that what you have is you have a phase where there is no kind of nudging from the external environment, so this would be like your parent who's speaking correctly in front of you right?",
                    "label": 1
                },
                {
                    "sent": "And so sometimes you don't have your parent there and there is no external nudging signal, but sometimes you do and they use this term here beta to indicate the difference between those situations, so they call.",
                    "label": 1
                },
                {
                    "sent": "When beta is equal to 0, that's the free phase, and that's when there is no nudging on the system from the environment.",
                    "label": 0
                },
                {
                    "sent": "When beta is greater than zero, the system is being pushed towards the right answer by the environment and they call this the weekly clamped phase.",
                    "label": 0
                },
                {
                    "sent": "The to get a full clamping like is done in actual artificial neural networks.",
                    "label": 0
                },
                {
                    "sent": "You would have beta equal to Infinity and then the system is just kind of like a standard neural network and that during that clamped phase it is getting the correct answer forced on it.",
                    "label": 0
                },
                {
                    "sent": "But as long as betas, non infinite, but we've got is weak clamping and so the system is just kind of getting nudged towards the right answer.",
                    "label": 0
                },
                {
                    "sent": "And So what they?",
                    "label": 0
                },
                {
                    "sent": "What they show?",
                    "label": 0
                },
                {
                    "sent": "I'm not going to run through all the derivations and stuff.",
                    "label": 0
                },
                {
                    "sent": "I leave you to look it up in this paper here.",
                    "label": 0
                },
                {
                    "sent": "So they develop energy terms for this network so that they can know what the networks going to settle to.",
                    "label": 0
                },
                {
                    "sent": "Both with the nudging term and without the nudging term.",
                    "label": 0
                },
                {
                    "sent": "And then.",
                    "label": 0
                },
                {
                    "sent": "By taking the derivative.",
                    "label": 0
                },
                {
                    "sent": "Of their energy terms, they can get out this synaptic weight update.",
                    "label": 0
                },
                {
                    "sent": "So this synaptic weight update basically says if you've got any two neurons that are Co active together during the point in time in which the nudging factor was present, you want to increase the weight between those two neurons.",
                    "label": 0
                },
                {
                    "sent": "And if you have any two neurons that were Co active during the point when the when it was in free phase, you want to decrease the weight between those two neurons.",
                    "label": 0
                },
                {
                    "sent": "And this difference is then going to give you your weight update, and in fact what Benjamin and Joshua Show is that this can implement stochastic gradient descent on the standard loss function.",
                    "label": 0
                },
                {
                    "sent": "Just the error between D&Y.",
                    "label": 0
                },
                {
                    "sent": "Now, this is reminiscent for those of you who do know this kind of stuff of things like contrastive divergent's or Boltzmann machine training in that you are kind of looking at.",
                    "label": 0
                },
                {
                    "sent": "Yeah, he's actually not just squared error, but any laws that any losses differential OK, right right where the loss is defined by how your what your target is right, yeah, OK.",
                    "label": 0
                },
                {
                    "sent": "Right cool.",
                    "label": 0
                },
                {
                    "sent": "I so.",
                    "label": 0
                },
                {
                    "sent": "What what's very interesting about this then, is so, like I said, it's got a flavor kind of like contrast convergence, kind of like Boltzmann machines, etc.",
                    "label": 0
                },
                {
                    "sent": "But critically, they're not.",
                    "label": 0
                },
                {
                    "sent": "Really just clamping the correct answer on the system.",
                    "label": 0
                },
                {
                    "sent": "There is no point in time at which the system is forced to have the correct answer.",
                    "label": 0
                },
                {
                    "sent": "Instead of just getting nudged towards the correct answer, which is something probably more like what your brain actually has and is less problematic than the error term that is typically passed around in backpropagation, I think.",
                    "label": 1
                },
                {
                    "sent": "Now the other thing that's very interest.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "About this is it predicts a classic set of experiments known as spike timing dependent plasticity.",
                    "label": 1
                },
                {
                    "sent": "So let me unpack this a little bit for you.",
                    "label": 0
                },
                {
                    "sent": "So here you've got an illustration of two neurons.",
                    "label": 0
                },
                {
                    "sent": "These are the yellow dots.",
                    "label": 0
                },
                {
                    "sent": "That's what neurons look like.",
                    "label": 0
                },
                {
                    "sent": "And they are connected by a synapse, so we've got a presynaptic neuron jayanna postsynaptic neuron I and we can look at the time at which these two neurons are act.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Excuse me, I'm going to do that.",
                    "label": 0
                },
                {
                    "sent": "We can look at the time.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "These two neurons are active, so here we've got a little plot neuron.",
                    "label": 0
                },
                {
                    "sent": "J is active at this point in time and Neuron I is active.",
                    "label": 0
                },
                {
                    "sent": "At this point in time.",
                    "label": 0
                },
                {
                    "sent": "And when I say active I mean firing a spike.",
                    "label": 0
                },
                {
                    "sent": "And what researchers have shown, not just in the neocortex, but in a remarkable number of brain regions.",
                    "label": 0
                },
                {
                    "sent": "Is that if you look at the difference in time.",
                    "label": 0
                },
                {
                    "sent": "So if you take 2 neurons that are connected and you repeatedly get them to spike with some temporal difference between them.",
                    "label": 0
                },
                {
                    "sent": "So let's say we always get the red neuron to spike just before the green neuron, then you're going to get a particular change in the synapse and the change in the synapse is going to be dependent upon that difference in time between the presynaptic and postsynaptic spikes.",
                    "label": 0
                },
                {
                    "sent": "So that's what's actually plotted here on the X axis on the X axis is the difference in time between the presynaptic spike and the postsynaptic spike.",
                    "label": 0
                },
                {
                    "sent": "Where it's TJ minus TI.",
                    "label": 0
                },
                {
                    "sent": "So if TJ is greater than T wherein the negative phase.",
                    "label": 0
                },
                {
                    "sent": "Sorry if it's less than T were in the negative phase he ran.",
                    "label": 0
                },
                {
                    "sent": "If TJ is greater than T were in the positive phase here.",
                    "label": 0
                },
                {
                    "sent": "So in other words this half of the plot is where T the J neurons spiked before the eye neuron and this half of the plot is where the I neurons spike before the Jane, Ron and these dots are actual experimental.",
                    "label": 0
                },
                {
                    "sent": "Recordings of so on the Y axis were plotting the change in the synaptic connection between them, and you see this very clear relationship between the temporal difference between those spikes and how much the synapse between those two neurons change.",
                    "label": 0
                },
                {
                    "sent": "And neuro scientists got very excited about this result when it was when it first was discovered, and especially when it continued to be discovered in a number of brain regions because.",
                    "label": 0
                },
                {
                    "sent": "It's the closest thing they had kind of ever gotten to a clear learning rule for how synapses are updated in response to patterns of activity.",
                    "label": 0
                },
                {
                    "sent": "And you can show that it has some interesting properties.",
                    "label": 0
                },
                {
                    "sent": "It seems to be, for example, training neuron J to predict the activity of neuron I.",
                    "label": 0
                },
                {
                    "sent": "It has a kind of causal flavor to it.",
                    "label": 0
                },
                {
                    "sent": "But what's interesting?",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Is so Joshua and Benjamin showed that in fact.",
                    "label": 0
                },
                {
                    "sent": "You can get STD P out of a set like out of a learning algorithm that has this relationship where the change over time of your weights is a function of your postsynaptic activation times.",
                    "label": 1
                },
                {
                    "sent": "The temporal derivative of your presynaptic activation.",
                    "label": 0
                },
                {
                    "sent": "That was the original 1 right?",
                    "label": 0
                },
                {
                    "sent": "And then you can modify this to instead be the derivative of the full activation function.",
                    "label": 0
                },
                {
                    "sent": "Right?",
                    "label": 0
                },
                {
                    "sent": "Anne, what they also show is that this relationship does in fact hold for their equilibrium propagation algorithm.",
                    "label": 0
                },
                {
                    "sent": "And so.",
                    "label": 0
                },
                {
                    "sent": "In other words, their algorithm, though it's ultimately designed to be doing gradient descent on these cost functions.",
                    "label": 0
                },
                {
                    "sent": "Spits out STD P. If you were.",
                    "label": 0
                },
                {
                    "sent": "If you were, if you imagine that there we had a neural network learning by this algorithm and then you were an experimentalist testing for the learning algorithm in it, and you ran the STP experiments, you would get the same results that real neuroscientists got in the brain, so that's a very interesting finding and very exciting in many ways.",
                    "label": 1
                },
                {
                    "sent": "But Yep.",
                    "label": 0
                },
                {
                    "sent": "Can you deal?",
                    "label": 0
                },
                {
                    "sent": "There's a little more precise about this experiment, so like sure TJM TI are you like?",
                    "label": 0
                },
                {
                    "sent": "Would be that?",
                    "label": 0
                },
                {
                    "sent": "You're directly manipulating the voltage potential of these two neurons independently, correct?",
                    "label": 0
                },
                {
                    "sent": "And then how do you measure this change in the synaptic connectivity?",
                    "label": 0
                },
                {
                    "sent": "Sure, OK, so the way you do these experiments is you perform what's called a Patch clamp recording on both these neurons, so a Patch clamp recording is where you go with a tiny little glass pipette.",
                    "label": 0
                },
                {
                    "sent": "And you literally suction onto the neuron and then you burst a hole in its membrane so that you can record its intracellular electrical activity.",
                    "label": 0
                },
                {
                    "sent": "And So what they do is in these experiments is they'll Patch 2 neurons and then they can determine whether they are synaptically coupled by injecting current into the neurons and seeing if it induces a response in the other neuron.",
                    "label": 0
                },
                {
                    "sent": "That is to say, if they inject current, say into neuron J and they cause it to spike, do they see a postsynaptic response in neuron I with their Patch clamp recording?",
                    "label": 0
                },
                {
                    "sent": "And So what they do is they will then if they find 2 neurons that are synaptically coupled, they will inject current into neuron J and inject current into neuron.",
                    "label": 0
                },
                {
                    "sent": "I at slightly different times to create this pattern of a spike in neuron J and spiking neuron I at different times and they do that many, many times over.",
                    "label": 0
                },
                {
                    "sent": "Now the way that they measured the synaptic strength is a measure that postsynaptic response to neuron J spiking.",
                    "label": 0
                },
                {
                    "sent": "So when you cause neuron Jada Spike at first, you're going to get some response.",
                    "label": 0
                },
                {
                    "sent": "In neuron I you can measure that and then after you do this protocol, you can do that again and you can see how that postsynaptic response changed.",
                    "label": 0
                },
                {
                    "sent": "Yep.",
                    "label": 0
                },
                {
                    "sent": "Right?",
                    "label": 0
                },
                {
                    "sent": "Summarize.",
                    "label": 0
                },
                {
                    "sent": "So well, I was having trouble with your last bit there, but the first question was I if I take it correctly, was to what extent to these networks suffer from the same capacity issues that Hopfield networks suffer from?",
                    "label": 0
                },
                {
                    "sent": "Is that roughly right?",
                    "label": 0
                },
                {
                    "sent": "OK, I don't know the answer to that.",
                    "label": 0
                },
                {
                    "sent": "Do you want to address that?",
                    "label": 0
                },
                {
                    "sent": "They don't.",
                    "label": 0
                },
                {
                    "sent": "They have the same capacity as the normal people, right?",
                    "label": 0
                },
                {
                    "sent": "Yeah, 'cause there ultimately, although you're right, the flavor is similar in terms of the use of an energy function and stuff like that.",
                    "label": 0
                },
                {
                    "sent": "Limited capacity is because they don't have hidden units.",
                    "label": 0
                },
                {
                    "sent": "That's the problem, right?",
                    "label": 0
                },
                {
                    "sent": "Connection is basically stored only well order of endangered.",
                    "label": 0
                },
                {
                    "sent": "It's because they can't increase capacity, but here you can put as many hidden units as you want, right?",
                    "label": 0
                },
                {
                    "sent": "OK. Any other questions?",
                    "label": 0
                },
                {
                    "sent": "If you are very similar to how people answer anyways, yeah.",
                    "label": 0
                },
                {
                    "sent": "So another number, yeah?",
                    "label": 0
                },
                {
                    "sent": "So how does the temporal groups come in here?",
                    "label": 0
                },
                {
                    "sent": "Sorry, yeah, that's a good question, thank you.",
                    "label": 0
                },
                {
                    "sent": "So OK, the idea is that.",
                    "label": 0
                },
                {
                    "sent": "Alright, if at all.",
                    "label": 0
                },
                {
                    "sent": "If you if you consider the what's happening to, the voltage is in the neurons.",
                    "label": 0
                },
                {
                    "sent": "At the point in time in which you're running these STP experiments, right, presumably.",
                    "label": 0
                },
                {
                    "sent": "As when neuron I is excuse me.",
                    "label": 0
                },
                {
                    "sent": "Now in fact, now that I'm looking at this equation, I. I&J are reversed.",
                    "label": 0
                },
                {
                    "sent": "That's right, excuse me so ING reversed.",
                    "label": 0
                },
                {
                    "sent": "Uh, so.",
                    "label": 0
                },
                {
                    "sent": "You'll have to excuse me, let's.",
                    "label": 0
                },
                {
                    "sent": "Well, I don't yeah.",
                    "label": 0
                },
                {
                    "sent": "Let's make that.",
                    "label": 0
                },
                {
                    "sent": "Oh, I shouldn't actually be doing this.",
                    "label": 0
                },
                {
                    "sent": "'cause I'm on camera, but so let's let's let's reverse it.",
                    "label": 0
                },
                {
                    "sent": "So if it's.",
                    "label": 0
                },
                {
                    "sent": "I UJ Anthy, sorry UI.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "It should be like this.",
                    "label": 0
                },
                {
                    "sent": "Right, 'cause it's the temporal derivative of the postsynaptic neuron that we're interested in, yes, so the way this works is, let's imagine that neuron.",
                    "label": 0
                },
                {
                    "sent": "Jr presynaptic neuron is active.",
                    "label": 0
                },
                {
                    "sent": "Right here and at that same time neuron IR postsynaptic neuron has an increasing voltage, so the temporal derivative of its voltage is positive.",
                    "label": 0
                },
                {
                    "sent": "That is probably a moment just before neuron I is going to spike.",
                    "label": 0
                },
                {
                    "sent": "So if you, if you're doing this protocol, the derivative of neurons are neuron eyes, voltage at the time of.",
                    "label": 0
                },
                {
                    "sent": "Of the input from neuron J is positive and so this relationship, not this one.",
                    "label": 0
                },
                {
                    "sent": "Another error for my slides to correct excuse me is going to give you potentiation and that's what you see right here.",
                    "label": 0
                },
                {
                    "sent": "In contrast, if you have the postsynaptic neuron spike before the presynaptic neuron, then the derivative of the postsynaptic neurons voltage is going to be going down at the time that the presynaptic inputs arrive, and so that's going to give you a negative term, and you're going to decrease the weights.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I we can do back prop without explicit error terms an we can just kind of have a system where the neural network is nudged towards the right answer by the external environment.",
                    "label": 1
                },
                {
                    "sent": "And Interestingly it seems to match experimental data on spike timing dependent plasticity, so that's cool item number one down.",
                    "label": 1
                },
                {
                    "sent": "Alright, now transpose the weights so.",
                    "label": 0
                },
                {
                    "sent": "That previous model that I showed you is still depending upon symmetric weights in the network, and the idea that the neurons somehow have access to the transpose of the downstream weights, which is problematic.",
                    "label": 0
                },
                {
                    "sent": "And as I said, that is.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In fact, one of the biggest issues as far as neuro scientists are concerned.",
                    "label": 0
                },
                {
                    "sent": "So let's draw out what it would actually have to look like.",
                    "label": 0
                },
                {
                    "sent": "So here we've got a neural network, some hypothetical neural network that exists in our brain with input hidden unit output.",
                    "label": 0
                },
                {
                    "sent": "And the colors here represent the synapses onto neurons in the output layer an.",
                    "label": 0
                },
                {
                    "sent": "In order to calculate my weight updates in my hidden layer theoretically, what I need is I need a pathway that's going to send the error term back.",
                    "label": 0
                },
                {
                    "sent": "And do so with synapses that exactly mirror the synapses here.",
                    "label": 0
                },
                {
                    "sent": "And this, as I said, is what most neuroscientists consider to be bonkers, because that's a very difficult setup.",
                    "label": 0
                },
                {
                    "sent": "And certainly it's nothing you should assume exists in the brain.",
                    "label": 0
                },
                {
                    "sent": "And experimental data suggests that it most definitely does not exist in the brain.",
                    "label": 0
                },
                {
                    "sent": "Although.",
                    "label": 0
                },
                {
                    "sent": "There are feedback connections, it's just that there's the evidence suggests that they're not perfectly symmetric.",
                    "label": 0
                },
                {
                    "sent": "Like I said earlier, that.",
                    "label": 0
                },
                {
                    "sent": "For some pairs of neurons, there aren't any feedback connections.",
                    "label": 0
                },
                {
                    "sent": "That's correct, yes.",
                    "label": 0
                },
                {
                    "sent": "Backpack.",
                    "label": 0
                },
                {
                    "sent": "That's right, so it could be that they are connected indirectly via a couple of different neurons, but then it makes the question of having symmetric synapses even harder.",
                    "label": 0
                },
                {
                    "sent": "So it's a very difficult problem.",
                    "label": 0
                },
                {
                    "sent": "Now let's just simplify this illustration a little bit, so the idea is that here we've got synapses W, not here.",
                    "label": 0
                },
                {
                    "sent": "We've got synapses W one, and then we've got feedback projections from the output layer to the hidden layer that are somehow just the transpose of W. One.",
                    "label": 1
                },
                {
                    "sent": "That's the original idea of backpropagation.",
                    "label": 0
                },
                {
                    "sent": "And like I said, it leads many neuroscientists to dismiss it.",
                    "label": 1
                },
                {
                    "sent": "Now The thing is though, so Tim Lillicrap, who's researcher at Google DeepMind now.",
                    "label": 0
                },
                {
                    "sent": "He and I we we took Jeff Hinton's neural networks courses, undergrads together long ago, and we both drank his Kool aid and we.",
                    "label": 0
                },
                {
                    "sent": "We were convinced that the brain did backdrop at the time.",
                    "label": 0
                },
                {
                    "sent": "That was a very controversial idea.",
                    "label": 0
                },
                {
                    "sent": "It certainly wasn't in Vogue, and but he and I and I were sure it did something like that.",
                    "label": 0
                },
                {
                    "sent": "So we had had many discussions about.",
                    "label": 0
                },
                {
                    "sent": "OK, well, even if you're not guaranteed symmetric weights, how could you maybe learn how to have symmetric weights?",
                    "label": 0
                },
                {
                    "sent": "So could you design A learning algorithm where you could actually train the feedback connections so that they will eventually give you this metric weights that allow you to do back propagation?",
                    "label": 0
                },
                {
                    "sent": "And Tim decided that he was going to try to.",
                    "label": 0
                },
                {
                    "sent": "He's going to jump into it.",
                    "label": 0
                },
                {
                    "sent": "I was a young father doing a postdoc at the time, and I was like, yeah, whatever you go ahead, he's he's going to jump into.",
                    "label": 0
                },
                {
                    "sent": "So he's going to train a learning algorithm to learn these backwards weights now.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "He had an algorithm that he was interested in and to test his algorithm he wanted to develop a control case.",
                    "label": 0
                },
                {
                    "sent": "Now the obvious control case was to use a condition where rather than sending the error back through the weights that he's trying to train, he sends the error back through some random matrix B, which he leaves fixed, so he doesn't train the backwards weights, you just send the error back through a random matrix and updates using.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This random matrix B in place of the transpose of the feedforward matrix.",
                    "label": 1
                },
                {
                    "sent": "And so theoretically that should be crap.",
                    "label": 1
                },
                {
                    "sent": "And that's going to be his control case to compare his learning algorithm to which should be doing well.",
                    "label": 0
                },
                {
                    "sent": "But weirdly.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Enough, the control condition learned quite well.",
                    "label": 1
                },
                {
                    "sent": "It worked better than his.",
                    "label": 0
                },
                {
                    "sent": "He he came back.",
                    "label": 0
                },
                {
                    "sent": "He called me on the phone that week he came right back to his simulations and he saw it and he ran it a couple more times and.",
                    "label": 0
                },
                {
                    "sent": "He called me.",
                    "label": 0
                },
                {
                    "sent": "He was like I have this weird really really weird result.",
                    "label": 0
                },
                {
                    "sent": "I don't know what's going on.",
                    "label": 0
                },
                {
                    "sent": "My control condition is learning better than my than the learning algorithm was trying to design.",
                    "label": 0
                },
                {
                    "sent": "I think it must be a bug, but I'm going to run it again and again and again and he did it again and again and again.",
                    "label": 0
                },
                {
                    "sent": "It always came back.",
                    "label": 0
                },
                {
                    "sent": "The control condition learned better than his learning algorithm learn quite well.",
                    "label": 0
                },
                {
                    "sent": "And so in fact.",
                    "label": 0
                },
                {
                    "sent": "So what he called this situation where you're just pumping back through a random matrix.",
                    "label": 0
                },
                {
                    "sent": "He called this feedback alignment and you'll explain why in a second.",
                    "label": 0
                },
                {
                    "sent": "Here I'm showing you a plot of the test error that he gets out on Em Nest in a 1 hidden layer neural network.",
                    "label": 0
                },
                {
                    "sent": "So just a fully connected neural Network 1 hidden layer.",
                    "label": 0
                },
                {
                    "sent": "Well, the shallow network is is no hidden layer, so that's as expected.",
                    "label": 0
                },
                {
                    "sent": "This is why we're all at a deep learning summer school because the shallow network sucks.",
                    "label": 0
                },
                {
                    "sent": "But then here is back prop.",
                    "label": 0
                },
                {
                    "sent": "And just running vanilla backdrop on amnesty and a fully connected network, you'll get down to like 2.4%.",
                    "label": 0
                },
                {
                    "sent": "And here's his algorithm using the random matrix and it's actually doing a little bit better than backpropagation in this network, which is weird.",
                    "label": 0
                },
                {
                    "sent": "What's going on?",
                    "label": 0
                },
                {
                    "sent": "So it turns out that the reason this was working is that the forward weights actually align themselves with those random backwards weights.",
                    "label": 1
                },
                {
                    "sent": "So here's what I'm plotting here.",
                    "label": 0
                },
                {
                    "sent": "This is so you can look at the weight updates that are prescribed by this feedback alignment algorithm and the weight updates that are prescribed by backpropagation for the hidden layer.",
                    "label": 0
                },
                {
                    "sent": "And both of these are just vectors that we can measure the angle between, right?",
                    "label": 0
                },
                {
                    "sent": "So feedback alignment this using the random matrix is going to push the weights in a particular direction and wait space back propagation is going to push it in another direction in the weight space.",
                    "label": 0
                },
                {
                    "sent": "And if you have any two vectors in a very high dimensional space, just random vectors in high dimensional space, they're going to be orthogonal to each other.",
                    "label": 0
                },
                {
                    "sent": "So if these two algorithms were doing something quite different, they should be these two.",
                    "label": 0
                },
                {
                    "sent": "The angle between these two things should be 90 degrees.",
                    "label": 0
                },
                {
                    "sent": "And indeed, that's what happens when you first start running the algorithm.",
                    "label": 0
                },
                {
                    "sent": "It may be hard to see here, but the first point, so we're plotting across training examples.",
                    "label": 0
                },
                {
                    "sent": "The angle between what backpropagation is prescribing and what his feedback alignment algorithm with the random matrix was prescribing.",
                    "label": 0
                },
                {
                    "sent": "And it starts off orthogonal and then it rapidly drops down.",
                    "label": 0
                },
                {
                    "sent": "So the system is actually coming to prescribe weight updates now like this is just below 45 degrees here, but in a high dimensional environment that's actually pretty much in the right direction.",
                    "label": 0
                },
                {
                    "sent": "It's getting pushed yeah, and it's going down and it's going down right?",
                    "label": 0
                },
                {
                    "sent": "Yes?",
                    "label": 0
                },
                {
                    "sent": "So in other words, what the network is doing is it's actually learning over the first few training examples to basically approximate backpropagation.",
                    "label": 0
                },
                {
                    "sent": "And the way it's doing that is.",
                    "label": 0
                },
                {
                    "sent": "What Tim shows in the paper, which you can read here, is that this.",
                    "label": 0
                },
                {
                    "sent": "Weight matrix is coming to be.",
                    "label": 0
                },
                {
                    "sent": "In fact the pseudo inverse of the random backwards projection.",
                    "label": 0
                },
                {
                    "sent": "And so that's why the system actually learns quite well because it's actually approximating something 2nd order because it's not just the transpose, it's coming to approximate the pseudoinverse.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "That was surprising, and it means that we can do back prop without the transpose of the weights, yeah?",
                    "label": 1
                },
                {
                    "sent": "1 Hidden layer order.",
                    "label": 0
                },
                {
                    "sent": "This is just an observation.",
                    "label": 0
                },
                {
                    "sent": "It seems that the weights will converge towards metric OK, right?",
                    "label": 0
                },
                {
                    "sent": "Right, yes, and so let me just say something to that.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Fact, I think that.",
                    "label": 0
                },
                {
                    "sent": "So with this algorithm, what Tim's result illustrates is that.",
                    "label": 0
                },
                {
                    "sent": "You don't need to have symmetric weights to get things up and running, but that is not to say that the feedback weights are not learning and learning in a way to help make credit assignment on a cost function better.",
                    "label": 0
                },
                {
                    "sent": "So I think you know we do know that the backwards projections in our brains are plastic.",
                    "label": 1
                },
                {
                    "sent": "And they are probably learning, unlike in this case, but nonetheless what this tells us, and that's what you was getting at, is if you have an auto encoder, it will learn to give you the right sort of weights for backdrop.",
                    "label": 0
                },
                {
                    "sent": "So if our brains say or stacked autoencoders, then we could effectively be doing backdrop through that system.",
                    "label": 0
                },
                {
                    "sent": "But the point is, and this is what's reassuring for me.",
                    "label": 0
                },
                {
                    "sent": "Is a neuro scientist, even if it doesn't get it perfect.",
                    "label": 0
                },
                {
                    "sent": "So even if it doesn't have ideally symmetric weights.",
                    "label": 0
                },
                {
                    "sent": "The system is still going to learn quite well in fact, and it means that we are no longer faced by the strict requirement that we have symmetric feedback weights to do back propagation in the brain.",
                    "label": 0
                },
                {
                    "sent": "So they also get some experiments on a deeper version of the network that the results were very convincing.",
                    "label": 0
                },
                {
                    "sent": "As far as I'm concerned, right?",
                    "label": 0
                },
                {
                    "sent": "This extends to yeah, so this is yeah, so I left that point out, but that's true.",
                    "label": 0
                },
                {
                    "sent": "The extent to which this generalizes to ever deeper networks is questionable, and so I think to get to networks with many hidden layers, you probably need some kind of training on the feedback system to have it work.",
                    "label": 0
                },
                {
                    "sent": "Yeah, is there some linear algebra reason why the.",
                    "label": 0
                },
                {
                    "sent": "Back propagated error signal which is soon by the transpose should be have a positive inner product or less than 90 degrees angle with the feedback if the feedback was impacted by a pseudoinverse like are, the suit is the output of the pseudoinverse in the output of the transpose for some reason going to be aligned?",
                    "label": 0
                },
                {
                    "sent": "Yes, I mean so.",
                    "label": 0
                },
                {
                    "sent": "The extent to which the output from running it through the pseudoinverse versus running it through the transpose, the extent to which they are aligned is obviously going to depend upon the extent to which the transpose in the pseudoinverse are similar matrices to each other.",
                    "label": 0
                },
                {
                    "sent": "Similar linear transformations and.",
                    "label": 0
                },
                {
                    "sent": "I mean here I don't want to expect.",
                    "label": 0
                },
                {
                    "sent": "I don't want to comment too much because I haven't actually analyzed this, but they're going to be roughly in agreement for many matrices right?",
                    "label": 0
                },
                {
                    "sent": "Many random matrices, right, I guess.",
                    "label": 0
                },
                {
                    "sent": "I thought I could find some inputs to these two operators such that the output would be anticorrelated.",
                    "label": 0
                },
                {
                    "sent": "You know, kind of proven 90 degree angle.",
                    "label": 0
                },
                {
                    "sent": "That's a, that's a good question.",
                    "label": 0
                },
                {
                    "sent": "I you know I'm going to have to say that I don't have a good intuition for why that cannot be the case.",
                    "label": 0
                },
                {
                    "sent": "I don't know if you do.",
                    "label": 0
                },
                {
                    "sent": "Yeah yeah.",
                    "label": 0
                },
                {
                    "sent": "I mean, that's certainly true most of the time, but why do we never see it pop above 90 degrees?",
                    "label": 0
                },
                {
                    "sent": "Well, I mean so it might have something to do with the the inputs to the.",
                    "label": 0
                },
                {
                    "sent": "Whatever you want to call it back way as well, Yep.",
                    "label": 0
                },
                {
                    "sent": "That's a good question.",
                    "label": 0
                },
                {
                    "sent": "I I'm going to think about that more.",
                    "label": 0
                },
                {
                    "sent": "OK, so sorry, just to yet another question.",
                    "label": 0
                },
                {
                    "sent": "Wait?",
                    "label": 0
                },
                {
                    "sent": "My.",
                    "label": 0
                },
                {
                    "sent": "My.",
                    "label": 0
                },
                {
                    "sent": "Problem with feedback is that if the backwards way Sir are frozen for all time, that's also so much biologically improbable.",
                    "label": 0
                },
                {
                    "sent": "Oh yes, changes all the time.",
                    "label": 0
                },
                {
                    "sent": "Yes, yes, it's not like.",
                    "label": 0
                },
                {
                    "sent": "A way to distinguish in particular synaptic weight as backwards or forwards, and that one should freeze and that one should not well, OK. That second statement is not true.",
                    "label": 0
                },
                {
                    "sent": "There is a way to determine which weights are the backwards and forwards weights in fact, but I take your larger point and we'll talk about that in a second, but I take your larger point that backwards weights in the real brain are undoubtedly not frozen.",
                    "label": 0
                },
                {
                    "sent": "Like I said, in fact, we know experimentally that they are changing.",
                    "label": 0
                },
                {
                    "sent": "I.",
                    "label": 0
                },
                {
                    "sent": "But again, the reason that this is satisfying is not because I think the brain is learning with frozen backwards weights.",
                    "label": 1
                },
                {
                    "sent": "It's a demonstration that the explicit symmetry that was assumed to be required to do stochastic gradient descent in a multilayer neural network is not in fact required for that, and that means that the brain doesn't have to meet the stringent symmetry requirements.",
                    "label": 0
                },
                {
                    "sent": "That led many neuroscientists to dismiss the idea of backdrop in the brain.",
                    "label": 0
                },
                {
                    "sent": "Yep.",
                    "label": 1
                },
                {
                    "sent": "Presentation generated so yeah.",
                    "label": 0
                },
                {
                    "sent": "To be aligned with the random matrix and the neurons.",
                    "label": 0
                },
                {
                    "sent": "One thing.",
                    "label": 0
                },
                {
                    "sent": "Well, no, OK.",
                    "label": 0
                },
                {
                    "sent": "So let's clarify it.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "W 0 doesn't align with the random matrix W one does now.",
                    "label": 0
                },
                {
                    "sent": "In fact, what W 0 ends up doing is producing a set of weights that separate the representations for the different inputs in a manner that respects the separation that the error term imposes on them.",
                    "label": 1
                },
                {
                    "sent": "So if you look at the representations, it's a good question.",
                    "label": 0
                },
                {
                    "sent": "If you look at the representations in a network that's trained with feedback alignment.",
                    "label": 0
                },
                {
                    "sent": "What it does is in the hidden layers it separates the different categories onto different manifolds in fact.",
                    "label": 1
                },
                {
                    "sent": "So if you run T sne on the representations in the hidden layer.",
                    "label": 1
                },
                {
                    "sent": "You will find that your categories are in fact pulled apart from each other and lie on clean different manifolds much more so than in the input.",
                    "label": 0
                },
                {
                    "sent": "Sure, yeah, it learns exactly the same type of features that something like backpropagation does, which as you've seen from the number of talks, an papers and stuff often look like many of the features that we see in the brain, edge detection, etc.",
                    "label": 0
                },
                {
                    "sent": "So on a single neuron level it matches intuitions, and on on the vector level it also matches intuitions.",
                    "label": 0
                },
                {
                    "sent": "Surprisingly.",
                    "label": 0
                },
                {
                    "sent": "When you have like this feature representation and you project, that will basically run the matrix and you get correct location.",
                    "label": 0
                },
                {
                    "sent": "Well, so the key is that the representations that are getting learned here are going to separate out the different categories because your still your error term is going to give you information on how the different categories should be separated and even when you run that through a random matrix you've still got that information available to you.",
                    "label": 0
                },
                {
                    "sent": "So in order to respect the.",
                    "label": 0
                },
                {
                    "sent": "Information that the feedback is sending this hidden layer will develop a set of representations that separate out the categories and now the goal of this weight matrix is basically just to figure out what the transformation is from those representations to the output space, which is in fact to do the inverse of B.",
                    "label": 1
                },
                {
                    "sent": "That's why it learns to align itself.",
                    "label": 1
                },
                {
                    "sent": "That's right, yeah.",
                    "label": 0
                },
                {
                    "sent": "So this is what we were just talking about.",
                    "label": 0
                },
                {
                    "sent": "Is the pseudoinverse in the transpose are not going to be identical to each other, but they're going to provide?",
                    "label": 0
                },
                {
                    "sent": "At least empirically, we see that given a large number of different random matrices that you select for B, they actually provide the same direction of push on the hidden layer.",
                    "label": 0
                },
                {
                    "sent": "But we can imagine matrices like if we design B to give us a big difference between the pseudoinverse in this and the transpose, then maybe we could push back prop and feedback alignment away from each other.",
                    "label": 0
                },
                {
                    "sent": "Yep.",
                    "label": 0
                },
                {
                    "sent": "That's not directly connect.",
                    "label": 0
                },
                {
                    "sent": "You need the news, yeah?",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 1
                },
                {
                    "sent": "At the same time, well, OK, so that's a good question.",
                    "label": 0
                },
                {
                    "sent": "These are one of the many unsolved issues, so dealing with the all of the many different delays that exist in the brain and figuring out how you do credit assignment appropriately.",
                    "label": 0
                },
                {
                    "sent": "Given all of those different delays is not a trivial thing to workout, but I think the important thing, and this is what?",
                    "label": 0
                },
                {
                    "sent": "I always say to neuroscientists is the point is not that these models solve all the problems for us.",
                    "label": 1
                },
                {
                    "sent": "They're not telling us exactly how the brains doing it.",
                    "label": 0
                },
                {
                    "sent": "They're here to illustrate that what we thought was a problem is not, in fact, a problem.",
                    "label": 0
                },
                {
                    "sent": "Now the delays is still a problem, but there will be other ways to deal with that.",
                    "label": 0
                },
                {
                    "sent": "Now I think I'm going to.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For the next section, I think I'm going to because I'm running out of time here and I want to have time for questions.",
                    "label": 0
                },
                {
                    "sent": "With all due respect to Syria, I'm going to skip the stuff on Syria's spike prop, 'cause I think he said he was going to talk a little bit about it.",
                    "label": 0
                },
                {
                    "sent": "So what?",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I'll just say is issue 3 that I was going to talk about is how do you deal with the fact that we have these all or none action potentials and we want to take the derivative of the activation function with these.",
                    "label": 0
                },
                {
                    "sent": "Discrete events which seems problematic.",
                    "label": 0
                },
                {
                    "sent": "And I'll just note that.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Surya Ganguly's lab, particularly with Frederick Zenke.",
                    "label": 0
                },
                {
                    "sent": "They've designed the system, which you can read about here, that does affectively backpropagation on very precise spike trains by just defining a different loss function.",
                    "label": 0
                },
                {
                    "sent": "That is the difference between the spike trains convolved with this temporal convolution kernel, and then replacing this nasty term with.",
                    "label": 0
                },
                {
                    "sent": "A.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Nice auxiliary function that they can take the derivative of.",
                    "label": 0
                },
                {
                    "sent": "And also I'm not going to.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the math 'cause I want to move on to the next topic.",
                    "label": 0
                },
                {
                    "sent": "But here you can see that what they can do with that system is they can actually say to the neurons.",
                    "label": 0
                },
                {
                    "sent": "OK, we want you to Spike at this moment this moment this moment, this moment.",
                    "label": 0
                },
                {
                    "sent": "So here you're looking at the spikes in the input layer to the neural network.",
                    "label": 0
                },
                {
                    "sent": "So actually here.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Move to this one here we've got hidden units, so here's the spikes in the input layer.",
                    "label": 0
                },
                {
                    "sent": "Here are the hidden unit voltages, and here is the output.",
                    "label": 0
                },
                {
                    "sent": "An initially.",
                    "label": 0
                },
                {
                    "sent": "We tell the network you should spike here, here, here, here.",
                    "label": 0
                },
                {
                    "sent": "It doesn't do it, but over the course of training you can get it to give you exactly this pattern of spikes.",
                    "label": 0
                },
                {
                    "sent": "So it is in fact possible to do training with a hidden layer with spikes, but I'll let Syria tell you a little bit more about that.",
                    "label": 0
                },
                {
                    "sent": "So what I'd like.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To move to, so I'll just say item three.",
                    "label": 0
                },
                {
                    "sent": "Yes, we can do back prop with precise spike trains.",
                    "label": 0
                },
                {
                    "sent": "And it's it's actually quite an elegant solution, I think.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So I want to get to the 4th issue which is so near and dear to my heart and will maybe be more novel for for some of you.",
                    "label": 0
                },
                {
                    "sent": "So as I mentioned, the 4th issue is this issue of doing forwards and backwards passes to do back prop in a neural network.",
                    "label": 0
                },
                {
                    "sent": "The idea is that you need to do an initial forward pass through the network Calculator error back, propagate that error and that forward pass needs to be kind of clean as it were, it shouldn't be incorporating feedback at the moment of the forward pass, it should be just communicating whatever the feedforward weights are calculating on the input.",
                    "label": 0
                },
                {
                    "sent": "But our own brains don't seem to exhibit this sort of forward pass backward pass nonsense.",
                    "label": 0
                },
                {
                    "sent": "They're just kind of chattering away.",
                    "label": 0
                },
                {
                    "sent": "And there's all these feedback connections, so presumably for your neurons in, say, primary visual cortex, they will always be receiving feedback from higher order regions anyway.",
                    "label": 0
                },
                {
                    "sent": "And then you left with the question, if well, how can you actually do some of these calculations, given that they all assume that you had a forward pass initially to figure out how the networks transforming your input.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Well, what's interesting is that in the neocortex, and this comes back to your question about, you know it can't know what's a feedback synapse and what's not.",
                    "label": 0
                },
                {
                    "sent": "What's interesting is that the brain actually does treat feedback synapses differently from bottom up synapses.",
                    "label": 0
                },
                {
                    "sent": "So in your neocortex, which again is the region of the brain that we're interested in here.",
                    "label": 0
                },
                {
                    "sent": "The majority of the cells are a particular type of cell known as a pyramidal neuron, which is illustrated on the left here.",
                    "label": 0
                },
                {
                    "sent": "They're called pyramidal neurons because the cell body, which is here is shaped a bit like a pyramid, but really the entire thing resembles big tree more accurately.",
                    "label": 0
                },
                {
                    "sent": "So what's interesting about this structure is basically so these pyramidal neurons will have their cell body deeper in your neocortex, and they have a whole host of dendritic branches that come out around the cell body that are known as the basal dendrites, and they're kind of like the roots.",
                    "label": 0
                },
                {
                    "sent": "Of a tree.",
                    "label": 0
                },
                {
                    "sent": "And then they send up one unique dendrite called the apical shaft.",
                    "label": 0
                },
                {
                    "sent": "Which goes up up up, whoops, sorry.",
                    "label": 0
                },
                {
                    "sent": "This is the frustrating thing about not using a pointer is on here.",
                    "label": 0
                },
                {
                    "sent": "I don't laptop.",
                    "label": 0
                },
                {
                    "sent": "You can move your slides.",
                    "label": 0
                },
                {
                    "sent": "It goes up up, up towards the surface of the brain and then so that's kind of like the trunk of your tree.",
                    "label": 0
                },
                {
                    "sent": "And then as it approaches the surface of the brain, it branches again, just like the branches of a big tree and those those upper branches are known as the apical dendrites.",
                    "label": 0
                },
                {
                    "sent": "Now, the reason I'm telling you about this structure is what's interesting is that anatomical work has shown that, generally speaking, you know nothing is a hard and fast rule in biology, but generally speaking.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The apical dendrites are receiving top down feedback from higher order regions of the brain, whereas the basal dendrites are receiving bottom up.",
                    "label": 0
                },
                {
                    "sent": "Sensory information coming in from your eyes, your skin, your nose, etc.",
                    "label": 0
                },
                {
                    "sent": "So the neurons in the neocortex actually spatially segregate.",
                    "label": 0
                },
                {
                    "sent": "The bottom up and the top down connections to the neurons.",
                    "label": 1
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "This segregation of the inputs is.",
                    "label": 1
                },
                {
                    "sent": "Particularly weird when you first look at it because of how far the apical dendrites are from the cell body.",
                    "label": 0
                },
                {
                    "sent": "So like when I first saw this structure, I just kind of 'cause I had originally been trained in AI, and then I went into neuroscience.",
                    "label": 0
                },
                {
                    "sent": "And when I first saw this structure, I just kind of registered in my brain as well.",
                    "label": 0
                },
                {
                    "sent": "That's weird, but it got we.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Later, when I learned about the work of Matthew Larcom.",
                    "label": 0
                },
                {
                    "sent": "So Matthew Larcom did throughout the late 2000s these heroic experiments where he would record from different parts of the apical dendrites in these pyramidal neurons.",
                    "label": 1
                },
                {
                    "sent": "So this is an illustration of some of the experiments that he ran.",
                    "label": 0
                },
                {
                    "sent": "He's got a electrode that he's recording the voltage in the dendrite from at this point in the apical dendrite, just at the start of the apical shaft.",
                    "label": 0
                },
                {
                    "sent": "And then he's got another electrode illustrated in red here, up at one of the higher branches in these apical dendrites.",
                    "label": 1
                },
                {
                    "sent": "And then he puffs sucrose onto this upper branch, which causes electrical activity in the branch.",
                    "label": 0
                },
                {
                    "sent": "Now what you're looking at here, these are the traces of the membrane potential of the voltage that was recorded by those two different electrodes during this experiment.",
                    "label": 0
                },
                {
                    "sent": "So we can see the response to the sucrose on the red trace.",
                    "label": 0
                },
                {
                    "sent": "All these little like bumps up this is it zoomed in.",
                    "label": 0
                },
                {
                    "sent": "All these little bumps up.",
                    "label": 0
                },
                {
                    "sent": "Excuse me are excitatory postsynaptic potentials they are the dendrite responding to that sucrose.",
                    "label": 0
                },
                {
                    "sent": "But notice that on the blue electrode, not a lot's happening.",
                    "label": 0
                },
                {
                    "sent": "That is because the distance along that cable.",
                    "label": 1
                },
                {
                    "sent": "So you can think of these dendrites as being like electrical cables.",
                    "label": 0
                },
                {
                    "sent": "They have actually a fairly high resistance along them and it is not trivial for current to travel down those cables, and in fact what Matthews result shows is that by the time the current gets down to that apical trunk.",
                    "label": 0
                },
                {
                    "sent": "It's basically gone, or at least it's severely attenuated.",
                    "label": 0
                },
                {
                    "sent": "So this is actually a plot of four different distances along the dendrite.",
                    "label": 0
                },
                {
                    "sent": "How much was the initial input to the dendrite attenuated?",
                    "label": 0
                },
                {
                    "sent": "And what you can see is that by the time you get like a 400 micro meter distance, which if you look at, here's the scale bar so you can see this entire thing is like a millimetre long out of 400 micro meter distance you basically out of 40.",
                    "label": 0
                },
                {
                    "sent": "40% to 1040 times attenuation of your EPS P. Now that's really weird, because like I said, the top down signals are coming into these apical dendrites, so the neuron, so one of the other things for those of you who aren't by all, don't have a biology background that I should mention is the activity of the neuron.",
                    "label": 0
                },
                {
                    "sent": "The spikes are ultimately driven by the Axon hillock, which is just off the cell body here.",
                    "label": 0
                },
                {
                    "sent": "So that means that the site on the neuron where the activity is being generated, the activity that's going to be transmitted to the rest of the network.",
                    "label": 0
                },
                {
                    "sent": "Is so far from the dendrites, where the top down feedback arrives that the top down feedback would in fact not be altering the activity of the neuron in most circumstances.",
                    "label": 0
                },
                {
                    "sent": "Which is very seems a very strange thing to do.",
                    "label": 0
                },
                {
                    "sent": "WHI would you have top down feedback that's not driving the cell?",
                    "label": 0
                },
                {
                    "sent": "Well, Interestingly, what Matthew then showed in and.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Other set of experiments is that the top down feedback can drive the cell, but only in these discrete moments driven by nonlinear events called plateau potentials.",
                    "label": 0
                },
                {
                    "sent": "So this is a similar experimental setup.",
                    "label": 0
                },
                {
                    "sent": "He's got a red electrode in the higher apical dendrites here.",
                    "label": 1
                },
                {
                    "sent": "A blue electrode on the shaft and then he's got a third electrode on the cell body and we've got four different recordings showing the voltage recorded on those different electrodes.",
                    "label": 0
                },
                {
                    "sent": "Where it's color coded for the specific electrodes.",
                    "label": 0
                },
                {
                    "sent": "Now so.",
                    "label": 0
                },
                {
                    "sent": "What you can see here in B is that when he provides a stimulation to the red electrode, you get a response on the red electrode.",
                    "label": 0
                },
                {
                    "sent": "And almost nothing on the blue electrode an nothing at all on the black electrode because it's not propagating.",
                    "label": 0
                },
                {
                    "sent": "You can ignore C for a second.",
                    "label": 0
                },
                {
                    "sent": "That's there for the neuroscience audience for a specific reason.",
                    "label": 0
                },
                {
                    "sent": "But what's interesting is D&E here.",
                    "label": 0
                },
                {
                    "sent": "So what he showed is that if you get sufficient activation of the apical trunk here.",
                    "label": 0
                },
                {
                    "sent": "Either because you're injecting current at the cell body at the same time, or you just inject enough current into the red guy, you get this huge nonlinear event in the apical dendrites.",
                    "label": 1
                },
                {
                    "sent": "It's kind of like a spike in fact, except it last longer, and for those of you who care about this kind of stuff, it's actually driven by voltage gated calcium channels rather than sodium channels.",
                    "label": 0
                },
                {
                    "sent": "But here, on the red and blue traces we see this big nonlinear event, and these are called plateau potentials because they last for this long period of time.",
                    "label": 0
                },
                {
                    "sent": "And what's interesting is these plateau potentials can then drive bursts of spikes at the cell body.",
                    "label": 0
                },
                {
                    "sent": "At the Axon hillock.",
                    "label": 0
                },
                {
                    "sent": "And that means that it is possible for the top down feedback to drive activity here, but only when there is sufficient topdown activity to activate this nonlinear function.",
                    "label": 0
                },
                {
                    "sent": "And what that means effectively is that most of the time the cell is going to be in feedforward mode.",
                    "label": 1
                },
                {
                    "sent": "It will be receiving inputs to its basal dendrites.",
                    "label": 0
                },
                {
                    "sent": "Which it can then oops excuse me which it can then communicate to other neurons.",
                    "label": 0
                },
                {
                    "sent": "But occasionally it will respond to feedback when the feedback successfully triggers one of these nonlinear actions, yeah.",
                    "label": 0
                },
                {
                    "sent": "This attenuation thing happening also fairly outgoing.",
                    "label": 0
                },
                {
                    "sent": "No, so axons do not suffer from this attenuation issue because they are in fact designed by evolution, not too so they are rich with nonlinear voltage gated channels that help to regenerate the currents as they travel through the Axon.",
                    "label": 0
                },
                {
                    "sent": "That's right, and that's what that's what happens with these nonlinear events here as well.",
                    "label": 0
                },
                {
                    "sent": "Now so.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "My lab got interested in this because we said, well if that's the case, if you've got this situation where most of the time the neurons are effectively in a feedforward mode, and then sometimes they receive this nonlinear signal from the top down system, maybe you could basically do back prop without having explicit forward passes and backwards passes, just instead by incorporating this segregation that exists in the actual dendrites.",
                    "label": 0
                },
                {
                    "sent": "So we built this kind of simplified model of pyramidal neurons.",
                    "label": 0
                },
                {
                    "sent": "My student Jordan who's here an together with Tim Lillicrap.",
                    "label": 0
                },
                {
                    "sent": "Where we had neurons that are now no longer the point neurons that we use usually in artificial neural networks, but instead are neurons with three compartments.",
                    "label": 0
                },
                {
                    "sent": "A basal dendrite compartment that's receiving feedforward inputs and apical dendrite compartment that's receiving feedback inputs Anecelle body that's responsible for generating spikes.",
                    "label": 0
                },
                {
                    "sent": "And what we did is based on Matthew Larcom's data.",
                    "label": 0
                },
                {
                    "sent": "We had it that the cell body is largely responding to the inputs to the basal dendrites.",
                    "label": 0
                },
                {
                    "sent": "Most of the time.",
                    "label": 0
                },
                {
                    "sent": "Which you can see here.",
                    "label": 0
                },
                {
                    "sent": "So this is the voltage in the cell body.",
                    "label": 0
                },
                {
                    "sent": "Is the voltage in the basal dendrites, and here's the voltage in the apical dendrite and most of the time, the cell body is ignoring what's happening in the apical dendrite.",
                    "label": 1
                },
                {
                    "sent": "But occasionally the apical dendrite can trigger nonlinear plateau potential, which we then just take as the average of the voltage over the past 30 seconds.",
                    "label": 0
                },
                {
                    "sent": "30 sorry, 30 milliseconds for the apical dendrite and that can then get communicated to the rest of the cell.",
                    "label": 0
                },
                {
                    "sent": "And so.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So what we do is.",
                    "label": 0
                },
                {
                    "sent": "Kind of similar to equilibrium propagation, but nowhere as elegant.",
                    "label": 0
                },
                {
                    "sent": "We have a forward phase where there is no feedback from the environment and the network just runs.",
                    "label": 0
                },
                {
                    "sent": "We presented with an image.",
                    "label": 0
                },
                {
                    "sent": "An activity propagates through the network.",
                    "label": 0
                },
                {
                    "sent": "And then a plateau potential occurs.",
                    "label": 0
                },
                {
                    "sent": "One of these nonlinear events where the feedback is actually transmitted to the rest of the neurons.",
                    "label": 0
                },
                {
                    "sent": "Then we engage in a phase where we have some external pressure that's nudging the system towards the correct answer.",
                    "label": 0
                },
                {
                    "sent": "And excuse me.",
                    "label": 0
                },
                {
                    "sent": "An we allow activity to propagate through the network both upwards and backwards, except of course again the backwards flow is effectively cut off because of the segregation of the apical dendrite.",
                    "label": 0
                },
                {
                    "sent": "And then we generated another plateau potential.",
                    "label": 0
                },
                {
                    "sent": "And what we do is we update our weights using the difference between these two plateau potentials, which is affectively a way of doing feedback alignment.",
                    "label": 1
                },
                {
                    "sent": "In fact, because we use random weights for our backwards weights here.",
                    "label": 1
                },
                {
                    "sent": "And by taking the difference between these two plateau potentials, then we are we have a system which is going to learn to do backpropagation in fact.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So you can see that here.",
                    "label": 0
                },
                {
                    "sent": "So we just tested the basic result first.",
                    "label": 0
                },
                {
                    "sent": "That kind of like with feedback alignment.",
                    "label": 0
                },
                {
                    "sent": "We wanted to see that if we added hidden layers to this network, we got improved performance.",
                    "label": 0
                },
                {
                    "sent": "So this is classification on amnist.",
                    "label": 0
                },
                {
                    "sent": "Obviously these actual numbers suck, so I call it deep learning light.",
                    "label": 0
                },
                {
                    "sent": "But 'cause we're running biophysical simulation with voltages and stuff and getting those numbers doing the parameter search to get those numbers down as.",
                    "label": 0
                },
                {
                    "sent": "Tricky, we've got some initial some more data showing that those can get better, but the important point is that as we add hidden layers to the network, it does seem to get better.",
                    "label": 0
                },
                {
                    "sent": "Though as Joshua mentioned, for as with feedback alignment, we find that there are diminishing returns.",
                    "label": 0
                },
                {
                    "sent": "You can't just create ever deeper networks.",
                    "label": 0
                },
                {
                    "sent": "But the more important principle here is that we're doing this without explicit forward and backwards passes.",
                    "label": 0
                },
                {
                    "sent": "The entire system is just allowed to kind of chatter at itself in whatever direction, and the way that we're implementing an effective forward pass is by using that segregation of the apical dendrite, which is something that we actually see in the real neocortex.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is just a demonstration that we're getting that same basic feedback alignment effect.",
                    "label": 0
                },
                {
                    "sent": "So this is the angle between what our algorithm asks for and what backpropagation asks for overtraining epox.",
                    "label": 0
                },
                {
                    "sent": "If we send back the actual voltages through the backward connections, we get really good agreement between them.",
                    "label": 0
                },
                {
                    "sent": "If we use the spikes, we get better than orthogonal, but not perfect, but nonetheless in a very high dimensional space, that's still roughly the same direction.",
                    "label": 0
                },
                {
                    "sent": "And so if you look at the receptive fields that are generated by our learning rule, that's just using these plateau potentials to learn an what backpropagation learns.",
                    "label": 0
                },
                {
                    "sent": "So these are receptive fields in the hidden layer of the network.",
                    "label": 0
                },
                {
                    "sent": "You see very similar features pop out, so it seems to be learning something very similar, but again done without an explicit forward and backwards pass.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now.",
                    "label": 0
                },
                {
                    "sent": "One of the issues with our model though is that we are using these rather artificial plateau potentials, and it's not clear that.",
                    "label": 0
                },
                {
                    "sent": "That's actually something that would be used by the neurons.",
                    "label": 0
                },
                {
                    "sent": "What we should really be incorporating?",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is.",
                    "label": 0
                },
                {
                    "sent": "These bursts of action potentials that Matthew Larcom recorded because that's what's going to ultimately drive activity throughout all the dendrites in the cell and what's really going to be the key to communicating it to other neurons in the system as well for doing properly deep learning.",
                    "label": 0
                },
                {
                    "sent": "So what I wanted to show you in the very.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Hospet before I just take some questions is.",
                    "label": 0
                },
                {
                    "sent": "There are some exciting results out from Richard Nodes Lab at the University of Ottawa.",
                    "label": 0
                },
                {
                    "sent": "Unfortunately, this is unpublished.",
                    "label": 0
                },
                {
                    "sent": "It'll be up on archive at some point soon, so I just recommend looking up now and specular if you're interested in this in a month or so.",
                    "label": 0
                },
                {
                    "sent": "So what they did is they ran some biophysical simulations of pyramidal neurons.",
                    "label": 0
                },
                {
                    "sent": "So these are these are simulations of pyramidal neurons with asamaan that long apical dendrite.",
                    "label": 0
                },
                {
                    "sent": "I was telling you about.",
                    "label": 0
                },
                {
                    "sent": "And they fit their biophysical simulations to actual experimental data.",
                    "label": 0
                },
                {
                    "sent": "And then they looked at what the?",
                    "label": 0
                },
                {
                    "sent": "Cells activity is communicating whether it's communicating top down signals to the apical dendrite or whether it's commuting bottom up signals to the dendrites around the soma.",
                    "label": 0
                },
                {
                    "sent": "What they do in particular though, which is very interesting, is they.",
                    "label": 0
                },
                {
                    "sent": "Basically just look at the number of events, so here you can see a spike and here you can see a burst and they treat both bursts and spikes as just an event.",
                    "label": 0
                },
                {
                    "sent": "And then they look at both the rate of events and the probability that a Bearss.",
                    "label": 0
                },
                {
                    "sent": "Sorry that an event is a burst.",
                    "label": 0
                },
                {
                    "sent": "And what's interesting is that if you look at so here they are providing a decreasing current to the dendrite to the apical dendrite and an increasing current to the soma.",
                    "label": 0
                },
                {
                    "sent": "And what you see is that the event rate is a function, so that is the rate at which both burst send spikes occur is a function of the input.",
                    "label": 1
                },
                {
                    "sent": "The bottom up input to the soma.",
                    "label": 0
                },
                {
                    "sent": "Whereas the probability that an event is a burst is a function of the topdown input to the dendrites.",
                    "label": 0
                },
                {
                    "sent": "And if you do this same thing, so you provide two different currents overtime.",
                    "label": 0
                },
                {
                    "sent": "We see this same result Pop out here.",
                    "label": 0
                },
                {
                    "sent": "So if you just count the rate of spiking in these neurons, you don't see much of anything.",
                    "label": 0
                },
                {
                    "sent": "But if you look at the event rate, you see the bottom up input to the soma, and if you look at the burst probability you see the top down input to the dendritic inputs.",
                    "label": 0
                },
                {
                    "sent": "Sorry to the apical dendrites.",
                    "label": 0
                },
                {
                    "sent": "And that's very exciting, because what that means is that pyramidal neurons.",
                    "label": 0
                },
                {
                    "sent": "Are effectively multiplexing their top down and bottom up signals constantly, so the neurons in your brain have two different signals, one that communicates the bottom up information that's coming from your sensory systems, and another signal that communicates the top down information that's coming from the higher order regions of the neocortex.",
                    "label": 1
                },
                {
                    "sent": "And theoretically these two different signals could then be used to do something like backpropagation without having to have separate forward and backwards passes.",
                    "label": 0
                },
                {
                    "sent": "Because the entire system is actually keeping those two streams of information separately as it travels through the network.",
                    "label": 0
                },
                {
                    "sent": "So what's also interesting.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But this is we see that there are subtypes of neurons in the neocortex.",
                    "label": 0
                },
                {
                    "sent": "That have synapses that respond to bursts quite differently.",
                    "label": 0
                },
                {
                    "sent": "So some neurons have what are called short term depressing synapses, which means that they don't actually respond to burst differently than spikes, because when the first action potential occurs, the synapses depress rapidly, and so they don't respond to the subsequent spikes.",
                    "label": 0
                },
                {
                    "sent": "And there are other synapses called short term facilitating synapses which don't really respond much to the first spike, but respond very well if you get multiple spikes in a row via burst.",
                    "label": 0
                },
                {
                    "sent": "And so what's interesting about that is we see that there are different types of neurons in the neocortex, and I don't have time to go through the different types.",
                    "label": 0
                },
                {
                    "sent": "I'll just tell you that there are two different types of neurons in neocortex.",
                    "label": 0
                },
                {
                    "sent": "That have short term depressing synapses and short term facilitating synopses.",
                    "label": 0
                },
                {
                    "sent": "And that means that theoretically, we've got two different pools of neurons, one that is explicitly listening to the bottom up signals and one that is explicitly listening to the top down signals.",
                    "label": 0
                },
                {
                    "sent": "And again, that would allow the system to engage in a backpropagation like calculation without separate forward and backwards passes, which I think is a very exciting result and potentially the key to understanding how some of this unfolds.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So to summarize.",
                    "label": 0
                },
                {
                    "sent": "Item number 4 doesn't seem to be an issue either, because your brain actually seems to be designed specifically to do simultaneous forward and backwards passes and to carry that information with different signals.",
                    "label": 0
                },
                {
                    "sent": "So it's in fact very plausable that you could do learning without these separate passes.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So to end off here, I began this talk by identifying the kind of issues with this equation and the things that made neuro scientists very sceptical for a long time that we could do deep learning in the brain.",
                    "label": 0
                },
                {
                    "sent": "But over the last two years, we've kind of seen how you can systematically just pull apart each one of these, and it turns out that they're not.",
                    "label": 0
                },
                {
                    "sent": "None of them are a big issue now.",
                    "label": 0
                },
                {
                    "sent": "There are other issues that are going to rise, whether it be the delay time constants or questions of how you do recurrence.",
                    "label": 0
                },
                {
                    "sent": "And I'll get to that in one second, but at the end of the day, I think they're all going to be surmountable.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Of course, the final remaining one, which I just mentioned, the elephant in the room for us, is back prop through time by Prop.",
                    "label": 0
                },
                {
                    "sent": "Through time is really, really critical for training recurrent neural networks, but doing backdrop through time in a biologically realistic way is pretty difficult.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So of course, the way back property time works right is if we have are currently connected set of neurons, we unroll the neurons through time such that we treat early time points as being like the initial layers of a neural network and later time points as being the higher layers.",
                    "label": 0
                },
                {
                    "sent": "And then you just run back, prop through it as if you had a standard stock neural network.",
                    "label": 0
                },
                {
                    "sent": "That's great for training and neural network, but if you're going to try to do this in a biologically realistic fashion, you have to somehow have a record across time of the activity patterns in the inputs at each time point, and you have to have those all time stamped and matched up with each other.",
                    "label": 0
                },
                {
                    "sent": "And we just have no way of seeing how the brain can do that.",
                    "label": 0
                },
                {
                    "sent": "Right now I have some ideas about how this might work, but I'll leave that for another time and maybe for you guys to resolve in your work.",
                    "label": 0
                },
                {
                    "sent": "If you work in this area.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "What I will say is this though.",
                    "label": 0
                },
                {
                    "sent": "To finish off, there's a very good reason that deep learning is taken over AI, and that is that it works.",
                    "label": 1
                },
                {
                    "sent": "And the reasons that it works apply equally.",
                    "label": 0
                },
                {
                    "sent": "To our own brains, that is to say that if you're going to try to optimize a huge number of parameters so you're working in a very high dimensional space and you're trying to optimize some cost function, doing gradient descent or stochastic gradient descent is a really good way of solving that problem, and it seems very likely.",
                    "label": 0
                },
                {
                    "sent": "I would argue because we don't really know of another good way to do that, right like to my knowledge, no one's ever demonstrated an equally powerful mechanism.",
                    "label": 0
                },
                {
                    "sent": "For learning in these high dimensional spaces, it seems entirely likely that our brains.",
                    "label": 0
                },
                {
                    "sent": "Did through the course of you know evolution, settle appana similar solution?",
                    "label": 0
                },
                {
                    "sent": "Something like stochastic gradient descent?",
                    "label": 0
                },
                {
                    "sent": "And I think that until neuro scientists are able to articulate an alternative way of learning these high dimensional spaces, we have to take very seriously the idea that our brains are doing something like backdrop.",
                    "label": 0
                },
                {
                    "sent": "And that's particularly true because as we saw the old objections don't hold water anymore, and I suspect that the additional objections that are going to be raised will not hold water for very long either.",
                    "label": 0
                },
                {
                    "sent": "I.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And so the last, very last thing I'll leave you with is the following kind of wacky thought, and this is an absurd bit of bullshit on my part, but.",
                    "label": 1
                },
                {
                    "sent": "Whatever, it's fun.",
                    "label": 0
                },
                {
                    "sent": "Let's say for a second that our brains are doing gradient descent, and let's say that we were able as neuro scientists to identify where those signals are.",
                    "label": 1
                },
                {
                    "sent": "If they are the top down signals into the apical dendrite that are guiding the like telling the neurons about the gradient or something like that.",
                    "label": 0
                },
                {
                    "sent": "Theoretically, if we could get a sufficiently good neural prosthesis such that we could actually tap into these signals that are communicating the gradient to the neurons.",
                    "label": 0
                },
                {
                    "sent": "You could have a system where you have an external cost function in some neural network and you back prop through that system and into the brain.",
                    "label": 0
                },
                {
                    "sent": "OK, that's very scary, yes.",
                    "label": 0
                },
                {
                    "sent": "And so then you could have a truly seamless AI brain interface where you actually update your brain in order to maximize the cost functions of your external prostheses.",
                    "label": 0
                },
                {
                    "sent": "Which.",
                    "label": 0
                },
                {
                    "sent": "Updates.",
                    "label": 0
                },
                {
                    "sent": "That's what I'm saying.",
                    "label": 0
                },
                {
                    "sent": "I think it should.",
                    "label": 0
                },
                {
                    "sent": "Yes exactly, you want to be able to send back the signals to the neurons that tell them what the gradient is of that external cost function.",
                    "label": 0
                },
                {
                    "sent": "And that will guide them in their synaptic weight updates.",
                    "label": 0
                },
                {
                    "sent": "Yes, just doing it.",
                    "label": 0
                },
                {
                    "sent": "That's right, we're doing it through very slow channel.",
                    "label": 0
                },
                {
                    "sent": "That's right.",
                    "label": 0
                },
                {
                    "sent": "So the other thing is though, you're sort of doing it insofar as there, you still have to construct the cost function internally for yourself, right?",
                    "label": 0
                },
                {
                    "sent": "Like you have that cost function by virtue of your internal goals with your phone.",
                    "label": 1
                },
                {
                    "sent": "But if you had a system where you could literally take any cost function and propagate that back through the brain.",
                    "label": 0
                },
                {
                    "sent": "It wouldn't have to be the things that you're explicitly interested in.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "Yeah, I was working at DARPA.",
                    "label": 0
                },
                {
                    "sent": "Not, not really, don't.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Anyway, that's that I'm sorry we only have a couple of minutes for questions, but thank you very much.",
                    "label": 0
                }
            ]
        }
    }
}