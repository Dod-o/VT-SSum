{
    "id": "xb7lms35wem6drnw33l7elrcsvdgglyz",
    "title": "Linked Data and APIs",
    "info": {
        "author": [
            "G\u00fcnter Ladwig, Institute of Applied Informatics and Formal Description Methods (AIFB), Karlsruhe Institute of Technology (KIT)"
        ],
        "published": "Dec. 23, 2011",
        "recorded": "December 2011",
        "category": [
            "Top->Computer Science->Semantic Web"
        ]
    },
    "url": "http://videolectures.net/coinplanetdataschool2011_ladwig_data/",
    "segmentation": [
        [
            "OK, so welcome everybody to my talk.",
            "I'm first going to introduce as you already set a short introduction on Planet data.",
            "Plan data is a European project.",
            "It's a network of excellent project which is funded in the 7th Framework Programme and Network of Excellence.",
            "Projects are different from usual research projects because they may name is here to establish a European Community, and in this case for planet data about.",
            "It's about large scale data management.",
            "And so the research is not the main focus, but mainly establishing a community and able enabling other organizations other people to perform research on this topic.",
            "So the main objectives of training data are first.",
            "There is also, of course the research part.",
            "And then there are this planet Data Lab which which contains a list of tools and best practices for working with large scale data.",
            "And there's also.",
            "The goal of disseminating and training other people in this topic.",
            "Why, for example, workshops or things like this winter school here and finally, the network of Excellence project also has its own calls for which are called planet data programs, where other organizations can apply for funding to perform projects in this area of data management."
        ],
        [
            "Is a short overview of the work plan highlight, so there are a few topics that are addressed.",
            "In fact, in planet data.",
            "First our stream lagged data quality assessment of interlinked datasets, provenance and access control.",
            "Plan data also tries to publish datasets and vocabularies, including best practices for how to work or work with the state and how to publish data.",
            "And as already mentioned, there's a summer school which is a yearly summer school which is colocated with the extended Semantic Web conference and also these blended data programs."
        ],
        [
            "OK, so now I get through my tutorial and this is the first part of a two part tutorial which I will which with my colleague Stephen stuff."
        ],
        [
            "And in the 1st.",
            "Sorry tough.",
            "OK, so as I already said, this tutorial in two parts, the first part.",
            "The first part is the bottling data, which I'm going to talk about in this first session and the second part is about link data linked APIs, which definitely going to talk about in the outline of my talk is I'm first going to introduce link data.",
            "What it is about.",
            "Present the main link data principles which underlie this new paradigm of publishing data on the web, and then I'm going giving some best practices and some more information on how to publish and access link data."
        ],
        [
            "OK, so the web today is mainly of documents.",
            "You have this.",
            "We have many many millions of documents which are interlinked.",
            "We're we're these documents I HTML documents usually and these are interlinked.",
            "We hyperlink so everybody knows this by now this was invented at the beginning of the 90s by Tim Berners Lee and by using by having this interlinked structure you are able to discover new content by following links."
        ],
        [
            "However, many of these pages, or these homepage is actually driven by data.",
            "So basically almost all websites have some database behind them which actually stores structured data.",
            "So for example, if you have a home page here on the left hand side, this is from the German railway, where you can look up train connections and basically when you enter something in the form then it accesses the database and from this generates HTML document.",
            "But each of these websites has their own database which are not interlinked so.",
            "One website has one database and the other website is another database, and the only links between them are maybe we are HTML, we're hypertext links in the HTML document and this."
        ],
        [
            "Through what we call data silos.",
            "So basically we have all this data available on the web, but it's in Silo, so these are datasets that for websites are not interconnected and we can easily make sense or of it's not easily possible to combine data from more than from multiple datasets, so each each data is the data silo and there's no connection between them."
        ],
        [
            "And the web of data.",
            "And this is what link data is also about is.",
            "Aims to change that.",
            "So here we have we try to link data instead of documents.",
            "And.",
            "Published published the data in Machine readable format.",
            "So becauses HTML documents are not easily understandable.",
            "I understand this may be the correct word but did not easily possible by.",
            "By computers or machines, and So what we try to do here and link data is to publish data in a machine readable format.",
            "And basically we have.",
            "Now we want we want to have is we have datasets and these are interconnected via links instead of documents and so basically this means that the web is the web short work or should be accessible as a database."
        ],
        [
            "So the motivation behind this is that with the increased use of computers over the last decades, more and more data is being stored.",
            "So there's basically the data volumes are kind of exploding.",
            "This are increasing exponentially, and many organizations rely on data for business decisions.",
            "Governments rely on them for policy decisions, and also every end user basically relies on data that is available in the web for doing many, many things like finding train connections.",
            "Or finding a cinema where if you want to watch a movie.",
            "So, and to facilitate access to this or the integration of these datasets, we in linked data we use semantic web technologies.",
            "I'm going to go into more detail later on, and the main promise behind this link data is that we want to combine data from multiple data from multiple sources to gain new insights.",
            "So basically we have multiple datasets and we try to find new information by combining these.",
            "So for example, I don't know if you have some kind of data set.",
            "About criminal statistics, and you have a data set about.",
            "I don't know how prices and then you can for example correlate this data and and find out if the criminal criminality has an affect on health prices in a certain area.",
            "Things like that.",
            "Anne."
        ],
        [
            "To this end, Tim Berners Lee, a few years ago, proposed the link data principles.",
            "There's this, Tim Berners Lee was the original inventor of the World Wide Web.",
            "And there's this Ted talk.",
            "I mean, I don't know if you're aware of Ted talks, but these are kind of visionary talks that happen at a few conferences year, and these are always very informative and he has this Ted talk about link data principle.",
            "So if you want to watch that, I recommended and.",
            "He proposed.",
            "Falling data principles, which is the first part of the what I'm going to talk about and why are these linked data principles?",
            "A lot of bad data has been published in the last few years."
        ],
        [
            "So what you see here is it's the state of the linked or the web of data in 2007 few years ago, and each of these nodes in this graph is a separate data set.",
            "So for example, we have the data set, DB pedia, or Geo names, and the edges between them between the datasets stand for links between the datasets and so."
        ],
        [
            "To consider over."
        ],
        [
            "Time that this web of data."
        ],
        [
            "Grown."
        ],
        [
            "Very much so."
        ],
        [
            "So for example, we."
        ],
        [
            "Now."
        ],
        [
            "In 2000"
        ],
        [
            "11 and they're basically hundreds of datasets available as linked data, and all these are interlinked."
        ],
        [
            "And what kind of data is actually published here?",
            "This is like, I guess from last year, so a large part of this data is government data which are which is published by government agencies.",
            "For example in the United Kingdom there's this initiative called data.gov.uk and which tries to which publishes data that is generated or created by by government agencies.",
            "For example, these crime statistics.",
            "This would be one example for this, but there are also other kinds of datasets.",
            "For example geographic datasets.",
            "This contains informations.",
            "Things like that that Berlin is located in Germany and that Germany bought us Poland and other countries and these kind of geographical information is contained in these datasets.",
            "There also life science datasets which for example contain information about proteins, genes or diseases or drugs, but they are also cross domain data sets which contain data, not about a single domain but for.",
            "The larger"
        ],
        [
            "Super domains and one of one example for this is a DB pedia data set which is actually linked data version of Wikipedia.",
            "I mean, you're all aware of Wikipedia and what DB pedia does.",
            "Is it automatically extract structured, structured data from Wikipedia?",
            "So Wikipedia is mainly text, but deep down in an automatic fashion extract structured information.",
            "So for example, if you're probably aware of this because on many many Wikipedia pages you have these infoboxes on the right hand side.",
            "So for example, if you have I don't know.",
            "Four players in each football player has a hazardous info box with information about this name is age, the teams he played at, how many goals scored, and whatever, and this is kind of structured information in contrast to text, which is natural language.",
            "These are.",
            "We have this information like I don't know.",
            "Messy Squad One 200 goals or whatever and he played at Barcelona and what DPI does it takes this information and it automatically extracts and.",
            "Published this is linked data in a structured way, so basically we have now a database of facts extracted from Wikipedia and you can run queries on them.",
            "And did Peter actually is kind of an interlinking hop in the linked Data Web Justice, Wikipedia is often for the normal web because a lot of other datasets linked to DB pedia and so that you can find connections between other datasets via by going through DB pedia.",
            "I will show later how this actually in works."
        ],
        [
            "Another use case, falling data is a BBC music website.",
            "So this.",
            "BBC Music website contains data about programs that BBC has on the radio, for example and, but also about artists, songs and basically background information in this website is actually a combination of BBC internal data, which are the playlists that which songs are played in the radio but also other datasets which are actually linked data datasets.",
            "For example Musicbrainz which contains information about artists and albums or Wikipedia which also contains.",
            "Artists about information about artists and these datasets underlies this BBC music website.",
            "So basically they have added value on the on the home page or on the website by using linked open data datasets, and they also publish their own data via link data principles so that other people can use them.",
            "So for example, if you want to look up Marlena Dietrich.",
            "In the BBC music data set, you can go to this UI and it will give you more information about money indeed."
        ],
        [
            "This.",
            "Another project of that you Link data assist virtual International Authority file which is a joint project between national libraries in related organizations.",
            "So many libraries have kind of a data catalog about authors and books they have written, and each currently each each National Library used to have their own catalog and this virtual international authority file is basically an integrated view on all these available data and they also use link data principles.",
            "To perform or to link between this virtual international authority file and the data that is available at."
        ],
        [
            "National libraries.",
            "And lot of what underlies this link data are semantic technologies, semantic semantic web technologies are standardized by the workload Web consortium.",
            "The World Wide Web Consortium for Maine.",
            "Standardizing organization for the World Wide Web and a lot of these.",
            "The technologies have been around for a few years, for example RDF, which is the main.",
            "Main data model falling data has been around for, I guess since 1999 and link data is actually only a subset of the semantic for semantic web stack.",
            "And I'm going to.",
            "Talk about all of these things so RDF and Sparkle and Link data also uses HTTP, which is a hypertext transfer protocol which is also used for websites and so basically I'll now if there are any questions until here."
        ],
        [
            "Then I go to the link data principles.",
            "Just."
        ],
        [
            "OK, so there are four link data principles.",
            "I'm going to talk about each one in turn, but in short the first link data principle is to use your eyes as names for things.",
            "The second principle is that we should use HTP your eyes.",
            "And the third principle is that when we, when somebody looks up such a UI, then we should return provide useful information.",
            "And in the case of data this means usually RDF, which is a data model and the 4th principle is that we should include links to other UI so that people can you discover new content."
        ],
        [
            "OK, so the first principle is you I use your."
        ],
        [
            "Just names for things.",
            "So basically, if in any scenario where you have to have data and you want to make some you want to describe things, then you have to identify these things.",
            "In relational databases you often have.",
            "I don't know some ideas in a table, but the problem here is that these are not unique globally unique.",
            "So basically you have one database and they're the ones might stand for some.",
            "Entity like Melina Dietrich, but in another database vid one might send for just some other person or even some completely different thing.",
            "So what we try to do here in the link data principles is that we use your eyes as a globally unique identifier for entities.",
            "So for example for the German philosopher Georg Wilhelm Friedrich, we have this UI from DB Pedia.",
            "Or we might also have your eye from a different data set from this virtual authority file."
        ],
        [
            "And by this is an illustration of this concept.",
            "So we basically want to give everything a unique name so that we can make assertions about this data and talk.",
            "And when we try to describe things and talk about things, we exactly we know exactly which which concrete thing we mean."
        ],
        [
            "So the second principle is to use HTTP UIS."
        ],
        [
            "And by using HTTP we basically enable.",
            "Look up on this UI, so HTTP is the main protocol that is used on the on the web for serving websites.",
            "Web servers have are readily available for serving data or for serving data using the HTTP protocol.",
            "And this actually uses the Domain Name System to ensure the uniqueness of identifiers, because on the web, when you have a domain, you're uniquely identified because there's a mapping from the name to the physical location, which is IP address basically of that computer or of that domain.",
            "And also by using HTTP UI so we can use the established HTTP infrastructure, so there's no additional new infrastructure has to be established for working with linked data.",
            "And what this what the use of HTTP your eyes does is basically it connects the logical level which is the thing we want to talk about the entity.",
            "For example, a person with the physical level which is the source for the data that describes that entity.",
            "So this is in.",
            "This is an important distinction where we distinguish between the thing or which is also called the thing you are I for example or non information resource.",
            "So for example this would be Melina Dietrich and we distinguish this from the from the source of the document that actually describes this person, which we then call information resource or thought the source UI."
        ],
        [
            "So how do you actually look like?",
            "And you probably have seen these few.",
            "Anyway, when you use a browser, but."
        ],
        [
            "The first part of the protocol, which in Link data cases, usually HTTP.",
            "The second part is the host name."
        ],
        [
            "And then we called of the first.",
            "Everything up to the last slash, the namespace.",
            "And whatever is written behind that the local name.",
            "So basically we have the namespace here is deep.org/resource and the local name is India which is an entity described in the namespace of DPD.",
            "Basically, and what I'm going to use here in the.",
            "Talk a lot as a kind of a shorthand short for writing such a rise, and these are written.",
            "There's a prefix DB pedia, which Maps to the namespace.",
            "So basically there's a.",
            "There are many popularly loose use prefixes and this map to the namespace so that we can write DB pedia: India instead of the whole UI.",
            "So this just makes it kind of shorter and easier to read for humans."
        ],
        [
            "So I come back to this distinction between information resource and non information resource.",
            "So.",
            "Here is the problem here is that, for example, if you have Marlene Dietrich and the person, so this is a non information resource or thing.",
            "But we also and we have a document which contains data about Marlena Dietrich.",
            "For example.",
            "I don't know her age and her birthplace and whatever, and now we have the we wouldn't make this distinction between the non information resource or the thing and the source then we couldn't say for example.",
            "We couldn't provide information about the source.",
            "For example, it might be interesting to know when the source of the data document that describes the entity was created by whom it was created, but license it has, and so we have to make this distinction between the thing and the source so that we can make statements about the thing.",
            "For example, the name or the age of Marlene Dietrich.",
            "And on the other hand we can make statements about the source, for example by whom the data was created or when it was created.",
            "But copywriter tests.",
            "So this is the main rationale, or the main reason for."
        ],
        [
            "Making this distinction.",
            "There actually are two ways on how to order two mainly used ways on how to make this distinction.",
            "So first we establish this correspondence between the thing you are in the source UI by using hash URS.",
            "So maybe I've seen this in HTTP your eye services.",
            "That you can at hash at the end of the UI.",
            "So in this example it's the hash artist, and we now use because this is actually part of the HTTP standard.",
            "When browser you looks up this UI, it actually does not send the hash part to the web server, but only the part before that, and So what we do here is when we will look up this UI with the hash part which identifies Marlene Dietrich.",
            "Then we perform a look up on this UI, and this is the content returned from the web server.",
            "And so basically we distinguish between the thing and the source.",
            "Why using this hash at the end of the UI?",
            "So the things have a hashtag at the end of the UI and the sources don't."
        ],
        [
            "And you can see this is an example request for actually for the description or the link data UI for Tim Berners Lee, which is there at the top.",
            "As you can see that it has a hash at the end hash and I and now the get request is performed by the HTTP client.",
            "And actually, what it also does here it HTTPS HTTP standard allows to specify which kind of content you want to get back here.",
            "Browsers usually say they want to have.",
            "HTML documents, but in this case we actually say that we want to have RDF data and we perform this get request on the you can see here and there.",
            "You see at the MD Hash tag is missing and then the server responds with the HTTP code 200, which means everything is fine basically and it also returns data with this content type that we requested.",
            "So basically this is the way of how we can look up data on the web of data for entities for single entity."
        ],
        [
            "There's actually another way to establish this correspondence between the thing in the source UI and in this case.",
            "This is done via HTTP redirect, so the HTTP protocol allows for redirect with.",
            "Basically, when you look up particular UI, then the server response.",
            "Please look at some other UI and this is a 303 status code which we call this 3303 redirects.",
            "And what happens here is we perform this look up on the DB pedia UI for Linda Dietrich with peter.org/resources/melinadietrich.",
            "And then the server first response with the 303 and redirects to.",
            "For example, if you requested RDF data to this UI, or if we requested HTML data, redirect to a different UI and basically both of these contain the same data but in different formats from the HTML document is meant for human users to understand, and the RDF data is basically used for.",
            "Computers to understand and actually can show you how this works.",
            "I just switched to so you can see here is.",
            "When I enter.",
            "So this is a UI for cuts or the city in Germany where Institute is located, and when I now open this page then actually you can see at the top then DP to its now DVP dogs list page search culture culture which is the HTML representation and now we have all the facts which are stored in DB pedia about carpool for that kind of control down there's an abstract.",
            "And for example there's the area code or the country Castle is located in which is Germany.",
            "And I can also click on these links.",
            "To navigate to different sources, for example to Germany, I think the page is quite large, so it takes a while.",
            "Yeah, and now we look at the entity or the information about Germany that start in DB pedia which is in this case data extracted from Wikipedia.",
            "But in a structured way.",
            "Now because we have all these different attributes and they have values.",
            "For example the population density of Germany is 228 people per square meter probably.",
            "Kate."
        ],
        [
            "Artist.",
            "OK, so some best practices for for UI schemes, so you should only when you publish data.",
            "You should of course only using data files within your own namespace, because you actually can control this namespace about having a web server that listens on this on the domain name.",
            "You should use mint or crisp and short UI switch.",
            "Out mentioning the underlying technology.",
            "For example, this DB pedia UI for cards with much nicer than the 1 one after that, because it's very long.",
            "It contains support, name and things like that are not very usable or easily understandable for human users.",
            "It's also very important to keep your eye stable overtime, 'cause obviously people easier for people other people to find the UI's if they are valid over a longer period of time.",
            "And because of this correspondence I just talked about between the thing and the source, you either usually three UI's that are related to a given resource.",
            "We have first identifier for the resource.",
            "Then we have an identifier for the related to be source or the document describing the data.",
            "For for meant for users, so typically in HTML and we have an UI for the document that describes the resource in a machine readable format, usually in RDF."
        ],
        [
            "OK, so.",
            "Now come to the third.",
            "Link data principle which which says to provide useful information."
        ],
        [
            "So the link to principle says when when somebody looks up to you, I so performs an HTTP get.",
            "Requests on this UI, then the server should return useful data using standards.",
            "In this case this usually means RDF.",
            "RDF stands for Resource Description Framework and this is a format for encoding craft structured data."
        ],
        [
            "An the RDF is basically a directed and labeled graph.",
            "So you can see this here.",
            "We have this.",
            "We have one so called triple which the subject and predicate in an object and this means that DPW is here the subject.",
            "The predicate is capital, and the object with Germany basically what this cess or the statement says is that Berlin is the capital of Germany.",
            "And there are also other not just connections between entities, but RDF also supports attribute values which are called literals in RDF.",
            "So basically this means that for Germany the label or the common name for Germany for the entity Germany is Deutschland in German.",
            "But you can also provide other languages which are which are denoted with this tech at the end here, and it's a Germany in English and in this case Germany is a subject for this triple, but it's the object for this trip here.",
            "So basically what we have here is this directed labeled graph and actually you can model almost for example, relational data can be modeled as graph for example.",
            "Basically, this subsumes the relational model that is used in traditional relational databases.",
            "So maybe you could convert any any data that is available as XML, for example, or also as relational data, into RDF.",
            "There may be multiple formats for serializing RDF, RDF, XML is the most widely diploid serialization, but I'll"
        ],
        [
            "In this talk we are mainly going and Stephen authors mainly going to use Turtle, and here's an example for an RDF document about India.",
            "So basically this is the data returned when you look up India and DB Pedia.",
            "And and again, you have this at the start.",
            "You have some defined prefixes that I was already talking about and below that is the actual RDF data, again organized in a trip away.",
            "So subject predicate object and this first trip, for example, says that the pages of type countries are basically DB pedia is a country and the second trip again uses this RDF label to say that the entity India has an English name, India."
        ],
        [
            "And what because RDF?",
            "Some RDF is a graph.",
            "Structure is a graph and they have unique identifiers because we use you guys as identifiers for nodes and edges or predicates.",
            "And these are globally unique.",
            "So what this means that we have?",
            "We have two RDF graphs and in this case I don't know if you can see this, But this UI is the same as the one up there on the left hand side.",
            "So if we want to merge these RDF graphs, there's basically nothing we have to do because we can just put them together and be cause the USR globally unique.",
            "We get a merge graph like this, so this is a very simple way when when we have two datasets that are in RDF and they use.",
            "Unique your eyes then it's very easy to put them together because we can just throw them together and we've done basically."
        ],
        [
            "M. So.",
            "Um?",
            "As I. I thought we already saw there are some some properties that are kind of predefined.",
            "For example this type property and these are part of RDF vocabulary, so basically.",
            "Vocabulary defines the term Thor classes that can be used when describing things or entities and for you.",
            "Therefore, for describing these vocabulary sets of so called RDF schema standard, which specifies classes and properties to describe vocabularies.",
            "So for example we have this.",
            "There are multiple classes so that we can talk about other classes or properties, and there are also some predefined properties.",
            "For example RDF type.",
            "We saw which gives type to an entity or audiences label, which is used to denote or give the common name as a literal of an entity.",
            "So many of those are many predefined vocabulary are available, and actually most of these vocabulary vocabularies also conform to link data principle.",
            "So this was what this means is that when you have such a vocabulary terms such as RDF type, you can because this expense to a UI complete your eye with the prefix and then you can perform a look up on this UI and get more information.",
            "About this vocabulary term.",
            "So basically the vocabularies are self descriptive, you don't have, you don't need another specification which says what the vocabulary is about because the name or the name of the term of the UI and this is enough to get more information about this vocabulary."
        ],
        [
            "I'm so when you when you try to publish link data using, you have to use vocabularies and if possible you should reuse existing terms because they're also already a lot of predefined vocabularies and you can find these terms by, for example, asking experts.",
            "Of course looking at examples or there also.",
            "Specialized search indexes for discovering vocabularies.",
            "So for example to just to give an example of vocabulary set available.",
            "For example, the friend of a friend vocabulary is used to describe people it has.",
            "Property for saying someone knows somebody else or what the homepage of someone is or the email address where he works or she works and there are other other available vocabularies.",
            "For example the Dublin Core defines general meta data attributes for example like.",
            "Create a title of documents and things like that.",
            "So basically there's already a lot of work that has been done on defining these vocabularies, and it's possible you should reuse them."
        ],
        [
            "OK, so the 4th principle is to link to other UI's."
        ],
        [
            "So in the same way, for as we use links for HTML documents to discover new related content by clicking on links on webpages, these links to.",
            "These links to other UI's in linked data and the web of data enable people and machines to jump from server to server and discover new related data.",
            "We can distinguish here between external links and internal links, so internal links are links in the same namespace.",
            "So for example, if one DB pedia entity India links to another DP entity for the President or the Leader of India and External links link between datasets."
        ],
        [
            "And in this example I showed before there already some links to other entities.",
            "For example, we have this property leader name for India which gives the leader of India which and this links to another DB pedia entity.",
            "But there also this is also a special predefined property called over the same S which says that this entity is the same as this one which is from the Opencyc project.",
            "And Additionally there for example also linked to the New York Times data set, and basically this makes an assertion that DB pedia India is the same entity as this one in another namespace.",
            "So that when you get this information you can save that you can aggregate information from multiple sources and you know by wire this link that these actually talk about the same resources but they are different data because it's from different publishers.",
            "But in this way the data integration becomes very easy because when we have this explicit links.",
            "We can easily aggregate the data from multiple datasets."
        ],
        [
            "So how do we interlink resources and resources?",
            "We have explicit interlinking by simply reusing your eyes from other datasets.",
            "We can you establish equivalence where this, say mathlink.",
            "But there are also other property project properties such as this 4th North, which is from the friend of a friend to vocabulary already talked about, which says that somebody's know somebody else.",
            "And how do we establish these links?",
            "So of course it's possible to do this manually, but this can be a very itchy.",
            "Pensive tough because there are millions of entities and then you have to look at millions of entities and try to find links between them.",
            "But Fortunately there are also tools or that perform this in an automatic or semi automatic fashion.",
            "These are of course not perfect because these will usually create links first, not find all links or create links that are incorrect.",
            "But this could basically our first step and then the user can be fine whatever the output of these tools are is.",
            "So another best practice is to.",
            "For data publishers to get external links so when you publish a data set then basically it's at first nobody knows about it because you just put it on some web server.",
            "And I mean this is the same problem when you have a web page and then nobody finds it because there are no links from other web pages.",
            "Or in this case other datasets.",
            "So data publishers should try to get external links from other datasets by talking to the publishers and asking them to add links to their datasets and is also helpful to use established datasets such as deep jazz interlinking hub so.",
            "If two datasets linked to DB pedia then be basically also have the connection between the datasets."
        ],
        [
            "End to to find related efforts as this comprehensive knowledge archive networks he can, which is a list or an archive of linked open data, not only linked open data, but in general datasets are published on the web, and then you can search for topics and they have text for datasets which enables you to find data for out ever use case.",
            "You have an.",
            "You can also add your own data set there to make it available or to have other people find it."
        ],
        [
            "OK, so this is the first part.",
            "About the link data principles.",
            "So in summary, what are the benefits of link data?",
            "First we have an explicit simple data representation.",
            "We have a common data format in RDF.",
            "This is very helpful because.",
            "In a lot of cases, people will use their own proprietary format.",
            "I don't know in a relation database or in an XML and these are not easily integratable, so usable at the same time.",
            "And by by having everybody use a common data format which uses unique, globally unique identifiers, we are one step further and on the way to integrated or a web of data.",
            "The web of data is also completely distributed system that is decentralized becausw.",
            "Everybody is able to publish their own datasets and the controls only his own data set.",
            "But it is also cross referencing and allows for linking to other datasets.",
            "Of course, because it's decentralized system, this does not guarantee referential integrity, so this May's on the web, but it can happen that.",
            "Links go to become invalid and this is when you get an HTTP 404 error, for example, but this is the price.",
            "Basically you pay for having a decentralized system.",
            "It is a loose coupling, so this is again the refresher integrity, which is not guaranteed.",
            "But as we see if this makes it actually easier to for people to publish their data because they can just put the data out there and then wait for other people to discover it or put links there.",
            "And this is the overhead costs for publishing data is much lower in this case and as we can see and this was actually one of the main one factor in.",
            "Why the web became so popular?",
            "Because it's so easy to put data out there and then link it later or improve the layer the data incrementally."
        ],
        [
            "Just skip this."
        ],
        [
            "So, of course, but Linklater has also challenges.",
            "First, there's a ramp up cost for data conversion, so if your data is not available in RDF, then first you have to convert it to RDF to publish it, and this can be a significant cost depending on whatever data format your or whatever form your data is stored in.",
            "But there are tools that help you with this.",
            "For example, there are seemingly automatic tools for finding mappings between relational databases in RDF.",
            "And this provide your support for doing this conversion.",
            "Integrated data may also be messy at first because anybody can put data put out there, and there's no guarantee about the quality of the data.",
            "But on the other hand, the data can then be refined as the need arises and the distributed creation also may lead to inconsistencies.",
            "For example, if you are some two people, make the same statement about, for example, the age of Marlena Dietrich, and one says she is this age and the other says she's a different edge, then you have an inconsistent.",
            "Because you have two different values for the same property for the same entity, but this kind of inconsistencies can be detected and diagnosed and then fixed with appropriate tools.",
            "But of course this also means that when you consume link data, because as in the same way that when you consume Wikipedia, you have to be aware of the fact that it might not be completely true in all cases, or there might be."
        ],
        [
            "Sensitive.",
            "And to to address some of these problems.",
            "This so called pedantic Web Group which is a community group which actually actively contact publishers about errors and issues in their datasets.",
            "An they already have fixed or already several errors in populated for fixed after having been contacted by this pedantic web group."
        ],
        [
            "OK, so are there questions for the first path of link data principles?",
            "OK. OK so yeah.",
            "So you partially answered my question, but I'll ask again.",
            "How do you collect the garbage data and so get rid of it?",
            "Well, I mean, for example, for this inconsistency when you have multiple values, just simple example for the same property for certain definitely set.",
            "You can detect these tools for this and then you actually have to contact the data publishers and say look something is wrong here and they have to manually fix.",
            "Their own data, so this is the way becausw.",
            "Publishers are independent entities and so this is more of a social.",
            "Effort so that you have to talk to people.",
            "There's no, no, unfortunately not yet.",
            "I mean, this is of course research topics.",
            "No automatic way to fix these errors.",
            "OK, so in the next part will talk about how I give some tips and tricks and by spectus is about publishing data and mainly about converting legacy data."
        ],
        [
            "Into linked data.",
            "So the problem here is of course that large amounts of data already managed for in relational databases, for example, or many other web datasets are already published as Jason APIs or is published as XML or CSV.",
            "So, separated value files and.",
            "So in order to publish this, this data is RDF works link data.",
            "There are two steps you have to do.",
            "First, this ontology modeling.",
            "So you have to decide how your data is going to be represented as RDF.",
            "And as already set, you can reuse existing vocabularies, but in many cases you have to also add your own vocabulary which suits your data.",
            "And in the second step that you can then.",
            "Create mappings between your data and whatever formative and RDF data, and then you have.",
            "With these mappings can protest be expressed in procedural language?",
            "So just you know, by programming in Java, for example, or they're also declarative languages which define these mappings, and then when you have these mappings between your data in one format and audio RDF data, then you can automatically convert the data from one representation into the other.",
            "And."
        ],
        [
            "So when you have text documents, it is possible to link text to data and this is called.",
            "The process is called named entity recognition and text documents and what this does it establish links between text and structured description of entities that are mentioned in the text.",
            "So for example, one tool that does is Wiki Fire tool which links entities that appear in texts to Wikipedia articles and thereby also 2D PDF for example.",
            "So when you have this this text ASAP acquire Sybase.",
            "Or 5.8 billion dollars, but why?",
            "And then when you run this through named entity Recognition tool then you get for entities that are named or used in this text you get links to structure or to structure descriptions of of this the office entity.",
            "So for example for ASAP you get the link which for example links to DB pedia.",
            "And for Sybase you get also linked to DB Pedia and in this way you have established a link between text documents.",
            "And structured data because text documents are unstructured data.",
            "This is natural language and this is not really easily easily usable for four machines because they have a hard time understanding natural language."
        ],
        [
            "Another way of converting your data is a once off data conversion, for example that you can convert spreadsheet data, which is an excellent two RDF using whatever programming programming language do like.",
            "Or for XML.",
            "You can also use.",
            "The style sheets are transforming stylesheets to converter artific smell.",
            "And what you have to do here is of course also provide you eyes for four entities."
        ],
        [
            "And if you already have data set on API for your data set which is accessible via HTTP protocol, for example which returns Jason or XML, then it's possible to write wrappers around this which then convert this data from Jason or from XML on the fly to RDF.",
            "And actually, it's definitely we'll talk about this more in the next session."
        ],
        [
            "And at the last thing I'm going to talk about in this part is that they are actually one.",
            "I guess there are multiple tools, but one of them is the D2R server for expressing mappings between relational databases in RDF.",
            "So when you have your data stored in a relational database, some SQL Server I don't know.",
            "For example my SQL and then you can define mappings between using relational database and whatever RDF representation you chose an express.",
            "This in these detour mappings.",
            "And then, but due to a server does it provides an interface that Link data interface for your database, so any requests that comes in from for example HTML browsers or Sparkle clients, Parker is a query language for RDF and this is on the fly translated into SQL.",
            "This is sent to the relational database and the answers again translated into RDF.",
            "So basically for the client C is suggested link data server, but on the back end the data is still stored in RDF and whatever use you have for the data there for your.",
            "For your business, you can still keep on using your database as you were before, but this is just on the fly conversion, which makes the data also available as RDF."
        ],
        [
            "OK, so.",
            "Yeah, there are some icons missing this.",
            "This should be start on the left hand side so there's this concept of five star data which basically says describes or should describe the quality of a data set.",
            "So to get one star basically.",
            "I mean there's no authority that gives out the stars, but the notion that one star you get for making data available on the web in whatever format but with an open license, so this is crucial for this open licenses so that anybody can use this data.",
            "And you get two stars for publishing the data in the machine readable format.",
            "And a structured data, for example Excel.",
            "Instead of scanning and image scan of a table and you get three stars by using a non proprietary format.",
            "So this is for example XML instead of CSV.",
            "And Additionally, if you open standard from the such as RDF and Sparkle, you get another star and if you link your data to other datasets you get 5 stars.",
            "Thank God who defined that.",
            "Um?",
            "They say your eyes is also from the I think from the World Wide Web Consortium, but it's I mean it's not really.",
            "There's no authority that look the datasets and give them.",
            "I actually, I'm not sure, but it's not really.",
            "It's kind of you.",
            "Can you put your stuff on there on your own?",
            "I mean if you lie then you could lie, but you know you're not supposed to."
        ],
        [
            "OK, so and in the final part of the tutorial I'm now I will talk about how we can access link data and how to run queries on linked data so that we can make sense of the data that is published."
        ],
        [
            "OK, so basically we already know of one way to access link data which I already showed you.",
            "You can just perform an HTTP look up on the UI.",
            "And just for example, is a is a tool.",
            "It's called tabulator, which basically be able you can enter your eye and it retrieves the link data and then presents it in a nicer format.",
            "For example.",
            "And of course this might be enough for some applications.",
            "So for example for this BBC music website, when you just want to provide background information about entities you're looking at, then simple link data lookups might be enough.",
            "But now that we have the data in a structured formatted mine, we actually want to execute queries so.",
            "And how do we do that?"
        ],
        [
            "For RDF, the main query language is Parker, which you can think of SQL for RDF.",
            "I hope you're aware of SQL.",
            "Which scares the query language that has been around for decades now.",
            "I think since the 80s or whatever for relational database and basically what's Parker does is the query language for RDF for RDF graph.",
            "So whereas careless about relations, Parker is about graph, so this syntax is somewhat similar because you have also in some cases is select from where syntax we have where you specify first whatever variables you want to retrieve from where you want to retrieve them, and then we're contains conditions about the data that you want to retrieve, but actually sparkle supports more than one query type part from selected also describes, supports, asked, describe and construct queries.",
            "And I'm now going to show you to give an introduction only of two of these groups, namely select and construct queries.",
            "So sparklers based on graph patterns cause what we want to query our graph so that we're on the other hand, the query language or has also has to support graph of course."
        ],
        [
            "And the basic graph pattern is a basic building block of Parker queries.",
            "Basic graph pattern.",
            "So this is basic graph pattern.",
            "It's surrounded by these parenthesis and it's a conjunction of."
        ],
        [
            "Triple patterns so true pattern is basically a triple.",
            "We already saw those perform in the RDF example where we had DB pedia, India type country and we now have triple patterns.",
            "Basically the same thing as a triple where the subject, predicate and object are replaced by variables.",
            "For example, variable X and such a triple pattern as the first one.",
            "Here basically matches all triplets where the predicates RDF type and the object is.",
            "DB Pedia over the country and any subject.",
            "So and then.",
            "Basically the result of these of matching this triple pattern against the graph are bindings for 4X.",
            "So basically all triples where the subject appears subject appears together with these predicates and objects."
        ],
        [
            "And I'm OK. As I said, the Accessor is a variable and then we call the other the other positions where we have no variables are constant."
        ],
        [
            "And the basic graph pattern is a conjunction of triple patterns.",
            "So this means that here the both variables refer actually to the same.",
            "Same note in the pattern Graph and this means that here we have to perform a joint.",
            "Oh.",
            "I'm get the results."
        ],
        [
            "So we can also visualize these basic graph pattern.",
            "Its graph as we already saw in RDF data.",
            "Before that, and again we have one variable.",
            "X has an edge to country with a label or with the name RDF type and an RDF label edged predicate to to the variable Y. I thought you want to have a more formal definition on what constitutes.",
            "Result for such a graph pattern is that Beijing graph pattern matches a subgraph of the RDF data.",
            "When the IDF terms from their sub graph may be substituted for the variables and the resulting RDF graph is equivalent.",
            "To the sub graph that contains that was a match."
        ],
        [
            "I mean, this is more.",
            "I'll be this more become become more clear.",
            "Example on the next slide.",
            "So the first query type I'm talking about we talk about is the select queries, which is which are analog to the select queries in SQL.",
            "Select curious look like this you have selected then a list of variables and the where clause.",
            "There is a basic graph pattern.",
            "And the result is a table of bindings for the selected for the variables that appear in."
        ],
        [
            "Select clause so for example we have here some data.",
            "These are just.",
            "You know, six triples where we have say triplets that say India is a country and has this name and the same for Germany and for France.",
            "And we have this example query where we have two select query to select variables and one basic graph pattern.",
            "And what the query engine now does.",
            "It basically matches these.",
            "This this basic graph pattern two to the RDF data to the RDF graph, and then the result is a table where we have for each for both variables.",
            "Findings that are created by matching the basic graph pattern to the RDF data.",
            "So what we can see here is that we have two results, so the 1st result is a binding of DP to index BP to India to X and India to Y.",
            "This comes from the 1st.",
            "It's the same for Germany from the 2nd, and actually this does not generate a match because in here in this case is a different product reduced which does not match.",
            "This label, which is the condition in the in the basic graph pattern.",
            "So This is why the first pattern matches.",
            "But because this is conjunction, which means that both of these, both of these two parents have to match the same time, which is why no result is generated from the last two triples."
        ],
        [
            "OK, so the second query type is a construct queries and these also have basic graph pattern in the where clause.",
            "But the differences in the result of the data of the query.",
            "So about the contracts construct, reduce it to create a new graph.",
            "For for this you have such a template basic graph pattern which contains a subset or even all variables from the graph pattern in the where clause and basically the result of a concept reason you RDF graph where.",
            "The bindings for the variables are substituted in the variable for in the template."
        ],
        [
            "So again, we have.",
            "On an example, we now have the where clause is the same as before, and we can assume the same data as before, so this about Germany, India in France.",
            "But we now have a construct query where we have a template which also uses the variables X&Y.",
            "But in this case the template is different because it assigns a different.",
            "Object for the type pattern and it uses fourth name instead of RDF label, triple pattern and so basically what the career engineer does, is it?",
            "First finds all the bindings for the variables.",
            "This is the same as before and then it takes the template.",
            "And then substitute the bindings for the variables in the template so that for this result we get this RDF graph, so this is again in RDF graph, not not a table, and we can all see here that DPR indexer binding.",
            "Forex was substituted in both.",
            "In both patterns for X and the binding for Y was substituted in the second triple pattern for the object.",
            "Variable Y, which appears as the object.",
            "So in this way basically we can create new RDF graph based on the results of a query and in a similar fashion.",
            "This happened for the 2nd result where Germany and the entity Germany and the literal Germany are substituted for X&Y.",
            "So basically for each.",
            "Reside in this table.",
            "We get a separate RDF graph as an output of this of this construct query."
        ],
        [
            "So this was just a short introduction to spark and Spark actually supports way more than just the basic graph patterns.",
            "It has optional patterns so that not all patterns have to match to create a result.",
            "It has filter conditions.",
            "So in this example query you see that we can filter on the literal here and say that we only want results where the language of the literal.",
            "We have this language taxes English.",
            "You can also order on attributes.",
            "You can say limit and offset the same as in SQL.",
            "We can say you only you only want the ten 1st result.",
            "And I'm.",
            "Many things more, and so if you want to, there's this sparkle by example document which is quite nice.",
            "And also this is the sparkling new Sparkle 1.1 standard if you want to actually look at the grammar."
        ],
        [
            "OK, so now that we have this query language, how do we actually execute this over linked data?",
            "Because Link data start on some web server somewhere and I am here on my PC and then I want to execute a sparkle query and so how do I do that for for execute increase over linked data there are two main architectures that we can distinguish.",
            "The first is the warehousing architecture.",
            "And in this case we first download whatever data we interested in and start in the database on our local computer on our local network for example.",
            "So and then we can execute queries on this local database and get the results back and then find out where we wanted in the 1st place.",
            "But on the other hand, the other architecture is that if you don't want to use a local database, we have to perform some kind of virtual integration and distributed querying where we.",
            "The way we try to directly query that it's linked data link data that is stored at remote servers and I'm now going to.",
            "Present both of these architectures and show what the disadvantages advantages of these architectures are."
        ],
        [
            "For the first in the warehousing architecture, we first have to download all the data we interested in and start in local database.",
            "So this is possible.",
            "For example, as many datasets actually provide RDF dump.",
            "So one file that contains all the data that they published, not in a single GPU ice, but in one are huge RDF file which you can download and then store in your local database.",
            "This is possible for some datasets.",
            "For example, DB PEDIA provides such an RDF dump.",
            "But not all datasets do so, or all data publishers do so, and what you can then do is otherwise you have to crawling data by following links.",
            "So this is basically the same as web crawler.",
            "So for example when Google wants to build this search indexer, has this crawler or spider which starts with a certain predefined set of HTML pages and then follows links to discover all web pages and incrementally increases the search space.",
            "And basically in this way hopefully discovers all the pages that there on the Internet.",
            "And you can do the same thing funding data because we have these links.",
            "I was talking about all the time before between between data entities and you can crawl link data in the same way by following links and downloading whatever content there is behind these.",
            "HTP you eyes.",
            "And when you do this, you can start in local database and then execute queries on them on the data.",
            "The thought of food store this data.",
            "There are so called triple stars becaused this we have RDF triples and these are purpose built databases for storage and retrieval of RDF and for example for retrieval you can use sparkle and there are.",
            "This are quite quite mature technology.",
            "There are open source systems available for doing this or even commercial systems.",
            "The advantage of using such a warehousing on materialization strategy architecture is that you are in control.",
            "You don't depend on third parties for providing.",
            "Access to linked data because you start in your local database and this also usually means that the performance is better because it starts.",
            "You don't have to go over the Internet or network access to execute queries and it's locally starting your own database and you can put whatever hardware you have or whatever hardware you like behind it and then the performance is usually better.",
            "But on the other hand, of course you have an operating cost for the hardware for the software, for the maintenance, and this is an overhead.",
            "Of course, and also the data that you have stored locally might not always be up to date, because link data can in some cases change very rapidly daily, hourly or even in minutes.",
            "An in this case you only have what you're curious, honest, whatever you download it at some point.",
            "So either you have to download new data all the time, or you are operating on data that is out of date.",
            "So this depends on the use case.",
            "Whatever you have if you can.",
            "If you need up-to-date data, then maybe warehousing is not the best strategy.",
            "But if you're fine with operating on all data on outdated data, then the warehousing strategy architecture might might be suitable."
        ],
        [
            "So on the other hand, on the other end of the spectrum, basically is this virtual integration of distributed querying architectures, and I will talk about two of them here.",
            "The first is the Spark Endpoint Federation.",
            "A lot of data publishers on which publishing data also provides Barker endpoints.",
            "So basically triple stores that can be reached.",
            "Also, we are HTTP and you can execute queries, sparkle queries on them.",
            "So this these queries and will run on the hardware that the data publishers provides and you just get the result spectrum and.",
            "In the end point, Federation of the Mediator basically provides an integrated view on multiple of the sparkle endpoints an but on the other hand, not all of the data sets are available spark endpoints, and for this we have this link data query processing techniques which have been proposed in the in the last few years and academic community and what here the query engine does not talk to spark endpoints or to other databases but directly uses HTTPS.",
            "So link data look up to retrieve data and then process it is.",
            "To answer queries that are posed by the user."
        ],
        [
            "So I already mentioned many of the datasets.",
            "Actually I think it was about 65% of the datasets Office park endpoint, so these are basically triple stores.",
            "The data publisher with the data publisher stores there whatever data they published and they provide an endpoint that anybody can use.",
            "You can send Sparkle Cruiser and get relayed spec for free.",
            "This is quite amazing actually that people are willing to do this, but on the other hand is also means that these are sometimes unreliable, so this might go down at some point you can't.",
            "Can't often rely on these endpoints, or the quality varies.",
            "Some endpoints are very stable and other endpoints might not be, and also in some cases you have because these are for free, you have query limits, or you can only return a certain number of results or come very complex queries are not supported, for example.",
            "So this is what you have to keep in mind if you want to use Spark endpoints so that this might be unreliable and things like that."
        ],
        [
            "So what the Federation is about that is that this mediator which sits on your local machine, it provides a virtual integration of remote data sources.",
            "So no data is actually stored locally.",
            "But whenever you send a query to this mediator, for example this one which asks about presidents.",
            "And the party which the president belongs to and actually tries to find more information about this entity from the New York Times data set, which is linked via same S link and know when we have for example, 2 two sources for this DB pedia and the New York Times data set.",
            "No data set here is able to answer the complete query.",
            "So the 1st two triple patterns might appear in the first data set in the second last two triple patterns might appear in the New York Times data set.",
            "So when we then send the whole query to each of the spark endpoints, we get no results because none of the endpoints contain data that can answer the query.",
            "So what the mediator does, it splits a career in two parts and send these to the spark endpoints and then recombines the results it gets from the.",
            "From the endpoints.",
            "To provide query answers."
        ],
        [
            "For this is a list of some of these Federation systems that are available and for example, one of these systems which is called FedEx, which was just published at the International Semantic Web Conference a few months ago, and you can see here that the process is as follows.",
            "You get a sparkle request and it first passes the query and then it performs source selection.",
            "Source selection means that which tries to find out which endpoints that knows about can answer which part of the query.",
            "And then performs global optimizations and then execute the query by splitting it and sending it to the spark endpoints that were selected.",
            "And then we combined the results to present.",
            "Finally result of the user.",
            "There's also an open source implementation which you can just use as you wish."
        ],
        [
            "So on the other hand, there's link data processing, link data, group processing techniques, and these work directly over linked data, so there are no spark endpoints.",
            "But what the query engine does, it retrieves link data sources during query execution while performing HTTP.",
            "Look up just as presented during the.",
            "During the link data principles in the first part of the talk, but also basically all the crew processing other than retrieving the data is done locally and here the source discovery and selection is crucial.",
            "Selection is basically the same cause As for the spark endpoints, But the problem is that we have many, many more sources in this case, because each HTTP UI is a possible source, you know there's no single endpoint for the whole data set, but the data set consists of millions of entities possibly, and also millions of sources.",
            "The.",
            "The advantage of this approach is of course it's always up to date 'cause just in this.",
            "In this bucket Finepoint Federation, because you directly use link data and knows locally stored copy, you always use the most up-to-date of whatever the data publisher has published.",
            "And in addition, this does not rely on Spark endpoints, but basically means that any link data that is or any data that is published.",
            "This link data can be queried in this way even if the publisher does not provide a spark endpoint.",
            "I mean many do, but.",
            "Some of them are like 30% of them don't provide this back end point and by using LINQ data query processing implementations, you can actually access also this data which is not in a sparkle endpoint.",
            "I'm on the on the other side.",
            "Link data query processing is usually.",
            "Fairly slow becauses you have always to retrieve you.",
            "Always retrieve a source in as a whole.",
            "Yeah, so there's no way to say I want only the data from this HTTP UI that matches a particular part of my query.",
            "So this means that you retrieve much more data.",
            "And then also the high number of possible sources and overhead because you have to contact them and get unsuspecting, which again increases or decreases performance and increases query time and the source discovery and selection process is actually more complex.",
            "And for sparkling points."
        ],
        [
            "I'm.",
            "So this is just an overview of the current research in this topic, 'cause this is what I do when I don't give tutorials at winter schools and so the sources xcovery and there are two main techniques for doing the sources cover the sources, carries a process of finding sources that are relevant for for your, for your query.",
            "So first there's a possibility of a ramp runtime discovery which takes advantage of the links that are available in the linked data Web so.",
            "When you when you start at one source and you have have links to other sources and then the query engine can follow these links and thereby discover new sources and download them and process the data in them to answer queries and this of course relies on the links because when the links are not there then this engine or this type of engine will not find answers to the query and on the other hand you have the possibility of using a source index which is a precomputed index of sources.",
            "So basically you have to 1st download all the sources that you are interested in first.",
            "And these are index which then map triple patterns or parts of your query to relevant sources.",
            "And this is similar to.",
            "It's not quite the same as away as expected, but first to build a source index you have first quality data link data, for example, and.",
            "The next step is sensa selection or South ranking, because they're usually too many sources to process of a single query.",
            "There might be hundreds of thousand sources that match or contain possibly relevant data, and so you have to decide which of these sources are actually really relevant in the sense that they will produce final results.",
            "And.",
            "When you have a source index is a bit easier because you know more about the know more about the content in these sources and then you can rank the sources by the number of expected results.",
            "When you process that source.",
            "And there's also the possibility to refine the ranking at runtime.",
            "So when some sources have been retrieved, you have more a better idea about the data that matches the query and then can refine your ranking and decide on the fly which sources you want to retrieve and 3rd consideration when doing data.",
            "Reprocessing is with the career processing itself so because your perform network access this might lead to blocking because you have to wait for an answer from the server and what you don't want to do is basically wait for single server and store the whole query execution process.",
            "But contact multiple servers in parallel and there are few techniques for doing this so that the results that are available can be produced early and that slow servers don't block the whole query execution."
        ],
        [
            "So before coming to the summary, I'm just going to show you an example of a SPARQL endpoint.",
            "Um?",
            "So this is an HTML interface or formula interface for this back end point of DB pedia.",
            "And I have prepared some query.",
            "So this is basically the query from the example that we used.",
            "And this again gets the label of all entities set off the type country.",
            "And when I now click on run query I get this table.",
            "So I get bindings for X&Y and becaused.",
            "Peter provides identifiers in multiple languages, I get multiple results for a single entity.",
            "So for example Falkland Islands, I get the name in Germany, cycling in zone and in English.",
            "If Falkland Islands for example.",
            "So this is a spark endpoints.",
            "Repeat, it provides and you can just run queries on them and thereby use or make sense of the data that is stored in DB pedia.",
            "And just to show you the.",
            "The different capability of is already off.",
            "Barker already set there.",
            "Are these filter conditions.",
            "And here we have.",
            "We have a filter which says that all bindings for variable Y should be of the half language English.",
            "And now we get the same result, but only the English literals.",
            "For example, to go of the English name in its total.",
            "So as you can see, the you know executing this park and points available is quite easy and this enables you to easily use datasets or that are available on the web.",
            "OK, so in summary, for accessing data sparkle is the query language of choice.",
            "For RDF it performs graph pattern matching.",
            "There are several query types.",
            "I talked about the select and construct queries sparkle at its core is about triple patterns and basic graph patterns, but also contains more advanced constructs such as order by filters and optionals, and there are two main architectures that we can distinguish when querying linked data.",
            "This warehousing architecture, which stores data locally.",
            "And the virtual integration which pushes the query processing to remote endpoints and is always up to date, but as often the case, what the best technique for is depends on the problem.",
            "So if you need up-to-date data for example, then the warehousing is probably not the best approach.",
            "But on the other hand, if you need the best performance, then you might want to use warehousing.",
            "If you need both.",
            "Then you have another problem, but basically you have to be aware of what is possible and then decide accordingly."
        ],
        [
            "OK so I'm."
        ],
        [
            "Mostly done, I have here some slides with links to tools that can be used for working with linked data.",
            "For example, these are triple stores where you can store link data into and they have programming interfaces for different languages."
        ],
        [
            "The frameworks are based on linked data, so this is basically further info."
        ],
        [
            "If you want to find out more and also some links to.",
            "Further information, and."
        ],
        [
            "It's about link data."
        ],
        [
            "So in summary, the link data Web is a large, differently sized and complex system based on simple principles.",
            "It identifies uniquely, identifies resources.",
            "We are HTTP your eyes when looking up these resources, you get a back RDF, which is a common data format and.",
            "Data published and consumers in this link data web have to coordinate little the web of data growth rapidly has been growing rapidly in the past few years, and the common access format enables an easier integration of datasets between different sources and actually first commercial applications are already emerging if you want to find out more.",
            "This is book on linked data, which is very, very helpful.",
            "So basically I'm done now, so thanks for listening.",
            "And if there are any questions.",
            "I'd be happy to answer.",
            "Thank you."
        ],
        [
            "And also I'm not the only one who worked on this slide, so just to attribute this to the correct sources.",
            "A lot of my colleagues also contributed to this leads."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so welcome everybody to my talk.",
                    "label": 0
                },
                {
                    "sent": "I'm first going to introduce as you already set a short introduction on Planet data.",
                    "label": 0
                },
                {
                    "sent": "Plan data is a European project.",
                    "label": 0
                },
                {
                    "sent": "It's a network of excellent project which is funded in the 7th Framework Programme and Network of Excellence.",
                    "label": 0
                },
                {
                    "sent": "Projects are different from usual research projects because they may name is here to establish a European Community, and in this case for planet data about.",
                    "label": 0
                },
                {
                    "sent": "It's about large scale data management.",
                    "label": 0
                },
                {
                    "sent": "And so the research is not the main focus, but mainly establishing a community and able enabling other organizations other people to perform research on this topic.",
                    "label": 0
                },
                {
                    "sent": "So the main objectives of training data are first.",
                    "label": 0
                },
                {
                    "sent": "There is also, of course the research part.",
                    "label": 0
                },
                {
                    "sent": "And then there are this planet Data Lab which which contains a list of tools and best practices for working with large scale data.",
                    "label": 0
                },
                {
                    "sent": "And there's also.",
                    "label": 0
                },
                {
                    "sent": "The goal of disseminating and training other people in this topic.",
                    "label": 0
                },
                {
                    "sent": "Why, for example, workshops or things like this winter school here and finally, the network of Excellence project also has its own calls for which are called planet data programs, where other organizations can apply for funding to perform projects in this area of data management.",
                    "label": 1
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Is a short overview of the work plan highlight, so there are a few topics that are addressed.",
                    "label": 0
                },
                {
                    "sent": "In fact, in planet data.",
                    "label": 0
                },
                {
                    "sent": "First our stream lagged data quality assessment of interlinked datasets, provenance and access control.",
                    "label": 1
                },
                {
                    "sent": "Plan data also tries to publish datasets and vocabularies, including best practices for how to work or work with the state and how to publish data.",
                    "label": 0
                },
                {
                    "sent": "And as already mentioned, there's a summer school which is a yearly summer school which is colocated with the extended Semantic Web conference and also these blended data programs.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so now I get through my tutorial and this is the first part of a two part tutorial which I will which with my colleague Stephen stuff.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And in the 1st.",
                    "label": 0
                },
                {
                    "sent": "Sorry tough.",
                    "label": 0
                },
                {
                    "sent": "OK, so as I already said, this tutorial in two parts, the first part.",
                    "label": 0
                },
                {
                    "sent": "The first part is the bottling data, which I'm going to talk about in this first session and the second part is about link data linked APIs, which definitely going to talk about in the outline of my talk is I'm first going to introduce link data.",
                    "label": 0
                },
                {
                    "sent": "What it is about.",
                    "label": 0
                },
                {
                    "sent": "Present the main link data principles which underlie this new paradigm of publishing data on the web, and then I'm going giving some best practices and some more information on how to publish and access link data.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so the web today is mainly of documents.",
                    "label": 1
                },
                {
                    "sent": "You have this.",
                    "label": 0
                },
                {
                    "sent": "We have many many millions of documents which are interlinked.",
                    "label": 0
                },
                {
                    "sent": "We're we're these documents I HTML documents usually and these are interlinked.",
                    "label": 0
                },
                {
                    "sent": "We hyperlink so everybody knows this by now this was invented at the beginning of the 90s by Tim Berners Lee and by using by having this interlinked structure you are able to discover new content by following links.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "However, many of these pages, or these homepage is actually driven by data.",
                    "label": 0
                },
                {
                    "sent": "So basically almost all websites have some database behind them which actually stores structured data.",
                    "label": 0
                },
                {
                    "sent": "So for example, if you have a home page here on the left hand side, this is from the German railway, where you can look up train connections and basically when you enter something in the form then it accesses the database and from this generates HTML document.",
                    "label": 0
                },
                {
                    "sent": "But each of these websites has their own database which are not interlinked so.",
                    "label": 0
                },
                {
                    "sent": "One website has one database and the other website is another database, and the only links between them are maybe we are HTML, we're hypertext links in the HTML document and this.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Through what we call data silos.",
                    "label": 0
                },
                {
                    "sent": "So basically we have all this data available on the web, but it's in Silo, so these are datasets that for websites are not interconnected and we can easily make sense or of it's not easily possible to combine data from more than from multiple datasets, so each each data is the data silo and there's no connection between them.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And the web of data.",
                    "label": 1
                },
                {
                    "sent": "And this is what link data is also about is.",
                    "label": 0
                },
                {
                    "sent": "Aims to change that.",
                    "label": 0
                },
                {
                    "sent": "So here we have we try to link data instead of documents.",
                    "label": 1
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "Published published the data in Machine readable format.",
                    "label": 0
                },
                {
                    "sent": "So becauses HTML documents are not easily understandable.",
                    "label": 0
                },
                {
                    "sent": "I understand this may be the correct word but did not easily possible by.",
                    "label": 0
                },
                {
                    "sent": "By computers or machines, and So what we try to do here and link data is to publish data in a machine readable format.",
                    "label": 0
                },
                {
                    "sent": "And basically we have.",
                    "label": 0
                },
                {
                    "sent": "Now we want we want to have is we have datasets and these are interconnected via links instead of documents and so basically this means that the web is the web short work or should be accessible as a database.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the motivation behind this is that with the increased use of computers over the last decades, more and more data is being stored.",
                    "label": 1
                },
                {
                    "sent": "So there's basically the data volumes are kind of exploding.",
                    "label": 1
                },
                {
                    "sent": "This are increasing exponentially, and many organizations rely on data for business decisions.",
                    "label": 1
                },
                {
                    "sent": "Governments rely on them for policy decisions, and also every end user basically relies on data that is available in the web for doing many, many things like finding train connections.",
                    "label": 1
                },
                {
                    "sent": "Or finding a cinema where if you want to watch a movie.",
                    "label": 0
                },
                {
                    "sent": "So, and to facilitate access to this or the integration of these datasets, we in linked data we use semantic web technologies.",
                    "label": 0
                },
                {
                    "sent": "I'm going to go into more detail later on, and the main promise behind this link data is that we want to combine data from multiple data from multiple sources to gain new insights.",
                    "label": 0
                },
                {
                    "sent": "So basically we have multiple datasets and we try to find new information by combining these.",
                    "label": 0
                },
                {
                    "sent": "So for example, I don't know if you have some kind of data set.",
                    "label": 0
                },
                {
                    "sent": "About criminal statistics, and you have a data set about.",
                    "label": 0
                },
                {
                    "sent": "I don't know how prices and then you can for example correlate this data and and find out if the criminal criminality has an affect on health prices in a certain area.",
                    "label": 0
                },
                {
                    "sent": "Things like that.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "To this end, Tim Berners Lee, a few years ago, proposed the link data principles.",
                    "label": 0
                },
                {
                    "sent": "There's this, Tim Berners Lee was the original inventor of the World Wide Web.",
                    "label": 0
                },
                {
                    "sent": "And there's this Ted talk.",
                    "label": 0
                },
                {
                    "sent": "I mean, I don't know if you're aware of Ted talks, but these are kind of visionary talks that happen at a few conferences year, and these are always very informative and he has this Ted talk about link data principle.",
                    "label": 0
                },
                {
                    "sent": "So if you want to watch that, I recommended and.",
                    "label": 0
                },
                {
                    "sent": "He proposed.",
                    "label": 0
                },
                {
                    "sent": "Falling data principles, which is the first part of the what I'm going to talk about and why are these linked data principles?",
                    "label": 1
                },
                {
                    "sent": "A lot of bad data has been published in the last few years.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So what you see here is it's the state of the linked or the web of data in 2007 few years ago, and each of these nodes in this graph is a separate data set.",
                    "label": 0
                },
                {
                    "sent": "So for example, we have the data set, DB pedia, or Geo names, and the edges between them between the datasets stand for links between the datasets and so.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To consider over.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Time that this web of data.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Grown.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Very much so.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So for example, we.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In 2000",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "11 and they're basically hundreds of datasets available as linked data, and all these are interlinked.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And what kind of data is actually published here?",
                    "label": 1
                },
                {
                    "sent": "This is like, I guess from last year, so a large part of this data is government data which are which is published by government agencies.",
                    "label": 0
                },
                {
                    "sent": "For example in the United Kingdom there's this initiative called data.gov.uk and which tries to which publishes data that is generated or created by by government agencies.",
                    "label": 0
                },
                {
                    "sent": "For example, these crime statistics.",
                    "label": 0
                },
                {
                    "sent": "This would be one example for this, but there are also other kinds of datasets.",
                    "label": 0
                },
                {
                    "sent": "For example geographic datasets.",
                    "label": 0
                },
                {
                    "sent": "This contains informations.",
                    "label": 0
                },
                {
                    "sent": "Things like that that Berlin is located in Germany and that Germany bought us Poland and other countries and these kind of geographical information is contained in these datasets.",
                    "label": 0
                },
                {
                    "sent": "There also life science datasets which for example contain information about proteins, genes or diseases or drugs, but they are also cross domain data sets which contain data, not about a single domain but for.",
                    "label": 0
                },
                {
                    "sent": "The larger",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Super domains and one of one example for this is a DB pedia data set which is actually linked data version of Wikipedia.",
                    "label": 1
                },
                {
                    "sent": "I mean, you're all aware of Wikipedia and what DB pedia does.",
                    "label": 0
                },
                {
                    "sent": "Is it automatically extract structured, structured data from Wikipedia?",
                    "label": 0
                },
                {
                    "sent": "So Wikipedia is mainly text, but deep down in an automatic fashion extract structured information.",
                    "label": 0
                },
                {
                    "sent": "So for example, if you're probably aware of this because on many many Wikipedia pages you have these infoboxes on the right hand side.",
                    "label": 0
                },
                {
                    "sent": "So for example, if you have I don't know.",
                    "label": 0
                },
                {
                    "sent": "Four players in each football player has a hazardous info box with information about this name is age, the teams he played at, how many goals scored, and whatever, and this is kind of structured information in contrast to text, which is natural language.",
                    "label": 0
                },
                {
                    "sent": "These are.",
                    "label": 0
                },
                {
                    "sent": "We have this information like I don't know.",
                    "label": 0
                },
                {
                    "sent": "Messy Squad One 200 goals or whatever and he played at Barcelona and what DPI does it takes this information and it automatically extracts and.",
                    "label": 0
                },
                {
                    "sent": "Published this is linked data in a structured way, so basically we have now a database of facts extracted from Wikipedia and you can run queries on them.",
                    "label": 0
                },
                {
                    "sent": "And did Peter actually is kind of an interlinking hop in the linked Data Web Justice, Wikipedia is often for the normal web because a lot of other datasets linked to DB pedia and so that you can find connections between other datasets via by going through DB pedia.",
                    "label": 0
                },
                {
                    "sent": "I will show later how this actually in works.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Another use case, falling data is a BBC music website.",
                    "label": 0
                },
                {
                    "sent": "So this.",
                    "label": 0
                },
                {
                    "sent": "BBC Music website contains data about programs that BBC has on the radio, for example and, but also about artists, songs and basically background information in this website is actually a combination of BBC internal data, which are the playlists that which songs are played in the radio but also other datasets which are actually linked data datasets.",
                    "label": 1
                },
                {
                    "sent": "For example Musicbrainz which contains information about artists and albums or Wikipedia which also contains.",
                    "label": 0
                },
                {
                    "sent": "Artists about information about artists and these datasets underlies this BBC music website.",
                    "label": 0
                },
                {
                    "sent": "So basically they have added value on the on the home page or on the website by using linked open data datasets, and they also publish their own data via link data principles so that other people can use them.",
                    "label": 0
                },
                {
                    "sent": "So for example, if you want to look up Marlena Dietrich.",
                    "label": 0
                },
                {
                    "sent": "In the BBC music data set, you can go to this UI and it will give you more information about money indeed.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This.",
                    "label": 0
                },
                {
                    "sent": "Another project of that you Link data assist virtual International Authority file which is a joint project between national libraries in related organizations.",
                    "label": 1
                },
                {
                    "sent": "So many libraries have kind of a data catalog about authors and books they have written, and each currently each each National Library used to have their own catalog and this virtual international authority file is basically an integrated view on all these available data and they also use link data principles.",
                    "label": 0
                },
                {
                    "sent": "To perform or to link between this virtual international authority file and the data that is available at.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "National libraries.",
                    "label": 0
                },
                {
                    "sent": "And lot of what underlies this link data are semantic technologies, semantic semantic web technologies are standardized by the workload Web consortium.",
                    "label": 1
                },
                {
                    "sent": "The World Wide Web Consortium for Maine.",
                    "label": 0
                },
                {
                    "sent": "Standardizing organization for the World Wide Web and a lot of these.",
                    "label": 0
                },
                {
                    "sent": "The technologies have been around for a few years, for example RDF, which is the main.",
                    "label": 0
                },
                {
                    "sent": "Main data model falling data has been around for, I guess since 1999 and link data is actually only a subset of the semantic for semantic web stack.",
                    "label": 1
                },
                {
                    "sent": "And I'm going to.",
                    "label": 0
                },
                {
                    "sent": "Talk about all of these things so RDF and Sparkle and Link data also uses HTTP, which is a hypertext transfer protocol which is also used for websites and so basically I'll now if there are any questions until here.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Then I go to the link data principles.",
                    "label": 0
                },
                {
                    "sent": "Just.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so there are four link data principles.",
                    "label": 1
                },
                {
                    "sent": "I'm going to talk about each one in turn, but in short the first link data principle is to use your eyes as names for things.",
                    "label": 1
                },
                {
                    "sent": "The second principle is that we should use HTP your eyes.",
                    "label": 0
                },
                {
                    "sent": "And the third principle is that when we, when somebody looks up such a UI, then we should return provide useful information.",
                    "label": 1
                },
                {
                    "sent": "And in the case of data this means usually RDF, which is a data model and the 4th principle is that we should include links to other UI so that people can you discover new content.",
                    "label": 1
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so the first principle is you I use your.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Just names for things.",
                    "label": 0
                },
                {
                    "sent": "So basically, if in any scenario where you have to have data and you want to make some you want to describe things, then you have to identify these things.",
                    "label": 0
                },
                {
                    "sent": "In relational databases you often have.",
                    "label": 0
                },
                {
                    "sent": "I don't know some ideas in a table, but the problem here is that these are not unique globally unique.",
                    "label": 0
                },
                {
                    "sent": "So basically you have one database and they're the ones might stand for some.",
                    "label": 0
                },
                {
                    "sent": "Entity like Melina Dietrich, but in another database vid one might send for just some other person or even some completely different thing.",
                    "label": 0
                },
                {
                    "sent": "So what we try to do here in the link data principles is that we use your eyes as a globally unique identifier for entities.",
                    "label": 0
                },
                {
                    "sent": "So for example for the German philosopher Georg Wilhelm Friedrich, we have this UI from DB Pedia.",
                    "label": 1
                },
                {
                    "sent": "Or we might also have your eye from a different data set from this virtual authority file.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And by this is an illustration of this concept.",
                    "label": 0
                },
                {
                    "sent": "So we basically want to give everything a unique name so that we can make assertions about this data and talk.",
                    "label": 0
                },
                {
                    "sent": "And when we try to describe things and talk about things, we exactly we know exactly which which concrete thing we mean.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the second principle is to use HTTP UIS.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And by using HTTP we basically enable.",
                    "label": 0
                },
                {
                    "sent": "Look up on this UI, so HTTP is the main protocol that is used on the on the web for serving websites.",
                    "label": 0
                },
                {
                    "sent": "Web servers have are readily available for serving data or for serving data using the HTTP protocol.",
                    "label": 0
                },
                {
                    "sent": "And this actually uses the Domain Name System to ensure the uniqueness of identifiers, because on the web, when you have a domain, you're uniquely identified because there's a mapping from the name to the physical location, which is IP address basically of that computer or of that domain.",
                    "label": 1
                },
                {
                    "sent": "And also by using HTTP UI so we can use the established HTTP infrastructure, so there's no additional new infrastructure has to be established for working with linked data.",
                    "label": 0
                },
                {
                    "sent": "And what this what the use of HTTP your eyes does is basically it connects the logical level which is the thing we want to talk about the entity.",
                    "label": 0
                },
                {
                    "sent": "For example, a person with the physical level which is the source for the data that describes that entity.",
                    "label": 0
                },
                {
                    "sent": "So this is in.",
                    "label": 0
                },
                {
                    "sent": "This is an important distinction where we distinguish between the thing or which is also called the thing you are I for example or non information resource.",
                    "label": 0
                },
                {
                    "sent": "So for example this would be Melina Dietrich and we distinguish this from the from the source of the document that actually describes this person, which we then call information resource or thought the source UI.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So how do you actually look like?",
                    "label": 0
                },
                {
                    "sent": "And you probably have seen these few.",
                    "label": 0
                },
                {
                    "sent": "Anyway, when you use a browser, but.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The first part of the protocol, which in Link data cases, usually HTTP.",
                    "label": 0
                },
                {
                    "sent": "The second part is the host name.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then we called of the first.",
                    "label": 0
                },
                {
                    "sent": "Everything up to the last slash, the namespace.",
                    "label": 0
                },
                {
                    "sent": "And whatever is written behind that the local name.",
                    "label": 0
                },
                {
                    "sent": "So basically we have the namespace here is deep.org/resource and the local name is India which is an entity described in the namespace of DPD.",
                    "label": 0
                },
                {
                    "sent": "Basically, and what I'm going to use here in the.",
                    "label": 0
                },
                {
                    "sent": "Talk a lot as a kind of a shorthand short for writing such a rise, and these are written.",
                    "label": 0
                },
                {
                    "sent": "There's a prefix DB pedia, which Maps to the namespace.",
                    "label": 0
                },
                {
                    "sent": "So basically there's a.",
                    "label": 0
                },
                {
                    "sent": "There are many popularly loose use prefixes and this map to the namespace so that we can write DB pedia: India instead of the whole UI.",
                    "label": 0
                },
                {
                    "sent": "So this just makes it kind of shorter and easier to read for humans.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So I come back to this distinction between information resource and non information resource.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Here is the problem here is that, for example, if you have Marlene Dietrich and the person, so this is a non information resource or thing.",
                    "label": 1
                },
                {
                    "sent": "But we also and we have a document which contains data about Marlena Dietrich.",
                    "label": 0
                },
                {
                    "sent": "For example.",
                    "label": 0
                },
                {
                    "sent": "I don't know her age and her birthplace and whatever, and now we have the we wouldn't make this distinction between the non information resource or the thing and the source then we couldn't say for example.",
                    "label": 0
                },
                {
                    "sent": "We couldn't provide information about the source.",
                    "label": 0
                },
                {
                    "sent": "For example, it might be interesting to know when the source of the data document that describes the entity was created by whom it was created, but license it has, and so we have to make this distinction between the thing and the source so that we can make statements about the thing.",
                    "label": 0
                },
                {
                    "sent": "For example, the name or the age of Marlene Dietrich.",
                    "label": 0
                },
                {
                    "sent": "And on the other hand we can make statements about the source, for example by whom the data was created or when it was created.",
                    "label": 0
                },
                {
                    "sent": "But copywriter tests.",
                    "label": 0
                },
                {
                    "sent": "So this is the main rationale, or the main reason for.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Making this distinction.",
                    "label": 0
                },
                {
                    "sent": "There actually are two ways on how to order two mainly used ways on how to make this distinction.",
                    "label": 0
                },
                {
                    "sent": "So first we establish this correspondence between the thing you are in the source UI by using hash URS.",
                    "label": 1
                },
                {
                    "sent": "So maybe I've seen this in HTTP your eye services.",
                    "label": 0
                },
                {
                    "sent": "That you can at hash at the end of the UI.",
                    "label": 0
                },
                {
                    "sent": "So in this example it's the hash artist, and we now use because this is actually part of the HTTP standard.",
                    "label": 0
                },
                {
                    "sent": "When browser you looks up this UI, it actually does not send the hash part to the web server, but only the part before that, and So what we do here is when we will look up this UI with the hash part which identifies Marlene Dietrich.",
                    "label": 1
                },
                {
                    "sent": "Then we perform a look up on this UI, and this is the content returned from the web server.",
                    "label": 0
                },
                {
                    "sent": "And so basically we distinguish between the thing and the source.",
                    "label": 0
                },
                {
                    "sent": "Why using this hash at the end of the UI?",
                    "label": 0
                },
                {
                    "sent": "So the things have a hashtag at the end of the UI and the sources don't.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And you can see this is an example request for actually for the description or the link data UI for Tim Berners Lee, which is there at the top.",
                    "label": 0
                },
                {
                    "sent": "As you can see that it has a hash at the end hash and I and now the get request is performed by the HTTP client.",
                    "label": 0
                },
                {
                    "sent": "And actually, what it also does here it HTTPS HTTP standard allows to specify which kind of content you want to get back here.",
                    "label": 0
                },
                {
                    "sent": "Browsers usually say they want to have.",
                    "label": 0
                },
                {
                    "sent": "HTML documents, but in this case we actually say that we want to have RDF data and we perform this get request on the you can see here and there.",
                    "label": 0
                },
                {
                    "sent": "You see at the MD Hash tag is missing and then the server responds with the HTTP code 200, which means everything is fine basically and it also returns data with this content type that we requested.",
                    "label": 0
                },
                {
                    "sent": "So basically this is the way of how we can look up data on the web of data for entities for single entity.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "There's actually another way to establish this correspondence between the thing in the source UI and in this case.",
                    "label": 1
                },
                {
                    "sent": "This is done via HTTP redirect, so the HTTP protocol allows for redirect with.",
                    "label": 0
                },
                {
                    "sent": "Basically, when you look up particular UI, then the server response.",
                    "label": 0
                },
                {
                    "sent": "Please look at some other UI and this is a 303 status code which we call this 3303 redirects.",
                    "label": 0
                },
                {
                    "sent": "And what happens here is we perform this look up on the DB pedia UI for Linda Dietrich with peter.org/resources/melinadietrich.",
                    "label": 0
                },
                {
                    "sent": "And then the server first response with the 303 and redirects to.",
                    "label": 0
                },
                {
                    "sent": "For example, if you requested RDF data to this UI, or if we requested HTML data, redirect to a different UI and basically both of these contain the same data but in different formats from the HTML document is meant for human users to understand, and the RDF data is basically used for.",
                    "label": 0
                },
                {
                    "sent": "Computers to understand and actually can show you how this works.",
                    "label": 0
                },
                {
                    "sent": "I just switched to so you can see here is.",
                    "label": 0
                },
                {
                    "sent": "When I enter.",
                    "label": 0
                },
                {
                    "sent": "So this is a UI for cuts or the city in Germany where Institute is located, and when I now open this page then actually you can see at the top then DP to its now DVP dogs list page search culture culture which is the HTML representation and now we have all the facts which are stored in DB pedia about carpool for that kind of control down there's an abstract.",
                    "label": 0
                },
                {
                    "sent": "And for example there's the area code or the country Castle is located in which is Germany.",
                    "label": 0
                },
                {
                    "sent": "And I can also click on these links.",
                    "label": 0
                },
                {
                    "sent": "To navigate to different sources, for example to Germany, I think the page is quite large, so it takes a while.",
                    "label": 0
                },
                {
                    "sent": "Yeah, and now we look at the entity or the information about Germany that start in DB pedia which is in this case data extracted from Wikipedia.",
                    "label": 0
                },
                {
                    "sent": "But in a structured way.",
                    "label": 0
                },
                {
                    "sent": "Now because we have all these different attributes and they have values.",
                    "label": 0
                },
                {
                    "sent": "For example the population density of Germany is 228 people per square meter probably.",
                    "label": 0
                },
                {
                    "sent": "Kate.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Artist.",
                    "label": 0
                },
                {
                    "sent": "OK, so some best practices for for UI schemes, so you should only when you publish data.",
                    "label": 0
                },
                {
                    "sent": "You should of course only using data files within your own namespace, because you actually can control this namespace about having a web server that listens on this on the domain name.",
                    "label": 0
                },
                {
                    "sent": "You should use mint or crisp and short UI switch.",
                    "label": 0
                },
                {
                    "sent": "Out mentioning the underlying technology.",
                    "label": 0
                },
                {
                    "sent": "For example, this DB pedia UI for cards with much nicer than the 1 one after that, because it's very long.",
                    "label": 0
                },
                {
                    "sent": "It contains support, name and things like that are not very usable or easily understandable for human users.",
                    "label": 0
                },
                {
                    "sent": "It's also very important to keep your eye stable overtime, 'cause obviously people easier for people other people to find the UI's if they are valid over a longer period of time.",
                    "label": 0
                },
                {
                    "sent": "And because of this correspondence I just talked about between the thing and the source, you either usually three UI's that are related to a given resource.",
                    "label": 1
                },
                {
                    "sent": "We have first identifier for the resource.",
                    "label": 1
                },
                {
                    "sent": "Then we have an identifier for the related to be source or the document describing the data.",
                    "label": 1
                },
                {
                    "sent": "For for meant for users, so typically in HTML and we have an UI for the document that describes the resource in a machine readable format, usually in RDF.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "Now come to the third.",
                    "label": 0
                },
                {
                    "sent": "Link data principle which which says to provide useful information.",
                    "label": 1
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the link to principle says when when somebody looks up to you, I so performs an HTTP get.",
                    "label": 0
                },
                {
                    "sent": "Requests on this UI, then the server should return useful data using standards.",
                    "label": 0
                },
                {
                    "sent": "In this case this usually means RDF.",
                    "label": 0
                },
                {
                    "sent": "RDF stands for Resource Description Framework and this is a format for encoding craft structured data.",
                    "label": 1
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "An the RDF is basically a directed and labeled graph.",
                    "label": 0
                },
                {
                    "sent": "So you can see this here.",
                    "label": 0
                },
                {
                    "sent": "We have this.",
                    "label": 0
                },
                {
                    "sent": "We have one so called triple which the subject and predicate in an object and this means that DPW is here the subject.",
                    "label": 0
                },
                {
                    "sent": "The predicate is capital, and the object with Germany basically what this cess or the statement says is that Berlin is the capital of Germany.",
                    "label": 0
                },
                {
                    "sent": "And there are also other not just connections between entities, but RDF also supports attribute values which are called literals in RDF.",
                    "label": 0
                },
                {
                    "sent": "So basically this means that for Germany the label or the common name for Germany for the entity Germany is Deutschland in German.",
                    "label": 0
                },
                {
                    "sent": "But you can also provide other languages which are which are denoted with this tech at the end here, and it's a Germany in English and in this case Germany is a subject for this triple, but it's the object for this trip here.",
                    "label": 0
                },
                {
                    "sent": "So basically what we have here is this directed labeled graph and actually you can model almost for example, relational data can be modeled as graph for example.",
                    "label": 1
                },
                {
                    "sent": "Basically, this subsumes the relational model that is used in traditional relational databases.",
                    "label": 0
                },
                {
                    "sent": "So maybe you could convert any any data that is available as XML, for example, or also as relational data, into RDF.",
                    "label": 0
                },
                {
                    "sent": "There may be multiple formats for serializing RDF, RDF, XML is the most widely diploid serialization, but I'll",
                    "label": 1
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In this talk we are mainly going and Stephen authors mainly going to use Turtle, and here's an example for an RDF document about India.",
                    "label": 0
                },
                {
                    "sent": "So basically this is the data returned when you look up India and DB Pedia.",
                    "label": 0
                },
                {
                    "sent": "And and again, you have this at the start.",
                    "label": 0
                },
                {
                    "sent": "You have some defined prefixes that I was already talking about and below that is the actual RDF data, again organized in a trip away.",
                    "label": 0
                },
                {
                    "sent": "So subject predicate object and this first trip, for example, says that the pages of type countries are basically DB pedia is a country and the second trip again uses this RDF label to say that the entity India has an English name, India.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And what because RDF?",
                    "label": 0
                },
                {
                    "sent": "Some RDF is a graph.",
                    "label": 0
                },
                {
                    "sent": "Structure is a graph and they have unique identifiers because we use you guys as identifiers for nodes and edges or predicates.",
                    "label": 0
                },
                {
                    "sent": "And these are globally unique.",
                    "label": 0
                },
                {
                    "sent": "So what this means that we have?",
                    "label": 0
                },
                {
                    "sent": "We have two RDF graphs and in this case I don't know if you can see this, But this UI is the same as the one up there on the left hand side.",
                    "label": 0
                },
                {
                    "sent": "So if we want to merge these RDF graphs, there's basically nothing we have to do because we can just put them together and be cause the USR globally unique.",
                    "label": 0
                },
                {
                    "sent": "We get a merge graph like this, so this is a very simple way when when we have two datasets that are in RDF and they use.",
                    "label": 0
                },
                {
                    "sent": "Unique your eyes then it's very easy to put them together because we can just throw them together and we've done basically.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "M. So.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "As I. I thought we already saw there are some some properties that are kind of predefined.",
                    "label": 0
                },
                {
                    "sent": "For example this type property and these are part of RDF vocabulary, so basically.",
                    "label": 0
                },
                {
                    "sent": "Vocabulary defines the term Thor classes that can be used when describing things or entities and for you.",
                    "label": 0
                },
                {
                    "sent": "Therefore, for describing these vocabulary sets of so called RDF schema standard, which specifies classes and properties to describe vocabularies.",
                    "label": 1
                },
                {
                    "sent": "So for example we have this.",
                    "label": 0
                },
                {
                    "sent": "There are multiple classes so that we can talk about other classes or properties, and there are also some predefined properties.",
                    "label": 0
                },
                {
                    "sent": "For example RDF type.",
                    "label": 0
                },
                {
                    "sent": "We saw which gives type to an entity or audiences label, which is used to denote or give the common name as a literal of an entity.",
                    "label": 0
                },
                {
                    "sent": "So many of those are many predefined vocabulary are available, and actually most of these vocabulary vocabularies also conform to link data principle.",
                    "label": 0
                },
                {
                    "sent": "So this was what this means is that when you have such a vocabulary terms such as RDF type, you can because this expense to a UI complete your eye with the prefix and then you can perform a look up on this UI and get more information.",
                    "label": 0
                },
                {
                    "sent": "About this vocabulary term.",
                    "label": 0
                },
                {
                    "sent": "So basically the vocabularies are self descriptive, you don't have, you don't need another specification which says what the vocabulary is about because the name or the name of the term of the UI and this is enough to get more information about this vocabulary.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I'm so when you when you try to publish link data using, you have to use vocabularies and if possible you should reuse existing terms because they're also already a lot of predefined vocabularies and you can find these terms by, for example, asking experts.",
                    "label": 0
                },
                {
                    "sent": "Of course looking at examples or there also.",
                    "label": 0
                },
                {
                    "sent": "Specialized search indexes for discovering vocabularies.",
                    "label": 0
                },
                {
                    "sent": "So for example to just to give an example of vocabulary set available.",
                    "label": 0
                },
                {
                    "sent": "For example, the friend of a friend vocabulary is used to describe people it has.",
                    "label": 0
                },
                {
                    "sent": "Property for saying someone knows somebody else or what the homepage of someone is or the email address where he works or she works and there are other other available vocabularies.",
                    "label": 0
                },
                {
                    "sent": "For example the Dublin Core defines general meta data attributes for example like.",
                    "label": 0
                },
                {
                    "sent": "Create a title of documents and things like that.",
                    "label": 0
                },
                {
                    "sent": "So basically there's already a lot of work that has been done on defining these vocabularies, and it's possible you should reuse them.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_48": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so the 4th principle is to link to other UI's.",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So in the same way, for as we use links for HTML documents to discover new related content by clicking on links on webpages, these links to.",
                    "label": 0
                },
                {
                    "sent": "These links to other UI's in linked data and the web of data enable people and machines to jump from server to server and discover new related data.",
                    "label": 1
                },
                {
                    "sent": "We can distinguish here between external links and internal links, so internal links are links in the same namespace.",
                    "label": 0
                },
                {
                    "sent": "So for example, if one DB pedia entity India links to another DP entity for the President or the Leader of India and External links link between datasets.",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And in this example I showed before there already some links to other entities.",
                    "label": 1
                },
                {
                    "sent": "For example, we have this property leader name for India which gives the leader of India which and this links to another DB pedia entity.",
                    "label": 0
                },
                {
                    "sent": "But there also this is also a special predefined property called over the same S which says that this entity is the same as this one which is from the Opencyc project.",
                    "label": 0
                },
                {
                    "sent": "And Additionally there for example also linked to the New York Times data set, and basically this makes an assertion that DB pedia India is the same entity as this one in another namespace.",
                    "label": 0
                },
                {
                    "sent": "So that when you get this information you can save that you can aggregate information from multiple sources and you know by wire this link that these actually talk about the same resources but they are different data because it's from different publishers.",
                    "label": 0
                },
                {
                    "sent": "But in this way the data integration becomes very easy because when we have this explicit links.",
                    "label": 0
                },
                {
                    "sent": "We can easily aggregate the data from multiple datasets.",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So how do we interlink resources and resources?",
                    "label": 0
                },
                {
                    "sent": "We have explicit interlinking by simply reusing your eyes from other datasets.",
                    "label": 0
                },
                {
                    "sent": "We can you establish equivalence where this, say mathlink.",
                    "label": 0
                },
                {
                    "sent": "But there are also other property project properties such as this 4th North, which is from the friend of a friend to vocabulary already talked about, which says that somebody's know somebody else.",
                    "label": 0
                },
                {
                    "sent": "And how do we establish these links?",
                    "label": 0
                },
                {
                    "sent": "So of course it's possible to do this manually, but this can be a very itchy.",
                    "label": 0
                },
                {
                    "sent": "Pensive tough because there are millions of entities and then you have to look at millions of entities and try to find links between them.",
                    "label": 0
                },
                {
                    "sent": "But Fortunately there are also tools or that perform this in an automatic or semi automatic fashion.",
                    "label": 0
                },
                {
                    "sent": "These are of course not perfect because these will usually create links first, not find all links or create links that are incorrect.",
                    "label": 0
                },
                {
                    "sent": "But this could basically our first step and then the user can be fine whatever the output of these tools are is.",
                    "label": 0
                },
                {
                    "sent": "So another best practice is to.",
                    "label": 0
                },
                {
                    "sent": "For data publishers to get external links so when you publish a data set then basically it's at first nobody knows about it because you just put it on some web server.",
                    "label": 0
                },
                {
                    "sent": "And I mean this is the same problem when you have a web page and then nobody finds it because there are no links from other web pages.",
                    "label": 0
                },
                {
                    "sent": "Or in this case other datasets.",
                    "label": 0
                },
                {
                    "sent": "So data publishers should try to get external links from other datasets by talking to the publishers and asking them to add links to their datasets and is also helpful to use established datasets such as deep jazz interlinking hub so.",
                    "label": 1
                },
                {
                    "sent": "If two datasets linked to DB pedia then be basically also have the connection between the datasets.",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "End to to find related efforts as this comprehensive knowledge archive networks he can, which is a list or an archive of linked open data, not only linked open data, but in general datasets are published on the web, and then you can search for topics and they have text for datasets which enables you to find data for out ever use case.",
                    "label": 1
                },
                {
                    "sent": "You have an.",
                    "label": 1
                },
                {
                    "sent": "You can also add your own data set there to make it available or to have other people find it.",
                    "label": 0
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so this is the first part.",
                    "label": 0
                },
                {
                    "sent": "About the link data principles.",
                    "label": 0
                },
                {
                    "sent": "So in summary, what are the benefits of link data?",
                    "label": 1
                },
                {
                    "sent": "First we have an explicit simple data representation.",
                    "label": 1
                },
                {
                    "sent": "We have a common data format in RDF.",
                    "label": 0
                },
                {
                    "sent": "This is very helpful because.",
                    "label": 0
                },
                {
                    "sent": "In a lot of cases, people will use their own proprietary format.",
                    "label": 1
                },
                {
                    "sent": "I don't know in a relation database or in an XML and these are not easily integratable, so usable at the same time.",
                    "label": 0
                },
                {
                    "sent": "And by by having everybody use a common data format which uses unique, globally unique identifiers, we are one step further and on the way to integrated or a web of data.",
                    "label": 0
                },
                {
                    "sent": "The web of data is also completely distributed system that is decentralized becausw.",
                    "label": 0
                },
                {
                    "sent": "Everybody is able to publish their own datasets and the controls only his own data set.",
                    "label": 1
                },
                {
                    "sent": "But it is also cross referencing and allows for linking to other datasets.",
                    "label": 0
                },
                {
                    "sent": "Of course, because it's decentralized system, this does not guarantee referential integrity, so this May's on the web, but it can happen that.",
                    "label": 0
                },
                {
                    "sent": "Links go to become invalid and this is when you get an HTTP 404 error, for example, but this is the price.",
                    "label": 0
                },
                {
                    "sent": "Basically you pay for having a decentralized system.",
                    "label": 0
                },
                {
                    "sent": "It is a loose coupling, so this is again the refresher integrity, which is not guaranteed.",
                    "label": 0
                },
                {
                    "sent": "But as we see if this makes it actually easier to for people to publish their data because they can just put the data out there and then wait for other people to discover it or put links there.",
                    "label": 0
                },
                {
                    "sent": "And this is the overhead costs for publishing data is much lower in this case and as we can see and this was actually one of the main one factor in.",
                    "label": 0
                },
                {
                    "sent": "Why the web became so popular?",
                    "label": 0
                },
                {
                    "sent": "Because it's so easy to put data out there and then link it later or improve the layer the data incrementally.",
                    "label": 0
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Just skip this.",
                    "label": 0
                }
            ]
        },
        "clip_55": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So, of course, but Linklater has also challenges.",
                    "label": 0
                },
                {
                    "sent": "First, there's a ramp up cost for data conversion, so if your data is not available in RDF, then first you have to convert it to RDF to publish it, and this can be a significant cost depending on whatever data format your or whatever form your data is stored in.",
                    "label": 0
                },
                {
                    "sent": "But there are tools that help you with this.",
                    "label": 0
                },
                {
                    "sent": "For example, there are seemingly automatic tools for finding mappings between relational databases in RDF.",
                    "label": 0
                },
                {
                    "sent": "And this provide your support for doing this conversion.",
                    "label": 0
                },
                {
                    "sent": "Integrated data may also be messy at first because anybody can put data put out there, and there's no guarantee about the quality of the data.",
                    "label": 1
                },
                {
                    "sent": "But on the other hand, the data can then be refined as the need arises and the distributed creation also may lead to inconsistencies.",
                    "label": 0
                },
                {
                    "sent": "For example, if you are some two people, make the same statement about, for example, the age of Marlena Dietrich, and one says she is this age and the other says she's a different edge, then you have an inconsistent.",
                    "label": 0
                },
                {
                    "sent": "Because you have two different values for the same property for the same entity, but this kind of inconsistencies can be detected and diagnosed and then fixed with appropriate tools.",
                    "label": 1
                },
                {
                    "sent": "But of course this also means that when you consume link data, because as in the same way that when you consume Wikipedia, you have to be aware of the fact that it might not be completely true in all cases, or there might be.",
                    "label": 0
                }
            ]
        },
        "clip_56": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Sensitive.",
                    "label": 0
                },
                {
                    "sent": "And to to address some of these problems.",
                    "label": 0
                },
                {
                    "sent": "This so called pedantic Web Group which is a community group which actually actively contact publishers about errors and issues in their datasets.",
                    "label": 1
                },
                {
                    "sent": "An they already have fixed or already several errors in populated for fixed after having been contacted by this pedantic web group.",
                    "label": 0
                }
            ]
        },
        "clip_57": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so are there questions for the first path of link data principles?",
                    "label": 0
                },
                {
                    "sent": "OK. OK so yeah.",
                    "label": 0
                },
                {
                    "sent": "So you partially answered my question, but I'll ask again.",
                    "label": 0
                },
                {
                    "sent": "How do you collect the garbage data and so get rid of it?",
                    "label": 0
                },
                {
                    "sent": "Well, I mean, for example, for this inconsistency when you have multiple values, just simple example for the same property for certain definitely set.",
                    "label": 0
                },
                {
                    "sent": "You can detect these tools for this and then you actually have to contact the data publishers and say look something is wrong here and they have to manually fix.",
                    "label": 0
                },
                {
                    "sent": "Their own data, so this is the way becausw.",
                    "label": 0
                },
                {
                    "sent": "Publishers are independent entities and so this is more of a social.",
                    "label": 0
                },
                {
                    "sent": "Effort so that you have to talk to people.",
                    "label": 0
                },
                {
                    "sent": "There's no, no, unfortunately not yet.",
                    "label": 0
                },
                {
                    "sent": "I mean, this is of course research topics.",
                    "label": 0
                },
                {
                    "sent": "No automatic way to fix these errors.",
                    "label": 0
                },
                {
                    "sent": "OK, so in the next part will talk about how I give some tips and tricks and by spectus is about publishing data and mainly about converting legacy data.",
                    "label": 0
                }
            ]
        },
        "clip_58": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Into linked data.",
                    "label": 0
                },
                {
                    "sent": "So the problem here is of course that large amounts of data already managed for in relational databases, for example, or many other web datasets are already published as Jason APIs or is published as XML or CSV.",
                    "label": 1
                },
                {
                    "sent": "So, separated value files and.",
                    "label": 0
                },
                {
                    "sent": "So in order to publish this, this data is RDF works link data.",
                    "label": 0
                },
                {
                    "sent": "There are two steps you have to do.",
                    "label": 0
                },
                {
                    "sent": "First, this ontology modeling.",
                    "label": 0
                },
                {
                    "sent": "So you have to decide how your data is going to be represented as RDF.",
                    "label": 0
                },
                {
                    "sent": "And as already set, you can reuse existing vocabularies, but in many cases you have to also add your own vocabulary which suits your data.",
                    "label": 0
                },
                {
                    "sent": "And in the second step that you can then.",
                    "label": 0
                },
                {
                    "sent": "Create mappings between your data and whatever formative and RDF data, and then you have.",
                    "label": 0
                },
                {
                    "sent": "With these mappings can protest be expressed in procedural language?",
                    "label": 0
                },
                {
                    "sent": "So just you know, by programming in Java, for example, or they're also declarative languages which define these mappings, and then when you have these mappings between your data in one format and audio RDF data, then you can automatically convert the data from one representation into the other.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                }
            ]
        },
        "clip_59": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So when you have text documents, it is possible to link text to data and this is called.",
                    "label": 0
                },
                {
                    "sent": "The process is called named entity recognition and text documents and what this does it establish links between text and structured description of entities that are mentioned in the text.",
                    "label": 1
                },
                {
                    "sent": "So for example, one tool that does is Wiki Fire tool which links entities that appear in texts to Wikipedia articles and thereby also 2D PDF for example.",
                    "label": 0
                },
                {
                    "sent": "So when you have this this text ASAP acquire Sybase.",
                    "label": 1
                },
                {
                    "sent": "Or 5.8 billion dollars, but why?",
                    "label": 0
                },
                {
                    "sent": "And then when you run this through named entity Recognition tool then you get for entities that are named or used in this text you get links to structure or to structure descriptions of of this the office entity.",
                    "label": 0
                },
                {
                    "sent": "So for example for ASAP you get the link which for example links to DB pedia.",
                    "label": 0
                },
                {
                    "sent": "And for Sybase you get also linked to DB Pedia and in this way you have established a link between text documents.",
                    "label": 0
                },
                {
                    "sent": "And structured data because text documents are unstructured data.",
                    "label": 0
                },
                {
                    "sent": "This is natural language and this is not really easily easily usable for four machines because they have a hard time understanding natural language.",
                    "label": 0
                }
            ]
        },
        "clip_60": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Another way of converting your data is a once off data conversion, for example that you can convert spreadsheet data, which is an excellent two RDF using whatever programming programming language do like.",
                    "label": 1
                },
                {
                    "sent": "Or for XML.",
                    "label": 0
                },
                {
                    "sent": "You can also use.",
                    "label": 0
                },
                {
                    "sent": "The style sheets are transforming stylesheets to converter artific smell.",
                    "label": 0
                },
                {
                    "sent": "And what you have to do here is of course also provide you eyes for four entities.",
                    "label": 0
                }
            ]
        },
        "clip_61": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And if you already have data set on API for your data set which is accessible via HTTP protocol, for example which returns Jason or XML, then it's possible to write wrappers around this which then convert this data from Jason or from XML on the fly to RDF.",
                    "label": 0
                },
                {
                    "sent": "And actually, it's definitely we'll talk about this more in the next session.",
                    "label": 0
                }
            ]
        },
        "clip_62": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And at the last thing I'm going to talk about in this part is that they are actually one.",
                    "label": 0
                },
                {
                    "sent": "I guess there are multiple tools, but one of them is the D2R server for expressing mappings between relational databases in RDF.",
                    "label": 0
                },
                {
                    "sent": "So when you have your data stored in a relational database, some SQL Server I don't know.",
                    "label": 0
                },
                {
                    "sent": "For example my SQL and then you can define mappings between using relational database and whatever RDF representation you chose an express.",
                    "label": 0
                },
                {
                    "sent": "This in these detour mappings.",
                    "label": 0
                },
                {
                    "sent": "And then, but due to a server does it provides an interface that Link data interface for your database, so any requests that comes in from for example HTML browsers or Sparkle clients, Parker is a query language for RDF and this is on the fly translated into SQL.",
                    "label": 0
                },
                {
                    "sent": "This is sent to the relational database and the answers again translated into RDF.",
                    "label": 0
                },
                {
                    "sent": "So basically for the client C is suggested link data server, but on the back end the data is still stored in RDF and whatever use you have for the data there for your.",
                    "label": 0
                },
                {
                    "sent": "For your business, you can still keep on using your database as you were before, but this is just on the fly conversion, which makes the data also available as RDF.",
                    "label": 0
                }
            ]
        },
        "clip_63": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "Yeah, there are some icons missing this.",
                    "label": 0
                },
                {
                    "sent": "This should be start on the left hand side so there's this concept of five star data which basically says describes or should describe the quality of a data set.",
                    "label": 0
                },
                {
                    "sent": "So to get one star basically.",
                    "label": 0
                },
                {
                    "sent": "I mean there's no authority that gives out the stars, but the notion that one star you get for making data available on the web in whatever format but with an open license, so this is crucial for this open licenses so that anybody can use this data.",
                    "label": 1
                },
                {
                    "sent": "And you get two stars for publishing the data in the machine readable format.",
                    "label": 0
                },
                {
                    "sent": "And a structured data, for example Excel.",
                    "label": 1
                },
                {
                    "sent": "Instead of scanning and image scan of a table and you get three stars by using a non proprietary format.",
                    "label": 1
                },
                {
                    "sent": "So this is for example XML instead of CSV.",
                    "label": 0
                },
                {
                    "sent": "And Additionally, if you open standard from the such as RDF and Sparkle, you get another star and if you link your data to other datasets you get 5 stars.",
                    "label": 0
                },
                {
                    "sent": "Thank God who defined that.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "They say your eyes is also from the I think from the World Wide Web Consortium, but it's I mean it's not really.",
                    "label": 0
                },
                {
                    "sent": "There's no authority that look the datasets and give them.",
                    "label": 0
                },
                {
                    "sent": "I actually, I'm not sure, but it's not really.",
                    "label": 0
                },
                {
                    "sent": "It's kind of you.",
                    "label": 0
                },
                {
                    "sent": "Can you put your stuff on there on your own?",
                    "label": 0
                },
                {
                    "sent": "I mean if you lie then you could lie, but you know you're not supposed to.",
                    "label": 0
                }
            ]
        },
        "clip_64": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so and in the final part of the tutorial I'm now I will talk about how we can access link data and how to run queries on linked data so that we can make sense of the data that is published.",
                    "label": 0
                }
            ]
        },
        "clip_65": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so basically we already know of one way to access link data which I already showed you.",
                    "label": 1
                },
                {
                    "sent": "You can just perform an HTTP look up on the UI.",
                    "label": 0
                },
                {
                    "sent": "And just for example, is a is a tool.",
                    "label": 0
                },
                {
                    "sent": "It's called tabulator, which basically be able you can enter your eye and it retrieves the link data and then presents it in a nicer format.",
                    "label": 0
                },
                {
                    "sent": "For example.",
                    "label": 0
                },
                {
                    "sent": "And of course this might be enough for some applications.",
                    "label": 0
                },
                {
                    "sent": "So for example for this BBC music website, when you just want to provide background information about entities you're looking at, then simple link data lookups might be enough.",
                    "label": 0
                },
                {
                    "sent": "But now that we have the data in a structured formatted mine, we actually want to execute queries so.",
                    "label": 0
                },
                {
                    "sent": "And how do we do that?",
                    "label": 0
                }
            ]
        },
        "clip_66": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "For RDF, the main query language is Parker, which you can think of SQL for RDF.",
                    "label": 1
                },
                {
                    "sent": "I hope you're aware of SQL.",
                    "label": 0
                },
                {
                    "sent": "Which scares the query language that has been around for decades now.",
                    "label": 0
                },
                {
                    "sent": "I think since the 80s or whatever for relational database and basically what's Parker does is the query language for RDF for RDF graph.",
                    "label": 0
                },
                {
                    "sent": "So whereas careless about relations, Parker is about graph, so this syntax is somewhat similar because you have also in some cases is select from where syntax we have where you specify first whatever variables you want to retrieve from where you want to retrieve them, and then we're contains conditions about the data that you want to retrieve, but actually sparkle supports more than one query type part from selected also describes, supports, asked, describe and construct queries.",
                    "label": 0
                },
                {
                    "sent": "And I'm now going to show you to give an introduction only of two of these groups, namely select and construct queries.",
                    "label": 0
                },
                {
                    "sent": "So sparklers based on graph patterns cause what we want to query our graph so that we're on the other hand, the query language or has also has to support graph of course.",
                    "label": 1
                }
            ]
        },
        "clip_67": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And the basic graph pattern is a basic building block of Parker queries.",
                    "label": 1
                },
                {
                    "sent": "Basic graph pattern.",
                    "label": 0
                },
                {
                    "sent": "So this is basic graph pattern.",
                    "label": 0
                },
                {
                    "sent": "It's surrounded by these parenthesis and it's a conjunction of.",
                    "label": 0
                }
            ]
        },
        "clip_68": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Triple patterns so true pattern is basically a triple.",
                    "label": 0
                },
                {
                    "sent": "We already saw those perform in the RDF example where we had DB pedia, India type country and we now have triple patterns.",
                    "label": 1
                },
                {
                    "sent": "Basically the same thing as a triple where the subject, predicate and object are replaced by variables.",
                    "label": 0
                },
                {
                    "sent": "For example, variable X and such a triple pattern as the first one.",
                    "label": 0
                },
                {
                    "sent": "Here basically matches all triplets where the predicates RDF type and the object is.",
                    "label": 0
                },
                {
                    "sent": "DB Pedia over the country and any subject.",
                    "label": 0
                },
                {
                    "sent": "So and then.",
                    "label": 0
                },
                {
                    "sent": "Basically the result of these of matching this triple pattern against the graph are bindings for 4X.",
                    "label": 1
                },
                {
                    "sent": "So basically all triples where the subject appears subject appears together with these predicates and objects.",
                    "label": 0
                }
            ]
        },
        "clip_69": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And I'm OK. As I said, the Accessor is a variable and then we call the other the other positions where we have no variables are constant.",
                    "label": 0
                }
            ]
        },
        "clip_70": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And the basic graph pattern is a conjunction of triple patterns.",
                    "label": 1
                },
                {
                    "sent": "So this means that here the both variables refer actually to the same.",
                    "label": 0
                },
                {
                    "sent": "Same note in the pattern Graph and this means that here we have to perform a joint.",
                    "label": 0
                },
                {
                    "sent": "Oh.",
                    "label": 0
                },
                {
                    "sent": "I'm get the results.",
                    "label": 0
                }
            ]
        },
        "clip_71": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we can also visualize these basic graph pattern.",
                    "label": 0
                },
                {
                    "sent": "Its graph as we already saw in RDF data.",
                    "label": 0
                },
                {
                    "sent": "Before that, and again we have one variable.",
                    "label": 0
                },
                {
                    "sent": "X has an edge to country with a label or with the name RDF type and an RDF label edged predicate to to the variable Y. I thought you want to have a more formal definition on what constitutes.",
                    "label": 0
                },
                {
                    "sent": "Result for such a graph pattern is that Beijing graph pattern matches a subgraph of the RDF data.",
                    "label": 1
                },
                {
                    "sent": "When the IDF terms from their sub graph may be substituted for the variables and the resulting RDF graph is equivalent.",
                    "label": 1
                },
                {
                    "sent": "To the sub graph that contains that was a match.",
                    "label": 0
                }
            ]
        },
        "clip_72": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I mean, this is more.",
                    "label": 0
                },
                {
                    "sent": "I'll be this more become become more clear.",
                    "label": 0
                },
                {
                    "sent": "Example on the next slide.",
                    "label": 0
                },
                {
                    "sent": "So the first query type I'm talking about we talk about is the select queries, which is which are analog to the select queries in SQL.",
                    "label": 0
                },
                {
                    "sent": "Select curious look like this you have selected then a list of variables and the where clause.",
                    "label": 0
                },
                {
                    "sent": "There is a basic graph pattern.",
                    "label": 0
                },
                {
                    "sent": "And the result is a table of bindings for the selected for the variables that appear in.",
                    "label": 1
                }
            ]
        },
        "clip_73": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Select clause so for example we have here some data.",
                    "label": 0
                },
                {
                    "sent": "These are just.",
                    "label": 0
                },
                {
                    "sent": "You know, six triples where we have say triplets that say India is a country and has this name and the same for Germany and for France.",
                    "label": 0
                },
                {
                    "sent": "And we have this example query where we have two select query to select variables and one basic graph pattern.",
                    "label": 0
                },
                {
                    "sent": "And what the query engine now does.",
                    "label": 0
                },
                {
                    "sent": "It basically matches these.",
                    "label": 0
                },
                {
                    "sent": "This this basic graph pattern two to the RDF data to the RDF graph, and then the result is a table where we have for each for both variables.",
                    "label": 0
                },
                {
                    "sent": "Findings that are created by matching the basic graph pattern to the RDF data.",
                    "label": 0
                },
                {
                    "sent": "So what we can see here is that we have two results, so the 1st result is a binding of DP to index BP to India to X and India to Y.",
                    "label": 0
                },
                {
                    "sent": "This comes from the 1st.",
                    "label": 0
                },
                {
                    "sent": "It's the same for Germany from the 2nd, and actually this does not generate a match because in here in this case is a different product reduced which does not match.",
                    "label": 0
                },
                {
                    "sent": "This label, which is the condition in the in the basic graph pattern.",
                    "label": 0
                },
                {
                    "sent": "So This is why the first pattern matches.",
                    "label": 0
                },
                {
                    "sent": "But because this is conjunction, which means that both of these, both of these two parents have to match the same time, which is why no result is generated from the last two triples.",
                    "label": 0
                }
            ]
        },
        "clip_74": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so the second query type is a construct queries and these also have basic graph pattern in the where clause.",
                    "label": 0
                },
                {
                    "sent": "But the differences in the result of the data of the query.",
                    "label": 0
                },
                {
                    "sent": "So about the contracts construct, reduce it to create a new graph.",
                    "label": 0
                },
                {
                    "sent": "For for this you have such a template basic graph pattern which contains a subset or even all variables from the graph pattern in the where clause and basically the result of a concept reason you RDF graph where.",
                    "label": 1
                },
                {
                    "sent": "The bindings for the variables are substituted in the variable for in the template.",
                    "label": 1
                }
            ]
        },
        "clip_75": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So again, we have.",
                    "label": 0
                },
                {
                    "sent": "On an example, we now have the where clause is the same as before, and we can assume the same data as before, so this about Germany, India in France.",
                    "label": 0
                },
                {
                    "sent": "But we now have a construct query where we have a template which also uses the variables X&Y.",
                    "label": 0
                },
                {
                    "sent": "But in this case the template is different because it assigns a different.",
                    "label": 0
                },
                {
                    "sent": "Object for the type pattern and it uses fourth name instead of RDF label, triple pattern and so basically what the career engineer does, is it?",
                    "label": 0
                },
                {
                    "sent": "First finds all the bindings for the variables.",
                    "label": 0
                },
                {
                    "sent": "This is the same as before and then it takes the template.",
                    "label": 0
                },
                {
                    "sent": "And then substitute the bindings for the variables in the template so that for this result we get this RDF graph, so this is again in RDF graph, not not a table, and we can all see here that DPR indexer binding.",
                    "label": 0
                },
                {
                    "sent": "Forex was substituted in both.",
                    "label": 0
                },
                {
                    "sent": "In both patterns for X and the binding for Y was substituted in the second triple pattern for the object.",
                    "label": 0
                },
                {
                    "sent": "Variable Y, which appears as the object.",
                    "label": 0
                },
                {
                    "sent": "So in this way basically we can create new RDF graph based on the results of a query and in a similar fashion.",
                    "label": 0
                },
                {
                    "sent": "This happened for the 2nd result where Germany and the entity Germany and the literal Germany are substituted for X&Y.",
                    "label": 0
                },
                {
                    "sent": "So basically for each.",
                    "label": 0
                },
                {
                    "sent": "Reside in this table.",
                    "label": 0
                },
                {
                    "sent": "We get a separate RDF graph as an output of this of this construct query.",
                    "label": 0
                }
            ]
        },
        "clip_76": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this was just a short introduction to spark and Spark actually supports way more than just the basic graph patterns.",
                    "label": 1
                },
                {
                    "sent": "It has optional patterns so that not all patterns have to match to create a result.",
                    "label": 0
                },
                {
                    "sent": "It has filter conditions.",
                    "label": 0
                },
                {
                    "sent": "So in this example query you see that we can filter on the literal here and say that we only want results where the language of the literal.",
                    "label": 0
                },
                {
                    "sent": "We have this language taxes English.",
                    "label": 0
                },
                {
                    "sent": "You can also order on attributes.",
                    "label": 0
                },
                {
                    "sent": "You can say limit and offset the same as in SQL.",
                    "label": 0
                },
                {
                    "sent": "We can say you only you only want the ten 1st result.",
                    "label": 0
                },
                {
                    "sent": "And I'm.",
                    "label": 0
                },
                {
                    "sent": "Many things more, and so if you want to, there's this sparkle by example document which is quite nice.",
                    "label": 0
                },
                {
                    "sent": "And also this is the sparkling new Sparkle 1.1 standard if you want to actually look at the grammar.",
                    "label": 0
                }
            ]
        },
        "clip_77": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so now that we have this query language, how do we actually execute this over linked data?",
                    "label": 1
                },
                {
                    "sent": "Because Link data start on some web server somewhere and I am here on my PC and then I want to execute a sparkle query and so how do I do that for for execute increase over linked data there are two main architectures that we can distinguish.",
                    "label": 0
                },
                {
                    "sent": "The first is the warehousing architecture.",
                    "label": 0
                },
                {
                    "sent": "And in this case we first download whatever data we interested in and start in the database on our local computer on our local network for example.",
                    "label": 0
                },
                {
                    "sent": "So and then we can execute queries on this local database and get the results back and then find out where we wanted in the 1st place.",
                    "label": 0
                },
                {
                    "sent": "But on the other hand, the other architecture is that if you don't want to use a local database, we have to perform some kind of virtual integration and distributed querying where we.",
                    "label": 1
                },
                {
                    "sent": "The way we try to directly query that it's linked data link data that is stored at remote servers and I'm now going to.",
                    "label": 0
                },
                {
                    "sent": "Present both of these architectures and show what the disadvantages advantages of these architectures are.",
                    "label": 0
                }
            ]
        },
        "clip_78": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "For the first in the warehousing architecture, we first have to download all the data we interested in and start in local database.",
                    "label": 0
                },
                {
                    "sent": "So this is possible.",
                    "label": 0
                },
                {
                    "sent": "For example, as many datasets actually provide RDF dump.",
                    "label": 1
                },
                {
                    "sent": "So one file that contains all the data that they published, not in a single GPU ice, but in one are huge RDF file which you can download and then store in your local database.",
                    "label": 0
                },
                {
                    "sent": "This is possible for some datasets.",
                    "label": 1
                },
                {
                    "sent": "For example, DB PEDIA provides such an RDF dump.",
                    "label": 0
                },
                {
                    "sent": "But not all datasets do so, or all data publishers do so, and what you can then do is otherwise you have to crawling data by following links.",
                    "label": 1
                },
                {
                    "sent": "So this is basically the same as web crawler.",
                    "label": 0
                },
                {
                    "sent": "So for example when Google wants to build this search indexer, has this crawler or spider which starts with a certain predefined set of HTML pages and then follows links to discover all web pages and incrementally increases the search space.",
                    "label": 0
                },
                {
                    "sent": "And basically in this way hopefully discovers all the pages that there on the Internet.",
                    "label": 0
                },
                {
                    "sent": "And you can do the same thing funding data because we have these links.",
                    "label": 0
                },
                {
                    "sent": "I was talking about all the time before between between data entities and you can crawl link data in the same way by following links and downloading whatever content there is behind these.",
                    "label": 0
                },
                {
                    "sent": "HTP you eyes.",
                    "label": 0
                },
                {
                    "sent": "And when you do this, you can start in local database and then execute queries on them on the data.",
                    "label": 0
                },
                {
                    "sent": "The thought of food store this data.",
                    "label": 0
                },
                {
                    "sent": "There are so called triple stars becaused this we have RDF triples and these are purpose built databases for storage and retrieval of RDF and for example for retrieval you can use sparkle and there are.",
                    "label": 1
                },
                {
                    "sent": "This are quite quite mature technology.",
                    "label": 1
                },
                {
                    "sent": "There are open source systems available for doing this or even commercial systems.",
                    "label": 0
                },
                {
                    "sent": "The advantage of using such a warehousing on materialization strategy architecture is that you are in control.",
                    "label": 0
                },
                {
                    "sent": "You don't depend on third parties for providing.",
                    "label": 0
                },
                {
                    "sent": "Access to linked data because you start in your local database and this also usually means that the performance is better because it starts.",
                    "label": 0
                },
                {
                    "sent": "You don't have to go over the Internet or network access to execute queries and it's locally starting your own database and you can put whatever hardware you have or whatever hardware you like behind it and then the performance is usually better.",
                    "label": 0
                },
                {
                    "sent": "But on the other hand, of course you have an operating cost for the hardware for the software, for the maintenance, and this is an overhead.",
                    "label": 0
                },
                {
                    "sent": "Of course, and also the data that you have stored locally might not always be up to date, because link data can in some cases change very rapidly daily, hourly or even in minutes.",
                    "label": 0
                },
                {
                    "sent": "An in this case you only have what you're curious, honest, whatever you download it at some point.",
                    "label": 0
                },
                {
                    "sent": "So either you have to download new data all the time, or you are operating on data that is out of date.",
                    "label": 0
                },
                {
                    "sent": "So this depends on the use case.",
                    "label": 0
                },
                {
                    "sent": "Whatever you have if you can.",
                    "label": 0
                },
                {
                    "sent": "If you need up-to-date data, then maybe warehousing is not the best strategy.",
                    "label": 0
                },
                {
                    "sent": "But if you're fine with operating on all data on outdated data, then the warehousing strategy architecture might might be suitable.",
                    "label": 0
                }
            ]
        },
        "clip_79": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So on the other hand, on the other end of the spectrum, basically is this virtual integration of distributed querying architectures, and I will talk about two of them here.",
                    "label": 0
                },
                {
                    "sent": "The first is the Spark Endpoint Federation.",
                    "label": 1
                },
                {
                    "sent": "A lot of data publishers on which publishing data also provides Barker endpoints.",
                    "label": 0
                },
                {
                    "sent": "So basically triple stores that can be reached.",
                    "label": 0
                },
                {
                    "sent": "Also, we are HTTP and you can execute queries, sparkle queries on them.",
                    "label": 0
                },
                {
                    "sent": "So this these queries and will run on the hardware that the data publishers provides and you just get the result spectrum and.",
                    "label": 0
                },
                {
                    "sent": "In the end point, Federation of the Mediator basically provides an integrated view on multiple of the sparkle endpoints an but on the other hand, not all of the data sets are available spark endpoints, and for this we have this link data query processing techniques which have been proposed in the in the last few years and academic community and what here the query engine does not talk to spark endpoints or to other databases but directly uses HTTPS.",
                    "label": 0
                },
                {
                    "sent": "So link data look up to retrieve data and then process it is.",
                    "label": 0
                },
                {
                    "sent": "To answer queries that are posed by the user.",
                    "label": 0
                }
            ]
        },
        "clip_80": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So I already mentioned many of the datasets.",
                    "label": 0
                },
                {
                    "sent": "Actually I think it was about 65% of the datasets Office park endpoint, so these are basically triple stores.",
                    "label": 1
                },
                {
                    "sent": "The data publisher with the data publisher stores there whatever data they published and they provide an endpoint that anybody can use.",
                    "label": 0
                },
                {
                    "sent": "You can send Sparkle Cruiser and get relayed spec for free.",
                    "label": 1
                },
                {
                    "sent": "This is quite amazing actually that people are willing to do this, but on the other hand is also means that these are sometimes unreliable, so this might go down at some point you can't.",
                    "label": 0
                },
                {
                    "sent": "Can't often rely on these endpoints, or the quality varies.",
                    "label": 0
                },
                {
                    "sent": "Some endpoints are very stable and other endpoints might not be, and also in some cases you have because these are for free, you have query limits, or you can only return a certain number of results or come very complex queries are not supported, for example.",
                    "label": 0
                },
                {
                    "sent": "So this is what you have to keep in mind if you want to use Spark endpoints so that this might be unreliable and things like that.",
                    "label": 0
                }
            ]
        },
        "clip_81": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So what the Federation is about that is that this mediator which sits on your local machine, it provides a virtual integration of remote data sources.",
                    "label": 1
                },
                {
                    "sent": "So no data is actually stored locally.",
                    "label": 0
                },
                {
                    "sent": "But whenever you send a query to this mediator, for example this one which asks about presidents.",
                    "label": 0
                },
                {
                    "sent": "And the party which the president belongs to and actually tries to find more information about this entity from the New York Times data set, which is linked via same S link and know when we have for example, 2 two sources for this DB pedia and the New York Times data set.",
                    "label": 0
                },
                {
                    "sent": "No data set here is able to answer the complete query.",
                    "label": 0
                },
                {
                    "sent": "So the 1st two triple patterns might appear in the first data set in the second last two triple patterns might appear in the New York Times data set.",
                    "label": 0
                },
                {
                    "sent": "So when we then send the whole query to each of the spark endpoints, we get no results because none of the endpoints contain data that can answer the query.",
                    "label": 0
                },
                {
                    "sent": "So what the mediator does, it splits a career in two parts and send these to the spark endpoints and then recombines the results it gets from the.",
                    "label": 0
                },
                {
                    "sent": "From the endpoints.",
                    "label": 0
                },
                {
                    "sent": "To provide query answers.",
                    "label": 0
                }
            ]
        },
        "clip_82": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For this is a list of some of these Federation systems that are available and for example, one of these systems which is called FedEx, which was just published at the International Semantic Web Conference a few months ago, and you can see here that the process is as follows.",
                    "label": 0
                },
                {
                    "sent": "You get a sparkle request and it first passes the query and then it performs source selection.",
                    "label": 0
                },
                {
                    "sent": "Source selection means that which tries to find out which endpoints that knows about can answer which part of the query.",
                    "label": 0
                },
                {
                    "sent": "And then performs global optimizations and then execute the query by splitting it and sending it to the spark endpoints that were selected.",
                    "label": 0
                },
                {
                    "sent": "And then we combined the results to present.",
                    "label": 0
                },
                {
                    "sent": "Finally result of the user.",
                    "label": 0
                },
                {
                    "sent": "There's also an open source implementation which you can just use as you wish.",
                    "label": 0
                }
            ]
        },
        "clip_83": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So on the other hand, there's link data processing, link data, group processing techniques, and these work directly over linked data, so there are no spark endpoints.",
                    "label": 0
                },
                {
                    "sent": "But what the query engine does, it retrieves link data sources during query execution while performing HTTP.",
                    "label": 1
                },
                {
                    "sent": "Look up just as presented during the.",
                    "label": 0
                },
                {
                    "sent": "During the link data principles in the first part of the talk, but also basically all the crew processing other than retrieving the data is done locally and here the source discovery and selection is crucial.",
                    "label": 1
                },
                {
                    "sent": "Selection is basically the same cause As for the spark endpoints, But the problem is that we have many, many more sources in this case, because each HTTP UI is a possible source, you know there's no single endpoint for the whole data set, but the data set consists of millions of entities possibly, and also millions of sources.",
                    "label": 0
                },
                {
                    "sent": "The.",
                    "label": 0
                },
                {
                    "sent": "The advantage of this approach is of course it's always up to date 'cause just in this.",
                    "label": 0
                },
                {
                    "sent": "In this bucket Finepoint Federation, because you directly use link data and knows locally stored copy, you always use the most up-to-date of whatever the data publisher has published.",
                    "label": 1
                },
                {
                    "sent": "And in addition, this does not rely on Spark endpoints, but basically means that any link data that is or any data that is published.",
                    "label": 0
                },
                {
                    "sent": "This link data can be queried in this way even if the publisher does not provide a spark endpoint.",
                    "label": 0
                },
                {
                    "sent": "I mean many do, but.",
                    "label": 0
                },
                {
                    "sent": "Some of them are like 30% of them don't provide this back end point and by using LINQ data query processing implementations, you can actually access also this data which is not in a sparkle endpoint.",
                    "label": 0
                },
                {
                    "sent": "I'm on the on the other side.",
                    "label": 1
                },
                {
                    "sent": "Link data query processing is usually.",
                    "label": 0
                },
                {
                    "sent": "Fairly slow becauses you have always to retrieve you.",
                    "label": 0
                },
                {
                    "sent": "Always retrieve a source in as a whole.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so there's no way to say I want only the data from this HTTP UI that matches a particular part of my query.",
                    "label": 0
                },
                {
                    "sent": "So this means that you retrieve much more data.",
                    "label": 1
                },
                {
                    "sent": "And then also the high number of possible sources and overhead because you have to contact them and get unsuspecting, which again increases or decreases performance and increases query time and the source discovery and selection process is actually more complex.",
                    "label": 0
                },
                {
                    "sent": "And for sparkling points.",
                    "label": 0
                }
            ]
        },
        "clip_84": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I'm.",
                    "label": 0
                },
                {
                    "sent": "So this is just an overview of the current research in this topic, 'cause this is what I do when I don't give tutorials at winter schools and so the sources xcovery and there are two main techniques for doing the sources cover the sources, carries a process of finding sources that are relevant for for your, for your query.",
                    "label": 0
                },
                {
                    "sent": "So first there's a possibility of a ramp runtime discovery which takes advantage of the links that are available in the linked data Web so.",
                    "label": 0
                },
                {
                    "sent": "When you when you start at one source and you have have links to other sources and then the query engine can follow these links and thereby discover new sources and download them and process the data in them to answer queries and this of course relies on the links because when the links are not there then this engine or this type of engine will not find answers to the query and on the other hand you have the possibility of using a source index which is a precomputed index of sources.",
                    "label": 0
                },
                {
                    "sent": "So basically you have to 1st download all the sources that you are interested in first.",
                    "label": 0
                },
                {
                    "sent": "And these are index which then map triple patterns or parts of your query to relevant sources.",
                    "label": 1
                },
                {
                    "sent": "And this is similar to.",
                    "label": 0
                },
                {
                    "sent": "It's not quite the same as away as expected, but first to build a source index you have first quality data link data, for example, and.",
                    "label": 0
                },
                {
                    "sent": "The next step is sensa selection or South ranking, because they're usually too many sources to process of a single query.",
                    "label": 1
                },
                {
                    "sent": "There might be hundreds of thousand sources that match or contain possibly relevant data, and so you have to decide which of these sources are actually really relevant in the sense that they will produce final results.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "When you have a source index is a bit easier because you know more about the know more about the content in these sources and then you can rank the sources by the number of expected results.",
                    "label": 1
                },
                {
                    "sent": "When you process that source.",
                    "label": 0
                },
                {
                    "sent": "And there's also the possibility to refine the ranking at runtime.",
                    "label": 1
                },
                {
                    "sent": "So when some sources have been retrieved, you have more a better idea about the data that matches the query and then can refine your ranking and decide on the fly which sources you want to retrieve and 3rd consideration when doing data.",
                    "label": 0
                },
                {
                    "sent": "Reprocessing is with the career processing itself so because your perform network access this might lead to blocking because you have to wait for an answer from the server and what you don't want to do is basically wait for single server and store the whole query execution process.",
                    "label": 1
                },
                {
                    "sent": "But contact multiple servers in parallel and there are few techniques for doing this so that the results that are available can be produced early and that slow servers don't block the whole query execution.",
                    "label": 0
                }
            ]
        },
        "clip_85": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So before coming to the summary, I'm just going to show you an example of a SPARQL endpoint.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "So this is an HTML interface or formula interface for this back end point of DB pedia.",
                    "label": 0
                },
                {
                    "sent": "And I have prepared some query.",
                    "label": 0
                },
                {
                    "sent": "So this is basically the query from the example that we used.",
                    "label": 0
                },
                {
                    "sent": "And this again gets the label of all entities set off the type country.",
                    "label": 0
                },
                {
                    "sent": "And when I now click on run query I get this table.",
                    "label": 0
                },
                {
                    "sent": "So I get bindings for X&Y and becaused.",
                    "label": 0
                },
                {
                    "sent": "Peter provides identifiers in multiple languages, I get multiple results for a single entity.",
                    "label": 0
                },
                {
                    "sent": "So for example Falkland Islands, I get the name in Germany, cycling in zone and in English.",
                    "label": 0
                },
                {
                    "sent": "If Falkland Islands for example.",
                    "label": 0
                },
                {
                    "sent": "So this is a spark endpoints.",
                    "label": 0
                },
                {
                    "sent": "Repeat, it provides and you can just run queries on them and thereby use or make sense of the data that is stored in DB pedia.",
                    "label": 0
                },
                {
                    "sent": "And just to show you the.",
                    "label": 0
                },
                {
                    "sent": "The different capability of is already off.",
                    "label": 0
                },
                {
                    "sent": "Barker already set there.",
                    "label": 0
                },
                {
                    "sent": "Are these filter conditions.",
                    "label": 0
                },
                {
                    "sent": "And here we have.",
                    "label": 0
                },
                {
                    "sent": "We have a filter which says that all bindings for variable Y should be of the half language English.",
                    "label": 0
                },
                {
                    "sent": "And now we get the same result, but only the English literals.",
                    "label": 0
                },
                {
                    "sent": "For example, to go of the English name in its total.",
                    "label": 0
                },
                {
                    "sent": "So as you can see, the you know executing this park and points available is quite easy and this enables you to easily use datasets or that are available on the web.",
                    "label": 0
                },
                {
                    "sent": "OK, so in summary, for accessing data sparkle is the query language of choice.",
                    "label": 1
                },
                {
                    "sent": "For RDF it performs graph pattern matching.",
                    "label": 0
                },
                {
                    "sent": "There are several query types.",
                    "label": 0
                },
                {
                    "sent": "I talked about the select and construct queries sparkle at its core is about triple patterns and basic graph patterns, but also contains more advanced constructs such as order by filters and optionals, and there are two main architectures that we can distinguish when querying linked data.",
                    "label": 0
                },
                {
                    "sent": "This warehousing architecture, which stores data locally.",
                    "label": 0
                },
                {
                    "sent": "And the virtual integration which pushes the query processing to remote endpoints and is always up to date, but as often the case, what the best technique for is depends on the problem.",
                    "label": 1
                },
                {
                    "sent": "So if you need up-to-date data for example, then the warehousing is probably not the best approach.",
                    "label": 0
                },
                {
                    "sent": "But on the other hand, if you need the best performance, then you might want to use warehousing.",
                    "label": 0
                },
                {
                    "sent": "If you need both.",
                    "label": 0
                },
                {
                    "sent": "Then you have another problem, but basically you have to be aware of what is possible and then decide accordingly.",
                    "label": 0
                }
            ]
        },
        "clip_86": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK so I'm.",
                    "label": 0
                }
            ]
        },
        "clip_87": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Mostly done, I have here some slides with links to tools that can be used for working with linked data.",
                    "label": 0
                },
                {
                    "sent": "For example, these are triple stores where you can store link data into and they have programming interfaces for different languages.",
                    "label": 0
                }
            ]
        },
        "clip_88": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The frameworks are based on linked data, so this is basically further info.",
                    "label": 0
                }
            ]
        },
        "clip_89": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "If you want to find out more and also some links to.",
                    "label": 0
                },
                {
                    "sent": "Further information, and.",
                    "label": 0
                }
            ]
        },
        "clip_90": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It's about link data.",
                    "label": 0
                }
            ]
        },
        "clip_91": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So in summary, the link data Web is a large, differently sized and complex system based on simple principles.",
                    "label": 1
                },
                {
                    "sent": "It identifies uniquely, identifies resources.",
                    "label": 0
                },
                {
                    "sent": "We are HTTP your eyes when looking up these resources, you get a back RDF, which is a common data format and.",
                    "label": 1
                },
                {
                    "sent": "Data published and consumers in this link data web have to coordinate little the web of data growth rapidly has been growing rapidly in the past few years, and the common access format enables an easier integration of datasets between different sources and actually first commercial applications are already emerging if you want to find out more.",
                    "label": 0
                },
                {
                    "sent": "This is book on linked data, which is very, very helpful.",
                    "label": 0
                },
                {
                    "sent": "So basically I'm done now, so thanks for listening.",
                    "label": 0
                },
                {
                    "sent": "And if there are any questions.",
                    "label": 0
                },
                {
                    "sent": "I'd be happy to answer.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                }
            ]
        },
        "clip_92": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_93": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And also I'm not the only one who worked on this slide, so just to attribute this to the correct sources.",
                    "label": 0
                },
                {
                    "sent": "A lot of my colleagues also contributed to this leads.",
                    "label": 0
                }
            ]
        }
    }
}