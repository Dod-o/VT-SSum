{
    "id": "nrolbjhs66a3lumipdpnfmjph7qydoi6",
    "title": "A Fine-Grained Evaluation of SPARQL Endpoint Federation Systems",
    "info": {
        "author": [
            "Muhammad Saleem, Agile Knowledge Engineering and Semantic Web (AKSW), University of Leipzig"
        ],
        "published": "Nov. 10, 2016",
        "recorded": "October 2016",
        "category": [
            "Top->Computer Science->Semantic Web"
        ]
    },
    "url": "http://videolectures.net/iswc2016_saleem_federation_systems/",
    "segmentation": [
        [
            "Hello everybody, I'm going to present innovation of the sparkle endpoint filtration system.",
            "This is a Journal paper, so of course I cannot present everything, but I will try to present the most important results in this presentation."
        ],
        [
            "So here is the agenda for today's talk.",
            "First, I will talk about Sparkle Query Federation and then I will talk about some results of the survey about sparkle query processing systems.",
            "So we conducted actually a survey to get the information about in the feature about the sparkle query processing engine.",
            "And then I will talk about some performance variables that impact the performance of the Federated query and then in the last session I will talk about the sparkle endpoint, the evaluation results."
        ],
        [
            "So what are the approaches the general approaches for Federated sparkle query processing?",
            "So we have a three approaches.",
            "The first one is the Sparkle Endpoint Federation.",
            "So as the name suggest, we have a set of sparkle and points and we have a Federation engine and we have a Federated query so the Federation engine federate queries over the set of multiple sparkle endpoints.",
            "So we have some advantages pertaining to this approach because we have two optimization, the Federation engine can also optimize the query and we have another optimization at the sparkle endpoint, so it is well so generally this kind of Federation approaches can lead to fast query execution, but of course there is a downside of these approaches as well that most of the load data is not exposed as a sparkle endpoint.",
            "So we have another kind of Federation approaches which we called in Data Federation, or we also call it link traversal approaches.",
            "So in that the data shouldn't be exposed as a sparkle endpoint.",
            "If you have just a RDF data dumps, that's about the.",
            "You know the principles of the RDF.",
            "That's that's that's all for it.",
            "So that can cover like a lot of you know, data dumps.",
            "But of course you know that's based on the UI.",
            "Look up, so that can take some time.",
            "And then we have a hybrid approaches as well.",
            "So we have a set of sparkle and points and one side and we have a data dumps and there is a Federation engine that fed try to federate queries on top of both."
        ],
        [
            "So here is the paper is about the sparkle and perpetration approaches.",
            "I will just briefly show how the Sparkle Endpoint Federation works, so here we have a sparkle engine.",
            "This one this box is a sparkle engine and we have a set of sparkle endpoints, so let's suppose S1 to S4."
        ],
        [
            "And we have a given query from the user.",
            "So the first step is to."
        ],
        [
            "Far is the query, so in general in parsing what we get is to just get the individual triple patterns of the query."
        ],
        [
            "So once you get the individual triple patterns of the sparkle query the next.",
            "Step is the source selection, so the goal of the source selection is to identify what are the relevant or capable sources pertaining to each triple pattern.",
            "So here we need to specify which source is relevant for each individual triple pattern of the query."
        ],
        [
            "And then the Federated Query is one that that, should you know, collect results from more than one data set.",
            "And if you submit the complete query to each of the source, you cannot get you know results because the data is distributed.",
            "So to solve this you need to make sub queries of the big query and that is the job of the federator and then you need to optimize that.",
            "For example join order optimization.",
            "So once you get the subqueries there you need to.",
            "Send those subqueries and here the sources are already identified during the source selection, so you need to send those subqueries to the corresponding sparkle endpoints and that can be done in parallel, or that can be done in sequential depending upon the implementation."
        ],
        [
            "So he sparkle in point reply."
        ],
        [
            "And then you get the results back and then you have."
        ],
        [
            "Local data integration.",
            "So you integrate the results."
        ],
        [
            "And then send it back to the user.",
            "But the whole process is transparent to the user, so the user just submit the query and get the results back.",
            "But it doesn't know what happened in the background."
        ],
        [
            "So as I talk about source selection, that is to identify what are the relevant sources pertaining to a sparkle query.",
            "So there are three approaches that sort of generally used.",
            "So the first one is index free approach, so you don't have any index, no statistics, nothing about the datasets.",
            "So what in this approach that the only like most of the approaches using the sparkle ask queries.",
            "So for each ripple pattern you ask each of the source whether that contained results for the triple pattern yes or NO?",
            "So you just do the triple pattern by source selection.",
            "Using this worker, ask queries so this can potentially insure resultset completeness, because if you are using index the index can be outdated and once the index is out dated you cannot ensure the result set completeness, but here we don't use any index or the potentially can ensure resultset completeness.",
            "But the problem is this.",
            "A sparkle ask queries can be expensive as well, so if the number of sparkle ask queries are too much then the source selection time.",
            "Can be you know, increased.",
            "So here for this park, Alaska Nation can be used, for example, in the start you do sparkle, ask and then cache the results, and then the next time just check the cache and see like if you have a cache hit.",
            "Famous example is of this kind of source selection is in FedEx, which is a Federation engine.",
            "I will show the evaluation results later and then the second approach is index only.",
            "So we have only index and the complete source selection is based on index.",
            "So usually in index which we index the.",
            "Properties and then for each triple pattern, we just matched the predicates.",
            "If it's there in the index, then we select that source, otherwise we discarded.",
            "So this can be less efficient becausw.",
            "Mostly it only cares the predicates, but if the subject or object is bound then it usually overestimate the sources.",
            "Result set completeness is not insured.",
            "Becausw index can be outdated in famous examples are LHD and distributed IRQ."
        ],
        [
            "We have a third kind of source selection which is called hybrid, so which is a hybrid of Spark Alaskan index.",
            "So for some triple patterns, for example, if the subject and object is not bound in only the predicate is bound.",
            "So you can you can go directly, have a index look up and for the rest you can use Park Alaska.",
            "Very so depending upon.",
            "That is most efficient.",
            "In result set completeness is of course not insured because of the index and.",
            "Here also we can use the cache of the sparkle ask queries and famous examples are hibiscus in hepcidin.",
            "Ask blended."
        ],
        [
            "So now I'm talking about the server to the goal of this server was to collect information about existing Federation engine.",
            "So that's the first one is about the system in formation we collected like title and URL of the Federation and code whether the code is available in the implementation in licensing information and type of source selection and what kind of joint is used and whether the cash is used or not in whether there is a support for index update or not."
        ],
        [
            "So here is the result.",
            "I would just like to mention it's a bit hard to read from here, but I can show you know summary of that.",
            "But we can see here in the start we have the systems and then we have the category suspect sparkle and pointed Federation in Linked Data Federation and then the implementation.",
            "So for example we can see most of the systems are implemented in Java and here we can see the source selection.",
            "So most of them are using hybrid approach and here is the joint type.",
            "So bind join in his joints are commonly used.",
            "So here is."
        ],
        [
            "The summary, so the code availability.",
            "There are 59% of the Federation engine for which the source code is available."
        ],
        [
            "And then the type of source selection.",
            "So as I said, that majority of the sources are Federation engine are using hybrid sort selection approach.",
            "So there are 5665%.",
            "It will Federation engine that make use of the hybrid approach."
        ],
        [
            "And use of caching so it's like half of the systems are using caching."
        ],
        [
            "And weather is a support for index update so majority of them don't have any support for index update."
        ],
        [
            "And then we collect some information about the requirements.",
            "So for example the there confirm anymore requirements, but these are we picked as an important one, for example result set completeness and then the policy based query planning, which means that's like we are resuming that every time our data is open.",
            "But that's not the case like in some cases for example in medical domain the data is restricted and usually in hospitals or their data, so they have different you know.",
            "Policy level so different access level now whether there is a you know system that can deal with this kind of policy based query planning.",
            "And then we we ask about the support for partial result retrieval becausw it's possible that sometimes the query result is in million and the user might not be interested in all of the results, but a small and quick results might be more interested for the user.",
            "So then we talk about we ask about the adaptive query processing.",
            "Like sometimes the network traffic can influence the you know overall query performance or the sparkle endpoint can be busy.",
            "So whether they adopt the query plan and then we have support for provenance information and query runtime estimation and duplicate detection.",
            "So in top K query processing and support for sparkle important Sparkle features so."
        ],
        [
            "Here is the result."
        ],
        [
            "And here is the summary of the results.",
            "So for example result set completeness only 18% of the Federation engine ensure the result set completeness."
        ],
        [
            "Then the policy based query planning only fear of them or able to do this and then."
        ],
        [
            "The partial results retrieval are also not possible in many of them and then."
        ],
        [
            "The adaptive query for."
        ],
        [
            "Searching here we talk about provenance information so we can see that 94% don't give you any provenance information."
        ],
        [
            "So runtime estimation there is no Federation engine that can give you estimation of the runtime."
        ],
        [
            "And the duplicate detection and."
        ],
        [
            "On top K query processing."
        ],
        [
            "Here are some of the key features and that are, you know, that are that are supported by the various Federation engine."
        ],
        [
            "Here are some performance variables.",
            "Is a bit difficult to read, but I will try to.",
            "Edit or observer able which are performance metrics, for example number of our number of people pattern by sources or solution term very runtime.",
            "The answer complaint is in on the left side we have the independent variables that affect the performance metrics.",
            "For example in query the query shape and the basic triple veteran selectivity and intermediate results are those features that affect the.",
            "You know the dependent variable and then in the data we have the size frequency in these effects overall.",
            "And then of course in the platform, the Ram availability cash all these number of processors in in the end points we have endpoint type an initial delay in message size, this all affecting the result size is the perform."
        ],
        [
            "So here and are moving to the performance evaluation.",
            "We use three benchmarks so fair benches are famous of Federation benchmark.",
            "But this we also want to try the parallel querying capability of the Federation engine.",
            "So what we did is the problem is fed benches that it usually spend queries or one or two or three sources.",
            "So we want to, you know slice the data among different sources so that maximum number of sources are.",
            "Read it and so we slice that benchmark and then we have SP2 bench.",
            "So this is a triple Store benchmark but we Federated using slices in.",
            "Here is the Federation engine that we've all waited.",
            "So those are the engine by the time that code was available so that we can, you know, measure the performance matrices."
        ],
        [
            "Here is the result for the number of us so we can see the FedEx is the index free approach, so that's why the number of Sparkle asks are really high compared to the others and the 01 means that it's only index only approaches.",
            "And then the same goes for a week and see if we compare Fed bench with the slightest of the Fairbanks with the number of request increases because now the data is more partitioned."
        ],
        [
            "So here is the results of the triple pattern wise sources selected.",
            "In this case the NF set is the best engine that selects the minimum number of sources.",
            "So if you select minimum number of sources, that means you generate less network traffic in the intermediate results can be smaller as compared if you overestimated the sources."
        ],
        [
            "So here is the source election time, so we can see it.",
            "FedEx also make use of the cold and warm caching.",
            "So in the Cowlitz increase.",
            "But in the warm when the sparkle ask our cash then you know the the number goes significantly broke."
        ],
        [
            "And about resultset completeness, there are systems that says like we ensure the result set completeness, but in reality is not.",
            "For example in splendid like there are queries, for example LD one, the actual results is 2309 but we get 308 and then the LD 3 so far in LHD also 77 instead of 91.",
            "So here in our evaluation only FedEx gives complete results.",
            "But yeah, that's that's about the Fed bench evaluation.",
            "In the."
        ],
        [
            "Query runtime I'm presenting the here the the generalized results are generalized against the Fed bench and sliced bench.",
            "So which Federation engine is better?"
        ],
        [
            "So in 3rd bench the FedEx Warm is better in 25 out of 25 queries compared to FedEx Call and then the FedEx cold is better than LHD and then the LHD is better than splendid in an upset in distributed Air Cube."
        ],
        [
            "In Unsliced, bench, here are the results.",
            "So FedEx is the best system in terms of under query performance."
        ],
        [
            "And as I said that we want to measure the parallel query processing capability or the effect of data partitioning."
        ],
        [
            "So as I said, like if your data is distributed so you generate more network traffic and you you need to do more, you know query processing.",
            "So here we can see that when we slice the third bench then the most of the Federation engine, the performance is decreased as expected.",
            "But here for the distributed our Q it is increased.",
            "So when we investigated the reason, the reason is that the distributed IRQ make use of the nested loop joint, so it bombarded a single.",
            "Sparkle endpoints with two many number of requests, but now since the data is distributed so the number of requests was also distributed among the sparkle endpoints.",
            "So that's why the performance was increased."
        ],
        [
            "Yeah, that's all from my side.",
            "More details can be found in the paper.",
            "Thank you so much for your anticipation and now I'm open to take some questions.",
            "Alright, thank you very much."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Hello everybody, I'm going to present innovation of the sparkle endpoint filtration system.",
                    "label": 0
                },
                {
                    "sent": "This is a Journal paper, so of course I cannot present everything, but I will try to present the most important results in this presentation.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So here is the agenda for today's talk.",
                    "label": 0
                },
                {
                    "sent": "First, I will talk about Sparkle Query Federation and then I will talk about some results of the survey about sparkle query processing systems.",
                    "label": 1
                },
                {
                    "sent": "So we conducted actually a survey to get the information about in the feature about the sparkle query processing engine.",
                    "label": 0
                },
                {
                    "sent": "And then I will talk about some performance variables that impact the performance of the Federated query and then in the last session I will talk about the sparkle endpoint, the evaluation results.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So what are the approaches the general approaches for Federated sparkle query processing?",
                    "label": 0
                },
                {
                    "sent": "So we have a three approaches.",
                    "label": 0
                },
                {
                    "sent": "The first one is the Sparkle Endpoint Federation.",
                    "label": 1
                },
                {
                    "sent": "So as the name suggest, we have a set of sparkle and points and we have a Federation engine and we have a Federated query so the Federation engine federate queries over the set of multiple sparkle endpoints.",
                    "label": 0
                },
                {
                    "sent": "So we have some advantages pertaining to this approach because we have two optimization, the Federation engine can also optimize the query and we have another optimization at the sparkle endpoint, so it is well so generally this kind of Federation approaches can lead to fast query execution, but of course there is a downside of these approaches as well that most of the load data is not exposed as a sparkle endpoint.",
                    "label": 0
                },
                {
                    "sent": "So we have another kind of Federation approaches which we called in Data Federation, or we also call it link traversal approaches.",
                    "label": 0
                },
                {
                    "sent": "So in that the data shouldn't be exposed as a sparkle endpoint.",
                    "label": 0
                },
                {
                    "sent": "If you have just a RDF data dumps, that's about the.",
                    "label": 0
                },
                {
                    "sent": "You know the principles of the RDF.",
                    "label": 0
                },
                {
                    "sent": "That's that's that's all for it.",
                    "label": 0
                },
                {
                    "sent": "So that can cover like a lot of you know, data dumps.",
                    "label": 0
                },
                {
                    "sent": "But of course you know that's based on the UI.",
                    "label": 0
                },
                {
                    "sent": "Look up, so that can take some time.",
                    "label": 0
                },
                {
                    "sent": "And then we have a hybrid approaches as well.",
                    "label": 0
                },
                {
                    "sent": "So we have a set of sparkle and points and one side and we have a data dumps and there is a Federation engine that fed try to federate queries on top of both.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So here is the paper is about the sparkle and perpetration approaches.",
                    "label": 0
                },
                {
                    "sent": "I will just briefly show how the Sparkle Endpoint Federation works, so here we have a sparkle engine.",
                    "label": 1
                },
                {
                    "sent": "This one this box is a sparkle engine and we have a set of sparkle endpoints, so let's suppose S1 to S4.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we have a given query from the user.",
                    "label": 0
                },
                {
                    "sent": "So the first step is to.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Far is the query, so in general in parsing what we get is to just get the individual triple patterns of the query.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So once you get the individual triple patterns of the sparkle query the next.",
                    "label": 1
                },
                {
                    "sent": "Step is the source selection, so the goal of the source selection is to identify what are the relevant or capable sources pertaining to each triple pattern.",
                    "label": 1
                },
                {
                    "sent": "So here we need to specify which source is relevant for each individual triple pattern of the query.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then the Federated Query is one that that, should you know, collect results from more than one data set.",
                    "label": 0
                },
                {
                    "sent": "And if you submit the complete query to each of the source, you cannot get you know results because the data is distributed.",
                    "label": 0
                },
                {
                    "sent": "So to solve this you need to make sub queries of the big query and that is the job of the federator and then you need to optimize that.",
                    "label": 0
                },
                {
                    "sent": "For example join order optimization.",
                    "label": 0
                },
                {
                    "sent": "So once you get the subqueries there you need to.",
                    "label": 0
                },
                {
                    "sent": "Send those subqueries and here the sources are already identified during the source selection, so you need to send those subqueries to the corresponding sparkle endpoints and that can be done in parallel, or that can be done in sequential depending upon the implementation.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So he sparkle in point reply.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then you get the results back and then you have.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Local data integration.",
                    "label": 0
                },
                {
                    "sent": "So you integrate the results.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And then send it back to the user.",
                    "label": 0
                },
                {
                    "sent": "But the whole process is transparent to the user, so the user just submit the query and get the results back.",
                    "label": 1
                },
                {
                    "sent": "But it doesn't know what happened in the background.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So as I talk about source selection, that is to identify what are the relevant sources pertaining to a sparkle query.",
                    "label": 0
                },
                {
                    "sent": "So there are three approaches that sort of generally used.",
                    "label": 0
                },
                {
                    "sent": "So the first one is index free approach, so you don't have any index, no statistics, nothing about the datasets.",
                    "label": 0
                },
                {
                    "sent": "So what in this approach that the only like most of the approaches using the sparkle ask queries.",
                    "label": 0
                },
                {
                    "sent": "So for each ripple pattern you ask each of the source whether that contained results for the triple pattern yes or NO?",
                    "label": 0
                },
                {
                    "sent": "So you just do the triple pattern by source selection.",
                    "label": 0
                },
                {
                    "sent": "Using this worker, ask queries so this can potentially insure resultset completeness, because if you are using index the index can be outdated and once the index is out dated you cannot ensure the result set completeness, but here we don't use any index or the potentially can ensure resultset completeness.",
                    "label": 0
                },
                {
                    "sent": "But the problem is this.",
                    "label": 0
                },
                {
                    "sent": "A sparkle ask queries can be expensive as well, so if the number of sparkle ask queries are too much then the source selection time.",
                    "label": 1
                },
                {
                    "sent": "Can be you know, increased.",
                    "label": 0
                },
                {
                    "sent": "So here for this park, Alaska Nation can be used, for example, in the start you do sparkle, ask and then cache the results, and then the next time just check the cache and see like if you have a cache hit.",
                    "label": 0
                },
                {
                    "sent": "Famous example is of this kind of source selection is in FedEx, which is a Federation engine.",
                    "label": 0
                },
                {
                    "sent": "I will show the evaluation results later and then the second approach is index only.",
                    "label": 0
                },
                {
                    "sent": "So we have only index and the complete source selection is based on index.",
                    "label": 0
                },
                {
                    "sent": "So usually in index which we index the.",
                    "label": 0
                },
                {
                    "sent": "Properties and then for each triple pattern, we just matched the predicates.",
                    "label": 0
                },
                {
                    "sent": "If it's there in the index, then we select that source, otherwise we discarded.",
                    "label": 0
                },
                {
                    "sent": "So this can be less efficient becausw.",
                    "label": 0
                },
                {
                    "sent": "Mostly it only cares the predicates, but if the subject or object is bound then it usually overestimate the sources.",
                    "label": 1
                },
                {
                    "sent": "Result set completeness is not insured.",
                    "label": 0
                },
                {
                    "sent": "Becausw index can be outdated in famous examples are LHD and distributed IRQ.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We have a third kind of source selection which is called hybrid, so which is a hybrid of Spark Alaskan index.",
                    "label": 0
                },
                {
                    "sent": "So for some triple patterns, for example, if the subject and object is not bound in only the predicate is bound.",
                    "label": 0
                },
                {
                    "sent": "So you can you can go directly, have a index look up and for the rest you can use Park Alaska.",
                    "label": 0
                },
                {
                    "sent": "Very so depending upon.",
                    "label": 0
                },
                {
                    "sent": "That is most efficient.",
                    "label": 0
                },
                {
                    "sent": "In result set completeness is of course not insured because of the index and.",
                    "label": 1
                },
                {
                    "sent": "Here also we can use the cache of the sparkle ask queries and famous examples are hibiscus in hepcidin.",
                    "label": 0
                },
                {
                    "sent": "Ask blended.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So now I'm talking about the server to the goal of this server was to collect information about existing Federation engine.",
                    "label": 0
                },
                {
                    "sent": "So that's the first one is about the system in formation we collected like title and URL of the Federation and code whether the code is available in the implementation in licensing information and type of source selection and what kind of joint is used and whether the cash is used or not in whether there is a support for index update or not.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here is the result.",
                    "label": 0
                },
                {
                    "sent": "I would just like to mention it's a bit hard to read from here, but I can show you know summary of that.",
                    "label": 0
                },
                {
                    "sent": "But we can see here in the start we have the systems and then we have the category suspect sparkle and pointed Federation in Linked Data Federation and then the implementation.",
                    "label": 0
                },
                {
                    "sent": "So for example we can see most of the systems are implemented in Java and here we can see the source selection.",
                    "label": 0
                },
                {
                    "sent": "So most of them are using hybrid approach and here is the joint type.",
                    "label": 0
                },
                {
                    "sent": "So bind join in his joints are commonly used.",
                    "label": 0
                },
                {
                    "sent": "So here is.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The summary, so the code availability.",
                    "label": 0
                },
                {
                    "sent": "There are 59% of the Federation engine for which the source code is available.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then the type of source selection.",
                    "label": 0
                },
                {
                    "sent": "So as I said, that majority of the sources are Federation engine are using hybrid sort selection approach.",
                    "label": 0
                },
                {
                    "sent": "So there are 5665%.",
                    "label": 0
                },
                {
                    "sent": "It will Federation engine that make use of the hybrid approach.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And use of caching so it's like half of the systems are using caching.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And weather is a support for index update so majority of them don't have any support for index update.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And then we collect some information about the requirements.",
                    "label": 0
                },
                {
                    "sent": "So for example the there confirm anymore requirements, but these are we picked as an important one, for example result set completeness and then the policy based query planning, which means that's like we are resuming that every time our data is open.",
                    "label": 0
                },
                {
                    "sent": "But that's not the case like in some cases for example in medical domain the data is restricted and usually in hospitals or their data, so they have different you know.",
                    "label": 0
                },
                {
                    "sent": "Policy level so different access level now whether there is a you know system that can deal with this kind of policy based query planning.",
                    "label": 0
                },
                {
                    "sent": "And then we we ask about the support for partial result retrieval becausw it's possible that sometimes the query result is in million and the user might not be interested in all of the results, but a small and quick results might be more interested for the user.",
                    "label": 0
                },
                {
                    "sent": "So then we talk about we ask about the adaptive query processing.",
                    "label": 1
                },
                {
                    "sent": "Like sometimes the network traffic can influence the you know overall query performance or the sparkle endpoint can be busy.",
                    "label": 1
                },
                {
                    "sent": "So whether they adopt the query plan and then we have support for provenance information and query runtime estimation and duplicate detection.",
                    "label": 1
                },
                {
                    "sent": "So in top K query processing and support for sparkle important Sparkle features so.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here is the result.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And here is the summary of the results.",
                    "label": 0
                },
                {
                    "sent": "So for example result set completeness only 18% of the Federation engine ensure the result set completeness.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Then the policy based query planning only fear of them or able to do this and then.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The partial results retrieval are also not possible in many of them and then.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The adaptive query for.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Searching here we talk about provenance information so we can see that 94% don't give you any provenance information.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So runtime estimation there is no Federation engine that can give you estimation of the runtime.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And the duplicate detection and.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "On top K query processing.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here are some of the key features and that are, you know, that are that are supported by the various Federation engine.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here are some performance variables.",
                    "label": 0
                },
                {
                    "sent": "Is a bit difficult to read, but I will try to.",
                    "label": 0
                },
                {
                    "sent": "Edit or observer able which are performance metrics, for example number of our number of people pattern by sources or solution term very runtime.",
                    "label": 0
                },
                {
                    "sent": "The answer complaint is in on the left side we have the independent variables that affect the performance metrics.",
                    "label": 0
                },
                {
                    "sent": "For example in query the query shape and the basic triple veteran selectivity and intermediate results are those features that affect the.",
                    "label": 0
                },
                {
                    "sent": "You know the dependent variable and then in the data we have the size frequency in these effects overall.",
                    "label": 0
                },
                {
                    "sent": "And then of course in the platform, the Ram availability cash all these number of processors in in the end points we have endpoint type an initial delay in message size, this all affecting the result size is the perform.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here and are moving to the performance evaluation.",
                    "label": 0
                },
                {
                    "sent": "We use three benchmarks so fair benches are famous of Federation benchmark.",
                    "label": 0
                },
                {
                    "sent": "But this we also want to try the parallel querying capability of the Federation engine.",
                    "label": 0
                },
                {
                    "sent": "So what we did is the problem is fed benches that it usually spend queries or one or two or three sources.",
                    "label": 0
                },
                {
                    "sent": "So we want to, you know slice the data among different sources so that maximum number of sources are.",
                    "label": 0
                },
                {
                    "sent": "Read it and so we slice that benchmark and then we have SP2 bench.",
                    "label": 0
                },
                {
                    "sent": "So this is a triple Store benchmark but we Federated using slices in.",
                    "label": 0
                },
                {
                    "sent": "Here is the Federation engine that we've all waited.",
                    "label": 0
                },
                {
                    "sent": "So those are the engine by the time that code was available so that we can, you know, measure the performance matrices.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here is the result for the number of us so we can see the FedEx is the index free approach, so that's why the number of Sparkle asks are really high compared to the others and the 01 means that it's only index only approaches.",
                    "label": 0
                },
                {
                    "sent": "And then the same goes for a week and see if we compare Fed bench with the slightest of the Fairbanks with the number of request increases because now the data is more partitioned.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here is the results of the triple pattern wise sources selected.",
                    "label": 0
                },
                {
                    "sent": "In this case the NF set is the best engine that selects the minimum number of sources.",
                    "label": 0
                },
                {
                    "sent": "So if you select minimum number of sources, that means you generate less network traffic in the intermediate results can be smaller as compared if you overestimated the sources.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here is the source election time, so we can see it.",
                    "label": 0
                },
                {
                    "sent": "FedEx also make use of the cold and warm caching.",
                    "label": 0
                },
                {
                    "sent": "So in the Cowlitz increase.",
                    "label": 0
                },
                {
                    "sent": "But in the warm when the sparkle ask our cash then you know the the number goes significantly broke.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And about resultset completeness, there are systems that says like we ensure the result set completeness, but in reality is not.",
                    "label": 0
                },
                {
                    "sent": "For example in splendid like there are queries, for example LD one, the actual results is 2309 but we get 308 and then the LD 3 so far in LHD also 77 instead of 91.",
                    "label": 0
                },
                {
                    "sent": "So here in our evaluation only FedEx gives complete results.",
                    "label": 0
                },
                {
                    "sent": "But yeah, that's that's about the Fed bench evaluation.",
                    "label": 0
                },
                {
                    "sent": "In the.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Query runtime I'm presenting the here the the generalized results are generalized against the Fed bench and sliced bench.",
                    "label": 0
                },
                {
                    "sent": "So which Federation engine is better?",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So in 3rd bench the FedEx Warm is better in 25 out of 25 queries compared to FedEx Call and then the FedEx cold is better than LHD and then the LHD is better than splendid in an upset in distributed Air Cube.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In Unsliced, bench, here are the results.",
                    "label": 0
                },
                {
                    "sent": "So FedEx is the best system in terms of under query performance.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And as I said that we want to measure the parallel query processing capability or the effect of data partitioning.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So as I said, like if your data is distributed so you generate more network traffic and you you need to do more, you know query processing.",
                    "label": 0
                },
                {
                    "sent": "So here we can see that when we slice the third bench then the most of the Federation engine, the performance is decreased as expected.",
                    "label": 0
                },
                {
                    "sent": "But here for the distributed our Q it is increased.",
                    "label": 0
                },
                {
                    "sent": "So when we investigated the reason, the reason is that the distributed IRQ make use of the nested loop joint, so it bombarded a single.",
                    "label": 0
                },
                {
                    "sent": "Sparkle endpoints with two many number of requests, but now since the data is distributed so the number of requests was also distributed among the sparkle endpoints.",
                    "label": 0
                },
                {
                    "sent": "So that's why the performance was increased.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Yeah, that's all from my side.",
                    "label": 0
                },
                {
                    "sent": "More details can be found in the paper.",
                    "label": 0
                },
                {
                    "sent": "Thank you so much for your anticipation and now I'm open to take some questions.",
                    "label": 0
                },
                {
                    "sent": "Alright, thank you very much.",
                    "label": 0
                }
            ]
        }
    }
}