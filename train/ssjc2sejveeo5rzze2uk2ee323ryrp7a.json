{
    "id": "ssjc2sejveeo5rzze2uk2ee323ryrp7a",
    "title": "A Family of Penalty Functions for Structured Sparsity",
    "info": {
        "author": [
            "Jean Morales, Department of Computer Science, University College London"
        ],
        "published": "March 25, 2011",
        "recorded": "December 2010",
        "category": [
            "Top->Computer Science->Machine Learning->Regression"
        ]
    },
    "url": "http://videolectures.net/nips2010_morales_fpf/",
    "segmentation": [
        [
            "Thank you I'm Sommer Allison presenting a family of penalty functions so."
        ],
        [
            "The risers for vectors that are sparse and has some structure and this is joint work with Charles Michelia, Maximian open till so, we consider a linear model where the underlying vector beta star is known to be sparse.",
            "So in that case we found an estimate by minimizing the error term.",
            "The loss functions plus the L1 norm.",
            "This is the last technique and the starting point for our work is to use a variational formulation for DL1 norm.",
            "That is, Della Norm is the result of an Infinium optimization problem in a Doc Siri Vector Lambda which is constrained to be positive."
        ],
        [
            "So what we propose to do is to modify this function.",
            "And build their own Omega function which has an additional constraint so the auxiliary variable auxiliary vector is constrained to be inside set capital Lambda, which is a subset of the positive.",
            "Return them and the motivation for doing does is this key property that the function Omega is always strictly bigger than the yellow one norm and is exactly the same as the one norm if and only if the vector of the absolute values of beta inside.",
            "The constraint set capital Lambda.",
            "Is it could provide provide up a constraint or structure on the vector of absolute values and then the constraint is non convex that the absolute values bit are inside Lambda but the function Omega is convex.",
            "So we can solve the problem efficiently and they even have an alternating algorithm with minimizes with respect to beta and."
        ],
        [
            "Lambda, so there are several examples.",
            "Several possibilities for the choice of this set, capital, Lambda constraint set so we can embed the elements of the set in graph.",
            "So we have a hierarchical order, or indeed we can constraint the differences of the vector Lambda.",
            "The high order differences to be strictly positive.",
            "This could provide many different structures on the vector beta, so we have more examples.",
            "The poster we have theoretical properties of the function Omega and we have experimental results.",
            "So if you're interested, please do join us and post their W 2.",
            "Thank you very much."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Thank you I'm Sommer Allison presenting a family of penalty functions so.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The risers for vectors that are sparse and has some structure and this is joint work with Charles Michelia, Maximian open till so, we consider a linear model where the underlying vector beta star is known to be sparse.",
                    "label": 1
                },
                {
                    "sent": "So in that case we found an estimate by minimizing the error term.",
                    "label": 0
                },
                {
                    "sent": "The loss functions plus the L1 norm.",
                    "label": 0
                },
                {
                    "sent": "This is the last technique and the starting point for our work is to use a variational formulation for DL1 norm.",
                    "label": 1
                },
                {
                    "sent": "That is, Della Norm is the result of an Infinium optimization problem in a Doc Siri Vector Lambda which is constrained to be positive.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So what we propose to do is to modify this function.",
                    "label": 1
                },
                {
                    "sent": "And build their own Omega function which has an additional constraint so the auxiliary variable auxiliary vector is constrained to be inside set capital Lambda, which is a subset of the positive.",
                    "label": 0
                },
                {
                    "sent": "Return them and the motivation for doing does is this key property that the function Omega is always strictly bigger than the yellow one norm and is exactly the same as the one norm if and only if the vector of the absolute values of beta inside.",
                    "label": 0
                },
                {
                    "sent": "The constraint set capital Lambda.",
                    "label": 0
                },
                {
                    "sent": "Is it could provide provide up a constraint or structure on the vector of absolute values and then the constraint is non convex that the absolute values bit are inside Lambda but the function Omega is convex.",
                    "label": 1
                },
                {
                    "sent": "So we can solve the problem efficiently and they even have an alternating algorithm with minimizes with respect to beta and.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Lambda, so there are several examples.",
                    "label": 0
                },
                {
                    "sent": "Several possibilities for the choice of this set, capital, Lambda constraint set so we can embed the elements of the set in graph.",
                    "label": 1
                },
                {
                    "sent": "So we have a hierarchical order, or indeed we can constraint the differences of the vector Lambda.",
                    "label": 0
                },
                {
                    "sent": "The high order differences to be strictly positive.",
                    "label": 0
                },
                {
                    "sent": "This could provide many different structures on the vector beta, so we have more examples.",
                    "label": 0
                },
                {
                    "sent": "The poster we have theoretical properties of the function Omega and we have experimental results.",
                    "label": 0
                },
                {
                    "sent": "So if you're interested, please do join us and post their W 2.",
                    "label": 0
                },
                {
                    "sent": "Thank you very much.",
                    "label": 0
                }
            ]
        }
    }
}