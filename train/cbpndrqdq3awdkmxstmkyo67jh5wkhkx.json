{
    "id": "cbpndrqdq3awdkmxstmkyo67jh5wkhkx",
    "title": "DECAF: MEG-based Multimodal Database for Decoding Affective Physiological Responses",
    "info": {
        "author": [
            "Nicu Sebe, Department of Information Engineering and Computer Science (DISI), University of Trento"
        ],
        "published": "July 2, 2015",
        "recorded": "May 2015",
        "category": [
            "Top->Computer Science->Computer Vision->Face & Gesture Analysis",
            "Top->Computer Science->Computer Vision"
        ]
    },
    "url": "http://videolectures.net/fgconference2015_sebe_physiological_responses/",
    "segmentation": [
        [
            "I'm going to present your decaf so the idea of this of this work is to provide an alternative for people who want to investigate emotional responses too.",
            "To people viewing emotional videos.",
            "OK, So what we wanted to do.",
            "We were using this emoji device that we have at University of Trento tour together with our colleagues from.",
            "Note informatics operatory and you wanted to show that using these signals you could still get important affective cues for the content that we are running."
        ],
        [
            "Rising so in the state of the art for doing such things, people are looking at facial expressions, right?",
            "So they have facial videos.",
            "They they have physiological signals.",
            "They may look at their behavior in some way and they're also looking embrace signals.",
            "And then, of course, the standard know nowadays is to use EG.",
            "And you see something like like that, so you have that nice looking stuff that you are supposed to put on top of your head.",
            "And we were saying, well, but this is not very natural, right?",
            "So especially if you have to say.",
            "And and and look at some videos for an hour, an hour and a half.",
            "Maybe it's not.",
            "It's not very comfortable, so we were thinking why not trying to find an alternative."
        ],
        [
            "So in the literature, so there are several datasets trying to do this, so I'm relating to these two works which are very relevant to us.",
            "So one is a deep data set and there they had EG brain signal, physiological signals and facial videos.",
            "Another alternative it's man.",
            "Hope datasets practically done by the same group of people and they also have brain signal, physiological signal, eye gaze and facial videos.",
            "OK so I will not."
        ],
        [
            "That he was well, given that we have all these limitation right?",
            "So some of these sensors.",
            "Are they invasive, I would say.",
            "And then we'll all, of course, will limit the analysis to kind of short time interval and small user population.",
            "Amy G is less invasive.",
            "While you would say, well, maybe it's still kind of, you know, unnatural in some way, but at least you are saying you are sitting in a sort of an arm chair and you have this coil.",
            "Which kind of gets close to your head, but you have no physical contact.",
            "So in this part from this point of view, it's definitely more comfort rible.",
            "And then the user response is we believe is less affected by the physiological stressors enabling this nationalistic experience.",
            "And we were also looking at so in decaf.",
            "In deep they were looking at movie video clips.",
            "We were saying, well, maybe we can augment this using also movies.",
            "So what we have in decaf?",
            "So we have a data set comprising conquerant, recording of image signal.",
            "We also have physiological signals, so then we can show if they are complementary.",
            "If they can help together and near infrared facial video.",
            "Yesterday it was a question somebody asked me.",
            "Well, why do you really use near infrared?",
            "Well, it was not really a matter of choice because since we are dealing with with magnetic fields, regular camera will not work in this environment.",
            "So we had this particular camera that it was very.",
            "It is well shielded and so on.",
            "So we didn't have much much choice in here.",
            "What we have, we have certain subjects.",
            "And we had the 40 music clips from the deep data set plus 36 movie clips that we have collected right?",
            "And we were looking at subject while the subject we're looking at at emotional video clips."
        ],
        [
            "So let's let's hear comparison between MG and EG right?",
            "So it has been shown by cool Strat all and that this EG effectively encodes emotional response of the human to music video.",
            "And our assumption, our hypothesis would be that, well, maybe Emaji will do the same, OK?",
            "Both EG and MG are very high temporal resolution, right?",
            "So you have one to five kilohertz, so it's quite a lot.",
            "EG sends out of course is much cheaper and it is somehow more invasive.",
            "As I said, right?",
            "So you have that funny looking hats.",
            "Do you have to put on top of your of your head?",
            "Images More is far more accurate and then gives a very good spatial resolution of the brain responses, right?",
            "So you have 306 channels.",
            "I'm going to show in the next slides how these channels are distributed.",
            "You could also do with me G. Brain activity socialization and this has been shown to work pretty good and we believe that is less invasive, right?",
            "So you see here this is a view from the from down.",
            "So practically you are in an arm chair.",
            "You have this this coil on top of on top of your head but it's not physical contact and you just stay and look at the screen that is in front of you."
        ],
        [
            "OK, so is there any just signal?",
            "I'm not going into very much details, but practically what you have.",
            "You have this 306 channel so they are they are getting so their magnetic matters and you have them oriented at different areas so you have the occipitale ZAP Oriental, the temporal parts and the frontal right so left and right.",
            "And this is compared to the EG which has like 32 channels."
        ],
        [
            "OK, so So what did what we said we have so we have also time continuous recordist recording of head pose indicators right?",
            "So this is A3 hard signal to locate the exact pose of the head under the emoji.",
            "We have the 3D scan of the user head shape for all the users, so this is also for the source localization as a kind of thing.",
            "So since we do it, we said why not.",
            "And then we also have the MRI scans of the 50 of 15 users from source brain activity analysis, right?",
            "So all these kind of things are available for four people, so this one is not is not yet available online, but we are working on it to to kind of standard item to put it online."
        ],
        [
            "That stimuli, so we have the we have 40 music video clips of the one that had been used in in the deep data set.",
            "And so they are about 10 minutes long, which is a highlight for each music video clip and for the movies we have services, movies of varying length, right more or less around a minute and a half.",
            "And they were based on a preliminary study where is a pool of 50.",
            "So we started with 58 clips and then we had 42 graduate students who were asked to label them.",
            "So our idea was that, well, we wanted to have some representative movies that are in all these four quadrants, so means.",
            "Yet we have more or less a balance set for for the movies as well, right?",
            "So we have."
        ],
        [
            "Movies like so we have a sequence from The Exorcist, so it's it's quite disgusting.",
            "For example, there is something from the hangover Love Actually.",
            "So there are in the paper there is a list of all these movies, so we didn't take them randomly.",
            "Some of them are already reported in the in the literature for evoking this emotional responses.",
            "And then we have some other ones that we had picked somehow.",
            "OK, so how we did the experiment, so we have certain subjects so that 16 male and 14 females.",
            "So they were all more or less to graduate students and so we had this 76 stimuli and we were recording the energy brain signal.",
            "The ECG we had, horizontal, EOG, trapezius, EMG and near infrared facial videos.",
            "So we had all these things to say.",
            "Well why not?",
            "I mean, since we do this analysis, why not just provide all these things so people can just play around with the data?"
        ],
        [
            "So we were looking at at arousal valence, dominance and familiarity, so we were also wanted to see if you have seen the video before.",
            "So if you know what the movie is about, for example, would you have a different reaction or not?"
        ],
        [
            "As as a protocol, So what we had so is.",
            "This would take about it, considering that we have 76 clips will take about an hour and a half, so we also wanted to have to make sure that people will not get tired.",
            "So we wanted to to avoid all this kind of of bias, so we had.",
            "A little bit of calibration parts.",
            "Then we presented the clip after seeing the clip, we also users to evaluate the arousal and valence.",
            "So this is we have the scale from 1 to 5, so very counter.",
            "Very excited or very negative, so very positive.",
            "We were asking about the dominance and the film familiarity rating, right?",
            "So if you've seen the video before never few times many times OK and then we were just keep on going like that.",
            "We also had a 15 minute break.",
            "So just to have a little bit of to give the.",
            "It's in the little bit of time to relax."
        ],
        [
            "So for the distribution of the self assessment ratings, as you can see, we tried it to have more or less on UU distribution in all these quadrants.",
            "So this is for the movie video clip.",
            "This is for music video clip so so this is taken from from the deep data set.",
            "Here are our annotations is not always well separated, but still we wanted to see.",
            "Well, maybe maybe this ones will be will be quite representative for this quadrants."
        ],
        [
            "OK so far is a psycho physiological signals.",
            "As I said before, we had this physiological thing, so it's also coming so with the with the MG we were also doing this this recording."
        ],
        [
            "We were also interested in looking at the correlations between MG and emotions that these are some examples, so this is, well, it's it's.",
            "It's a top view of the overhead right.",
            "You see the years and the notes in here.",
            "This would be so.",
            "This is this.",
            "What indicates here is experiment.",
            "Correlation analysis between this image responses and the particle self assessment.",
            "And we we we notice that there is some some reasonable correlation between these two things, right?",
            "So there is hope for for, for getting some analysis you will see in my in the results when I'm presenting that the numbers are not so incredible, so it's still a lot of things to do.",
            "But we believe that if you provide them to the Community community can just take them over and and try to to improve the results on this."
        ],
        [
            "So so here what we were looking at.",
            "OK, so these are the reasons that we have, so the curacy FF1 measure.",
            "This is for the movie clips for the, so this is in population based analysis.",
            "You see that we have.",
            "I think I have it in the OK so we have some significant results for some of the information.",
            "Not for all of them.",
            "This is given more information for the movies than for the music video clips.",
            "Which makes sense because we believe these movies are really created to invoke more emotions.",
            "You can also see that you have more correlation.",
            "We should do this population based analysis that then subject based analysis.",
            "And then we were also looking at doing Fusion.",
            "So if you would just take signals from Amy G only and then.",
            "Physiological physiological signals or facial expression and trying to do late Fusion consignments and the results are much, much better than before, right?",
            "So so practically all this information are complementary.",
            "Great."
        ],
        [
            "Just over to provide also baseline.",
            "We were also looking at continuous emotion estimations of what we also have in the data set.",
            "I didn't put a slide in here.",
            "We also ask the users not all the not all the annotated, but some of them too.",
            "They had a slider so they could also continuously annotate the violence in the in the in the arousal of the of the clip, while the the clip was playing right.",
            "So you could you could have continuous annotation.",
            "And we were also doing some work it as learning analysis.",
            "So here a task will be every single clip.",
            "So you want you to do optimization over all the clips.",
            "So this is what I have here is the root mean square error for.",
            "So the first part will be in the first part of the movie.",
            "This would be somewhere in the middle of the movie, just to show that indeed, because some of the emotion parts are happening at the end of the movie.",
            "So for some of the movies that's important, and here we are just learning with multi task learning.",
            "What will be the weights for arousal and valence for the movie clips using different methods for multi touch learning?",
            "Right, so these results are also we provide them as as a baseline for for you guys.",
            "If you want to look into that."
        ],
        [
            "OK, so just to to conclude.",
            "So this is so far the largest multimodal affective data set with me G. Having got stuff ready for an official responses so we have over 2K samples.",
            "It's suitable for cognitive science, natural stimuli studies.",
            "So we have this time continuous HP.",
            "I recorded head shape models, recording of artifacts, so ECG T, median age, EOG, and we have the Amber scans and we also have the time, continuous violence and arousal labels for the septic movie clips.",
            "So the data set is available here.",
            "We we didn't put the raw signal, so you will have to email a sense that we can ship it to you.",
            "The problem is that's just it's, it's it's, it's that we have so much signal that a single of a second of signal is about one terabyte, right?",
            "So the raw signal, so it's it's quite a lot.",
            "So what we did and that's it.",
            "This is what is available.",
            "Actually we have some preprocessed features, right?",
            "So you can do some PCA.",
            "You can do some so you can.",
            "You can do a lot of signal processing on that.",
            "My students have been working quite a lot in trying to do all these tricks.",
            "How do you go from this huge amount of data to something shorter?",
            "I think we obtain reasonable result, but probably there is a lot of margin for improvement and before concluding here, I would say that we had a lot of discussion with colleagues from the Cognitive Neuroscience Department and because of the beginning and even now probably they said that this type of analysis nonsense, right?",
            "Because we treat the brain like a black box.",
            "We have the.",
            "The stimuli and then we just to look at the signals outside while they just want to understand why things are happening in the brain, which region and so on right for us?",
            "Well, at this stimuli are far more complex, So what they look at our colleagues, they just have some very very simple.",
            "I don't know red ball moving up and down for example.",
            "In that case they can get really the localizations of signal.",
            "Of course, if you have movie or or music clip as a stimulus is so complex that you cannot really understand what's going on in there.",
            "So, but where we are engineers and then we said, well, we still want to do it and.",
            "Well, we have some buddies and other results so.",
            "OK thanks."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I'm going to present your decaf so the idea of this of this work is to provide an alternative for people who want to investigate emotional responses too.",
                    "label": 0
                },
                {
                    "sent": "To people viewing emotional videos.",
                    "label": 0
                },
                {
                    "sent": "OK, So what we wanted to do.",
                    "label": 0
                },
                {
                    "sent": "We were using this emoji device that we have at University of Trento tour together with our colleagues from.",
                    "label": 1
                },
                {
                    "sent": "Note informatics operatory and you wanted to show that using these signals you could still get important affective cues for the content that we are running.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Rising so in the state of the art for doing such things, people are looking at facial expressions, right?",
                    "label": 1
                },
                {
                    "sent": "So they have facial videos.",
                    "label": 1
                },
                {
                    "sent": "They they have physiological signals.",
                    "label": 0
                },
                {
                    "sent": "They may look at their behavior in some way and they're also looking embrace signals.",
                    "label": 0
                },
                {
                    "sent": "And then, of course, the standard know nowadays is to use EG.",
                    "label": 0
                },
                {
                    "sent": "And you see something like like that, so you have that nice looking stuff that you are supposed to put on top of your head.",
                    "label": 0
                },
                {
                    "sent": "And we were saying, well, but this is not very natural, right?",
                    "label": 0
                },
                {
                    "sent": "So especially if you have to say.",
                    "label": 0
                },
                {
                    "sent": "And and and look at some videos for an hour, an hour and a half.",
                    "label": 0
                },
                {
                    "sent": "Maybe it's not.",
                    "label": 0
                },
                {
                    "sent": "It's not very comfortable, so we were thinking why not trying to find an alternative.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So in the literature, so there are several datasets trying to do this, so I'm relating to these two works which are very relevant to us.",
                    "label": 0
                },
                {
                    "sent": "So one is a deep data set and there they had EG brain signal, physiological signals and facial videos.",
                    "label": 1
                },
                {
                    "sent": "Another alternative it's man.",
                    "label": 1
                },
                {
                    "sent": "Hope datasets practically done by the same group of people and they also have brain signal, physiological signal, eye gaze and facial videos.",
                    "label": 0
                },
                {
                    "sent": "OK so I will not.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "That he was well, given that we have all these limitation right?",
                    "label": 0
                },
                {
                    "sent": "So some of these sensors.",
                    "label": 0
                },
                {
                    "sent": "Are they invasive, I would say.",
                    "label": 0
                },
                {
                    "sent": "And then we'll all, of course, will limit the analysis to kind of short time interval and small user population.",
                    "label": 1
                },
                {
                    "sent": "Amy G is less invasive.",
                    "label": 0
                },
                {
                    "sent": "While you would say, well, maybe it's still kind of, you know, unnatural in some way, but at least you are saying you are sitting in a sort of an arm chair and you have this coil.",
                    "label": 0
                },
                {
                    "sent": "Which kind of gets close to your head, but you have no physical contact.",
                    "label": 0
                },
                {
                    "sent": "So in this part from this point of view, it's definitely more comfort rible.",
                    "label": 0
                },
                {
                    "sent": "And then the user response is we believe is less affected by the physiological stressors enabling this nationalistic experience.",
                    "label": 1
                },
                {
                    "sent": "And we were also looking at so in decaf.",
                    "label": 0
                },
                {
                    "sent": "In deep they were looking at movie video clips.",
                    "label": 0
                },
                {
                    "sent": "We were saying, well, maybe we can augment this using also movies.",
                    "label": 0
                },
                {
                    "sent": "So what we have in decaf?",
                    "label": 0
                },
                {
                    "sent": "So we have a data set comprising conquerant, recording of image signal.",
                    "label": 0
                },
                {
                    "sent": "We also have physiological signals, so then we can show if they are complementary.",
                    "label": 0
                },
                {
                    "sent": "If they can help together and near infrared facial video.",
                    "label": 0
                },
                {
                    "sent": "Yesterday it was a question somebody asked me.",
                    "label": 0
                },
                {
                    "sent": "Well, why do you really use near infrared?",
                    "label": 0
                },
                {
                    "sent": "Well, it was not really a matter of choice because since we are dealing with with magnetic fields, regular camera will not work in this environment.",
                    "label": 0
                },
                {
                    "sent": "So we had this particular camera that it was very.",
                    "label": 0
                },
                {
                    "sent": "It is well shielded and so on.",
                    "label": 1
                },
                {
                    "sent": "So we didn't have much much choice in here.",
                    "label": 0
                },
                {
                    "sent": "What we have, we have certain subjects.",
                    "label": 1
                },
                {
                    "sent": "And we had the 40 music clips from the deep data set plus 36 movie clips that we have collected right?",
                    "label": 0
                },
                {
                    "sent": "And we were looking at subject while the subject we're looking at at emotional video clips.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So let's let's hear comparison between MG and EG right?",
                    "label": 0
                },
                {
                    "sent": "So it has been shown by cool Strat all and that this EG effectively encodes emotional response of the human to music video.",
                    "label": 1
                },
                {
                    "sent": "And our assumption, our hypothesis would be that, well, maybe Emaji will do the same, OK?",
                    "label": 1
                },
                {
                    "sent": "Both EG and MG are very high temporal resolution, right?",
                    "label": 1
                },
                {
                    "sent": "So you have one to five kilohertz, so it's quite a lot.",
                    "label": 0
                },
                {
                    "sent": "EG sends out of course is much cheaper and it is somehow more invasive.",
                    "label": 0
                },
                {
                    "sent": "As I said, right?",
                    "label": 0
                },
                {
                    "sent": "So you have that funny looking hats.",
                    "label": 0
                },
                {
                    "sent": "Do you have to put on top of your of your head?",
                    "label": 1
                },
                {
                    "sent": "Images More is far more accurate and then gives a very good spatial resolution of the brain responses, right?",
                    "label": 1
                },
                {
                    "sent": "So you have 306 channels.",
                    "label": 0
                },
                {
                    "sent": "I'm going to show in the next slides how these channels are distributed.",
                    "label": 0
                },
                {
                    "sent": "You could also do with me G. Brain activity socialization and this has been shown to work pretty good and we believe that is less invasive, right?",
                    "label": 0
                },
                {
                    "sent": "So you see here this is a view from the from down.",
                    "label": 0
                },
                {
                    "sent": "So practically you are in an arm chair.",
                    "label": 0
                },
                {
                    "sent": "You have this this coil on top of on top of your head but it's not physical contact and you just stay and look at the screen that is in front of you.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so is there any just signal?",
                    "label": 0
                },
                {
                    "sent": "I'm not going into very much details, but practically what you have.",
                    "label": 0
                },
                {
                    "sent": "You have this 306 channel so they are they are getting so their magnetic matters and you have them oriented at different areas so you have the occipitale ZAP Oriental, the temporal parts and the frontal right so left and right.",
                    "label": 0
                },
                {
                    "sent": "And this is compared to the EG which has like 32 channels.",
                    "label": 1
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so So what did what we said we have so we have also time continuous recordist recording of head pose indicators right?",
                    "label": 0
                },
                {
                    "sent": "So this is A3 hard signal to locate the exact pose of the head under the emoji.",
                    "label": 1
                },
                {
                    "sent": "We have the 3D scan of the user head shape for all the users, so this is also for the source localization as a kind of thing.",
                    "label": 0
                },
                {
                    "sent": "So since we do it, we said why not.",
                    "label": 0
                },
                {
                    "sent": "And then we also have the MRI scans of the 50 of 15 users from source brain activity analysis, right?",
                    "label": 0
                },
                {
                    "sent": "So all these kind of things are available for four people, so this one is not is not yet available online, but we are working on it to to kind of standard item to put it online.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "That stimuli, so we have the we have 40 music video clips of the one that had been used in in the deep data set.",
                    "label": 1
                },
                {
                    "sent": "And so they are about 10 minutes long, which is a highlight for each music video clip and for the movies we have services, movies of varying length, right more or less around a minute and a half.",
                    "label": 1
                },
                {
                    "sent": "And they were based on a preliminary study where is a pool of 50.",
                    "label": 1
                },
                {
                    "sent": "So we started with 58 clips and then we had 42 graduate students who were asked to label them.",
                    "label": 0
                },
                {
                    "sent": "So our idea was that, well, we wanted to have some representative movies that are in all these four quadrants, so means.",
                    "label": 0
                },
                {
                    "sent": "Yet we have more or less a balance set for for the movies as well, right?",
                    "label": 0
                },
                {
                    "sent": "So we have.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Movies like so we have a sequence from The Exorcist, so it's it's quite disgusting.",
                    "label": 0
                },
                {
                    "sent": "For example, there is something from the hangover Love Actually.",
                    "label": 0
                },
                {
                    "sent": "So there are in the paper there is a list of all these movies, so we didn't take them randomly.",
                    "label": 0
                },
                {
                    "sent": "Some of them are already reported in the in the literature for evoking this emotional responses.",
                    "label": 0
                },
                {
                    "sent": "And then we have some other ones that we had picked somehow.",
                    "label": 0
                },
                {
                    "sent": "OK, so how we did the experiment, so we have certain subjects so that 16 male and 14 females.",
                    "label": 0
                },
                {
                    "sent": "So they were all more or less to graduate students and so we had this 76 stimuli and we were recording the energy brain signal.",
                    "label": 0
                },
                {
                    "sent": "The ECG we had, horizontal, EOG, trapezius, EMG and near infrared facial videos.",
                    "label": 1
                },
                {
                    "sent": "So we had all these things to say.",
                    "label": 0
                },
                {
                    "sent": "Well why not?",
                    "label": 0
                },
                {
                    "sent": "I mean, since we do this analysis, why not just provide all these things so people can just play around with the data?",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we were looking at at arousal valence, dominance and familiarity, so we were also wanted to see if you have seen the video before.",
                    "label": 0
                },
                {
                    "sent": "So if you know what the movie is about, for example, would you have a different reaction or not?",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "As as a protocol, So what we had so is.",
                    "label": 0
                },
                {
                    "sent": "This would take about it, considering that we have 76 clips will take about an hour and a half, so we also wanted to have to make sure that people will not get tired.",
                    "label": 0
                },
                {
                    "sent": "So we wanted to to avoid all this kind of of bias, so we had.",
                    "label": 0
                },
                {
                    "sent": "A little bit of calibration parts.",
                    "label": 0
                },
                {
                    "sent": "Then we presented the clip after seeing the clip, we also users to evaluate the arousal and valence.",
                    "label": 0
                },
                {
                    "sent": "So this is we have the scale from 1 to 5, so very counter.",
                    "label": 0
                },
                {
                    "sent": "Very excited or very negative, so very positive.",
                    "label": 1
                },
                {
                    "sent": "We were asking about the dominance and the film familiarity rating, right?",
                    "label": 0
                },
                {
                    "sent": "So if you've seen the video before never few times many times OK and then we were just keep on going like that.",
                    "label": 0
                },
                {
                    "sent": "We also had a 15 minute break.",
                    "label": 0
                },
                {
                    "sent": "So just to have a little bit of to give the.",
                    "label": 0
                },
                {
                    "sent": "It's in the little bit of time to relax.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So for the distribution of the self assessment ratings, as you can see, we tried it to have more or less on UU distribution in all these quadrants.",
                    "label": 0
                },
                {
                    "sent": "So this is for the movie video clip.",
                    "label": 0
                },
                {
                    "sent": "This is for music video clip so so this is taken from from the deep data set.",
                    "label": 0
                },
                {
                    "sent": "Here are our annotations is not always well separated, but still we wanted to see.",
                    "label": 0
                },
                {
                    "sent": "Well, maybe maybe this ones will be will be quite representative for this quadrants.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK so far is a psycho physiological signals.",
                    "label": 0
                },
                {
                    "sent": "As I said before, we had this physiological thing, so it's also coming so with the with the MG we were also doing this this recording.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We were also interested in looking at the correlations between MG and emotions that these are some examples, so this is, well, it's it's.",
                    "label": 0
                },
                {
                    "sent": "It's a top view of the overhead right.",
                    "label": 0
                },
                {
                    "sent": "You see the years and the notes in here.",
                    "label": 0
                },
                {
                    "sent": "This would be so.",
                    "label": 0
                },
                {
                    "sent": "This is this.",
                    "label": 0
                },
                {
                    "sent": "What indicates here is experiment.",
                    "label": 0
                },
                {
                    "sent": "Correlation analysis between this image responses and the particle self assessment.",
                    "label": 0
                },
                {
                    "sent": "And we we we notice that there is some some reasonable correlation between these two things, right?",
                    "label": 0
                },
                {
                    "sent": "So there is hope for for, for getting some analysis you will see in my in the results when I'm presenting that the numbers are not so incredible, so it's still a lot of things to do.",
                    "label": 0
                },
                {
                    "sent": "But we believe that if you provide them to the Community community can just take them over and and try to to improve the results on this.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So so here what we were looking at.",
                    "label": 0
                },
                {
                    "sent": "OK, so these are the reasons that we have, so the curacy FF1 measure.",
                    "label": 0
                },
                {
                    "sent": "This is for the movie clips for the, so this is in population based analysis.",
                    "label": 0
                },
                {
                    "sent": "You see that we have.",
                    "label": 0
                },
                {
                    "sent": "I think I have it in the OK so we have some significant results for some of the information.",
                    "label": 0
                },
                {
                    "sent": "Not for all of them.",
                    "label": 0
                },
                {
                    "sent": "This is given more information for the movies than for the music video clips.",
                    "label": 0
                },
                {
                    "sent": "Which makes sense because we believe these movies are really created to invoke more emotions.",
                    "label": 0
                },
                {
                    "sent": "You can also see that you have more correlation.",
                    "label": 0
                },
                {
                    "sent": "We should do this population based analysis that then subject based analysis.",
                    "label": 0
                },
                {
                    "sent": "And then we were also looking at doing Fusion.",
                    "label": 0
                },
                {
                    "sent": "So if you would just take signals from Amy G only and then.",
                    "label": 0
                },
                {
                    "sent": "Physiological physiological signals or facial expression and trying to do late Fusion consignments and the results are much, much better than before, right?",
                    "label": 0
                },
                {
                    "sent": "So so practically all this information are complementary.",
                    "label": 0
                },
                {
                    "sent": "Great.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Just over to provide also baseline.",
                    "label": 0
                },
                {
                    "sent": "We were also looking at continuous emotion estimations of what we also have in the data set.",
                    "label": 0
                },
                {
                    "sent": "I didn't put a slide in here.",
                    "label": 0
                },
                {
                    "sent": "We also ask the users not all the not all the annotated, but some of them too.",
                    "label": 0
                },
                {
                    "sent": "They had a slider so they could also continuously annotate the violence in the in the in the arousal of the of the clip, while the the clip was playing right.",
                    "label": 0
                },
                {
                    "sent": "So you could you could have continuous annotation.",
                    "label": 0
                },
                {
                    "sent": "And we were also doing some work it as learning analysis.",
                    "label": 0
                },
                {
                    "sent": "So here a task will be every single clip.",
                    "label": 0
                },
                {
                    "sent": "So you want you to do optimization over all the clips.",
                    "label": 0
                },
                {
                    "sent": "So this is what I have here is the root mean square error for.",
                    "label": 0
                },
                {
                    "sent": "So the first part will be in the first part of the movie.",
                    "label": 0
                },
                {
                    "sent": "This would be somewhere in the middle of the movie, just to show that indeed, because some of the emotion parts are happening at the end of the movie.",
                    "label": 0
                },
                {
                    "sent": "So for some of the movies that's important, and here we are just learning with multi task learning.",
                    "label": 0
                },
                {
                    "sent": "What will be the weights for arousal and valence for the movie clips using different methods for multi touch learning?",
                    "label": 1
                },
                {
                    "sent": "Right, so these results are also we provide them as as a baseline for for you guys.",
                    "label": 0
                },
                {
                    "sent": "If you want to look into that.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so just to to conclude.",
                    "label": 0
                },
                {
                    "sent": "So this is so far the largest multimodal affective data set with me G. Having got stuff ready for an official responses so we have over 2K samples.",
                    "label": 1
                },
                {
                    "sent": "It's suitable for cognitive science, natural stimuli studies.",
                    "label": 0
                },
                {
                    "sent": "So we have this time continuous HP.",
                    "label": 0
                },
                {
                    "sent": "I recorded head shape models, recording of artifacts, so ECG T, median age, EOG, and we have the Amber scans and we also have the time, continuous violence and arousal labels for the septic movie clips.",
                    "label": 1
                },
                {
                    "sent": "So the data set is available here.",
                    "label": 0
                },
                {
                    "sent": "We we didn't put the raw signal, so you will have to email a sense that we can ship it to you.",
                    "label": 0
                },
                {
                    "sent": "The problem is that's just it's, it's it's, it's that we have so much signal that a single of a second of signal is about one terabyte, right?",
                    "label": 0
                },
                {
                    "sent": "So the raw signal, so it's it's quite a lot.",
                    "label": 0
                },
                {
                    "sent": "So what we did and that's it.",
                    "label": 0
                },
                {
                    "sent": "This is what is available.",
                    "label": 0
                },
                {
                    "sent": "Actually we have some preprocessed features, right?",
                    "label": 0
                },
                {
                    "sent": "So you can do some PCA.",
                    "label": 0
                },
                {
                    "sent": "You can do some so you can.",
                    "label": 0
                },
                {
                    "sent": "You can do a lot of signal processing on that.",
                    "label": 0
                },
                {
                    "sent": "My students have been working quite a lot in trying to do all these tricks.",
                    "label": 0
                },
                {
                    "sent": "How do you go from this huge amount of data to something shorter?",
                    "label": 0
                },
                {
                    "sent": "I think we obtain reasonable result, but probably there is a lot of margin for improvement and before concluding here, I would say that we had a lot of discussion with colleagues from the Cognitive Neuroscience Department and because of the beginning and even now probably they said that this type of analysis nonsense, right?",
                    "label": 0
                },
                {
                    "sent": "Because we treat the brain like a black box.",
                    "label": 0
                },
                {
                    "sent": "We have the.",
                    "label": 0
                },
                {
                    "sent": "The stimuli and then we just to look at the signals outside while they just want to understand why things are happening in the brain, which region and so on right for us?",
                    "label": 0
                },
                {
                    "sent": "Well, at this stimuli are far more complex, So what they look at our colleagues, they just have some very very simple.",
                    "label": 0
                },
                {
                    "sent": "I don't know red ball moving up and down for example.",
                    "label": 0
                },
                {
                    "sent": "In that case they can get really the localizations of signal.",
                    "label": 0
                },
                {
                    "sent": "Of course, if you have movie or or music clip as a stimulus is so complex that you cannot really understand what's going on in there.",
                    "label": 0
                },
                {
                    "sent": "So, but where we are engineers and then we said, well, we still want to do it and.",
                    "label": 0
                },
                {
                    "sent": "Well, we have some buddies and other results so.",
                    "label": 0
                },
                {
                    "sent": "OK thanks.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": []
        }
    }
}