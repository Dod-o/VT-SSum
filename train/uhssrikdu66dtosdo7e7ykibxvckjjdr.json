{
    "id": "uhssrikdu66dtosdo7e7ykibxvckjjdr",
    "title": "Bounded regret in stochastic multi-armed bandits",
    "info": {
        "author": [
            "S\u00e9bastien Bubeck, Department of Operations Research and Financial Engineering, Princeton University"
        ],
        "published": "Aug. 9, 2013",
        "recorded": "June 2013",
        "category": [
            "Top->Computer Science->Machine Learning"
        ]
    },
    "url": "http://videolectures.net/colt2013_bubeck_regret/",
    "segmentation": [
        [
            "Alright, so unsurprisingly, I'm going to talk to you about bandits.",
            "I hope it's a.",
            "It's a new story that I will tell you."
        ],
        [
            "OK, so that's first.",
            "That's a picture of me and Microsoft.",
            "When we were working on the paper, so we worked really hard.",
            "OK, so let's get it."
        ],
        [
            "Idiot Lee into the real stuff because I have quite a lot to say.",
            "OK, so I'm going to go through this in two minutes, not more.",
            "So we have.",
            "So that's a medium stochastic bandits.",
            "We have capability distributions that we assume to be sub Goshen.",
            "Assume that the proxy for the variance is 1.",
            "So what this means is that a Gaussian distribution with variance one is sub Gaussian distribution on the support of size 2.",
            "Is abortion OK?",
            "My notation is that new I is the ice distribution for the ice armor.",
            "Bandit Muai is a mean of the ice distribution.",
            "Mu Star is a maximal mean Delta.",
            "I is a sub optimality gap, so it's a difference between the maximal mean an UI.",
            "And then the games are young men did game goes as follows.",
            "So it's a sequential game that goes on form 10 rounds.",
            "And I teach on teaser players to select an arm and I denoted by capital it.",
            "So that's an element in the set one 2K and you receive a reward.",
            "A random variable drawn from the underlying probability distribution.",
            "So when he selects it receive YT which is drawn from knew it.",
            "What he wants is to maximize the total payoff that receives, which is a sum 40 = 1, two North of the Whitey's.",
            "So that's what he gains an.",
            "If you knew everything, if you knew or departmental what you would have done to maximize this is that you would have selected the arms that maximizes the mean and then you would have obtained end times mustar.",
            "So what we do is that we compare what we obtain to what we could have obtained and we call that the regret.",
            "And that's the performance measures that we are looking at that I did not buy capital RN which is a regret.",
            "So famous result from 2002 by Peter Hour Nicole Chapman.",
            "Kyan feature is that the.",
            "So there is a strategy called UCB which has a regret which is bounded as a constant times the sum of log divided by Delta I and the sum runs over all the arms.",
            "OK, so that's that's a regret bound.",
            "And then there is a very famous paper from 1995 by Lion Robbins which states that basically this result is optimal.",
            "So let me go through this year and quickly.",
            "So I assume that you have an algorithm strategy for the stochastic multi armed bandit with the following property so.",
            "If the reward distributions are Gaussian with variance one OK, then the regret is sub polynomial.",
            "OK, so it's a little oh of N2.",
            "ZA for any positive number a OK then.",
            "So if we have this property which is a case for UCB, for instance, then we can prove that for any Goshen distributions with variance one the regret when you re scale it by log as N tends to Infinity it is lower bounded by the sum of 1 over Delta.",
            "I OK, so it's exactly the same thing as you see.",
            "Be up to this constancy so I don't want to specify the constant.",
            "I don't.",
            "I don't want to.",
            "Get back down by this.",
            "Alright, so now you look at this and basically that's the end of the story and we all go home except that now what is fun is to try to make assumption on the correlation between the different arms, so we have all been working on that.",
            "What we were doing.",
            "So some of us were making metric Lipschitz assumption metric assumption on the set.",
            "One 2K saying that if I know that am I is good then I know that TMJ is good.",
            "If the distance between I&J is small so that's one possibility.",
            "Another possibility is to embed everything in the Euclidean space and to do linear bandits.",
            "Another possibility is to do contextual bandits.",
            "I mean there are many, many possible extensions and what I'm going to talk about is another type of assumption on the correlation which is less explicit than linear bandits or metric bandits.",
            "So my assumption is going to be the following.",
            "The assumption is that we know mustar.",
            "OK, so we know the value of the optimal arm and we know epsilon.",
            "A positive number epsilon, which is a lower bound on the smallest gap.",
            "So epsilon is such that epsilon.",
            "Is a lower bound on the smallest gap, so the smallest gap is defined as a mean of the Delta I, and I'm also going to assume that I have one unique optimal arm, so this mean is overall arms different from this optimal arm I saw.",
            "So the entire talk and the entire paper is about this setting.",
            "So why?",
            "Why is it interesting?",
            "Well, I think it's interesting for many reasons, but I can just give you one example.",
            "Which is so.",
            "I CML last year.",
            "I CML 12 there was this competition for exploration versus exploitation.",
            "Yes, OK, so there was this competition that I CML last year.",
            "The winner was was a kind of UCB but if you just apply UCB out of the box what you get for the click through rate of UCB out of the box is something like 6%.",
            "And now I'm going to tell you about algorithm for this setting, and if you apply this algorithm out of the box and you plug in new cycles 9% and epsilon to be something like point or 1%, so you plug in new star.",
            "Of course, 90%.",
            "And epsilon equals .1%.",
            "OK, you don't beat the winner, but you do immediately 8%.",
            "I miss without any tuning like it, it's completely immediately out of the box strategy that does that.",
            "OK, so that's just to motivate you to listen to this.",
            "Are you still at this light?",
            "I still have the slides, but I'm not going to use them anymore.",
            "OK, so alright, so let's let's consider the toy example, which is the case of two arms OK or two.",
            "An epsilon equals that.",
            "So, so it's very important that case here is a strategy that we propose.",
            "So, OK, so in this case we know mustar and we know Delta, so we know we know the two means writing one is new style and one is new thermostat.",
            "So I know that one guy is new star and one guy is Mr Minister.",
            "And what we're going to do is that we are going to look at this threshold, which is new star minus that over 2, and we do the following strategy.",
            "So I do not buy Newhart.",
            "IT does the average reward for I. I thank you.",
            "Using words observational, just average them and I know this by Newhart I see.",
            "So the algorithm is as follows.",
            "So at time T. If.",
            "If I have one of the two arms which has its empirical mean above this line, then I'm just going to play it.",
            "OK, and if both of them are out of the land and I just play the the best of them.",
            "If there exist, I know exactly.",
            "New apps do you guys and you stop?",
            "Signs that help to Zen play.",
            "Otherwise.",
            "Well, otherwise what this means is that I really I don't know which ARM is the best.",
            "OK, so I need to explore and where I'm going to expose that I'm just going to pull both up.",
            "Footballs So what can you prove out this strategy?",
            "What we prove is the following theorem.",
            "The regret of this strategy is bounded by a constant divided by Delta.",
            "Book.",
            "Both green people exactly, so I don't want to be too specific.",
            "So what you do is you pull the first one and then the second one at the next time step.",
            "So what is nice right about this theorem is that there is no log in OK, so it's uniformly bounded overtime, and if you actually if you run experiments with this thing, you really see that they regret it goes like this, so it grows a little bit at the beginning, and then it's flat.",
            "So it's completely different from UCB, which would be something like this, right?",
            "OK.",
            "So that's good.",
            "But now this strategy has some obvious issues, so you see, in practice we may have a rough idea of what is mustar but epsilon.",
            "We probably have a very bad idea of what it is right epsilon is going to be very small, so we want to be.",
            "As in sent like we don't want to be too sensitive with respect to this value of epsilon.",
            "Right now if I had.",
            "If I have this epsilon and if I do the same thing, I'm going to put the car right here.",
            "You see, and that's going to be bad, because if this is really smaller than the best time is going to be quite often belows about OK, so quite often I'm going to be in the situation where I pull both arms and this is because of the small epsilon.",
            "So this strategy, if I put an epsilon like like this, the regret that I'm going to get is going to be something like Delta.",
            "Excellent squared, OK, so as epsilon becomes smaller this is really bad, right?",
            "Our fixes are following and I'm going to describe it now in the general case where epsilon is not that of course, and I have chaos and started regard as follows, so it's still the same thing right here.",
            "So now strategy for chaos.",
            "So if there exist.",
            "And also that you had, I think.",
            "It's about new star minus epsilon.",
            "Now two, then play it.",
            "And now what do I do otherwise?",
            "So otherwise I need to be a little bit careful because I don't want to treat similarly now which is just right below the threshold and somebody who is like right here.",
            "OK, if there is, I want to put more the guys who are getting closer and closer to the threshold and the way that could down many ways to do it.",
            "But the way we choose to do it is by randomization because it makes everything much more elegant proof an everything.",
            "So what we do is we play, otherwise play.",
            "IT.",
            "At random, so at random from a probability distribution PT and PT.",
            "This is defined as follows.",
            "So probability of selecting action is going to be proportional to one over the estimated gap squared.",
            "So what is the estimated caps credits mustar?",
            "Minus mu hat IT square.",
            "OK, so note that if we are in this situation that we are playing at random, it means that everybody is below this threshold, right?",
            "So this this difference is I can be at most as small as epsilon over two.",
            "They cannot be smaller and that we need to use that to control this.",
            "Otherwise this is not a good idea if you don't have this assumption.",
            "Now what can we prove about this guy?",
            "So what we can do with the following theorem?",
            "We can prove that the regrets now going to be downloaded at his son, but I gotta go to my start.",
            "So we get the one with that I write constant.",
            "So you see you will get log and we don't.",
            "We want something, of course uniformly bounded, so we don't want to Nan.",
            "What we get is log one over epsilon.",
            "So it's good because you see it's not too sensitive to excellent.",
            "Yeah, I can set here when I set my epsilon to be this point 01 it doesn't cost me too much in terms of regret, right?",
            "Compared to this Delta over epsilon squared over there.",
            "But still there is something a bit disappointing about it.",
            "Because you see, let's go back to the case study example when K = 2 epsilon for set up, I don't.",
            "I just wanna vedetta here.",
            "I don't have log one over Delta divided by data, so something more reasonable would be to get longer data.",
            "I divided by yourself, that would be something more reasonable to get and we can always do it.",
            "So here you see so little bit Arbitrary Square.",
            "So what you can do is instead of the square, you can have general function side of new star minus you had IT.",
            "OK, so this corresponds to side of X.",
            "Equals X ^2.",
            "You can play with different potential functions and with so that's with.",
            "This guy is with side effects.",
            "Square and we've syafiq slightly more complicated X squared divided by log.",
            "Call X epsilon, which we get is.",
            "Grats bonded as constant but stop identical device off of login.",
            "Better I will let you know.",
            "Divided by Debra High, so that's good, but it's multiplied by Doctor Dog.",
            "So OK, so at this point we were really disappointed.",
            "There's no point in doing it if you get this.",
            "But you can remove it, but not with.",
            "This strategy is much more complicated, but choosing ideas from Thompson sampling you can actually derive something which doesn't use this.",
            "If you see, you can view this as a sort of prior over the transmitters and then Thompson sampling gives you ideas to derive new strategy, and using that with my students should you look within the audience, we were able to remove the other, but that's another story.",
            "OK, so that's it for.",
            "And now in the remaining time, I want to talk briefly about power bounds.",
            "Which actually.",
            "Yeah, do it so.",
            "OK, so one thing which is disappointing with Brian Robbins is that it's not fantastic level.",
            "So what we wanted is to have finite time now bound so some finite time lower bounds were already obtained by Connie and busy in 2000.",
            "But they were making this assumption that the strategy has to be well behaved in this sense.",
            "So what we can do is we can rewrite this lock box without any assumption.",
            "So it goes as follows.",
            "So first I need to prove street outlaws because you see I know new star and I know epsilon.",
            "So I'm going to prove a log on when I know you stop an OK, I'm going to do everything in the toy example where K = 2 and epsilon equals Delta.",
            "So I'm going to do one hour from when I know it.",
            "When I know you saw and I know that top one.",
            "Now on when I don't know Miss Thailand.",
            "I know that top and one outbound when.",
            "OK, yeah, so let's do known you stop.",
            "We do is we define two product distribution.",
            "Is your one.",
            "And Matt minus that one.",
            "But this means that it's advantage program where on the first time I have Russian distribution with mean zero and variance one and the 2nd one second are my aggression distribution with mean minus that time there as well as the other distribution that I consider it and it's termination fees and minus that one time.",
            "An African food is at 4, So what do you expect in this case right?",
            "No news on their class, so we expect around in one over data and what we can prove is that indeed for any strategy, either on you on new prime.",
            "So the maximum between the regrets and you and the regrettable right is now bounded by a constant.",
            "So.",
            "'cause this is type in America concert.",
            "Now what about?",
            "Um?",
            "The case where.",
            "Mustar is unknown.",
            "And that I've known.",
            "So in this case, what do we expect?",
            "Well, we expect to have maybe like Lion Robbins.",
            "OK, I didn't say anything new in terms of upper bound for this setting, so maybe we hope to get the login over Delta and that's indeed what we can get.",
            "So you take knew to be.",
            "Actually you can put a direct on the 1st ARM.",
            "An so here you the first time always give you 0 one and the second one is aggression with responded to Delta and on the other distribution you get direct and now it's a question distribution that would mean minus that one and the theorem is that for any strategy for any end the regrets eyes on you own new prime.",
            "Is larger than.",
            "Constant times login.",
            "Over there.",
            "Sorry, log in that square.",
            "I don't want to get into the devil.",
            "Alright, so this is really the finite time Lion, Robbins.",
            "There is zero assumption is just.",
            "Alright, so so far everything that I have written.",
            "Is actually really easy to prove.",
            "Except maybe for this one, but everything else is really at most relaxed.",
            "And now the next theorem is more than three nights.",
            "It's really well where we had to work quite a bit, so.",
            "So now I want to tackle the case where new star is known.",
            "And that is unknown.",
            "So you see, I'm not going to be able to do something as simple as those lower bounds, because for any finite family of distributions, I will know a lower bound on the smallest gap.",
            "OK, and then I can use this goes on, which has a finite regret.",
            "Right, so here what I want to show, of course, is that in this case, if you if you even if you know Mr.",
            "But you have no epsilon if you don't know any lower bound on Delta, then you cannot get bounded regret.",
            "That's what we want to show, but we have to go beyond what we did.",
            "So first thing is that we need to have an infinite family of distribution.",
            "The second issue is that actually you can get bounded regret in this case, and that was already observed by Lion Robbins.",
            "In 87.",
            "They have an algorithm which requires to know to know only mu stock and which has a bounded regret, except that what they prove that the regret is bounded.",
            "But the constant might depend in a very bad way on the distributions.",
            "OK, it's not going to be one over Delta is going to be something much more complicated, and in particular when you try to derive the world stage guarantee you will get the usual squared.",
            "Then we have to get through.",
            "Then you need the one over Delta.",
            "So we have another issue is that what we want to prove is not true.",
            "It's bad.",
            "But what what we really want to prove is that what you cannot get is bounded regret of the form one over Delta.",
            "So what we're going to do is that we are going to look at the rescaled regrets.",
            "OK, OK, we're going to look at the rescaled regret.",
            "OK, so we look at Delta times RN and we prove that this must be lower bounded by Logan.",
            "So theoretical, that follows.",
            "So I take trust distribution you not which is an N-01.",
            "Times and N -- 1.",
            "And then I take new Delta.",
            "Which is going to be an N minus that one.",
            "Times N. 01 OK, so I know new star is zero in this case, I just I have no way to allow bound to the smallest gap.",
            "OK, because I think Delta is ranging between zero and one.",
            "And what I can prove, what what we can prove is that.",
            "The Max.",
            "The chains are regret until new Zero and just three more over that time 01.",
            "Of the risk and regret that at times RN of new Delta.",
            "That is larger than a constant bank login, so another way to interpret this theorem is that there exists either under new Zero under one of those new Delta.",
            "There exists one distribution where the regret must be lower bounded by Logan over Delta.",
            "OK, even though you know new stuff.",
            "And the proof.",
            "I'm just going to say 1 one more.",
            "Which is because it's really that's the key technical.",
            "Contribution which might be helpful in other setting, but I'm just going to write that Eyaculation is that at some point you have to look at the code back.",
            "That's the law of the rewards that you observe when you play the game under New 0.",
            "The result that you observe when you play against new data.",
            "We can put the probability distribution of others new Delta instead of considering this come back here we can put integral of this guide with respect to some finite measurable Delta integrated zero and one.",
            "So this is not anymore program distribution, it's a finite measure, but the complexity makes sense.",
            "And watch movies at this callback is off is upper bounded by the number of times that you sent on two.",
            "So you see when you sent around two, you receive one bit of information.",
            "You distinguish between an N-01 and N -- 1 one.",
            "But when you put the first time you don't know between what and what you're distinguishing.",
            "OK, so you don't get one bit of information every time you put this up, and the difficulty was to make this formal.",
            "So thank you every time you put into you get and two times a constant.",
            "That's the number of information that you get.",
            "But now when you pull one, what you get is logged in.",
            "What you get to sort of logarithmic information when you don't know what you're trying to do this, and I'm going to stop here."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Alright, so unsurprisingly, I'm going to talk to you about bandits.",
                    "label": 0
                },
                {
                    "sent": "I hope it's a.",
                    "label": 0
                },
                {
                    "sent": "It's a new story that I will tell you.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so that's first.",
                    "label": 0
                },
                {
                    "sent": "That's a picture of me and Microsoft.",
                    "label": 0
                },
                {
                    "sent": "When we were working on the paper, so we worked really hard.",
                    "label": 0
                },
                {
                    "sent": "OK, so let's get it.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Idiot Lee into the real stuff because I have quite a lot to say.",
                    "label": 0
                },
                {
                    "sent": "OK, so I'm going to go through this in two minutes, not more.",
                    "label": 0
                },
                {
                    "sent": "So we have.",
                    "label": 0
                },
                {
                    "sent": "So that's a medium stochastic bandits.",
                    "label": 0
                },
                {
                    "sent": "We have capability distributions that we assume to be sub Goshen.",
                    "label": 0
                },
                {
                    "sent": "Assume that the proxy for the variance is 1.",
                    "label": 0
                },
                {
                    "sent": "So what this means is that a Gaussian distribution with variance one is sub Gaussian distribution on the support of size 2.",
                    "label": 0
                },
                {
                    "sent": "Is abortion OK?",
                    "label": 0
                },
                {
                    "sent": "My notation is that new I is the ice distribution for the ice armor.",
                    "label": 0
                },
                {
                    "sent": "Bandit Muai is a mean of the ice distribution.",
                    "label": 0
                },
                {
                    "sent": "Mu Star is a maximal mean Delta.",
                    "label": 0
                },
                {
                    "sent": "I is a sub optimality gap, so it's a difference between the maximal mean an UI.",
                    "label": 0
                },
                {
                    "sent": "And then the games are young men did game goes as follows.",
                    "label": 0
                },
                {
                    "sent": "So it's a sequential game that goes on form 10 rounds.",
                    "label": 0
                },
                {
                    "sent": "And I teach on teaser players to select an arm and I denoted by capital it.",
                    "label": 0
                },
                {
                    "sent": "So that's an element in the set one 2K and you receive a reward.",
                    "label": 0
                },
                {
                    "sent": "A random variable drawn from the underlying probability distribution.",
                    "label": 0
                },
                {
                    "sent": "So when he selects it receive YT which is drawn from knew it.",
                    "label": 0
                },
                {
                    "sent": "What he wants is to maximize the total payoff that receives, which is a sum 40 = 1, two North of the Whitey's.",
                    "label": 0
                },
                {
                    "sent": "So that's what he gains an.",
                    "label": 0
                },
                {
                    "sent": "If you knew everything, if you knew or departmental what you would have done to maximize this is that you would have selected the arms that maximizes the mean and then you would have obtained end times mustar.",
                    "label": 0
                },
                {
                    "sent": "So what we do is that we compare what we obtain to what we could have obtained and we call that the regret.",
                    "label": 0
                },
                {
                    "sent": "And that's the performance measures that we are looking at that I did not buy capital RN which is a regret.",
                    "label": 0
                },
                {
                    "sent": "So famous result from 2002 by Peter Hour Nicole Chapman.",
                    "label": 0
                },
                {
                    "sent": "Kyan feature is that the.",
                    "label": 0
                },
                {
                    "sent": "So there is a strategy called UCB which has a regret which is bounded as a constant times the sum of log divided by Delta I and the sum runs over all the arms.",
                    "label": 0
                },
                {
                    "sent": "OK, so that's that's a regret bound.",
                    "label": 0
                },
                {
                    "sent": "And then there is a very famous paper from 1995 by Lion Robbins which states that basically this result is optimal.",
                    "label": 0
                },
                {
                    "sent": "So let me go through this year and quickly.",
                    "label": 0
                },
                {
                    "sent": "So I assume that you have an algorithm strategy for the stochastic multi armed bandit with the following property so.",
                    "label": 0
                },
                {
                    "sent": "If the reward distributions are Gaussian with variance one OK, then the regret is sub polynomial.",
                    "label": 1
                },
                {
                    "sent": "OK, so it's a little oh of N2.",
                    "label": 0
                },
                {
                    "sent": "ZA for any positive number a OK then.",
                    "label": 0
                },
                {
                    "sent": "So if we have this property which is a case for UCB, for instance, then we can prove that for any Goshen distributions with variance one the regret when you re scale it by log as N tends to Infinity it is lower bounded by the sum of 1 over Delta.",
                    "label": 0
                },
                {
                    "sent": "I OK, so it's exactly the same thing as you see.",
                    "label": 0
                },
                {
                    "sent": "Be up to this constancy so I don't want to specify the constant.",
                    "label": 0
                },
                {
                    "sent": "I don't.",
                    "label": 0
                },
                {
                    "sent": "I don't want to.",
                    "label": 0
                },
                {
                    "sent": "Get back down by this.",
                    "label": 0
                },
                {
                    "sent": "Alright, so now you look at this and basically that's the end of the story and we all go home except that now what is fun is to try to make assumption on the correlation between the different arms, so we have all been working on that.",
                    "label": 0
                },
                {
                    "sent": "What we were doing.",
                    "label": 0
                },
                {
                    "sent": "So some of us were making metric Lipschitz assumption metric assumption on the set.",
                    "label": 0
                },
                {
                    "sent": "One 2K saying that if I know that am I is good then I know that TMJ is good.",
                    "label": 0
                },
                {
                    "sent": "If the distance between I&J is small so that's one possibility.",
                    "label": 0
                },
                {
                    "sent": "Another possibility is to embed everything in the Euclidean space and to do linear bandits.",
                    "label": 0
                },
                {
                    "sent": "Another possibility is to do contextual bandits.",
                    "label": 0
                },
                {
                    "sent": "I mean there are many, many possible extensions and what I'm going to talk about is another type of assumption on the correlation which is less explicit than linear bandits or metric bandits.",
                    "label": 0
                },
                {
                    "sent": "So my assumption is going to be the following.",
                    "label": 0
                },
                {
                    "sent": "The assumption is that we know mustar.",
                    "label": 0
                },
                {
                    "sent": "OK, so we know the value of the optimal arm and we know epsilon.",
                    "label": 0
                },
                {
                    "sent": "A positive number epsilon, which is a lower bound on the smallest gap.",
                    "label": 0
                },
                {
                    "sent": "So epsilon is such that epsilon.",
                    "label": 0
                },
                {
                    "sent": "Is a lower bound on the smallest gap, so the smallest gap is defined as a mean of the Delta I, and I'm also going to assume that I have one unique optimal arm, so this mean is overall arms different from this optimal arm I saw.",
                    "label": 0
                },
                {
                    "sent": "So the entire talk and the entire paper is about this setting.",
                    "label": 0
                },
                {
                    "sent": "So why?",
                    "label": 0
                },
                {
                    "sent": "Why is it interesting?",
                    "label": 0
                },
                {
                    "sent": "Well, I think it's interesting for many reasons, but I can just give you one example.",
                    "label": 0
                },
                {
                    "sent": "Which is so.",
                    "label": 0
                },
                {
                    "sent": "I CML last year.",
                    "label": 0
                },
                {
                    "sent": "I CML 12 there was this competition for exploration versus exploitation.",
                    "label": 0
                },
                {
                    "sent": "Yes, OK, so there was this competition that I CML last year.",
                    "label": 0
                },
                {
                    "sent": "The winner was was a kind of UCB but if you just apply UCB out of the box what you get for the click through rate of UCB out of the box is something like 6%.",
                    "label": 0
                },
                {
                    "sent": "And now I'm going to tell you about algorithm for this setting, and if you apply this algorithm out of the box and you plug in new cycles 9% and epsilon to be something like point or 1%, so you plug in new star.",
                    "label": 0
                },
                {
                    "sent": "Of course, 90%.",
                    "label": 0
                },
                {
                    "sent": "And epsilon equals .1%.",
                    "label": 0
                },
                {
                    "sent": "OK, you don't beat the winner, but you do immediately 8%.",
                    "label": 0
                },
                {
                    "sent": "I miss without any tuning like it, it's completely immediately out of the box strategy that does that.",
                    "label": 0
                },
                {
                    "sent": "OK, so that's just to motivate you to listen to this.",
                    "label": 0
                },
                {
                    "sent": "Are you still at this light?",
                    "label": 0
                },
                {
                    "sent": "I still have the slides, but I'm not going to use them anymore.",
                    "label": 0
                },
                {
                    "sent": "OK, so alright, so let's let's consider the toy example, which is the case of two arms OK or two.",
                    "label": 0
                },
                {
                    "sent": "An epsilon equals that.",
                    "label": 0
                },
                {
                    "sent": "So, so it's very important that case here is a strategy that we propose.",
                    "label": 0
                },
                {
                    "sent": "So, OK, so in this case we know mustar and we know Delta, so we know we know the two means writing one is new style and one is new thermostat.",
                    "label": 0
                },
                {
                    "sent": "So I know that one guy is new star and one guy is Mr Minister.",
                    "label": 0
                },
                {
                    "sent": "And what we're going to do is that we are going to look at this threshold, which is new star minus that over 2, and we do the following strategy.",
                    "label": 0
                },
                {
                    "sent": "So I do not buy Newhart.",
                    "label": 0
                },
                {
                    "sent": "IT does the average reward for I. I thank you.",
                    "label": 0
                },
                {
                    "sent": "Using words observational, just average them and I know this by Newhart I see.",
                    "label": 0
                },
                {
                    "sent": "So the algorithm is as follows.",
                    "label": 0
                },
                {
                    "sent": "So at time T. If.",
                    "label": 0
                },
                {
                    "sent": "If I have one of the two arms which has its empirical mean above this line, then I'm just going to play it.",
                    "label": 0
                },
                {
                    "sent": "OK, and if both of them are out of the land and I just play the the best of them.",
                    "label": 0
                },
                {
                    "sent": "If there exist, I know exactly.",
                    "label": 0
                },
                {
                    "sent": "New apps do you guys and you stop?",
                    "label": 0
                },
                {
                    "sent": "Signs that help to Zen play.",
                    "label": 0
                },
                {
                    "sent": "Otherwise.",
                    "label": 0
                },
                {
                    "sent": "Well, otherwise what this means is that I really I don't know which ARM is the best.",
                    "label": 0
                },
                {
                    "sent": "OK, so I need to explore and where I'm going to expose that I'm just going to pull both up.",
                    "label": 0
                },
                {
                    "sent": "Footballs So what can you prove out this strategy?",
                    "label": 0
                },
                {
                    "sent": "What we prove is the following theorem.",
                    "label": 0
                },
                {
                    "sent": "The regret of this strategy is bounded by a constant divided by Delta.",
                    "label": 0
                },
                {
                    "sent": "Book.",
                    "label": 0
                },
                {
                    "sent": "Both green people exactly, so I don't want to be too specific.",
                    "label": 0
                },
                {
                    "sent": "So what you do is you pull the first one and then the second one at the next time step.",
                    "label": 0
                },
                {
                    "sent": "So what is nice right about this theorem is that there is no log in OK, so it's uniformly bounded overtime, and if you actually if you run experiments with this thing, you really see that they regret it goes like this, so it grows a little bit at the beginning, and then it's flat.",
                    "label": 0
                },
                {
                    "sent": "So it's completely different from UCB, which would be something like this, right?",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So that's good.",
                    "label": 0
                },
                {
                    "sent": "But now this strategy has some obvious issues, so you see, in practice we may have a rough idea of what is mustar but epsilon.",
                    "label": 0
                },
                {
                    "sent": "We probably have a very bad idea of what it is right epsilon is going to be very small, so we want to be.",
                    "label": 0
                },
                {
                    "sent": "As in sent like we don't want to be too sensitive with respect to this value of epsilon.",
                    "label": 0
                },
                {
                    "sent": "Right now if I had.",
                    "label": 0
                },
                {
                    "sent": "If I have this epsilon and if I do the same thing, I'm going to put the car right here.",
                    "label": 0
                },
                {
                    "sent": "You see, and that's going to be bad, because if this is really smaller than the best time is going to be quite often belows about OK, so quite often I'm going to be in the situation where I pull both arms and this is because of the small epsilon.",
                    "label": 0
                },
                {
                    "sent": "So this strategy, if I put an epsilon like like this, the regret that I'm going to get is going to be something like Delta.",
                    "label": 0
                },
                {
                    "sent": "Excellent squared, OK, so as epsilon becomes smaller this is really bad, right?",
                    "label": 0
                },
                {
                    "sent": "Our fixes are following and I'm going to describe it now in the general case where epsilon is not that of course, and I have chaos and started regard as follows, so it's still the same thing right here.",
                    "label": 0
                },
                {
                    "sent": "So now strategy for chaos.",
                    "label": 0
                },
                {
                    "sent": "So if there exist.",
                    "label": 0
                },
                {
                    "sent": "And also that you had, I think.",
                    "label": 0
                },
                {
                    "sent": "It's about new star minus epsilon.",
                    "label": 0
                },
                {
                    "sent": "Now two, then play it.",
                    "label": 0
                },
                {
                    "sent": "And now what do I do otherwise?",
                    "label": 0
                },
                {
                    "sent": "So otherwise I need to be a little bit careful because I don't want to treat similarly now which is just right below the threshold and somebody who is like right here.",
                    "label": 0
                },
                {
                    "sent": "OK, if there is, I want to put more the guys who are getting closer and closer to the threshold and the way that could down many ways to do it.",
                    "label": 0
                },
                {
                    "sent": "But the way we choose to do it is by randomization because it makes everything much more elegant proof an everything.",
                    "label": 0
                },
                {
                    "sent": "So what we do is we play, otherwise play.",
                    "label": 0
                },
                {
                    "sent": "IT.",
                    "label": 0
                },
                {
                    "sent": "At random, so at random from a probability distribution PT and PT.",
                    "label": 0
                },
                {
                    "sent": "This is defined as follows.",
                    "label": 0
                },
                {
                    "sent": "So probability of selecting action is going to be proportional to one over the estimated gap squared.",
                    "label": 0
                },
                {
                    "sent": "So what is the estimated caps credits mustar?",
                    "label": 0
                },
                {
                    "sent": "Minus mu hat IT square.",
                    "label": 0
                },
                {
                    "sent": "OK, so note that if we are in this situation that we are playing at random, it means that everybody is below this threshold, right?",
                    "label": 0
                },
                {
                    "sent": "So this this difference is I can be at most as small as epsilon over two.",
                    "label": 0
                },
                {
                    "sent": "They cannot be smaller and that we need to use that to control this.",
                    "label": 0
                },
                {
                    "sent": "Otherwise this is not a good idea if you don't have this assumption.",
                    "label": 0
                },
                {
                    "sent": "Now what can we prove about this guy?",
                    "label": 0
                },
                {
                    "sent": "So what we can do with the following theorem?",
                    "label": 0
                },
                {
                    "sent": "We can prove that the regrets now going to be downloaded at his son, but I gotta go to my start.",
                    "label": 0
                },
                {
                    "sent": "So we get the one with that I write constant.",
                    "label": 0
                },
                {
                    "sent": "So you see you will get log and we don't.",
                    "label": 0
                },
                {
                    "sent": "We want something, of course uniformly bounded, so we don't want to Nan.",
                    "label": 0
                },
                {
                    "sent": "What we get is log one over epsilon.",
                    "label": 0
                },
                {
                    "sent": "So it's good because you see it's not too sensitive to excellent.",
                    "label": 0
                },
                {
                    "sent": "Yeah, I can set here when I set my epsilon to be this point 01 it doesn't cost me too much in terms of regret, right?",
                    "label": 0
                },
                {
                    "sent": "Compared to this Delta over epsilon squared over there.",
                    "label": 0
                },
                {
                    "sent": "But still there is something a bit disappointing about it.",
                    "label": 0
                },
                {
                    "sent": "Because you see, let's go back to the case study example when K = 2 epsilon for set up, I don't.",
                    "label": 0
                },
                {
                    "sent": "I just wanna vedetta here.",
                    "label": 0
                },
                {
                    "sent": "I don't have log one over Delta divided by data, so something more reasonable would be to get longer data.",
                    "label": 0
                },
                {
                    "sent": "I divided by yourself, that would be something more reasonable to get and we can always do it.",
                    "label": 0
                },
                {
                    "sent": "So here you see so little bit Arbitrary Square.",
                    "label": 0
                },
                {
                    "sent": "So what you can do is instead of the square, you can have general function side of new star minus you had IT.",
                    "label": 0
                },
                {
                    "sent": "OK, so this corresponds to side of X.",
                    "label": 0
                },
                {
                    "sent": "Equals X ^2.",
                    "label": 0
                },
                {
                    "sent": "You can play with different potential functions and with so that's with.",
                    "label": 0
                },
                {
                    "sent": "This guy is with side effects.",
                    "label": 0
                },
                {
                    "sent": "Square and we've syafiq slightly more complicated X squared divided by log.",
                    "label": 0
                },
                {
                    "sent": "Call X epsilon, which we get is.",
                    "label": 0
                },
                {
                    "sent": "Grats bonded as constant but stop identical device off of login.",
                    "label": 0
                },
                {
                    "sent": "Better I will let you know.",
                    "label": 0
                },
                {
                    "sent": "Divided by Debra High, so that's good, but it's multiplied by Doctor Dog.",
                    "label": 0
                },
                {
                    "sent": "So OK, so at this point we were really disappointed.",
                    "label": 0
                },
                {
                    "sent": "There's no point in doing it if you get this.",
                    "label": 0
                },
                {
                    "sent": "But you can remove it, but not with.",
                    "label": 0
                },
                {
                    "sent": "This strategy is much more complicated, but choosing ideas from Thompson sampling you can actually derive something which doesn't use this.",
                    "label": 0
                },
                {
                    "sent": "If you see, you can view this as a sort of prior over the transmitters and then Thompson sampling gives you ideas to derive new strategy, and using that with my students should you look within the audience, we were able to remove the other, but that's another story.",
                    "label": 0
                },
                {
                    "sent": "OK, so that's it for.",
                    "label": 0
                },
                {
                    "sent": "And now in the remaining time, I want to talk briefly about power bounds.",
                    "label": 0
                },
                {
                    "sent": "Which actually.",
                    "label": 0
                },
                {
                    "sent": "Yeah, do it so.",
                    "label": 0
                },
                {
                    "sent": "OK, so one thing which is disappointing with Brian Robbins is that it's not fantastic level.",
                    "label": 0
                },
                {
                    "sent": "So what we wanted is to have finite time now bound so some finite time lower bounds were already obtained by Connie and busy in 2000.",
                    "label": 0
                },
                {
                    "sent": "But they were making this assumption that the strategy has to be well behaved in this sense.",
                    "label": 0
                },
                {
                    "sent": "So what we can do is we can rewrite this lock box without any assumption.",
                    "label": 0
                },
                {
                    "sent": "So it goes as follows.",
                    "label": 0
                },
                {
                    "sent": "So first I need to prove street outlaws because you see I know new star and I know epsilon.",
                    "label": 0
                },
                {
                    "sent": "So I'm going to prove a log on when I know you stop an OK, I'm going to do everything in the toy example where K = 2 and epsilon equals Delta.",
                    "label": 0
                },
                {
                    "sent": "So I'm going to do one hour from when I know it.",
                    "label": 0
                },
                {
                    "sent": "When I know you saw and I know that top one.",
                    "label": 0
                },
                {
                    "sent": "Now on when I don't know Miss Thailand.",
                    "label": 0
                },
                {
                    "sent": "I know that top and one outbound when.",
                    "label": 0
                },
                {
                    "sent": "OK, yeah, so let's do known you stop.",
                    "label": 0
                },
                {
                    "sent": "We do is we define two product distribution.",
                    "label": 0
                },
                {
                    "sent": "Is your one.",
                    "label": 0
                },
                {
                    "sent": "And Matt minus that one.",
                    "label": 0
                },
                {
                    "sent": "But this means that it's advantage program where on the first time I have Russian distribution with mean zero and variance one and the 2nd one second are my aggression distribution with mean minus that time there as well as the other distribution that I consider it and it's termination fees and minus that one time.",
                    "label": 0
                },
                {
                    "sent": "An African food is at 4, So what do you expect in this case right?",
                    "label": 0
                },
                {
                    "sent": "No news on their class, so we expect around in one over data and what we can prove is that indeed for any strategy, either on you on new prime.",
                    "label": 0
                },
                {
                    "sent": "So the maximum between the regrets and you and the regrettable right is now bounded by a constant.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "'cause this is type in America concert.",
                    "label": 0
                },
                {
                    "sent": "Now what about?",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "The case where.",
                    "label": 0
                },
                {
                    "sent": "Mustar is unknown.",
                    "label": 0
                },
                {
                    "sent": "And that I've known.",
                    "label": 0
                },
                {
                    "sent": "So in this case, what do we expect?",
                    "label": 0
                },
                {
                    "sent": "Well, we expect to have maybe like Lion Robbins.",
                    "label": 0
                },
                {
                    "sent": "OK, I didn't say anything new in terms of upper bound for this setting, so maybe we hope to get the login over Delta and that's indeed what we can get.",
                    "label": 0
                },
                {
                    "sent": "So you take knew to be.",
                    "label": 0
                },
                {
                    "sent": "Actually you can put a direct on the 1st ARM.",
                    "label": 0
                },
                {
                    "sent": "An so here you the first time always give you 0 one and the second one is aggression with responded to Delta and on the other distribution you get direct and now it's a question distribution that would mean minus that one and the theorem is that for any strategy for any end the regrets eyes on you own new prime.",
                    "label": 0
                },
                {
                    "sent": "Is larger than.",
                    "label": 0
                },
                {
                    "sent": "Constant times login.",
                    "label": 0
                },
                {
                    "sent": "Over there.",
                    "label": 0
                },
                {
                    "sent": "Sorry, log in that square.",
                    "label": 0
                },
                {
                    "sent": "I don't want to get into the devil.",
                    "label": 0
                },
                {
                    "sent": "Alright, so this is really the finite time Lion, Robbins.",
                    "label": 0
                },
                {
                    "sent": "There is zero assumption is just.",
                    "label": 0
                },
                {
                    "sent": "Alright, so so far everything that I have written.",
                    "label": 0
                },
                {
                    "sent": "Is actually really easy to prove.",
                    "label": 0
                },
                {
                    "sent": "Except maybe for this one, but everything else is really at most relaxed.",
                    "label": 0
                },
                {
                    "sent": "And now the next theorem is more than three nights.",
                    "label": 0
                },
                {
                    "sent": "It's really well where we had to work quite a bit, so.",
                    "label": 0
                },
                {
                    "sent": "So now I want to tackle the case where new star is known.",
                    "label": 0
                },
                {
                    "sent": "And that is unknown.",
                    "label": 0
                },
                {
                    "sent": "So you see, I'm not going to be able to do something as simple as those lower bounds, because for any finite family of distributions, I will know a lower bound on the smallest gap.",
                    "label": 0
                },
                {
                    "sent": "OK, and then I can use this goes on, which has a finite regret.",
                    "label": 0
                },
                {
                    "sent": "Right, so here what I want to show, of course, is that in this case, if you if you even if you know Mr.",
                    "label": 0
                },
                {
                    "sent": "But you have no epsilon if you don't know any lower bound on Delta, then you cannot get bounded regret.",
                    "label": 0
                },
                {
                    "sent": "That's what we want to show, but we have to go beyond what we did.",
                    "label": 0
                },
                {
                    "sent": "So first thing is that we need to have an infinite family of distribution.",
                    "label": 0
                },
                {
                    "sent": "The second issue is that actually you can get bounded regret in this case, and that was already observed by Lion Robbins.",
                    "label": 0
                },
                {
                    "sent": "In 87.",
                    "label": 0
                },
                {
                    "sent": "They have an algorithm which requires to know to know only mu stock and which has a bounded regret, except that what they prove that the regret is bounded.",
                    "label": 0
                },
                {
                    "sent": "But the constant might depend in a very bad way on the distributions.",
                    "label": 0
                },
                {
                    "sent": "OK, it's not going to be one over Delta is going to be something much more complicated, and in particular when you try to derive the world stage guarantee you will get the usual squared.",
                    "label": 0
                },
                {
                    "sent": "Then we have to get through.",
                    "label": 0
                },
                {
                    "sent": "Then you need the one over Delta.",
                    "label": 0
                },
                {
                    "sent": "So we have another issue is that what we want to prove is not true.",
                    "label": 0
                },
                {
                    "sent": "It's bad.",
                    "label": 0
                },
                {
                    "sent": "But what what we really want to prove is that what you cannot get is bounded regret of the form one over Delta.",
                    "label": 0
                },
                {
                    "sent": "So what we're going to do is that we are going to look at the rescaled regrets.",
                    "label": 0
                },
                {
                    "sent": "OK, OK, we're going to look at the rescaled regret.",
                    "label": 0
                },
                {
                    "sent": "OK, so we look at Delta times RN and we prove that this must be lower bounded by Logan.",
                    "label": 0
                },
                {
                    "sent": "So theoretical, that follows.",
                    "label": 0
                },
                {
                    "sent": "So I take trust distribution you not which is an N-01.",
                    "label": 0
                },
                {
                    "sent": "Times and N -- 1.",
                    "label": 0
                },
                {
                    "sent": "And then I take new Delta.",
                    "label": 0
                },
                {
                    "sent": "Which is going to be an N minus that one.",
                    "label": 0
                },
                {
                    "sent": "Times N. 01 OK, so I know new star is zero in this case, I just I have no way to allow bound to the smallest gap.",
                    "label": 0
                },
                {
                    "sent": "OK, because I think Delta is ranging between zero and one.",
                    "label": 0
                },
                {
                    "sent": "And what I can prove, what what we can prove is that.",
                    "label": 0
                },
                {
                    "sent": "The Max.",
                    "label": 0
                },
                {
                    "sent": "The chains are regret until new Zero and just three more over that time 01.",
                    "label": 0
                },
                {
                    "sent": "Of the risk and regret that at times RN of new Delta.",
                    "label": 0
                },
                {
                    "sent": "That is larger than a constant bank login, so another way to interpret this theorem is that there exists either under new Zero under one of those new Delta.",
                    "label": 0
                },
                {
                    "sent": "There exists one distribution where the regret must be lower bounded by Logan over Delta.",
                    "label": 0
                },
                {
                    "sent": "OK, even though you know new stuff.",
                    "label": 0
                },
                {
                    "sent": "And the proof.",
                    "label": 0
                },
                {
                    "sent": "I'm just going to say 1 one more.",
                    "label": 0
                },
                {
                    "sent": "Which is because it's really that's the key technical.",
                    "label": 0
                },
                {
                    "sent": "Contribution which might be helpful in other setting, but I'm just going to write that Eyaculation is that at some point you have to look at the code back.",
                    "label": 0
                },
                {
                    "sent": "That's the law of the rewards that you observe when you play the game under New 0.",
                    "label": 0
                },
                {
                    "sent": "The result that you observe when you play against new data.",
                    "label": 0
                },
                {
                    "sent": "We can put the probability distribution of others new Delta instead of considering this come back here we can put integral of this guide with respect to some finite measurable Delta integrated zero and one.",
                    "label": 0
                },
                {
                    "sent": "So this is not anymore program distribution, it's a finite measure, but the complexity makes sense.",
                    "label": 0
                },
                {
                    "sent": "And watch movies at this callback is off is upper bounded by the number of times that you sent on two.",
                    "label": 0
                },
                {
                    "sent": "So you see when you sent around two, you receive one bit of information.",
                    "label": 0
                },
                {
                    "sent": "You distinguish between an N-01 and N -- 1 one.",
                    "label": 0
                },
                {
                    "sent": "But when you put the first time you don't know between what and what you're distinguishing.",
                    "label": 0
                },
                {
                    "sent": "OK, so you don't get one bit of information every time you put this up, and the difficulty was to make this formal.",
                    "label": 0
                },
                {
                    "sent": "So thank you every time you put into you get and two times a constant.",
                    "label": 0
                },
                {
                    "sent": "That's the number of information that you get.",
                    "label": 0
                },
                {
                    "sent": "But now when you pull one, what you get is logged in.",
                    "label": 0
                },
                {
                    "sent": "What you get to sort of logarithmic information when you don't know what you're trying to do this, and I'm going to stop here.",
                    "label": 0
                }
            ]
        }
    }
}