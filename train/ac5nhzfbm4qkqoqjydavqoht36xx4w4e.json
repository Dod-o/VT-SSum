{
    "id": "ac5nhzfbm4qkqoqjydavqoht36xx4w4e",
    "title": "Change Detection in Dynamic Scenes using Local Adaptive Transform",
    "info": {
        "author": [
            "Shishir K. Shah, Department of Computer Science, University of Houston"
        ],
        "published": "April 3, 2014",
        "recorded": "September 2013",
        "category": [
            "Top->Computer Science->Computer Vision",
            "Top->Computer Science->Machine Learning"
        ]
    },
    "url": "http://videolectures.net/bmvc2013_shah_change_detection/",
    "segmentation": [
        [
            "Alright, I'll talk a little bit about change detection and dynamic scenes using local adaptive transform.",
            "This is work done with my student conference over there.",
            "Unfortunately he was unable to come around to present his work, so just to sort of."
        ],
        [
            "For motivate the problem detecting changes in videos is certainly applicable in a multitude of problem domains.",
            "Video surveillance being one of those medical imaging being another remote sensing and so on so forth an.",
            "The key problem in identifying changes in videos is that there are a multitude of types of changes that occur.",
            "Lot of them could be non interesting and a lot of work in looking at low level.",
            "Detection and videos, especially surrounding changes as focused around the problem of trying to either model the background through understanding of the intensity distributions that occur or in order to try and characterize the changes that occur overtime through some kind of spatial temporal modeling, and certainly."
        ],
        [
            "The exploitation of videos in the context of looking at spatial temporal distributions is extremely relevant because as you can see in this little example, if I have a fixed camera looking at it a scene, there's going to be what idea problems you will have.",
            "Some movements of trees that will induce changes in pixel intensities and at the same time it will actually induce changes in the structure, but those may not be relevant or meaningful changes of interest.",
            "On the other hand, if you have a vehicle that moves through.",
            "That might be of particular interest depending on the problem domain.",
            "So the question becomes how do we differentiate between what a meaningful changes and what are the changes that we can ignore and they are more attuned to the dynamic background of the changing signatures within the background itself.",
            "So as a result, what we've been looking at."
        ],
        [
            "It is trying to differentiate between what we consider is ordered ordinary change versus what we may be able to characterize as relevant changes or things of interest in the video.",
            "Now, if I look at these videos up here.",
            "You have essentially on the top just a scene with flowing water an if we just look at flowing water in a scene that may not be very interesting, and as a result that possibly can be characterized as ordinary change an on the other hand, if you have a boat going through with the folks voting around that might be relevant and we maybe want to be able to pick that up as a relevant change and ignore everything else so."
        ],
        [
            "If we look at spatial temporal signatures of the mechanism to do something well, one of the things that we want to exploit is certainly try to localize changes in small regions.",
            "So we want to look at local patterns within the image and then come up with a way that we can characterize those local changes overtime.",
            "But also we want to come up with a measure where if the local pattern actually deviates from its normal repetetive signature or some kind of periodic signal.",
            "Then we should be able to get a high response and as a result differentiate that from something that might be persistently dynamic in the scene itself.",
            "Now the notion of using local patterns or spatial temporal signatures are not new that's being exploited in video analytics in recent years, and a multitude of transforms have been suggested, so building on this notion."
        ],
        [
            "What we wanted to explore was essentially a simple framework within which we could analyze these kind of dynamic videos.",
            "So what you have here is a is a generic framework that we put together where the idea is that initially you want to look at your data, try and decompose that into some self spatial temporal signatures that we can actually perform correlation analysis on in order to identify a compact signature signature that we can use as a feature that we can then try and characterize and model.",
            "And of course we want this to be something that we can extend and apply on every kind of test data set that we may encounter so that we can compare the signatures and come up with a way that we can measure a sense of similarity or dissimilarity in the context of our framework, we actually look at and compare patterns based on doing a significance testing that I'll discuss as I go around and discuss the conference of the framework."
        ],
        [
            "So the first and foremost the notion of trying to do spatial spatial temporal signature extraction, we want to be able to do that on a pixel by pixel basis in a way within the image, so we can localize the changes in its smallest form as much as possible.",
            "Now, of course this is something that can be can be a priori tuned if we know the kind of application domain that we're working under.",
            "But in order to actually characterize the spatial temporal signature, we want to leverage something that's sufficient.",
            "So in this work we looked at trying to.",
            "Leverage linear transforms that we can apply so."
        ],
        [
            "In a generic sense, what we have is a is a set of videos that we can look at and we can decompose a set of videos into small subset of frames and as a result and identify the data into 3 dimensional cube sets and over these cube sets we want to further decompose them into local regions, local cubes and we want to compute some sense for signature over those local cubes.",
            "So that's just a simple data decomposition or a grading scheme that we can impose on the on the data set that we have.",
            "Now."
        ],
        [
            "Within the data set, we want to explore a variety of linear transforms.",
            "Obviously, in order to compute a compact signature, it's not clear as to what transform I can leverage for a given underlying signature.",
            "As a result, initially we just started off by exploring three different transforms.",
            "We use a simple discrete cosine transform.",
            "We use a watch transform as well as Aslant transform, and the reason we use these three different Transformers simply because we have three different basis vectors.",
            "To help us characterize the underlying space restraint probably change that might be happening.",
            "Now, of course what we do is we compute these transforms over each of the cube sets that we have.",
            "The localized cube sets, and in this particular case, all our cube sets are simply defined as 8 by 8 by 8 cubes.",
            "So we compute those transforms and each one of those and then over the computed coefficients we define a notion of a compact signature in the compact Ness is defined entirely by computing the energy that we can."
        ],
        [
            "Pewter with signatures.",
            "Now of course, if we sum up all the coefficients, I expect the energy to sum up to one within the decomposed transform.",
            "So what I want to do is essentially define a sense of compactness where if I take and start summing the linearly ordered coefficients that I have, I want to find the ones that give me the highest or the closest value to one within the shortest number of coefficients that I can accumulate, right?",
            "So that's what I do, and basically I do that over all the.",
            "The transfer that I apply, and I say well, the one that I'll choose for a particular cube set, is the one that gives me the compactness measure as the maximum value across the three different transforms.",
            "I will only pick one of the transforms of the three, and I'll use that as a representative transform, but for that particular coefficient now on top of that I have now coefficient that I've extracted across those cubes.",
            "And of course if I look at it across the multiple set of frames that I have across the entire video, I'll end up with a lot of transform coefficients.",
            "Now I want don't want to necessarily represent all of them is as compact signature.",
            "So what I want to do is I want to somehow compute some statistics over the signatures I have."
        ],
        [
            "Across all the cube sets for the video at hand and what I want to do is simply look at the mean value if you will, of the coefficients I have selected for a particular transform across all the cube sets, and I'll represent that as the mean of all the coefficients I have, and Furthermore I will then compute a difference vector, an absolute difference for a cube sets coefficients with respect to the mean across the cubes over the entire video.",
            "That I have.",
            "And then of course I can compute the mean of that as well as the standard deviation, right?",
            "So the compact signature or the representation of the signature that I come up with then is simply the difference vectors for the coefficients I've selected as well as its mean and the standard deviation or the set of training frames that I have, so that becomes my signature."
        ],
        [
            "Once I have that signature, of course I can compute this for every video that I end up getting.",
            "So if I end up with a test video set, I'll repeat this entire procedure an I'll decompose the data set and I'll identify for the cube set that I have within that decompose data, set the corresponding.",
            "Transform that I was I used or identified during training and then compute the signature for that and then of course compute the difference of that signature with respect to my trained cube set that I have.",
            "Once again, if I compute this different signature with respect to the testing data that I got, I can compute a mean and a standard deviation over the coefficients I end up with now in general.",
            "As a result I will end up with for each cube set.",
            "A value or the different signature that are characterized by its mean and standard deviation, and I want to subject this too."
        ],
        [
            "Some kind of hypothesis testing in order to identify if the two signatures that I have the training one and the testing one are somehow different from each other and the way we do that, is by computing a bivariate.",
            "Inequality measure that was initially introduced by law and the Bible rate inequality measure simply states that if I have two random variables X&Y.",
            "Which are then characterized by the corresponding means and standard deviations as well as the correlation coefficient between the two.",
            "Then the joint distribution of the two has a lower bound where the lower bound for the joint probability will be defined within a specified interval that I can characterize by the mean and extended deviation for each of the independent variables so.",
            "You have the joint distribution that I defined that in the formula up there on the left, and that's defined by the inequality of lol.",
            "And then.",
            "Furthermore I can also define for the corresponding intervals that I want to characterize whether the two variables that I'm trying to do perform a significance test over are independent or not, and I actually equate the two of them together.",
            "So I simply say that my lower bound and upper bound for each of the independent variables.",
            "Is nothing but the average of the two means that I get and they are bounded by two times the measure of some standard deviation of the two variables on either end.",
            "And as a result, now I can compute these lower bounds and the joint distribution for the two random variables that I want to compare.",
            "Now for all the experiments that we did, we simply defined this lower bound to be a probability of .3 three, and as a result anything that deviates from that.",
            "We evaluate that as a relevant change.",
            "Otherwise we consider that to be an ordinary change."
        ],
        [
            "So this is what I end up with.",
            "Basically I have my 2 random variables X&Y and the random variables are nothing but the difference values that I compute over the coefficients in my cube set and then of course they are characterized by the mean as well as a standard deviation in that cube set and I can easily compute the joint probability over my training samples and the test sample that I end up getting.",
            "And of course I will apply this on a cube IQ basis in order to get sort of a binary change mask that I compute."
        ],
        [
            "Now since I want to compute this over all the frames in my video, we end up computing this as a cube set that is actually sliding over the entire set of video frames that we have, and the change mask that we actually compute over a set of eight frames is the joint or the OR operation between the result that we end up with the middle frames, right?",
            "So for every cube set that I have an 8 by 8 by 8 cubes, 8 frames, or it?",
            "A block of 8 by 8 pixels.",
            "I'll end up with one change mask an I want to slide that.",
            "Overall the video frames and the Change master report for a particular frame is going to be the odd result of the center 2 values.",
            "And of course this is going to be somewhat blocky simply because we are using 8 by 8 by 8 chunks and I want to do some spatial smoothing, so I simply use a small three by three window in order to smooth over the change mask that I end up with, right?",
            "So as a result of I frames like this, so I'll end up with changes that look something along those lines.",
            "And the white regions indicate the change.",
            "Now of course too."
        ],
        [
            "To do experiments over in order to evaluate this framework, what we did was we took videos from the dynamic background category defined on the benchmark.",
            "Overchangedetection.net this is a set of 6 videos that they have characterized over there which have reported ground truth values on a pixel by pixel basis and the way they define the ground truth values is that they define every pixel with the change value indicated by 2:55.",
            "There is a true change and define a mask or with the changes to be computed over the entire video frame.",
            "And then of course, if the motion is uncharacterized or something that should be reported as ordinary change, they have a separate label for that kind of emotion.",
            "So these are example video sets.",
            "These are the six video sets that they have within the within the benchmark data set.",
            "Now when we actually compute what we do."
        ],
        [
            "As we take the first 160 frames of each of these videos in order to do the training in order to identify which is the base transform that needs to be used for each cube within the within, the data set within the video and what we find is that depending on on the relevant background on the image, the chosen based transform is different under this particular selection criteria.",
            "So what you found what we find is that you know the.",
            "Colors represent the chosen transform for each of the blocks, so if you're if your background is some what?",
            "Periodic, more often than not, we end up picking a transform that represents the periodicity.",
            "On the other hand, if you end up with the background of the somewhat constant, then the chosen underlying transform represents a particular basis."
        ],
        [
            "So just to look at examples of some of the change detection that we get out of this framework, these are the changes that get picked up.",
            "So you see three different videos over here and you can see that the middle row represent the ground truth while the bottom row is the changes that we pick up through this framework.",
            "So the results look visually quite promising, and when we do a."
        ],
        [
            "Quantitative evaluation of range.",
            "The annotated data set that we have.",
            "What we find is that the framework actually performs quite well both in terms of the specificity of detected changes as well as the accuracy.",
            "Now the change detection.net as a website provides benchmarking capability, so we submitted our results onto the website as well and it's sort of a signs.",
            "Ranks two the algorithm and compares it to what other algorithms are we submitted on the website and it turns out that our performance as of now.",
            "Is outperforming all the other methods that have been submitted the closest performing method on the benchmark data set is the one that actually uses again the spatial temporal signature pattern, but it tries to encode a signature based on local binary patterns within a relevant 8 by 8 by 8 cube."
        ],
        [
            "So just to quickly wrap up.",
            "So the results are promising that we get out of this framework.",
            "There are certain limitations stemming from the method that we use, some of them being that you know the estimated base transform is identified during training and once it's identified during training, we persistently use the same transform for that particular data block throughout all the all the testing stages.",
            "Now of course, if somehow this could be converted into a more dynamic selection process.",
            "That would be beneficial because you may end up with changes that are not necessarily.",
            "Characterized by a single transform.",
            "And it may require a combination of multiple transforms.",
            "The second limitation comes from the fact that these are still block based computation, so the size of changes that you end up detecting are going to be limited by the smallest block size that you end up working with.",
            "And finally, you know we've not yet done large scale testing of this framework to see how it would perform on other kind of videos, and that's a future extension of their work.",
            "So with that I'll wrap up and be happy to take any.",
            "That you might have."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Alright, I'll talk a little bit about change detection and dynamic scenes using local adaptive transform.",
                    "label": 1
                },
                {
                    "sent": "This is work done with my student conference over there.",
                    "label": 0
                },
                {
                    "sent": "Unfortunately he was unable to come around to present his work, so just to sort of.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "For motivate the problem detecting changes in videos is certainly applicable in a multitude of problem domains.",
                    "label": 0
                },
                {
                    "sent": "Video surveillance being one of those medical imaging being another remote sensing and so on so forth an.",
                    "label": 1
                },
                {
                    "sent": "The key problem in identifying changes in videos is that there are a multitude of types of changes that occur.",
                    "label": 1
                },
                {
                    "sent": "Lot of them could be non interesting and a lot of work in looking at low level.",
                    "label": 0
                },
                {
                    "sent": "Detection and videos, especially surrounding changes as focused around the problem of trying to either model the background through understanding of the intensity distributions that occur or in order to try and characterize the changes that occur overtime through some kind of spatial temporal modeling, and certainly.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The exploitation of videos in the context of looking at spatial temporal distributions is extremely relevant because as you can see in this little example, if I have a fixed camera looking at it a scene, there's going to be what idea problems you will have.",
                    "label": 0
                },
                {
                    "sent": "Some movements of trees that will induce changes in pixel intensities and at the same time it will actually induce changes in the structure, but those may not be relevant or meaningful changes of interest.",
                    "label": 0
                },
                {
                    "sent": "On the other hand, if you have a vehicle that moves through.",
                    "label": 0
                },
                {
                    "sent": "That might be of particular interest depending on the problem domain.",
                    "label": 0
                },
                {
                    "sent": "So the question becomes how do we differentiate between what a meaningful changes and what are the changes that we can ignore and they are more attuned to the dynamic background of the changing signatures within the background itself.",
                    "label": 1
                },
                {
                    "sent": "So as a result, what we've been looking at.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "It is trying to differentiate between what we consider is ordered ordinary change versus what we may be able to characterize as relevant changes or things of interest in the video.",
                    "label": 1
                },
                {
                    "sent": "Now, if I look at these videos up here.",
                    "label": 0
                },
                {
                    "sent": "You have essentially on the top just a scene with flowing water an if we just look at flowing water in a scene that may not be very interesting, and as a result that possibly can be characterized as ordinary change an on the other hand, if you have a boat going through with the folks voting around that might be relevant and we maybe want to be able to pick that up as a relevant change and ignore everything else so.",
                    "label": 1
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "If we look at spatial temporal signatures of the mechanism to do something well, one of the things that we want to exploit is certainly try to localize changes in small regions.",
                    "label": 0
                },
                {
                    "sent": "So we want to look at local patterns within the image and then come up with a way that we can characterize those local changes overtime.",
                    "label": 0
                },
                {
                    "sent": "But also we want to come up with a measure where if the local pattern actually deviates from its normal repetetive signature or some kind of periodic signal.",
                    "label": 0
                },
                {
                    "sent": "Then we should be able to get a high response and as a result differentiate that from something that might be persistently dynamic in the scene itself.",
                    "label": 0
                },
                {
                    "sent": "Now the notion of using local patterns or spatial temporal signatures are not new that's being exploited in video analytics in recent years, and a multitude of transforms have been suggested, so building on this notion.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "What we wanted to explore was essentially a simple framework within which we could analyze these kind of dynamic videos.",
                    "label": 0
                },
                {
                    "sent": "So what you have here is a is a generic framework that we put together where the idea is that initially you want to look at your data, try and decompose that into some self spatial temporal signatures that we can actually perform correlation analysis on in order to identify a compact signature signature that we can use as a feature that we can then try and characterize and model.",
                    "label": 0
                },
                {
                    "sent": "And of course we want this to be something that we can extend and apply on every kind of test data set that we may encounter so that we can compare the signatures and come up with a way that we can measure a sense of similarity or dissimilarity in the context of our framework, we actually look at and compare patterns based on doing a significance testing that I'll discuss as I go around and discuss the conference of the framework.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the first and foremost the notion of trying to do spatial spatial temporal signature extraction, we want to be able to do that on a pixel by pixel basis in a way within the image, so we can localize the changes in its smallest form as much as possible.",
                    "label": 1
                },
                {
                    "sent": "Now, of course this is something that can be can be a priori tuned if we know the kind of application domain that we're working under.",
                    "label": 0
                },
                {
                    "sent": "But in order to actually characterize the spatial temporal signature, we want to leverage something that's sufficient.",
                    "label": 0
                },
                {
                    "sent": "So in this work we looked at trying to.",
                    "label": 1
                },
                {
                    "sent": "Leverage linear transforms that we can apply so.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In a generic sense, what we have is a is a set of videos that we can look at and we can decompose a set of videos into small subset of frames and as a result and identify the data into 3 dimensional cube sets and over these cube sets we want to further decompose them into local regions, local cubes and we want to compute some sense for signature over those local cubes.",
                    "label": 0
                },
                {
                    "sent": "So that's just a simple data decomposition or a grading scheme that we can impose on the on the data set that we have.",
                    "label": 0
                },
                {
                    "sent": "Now.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Within the data set, we want to explore a variety of linear transforms.",
                    "label": 1
                },
                {
                    "sent": "Obviously, in order to compute a compact signature, it's not clear as to what transform I can leverage for a given underlying signature.",
                    "label": 0
                },
                {
                    "sent": "As a result, initially we just started off by exploring three different transforms.",
                    "label": 1
                },
                {
                    "sent": "We use a simple discrete cosine transform.",
                    "label": 1
                },
                {
                    "sent": "We use a watch transform as well as Aslant transform, and the reason we use these three different Transformers simply because we have three different basis vectors.",
                    "label": 1
                },
                {
                    "sent": "To help us characterize the underlying space restraint probably change that might be happening.",
                    "label": 0
                },
                {
                    "sent": "Now, of course what we do is we compute these transforms over each of the cube sets that we have.",
                    "label": 0
                },
                {
                    "sent": "The localized cube sets, and in this particular case, all our cube sets are simply defined as 8 by 8 by 8 cubes.",
                    "label": 0
                },
                {
                    "sent": "So we compute those transforms and each one of those and then over the computed coefficients we define a notion of a compact signature in the compact Ness is defined entirely by computing the energy that we can.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Pewter with signatures.",
                    "label": 0
                },
                {
                    "sent": "Now of course, if we sum up all the coefficients, I expect the energy to sum up to one within the decomposed transform.",
                    "label": 0
                },
                {
                    "sent": "So what I want to do is essentially define a sense of compactness where if I take and start summing the linearly ordered coefficients that I have, I want to find the ones that give me the highest or the closest value to one within the shortest number of coefficients that I can accumulate, right?",
                    "label": 0
                },
                {
                    "sent": "So that's what I do, and basically I do that over all the.",
                    "label": 0
                },
                {
                    "sent": "The transfer that I apply, and I say well, the one that I'll choose for a particular cube set, is the one that gives me the compactness measure as the maximum value across the three different transforms.",
                    "label": 0
                },
                {
                    "sent": "I will only pick one of the transforms of the three, and I'll use that as a representative transform, but for that particular coefficient now on top of that I have now coefficient that I've extracted across those cubes.",
                    "label": 0
                },
                {
                    "sent": "And of course if I look at it across the multiple set of frames that I have across the entire video, I'll end up with a lot of transform coefficients.",
                    "label": 0
                },
                {
                    "sent": "Now I want don't want to necessarily represent all of them is as compact signature.",
                    "label": 0
                },
                {
                    "sent": "So what I want to do is I want to somehow compute some statistics over the signatures I have.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Across all the cube sets for the video at hand and what I want to do is simply look at the mean value if you will, of the coefficients I have selected for a particular transform across all the cube sets, and I'll represent that as the mean of all the coefficients I have, and Furthermore I will then compute a difference vector, an absolute difference for a cube sets coefficients with respect to the mean across the cubes over the entire video.",
                    "label": 1
                },
                {
                    "sent": "That I have.",
                    "label": 1
                },
                {
                    "sent": "And then of course I can compute the mean of that as well as the standard deviation, right?",
                    "label": 1
                },
                {
                    "sent": "So the compact signature or the representation of the signature that I come up with then is simply the difference vectors for the coefficients I've selected as well as its mean and the standard deviation or the set of training frames that I have, so that becomes my signature.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Once I have that signature, of course I can compute this for every video that I end up getting.",
                    "label": 0
                },
                {
                    "sent": "So if I end up with a test video set, I'll repeat this entire procedure an I'll decompose the data set and I'll identify for the cube set that I have within that decompose data, set the corresponding.",
                    "label": 1
                },
                {
                    "sent": "Transform that I was I used or identified during training and then compute the signature for that and then of course compute the difference of that signature with respect to my trained cube set that I have.",
                    "label": 0
                },
                {
                    "sent": "Once again, if I compute this different signature with respect to the testing data that I got, I can compute a mean and a standard deviation over the coefficients I end up with now in general.",
                    "label": 0
                },
                {
                    "sent": "As a result I will end up with for each cube set.",
                    "label": 1
                },
                {
                    "sent": "A value or the different signature that are characterized by its mean and standard deviation, and I want to subject this too.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Some kind of hypothesis testing in order to identify if the two signatures that I have the training one and the testing one are somehow different from each other and the way we do that, is by computing a bivariate.",
                    "label": 0
                },
                {
                    "sent": "Inequality measure that was initially introduced by law and the Bible rate inequality measure simply states that if I have two random variables X&Y.",
                    "label": 1
                },
                {
                    "sent": "Which are then characterized by the corresponding means and standard deviations as well as the correlation coefficient between the two.",
                    "label": 0
                },
                {
                    "sent": "Then the joint distribution of the two has a lower bound where the lower bound for the joint probability will be defined within a specified interval that I can characterize by the mean and extended deviation for each of the independent variables so.",
                    "label": 1
                },
                {
                    "sent": "You have the joint distribution that I defined that in the formula up there on the left, and that's defined by the inequality of lol.",
                    "label": 0
                },
                {
                    "sent": "And then.",
                    "label": 0
                },
                {
                    "sent": "Furthermore I can also define for the corresponding intervals that I want to characterize whether the two variables that I'm trying to do perform a significance test over are independent or not, and I actually equate the two of them together.",
                    "label": 0
                },
                {
                    "sent": "So I simply say that my lower bound and upper bound for each of the independent variables.",
                    "label": 0
                },
                {
                    "sent": "Is nothing but the average of the two means that I get and they are bounded by two times the measure of some standard deviation of the two variables on either end.",
                    "label": 1
                },
                {
                    "sent": "And as a result, now I can compute these lower bounds and the joint distribution for the two random variables that I want to compare.",
                    "label": 1
                },
                {
                    "sent": "Now for all the experiments that we did, we simply defined this lower bound to be a probability of .3 three, and as a result anything that deviates from that.",
                    "label": 0
                },
                {
                    "sent": "We evaluate that as a relevant change.",
                    "label": 0
                },
                {
                    "sent": "Otherwise we consider that to be an ordinary change.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this is what I end up with.",
                    "label": 0
                },
                {
                    "sent": "Basically I have my 2 random variables X&Y and the random variables are nothing but the difference values that I compute over the coefficients in my cube set and then of course they are characterized by the mean as well as a standard deviation in that cube set and I can easily compute the joint probability over my training samples and the test sample that I end up getting.",
                    "label": 1
                },
                {
                    "sent": "And of course I will apply this on a cube IQ basis in order to get sort of a binary change mask that I compute.",
                    "label": 1
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now since I want to compute this over all the frames in my video, we end up computing this as a cube set that is actually sliding over the entire set of video frames that we have, and the change mask that we actually compute over a set of eight frames is the joint or the OR operation between the result that we end up with the middle frames, right?",
                    "label": 0
                },
                {
                    "sent": "So for every cube set that I have an 8 by 8 by 8 cubes, 8 frames, or it?",
                    "label": 0
                },
                {
                    "sent": "A block of 8 by 8 pixels.",
                    "label": 0
                },
                {
                    "sent": "I'll end up with one change mask an I want to slide that.",
                    "label": 1
                },
                {
                    "sent": "Overall the video frames and the Change master report for a particular frame is going to be the odd result of the center 2 values.",
                    "label": 0
                },
                {
                    "sent": "And of course this is going to be somewhat blocky simply because we are using 8 by 8 by 8 chunks and I want to do some spatial smoothing, so I simply use a small three by three window in order to smooth over the change mask that I end up with, right?",
                    "label": 0
                },
                {
                    "sent": "So as a result of I frames like this, so I'll end up with changes that look something along those lines.",
                    "label": 0
                },
                {
                    "sent": "And the white regions indicate the change.",
                    "label": 0
                },
                {
                    "sent": "Now of course too.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "To do experiments over in order to evaluate this framework, what we did was we took videos from the dynamic background category defined on the benchmark.",
                    "label": 1
                },
                {
                    "sent": "Overchangedetection.net this is a set of 6 videos that they have characterized over there which have reported ground truth values on a pixel by pixel basis and the way they define the ground truth values is that they define every pixel with the change value indicated by 2:55.",
                    "label": 1
                },
                {
                    "sent": "There is a true change and define a mask or with the changes to be computed over the entire video frame.",
                    "label": 0
                },
                {
                    "sent": "And then of course, if the motion is uncharacterized or something that should be reported as ordinary change, they have a separate label for that kind of emotion.",
                    "label": 0
                },
                {
                    "sent": "So these are example video sets.",
                    "label": 0
                },
                {
                    "sent": "These are the six video sets that they have within the within the benchmark data set.",
                    "label": 0
                },
                {
                    "sent": "Now when we actually compute what we do.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "As we take the first 160 frames of each of these videos in order to do the training in order to identify which is the base transform that needs to be used for each cube within the within, the data set within the video and what we find is that depending on on the relevant background on the image, the chosen based transform is different under this particular selection criteria.",
                    "label": 0
                },
                {
                    "sent": "So what you found what we find is that you know the.",
                    "label": 0
                },
                {
                    "sent": "Colors represent the chosen transform for each of the blocks, so if you're if your background is some what?",
                    "label": 0
                },
                {
                    "sent": "Periodic, more often than not, we end up picking a transform that represents the periodicity.",
                    "label": 0
                },
                {
                    "sent": "On the other hand, if you end up with the background of the somewhat constant, then the chosen underlying transform represents a particular basis.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So just to look at examples of some of the change detection that we get out of this framework, these are the changes that get picked up.",
                    "label": 0
                },
                {
                    "sent": "So you see three different videos over here and you can see that the middle row represent the ground truth while the bottom row is the changes that we pick up through this framework.",
                    "label": 0
                },
                {
                    "sent": "So the results look visually quite promising, and when we do a.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Quantitative evaluation of range.",
                    "label": 0
                },
                {
                    "sent": "The annotated data set that we have.",
                    "label": 0
                },
                {
                    "sent": "What we find is that the framework actually performs quite well both in terms of the specificity of detected changes as well as the accuracy.",
                    "label": 0
                },
                {
                    "sent": "Now the change detection.net as a website provides benchmarking capability, so we submitted our results onto the website as well and it's sort of a signs.",
                    "label": 0
                },
                {
                    "sent": "Ranks two the algorithm and compares it to what other algorithms are we submitted on the website and it turns out that our performance as of now.",
                    "label": 0
                },
                {
                    "sent": "Is outperforming all the other methods that have been submitted the closest performing method on the benchmark data set is the one that actually uses again the spatial temporal signature pattern, but it tries to encode a signature based on local binary patterns within a relevant 8 by 8 by 8 cube.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So just to quickly wrap up.",
                    "label": 0
                },
                {
                    "sent": "So the results are promising that we get out of this framework.",
                    "label": 0
                },
                {
                    "sent": "There are certain limitations stemming from the method that we use, some of them being that you know the estimated base transform is identified during training and once it's identified during training, we persistently use the same transform for that particular data block throughout all the all the testing stages.",
                    "label": 0
                },
                {
                    "sent": "Now of course, if somehow this could be converted into a more dynamic selection process.",
                    "label": 0
                },
                {
                    "sent": "That would be beneficial because you may end up with changes that are not necessarily.",
                    "label": 0
                },
                {
                    "sent": "Characterized by a single transform.",
                    "label": 0
                },
                {
                    "sent": "And it may require a combination of multiple transforms.",
                    "label": 0
                },
                {
                    "sent": "The second limitation comes from the fact that these are still block based computation, so the size of changes that you end up detecting are going to be limited by the smallest block size that you end up working with.",
                    "label": 0
                },
                {
                    "sent": "And finally, you know we've not yet done large scale testing of this framework to see how it would perform on other kind of videos, and that's a future extension of their work.",
                    "label": 0
                },
                {
                    "sent": "So with that I'll wrap up and be happy to take any.",
                    "label": 0
                },
                {
                    "sent": "That you might have.",
                    "label": 0
                }
            ]
        }
    }
}