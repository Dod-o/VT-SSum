{
    "id": "swaqzghehfhmire2twe7uyth6od5345b",
    "title": "The JANES Project: Tools and Resources for Linguistic Analysis and Automatic Processing of User-Generated Content in Slovene",
    "info": {
        "author": [
            "Nikola Ljube\u0161i\u0107, Department of Knowledge Technologies, Jo\u017eef Stefan Institute"
        ],
        "published": "June 21, 2017",
        "recorded": "May 2017",
        "category": [
            "Top->Humanities->Languages",
            "Top->Computers->Digital Media",
            "Top->Computer Science->Social Media"
        ]
    },
    "url": "http://videolectures.net/clarinplusworkshop2017_ljubesic_janes_project/",
    "segmentation": [
        [
            "So hello everyone."
        ],
        [
            "Oh, thank you.",
            "My name is Nicola Lubitsch.",
            "I currently work at the age of Seven Institute in New Byana and I will present some of the results of the youngest project.",
            "Which mostly focused on automatic processing and linguistic analysis of Slovene user generated content."
        ],
        [
            "So Giannis was or still is the national Basic Research project, which lasts for three years.",
            "There were two institutions, which one technical and the other, rather linguistic ones with a team members and the main work packages where corpus, construction, linguistic analysis and resource and tool development.",
            "This is the website if you're interested in more details so."
        ],
        [
            "Now go to the 1st and deferred work package.",
            "So regarding the corpus it's currently in the 0.4 version, it will be compiled soon.",
            "In the final version, so we have various text types tweets for our blogs, news, comments and Wikipedia talk pages altogether.",
            "Roughly 200 million tokens in size.",
            "Regarding data processing, we do normalization morphosyntactic annotation and text or user level metadata enrichment, and I will talk about the.",
            "Data processing in the remainder of the presentation."
        ],
        [
            "When I will talk about resources and tools that we have developed inside the project linguistic part, I will not go in.",
            "So first of all, we develop that we'd cut tool that you can find a little bit about doing the Hanson session tonight to today in the afternoon.",
            "And this tool is especially useful for harvesting collections of low frequency languages, like Lavine, because there's just a small portion of Twitter being written in Slovene.",
            "The next tool I want to talk about is the CS Intizar so tool with a weird name for text normalization.",
            "It's actually based on.",
            "Very straightforward approach of character level, statistical machine translation and it actually achieves state of the art results.",
            "So many have tried to beat it with neural networks at the share task last year, I think, but it didn't succeed.",
            "So since Intizar was ranked first on the task of normalizing historical batch text sci-fi remember correctly and we have applied this tool too many languages by now.",
            "This is specially for Simona.",
            "It is just for you.",
            "So if you take Swiss German.",
            "And if you don't do anything with the text, you will have token level accuracy of 22%, so most of the tax has to be changed when normalized into some metals with German ansias intizar does 90%.",
            "Some reasonable baselines do around 80%, so you get quite a lot with multiple language models, tuning etc.",
            "And we did the same thing for multiple other languages like Slovene, Croatian, Serbian, Dutch and we applied it both to DirectX historical texts and computer mediated communication.",
            "So this tool is quite diverse, can be easy.",
            "We trained with reasonable amount of manually normalized data."
        ],
        [
            "Furthermore, we did some improvements on the tagger, so this was talked about doing today.",
            "Stay for multiple times.",
            "So if you have a standard model trained on newspaper texts, we achieved 95% accuracy in Slovene you have to take into account that we discriminate between 900 different morphosyntactic categories.",
            "So this is quite the hard task and if you just take this model and apply it on Twitter data or non standard with the later your model just falls apart and you get accuracy of 69%.",
            "But then if you do a few of tweaks, for instance at domain training data, which is very nice, some other standard.",
            "Tricks like adding some distributional information, some normalization information, etc.",
            "You can climb up back to roughly 88%, so it's still not at the accuracy level of standard text, but much, much better or useful.",
            "While 69% is actually not that useful.",
            "And this tagger was actually trained on multiple resources.",
            "We have developed resources for Slovene, Croatian, and Serbian following the same principles.",
            "The slovene.",
            "If the soil set is currently the most richest one because it contains normalization information, morphosyntactic annotation information, lemmatization and named entities while named this will be added to the Croatian Serbian datasets.",
            "They're all available from Clarion, and these tools are all available from GitHub, and this data sets were also eager to communicate with other people with similar datasets, maybe to organize some shared tasks so shared task.",
            "Obviously beautiful ways of comparing.",
            "Approaches and if other people have datasets in different language insults like languages, we are very good to join forces."
        ],
        [
            "Regarding metadata in Richmond.",
            "So inside of Giannis with two levels of text level enrichment.",
            "So first of all we predict the technical and linguistic level of tech standardness believe it or not most people flesh to eat examples that are highly unstandard about like 90% of Twitter is actually highly standard, at least in South like languages.",
            "So if linguists are interested in the non standard part of or some other researchers then you were supposed to fish out the mostly non standard data and this is what we did for the first level.",
            "The second level is the sentiment analysis enrichment and on the user level we did gender types in this communication between private and corporate users and region.",
            "So this was the enrichment part."
        ],
        [
            "And just for the final slides.",
            "So Giannis is coming to its end, but Frank is just starting.",
            "Frank is not on user generated content per say but on an annotation analysis and identification of socially unacceptable discourse.",
            "So a broader category then hate speech.",
            "So this project has just started.",
            "It has full partner, so it is a interdisciplinary project.",
            "It has technical people for mental pain, machine learning in it, but also linguists, social Sciences, people, and law.",
            "So starting law, so this is actually the setting that we believe is necessary to take this problem.",
            "We will focus on Facebook comments both from mainstream media and weird Facebook pages where people awkward positions meet and will have a rather complicated notation schema with seven level availables professional annotators, multiple annotations etc.",
            "And regarding the prediction tasks.",
            "So this handled Peapod will have different types of features it goes.",
            "So roughly with what Derek was talking previously, so we want just use the features audience signal that comes from the text will also use the signal coming from the overall post, like the sentiment or the standardness or the time it was published.",
            "All but also discussed level features like what is the dynamics of the discussions in these threads that we are analyzing and user level features like demographical information or general behavior in the social network.",
            "So this would be it for myself I guess."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So hello everyone.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Oh, thank you.",
                    "label": 0
                },
                {
                    "sent": "My name is Nicola Lubitsch.",
                    "label": 0
                },
                {
                    "sent": "I currently work at the age of Seven Institute in New Byana and I will present some of the results of the youngest project.",
                    "label": 0
                },
                {
                    "sent": "Which mostly focused on automatic processing and linguistic analysis of Slovene user generated content.",
                    "label": 1
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So Giannis was or still is the national Basic Research project, which lasts for three years.",
                    "label": 1
                },
                {
                    "sent": "There were two institutions, which one technical and the other, rather linguistic ones with a team members and the main work packages where corpus, construction, linguistic analysis and resource and tool development.",
                    "label": 1
                },
                {
                    "sent": "This is the website if you're interested in more details so.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now go to the 1st and deferred work package.",
                    "label": 0
                },
                {
                    "sent": "So regarding the corpus it's currently in the 0.4 version, it will be compiled soon.",
                    "label": 0
                },
                {
                    "sent": "In the final version, so we have various text types tweets for our blogs, news, comments and Wikipedia talk pages altogether.",
                    "label": 1
                },
                {
                    "sent": "Roughly 200 million tokens in size.",
                    "label": 0
                },
                {
                    "sent": "Regarding data processing, we do normalization morphosyntactic annotation and text or user level metadata enrichment, and I will talk about the.",
                    "label": 1
                },
                {
                    "sent": "Data processing in the remainder of the presentation.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "When I will talk about resources and tools that we have developed inside the project linguistic part, I will not go in.",
                    "label": 0
                },
                {
                    "sent": "So first of all, we develop that we'd cut tool that you can find a little bit about doing the Hanson session tonight to today in the afternoon.",
                    "label": 0
                },
                {
                    "sent": "And this tool is especially useful for harvesting collections of low frequency languages, like Lavine, because there's just a small portion of Twitter being written in Slovene.",
                    "label": 1
                },
                {
                    "sent": "The next tool I want to talk about is the CS Intizar so tool with a weird name for text normalization.",
                    "label": 0
                },
                {
                    "sent": "It's actually based on.",
                    "label": 0
                },
                {
                    "sent": "Very straightforward approach of character level, statistical machine translation and it actually achieves state of the art results.",
                    "label": 0
                },
                {
                    "sent": "So many have tried to beat it with neural networks at the share task last year, I think, but it didn't succeed.",
                    "label": 0
                },
                {
                    "sent": "So since Intizar was ranked first on the task of normalizing historical batch text sci-fi remember correctly and we have applied this tool too many languages by now.",
                    "label": 0
                },
                {
                    "sent": "This is specially for Simona.",
                    "label": 0
                },
                {
                    "sent": "It is just for you.",
                    "label": 0
                },
                {
                    "sent": "So if you take Swiss German.",
                    "label": 0
                },
                {
                    "sent": "And if you don't do anything with the text, you will have token level accuracy of 22%, so most of the tax has to be changed when normalized into some metals with German ansias intizar does 90%.",
                    "label": 0
                },
                {
                    "sent": "Some reasonable baselines do around 80%, so you get quite a lot with multiple language models, tuning etc.",
                    "label": 1
                },
                {
                    "sent": "And we did the same thing for multiple other languages like Slovene, Croatian, Serbian, Dutch and we applied it both to DirectX historical texts and computer mediated communication.",
                    "label": 0
                },
                {
                    "sent": "So this tool is quite diverse, can be easy.",
                    "label": 0
                },
                {
                    "sent": "We trained with reasonable amount of manually normalized data.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Furthermore, we did some improvements on the tagger, so this was talked about doing today.",
                    "label": 0
                },
                {
                    "sent": "Stay for multiple times.",
                    "label": 0
                },
                {
                    "sent": "So if you have a standard model trained on newspaper texts, we achieved 95% accuracy in Slovene you have to take into account that we discriminate between 900 different morphosyntactic categories.",
                    "label": 0
                },
                {
                    "sent": "So this is quite the hard task and if you just take this model and apply it on Twitter data or non standard with the later your model just falls apart and you get accuracy of 69%.",
                    "label": 0
                },
                {
                    "sent": "But then if you do a few of tweaks, for instance at domain training data, which is very nice, some other standard.",
                    "label": 0
                },
                {
                    "sent": "Tricks like adding some distributional information, some normalization information, etc.",
                    "label": 0
                },
                {
                    "sent": "You can climb up back to roughly 88%, so it's still not at the accuracy level of standard text, but much, much better or useful.",
                    "label": 0
                },
                {
                    "sent": "While 69% is actually not that useful.",
                    "label": 0
                },
                {
                    "sent": "And this tagger was actually trained on multiple resources.",
                    "label": 0
                },
                {
                    "sent": "We have developed resources for Slovene, Croatian, and Serbian following the same principles.",
                    "label": 1
                },
                {
                    "sent": "The slovene.",
                    "label": 0
                },
                {
                    "sent": "If the soil set is currently the most richest one because it contains normalization information, morphosyntactic annotation information, lemmatization and named entities while named this will be added to the Croatian Serbian datasets.",
                    "label": 0
                },
                {
                    "sent": "They're all available from Clarion, and these tools are all available from GitHub, and this data sets were also eager to communicate with other people with similar datasets, maybe to organize some shared tasks so shared task.",
                    "label": 0
                },
                {
                    "sent": "Obviously beautiful ways of comparing.",
                    "label": 0
                },
                {
                    "sent": "Approaches and if other people have datasets in different language insults like languages, we are very good to join forces.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Regarding metadata in Richmond.",
                    "label": 0
                },
                {
                    "sent": "So inside of Giannis with two levels of text level enrichment.",
                    "label": 0
                },
                {
                    "sent": "So first of all we predict the technical and linguistic level of tech standardness believe it or not most people flesh to eat examples that are highly unstandard about like 90% of Twitter is actually highly standard, at least in South like languages.",
                    "label": 0
                },
                {
                    "sent": "So if linguists are interested in the non standard part of or some other researchers then you were supposed to fish out the mostly non standard data and this is what we did for the first level.",
                    "label": 0
                },
                {
                    "sent": "The second level is the sentiment analysis enrichment and on the user level we did gender types in this communication between private and corporate users and region.",
                    "label": 0
                },
                {
                    "sent": "So this was the enrichment part.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And just for the final slides.",
                    "label": 0
                },
                {
                    "sent": "So Giannis is coming to its end, but Frank is just starting.",
                    "label": 0
                },
                {
                    "sent": "Frank is not on user generated content per say but on an annotation analysis and identification of socially unacceptable discourse.",
                    "label": 1
                },
                {
                    "sent": "So a broader category then hate speech.",
                    "label": 0
                },
                {
                    "sent": "So this project has just started.",
                    "label": 0
                },
                {
                    "sent": "It has full partner, so it is a interdisciplinary project.",
                    "label": 0
                },
                {
                    "sent": "It has technical people for mental pain, machine learning in it, but also linguists, social Sciences, people, and law.",
                    "label": 0
                },
                {
                    "sent": "So starting law, so this is actually the setting that we believe is necessary to take this problem.",
                    "label": 1
                },
                {
                    "sent": "We will focus on Facebook comments both from mainstream media and weird Facebook pages where people awkward positions meet and will have a rather complicated notation schema with seven level availables professional annotators, multiple annotations etc.",
                    "label": 0
                },
                {
                    "sent": "And regarding the prediction tasks.",
                    "label": 0
                },
                {
                    "sent": "So this handled Peapod will have different types of features it goes.",
                    "label": 0
                },
                {
                    "sent": "So roughly with what Derek was talking previously, so we want just use the features audience signal that comes from the text will also use the signal coming from the overall post, like the sentiment or the standardness or the time it was published.",
                    "label": 0
                },
                {
                    "sent": "All but also discussed level features like what is the dynamics of the discussions in these threads that we are analyzing and user level features like demographical information or general behavior in the social network.",
                    "label": 0
                },
                {
                    "sent": "So this would be it for myself I guess.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": []
        }
    }
}