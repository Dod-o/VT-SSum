{
    "id": "ywuecyfksqqifrdw34wl7scwk5brfh5p",
    "title": "Ensemble Pruning via Individual Contribution Ordering",
    "info": {
        "author": [
            "Zhenyu Lu, College of Engineering and Mathematical Sciences, University of Vermont"
        ],
        "published": "Oct. 1, 2010",
        "recorded": "July 2010",
        "category": [
            "Top->Computer Science->Data Mining",
            "Top->Computer Science->Databases"
        ]
    },
    "url": "http://videolectures.net/kdd2010_lu_epic/",
    "segmentation": [
        [
            "I'm doing all the work is done by me by code Advisor.",
            "Hunger from the University of above and our colleague machines and tools from University of Technology, Sydney."
        ],
        [
            "So what is known?",
            "The barriers that make predictions activate so has been proven to be successful in many applications.",
            "But one problem because existing automobile sources that tends to build large consumers."
        ],
        [
            "One question was in.",
            "Wasn't raised as that given an ensemble all on some members necessary.",
            "The answer is no.",
            "In many cases, like in this toy example, some classifiers can be taken out safely without hurting the performance of the whole ensemble.",
            "The technique to take a construct someone stumbles that is as good as or even better than the whole ensemble is called on some pruning or selective ensemble."
        ],
        [
            "It hasn't proven that.",
            "Many could be better or which is sub.",
            "Also most could be better than the whole ensemble.",
            "As an example of a state of the art of opening method aren't agent ordering.",
            "Oh is pruning method that given and assemble it, reorders the ensemble members in terms of their expected performance in sub ensembles.",
            "And by incorporating classifiers on sum of numbers according to this order, some more samples can be constructed that is better than the whole ensemble for this auto set.",
            "The green line here is error code of the bagging ensemble.",
            "With the increase of our summer sitis.",
            "As you can see the error goes monotonically down.",
            "But if you reorder the other numbers by oh.",
            "Incorporate all numbers according to this order.",
            "Someone stumbles with 40 around 40.",
            "Size out on 40, is much better than the whole example, and is the lowest error in this order.",
            "So our approach is similar to awesome aren't ignoring in that we reorder the other numbers.",
            "Are the differences that we use different measures to reorder them?"
        ],
        [
            "So our method is called on summer pruning their individual conservation darling epic short.",
            "So I'm just show you one example here, said so the error curve if you incorporate on some Members according to the order given by Epic, outperforms the color that given by oh, and it's better than whole sample."
        ],
        [
            "So the intuition of our approach as any other method, the accuracy diverse tradeoff is crucial, which means both the accuracy of individual classifiers and the diversity of the whole ensemble are crucial."
        ],
        [
            "So let me introduce the heuristic of individual contribution, so this individual contribution.",
            "Is defined as each ensemble members expected performance in sub ensembles.",
            "Given one number and one data point, there are four cases.",
            "The first one is that the number is correct, but it's in the majority.",
            "The second one is correct, and in the majority, and it could be incorrect and in the majority and incorrect.",
            "But in the majority.",
            "Intuitively.",
            "Each correct predictions make positive contribution and each incorrect predictions make negative contribution.",
            "On top of that.",
            "In this paper we gave the order of individual contribution of this four cases, which is that if you are correct but in the minority, your individual contribution is the highest, and if you are incorrect, but in the majority your contribution is the lowest.",
            "To understand this, take the first case.",
            "For example, when you're correct, but in the majority, you're both accurate and your contribute diversity.",
            "To downsample 'cause you're more different with your peer members.",
            "If you're incorrect.",
            "But in the majority.",
            "You are both incorrect, accurate and you're not that diverse.",
            "So.",
            "We in the paper we just described measure numerical measure that is based on this order.",
            "For details, please come to the poster session.",
            "Die"
        ],
        [
            "Prism epic.",
            "1st to train sample of classifiers, then calculate individual contribution of each ensemble member.",
            "I'm gonna selection set in this paper.",
            "The selection set is an independent set from trains at testing set.",
            "And reorder each member by decreasing contribution and output.",
            "The first X percent of individual classifiers."
        ],
        [
            "So you've seen this example before, so the setting is that for each data set there are 300 independent runs.",
            "The ultimate size is 200 and the base learner was J48 and also method was back."
        ],
        [
            "We conducted experiments on 26 datasets from UCI and with the same settings and the Paris represents the wind tilhas situation of T test.",
            "As you can see.",
            "Oh, I picked on the forum both oh and bagging whole ensemble on two different settings, which is if you take the X percent because 250% or 30%."
        ],
        [
            "Conclusions.",
            "The main contribution of this paper is that.",
            "The four cases have a strict order, which is in decreasing order.",
            "Correct minority, correct charity, incorrect minority, incorrect majority and epic.",
            "Based on this individual contribution measure is a single parameter.",
            "Fast and effective pruning method is spring.",
            "Time is near linear to the size of ensemble.",
            "Is affective 'cause up from a state of the art of.",
            "Doesn't matter, so for future work we would like to make Epic parameter list, so this is relatively easy if you're using a selection set, you can just use it as a validation set to find the sub ensemble with the lowest error point and would like to test and generalize epic to let them work with like different baseball fires and different also methods and maybe higher genus almost.",
            "Find we would also like to design better individual contribution mirror.",
            "Thank you.",
            "We have time for questions.",
            "So I'm not very clear on how to calculate GPC score.",
            "It seems very promising, but is it calculated score by considering every individual classifier on every individual instance in the validation sets, then aggregate the score together to get a score for the individual classifier?",
            "Yes, exactly.",
            "OK.",
            "So any more question, so very good time controller.",
            "It's time for coffee break.",
            "Very much thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I'm doing all the work is done by me by code Advisor.",
                    "label": 0
                },
                {
                    "sent": "Hunger from the University of above and our colleague machines and tools from University of Technology, Sydney.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So what is known?",
                    "label": 0
                },
                {
                    "sent": "The barriers that make predictions activate so has been proven to be successful in many applications.",
                    "label": 0
                },
                {
                    "sent": "But one problem because existing automobile sources that tends to build large consumers.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "One question was in.",
                    "label": 0
                },
                {
                    "sent": "Wasn't raised as that given an ensemble all on some members necessary.",
                    "label": 0
                },
                {
                    "sent": "The answer is no.",
                    "label": 0
                },
                {
                    "sent": "In many cases, like in this toy example, some classifiers can be taken out safely without hurting the performance of the whole ensemble.",
                    "label": 0
                },
                {
                    "sent": "The technique to take a construct someone stumbles that is as good as or even better than the whole ensemble is called on some pruning or selective ensemble.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "It hasn't proven that.",
                    "label": 0
                },
                {
                    "sent": "Many could be better or which is sub.",
                    "label": 1
                },
                {
                    "sent": "Also most could be better than the whole ensemble.",
                    "label": 0
                },
                {
                    "sent": "As an example of a state of the art of opening method aren't agent ordering.",
                    "label": 0
                },
                {
                    "sent": "Oh is pruning method that given and assemble it, reorders the ensemble members in terms of their expected performance in sub ensembles.",
                    "label": 0
                },
                {
                    "sent": "And by incorporating classifiers on sum of numbers according to this order, some more samples can be constructed that is better than the whole ensemble for this auto set.",
                    "label": 0
                },
                {
                    "sent": "The green line here is error code of the bagging ensemble.",
                    "label": 0
                },
                {
                    "sent": "With the increase of our summer sitis.",
                    "label": 0
                },
                {
                    "sent": "As you can see the error goes monotonically down.",
                    "label": 0
                },
                {
                    "sent": "But if you reorder the other numbers by oh.",
                    "label": 0
                },
                {
                    "sent": "Incorporate all numbers according to this order.",
                    "label": 0
                },
                {
                    "sent": "Someone stumbles with 40 around 40.",
                    "label": 0
                },
                {
                    "sent": "Size out on 40, is much better than the whole example, and is the lowest error in this order.",
                    "label": 0
                },
                {
                    "sent": "So our approach is similar to awesome aren't ignoring in that we reorder the other numbers.",
                    "label": 0
                },
                {
                    "sent": "Are the differences that we use different measures to reorder them?",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So our method is called on summer pruning their individual conservation darling epic short.",
                    "label": 0
                },
                {
                    "sent": "So I'm just show you one example here, said so the error curve if you incorporate on some Members according to the order given by Epic, outperforms the color that given by oh, and it's better than whole sample.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the intuition of our approach as any other method, the accuracy diverse tradeoff is crucial, which means both the accuracy of individual classifiers and the diversity of the whole ensemble are crucial.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So let me introduce the heuristic of individual contribution, so this individual contribution.",
                    "label": 0
                },
                {
                    "sent": "Is defined as each ensemble members expected performance in sub ensembles.",
                    "label": 0
                },
                {
                    "sent": "Given one number and one data point, there are four cases.",
                    "label": 0
                },
                {
                    "sent": "The first one is that the number is correct, but it's in the majority.",
                    "label": 0
                },
                {
                    "sent": "The second one is correct, and in the majority, and it could be incorrect and in the majority and incorrect.",
                    "label": 1
                },
                {
                    "sent": "But in the majority.",
                    "label": 0
                },
                {
                    "sent": "Intuitively.",
                    "label": 0
                },
                {
                    "sent": "Each correct predictions make positive contribution and each incorrect predictions make negative contribution.",
                    "label": 0
                },
                {
                    "sent": "On top of that.",
                    "label": 1
                },
                {
                    "sent": "In this paper we gave the order of individual contribution of this four cases, which is that if you are correct but in the minority, your individual contribution is the highest, and if you are incorrect, but in the majority your contribution is the lowest.",
                    "label": 0
                },
                {
                    "sent": "To understand this, take the first case.",
                    "label": 0
                },
                {
                    "sent": "For example, when you're correct, but in the majority, you're both accurate and your contribute diversity.",
                    "label": 0
                },
                {
                    "sent": "To downsample 'cause you're more different with your peer members.",
                    "label": 0
                },
                {
                    "sent": "If you're incorrect.",
                    "label": 0
                },
                {
                    "sent": "But in the majority.",
                    "label": 0
                },
                {
                    "sent": "You are both incorrect, accurate and you're not that diverse.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "We in the paper we just described measure numerical measure that is based on this order.",
                    "label": 0
                },
                {
                    "sent": "For details, please come to the poster session.",
                    "label": 0
                },
                {
                    "sent": "Die",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Prism epic.",
                    "label": 0
                },
                {
                    "sent": "1st to train sample of classifiers, then calculate individual contribution of each ensemble member.",
                    "label": 1
                },
                {
                    "sent": "I'm gonna selection set in this paper.",
                    "label": 0
                },
                {
                    "sent": "The selection set is an independent set from trains at testing set.",
                    "label": 0
                },
                {
                    "sent": "And reorder each member by decreasing contribution and output.",
                    "label": 1
                },
                {
                    "sent": "The first X percent of individual classifiers.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So you've seen this example before, so the setting is that for each data set there are 300 independent runs.",
                    "label": 0
                },
                {
                    "sent": "The ultimate size is 200 and the base learner was J48 and also method was back.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We conducted experiments on 26 datasets from UCI and with the same settings and the Paris represents the wind tilhas situation of T test.",
                    "label": 0
                },
                {
                    "sent": "As you can see.",
                    "label": 0
                },
                {
                    "sent": "Oh, I picked on the forum both oh and bagging whole ensemble on two different settings, which is if you take the X percent because 250% or 30%.",
                    "label": 1
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Conclusions.",
                    "label": 0
                },
                {
                    "sent": "The main contribution of this paper is that.",
                    "label": 0
                },
                {
                    "sent": "The four cases have a strict order, which is in decreasing order.",
                    "label": 1
                },
                {
                    "sent": "Correct minority, correct charity, incorrect minority, incorrect majority and epic.",
                    "label": 1
                },
                {
                    "sent": "Based on this individual contribution measure is a single parameter.",
                    "label": 1
                },
                {
                    "sent": "Fast and effective pruning method is spring.",
                    "label": 1
                },
                {
                    "sent": "Time is near linear to the size of ensemble.",
                    "label": 0
                },
                {
                    "sent": "Is affective 'cause up from a state of the art of.",
                    "label": 0
                },
                {
                    "sent": "Doesn't matter, so for future work we would like to make Epic parameter list, so this is relatively easy if you're using a selection set, you can just use it as a validation set to find the sub ensemble with the lowest error point and would like to test and generalize epic to let them work with like different baseball fires and different also methods and maybe higher genus almost.",
                    "label": 1
                },
                {
                    "sent": "Find we would also like to design better individual contribution mirror.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                },
                {
                    "sent": "We have time for questions.",
                    "label": 0
                },
                {
                    "sent": "So I'm not very clear on how to calculate GPC score.",
                    "label": 0
                },
                {
                    "sent": "It seems very promising, but is it calculated score by considering every individual classifier on every individual instance in the validation sets, then aggregate the score together to get a score for the individual classifier?",
                    "label": 0
                },
                {
                    "sent": "Yes, exactly.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So any more question, so very good time controller.",
                    "label": 0
                },
                {
                    "sent": "It's time for coffee break.",
                    "label": 0
                },
                {
                    "sent": "Very much thank you.",
                    "label": 0
                }
            ]
        }
    }
}