{
    "id": "wthfcpeud2drmtwbnzcg3vcpbzhqcaxe",
    "title": "DeFacto - Deep Fact Validation",
    "info": {
        "author": [
            "Daniel Gerber, Department of Business Information Systems, University of Leipzig"
        ],
        "published": "Dec. 3, 2012",
        "recorded": "November 2012",
        "category": [
            "Top->Computer Science->Semantic Web->Linked Data"
        ]
    },
    "url": "http://videolectures.net/iswc2012_gerber_defacto/",
    "segmentation": [
        [
            "My name is Daniel and I'm going to present to you the joint work I've done together with Jens Lehmann more mid, more, say in axle curled mongomo.",
            "All of us are from the University of Lipstick and CSW Research Group, so the talk I'm going to give today is about the factor which is an acronym for the Deep Fact Validation."
        ],
        [
            "So what was our motivation?",
            "Let's consider.",
            "We have this little knowledge base here about the movie domain, and let's assume this was extracted from an automatic approach.",
            "So from free text.",
            "So if we have if we're going to look at the single triple here, we don't have any information about it.",
            "In terms of metadata, so we don't really know if that's true or not and what we want to do is to build a framework which is able to decide that question and also.",
            "It would be really nice to have some sort of evidence, some sort of provenance, information about the triple.",
            "So here we have an excerpt of this website called Exa Miner where it explicitly stated that offered Hitchcock was the director of that certain movie, and for now that would make a human need to do.",
            "He would need to make he would need to create a query and then answer that or push the search engine and then he would need to scan through all the documents and find the relevant answer.",
            "So this was why we came."
        ],
        [
            "Up with this architecture of our approach, and this is a very high level architecture here.",
            "So let's first.",
            "So let's start here an.",
            "We start with the input ripple and to find any provenance information on the web we first need to have.",
            "And natural natural language representation of that certain triple.",
            "And that's where the block pattern library comes into play.",
            "This is a library of natural language representations for formal relations, which I'm going to go into details soon.",
            "And if we have this natural language representation of the triple, we can build search engine queries which we send them, in our case to Bing, and we can then use the relevant documents which are returned and store them in the index for further analyzation.",
            "If we have those documents, we can then extract or try to extract proofs from those web pages and score them with the help of supervised machine learning approach and we also wanted to have a trust layer where we can decide on the trustworthiness of a given website.",
            "And in the final step we just called perfect confirmation, which also supervised machine learning step.",
            "We can combine those two layers together and then decide if given given fact is true or not.",
            "So this is a value between zero and one here, which we can also present to the user to better understand the question so."
        ],
        [
            "First, start here with the how we find the natural language representation of the triple, and as I said, we are using both offered this, which is an acronym for Bootstrapping Link data and has or it can be characterized characterized in the following four steps.",
            "So let's assume we have this knowledge base again about the movie domain, and there are those four movies and they all have the same director.",
            "We can then use the labels of those entities and query the web where a given corpus.",
            "To find define sentences which contain both entities and we can then have a look at the patterns which occur between those two entities and collect them and score them, which is what we are doing in boy with neural neural network.",
            "So also supervised machine learning approach and we can score the patterns accordingly and use the most or the highest score patterns, then to again query and index to find sentences which contain those highly scored patterns to be able to extract new knowledge from that.",
            "So this is.",
            "This approach is not only limited to English right here?",
            "You can also use cross language input and we tried it also for German.",
            "So to do that for."
        ],
        [
            "Facto, we specifically trained board for that, so we use the top 60 most use all object properties.",
            "And this sums up to 7.75 million out of almost 10,000,000 object properties in DB pedia, which is about 78%.",
            "At I think June this year and we.",
            "Man, you are.",
            "We selected 1010.",
            "Very frequent patterns and we manually annotated them.",
            "Pairwise so we later later, Curtis resolve conflicts.",
            "So we also had guidelines where we.",
            "Where we said that pattern shouldn't be too generic that it shouldn't be able to use for multiple relations like this's here.",
            "That could be an instance of multiple relations, and the patterns shouldn't be too specific like the Italian region here.",
            "That should only be region.",
            "So this sums up too.",
            "To a list of 488 patterns which we annotated and we put them in the neural network.",
            "And we performed 10 fold cross validation on those patterns and we're achieved and we achieved an F1 score of 70, three point 2%.",
            "So the result of this first training step is a large library of natural scored natural language representations for formal relations, which we can now use to query the web."
        ],
        [
            "And this is what we've done here.",
            "So we can create a bunch of automatic queries and we.",
            "We used entity labels and we used the normalized version of the pattern and we.",
            "We ended them together.",
            "We tried to put All in all in quotes, but this.",
            "So as we did it, the results were too sparse.",
            "Um, yes so.",
            "And the relevant documents now, which returned by the search engine were stored in a Lucene index.",
            "So this was the."
        ],
        [
            "First part, and now I want to talk about the roof scoring.",
            "And."
        ],
        [
            "This is done like this we have.",
            "Since I always use the example of Alfred Hitchcock here and there in the web sites, there might not always be that particular pattern.",
            "There might also be offered J Hitchcock or Alfred, Joseph Hitchcock or whatever, so we have a pre compiled list for all the DB pedia.",
            "Your eyes of surface forms and we look for pairs of those entities in the website text which we crawl.",
            "And if those entities are within a certain a certain distance, we extract this pattern, then as a possible proof.",
            "Yes, for each of those possible proofs we apply a feature extraction algorithm.",
            "In this case here, if we find a bore pattern inside those proofs, we can use a Boolean value.",
            "We can also use the score of the neural network for each of those proofs.",
            "We use the token distance between those two entity labels.",
            "And we also do a word net expansion on the proof phrase we find and the boy pattern.",
            "So this is a car similarity based on similar words from the sun sets of those two strings.",
            "We can count the total of the total occurrence of all those patterns in the list of websites we apply.",
            "A string similarity metric on the page title.",
            "From from the website since.",
            "If page is more, we think page is more relevant.",
            "If it says something about these entities.",
            "From the input ripple we also look for at the end of sentence characters which are which aren't available in this pattern here, and we use the phrase and as well as the property label as a word vector for this.",
            "This machine learning approach.",
            "We will.",
            "We trained our approach on randomly on a set of randomly sampled 527 proofs and we used four different machine learning classifiers which you can see here that we used logistic regression, naive based support vector machines and RBF networks as they were implemented in the vector machine Learning Toolkit and we have seen that we can reach the best results with 82.2.",
            "F major with support vector machines.",
            "So this was the proof score."
        ],
        [
            "Now, to the trustworthiness.",
            "And this has been the basics."
        ],
        [
            "Thing to analyze the trustworthiness of web pages is to determine the similarity between the website and the input triple, and we can do that by comparing the topics of a given query with the search results returned by the search engine, and to do that we rely on an approach which was proposed by Nakamura Dell in 2007 that the task to rerank search results based on based on trustworthiness, and they did it by.",
            "Or they.",
            "Try to extract features from large user study with more than 1000 thousand participants, but we had to extend their approach becausw they only had a single search term and we have with the subject in the object label.",
            "We have two different search terms.",
            "So we use therefore differ."
        ],
        [
            "Trustworthiness features which are, namely the topic majority in the web which is only the number of web pages which have similar topics that are current page.",
            "And that means that.",
            "The more the page or the higher this indicator is, the more the page includes topics that can consider to be a significant to search query.",
            "The topic majority in the search results is then the number of search results which are similar to the search results which are.",
            "B2 elevated and that indicator can then be used to determine whether the search terms are significant in the search results.",
            "Topic coverage is only a rate about the topic terms which appear on the current site, and we use also the Pagerank which is in our case just a Google page rank for a given website."
        ],
        [
            "So now we can combine the trustworthiness, features and the proof scoring features in the final effect confirmation step.",
            "And as I said."
        ],
        [
            "That's supervised machine learning approach and here we also applied a feature extraction step.",
            "And the first thing we needed to do is to create out of the proof scores we needed to create a score for a given website, and this is done by this formula here.",
            "So the score of a website is 1 minus this product, and where PR is a proof of the set of all proofs for a given website and the FC function.",
            "Here is the classifier I just presented for the proof scoring.",
            "Parts.",
            "So Furthermore, you would expect that the trustworthiness of a web page and the textual evidence we can find in those website or autocal features, but.",
            "We wanted to score websites higher if they are trustworthy and they contain highly rated proof.",
            "So we combine those.",
            "We combined the trustworthiness and the proof scores together with those two formulas where you can instantiate F here with all those trustworthiness features, namely the topic majority in the web and in the search results, the topic coverage and.",
            "The pay track and then the first one you some.",
            "You sum those products up and in the second one you only use the maximum score for each or for other websites.",
            "So this makes 8 features, but we also used some more, namely the.",
            "We use the total number of proof phrases we could extract from all the websites.",
            "We use total hit count from all the queries we sent to the search engine and we applied a domain and range check for with respect to the RDF type of the subject and object."
        ],
        [
            "So how did we evaluate it?",
            "The main goal we try to answer there is, can we effectively distinguish between true and false facts, and to do so again we use the top 60 most use all object properties and at that stage just wanted to say that we are can extend that at anytime to other properties and we are not limited to DB pedia in general so.",
            "To avoid our approach, we need to create a set of positive and negative training data and so far there is no benchmark for that available.",
            "So we need to come up with that ourselves.",
            "The generation of the positive training data."
        ],
        [
            "Is here the easiest step.",
            "We randomly selected 10 triples for each property, which sums up to six, sorry.",
            "Which which sums up to 600.",
            "To 600 triples and we needed to manually evaluated them as true or false, and we did that with the web with a web search.",
            "And of course to make sure that we don't.",
            "Um?",
            "Use Wikipedia, we excluded the Wikipedia infoboxes and also web pages which build up on the Wikipedia infoboxes and in total we had then 473 positive examples.",
            "Which we can use in our machine learning approach.",
            "Now the two have the same number of negative or false data is pretty difficult since we need false data which is very similar to the true data.",
            "Otherwise you would never have.",
            "You would never find any documents which contain 2 random random concepts.",
            "So what we did there?"
        ],
        [
            "Is just assume we have this property X here with has a domain of the Class Y and range of class set and we have this instance of this positive training data.",
            "Here we created our first Test set by which is also called subject by selecting randomly another individual of class Y for for the subject of the correct triple.",
            "This is the same thing what we?"
        ],
        [
            "Done for a second test set, which is then called object.",
            "There we exchanged it with another another individual of class set.",
            "And the third test."
        ],
        [
            "Set is where we exchanged the subject and the object.",
            "The 4th Test said."
        ],
        [
            "Is random property where we didn't abide to any domain and range restrictions from the replace property and."
        ],
        [
            "Last or the almost last Test set is where we change the subject, the object and property.",
            "And to make it, I think."
        ],
        [
            "To make it more realistic to real input from actual users, we combine 20% of each test set to this 20% mix test set, and we applied again a tenfold cross validation with different machine learning classifiers."
        ],
        [
            "Here are the results of our evaluation, and this plot shows the F1 measure for each of those.",
            "For each of those classifiers, and as you can see, the naive Bayes and the RBF networks perform both very poorly.",
            "Logistic regression and support vector machines are very close and the J 48.",
            "Decision trees here outperform on almost each test set to support vector machines and.",
            "The most important, the most important question here or the most important thing we've seen that we get a 6% F one score increase with J48 decision trees."
        ],
        [
            "So to discuss the results.",
            "Precisely we get 82.6 to 87.6% of 1 measure for those first 5 sender test set and 78.8% F Measure F1 measure for the 20% mix test set with the J 48 decision trees.",
            "As expected, the easiest data set would be a random.",
            "Or is the random data set which is just.",
            "Randomly selected triples and the hardest test set is just 20%.",
            "Mixed test set.",
            "Also, what we notice here that our generation of the true facts is very challenging for defacto, since there are a lot of triples in DB pedia, which describes some things which happened in the past and we've passed.",
            "I mean time before before the web or there is.",
            "Thom Sings, which might have happened in a non English part of the world and therefore we don't have English.",
            "Facts for that as a result of that.",
            "Of that fact is that de facto works better for more popular effects, and you can get involved with.",
            "The training data and the test set, as well as the source code online."
        ],
        [
            "So I just wanted to present to you a very short demo of those two projects.",
            "So.",
            "Here is the interface.",
            "You can see the relations on the left side and you can click like for example on the director relation and you see all the natural language patterns.",
            "Here you can select different features in the table and sort the table accordingly.",
            "You can also click on the pattern here and it should you should.",
            "You should see detailed few of the pattern itself.",
            "You can click on that button here and you can see from which triples your learn that pattern from and how often do you find it?",
            "You can look for sentences in the index where you learn the pattern from and the last thing should be.",
            "You can query the index to find sentences where where this pattern also occurs.",
            "So here's the interface for defacto and you can try to use.",
            "An example here or just enter triple for yourself.",
            "There should be an auto completion for DPA.",
            "Your eyes here.",
            "And this is also the example from the paper under presentation here, and there should be results in a few seconds.",
            "And OK.",
            "It takes awhile so.",
            "There's this list of facts here.",
            "We have 8787% proof for that fact, and you can see the trustworthiness features on the right.",
            "You can see that we extracted here proof raise with a boy pattern, which is director in this case and you can also download the provenance information as RDF so.",
            "To conclude with my talk."
        ],
        [
            "We presented here to facto, which is a framework which is able to check the validity of facts using the web as a corpus, and you can also export the provenance information.",
            "As RDF envy, use of provenance ontology from the WCS free.",
            "We achieved F1 score or an average of 1 score of 84.2% on our training data with the J 48 decision trees and you have GUI prototypes available at the factor that hw.org and boarded hsw.org and in the future we want to extend defacto to work with different languages which should be easy since was also.",
            "Multilingual now.",
            "We want to extend it to support data type properties, which would require more effort and we also want to present negative evidence to the user as well as to get the lay user involved to create a natural language interface for.",
            "Yeah, so that you don't need to select your eyes for for triples, so."
        ],
        [
            "I think that's it.",
            "I'm thank you very much and I would be happy to answer some questions."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "My name is Daniel and I'm going to present to you the joint work I've done together with Jens Lehmann more mid, more, say in axle curled mongomo.",
                    "label": 0
                },
                {
                    "sent": "All of us are from the University of Lipstick and CSW Research Group, so the talk I'm going to give today is about the factor which is an acronym for the Deep Fact Validation.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So what was our motivation?",
                    "label": 0
                },
                {
                    "sent": "Let's consider.",
                    "label": 0
                },
                {
                    "sent": "We have this little knowledge base here about the movie domain, and let's assume this was extracted from an automatic approach.",
                    "label": 0
                },
                {
                    "sent": "So from free text.",
                    "label": 0
                },
                {
                    "sent": "So if we have if we're going to look at the single triple here, we don't have any information about it.",
                    "label": 0
                },
                {
                    "sent": "In terms of metadata, so we don't really know if that's true or not and what we want to do is to build a framework which is able to decide that question and also.",
                    "label": 0
                },
                {
                    "sent": "It would be really nice to have some sort of evidence, some sort of provenance, information about the triple.",
                    "label": 0
                },
                {
                    "sent": "So here we have an excerpt of this website called Exa Miner where it explicitly stated that offered Hitchcock was the director of that certain movie, and for now that would make a human need to do.",
                    "label": 0
                },
                {
                    "sent": "He would need to make he would need to create a query and then answer that or push the search engine and then he would need to scan through all the documents and find the relevant answer.",
                    "label": 0
                },
                {
                    "sent": "So this was why we came.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Up with this architecture of our approach, and this is a very high level architecture here.",
                    "label": 0
                },
                {
                    "sent": "So let's first.",
                    "label": 0
                },
                {
                    "sent": "So let's start here an.",
                    "label": 0
                },
                {
                    "sent": "We start with the input ripple and to find any provenance information on the web we first need to have.",
                    "label": 0
                },
                {
                    "sent": "And natural natural language representation of that certain triple.",
                    "label": 1
                },
                {
                    "sent": "And that's where the block pattern library comes into play.",
                    "label": 0
                },
                {
                    "sent": "This is a library of natural language representations for formal relations, which I'm going to go into details soon.",
                    "label": 0
                },
                {
                    "sent": "And if we have this natural language representation of the triple, we can build search engine queries which we send them, in our case to Bing, and we can then use the relevant documents which are returned and store them in the index for further analyzation.",
                    "label": 0
                },
                {
                    "sent": "If we have those documents, we can then extract or try to extract proofs from those web pages and score them with the help of supervised machine learning approach and we also wanted to have a trust layer where we can decide on the trustworthiness of a given website.",
                    "label": 0
                },
                {
                    "sent": "And in the final step we just called perfect confirmation, which also supervised machine learning step.",
                    "label": 0
                },
                {
                    "sent": "We can combine those two layers together and then decide if given given fact is true or not.",
                    "label": 0
                },
                {
                    "sent": "So this is a value between zero and one here, which we can also present to the user to better understand the question so.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "First, start here with the how we find the natural language representation of the triple, and as I said, we are using both offered this, which is an acronym for Bootstrapping Link data and has or it can be characterized characterized in the following four steps.",
                    "label": 0
                },
                {
                    "sent": "So let's assume we have this knowledge base again about the movie domain, and there are those four movies and they all have the same director.",
                    "label": 0
                },
                {
                    "sent": "We can then use the labels of those entities and query the web where a given corpus.",
                    "label": 0
                },
                {
                    "sent": "To find define sentences which contain both entities and we can then have a look at the patterns which occur between those two entities and collect them and score them, which is what we are doing in boy with neural neural network.",
                    "label": 0
                },
                {
                    "sent": "So also supervised machine learning approach and we can score the patterns accordingly and use the most or the highest score patterns, then to again query and index to find sentences which contain those highly scored patterns to be able to extract new knowledge from that.",
                    "label": 0
                },
                {
                    "sent": "So this is.",
                    "label": 0
                },
                {
                    "sent": "This approach is not only limited to English right here?",
                    "label": 0
                },
                {
                    "sent": "You can also use cross language input and we tried it also for German.",
                    "label": 0
                },
                {
                    "sent": "So to do that for.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Facto, we specifically trained board for that, so we use the top 60 most use all object properties.",
                    "label": 0
                },
                {
                    "sent": "And this sums up to 7.75 million out of almost 10,000,000 object properties in DB pedia, which is about 78%.",
                    "label": 0
                },
                {
                    "sent": "At I think June this year and we.",
                    "label": 0
                },
                {
                    "sent": "Man, you are.",
                    "label": 0
                },
                {
                    "sent": "We selected 1010.",
                    "label": 0
                },
                {
                    "sent": "Very frequent patterns and we manually annotated them.",
                    "label": 0
                },
                {
                    "sent": "Pairwise so we later later, Curtis resolve conflicts.",
                    "label": 0
                },
                {
                    "sent": "So we also had guidelines where we.",
                    "label": 0
                },
                {
                    "sent": "Where we said that pattern shouldn't be too generic that it shouldn't be able to use for multiple relations like this's here.",
                    "label": 0
                },
                {
                    "sent": "That could be an instance of multiple relations, and the patterns shouldn't be too specific like the Italian region here.",
                    "label": 1
                },
                {
                    "sent": "That should only be region.",
                    "label": 0
                },
                {
                    "sent": "So this sums up too.",
                    "label": 0
                },
                {
                    "sent": "To a list of 488 patterns which we annotated and we put them in the neural network.",
                    "label": 0
                },
                {
                    "sent": "And we performed 10 fold cross validation on those patterns and we're achieved and we achieved an F1 score of 70, three point 2%.",
                    "label": 0
                },
                {
                    "sent": "So the result of this first training step is a large library of natural scored natural language representations for formal relations, which we can now use to query the web.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And this is what we've done here.",
                    "label": 0
                },
                {
                    "sent": "So we can create a bunch of automatic queries and we.",
                    "label": 0
                },
                {
                    "sent": "We used entity labels and we used the normalized version of the pattern and we.",
                    "label": 0
                },
                {
                    "sent": "We ended them together.",
                    "label": 0
                },
                {
                    "sent": "We tried to put All in all in quotes, but this.",
                    "label": 0
                },
                {
                    "sent": "So as we did it, the results were too sparse.",
                    "label": 0
                },
                {
                    "sent": "Um, yes so.",
                    "label": 0
                },
                {
                    "sent": "And the relevant documents now, which returned by the search engine were stored in a Lucene index.",
                    "label": 0
                },
                {
                    "sent": "So this was the.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "First part, and now I want to talk about the roof scoring.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This is done like this we have.",
                    "label": 0
                },
                {
                    "sent": "Since I always use the example of Alfred Hitchcock here and there in the web sites, there might not always be that particular pattern.",
                    "label": 0
                },
                {
                    "sent": "There might also be offered J Hitchcock or Alfred, Joseph Hitchcock or whatever, so we have a pre compiled list for all the DB pedia.",
                    "label": 0
                },
                {
                    "sent": "Your eyes of surface forms and we look for pairs of those entities in the website text which we crawl.",
                    "label": 0
                },
                {
                    "sent": "And if those entities are within a certain a certain distance, we extract this pattern, then as a possible proof.",
                    "label": 0
                },
                {
                    "sent": "Yes, for each of those possible proofs we apply a feature extraction algorithm.",
                    "label": 0
                },
                {
                    "sent": "In this case here, if we find a bore pattern inside those proofs, we can use a Boolean value.",
                    "label": 0
                },
                {
                    "sent": "We can also use the score of the neural network for each of those proofs.",
                    "label": 0
                },
                {
                    "sent": "We use the token distance between those two entity labels.",
                    "label": 1
                },
                {
                    "sent": "And we also do a word net expansion on the proof phrase we find and the boy pattern.",
                    "label": 0
                },
                {
                    "sent": "So this is a car similarity based on similar words from the sun sets of those two strings.",
                    "label": 0
                },
                {
                    "sent": "We can count the total of the total occurrence of all those patterns in the list of websites we apply.",
                    "label": 1
                },
                {
                    "sent": "A string similarity metric on the page title.",
                    "label": 0
                },
                {
                    "sent": "From from the website since.",
                    "label": 0
                },
                {
                    "sent": "If page is more, we think page is more relevant.",
                    "label": 0
                },
                {
                    "sent": "If it says something about these entities.",
                    "label": 1
                },
                {
                    "sent": "From the input ripple we also look for at the end of sentence characters which are which aren't available in this pattern here, and we use the phrase and as well as the property label as a word vector for this.",
                    "label": 0
                },
                {
                    "sent": "This machine learning approach.",
                    "label": 0
                },
                {
                    "sent": "We will.",
                    "label": 0
                },
                {
                    "sent": "We trained our approach on randomly on a set of randomly sampled 527 proofs and we used four different machine learning classifiers which you can see here that we used logistic regression, naive based support vector machines and RBF networks as they were implemented in the vector machine Learning Toolkit and we have seen that we can reach the best results with 82.2.",
                    "label": 0
                },
                {
                    "sent": "F major with support vector machines.",
                    "label": 0
                },
                {
                    "sent": "So this was the proof score.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now, to the trustworthiness.",
                    "label": 0
                },
                {
                    "sent": "And this has been the basics.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Thing to analyze the trustworthiness of web pages is to determine the similarity between the website and the input triple, and we can do that by comparing the topics of a given query with the search results returned by the search engine, and to do that we rely on an approach which was proposed by Nakamura Dell in 2007 that the task to rerank search results based on based on trustworthiness, and they did it by.",
                    "label": 1
                },
                {
                    "sent": "Or they.",
                    "label": 0
                },
                {
                    "sent": "Try to extract features from large user study with more than 1000 thousand participants, but we had to extend their approach becausw they only had a single search term and we have with the subject in the object label.",
                    "label": 1
                },
                {
                    "sent": "We have two different search terms.",
                    "label": 0
                },
                {
                    "sent": "So we use therefore differ.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Trustworthiness features which are, namely the topic majority in the web which is only the number of web pages which have similar topics that are current page.",
                    "label": 1
                },
                {
                    "sent": "And that means that.",
                    "label": 0
                },
                {
                    "sent": "The more the page or the higher this indicator is, the more the page includes topics that can consider to be a significant to search query.",
                    "label": 0
                },
                {
                    "sent": "The topic majority in the search results is then the number of search results which are similar to the search results which are.",
                    "label": 1
                },
                {
                    "sent": "B2 elevated and that indicator can then be used to determine whether the search terms are significant in the search results.",
                    "label": 0
                },
                {
                    "sent": "Topic coverage is only a rate about the topic terms which appear on the current site, and we use also the Pagerank which is in our case just a Google page rank for a given website.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So now we can combine the trustworthiness, features and the proof scoring features in the final effect confirmation step.",
                    "label": 0
                },
                {
                    "sent": "And as I said.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "That's supervised machine learning approach and here we also applied a feature extraction step.",
                    "label": 0
                },
                {
                    "sent": "And the first thing we needed to do is to create out of the proof scores we needed to create a score for a given website, and this is done by this formula here.",
                    "label": 0
                },
                {
                    "sent": "So the score of a website is 1 minus this product, and where PR is a proof of the set of all proofs for a given website and the FC function.",
                    "label": 0
                },
                {
                    "sent": "Here is the classifier I just presented for the proof scoring.",
                    "label": 0
                },
                {
                    "sent": "Parts.",
                    "label": 0
                },
                {
                    "sent": "So Furthermore, you would expect that the trustworthiness of a web page and the textual evidence we can find in those website or autocal features, but.",
                    "label": 0
                },
                {
                    "sent": "We wanted to score websites higher if they are trustworthy and they contain highly rated proof.",
                    "label": 1
                },
                {
                    "sent": "So we combine those.",
                    "label": 0
                },
                {
                    "sent": "We combined the trustworthiness and the proof scores together with those two formulas where you can instantiate F here with all those trustworthiness features, namely the topic majority in the web and in the search results, the topic coverage and.",
                    "label": 0
                },
                {
                    "sent": "The pay track and then the first one you some.",
                    "label": 0
                },
                {
                    "sent": "You sum those products up and in the second one you only use the maximum score for each or for other websites.",
                    "label": 1
                },
                {
                    "sent": "So this makes 8 features, but we also used some more, namely the.",
                    "label": 1
                },
                {
                    "sent": "We use the total number of proof phrases we could extract from all the websites.",
                    "label": 1
                },
                {
                    "sent": "We use total hit count from all the queries we sent to the search engine and we applied a domain and range check for with respect to the RDF type of the subject and object.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So how did we evaluate it?",
                    "label": 0
                },
                {
                    "sent": "The main goal we try to answer there is, can we effectively distinguish between true and false facts, and to do so again we use the top 60 most use all object properties and at that stage just wanted to say that we are can extend that at anytime to other properties and we are not limited to DB pedia in general so.",
                    "label": 1
                },
                {
                    "sent": "To avoid our approach, we need to create a set of positive and negative training data and so far there is no benchmark for that available.",
                    "label": 0
                },
                {
                    "sent": "So we need to come up with that ourselves.",
                    "label": 0
                },
                {
                    "sent": "The generation of the positive training data.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Is here the easiest step.",
                    "label": 0
                },
                {
                    "sent": "We randomly selected 10 triples for each property, which sums up to six, sorry.",
                    "label": 1
                },
                {
                    "sent": "Which which sums up to 600.",
                    "label": 0
                },
                {
                    "sent": "To 600 triples and we needed to manually evaluated them as true or false, and we did that with the web with a web search.",
                    "label": 0
                },
                {
                    "sent": "And of course to make sure that we don't.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Use Wikipedia, we excluded the Wikipedia infoboxes and also web pages which build up on the Wikipedia infoboxes and in total we had then 473 positive examples.",
                    "label": 0
                },
                {
                    "sent": "Which we can use in our machine learning approach.",
                    "label": 0
                },
                {
                    "sent": "Now the two have the same number of negative or false data is pretty difficult since we need false data which is very similar to the true data.",
                    "label": 0
                },
                {
                    "sent": "Otherwise you would never have.",
                    "label": 0
                },
                {
                    "sent": "You would never find any documents which contain 2 random random concepts.",
                    "label": 0
                },
                {
                    "sent": "So what we did there?",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Is just assume we have this property X here with has a domain of the Class Y and range of class set and we have this instance of this positive training data.",
                    "label": 1
                },
                {
                    "sent": "Here we created our first Test set by which is also called subject by selecting randomly another individual of class Y for for the subject of the correct triple.",
                    "label": 1
                },
                {
                    "sent": "This is the same thing what we?",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Done for a second test set, which is then called object.",
                    "label": 0
                },
                {
                    "sent": "There we exchanged it with another another individual of class set.",
                    "label": 1
                },
                {
                    "sent": "And the third test.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Set is where we exchanged the subject and the object.",
                    "label": 0
                },
                {
                    "sent": "The 4th Test said.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is random property where we didn't abide to any domain and range restrictions from the replace property and.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Last or the almost last Test set is where we change the subject, the object and property.",
                    "label": 0
                },
                {
                    "sent": "And to make it, I think.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To make it more realistic to real input from actual users, we combine 20% of each test set to this 20% mix test set, and we applied again a tenfold cross validation with different machine learning classifiers.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here are the results of our evaluation, and this plot shows the F1 measure for each of those.",
                    "label": 0
                },
                {
                    "sent": "For each of those classifiers, and as you can see, the naive Bayes and the RBF networks perform both very poorly.",
                    "label": 0
                },
                {
                    "sent": "Logistic regression and support vector machines are very close and the J 48.",
                    "label": 0
                },
                {
                    "sent": "Decision trees here outperform on almost each test set to support vector machines and.",
                    "label": 0
                },
                {
                    "sent": "The most important, the most important question here or the most important thing we've seen that we get a 6% F one score increase with J48 decision trees.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So to discuss the results.",
                    "label": 0
                },
                {
                    "sent": "Precisely we get 82.6 to 87.6% of 1 measure for those first 5 sender test set and 78.8% F Measure F1 measure for the 20% mix test set with the J 48 decision trees.",
                    "label": 1
                },
                {
                    "sent": "As expected, the easiest data set would be a random.",
                    "label": 0
                },
                {
                    "sent": "Or is the random data set which is just.",
                    "label": 0
                },
                {
                    "sent": "Randomly selected triples and the hardest test set is just 20%.",
                    "label": 0
                },
                {
                    "sent": "Mixed test set.",
                    "label": 0
                },
                {
                    "sent": "Also, what we notice here that our generation of the true facts is very challenging for defacto, since there are a lot of triples in DB pedia, which describes some things which happened in the past and we've passed.",
                    "label": 0
                },
                {
                    "sent": "I mean time before before the web or there is.",
                    "label": 0
                },
                {
                    "sent": "Thom Sings, which might have happened in a non English part of the world and therefore we don't have English.",
                    "label": 0
                },
                {
                    "sent": "Facts for that as a result of that.",
                    "label": 1
                },
                {
                    "sent": "Of that fact is that de facto works better for more popular effects, and you can get involved with.",
                    "label": 0
                },
                {
                    "sent": "The training data and the test set, as well as the source code online.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So I just wanted to present to you a very short demo of those two projects.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Here is the interface.",
                    "label": 0
                },
                {
                    "sent": "You can see the relations on the left side and you can click like for example on the director relation and you see all the natural language patterns.",
                    "label": 0
                },
                {
                    "sent": "Here you can select different features in the table and sort the table accordingly.",
                    "label": 0
                },
                {
                    "sent": "You can also click on the pattern here and it should you should.",
                    "label": 0
                },
                {
                    "sent": "You should see detailed few of the pattern itself.",
                    "label": 0
                },
                {
                    "sent": "You can click on that button here and you can see from which triples your learn that pattern from and how often do you find it?",
                    "label": 0
                },
                {
                    "sent": "You can look for sentences in the index where you learn the pattern from and the last thing should be.",
                    "label": 0
                },
                {
                    "sent": "You can query the index to find sentences where where this pattern also occurs.",
                    "label": 0
                },
                {
                    "sent": "So here's the interface for defacto and you can try to use.",
                    "label": 0
                },
                {
                    "sent": "An example here or just enter triple for yourself.",
                    "label": 0
                },
                {
                    "sent": "There should be an auto completion for DPA.",
                    "label": 0
                },
                {
                    "sent": "Your eyes here.",
                    "label": 0
                },
                {
                    "sent": "And this is also the example from the paper under presentation here, and there should be results in a few seconds.",
                    "label": 0
                },
                {
                    "sent": "And OK.",
                    "label": 0
                },
                {
                    "sent": "It takes awhile so.",
                    "label": 0
                },
                {
                    "sent": "There's this list of facts here.",
                    "label": 0
                },
                {
                    "sent": "We have 8787% proof for that fact, and you can see the trustworthiness features on the right.",
                    "label": 0
                },
                {
                    "sent": "You can see that we extracted here proof raise with a boy pattern, which is director in this case and you can also download the provenance information as RDF so.",
                    "label": 0
                },
                {
                    "sent": "To conclude with my talk.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We presented here to facto, which is a framework which is able to check the validity of facts using the web as a corpus, and you can also export the provenance information.",
                    "label": 1
                },
                {
                    "sent": "As RDF envy, use of provenance ontology from the WCS free.",
                    "label": 1
                },
                {
                    "sent": "We achieved F1 score or an average of 1 score of 84.2% on our training data with the J 48 decision trees and you have GUI prototypes available at the factor that hw.org and boarded hsw.org and in the future we want to extend defacto to work with different languages which should be easy since was also.",
                    "label": 0
                },
                {
                    "sent": "Multilingual now.",
                    "label": 0
                },
                {
                    "sent": "We want to extend it to support data type properties, which would require more effort and we also want to present negative evidence to the user as well as to get the lay user involved to create a natural language interface for.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so that you don't need to select your eyes for for triples, so.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I think that's it.",
                    "label": 0
                },
                {
                    "sent": "I'm thank you very much and I would be happy to answer some questions.",
                    "label": 0
                }
            ]
        }
    }
}