{
    "id": "nwnrzeaqpy5tjzuzysojfn7ecanyaoqy",
    "title": "Diffusions and Geodesic Flows on Manifolds: The Differential Geometry of Markov Chain Monte Carlo",
    "info": {
        "author": [
            "Mark Girolami, School of Computing Science, University of Glasgow"
        ],
        "published": "Jan. 15, 2013",
        "recorded": "April 2012",
        "category": [
            "Top->Computer Science->Machine Learning->Monte Carlo Methods",
            "Top->Computer Science->Machine Learning->Markov Processes"
        ]
    },
    "url": "http://videolectures.net/mlss2012_girolami_mcmc/",
    "segmentation": [
        [
            "My heart really started to sing when I saw that the weather wasn't too great when we broke for lunch because I had visions of talking to about a handful of really eager Beavers and the rest of you would be out in the beach, but Fortunately wasn't that warm for you to stay out there.",
            "So I'm glad you're back in the warmth and here.",
            "So unlike Benard and Neil, I probably need a little bit of introduction as I'm this is my first ever machine learning Summer School an as you said, I'm from the Department of Statistical Science at UCL.",
            "UCL Department statistical Science was set up by Karl Pearson, who was mentioned many times and news talk and.",
            "Was also in the Vanguard of the Bayesian movement in the statistics community, with people like Dennis Lindley and various others.",
            "So today I'm going to try and give you a tutorial and one of the things I really hope that I managed to do is leave you with intuition rather than lots and lots of detailed theory, right?",
            "So intuition that will motivate you to study the detailed theory and that's one of the things I found with Bernards talk this morning and news that really provided very beautiful intuitions.",
            "And although I thought I knew everything.",
            "That I cared to ever want to know about PCA.",
            "I really felt that you know there were a number of of intuitions that I had missed, so hopefully you'll get some intuitions about MCMC, and in particular the.",
            "The Grand New World of geometric Markov chain Monte Carlo and I hope that some of you will get really excited by it and start to contribute to the area.",
            "But before I start and all of that, I think we need to lay down some some basic ground."
        ],
        [
            "Mark so.",
            "The whole reason for.",
            "Markov chain Monte Carlo is really because of this chart here.",
            "Can everyone see well the chap who this picture is meant to represent?",
            "So of course this is meant to be the Reverend Thomas Base.",
            "Who is credited for the whole new?"
        ],
        [
            "Ocean of probability inversion.",
            "And this leads to the whole area of what is called in statistics and the machine learning Bayesian inference.",
            "And you hear an awful lot more about that next week.",
            "So in many ways I'm just a kind of warm up act for the likes of Zubin and Co. Who will be talking in great depth about Bayesian methods and Bayesian nonparametrics.",
            "So I'm going to present the kind of nuts and bolts if you will be able to do sensible Bayesian inference.",
            "And so if we have some observations, if we make some observations from some experiment or from some logging device, we have data associated with that X.",
            "And then we have a model trying to describe what we've observed and that model will have.",
            "Some free parameters.",
            "There may also be components of the model or variables associated with the model, which we don't observe, so they are heading to as their latent, or they're on observed.",
            "Now I'm just going to bundle both the parameters of our model and the latent variables all into some set of random variables theater.",
            "No.",
            "As Bernard mentioned today, and Neil alluded to as well in Bayesian inference, the key.",
            "Issue that we have to address is how we define a prior distribution.",
            "Over all of the unknowns in our model, now in fact we have to go a step back becausw in our model.",
            "Our model may in fact just be.",
            "One particular instantiation from a whole model class and in which case we would actually have a prior distribution over the instantiations of the models within the model class.",
            "But here just to keep things simple, I'm assuming that we are conditioning on one model, so I'm not going to consider trans dimensional.",
            "Markov chain Monte Carlo, where we actually look across a whole model class or finite model class.",
            "I'm considering just one particular model with a set of latent variables and the set of parameters OK, But please bear in mind that this is only part of the story.",
            "And if there's time.",
            "Probably in the third lecture I'll then talk about the issue of doing inference over model classes.",
            "But for now, we're looking at a prior distribution over all of the unknowns associated with our model, and I'll call.",
            "I'll see that there is some distribution or some density associated with the measure Pi nought over Theta.",
            "Now, of course, for those of you who haven't been hanging about all these Bayesians and machine the machine learning community.",
            "The prior distribution.",
            "I'm is something as I said that has to be selected based on your prior understanding or prior observations or prior beliefs and that may be something as simple As for example in some of the probabilistic principal component analysis models that Neil spoke off this morning.",
            "He alluded to using a Bayesian approach rather than just the likelihood based approach, so you would then be putting priors over the column vectors of W and you would be putting priors over the values of the variance Sigma squared.",
            "And of course one of the simple things you definitely know about Sigma squared is that it's it's got its values have to be constrained to the positive part of the real line.",
            "So there straight away there is a constraint that can be codified and some sort of prior distribution which restricts the support of the distribution of that particular random variable and on it goes.",
            "No, the data under the model and the current values of our observed variables and parameters we defined by the likelihood the probability of the data X conditioned on Theta.",
            "Now again, for completeness, we would of course also condition on M the particular instance of the model class that we are considering.",
            "But here I'm just making that implicit.",
            "Now of course, the posterior distribution, which is the.",
            "The whole basis of Bayesian inference follows just by the application of the of this simple rule here, so we can invert the likelihood so the probabilities probability can be inverted by multiplying by the prior.",
            "And then re normalizing so that this is indeed density functional or or an actual distribution.",
            "So it would be normalized in this respect here.",
            "So what we're doing with this very simple equation allows us to do and, which has been the basis of a huge amount of infighting within the statistics community.",
            "For the best part of a couple of centuries is that we can invert.",
            "As I said, the likelihood of our observations given causes to the other way round.",
            "No.",
            "Until the advent of the methods that I'm going to talk about MCMC, it didn't really become apparent to a lot of statisticians that in actual fact Bayesian methods based on models for inference actually work.",
            "Ann one statisticians started to realize that it worked.",
            "Then all the sort of philosophical issues associated with Bayesian inference started to die away.",
            "But I have to say that this is an extremely powerful representation, despite it just simply being a piece of algebra.",
            "Is.",
            "Yes, and I guess Zubin will wax lyrical about.",
            "The power of the posterior distribution.",
            "Now, of course, once we've.",
            "Obtain this posterior.",
            "Distribution, then all subsequent inference regarding the model which underlies our prior and our likelihood, requires specific integration with respect to this posterior measure.",
            "So, say, for example, we were interested in the expected value of some function of the parameters or the variables of interest.",
            "We would take the expectation with respect to the posterior, so you'll see this notation quite a lot the expectation.",
            "With respect to the measure associated with this conditional theater, given X of this function here.",
            "So all Bayesian inference requires us to, rather than optimizing the likelihood setting, we have to integrate.",
            "We have to perform these multi dimensional integrals.",
            "This is a stray closing bracket.",
            "OK, and.",
            "This is all great, but for models of and inference problems of real interest, real interest to the natural to the physical to the engineering Sciences to economics finance.",
            "What have you?",
            "There are very few cases.",
            "Where the prior predictive likelihood is this is called or the evidence.",
            "So the marginal likelihood is analytic.",
            "So in other words, there are very very few instances where the posterior distribution, which is the capstone of Bayesian inference, can actually be obtained in any analytic forum.",
            "And because of that progress in the use of the widespread use of Bayesian inference was largely halted because of this, and was restricted to the choice of a prior distribution and a likelihood which comprised of what was called a conjugate pair.",
            "Where the distribution of the prior combined with the distribution of the likelihood induced the posterior which had the same functional properties as the prior distribution.",
            "OK, so it everything was analytic.",
            "Brother a cumulant based expansions, which were of course approximations that had been considered as well, but to do anything in some sort of exact way, was really limited to conjugate priors.",
            "I'm likelihood functions and so that really as I said, restricted.",
            "Bayesian."
        ],
        [
            "France, for quite some time.",
            "But then some statisticians and all the smart statisticians tend to read papers and physics or hang out with physicists.",
            "And the land of the Monte Carlo principle.",
            "Now what's Monte Carlo running for?",
            "Formula One Formula One.",
            "Sorry.",
            "Casinos?",
            "Yeah well, it's similar tax.",
            "Even lots of good cyclists live in one."
        ],
        [
            "Decarlo but of course the big thing is that it's it's famous for the casino where games of Chance or played and, and that's exactly what the Monte Carlo principle is based on, is based on random.",
            "The outcome of a random events and this outcome of random events or these stochastic process is."
        ],
        [
            "Enable us to be able to start to think about how can we numeric.",
            "How can we obtain estimates of these integrals?",
            "Right, because these integrals are nothing but expectations under a particular measure.",
            "I."
        ],
        [
            "So based on some sort of stochastic process, so the Monte Carlo principle.",
            "Allows us to obtain an estimate.",
            "It's not an approximation, right?",
            "It's a statistical estimate of all of these intractable integrals that we're faced with in Bayesian inference.",
            "So typically, if we have some function of a random variable and we want to take an expectation with respect to some density and associated measure an, then if this cannot be obtained analytically.",
            "We can use stochastic simulation.",
            "To obtain an estimate as follows, we obtain.",
            "A set of independent and identically distributed samples, so these samples Theta superscript North are distributed according to the Let's just call it this particular density of interest and they are going to be independent of each other, so we're going to be independent draws from this distribution.",
            "And once we have a number of these samples, we can then just plug them in to this numerical estimate here.",
            "OK, so we plug the values of a random variables into our function and then we just take the plug and estimate.",
            "We just take the empirical mean.",
            "And it turns out that.",
            "Aisin tends to Infinity.",
            "Then this Monte Carlo estimate tends to the desired expectation and.",
            "The nice thing about this is that this is a good poker estimator in that it's an unbiased estimator of the integral of interest, and it's a consistent estimator as well.",
            "So as the number of sample draws IID sample draws increases.",
            "Then our estimate will tend to the actual integral of interest, and Furthermore the error.",
            "OK, so the error associated with our Monte Carlo estimate will converge as follows.",
            "So if I take my estimate, my Monte Carlo estimate based on N IID samples.",
            "I just take the absolute error scaling it by routine, then this converter distribution of this error right goes towards the standardized normal distribution, which has a mean of zero, indicating of course this is unbiased and the variance is just going to be the variance of the.",
            "The function of interest.",
            "Well, this is great, so we can now perform Bayesian inference if we have a mechanism to draw samples from our target distribution, which of course is going to be the posterior distribution.",
            "So how do we do that?"
        ],
        [
            "Well.",
            "The most general scheme, and there are a lot of less general schemes which I'm not going to talk about, but the.",
            "The most powerful certainly is to set up a Markov process.",
            "Who's stationary distribution?",
            "Is the distribution that you're interested in.",
            "So if you can devise a Markov process.",
            "You then simulate from that until it converges to its invariant distribution.",
            "And then you keep running that process and all of the draws from that process will be draws from the invariant distribution of the process, which would be the distribution that you're interested in.",
            "So in this case, our posterior.",
            "So that also is pretty easy.",
            "So for those of you who skipped the Markov chains lecture and your undergraduate years, this is a very quick.",
            "Review of what you need to know about Markov chains to follow the rest of the work.",
            "So Andrew Mark of course was a Russian mathematician.",
            "Who devised the majority of the theory studying the conditions under which Markov process would actually have an invariant distribution?"
        ],
        [
            "OK, so the very first.",
            "Thing about a Markov process so that it's a stochastic process driven by a series of transitions.",
            "Now this process can be defined in a state space which is discrete or continuous, and the key thing is is defined.",
            "It's governed by a specific property such that the probability of the value at a particular time increment.",
            "I given the whole previous history of the process.",
            "Is just governed by the current value of the process.",
            "OK, so the previous history after the current one is completely lost in memory, so we just have this one step memory here.",
            "And this is the Markov property or the 1st order Markov property.",
            "The probability of the value, the random variable theater time increment I is conditional upon.",
            "The value of the random variable time increment I -- 1 and everything else is forgotten about.",
            "So that's the Markov property.",
            "Now we assume that these transitions or so I should say that this is a probability distribution.",
            "OK, I'm just calling it T to denote some sort of transition.",
            "Our probability of transition.",
            "Now the first thing is is that.",
            "To make sure that the analysis is fairly straightforward.",
            "The first thing is we assume is that the transition process is invariant to the time increment sorta time itself.",
            "So in other words, we have a process which is whose transitions are homogeneous, right?",
            "So it's invariant.",
            "Overall tier overall I in this case here.",
            "So introspective of the value of I where I is, 2 or 2002.",
            "This transition probability is always going to be the same.",
            "No, because these are transition probabilities.",
            "Then in discrete case if we sum over all the possible values that the random variable can take, and of course this is going to come to one and likewise in the continuous case the integral is going to equal 1, and here's a very simple example here discrete example.",
            "So the probability of making a transition if the value of the random variable is a right at the next step.",
            "The value is going to be a 0.",
            "So there's never going to be a self transition, but there's going to be probability one about it's going to make a transition to state a state B. OK, likewise down here if you're in.",
            "If the values is C, then there's a .6 probability of making a transition to a probability .4 of making a transition to be.",
            "And of course this sums to one, so there's zero probability that it's going to make a transition to see.",
            "Very standard, so this is a stochastic matrix whose rows each sum to one.",
            "To satisfy this condition here.",
            "Well, let's just pluck a particular set of probabilities from the air.",
            "And let's say that pie at time one theater one is just equal to whatever this is here .5 point 2.3.",
            "So the probability.",
            "Of observing a random variable being in state A is going to be about half, and then the rest of the probability is split roughly 5050.",
            "Between being in State B in state C, What happens?",
            "One transition after?",
            "Well, one transition after we then can compute what the probability of each of these are being unconditional in each of the states will be by simply multiplying.",
            "Probabilities that we are in at time one right by.",
            "The transition the overall set of transition probabilities.",
            "So just by doing this vector matrix multiplication.",
            "We end up changing.",
            "The unconditional probabilities of state values from this to this here.",
            "And it's interesting.",
            "You see that the probability of being in state one.",
            ".5 node by the application of this transition Carol here it has no drop.",
            "The unconditional probability to .18 and you can see that that's fairly obvious.",
            "Becausw there's zero probabilities here of making any transitions from state 8 or state B2.",
            "State itself, so it's obviously going to drop from .5.",
            "I put about one click later at equals three.",
            "Well again, we just apply the transition operator 2\u03c0 one to get Pi 2 and \u03c0 three is obtained by again applying a transition operator to Pi 2, and on it goes.",
            "And what we see if we just generalize this is that at any point I then if we just raise or, we just multiply the transition operator.",
            "By itself I -- 1 times and multiply by the initial state probabilities, we'll obtain the next increment of this.",
            "This process, so there's something important here about raising the transition care."
        ],
        [
            "To some power.",
            "So if I just take this transition Care now I just start raising it to various powers.",
            "So here it is.",
            "Power 2, so this is the operator.",
            "That makes a move to T3.",
            "Here it is at T5.",
            "T8 T16.",
            "Now what do you see happening?",
            "What do you see happening?",
            "All the all the.",
            "It's it's all you're far too clever.",
            "Yeah, exactly what's happening is that the rank of this matrix, first of all is collapsing, and what we find is that all of the rows are exactly identical.",
            "And what we find is that.",
            "If we were to continue this process, in fact 64 is more than enough, but certainly if we were to run it indefinitely, then what we would end up with is that irrespective of the initial conditions, the initial distribution over states that if we apply this transition kernel because these are all of this, all the same value.",
            "And because the values in here but also to one, then this in essence.",
            "Ensures that this distribution is always going to be constant, is always going to be invariant.",
            "And what's happened now is that we've reached the invariant disk."
        ],
        [
            "Markov process defined by this transition kernel.",
            "This transition operator here."
        ],
        [
            "OK, well I guess that's all fairly straightforward stuff and some things that a lot of you have probably forgotten about from undergraduate studies or just suffice to say that the Markov chain it converges to an invariant distribution of the chain, right?",
            "The invariant distribution is defined by the transition operator.",
            "It is completely independent of the initial conditions of the initial state of the process now.",
            "The transition operator T has to be what's called irreducible.",
            "So in other words, the graph that defines the various transitions has to be fully connected, right?",
            "And if it's fully connected then that graph can't be split into smaller subgraphs.",
            "Because if the overall graph isn't fully connected and it can be partitioned into more than two or certainly more than one, then what it means is that there will be 0 probabilities.",
            "Of actually moving from one state to the other, and what we really want is is the process to be fully connected so that there's non zero probability of moving from one state to another.",
            "OK, so the for the invariant distribution to exist, then the transition operator has to be irreducible.",
            "Another property is that the chain has to be a periodic, so if you think about our transition operator, if we had ones on the diagonal.",
            "So as soon as we reach the particular value, so a, then the probability of making a transition to a is 1.",
            "The probability of making a transition to E is 1 and always will be.",
            "We will never move out of this this cycle as it were, so the chain has to be a periodic right?",
            "So there has to be absolutely no cycles at all.",
            "Which have probability.",
            "One of the process remaining and.",
            "No.",
            "The mean?",
            "Subject of study in Markov chain theory is defining the conditions for which an invariant distribution exists, and then verifying what those are.",
            "And I've given some of them here.",
            "No one sufficient condition.",
            "That is required, is it the chain?",
            "Has to be what's called reversible.",
            "For the physicists amongst you, you'll understand this as satisfying what's called detailed balance.",
            "So in other words.",
            "The unconditional probability of taking on values Theta at minus one followed by making the transition to I3 to I right given Sita I -- 1.",
            "Has got to be equal to the inverse probability starting at C to I and then making the transition backwards to see to the value of Theta I -- 1 and that has to hold for all values of Theta, so that's the detailed bounce condition.",
            "So this is a very important condition why?",
            "Well?",
            "Because it's sufficient that if the transition operator satisfies this reverse ability?",
            "Satisfies detailed balance, then an invariant distribution exists, and it.",
            "Let's just remember that what we're trying to do is we're trying to devise a Markov process whose invariant distribution will be the posterior that we are interested in drawing samples from.",
            "And.",
            "Just to show that this actually indeed.",
            "Retains the invariant distribution if we just sum over all values of Theta at I -- 1.",
            "Then we see.",
            "The condition here holds, so this invariant distribution.",
            "So this is just like the Chapman Kolmogorov equations.",
            "OK, so detailed detailed balance to exist.",
            "Then there will be an invariant distribution that satisfies these equations here.",
            "So as I said, Markov chain theory, we would consider what are the conditions for the existence of an invariant distribution given a transition operator.",
            "But we're actually interested in the opposite thing.",
            "We know what the invariant distribution is.",
            "We know their invariant distribution that we want.",
            "So how do we then obtain a transition operator that guarantees that the invariant distribution of the chain is the posterior of interest?",
            "And that's why."
        ],
        [
            "I'm going to come to know.",
            "No, in most machine learning lectures of texts that I've read, the Metropolis Hastings algorithm is presented as the Metropolis Hastings algorithm.",
            "But what I'm going to do today, as I'm going to go through.",
            "A derivation and proof of the methods so that you really understand what's going on so that those of you who want to study this area further you at least understand what this thing, what the constraints are, and for those of you that really don't want to study this.",
            "This either any further, well you'll be better educated than you will by the time before you came to La Palma, so the Metropolis Hastings algorithm.",
            "Well, here's a picture of Nick Metropolis, who, along with Hastings, not Hastings, Taylor and some others, man and wife.",
            "Piering published the paper in 53.",
            "On how to simulate.",
            "States of a particular physical system.",
            "Using what I'm about to describe to you, so that's Nick Metropolis from the Metropolis haste."
        ],
        [
            "Algorithm and this is Hastings.",
            "This is the picture of Hastings that you'll find on the web if you look for him.",
            "And why is that?",
            "Well put Hastings in 1970 published the paper in Biometrika.",
            "Which generalized?",
            "The metropolis algorithm, and I think the number of citations to that paper is probably more than enough to make Bernard jealous in terms of the number of citations that that.",
            "Doctor Hastings obtained.",
            "And yet Despite that he was an associate professor of statistics at the University of Toronto.",
            "They never gave him tenure.",
            "So put on Hastings, never quite managed to get his photograph on to Google at all.",
            "But nevertheless.",
            "He made quite a huge contribution to the whole area.",
            "Right now I'm going to switch.",
            "To the continuous domain.",
            "OK, so all of the arguments hold for the discrete domain, but the continuous domain is more.",
            "Is more general because I'm going to have to.",
            "Well, 'cause I'm going to be dealing with densities and measures and so forth.",
            "So what I'm seeing here is then that the condition that we saw previously is that this Pi star of some element DY which is just equal to a density.",
            "Value of Y multiplied by whatever the measure is going to be, so you can just think of this as the distribution, right?",
            "Which of course is.",
            "This is not our transition operator, right?",
            "So it's the probability of moving from a value of X.",
            "Time T. To a value in DY Time T + 1.",
            "And this is the unconditional distribution under the invariant distribution Pi of X. OK, so as in the discrete case, at the NTH iteration then the transition kernel transition operator is just going to be this linear operation on the.",
            "Transition candle at N -- 1 on the.",
            "Transition kernel itself.",
            "So what we have to do, just remember is that we have to define a transition kernel.",
            "P of XDY So there is got this posterior distribution as its invariant density.",
            "So how are we going to do that?",
            "Well, let's just consider a function.",
            "This is not a density, it's not a distribution, just a function.",
            "So function of.",
            "X&Y.",
            "And let's define a transition operator based on this as follows.",
            "We'll say that the transition kernel.",
            "P of XY is going to be equal to the sum of this function.",
            "Times some.",
            "Volume element DY.",
            "So just say this is the measure.",
            "And then some function out of X and then this Delta function here, which will take on the value of 1.",
            "If the value of X is within this element here.",
            "Note the only condition that we have is that the integral of P with respect to DX will equal 1, because it's a.",
            "It's a valid transition operator for a Markov process.",
            "And we will also just make the assumption will just enforce that P of X&X is equal to 0.",
            "This condition holds as I just mentioned to you.",
            "Then what this says is that this function here are of X.",
            "Well, if we integrate with respect to DX over the complete domain, so this is 1, right?",
            "Well, this is the integral and then this here is just going to be the integral.",
            "Well, so this is just going to be one.",
            "So this just comes out is out of X and so we define out of X is 1 minus the integral of this function.",
            "Whatever this function happens to be.",
            "And it turns out to be the probability.",
            "That the chain will remain.",
            "At the current value of the random variables that define the chain.",
            "No.",
            "If this function P of X&Y satisfies the reverse ability condition, so, just remember the reversibility condition, we write it here.",
            "OK, so P of XY.",
            "Times \u03c0 of X must be equal to the reverse operation, so PY to X Pi of Y.",
            "Now, if this satisfies reverse ability, then we can go home.",
            "Well, we can't go for dinner yet.",
            "'cause this won't satisfy reversibility in the most general sense.",
            "But if it does, then we know that Pi is going to be the invariant density of this transition kernel.",
            "Well, this is great, so we've reversed the whole process.",
            "We've no but the bare bones of a transition care, nor which is going to give us the invariant distribution that we are looking for.",
            "An.",
            "For one thing, we need to do is, we just need to convince ourselves that this."
        ],
        [
            "This is the case, and so I'm just going to go through a very simple derivation.",
            "So the first thing that we do.",
            "Is that we take?",
            "This transition operator and we apply the Pi of X to it and then integrate OK. Over the whole domain.",
            "So if we just plug in Pi of X under integral.",
            "Over D of X into the expression on the right hand side.",
            "Then we get this here.",
            "Now what I've got here.",
            "Alright is an expression which is defining this region a OK, so I'm integrating the random variable Y over this particular region A.",
            "We have the.",
            "\u03a0 of X integrated with respect to D of X and then we have the same deal here.",
            "So if we just.",
            "Shuffle things about here.",
            "To make things a bit tidier and we just notice that for X.",
            "So this Delta function in essence restricts the domain of integration here to the region A.",
            "So not so fine.",
            "As I said, all that we've done here is, we've just shuffled things about.",
            "We've done nothing else.",
            "No.",
            "If this is reversible.",
            "Then we can see that P of XY Pi of X DX is equal to.",
            "\u03a0 of yx Pi P. Of YX Pi of YDX.",
            "OK. Everyone happy with that, so I'm assuming.",
            "But if this is reversible, then I can replace this expression with this here.",
            "I can work this out and it turns out of course that this is just going to be 1 minus the probability that this is going to be the probability of just remaining at the value Y.",
            "And then of course we're going to integrate over a with respect to Pi ydy.",
            "This hasn't changed the tool and you can see straight away what's going to happen is that these terms are going to cancel out and we're just going to be left with the integral of Pi of ydy with respect to a, which of course is the distribution that we're interested in.",
            "So the fact that we've used the transition care."
        ],
        [
            "Final.",
            "Of this form here."
        ],
        [
            "And becausw reverse ability or detailed bounds is a sufficient condition for an invariant distribution to exist for this particular transition operator.",
            "By exploiting the detail bounds condition.",
            "Here we've been able to convince ourselves that this transition operator indeed will deliver the invariant distribution of interest, so the reverse ability condition for this function PXY is enough.",
            "It's sufficient in designing our transition operator.",
            "That's great.",
            "OK, what's next?",
            "Well, what in fact is the form of Piave?"
        ],
        [
            "XY.",
            "Alright, so.",
            "We've got our transition Care now we need to start to put some meat over these bones.",
            "I OK let's.",
            "Let's pluck from the ear.",
            "A density associated with some distribution from which we can reasonably simulate samples, and we call this the proposal density.",
            "So this is a density that would be amenable to.",
            "As I said, simulating random variables from in an easy manner.",
            "A normal distribution, a uniform distribution, whatever, some arbitrary distribution.",
            "And we'll call it Q of XY, right?",
            "So the probability that given particular values X, we will then generate values Y.",
            "So of course this is a density, so it satisfies all the usual criteria if it satisfies.",
            "If Q of XY is reversible jobs done.",
            "The thing is, it may not be reversible.",
            "And it may not be reversible for a number of well, for two reasons.",
            "In particular, one is the following.",
            "It may be that the detailed bounce condition.",
            "It reduces to.",
            "And inequality.",
            "So for example here, instead of having an equality, we might have the fact that.",
            "Q of XY times \u03c0 of X is always greater than the reverse.",
            "So in other words, the number of transitions from X to Y course 2 often.",
            "Right to ensure that the balance condition.",
            "Well, we can.",
            "We can sort that out by re balancing both sides, right?",
            "So we could introduce another probability or call it Alpha, which again will be a function of X&Y and we can define that in some way to ensure that this inequality will always go back to an equality.",
            "So in this case here, for example, we would 1A X of Y to be smaller than one in some way because we want to reduce this value to to be in line with the right hand side.",
            "So we can establish reverse ability by defining.",
            "I.",
            "By augmenting this with Alpha XY, so we know how Pi of X.",
            "The value of our proposal distribution and then the value of this acceptance probability, and then likewise on the reverse side, will have this value of the acceptance probability.",
            "But in the reverse direction.",
            "Well, that's great so.",
            "By definition, we've enforced reverse ability, but we know we need to.",
            "Define what what sort of functional form this Alpha X of Y is going to be.",
            "Well, it's a distribution, so the maximum value is going to be set to 1.",
            "So in that case, then we'll set to for this condition.",
            "Here we'll set this to one.",
            "K. So our balance condition looks like this.",
            "And then some primary school algebra just tells us that the acceptance probability.",
            "Has to take the form of.",
            "The probability under.",
            "The desired distribution of Y multiplied by the proposal distribution in the reverse direction, and that's divided by.",
            "The density at X on the desired distribution and then the forward proposal distribution.",
            "So in other words, OK, right?",
            "So I've made the argument for when the left hand side is larger than the right hand side.",
            "I'll leave it to use a homework exercise to figure out what I don't even do it for homework because it's trivial.",
            "It's it's just that."
        ],
        [
            "Yes, and it all works out the same.",
            "So what this means is that, again, if I just remember."
        ],
        [
            "Just remind you the P function here, which I said it wasn't.",
            "A density is just some arbitrary function.",
            "There's no looking like this here.",
            "Where is it?"
        ],
        [
            "Yeah, so the P function associated with the Metropolis Hastings algorithm.",
            "Is just going to be equal to the product of the proposal?",
            "On the acceptance probability.",
            "For all values of X&Y not being equal?",
            "On the acceptance, probability is just going to be equal to the minimum of its maximum value, which was which was in the case that I showed you there one or.",
            "The ratio that popped out when we enforced the reversibility condition.",
            "So we're almost there.",
            "So the overall transition kernel.",
            "That we come up with turns out to be, well, our P function is just proposal times acceptance plus the probability of staying in a particular position and then.",
            "Just defined by the Delta function this.",
            "By the way, that we have defined it and we have developed.",
            "It is reversible and therefore Pi of X will be its invariant density.",
            "So the Metropolis Hastings algorithm.",
            "I mean all it really is, the algorithm is just a way of representing the transition operator.",
            "Think by this proposal distribution and that requires to be chosen.",
            "Everything else is defined for us.",
            "\u03a0 is what we want.",
            "Q is something that we have to select.",
            "OK, so this acceptance probability.",
            "This ratio here.",
            "So for any density.",
            "Which we can write as the Unnormalized forum divided by its normalizing constant.",
            "OK, then just boils down to this here.",
            "So the troublesome normalizing constant, which beleaguered.",
            "Bayesian star closet Bayesian statisticians.",
            "In the Fifties, 60s and 70s has no disappeared, so we no longer have to concern ourselves with trying to.",
            "To be able to analytically obtain the normalizing constant or the evidence of the marginal likelihood or the physicists call it.",
            "The partition function it's not needed.",
            "In this case here.",
            "So this is absolutely great, right?",
            "Pretty pretty awesome.",
            "And."
        ],
        [
            "But we can even go further.",
            "So if the proposal distribution is actually symmetric, the symmetry doesn't mean reverse ability, but it's symmetric in its arguments.",
            "So if we take a normal distribution right for X with a mean of Y in some covariance structure, then of course the symmetry, right?",
            "So they're both the same.",
            "Well, it turns out that."
        ],
        [
            "And that the normal these two proposals."
        ],
        [
            "We're going to cancel out, and the acceptance probability is just going to be the ratio of the unnormalized densities.",
            "That's nice.",
            "Now what does this mean?",
            "Well, it suggests for one thing that if your proposal mechanism right takes.",
            "The chain.",
            "Into a region where the density is higher.",
            "Then that move is always going to be accepted, because this is always going to be greater than one.",
            "So what this means is that the Metropolis Hastings algorithm is reacting to the local density structure.",
            "Right, so if it moves into a region of higher density.",
            "It's going to be accepted, so there's always going to be a force pushing the chain into regions of high density.",
            "However, moves into regions of lower density are going to be accepted, not with probability 0, but with some probability.",
            "Whatever that ratio happens to be.",
            "And that means then that we get process which will.",
            "Explore the support of the distribution right at the frequency that is required to ensure appropriate coverage of the invariant distribution.",
            "So this looks great.",
            "So typically what would normally take 30 seconds in a standard machine learning.",
            "Lecture would be this here, so this is the Metropolis Hastings algorithm.",
            "As you recorded up.",
            "Right, so you just simulate from your proposal distribution.",
            "Then you draw a uniform number between zero and one just so that you can accept or reject with probability Alpha, and then you just set the value of the chain to whatever you've drawn from your proposal distribution.",
            "I.",
            "If the acceptance probability dictates or otherwise, we stay in the same position and we just keep doing that, so hopefully.",
            "I guess most of you have probably quoted the Metroplus algorithm, but I hope that you've got a better fuel for the sort of mechanisms underlying.",
            "This very very general MCMC method, because now that you've got a feel for that, looking at more complex and more interesting methods like reversible jump MCMC or some of the more esoteric things which I'm going to come onto is all going to be based on an understanding of the underlying principles of a periodicity.",
            "Of.",
            "Of invariants of the measure of reversibility.",
            "In detail bounds and why these have to be satisfied."
        ],
        [
            "OK yeah this is some R code for those of the R aficionados here.",
            "This is the.",
            "Metropolis Hastings algorithm in R, where the target density is just the standardized normal and the proposal distribution is just a uniform distribution between plus and minus some value, whatever.",
            "OK.",
            "So that's it.",
            "That's the metropolis Hastings algorithm, and it's the basis pretty much on which all MCMC and all the cutting edge MCMC methodology that's being developed these days is based on this here.",
            "So you can Bluff your way through any party full of computational statisticians and so forth.",
            "Now you can understand what reverse ability and so forth and why it's so important."
        ],
        [
            "OK, any questions?",
            "Looks like you've been right.",
            "This is this is discreet.",
            "Yes.",
            "So this is a discrete Markov process rather than a continuous one.",
            "Yeah, and I'm not going to be talking about continuous.",
            "Process is.",
            "Actually, I am I tell a lie, I am.",
            "But as an application.",
            "The samples produced by this algorithm are going to be IE no.",
            "Very good, so remember that for the Monte Carlo estimate.",
            "And for the CLT, right?",
            "So for the expression for the Monte Carlo error, so the variance of the estimate to hold?",
            "Then the samples have to be IID.",
            "No, we've devised a Markov chain.",
            "With first order dependence, so the.",
            "Samples are going to be.",
            "Going to have first order correlation.",
            "So what that means then is that the Monte Carlo error of the variance of the estimate is going to inflate, and it's going to inflate by a factor based on the covariance of the samples that come off this process.",
            "Now there's a lot of work and some of the work that I'm going to talk about.",
            "In later lectures is being done on how to, in essence, have almost effectively independent samples from the Markov chain, so these will be identically distributed, but they won't be independent, they will be correlated.",
            "And if you're and what you find is that for really interesting problems, that level of correlation.",
            "Can be really high, so although we've cracked the problem of being able to sample from the posterior distribution.",
            "The efficiency of the estimates that we obtain from those samples is governed largely by how independent we can drive the samples from which we, you know.",
            "We draw the samples from the chain, and I'm going to talk about these issues as we go along.",
            "OK then what time do we knock off?",
            "Oh great, good good good.",
            "Can I finish?",
            "I've got 2 little things here and then we'll stop for a little break, yeah.",
            "Is that OK?",
            "It's not OK, but you're going to.",
            "You're going to love with it.",
            "OK, so.",
            "So we've defined the kernel, a kernel that we know will satisfy reverse ability and will give us our invariant distribution.",
            "But with that we can do some other things.",
            "We can, for example, we can design other kernels by taking products or mixtures of them.",
            "So I'm going to look at a product care no.",
            "The reason for this is are the motivation for something like this is as follows.",
            "Let's assume that we're trying to sample.",
            "From a distribution which is random, variables have quite a high dimensionality.",
            "Then what you probably find in what you do find is that the probability of acceptance is going to be very low unless you are very clever in the way that you devise your proposal distribution.",
            "And as I said, I'm going to talk a lot about that in the coming lectures.",
            "So if the target density is high dimensional multivariate, one thing that we could do is we could break up.",
            "These vectors into little sub blocks and then we could try and run proposals unchains on these sub blocks right?",
            "So this might be our kind of reasonable way of designing proposals that would allow us to have a reasonable level of acceptance probability.",
            "But of course the question is, well, I mean reduce doing something like this, ensure convergence to the correct target.",
            "So let's take a. OK, let's see.",
            "The X is a vector know in a 2 dimensional space.",
            "So X1 and X2 of the other components.",
            "And.",
            "We're going to see that we've got a conditional transition kernel P1, which moves.",
            "X1.",
            "OK, so the X1 component into D1 conditional on.",
            "X2 taking a particular value right and this transition Karen was going to have an invariant density which is going to be the conditional of X1.",
            "Given a particular fixed value of X2 and likewise we have a transition care no P2.",
            "Which does the same operation on the second component of the.",
            "Of the vector and it will have its own invariant density Pi 2 given one.",
            "Given a fixed value for X1.",
            "And of course, the standard conditions apply.",
            "In terms of invariants.",
            "And what I'm stating is that the product of these two kernels.",
            "Has an invariant density.",
            "Which is the joint density that we are interested in?",
            "Right now.",
            "I've taken it to the simplest case where this is a 2 dimensional vector.",
            "Right on each of these is just a univariate thing, but these could actually be blocks of different dimension, so this would all still hold.",
            "OK could you could someone volunteer to prove this?",
            "Why you bought here.",
            "Let's see your hand up.",
            "He's pretending it didn't seem.",
            "OK, it's actually fairly straightforward and the mechanics are very similar to what we did for the."
        ],
        [
            "The simple case, but let's just go through it.",
            "So first of all, the product kernel.",
            "So here's arcano.",
            "And here's the invariant distribution.",
            "K so we can just do a bit of jiggling about the key thing here is that we will split.",
            "This density into its conditional and its unconditional component.",
            "And what we will then find?",
            "Is that this here by definition, is just going to be the conditional invariant for the transition kernel Pi one.",
            "Now what we'll do is we'll.",
            "Will rewrite this using Bayes rule so that this is \u03c0 of two given one.",
            "Right, so I've just.",
            "I've just rewritten this Miss form here.",
            "And.",
            "This of course comes out of the brackets these Council.",
            "This of course.",
            "The central, of course, then gives us the conditional distribution.",
            "We are interested in and this product form.",
            "Ensures that the.",
            "The joint distribution comes out from the application of this product of transition kernels."
        ],
        [
            "So it's all good.",
            "I mean, if you've heard of the Gibbs sampler.",
            "Well, not as many as I thought.",
            "Well, the Gibbs sampler is nothing but.",
            "A spatial instance of the.",
            "Metropolis Hastings algorithm.",
            "Because what we're going to do is we're going to say that we're going to set.",
            "The transition kernels.",
            "To be equal to the conditional distributions.",
            "Right, so the exact conditional distributions that we are of the joint distribution that we are interested in.",
            "So if we devise our acceptance probability and we plug these in, then again some primary school algebra takes us to the fact that these all cancel out and we end up with an acceptance probability of 1.",
            "So in other words, if we can obtain the exact conditional distributions.",
            "And simulate from those.",
            "Right, we accept every draw.",
            "With probability one and we know that by simulating repeatedly from these exact conditionals, then this will have this Markov chain will have an invariant distribution."
        ],
        [
            "Which is the joint?"
        ],
        [
            "And that we interested in so the Gibbs sampler, you know, as I said, is just.",
            "Is just another choice of the whatever the transition kernel is for the Metropolis Hastings algorithm."
        ],
        [
            "So I'll close on this.",
            "Not close, I will break for this point here.",
            "Let's take a bivariate Gaussian as an example, so we're going to see that our target distribution is a Gaussian.",
            "Which is a mean of 0.",
            "And has a covariance structure such that the variance is 1.",
            "And the.",
            "Covariance structure is governed by this coefficient rho here.",
            "K. Now for the Metropolis Hastings algorithm, let's define a proposal mechanism.",
            "Which is a normal.",
            "And I guess the only thing that we can.",
            "We can do here as we can see well, the covariance structure of our proposal mechanism is going to have some parameter with parameter Sigma.",
            "OK so if I workout my acceptance probability for this target density then it again it just turns out to be the ratio of the unnormalized.",
            "Densities of the target distribution, which is just going to be exponential at the proposal value over the exponential of this quadratic form at the current value.",
            "No.",
            "Anne.",
            "Can I mean, given what we've been talking about?",
            "Can you see any issues?",
            "Kind of practical issues that may arise.",
            "I.",
            "Given.",
            "The structure of our target density and the structure of our proposal.",
            "Density.",
            "OK, so those are a little bit about sampling can show off and maybe actually save what you think might be an issue here.",
            "To near dinner so.",
            "I'll put you out of your misery, so let's assume that rule was very large, something like .99.",
            "Then we have a distribution that would look something a target distribution that's going to look something like this very long elongated sort of cigar shaped things similar to what new was showing earlier on today.",
            "So that's our target distribution.",
            "But our proposal.",
            "Right is this vertical thing here, right?",
            "So it's going to have.",
            "Specticle covariance is radius.",
            "Is proportional to Sigma.",
            "OK.",
            "So you can see that if we make our a bad choice for Sigma.",
            "So let's say that we make Sigma look something like this here.",
            "Then what's going to happen well?",
            "If we are currently at this point, this is no yes.",
            "Currently at this point here.",
            "Right, I should actually.",
            "Sample with replacement.",
            "Without replacement I should see.",
            "So let's say that Sigma is.",
            "You know it's defining some sort of sphere like this, then you know it's very probable that we're going to get proposals.",
            "In these regions here.",
            "So what this means is that the probability of acceptance.",
            "For these samples.",
            "Is going to be very low.",
            "Because of this ratio here.",
            "Here, on the other hand, is probably not going to be too bad, but what this means is that the acceptance probability, so the number of proposals that you have to make before the chain actually moves anywhere is going to be very large, and so it's absolutely clear that this proposal mechanism is going to be really critical, and being able to devise an efficient chain and efficient chain.",
            "What I mean by efficient, I mean efficient in terms of the computation.",
            "Because there's going to be a cost associated with.",
            "Making a proposal and then assessing whether it gets accepted or rejected.",
            "But Furthermore you are asking the question about the iid nature of the chain.",
            "Remember that if we make a proposal, so we're here.",
            "We make a proposal here.",
            "It gets rejected.",
            "The chain stays where it is.",
            "Who make another proposal?",
            "It gets rejected.",
            "The chain stays where it is, and So what you end up with is a chain that might be.",
            "Staying in the same place for long periods of time and what does this do?",
            "It adds to the correlation structure.",
            "And therefore it inflates the variance of the.",
            "Monte Carlo estimates that you're going to be using these samples for, so this in actual fact is a very serious issue.",
            "And one that we're going to try and address later on.",
            "So this seems to be quite troublesome.",
            "We're going to have to tune this thing.",
            "This is a pain, but our target density is a 2 dimensional Gaussian.",
            "Well, this is great.",
            "We can get the exact conditional distributions and have a Gibbs sampler.",
            "So everything is going to be accepted.",
            "Alright, everything succeeded with probability one, so the problem solved.",
            "Well, is it really?",
            "Let's look at the exact form of the exact conditionals.",
            "So here we are here.",
            "So for a current value of X2, then the exact conditional is equal to the coral efficient scales the the current value.",
            "And then the variance is 1 minus row squared, and that's the same for both of these conditionals.",
            "But it doesn't matter, we just simulate these.",
            "We accept all of them.",
            "Is there a problem here?",
            "Yeah, what's the problem?",
            "Close to one will say yeah, exactly so for the example that we've got here rule .99 or whatever.",
            "Then it means that our little conditionals.",
            "Write 4X1.",
            "It's going to look something like this.",
            "1 minus rule squared is going to be very small, so any moves are going to be tiny in this direction and likewise.",
            "In the wide and the.",
            "Yeah the X2 direction.",
            "It's going to be very small, So what we end up doing is making these incredibly small.",
            "Axis aligned moves, so the actual amount of time it's going to take to traverse the support of this distribution is going to be very long, and again, Furthermore becausw.",
            "The chain is incrementing very in a very, very small steps.",
            "The correlation is going to increase and therefore the Monte Carlo error that we see in our, whatever our estimates happened to be is going to increase.",
            "So we have a problem.",
            "And it turns out to be a very serious problem in the really interesting applications that.",
            "Well, I."
        ],
        [
            "To work with.",
            "I told a lie.",
            "I said this was the last thing.",
            "This is actually the last thing here and then and then you can all go for whatever you're going for.",
            "So we talked about product kernels.",
            "What about mixture?",
            "Care knows?",
            "So let's say again, we've got the same to transition kernels and we've got two transition kernels.",
            "P1 and P2 and they both have in this case.",
            "\u03a0 as the invariant density.",
            "Now let's just define some probability gamma, and we set up our mixture kernel.",
            "It looks like this.",
            "So what's the invariant density of the transition kernel composed of this mixture here?",
            "What's the invariant density that's invariant density of Pi one unpi 2?",
            "P1 and P2's pie then puts the invariant density of this mixture.",
            "Pie.",
            "I.",
            "It's too close to dinner, but you can convince yourself that it's Pi XI mean it's trivial.",
            "What situations might this be useful so the product?",
            "It was very clear that for multivariate distributions of product, kernel may prove to be useful, not about a mixture, care no.",
            "When do you think it might be useful?",
            "Are you saying I never want to do MCMC again after this so I don't care when or where it's useful?",
            "I've lost enough.",
            "Very.",
            "Yeah, I mean adaptation is a very good point.",
            "I would certainly allow you to adapt well in a very loose sense, it wouldn't be adaptive, but let's say that we had a distribution that looked like this.",
            "I don't know if you can see that, but it's basically just one bump separated at the tails by another little bump.",
            "Well, what you could and actually fight do here.",
            "So the problem that we're going to have is that when the Markov chain is in here, remember that.",
            "The Hastings ratio showed us that with that, if we make a proposal to move into a region of higher density, right, it's always going to be accepted.",
            "And if we move, make a proposal to move into a region of lower density is going to be accepted with probability which is equal to the ratio of of the two probabilities.",
            "So if we're here.",
            "Right, and we make a proposal here.",
            "Well, fine, we're going to do lots of exploration here, but we want to get over here.",
            "So let's imagine that we make a proposal to here, while the probability of accepting such a move is going to be very small, so it could take a very, very long time.",
            "Very large number of tries before eventually this move is accepted.",
            "Then you can make the leap over to this other.",
            "Bumper this other mode here.",
            "So one thing that you could do is you could have two disks.",
            "You could have two transition kernels, one which was for local moves and one which was for global moves.",
            "So you could have one in essence, which covered everything here.",
            "Right, so you could make moves from this region to this region under, say, part P2.",
            "And then once you're in here, you would have your Pi one, which would be much, much smaller in terms of its variance, right?",
            "So for multimodal distributions, or distributions that have ridges and all sorts of strange things, and then this mixture distribute this mixture, Kernow may actually be useful.",
            "And it turns out indeed that it."
        ],
        [
            "That it is.",
            "I'm.",
            "OK, we talked about the fact that Monte Carlo estimates required IID samples.",
            "And you created this slide here.",
            "The other thing, of course, is how long do we have to wait before the chain is converged, and so forth, right?",
            "And shall we take our?",
            "I don't know 10 minute break.",
            "Any questions?",
            "What's for dinner?",
            "OK, I see in 10 minutes."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "My heart really started to sing when I saw that the weather wasn't too great when we broke for lunch because I had visions of talking to about a handful of really eager Beavers and the rest of you would be out in the beach, but Fortunately wasn't that warm for you to stay out there.",
                    "label": 0
                },
                {
                    "sent": "So I'm glad you're back in the warmth and here.",
                    "label": 0
                },
                {
                    "sent": "So unlike Benard and Neil, I probably need a little bit of introduction as I'm this is my first ever machine learning Summer School an as you said, I'm from the Department of Statistical Science at UCL.",
                    "label": 1
                },
                {
                    "sent": "UCL Department statistical Science was set up by Karl Pearson, who was mentioned many times and news talk and.",
                    "label": 0
                },
                {
                    "sent": "Was also in the Vanguard of the Bayesian movement in the statistics community, with people like Dennis Lindley and various others.",
                    "label": 0
                },
                {
                    "sent": "So today I'm going to try and give you a tutorial and one of the things I really hope that I managed to do is leave you with intuition rather than lots and lots of detailed theory, right?",
                    "label": 0
                },
                {
                    "sent": "So intuition that will motivate you to study the detailed theory and that's one of the things I found with Bernards talk this morning and news that really provided very beautiful intuitions.",
                    "label": 0
                },
                {
                    "sent": "And although I thought I knew everything.",
                    "label": 0
                },
                {
                    "sent": "That I cared to ever want to know about PCA.",
                    "label": 0
                },
                {
                    "sent": "I really felt that you know there were a number of of intuitions that I had missed, so hopefully you'll get some intuitions about MCMC, and in particular the.",
                    "label": 0
                },
                {
                    "sent": "The Grand New World of geometric Markov chain Monte Carlo and I hope that some of you will get really excited by it and start to contribute to the area.",
                    "label": 0
                },
                {
                    "sent": "But before I start and all of that, I think we need to lay down some some basic ground.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Mark so.",
                    "label": 0
                },
                {
                    "sent": "The whole reason for.",
                    "label": 0
                },
                {
                    "sent": "Markov chain Monte Carlo is really because of this chart here.",
                    "label": 0
                },
                {
                    "sent": "Can everyone see well the chap who this picture is meant to represent?",
                    "label": 0
                },
                {
                    "sent": "So of course this is meant to be the Reverend Thomas Base.",
                    "label": 0
                },
                {
                    "sent": "Who is credited for the whole new?",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Ocean of probability inversion.",
                    "label": 0
                },
                {
                    "sent": "And this leads to the whole area of what is called in statistics and the machine learning Bayesian inference.",
                    "label": 0
                },
                {
                    "sent": "And you hear an awful lot more about that next week.",
                    "label": 0
                },
                {
                    "sent": "So in many ways I'm just a kind of warm up act for the likes of Zubin and Co. Who will be talking in great depth about Bayesian methods and Bayesian nonparametrics.",
                    "label": 0
                },
                {
                    "sent": "So I'm going to present the kind of nuts and bolts if you will be able to do sensible Bayesian inference.",
                    "label": 0
                },
                {
                    "sent": "And so if we have some observations, if we make some observations from some experiment or from some logging device, we have data associated with that X.",
                    "label": 0
                },
                {
                    "sent": "And then we have a model trying to describe what we've observed and that model will have.",
                    "label": 0
                },
                {
                    "sent": "Some free parameters.",
                    "label": 0
                },
                {
                    "sent": "There may also be components of the model or variables associated with the model, which we don't observe, so they are heading to as their latent, or they're on observed.",
                    "label": 0
                },
                {
                    "sent": "Now I'm just going to bundle both the parameters of our model and the latent variables all into some set of random variables theater.",
                    "label": 0
                },
                {
                    "sent": "No.",
                    "label": 0
                },
                {
                    "sent": "As Bernard mentioned today, and Neil alluded to as well in Bayesian inference, the key.",
                    "label": 1
                },
                {
                    "sent": "Issue that we have to address is how we define a prior distribution.",
                    "label": 1
                },
                {
                    "sent": "Over all of the unknowns in our model, now in fact we have to go a step back becausw in our model.",
                    "label": 0
                },
                {
                    "sent": "Our model may in fact just be.",
                    "label": 0
                },
                {
                    "sent": "One particular instantiation from a whole model class and in which case we would actually have a prior distribution over the instantiations of the models within the model class.",
                    "label": 0
                },
                {
                    "sent": "But here just to keep things simple, I'm assuming that we are conditioning on one model, so I'm not going to consider trans dimensional.",
                    "label": 0
                },
                {
                    "sent": "Markov chain Monte Carlo, where we actually look across a whole model class or finite model class.",
                    "label": 0
                },
                {
                    "sent": "I'm considering just one particular model with a set of latent variables and the set of parameters OK, But please bear in mind that this is only part of the story.",
                    "label": 0
                },
                {
                    "sent": "And if there's time.",
                    "label": 0
                },
                {
                    "sent": "Probably in the third lecture I'll then talk about the issue of doing inference over model classes.",
                    "label": 0
                },
                {
                    "sent": "But for now, we're looking at a prior distribution over all of the unknowns associated with our model, and I'll call.",
                    "label": 0
                },
                {
                    "sent": "I'll see that there is some distribution or some density associated with the measure Pi nought over Theta.",
                    "label": 0
                },
                {
                    "sent": "Now, of course, for those of you who haven't been hanging about all these Bayesians and machine the machine learning community.",
                    "label": 0
                },
                {
                    "sent": "The prior distribution.",
                    "label": 0
                },
                {
                    "sent": "I'm is something as I said that has to be selected based on your prior understanding or prior observations or prior beliefs and that may be something as simple As for example in some of the probabilistic principal component analysis models that Neil spoke off this morning.",
                    "label": 0
                },
                {
                    "sent": "He alluded to using a Bayesian approach rather than just the likelihood based approach, so you would then be putting priors over the column vectors of W and you would be putting priors over the values of the variance Sigma squared.",
                    "label": 0
                },
                {
                    "sent": "And of course one of the simple things you definitely know about Sigma squared is that it's it's got its values have to be constrained to the positive part of the real line.",
                    "label": 0
                },
                {
                    "sent": "So there straight away there is a constraint that can be codified and some sort of prior distribution which restricts the support of the distribution of that particular random variable and on it goes.",
                    "label": 0
                },
                {
                    "sent": "No, the data under the model and the current values of our observed variables and parameters we defined by the likelihood the probability of the data X conditioned on Theta.",
                    "label": 1
                },
                {
                    "sent": "Now again, for completeness, we would of course also condition on M the particular instance of the model class that we are considering.",
                    "label": 0
                },
                {
                    "sent": "But here I'm just making that implicit.",
                    "label": 0
                },
                {
                    "sent": "Now of course, the posterior distribution, which is the.",
                    "label": 0
                },
                {
                    "sent": "The whole basis of Bayesian inference follows just by the application of the of this simple rule here, so we can invert the likelihood so the probabilities probability can be inverted by multiplying by the prior.",
                    "label": 0
                },
                {
                    "sent": "And then re normalizing so that this is indeed density functional or or an actual distribution.",
                    "label": 0
                },
                {
                    "sent": "So it would be normalized in this respect here.",
                    "label": 0
                },
                {
                    "sent": "So what we're doing with this very simple equation allows us to do and, which has been the basis of a huge amount of infighting within the statistics community.",
                    "label": 0
                },
                {
                    "sent": "For the best part of a couple of centuries is that we can invert.",
                    "label": 0
                },
                {
                    "sent": "As I said, the likelihood of our observations given causes to the other way round.",
                    "label": 0
                },
                {
                    "sent": "No.",
                    "label": 0
                },
                {
                    "sent": "Until the advent of the methods that I'm going to talk about MCMC, it didn't really become apparent to a lot of statisticians that in actual fact Bayesian methods based on models for inference actually work.",
                    "label": 0
                },
                {
                    "sent": "Ann one statisticians started to realize that it worked.",
                    "label": 0
                },
                {
                    "sent": "Then all the sort of philosophical issues associated with Bayesian inference started to die away.",
                    "label": 0
                },
                {
                    "sent": "But I have to say that this is an extremely powerful representation, despite it just simply being a piece of algebra.",
                    "label": 0
                },
                {
                    "sent": "Is.",
                    "label": 0
                },
                {
                    "sent": "Yes, and I guess Zubin will wax lyrical about.",
                    "label": 1
                },
                {
                    "sent": "The power of the posterior distribution.",
                    "label": 0
                },
                {
                    "sent": "Now, of course, once we've.",
                    "label": 0
                },
                {
                    "sent": "Obtain this posterior.",
                    "label": 0
                },
                {
                    "sent": "Distribution, then all subsequent inference regarding the model which underlies our prior and our likelihood, requires specific integration with respect to this posterior measure.",
                    "label": 0
                },
                {
                    "sent": "So, say, for example, we were interested in the expected value of some function of the parameters or the variables of interest.",
                    "label": 0
                },
                {
                    "sent": "We would take the expectation with respect to the posterior, so you'll see this notation quite a lot the expectation.",
                    "label": 0
                },
                {
                    "sent": "With respect to the measure associated with this conditional theater, given X of this function here.",
                    "label": 0
                },
                {
                    "sent": "So all Bayesian inference requires us to, rather than optimizing the likelihood setting, we have to integrate.",
                    "label": 0
                },
                {
                    "sent": "We have to perform these multi dimensional integrals.",
                    "label": 0
                },
                {
                    "sent": "This is a stray closing bracket.",
                    "label": 0
                },
                {
                    "sent": "OK, and.",
                    "label": 0
                },
                {
                    "sent": "This is all great, but for models of and inference problems of real interest, real interest to the natural to the physical to the engineering Sciences to economics finance.",
                    "label": 0
                },
                {
                    "sent": "What have you?",
                    "label": 0
                },
                {
                    "sent": "There are very few cases.",
                    "label": 0
                },
                {
                    "sent": "Where the prior predictive likelihood is this is called or the evidence.",
                    "label": 0
                },
                {
                    "sent": "So the marginal likelihood is analytic.",
                    "label": 0
                },
                {
                    "sent": "So in other words, there are very very few instances where the posterior distribution, which is the capstone of Bayesian inference, can actually be obtained in any analytic forum.",
                    "label": 0
                },
                {
                    "sent": "And because of that progress in the use of the widespread use of Bayesian inference was largely halted because of this, and was restricted to the choice of a prior distribution and a likelihood which comprised of what was called a conjugate pair.",
                    "label": 0
                },
                {
                    "sent": "Where the distribution of the prior combined with the distribution of the likelihood induced the posterior which had the same functional properties as the prior distribution.",
                    "label": 0
                },
                {
                    "sent": "OK, so it everything was analytic.",
                    "label": 0
                },
                {
                    "sent": "Brother a cumulant based expansions, which were of course approximations that had been considered as well, but to do anything in some sort of exact way, was really limited to conjugate priors.",
                    "label": 0
                },
                {
                    "sent": "I'm likelihood functions and so that really as I said, restricted.",
                    "label": 0
                },
                {
                    "sent": "Bayesian.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "France, for quite some time.",
                    "label": 0
                },
                {
                    "sent": "But then some statisticians and all the smart statisticians tend to read papers and physics or hang out with physicists.",
                    "label": 0
                },
                {
                    "sent": "And the land of the Monte Carlo principle.",
                    "label": 1
                },
                {
                    "sent": "Now what's Monte Carlo running for?",
                    "label": 0
                },
                {
                    "sent": "Formula One Formula One.",
                    "label": 0
                },
                {
                    "sent": "Sorry.",
                    "label": 0
                },
                {
                    "sent": "Casinos?",
                    "label": 0
                },
                {
                    "sent": "Yeah well, it's similar tax.",
                    "label": 0
                },
                {
                    "sent": "Even lots of good cyclists live in one.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Decarlo but of course the big thing is that it's it's famous for the casino where games of Chance or played and, and that's exactly what the Monte Carlo principle is based on, is based on random.",
                    "label": 0
                },
                {
                    "sent": "The outcome of a random events and this outcome of random events or these stochastic process is.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Enable us to be able to start to think about how can we numeric.",
                    "label": 0
                },
                {
                    "sent": "How can we obtain estimates of these integrals?",
                    "label": 0
                },
                {
                    "sent": "Right, because these integrals are nothing but expectations under a particular measure.",
                    "label": 0
                },
                {
                    "sent": "I.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So based on some sort of stochastic process, so the Monte Carlo principle.",
                    "label": 1
                },
                {
                    "sent": "Allows us to obtain an estimate.",
                    "label": 0
                },
                {
                    "sent": "It's not an approximation, right?",
                    "label": 0
                },
                {
                    "sent": "It's a statistical estimate of all of these intractable integrals that we're faced with in Bayesian inference.",
                    "label": 0
                },
                {
                    "sent": "So typically, if we have some function of a random variable and we want to take an expectation with respect to some density and associated measure an, then if this cannot be obtained analytically.",
                    "label": 0
                },
                {
                    "sent": "We can use stochastic simulation.",
                    "label": 0
                },
                {
                    "sent": "To obtain an estimate as follows, we obtain.",
                    "label": 0
                },
                {
                    "sent": "A set of independent and identically distributed samples, so these samples Theta superscript North are distributed according to the Let's just call it this particular density of interest and they are going to be independent of each other, so we're going to be independent draws from this distribution.",
                    "label": 0
                },
                {
                    "sent": "And once we have a number of these samples, we can then just plug them in to this numerical estimate here.",
                    "label": 0
                },
                {
                    "sent": "OK, so we plug the values of a random variables into our function and then we just take the plug and estimate.",
                    "label": 0
                },
                {
                    "sent": "We just take the empirical mean.",
                    "label": 0
                },
                {
                    "sent": "And it turns out that.",
                    "label": 0
                },
                {
                    "sent": "Aisin tends to Infinity.",
                    "label": 0
                },
                {
                    "sent": "Then this Monte Carlo estimate tends to the desired expectation and.",
                    "label": 0
                },
                {
                    "sent": "The nice thing about this is that this is a good poker estimator in that it's an unbiased estimator of the integral of interest, and it's a consistent estimator as well.",
                    "label": 0
                },
                {
                    "sent": "So as the number of sample draws IID sample draws increases.",
                    "label": 0
                },
                {
                    "sent": "Then our estimate will tend to the actual integral of interest, and Furthermore the error.",
                    "label": 0
                },
                {
                    "sent": "OK, so the error associated with our Monte Carlo estimate will converge as follows.",
                    "label": 0
                },
                {
                    "sent": "So if I take my estimate, my Monte Carlo estimate based on N IID samples.",
                    "label": 0
                },
                {
                    "sent": "I just take the absolute error scaling it by routine, then this converter distribution of this error right goes towards the standardized normal distribution, which has a mean of zero, indicating of course this is unbiased and the variance is just going to be the variance of the.",
                    "label": 0
                },
                {
                    "sent": "The function of interest.",
                    "label": 0
                },
                {
                    "sent": "Well, this is great, so we can now perform Bayesian inference if we have a mechanism to draw samples from our target distribution, which of course is going to be the posterior distribution.",
                    "label": 0
                },
                {
                    "sent": "So how do we do that?",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Well.",
                    "label": 0
                },
                {
                    "sent": "The most general scheme, and there are a lot of less general schemes which I'm not going to talk about, but the.",
                    "label": 1
                },
                {
                    "sent": "The most powerful certainly is to set up a Markov process.",
                    "label": 0
                },
                {
                    "sent": "Who's stationary distribution?",
                    "label": 0
                },
                {
                    "sent": "Is the distribution that you're interested in.",
                    "label": 0
                },
                {
                    "sent": "So if you can devise a Markov process.",
                    "label": 0
                },
                {
                    "sent": "You then simulate from that until it converges to its invariant distribution.",
                    "label": 0
                },
                {
                    "sent": "And then you keep running that process and all of the draws from that process will be draws from the invariant distribution of the process, which would be the distribution that you're interested in.",
                    "label": 0
                },
                {
                    "sent": "So in this case, our posterior.",
                    "label": 0
                },
                {
                    "sent": "So that also is pretty easy.",
                    "label": 1
                },
                {
                    "sent": "So for those of you who skipped the Markov chains lecture and your undergraduate years, this is a very quick.",
                    "label": 0
                },
                {
                    "sent": "Review of what you need to know about Markov chains to follow the rest of the work.",
                    "label": 0
                },
                {
                    "sent": "So Andrew Mark of course was a Russian mathematician.",
                    "label": 0
                },
                {
                    "sent": "Who devised the majority of the theory studying the conditions under which Markov process would actually have an invariant distribution?",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so the very first.",
                    "label": 0
                },
                {
                    "sent": "Thing about a Markov process so that it's a stochastic process driven by a series of transitions.",
                    "label": 0
                },
                {
                    "sent": "Now this process can be defined in a state space which is discrete or continuous, and the key thing is is defined.",
                    "label": 0
                },
                {
                    "sent": "It's governed by a specific property such that the probability of the value at a particular time increment.",
                    "label": 0
                },
                {
                    "sent": "I given the whole previous history of the process.",
                    "label": 0
                },
                {
                    "sent": "Is just governed by the current value of the process.",
                    "label": 0
                },
                {
                    "sent": "OK, so the previous history after the current one is completely lost in memory, so we just have this one step memory here.",
                    "label": 0
                },
                {
                    "sent": "And this is the Markov property or the 1st order Markov property.",
                    "label": 0
                },
                {
                    "sent": "The probability of the value, the random variable theater time increment I is conditional upon.",
                    "label": 0
                },
                {
                    "sent": "The value of the random variable time increment I -- 1 and everything else is forgotten about.",
                    "label": 0
                },
                {
                    "sent": "So that's the Markov property.",
                    "label": 1
                },
                {
                    "sent": "Now we assume that these transitions or so I should say that this is a probability distribution.",
                    "label": 0
                },
                {
                    "sent": "OK, I'm just calling it T to denote some sort of transition.",
                    "label": 0
                },
                {
                    "sent": "Our probability of transition.",
                    "label": 0
                },
                {
                    "sent": "Now the first thing is is that.",
                    "label": 0
                },
                {
                    "sent": "To make sure that the analysis is fairly straightforward.",
                    "label": 0
                },
                {
                    "sent": "The first thing is we assume is that the transition process is invariant to the time increment sorta time itself.",
                    "label": 0
                },
                {
                    "sent": "So in other words, we have a process which is whose transitions are homogeneous, right?",
                    "label": 0
                },
                {
                    "sent": "So it's invariant.",
                    "label": 0
                },
                {
                    "sent": "Overall tier overall I in this case here.",
                    "label": 0
                },
                {
                    "sent": "So introspective of the value of I where I is, 2 or 2002.",
                    "label": 0
                },
                {
                    "sent": "This transition probability is always going to be the same.",
                    "label": 0
                },
                {
                    "sent": "No, because these are transition probabilities.",
                    "label": 0
                },
                {
                    "sent": "Then in discrete case if we sum over all the possible values that the random variable can take, and of course this is going to come to one and likewise in the continuous case the integral is going to equal 1, and here's a very simple example here discrete example.",
                    "label": 0
                },
                {
                    "sent": "So the probability of making a transition if the value of the random variable is a right at the next step.",
                    "label": 0
                },
                {
                    "sent": "The value is going to be a 0.",
                    "label": 0
                },
                {
                    "sent": "So there's never going to be a self transition, but there's going to be probability one about it's going to make a transition to state a state B. OK, likewise down here if you're in.",
                    "label": 0
                },
                {
                    "sent": "If the values is C, then there's a .6 probability of making a transition to a probability .4 of making a transition to be.",
                    "label": 0
                },
                {
                    "sent": "And of course this sums to one, so there's zero probability that it's going to make a transition to see.",
                    "label": 0
                },
                {
                    "sent": "Very standard, so this is a stochastic matrix whose rows each sum to one.",
                    "label": 0
                },
                {
                    "sent": "To satisfy this condition here.",
                    "label": 0
                },
                {
                    "sent": "Well, let's just pluck a particular set of probabilities from the air.",
                    "label": 0
                },
                {
                    "sent": "And let's say that pie at time one theater one is just equal to whatever this is here .5 point 2.3.",
                    "label": 0
                },
                {
                    "sent": "So the probability.",
                    "label": 0
                },
                {
                    "sent": "Of observing a random variable being in state A is going to be about half, and then the rest of the probability is split roughly 5050.",
                    "label": 0
                },
                {
                    "sent": "Between being in State B in state C, What happens?",
                    "label": 0
                },
                {
                    "sent": "One transition after?",
                    "label": 0
                },
                {
                    "sent": "Well, one transition after we then can compute what the probability of each of these are being unconditional in each of the states will be by simply multiplying.",
                    "label": 0
                },
                {
                    "sent": "Probabilities that we are in at time one right by.",
                    "label": 0
                },
                {
                    "sent": "The transition the overall set of transition probabilities.",
                    "label": 0
                },
                {
                    "sent": "So just by doing this vector matrix multiplication.",
                    "label": 0
                },
                {
                    "sent": "We end up changing.",
                    "label": 0
                },
                {
                    "sent": "The unconditional probabilities of state values from this to this here.",
                    "label": 0
                },
                {
                    "sent": "And it's interesting.",
                    "label": 0
                },
                {
                    "sent": "You see that the probability of being in state one.",
                    "label": 0
                },
                {
                    "sent": ".5 node by the application of this transition Carol here it has no drop.",
                    "label": 0
                },
                {
                    "sent": "The unconditional probability to .18 and you can see that that's fairly obvious.",
                    "label": 0
                },
                {
                    "sent": "Becausw there's zero probabilities here of making any transitions from state 8 or state B2.",
                    "label": 0
                },
                {
                    "sent": "State itself, so it's obviously going to drop from .5.",
                    "label": 0
                },
                {
                    "sent": "I put about one click later at equals three.",
                    "label": 0
                },
                {
                    "sent": "Well again, we just apply the transition operator 2\u03c0 one to get Pi 2 and \u03c0 three is obtained by again applying a transition operator to Pi 2, and on it goes.",
                    "label": 0
                },
                {
                    "sent": "And what we see if we just generalize this is that at any point I then if we just raise or, we just multiply the transition operator.",
                    "label": 0
                },
                {
                    "sent": "By itself I -- 1 times and multiply by the initial state probabilities, we'll obtain the next increment of this.",
                    "label": 0
                },
                {
                    "sent": "This process, so there's something important here about raising the transition care.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To some power.",
                    "label": 0
                },
                {
                    "sent": "So if I just take this transition Care now I just start raising it to various powers.",
                    "label": 0
                },
                {
                    "sent": "So here it is.",
                    "label": 0
                },
                {
                    "sent": "Power 2, so this is the operator.",
                    "label": 0
                },
                {
                    "sent": "That makes a move to T3.",
                    "label": 0
                },
                {
                    "sent": "Here it is at T5.",
                    "label": 0
                },
                {
                    "sent": "T8 T16.",
                    "label": 0
                },
                {
                    "sent": "Now what do you see happening?",
                    "label": 0
                },
                {
                    "sent": "What do you see happening?",
                    "label": 0
                },
                {
                    "sent": "All the all the.",
                    "label": 0
                },
                {
                    "sent": "It's it's all you're far too clever.",
                    "label": 0
                },
                {
                    "sent": "Yeah, exactly what's happening is that the rank of this matrix, first of all is collapsing, and what we find is that all of the rows are exactly identical.",
                    "label": 0
                },
                {
                    "sent": "And what we find is that.",
                    "label": 0
                },
                {
                    "sent": "If we were to continue this process, in fact 64 is more than enough, but certainly if we were to run it indefinitely, then what we would end up with is that irrespective of the initial conditions, the initial distribution over states that if we apply this transition kernel because these are all of this, all the same value.",
                    "label": 0
                },
                {
                    "sent": "And because the values in here but also to one, then this in essence.",
                    "label": 0
                },
                {
                    "sent": "Ensures that this distribution is always going to be constant, is always going to be invariant.",
                    "label": 0
                },
                {
                    "sent": "And what's happened now is that we've reached the invariant disk.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Markov process defined by this transition kernel.",
                    "label": 0
                },
                {
                    "sent": "This transition operator here.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, well I guess that's all fairly straightforward stuff and some things that a lot of you have probably forgotten about from undergraduate studies or just suffice to say that the Markov chain it converges to an invariant distribution of the chain, right?",
                    "label": 1
                },
                {
                    "sent": "The invariant distribution is defined by the transition operator.",
                    "label": 1
                },
                {
                    "sent": "It is completely independent of the initial conditions of the initial state of the process now.",
                    "label": 0
                },
                {
                    "sent": "The transition operator T has to be what's called irreducible.",
                    "label": 0
                },
                {
                    "sent": "So in other words, the graph that defines the various transitions has to be fully connected, right?",
                    "label": 0
                },
                {
                    "sent": "And if it's fully connected then that graph can't be split into smaller subgraphs.",
                    "label": 0
                },
                {
                    "sent": "Because if the overall graph isn't fully connected and it can be partitioned into more than two or certainly more than one, then what it means is that there will be 0 probabilities.",
                    "label": 0
                },
                {
                    "sent": "Of actually moving from one state to the other, and what we really want is is the process to be fully connected so that there's non zero probability of moving from one state to another.",
                    "label": 0
                },
                {
                    "sent": "OK, so the for the invariant distribution to exist, then the transition operator has to be irreducible.",
                    "label": 1
                },
                {
                    "sent": "Another property is that the chain has to be a periodic, so if you think about our transition operator, if we had ones on the diagonal.",
                    "label": 0
                },
                {
                    "sent": "So as soon as we reach the particular value, so a, then the probability of making a transition to a is 1.",
                    "label": 0
                },
                {
                    "sent": "The probability of making a transition to E is 1 and always will be.",
                    "label": 0
                },
                {
                    "sent": "We will never move out of this this cycle as it were, so the chain has to be a periodic right?",
                    "label": 0
                },
                {
                    "sent": "So there has to be absolutely no cycles at all.",
                    "label": 0
                },
                {
                    "sent": "Which have probability.",
                    "label": 0
                },
                {
                    "sent": "One of the process remaining and.",
                    "label": 0
                },
                {
                    "sent": "No.",
                    "label": 0
                },
                {
                    "sent": "The mean?",
                    "label": 0
                },
                {
                    "sent": "Subject of study in Markov chain theory is defining the conditions for which an invariant distribution exists, and then verifying what those are.",
                    "label": 0
                },
                {
                    "sent": "And I've given some of them here.",
                    "label": 0
                },
                {
                    "sent": "No one sufficient condition.",
                    "label": 0
                },
                {
                    "sent": "That is required, is it the chain?",
                    "label": 0
                },
                {
                    "sent": "Has to be what's called reversible.",
                    "label": 0
                },
                {
                    "sent": "For the physicists amongst you, you'll understand this as satisfying what's called detailed balance.",
                    "label": 0
                },
                {
                    "sent": "So in other words.",
                    "label": 0
                },
                {
                    "sent": "The unconditional probability of taking on values Theta at minus one followed by making the transition to I3 to I right given Sita I -- 1.",
                    "label": 0
                },
                {
                    "sent": "Has got to be equal to the inverse probability starting at C to I and then making the transition backwards to see to the value of Theta I -- 1 and that has to hold for all values of Theta, so that's the detailed bounce condition.",
                    "label": 0
                },
                {
                    "sent": "So this is a very important condition why?",
                    "label": 0
                },
                {
                    "sent": "Well?",
                    "label": 0
                },
                {
                    "sent": "Because it's sufficient that if the transition operator satisfies this reverse ability?",
                    "label": 0
                },
                {
                    "sent": "Satisfies detailed balance, then an invariant distribution exists, and it.",
                    "label": 0
                },
                {
                    "sent": "Let's just remember that what we're trying to do is we're trying to devise a Markov process whose invariant distribution will be the posterior that we are interested in drawing samples from.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "Just to show that this actually indeed.",
                    "label": 0
                },
                {
                    "sent": "Retains the invariant distribution if we just sum over all values of Theta at I -- 1.",
                    "label": 0
                },
                {
                    "sent": "Then we see.",
                    "label": 0
                },
                {
                    "sent": "The condition here holds, so this invariant distribution.",
                    "label": 0
                },
                {
                    "sent": "So this is just like the Chapman Kolmogorov equations.",
                    "label": 0
                },
                {
                    "sent": "OK, so detailed detailed balance to exist.",
                    "label": 0
                },
                {
                    "sent": "Then there will be an invariant distribution that satisfies these equations here.",
                    "label": 0
                },
                {
                    "sent": "So as I said, Markov chain theory, we would consider what are the conditions for the existence of an invariant distribution given a transition operator.",
                    "label": 0
                },
                {
                    "sent": "But we're actually interested in the opposite thing.",
                    "label": 0
                },
                {
                    "sent": "We know what the invariant distribution is.",
                    "label": 0
                },
                {
                    "sent": "We know their invariant distribution that we want.",
                    "label": 0
                },
                {
                    "sent": "So how do we then obtain a transition operator that guarantees that the invariant distribution of the chain is the posterior of interest?",
                    "label": 1
                },
                {
                    "sent": "And that's why.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I'm going to come to know.",
                    "label": 0
                },
                {
                    "sent": "No, in most machine learning lectures of texts that I've read, the Metropolis Hastings algorithm is presented as the Metropolis Hastings algorithm.",
                    "label": 0
                },
                {
                    "sent": "But what I'm going to do today, as I'm going to go through.",
                    "label": 0
                },
                {
                    "sent": "A derivation and proof of the methods so that you really understand what's going on so that those of you who want to study this area further you at least understand what this thing, what the constraints are, and for those of you that really don't want to study this.",
                    "label": 0
                },
                {
                    "sent": "This either any further, well you'll be better educated than you will by the time before you came to La Palma, so the Metropolis Hastings algorithm.",
                    "label": 0
                },
                {
                    "sent": "Well, here's a picture of Nick Metropolis, who, along with Hastings, not Hastings, Taylor and some others, man and wife.",
                    "label": 0
                },
                {
                    "sent": "Piering published the paper in 53.",
                    "label": 0
                },
                {
                    "sent": "On how to simulate.",
                    "label": 0
                },
                {
                    "sent": "States of a particular physical system.",
                    "label": 0
                },
                {
                    "sent": "Using what I'm about to describe to you, so that's Nick Metropolis from the Metropolis haste.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Algorithm and this is Hastings.",
                    "label": 0
                },
                {
                    "sent": "This is the picture of Hastings that you'll find on the web if you look for him.",
                    "label": 0
                },
                {
                    "sent": "And why is that?",
                    "label": 0
                },
                {
                    "sent": "Well put Hastings in 1970 published the paper in Biometrika.",
                    "label": 0
                },
                {
                    "sent": "Which generalized?",
                    "label": 0
                },
                {
                    "sent": "The metropolis algorithm, and I think the number of citations to that paper is probably more than enough to make Bernard jealous in terms of the number of citations that that.",
                    "label": 0
                },
                {
                    "sent": "Doctor Hastings obtained.",
                    "label": 0
                },
                {
                    "sent": "And yet Despite that he was an associate professor of statistics at the University of Toronto.",
                    "label": 0
                },
                {
                    "sent": "They never gave him tenure.",
                    "label": 0
                },
                {
                    "sent": "So put on Hastings, never quite managed to get his photograph on to Google at all.",
                    "label": 0
                },
                {
                    "sent": "But nevertheless.",
                    "label": 0
                },
                {
                    "sent": "He made quite a huge contribution to the whole area.",
                    "label": 0
                },
                {
                    "sent": "Right now I'm going to switch.",
                    "label": 0
                },
                {
                    "sent": "To the continuous domain.",
                    "label": 0
                },
                {
                    "sent": "OK, so all of the arguments hold for the discrete domain, but the continuous domain is more.",
                    "label": 1
                },
                {
                    "sent": "Is more general because I'm going to have to.",
                    "label": 0
                },
                {
                    "sent": "Well, 'cause I'm going to be dealing with densities and measures and so forth.",
                    "label": 0
                },
                {
                    "sent": "So what I'm seeing here is then that the condition that we saw previously is that this Pi star of some element DY which is just equal to a density.",
                    "label": 0
                },
                {
                    "sent": "Value of Y multiplied by whatever the measure is going to be, so you can just think of this as the distribution, right?",
                    "label": 0
                },
                {
                    "sent": "Which of course is.",
                    "label": 0
                },
                {
                    "sent": "This is not our transition operator, right?",
                    "label": 0
                },
                {
                    "sent": "So it's the probability of moving from a value of X.",
                    "label": 0
                },
                {
                    "sent": "Time T. To a value in DY Time T + 1.",
                    "label": 0
                },
                {
                    "sent": "And this is the unconditional distribution under the invariant distribution Pi of X. OK, so as in the discrete case, at the NTH iteration then the transition kernel transition operator is just going to be this linear operation on the.",
                    "label": 1
                },
                {
                    "sent": "Transition candle at N -- 1 on the.",
                    "label": 1
                },
                {
                    "sent": "Transition kernel itself.",
                    "label": 0
                },
                {
                    "sent": "So what we have to do, just remember is that we have to define a transition kernel.",
                    "label": 0
                },
                {
                    "sent": "P of XDY So there is got this posterior distribution as its invariant density.",
                    "label": 0
                },
                {
                    "sent": "So how are we going to do that?",
                    "label": 0
                },
                {
                    "sent": "Well, let's just consider a function.",
                    "label": 0
                },
                {
                    "sent": "This is not a density, it's not a distribution, just a function.",
                    "label": 1
                },
                {
                    "sent": "So function of.",
                    "label": 0
                },
                {
                    "sent": "X&Y.",
                    "label": 0
                },
                {
                    "sent": "And let's define a transition operator based on this as follows.",
                    "label": 0
                },
                {
                    "sent": "We'll say that the transition kernel.",
                    "label": 0
                },
                {
                    "sent": "P of XY is going to be equal to the sum of this function.",
                    "label": 0
                },
                {
                    "sent": "Times some.",
                    "label": 0
                },
                {
                    "sent": "Volume element DY.",
                    "label": 0
                },
                {
                    "sent": "So just say this is the measure.",
                    "label": 0
                },
                {
                    "sent": "And then some function out of X and then this Delta function here, which will take on the value of 1.",
                    "label": 0
                },
                {
                    "sent": "If the value of X is within this element here.",
                    "label": 0
                },
                {
                    "sent": "Note the only condition that we have is that the integral of P with respect to DX will equal 1, because it's a.",
                    "label": 0
                },
                {
                    "sent": "It's a valid transition operator for a Markov process.",
                    "label": 0
                },
                {
                    "sent": "And we will also just make the assumption will just enforce that P of X&X is equal to 0.",
                    "label": 0
                },
                {
                    "sent": "This condition holds as I just mentioned to you.",
                    "label": 0
                },
                {
                    "sent": "Then what this says is that this function here are of X.",
                    "label": 0
                },
                {
                    "sent": "Well, if we integrate with respect to DX over the complete domain, so this is 1, right?",
                    "label": 0
                },
                {
                    "sent": "Well, this is the integral and then this here is just going to be the integral.",
                    "label": 0
                },
                {
                    "sent": "Well, so this is just going to be one.",
                    "label": 0
                },
                {
                    "sent": "So this just comes out is out of X and so we define out of X is 1 minus the integral of this function.",
                    "label": 0
                },
                {
                    "sent": "Whatever this function happens to be.",
                    "label": 0
                },
                {
                    "sent": "And it turns out to be the probability.",
                    "label": 0
                },
                {
                    "sent": "That the chain will remain.",
                    "label": 0
                },
                {
                    "sent": "At the current value of the random variables that define the chain.",
                    "label": 0
                },
                {
                    "sent": "No.",
                    "label": 0
                },
                {
                    "sent": "If this function P of X&Y satisfies the reverse ability condition, so, just remember the reversibility condition, we write it here.",
                    "label": 0
                },
                {
                    "sent": "OK, so P of XY.",
                    "label": 0
                },
                {
                    "sent": "Times \u03c0 of X must be equal to the reverse operation, so PY to X Pi of Y.",
                    "label": 0
                },
                {
                    "sent": "Now, if this satisfies reverse ability, then we can go home.",
                    "label": 0
                },
                {
                    "sent": "Well, we can't go for dinner yet.",
                    "label": 0
                },
                {
                    "sent": "'cause this won't satisfy reversibility in the most general sense.",
                    "label": 0
                },
                {
                    "sent": "But if it does, then we know that Pi is going to be the invariant density of this transition kernel.",
                    "label": 0
                },
                {
                    "sent": "Well, this is great, so we've reversed the whole process.",
                    "label": 0
                },
                {
                    "sent": "We've no but the bare bones of a transition care, nor which is going to give us the invariant distribution that we are looking for.",
                    "label": 0
                },
                {
                    "sent": "An.",
                    "label": 0
                },
                {
                    "sent": "For one thing, we need to do is, we just need to convince ourselves that this.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is the case, and so I'm just going to go through a very simple derivation.",
                    "label": 0
                },
                {
                    "sent": "So the first thing that we do.",
                    "label": 0
                },
                {
                    "sent": "Is that we take?",
                    "label": 0
                },
                {
                    "sent": "This transition operator and we apply the Pi of X to it and then integrate OK. Over the whole domain.",
                    "label": 0
                },
                {
                    "sent": "So if we just plug in Pi of X under integral.",
                    "label": 0
                },
                {
                    "sent": "Over D of X into the expression on the right hand side.",
                    "label": 0
                },
                {
                    "sent": "Then we get this here.",
                    "label": 0
                },
                {
                    "sent": "Now what I've got here.",
                    "label": 0
                },
                {
                    "sent": "Alright is an expression which is defining this region a OK, so I'm integrating the random variable Y over this particular region A.",
                    "label": 0
                },
                {
                    "sent": "We have the.",
                    "label": 0
                },
                {
                    "sent": "\u03a0 of X integrated with respect to D of X and then we have the same deal here.",
                    "label": 0
                },
                {
                    "sent": "So if we just.",
                    "label": 0
                },
                {
                    "sent": "Shuffle things about here.",
                    "label": 0
                },
                {
                    "sent": "To make things a bit tidier and we just notice that for X.",
                    "label": 0
                },
                {
                    "sent": "So this Delta function in essence restricts the domain of integration here to the region A.",
                    "label": 0
                },
                {
                    "sent": "So not so fine.",
                    "label": 0
                },
                {
                    "sent": "As I said, all that we've done here is, we've just shuffled things about.",
                    "label": 0
                },
                {
                    "sent": "We've done nothing else.",
                    "label": 0
                },
                {
                    "sent": "No.",
                    "label": 0
                },
                {
                    "sent": "If this is reversible.",
                    "label": 0
                },
                {
                    "sent": "Then we can see that P of XY Pi of X DX is equal to.",
                    "label": 0
                },
                {
                    "sent": "\u03a0 of yx Pi P. Of YX Pi of YDX.",
                    "label": 0
                },
                {
                    "sent": "OK. Everyone happy with that, so I'm assuming.",
                    "label": 0
                },
                {
                    "sent": "But if this is reversible, then I can replace this expression with this here.",
                    "label": 0
                },
                {
                    "sent": "I can work this out and it turns out of course that this is just going to be 1 minus the probability that this is going to be the probability of just remaining at the value Y.",
                    "label": 0
                },
                {
                    "sent": "And then of course we're going to integrate over a with respect to Pi ydy.",
                    "label": 0
                },
                {
                    "sent": "This hasn't changed the tool and you can see straight away what's going to happen is that these terms are going to cancel out and we're just going to be left with the integral of Pi of ydy with respect to a, which of course is the distribution that we're interested in.",
                    "label": 0
                },
                {
                    "sent": "So the fact that we've used the transition care.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Final.",
                    "label": 0
                },
                {
                    "sent": "Of this form here.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And becausw reverse ability or detailed bounds is a sufficient condition for an invariant distribution to exist for this particular transition operator.",
                    "label": 1
                },
                {
                    "sent": "By exploiting the detail bounds condition.",
                    "label": 0
                },
                {
                    "sent": "Here we've been able to convince ourselves that this transition operator indeed will deliver the invariant distribution of interest, so the reverse ability condition for this function PXY is enough.",
                    "label": 0
                },
                {
                    "sent": "It's sufficient in designing our transition operator.",
                    "label": 1
                },
                {
                    "sent": "That's great.",
                    "label": 0
                },
                {
                    "sent": "OK, what's next?",
                    "label": 0
                },
                {
                    "sent": "Well, what in fact is the form of Piave?",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "XY.",
                    "label": 0
                },
                {
                    "sent": "Alright, so.",
                    "label": 0
                },
                {
                    "sent": "We've got our transition Care now we need to start to put some meat over these bones.",
                    "label": 0
                },
                {
                    "sent": "I OK let's.",
                    "label": 0
                },
                {
                    "sent": "Let's pluck from the ear.",
                    "label": 0
                },
                {
                    "sent": "A density associated with some distribution from which we can reasonably simulate samples, and we call this the proposal density.",
                    "label": 0
                },
                {
                    "sent": "So this is a density that would be amenable to.",
                    "label": 0
                },
                {
                    "sent": "As I said, simulating random variables from in an easy manner.",
                    "label": 0
                },
                {
                    "sent": "A normal distribution, a uniform distribution, whatever, some arbitrary distribution.",
                    "label": 0
                },
                {
                    "sent": "And we'll call it Q of XY, right?",
                    "label": 0
                },
                {
                    "sent": "So the probability that given particular values X, we will then generate values Y.",
                    "label": 0
                },
                {
                    "sent": "So of course this is a density, so it satisfies all the usual criteria if it satisfies.",
                    "label": 0
                },
                {
                    "sent": "If Q of XY is reversible jobs done.",
                    "label": 0
                },
                {
                    "sent": "The thing is, it may not be reversible.",
                    "label": 0
                },
                {
                    "sent": "And it may not be reversible for a number of well, for two reasons.",
                    "label": 0
                },
                {
                    "sent": "In particular, one is the following.",
                    "label": 0
                },
                {
                    "sent": "It may be that the detailed bounce condition.",
                    "label": 0
                },
                {
                    "sent": "It reduces to.",
                    "label": 0
                },
                {
                    "sent": "And inequality.",
                    "label": 0
                },
                {
                    "sent": "So for example here, instead of having an equality, we might have the fact that.",
                    "label": 0
                },
                {
                    "sent": "Q of XY times \u03c0 of X is always greater than the reverse.",
                    "label": 0
                },
                {
                    "sent": "So in other words, the number of transitions from X to Y course 2 often.",
                    "label": 1
                },
                {
                    "sent": "Right to ensure that the balance condition.",
                    "label": 0
                },
                {
                    "sent": "Well, we can.",
                    "label": 0
                },
                {
                    "sent": "We can sort that out by re balancing both sides, right?",
                    "label": 0
                },
                {
                    "sent": "So we could introduce another probability or call it Alpha, which again will be a function of X&Y and we can define that in some way to ensure that this inequality will always go back to an equality.",
                    "label": 0
                },
                {
                    "sent": "So in this case here, for example, we would 1A X of Y to be smaller than one in some way because we want to reduce this value to to be in line with the right hand side.",
                    "label": 0
                },
                {
                    "sent": "So we can establish reverse ability by defining.",
                    "label": 0
                },
                {
                    "sent": "I.",
                    "label": 0
                },
                {
                    "sent": "By augmenting this with Alpha XY, so we know how Pi of X.",
                    "label": 0
                },
                {
                    "sent": "The value of our proposal distribution and then the value of this acceptance probability, and then likewise on the reverse side, will have this value of the acceptance probability.",
                    "label": 1
                },
                {
                    "sent": "But in the reverse direction.",
                    "label": 0
                },
                {
                    "sent": "Well, that's great so.",
                    "label": 0
                },
                {
                    "sent": "By definition, we've enforced reverse ability, but we know we need to.",
                    "label": 0
                },
                {
                    "sent": "Define what what sort of functional form this Alpha X of Y is going to be.",
                    "label": 0
                },
                {
                    "sent": "Well, it's a distribution, so the maximum value is going to be set to 1.",
                    "label": 0
                },
                {
                    "sent": "So in that case, then we'll set to for this condition.",
                    "label": 0
                },
                {
                    "sent": "Here we'll set this to one.",
                    "label": 0
                },
                {
                    "sent": "K. So our balance condition looks like this.",
                    "label": 0
                },
                {
                    "sent": "And then some primary school algebra just tells us that the acceptance probability.",
                    "label": 1
                },
                {
                    "sent": "Has to take the form of.",
                    "label": 0
                },
                {
                    "sent": "The probability under.",
                    "label": 0
                },
                {
                    "sent": "The desired distribution of Y multiplied by the proposal distribution in the reverse direction, and that's divided by.",
                    "label": 0
                },
                {
                    "sent": "The density at X on the desired distribution and then the forward proposal distribution.",
                    "label": 0
                },
                {
                    "sent": "So in other words, OK, right?",
                    "label": 0
                },
                {
                    "sent": "So I've made the argument for when the left hand side is larger than the right hand side.",
                    "label": 0
                },
                {
                    "sent": "I'll leave it to use a homework exercise to figure out what I don't even do it for homework because it's trivial.",
                    "label": 0
                },
                {
                    "sent": "It's it's just that.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Yes, and it all works out the same.",
                    "label": 0
                },
                {
                    "sent": "So what this means is that, again, if I just remember.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Just remind you the P function here, which I said it wasn't.",
                    "label": 0
                },
                {
                    "sent": "A density is just some arbitrary function.",
                    "label": 0
                },
                {
                    "sent": "There's no looking like this here.",
                    "label": 0
                },
                {
                    "sent": "Where is it?",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Yeah, so the P function associated with the Metropolis Hastings algorithm.",
                    "label": 0
                },
                {
                    "sent": "Is just going to be equal to the product of the proposal?",
                    "label": 1
                },
                {
                    "sent": "On the acceptance probability.",
                    "label": 0
                },
                {
                    "sent": "For all values of X&Y not being equal?",
                    "label": 0
                },
                {
                    "sent": "On the acceptance, probability is just going to be equal to the minimum of its maximum value, which was which was in the case that I showed you there one or.",
                    "label": 1
                },
                {
                    "sent": "The ratio that popped out when we enforced the reversibility condition.",
                    "label": 0
                },
                {
                    "sent": "So we're almost there.",
                    "label": 1
                },
                {
                    "sent": "So the overall transition kernel.",
                    "label": 1
                },
                {
                    "sent": "That we come up with turns out to be, well, our P function is just proposal times acceptance plus the probability of staying in a particular position and then.",
                    "label": 0
                },
                {
                    "sent": "Just defined by the Delta function this.",
                    "label": 0
                },
                {
                    "sent": "By the way, that we have defined it and we have developed.",
                    "label": 1
                },
                {
                    "sent": "It is reversible and therefore Pi of X will be its invariant density.",
                    "label": 0
                },
                {
                    "sent": "So the Metropolis Hastings algorithm.",
                    "label": 0
                },
                {
                    "sent": "I mean all it really is, the algorithm is just a way of representing the transition operator.",
                    "label": 0
                },
                {
                    "sent": "Think by this proposal distribution and that requires to be chosen.",
                    "label": 0
                },
                {
                    "sent": "Everything else is defined for us.",
                    "label": 0
                },
                {
                    "sent": "\u03a0 is what we want.",
                    "label": 0
                },
                {
                    "sent": "Q is something that we have to select.",
                    "label": 0
                },
                {
                    "sent": "OK, so this acceptance probability.",
                    "label": 0
                },
                {
                    "sent": "This ratio here.",
                    "label": 0
                },
                {
                    "sent": "So for any density.",
                    "label": 0
                },
                {
                    "sent": "Which we can write as the Unnormalized forum divided by its normalizing constant.",
                    "label": 0
                },
                {
                    "sent": "OK, then just boils down to this here.",
                    "label": 0
                },
                {
                    "sent": "So the troublesome normalizing constant, which beleaguered.",
                    "label": 0
                },
                {
                    "sent": "Bayesian star closet Bayesian statisticians.",
                    "label": 0
                },
                {
                    "sent": "In the Fifties, 60s and 70s has no disappeared, so we no longer have to concern ourselves with trying to.",
                    "label": 0
                },
                {
                    "sent": "To be able to analytically obtain the normalizing constant or the evidence of the marginal likelihood or the physicists call it.",
                    "label": 0
                },
                {
                    "sent": "The partition function it's not needed.",
                    "label": 0
                },
                {
                    "sent": "In this case here.",
                    "label": 0
                },
                {
                    "sent": "So this is absolutely great, right?",
                    "label": 0
                },
                {
                    "sent": "Pretty pretty awesome.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But we can even go further.",
                    "label": 0
                },
                {
                    "sent": "So if the proposal distribution is actually symmetric, the symmetry doesn't mean reverse ability, but it's symmetric in its arguments.",
                    "label": 0
                },
                {
                    "sent": "So if we take a normal distribution right for X with a mean of Y in some covariance structure, then of course the symmetry, right?",
                    "label": 0
                },
                {
                    "sent": "So they're both the same.",
                    "label": 0
                },
                {
                    "sent": "Well, it turns out that.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And that the normal these two proposals.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We're going to cancel out, and the acceptance probability is just going to be the ratio of the unnormalized densities.",
                    "label": 1
                },
                {
                    "sent": "That's nice.",
                    "label": 0
                },
                {
                    "sent": "Now what does this mean?",
                    "label": 0
                },
                {
                    "sent": "Well, it suggests for one thing that if your proposal mechanism right takes.",
                    "label": 0
                },
                {
                    "sent": "The chain.",
                    "label": 0
                },
                {
                    "sent": "Into a region where the density is higher.",
                    "label": 0
                },
                {
                    "sent": "Then that move is always going to be accepted, because this is always going to be greater than one.",
                    "label": 0
                },
                {
                    "sent": "So what this means is that the Metropolis Hastings algorithm is reacting to the local density structure.",
                    "label": 0
                },
                {
                    "sent": "Right, so if it moves into a region of higher density.",
                    "label": 1
                },
                {
                    "sent": "It's going to be accepted, so there's always going to be a force pushing the chain into regions of high density.",
                    "label": 0
                },
                {
                    "sent": "However, moves into regions of lower density are going to be accepted, not with probability 0, but with some probability.",
                    "label": 1
                },
                {
                    "sent": "Whatever that ratio happens to be.",
                    "label": 0
                },
                {
                    "sent": "And that means then that we get process which will.",
                    "label": 0
                },
                {
                    "sent": "Explore the support of the distribution right at the frequency that is required to ensure appropriate coverage of the invariant distribution.",
                    "label": 0
                },
                {
                    "sent": "So this looks great.",
                    "label": 0
                },
                {
                    "sent": "So typically what would normally take 30 seconds in a standard machine learning.",
                    "label": 0
                },
                {
                    "sent": "Lecture would be this here, so this is the Metropolis Hastings algorithm.",
                    "label": 0
                },
                {
                    "sent": "As you recorded up.",
                    "label": 0
                },
                {
                    "sent": "Right, so you just simulate from your proposal distribution.",
                    "label": 0
                },
                {
                    "sent": "Then you draw a uniform number between zero and one just so that you can accept or reject with probability Alpha, and then you just set the value of the chain to whatever you've drawn from your proposal distribution.",
                    "label": 0
                },
                {
                    "sent": "I.",
                    "label": 0
                },
                {
                    "sent": "If the acceptance probability dictates or otherwise, we stay in the same position and we just keep doing that, so hopefully.",
                    "label": 0
                },
                {
                    "sent": "I guess most of you have probably quoted the Metroplus algorithm, but I hope that you've got a better fuel for the sort of mechanisms underlying.",
                    "label": 0
                },
                {
                    "sent": "This very very general MCMC method, because now that you've got a feel for that, looking at more complex and more interesting methods like reversible jump MCMC or some of the more esoteric things which I'm going to come onto is all going to be based on an understanding of the underlying principles of a periodicity.",
                    "label": 0
                },
                {
                    "sent": "Of.",
                    "label": 0
                },
                {
                    "sent": "Of invariants of the measure of reversibility.",
                    "label": 0
                },
                {
                    "sent": "In detail bounds and why these have to be satisfied.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK yeah this is some R code for those of the R aficionados here.",
                    "label": 0
                },
                {
                    "sent": "This is the.",
                    "label": 0
                },
                {
                    "sent": "Metropolis Hastings algorithm in R, where the target density is just the standardized normal and the proposal distribution is just a uniform distribution between plus and minus some value, whatever.",
                    "label": 1
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So that's it.",
                    "label": 0
                },
                {
                    "sent": "That's the metropolis Hastings algorithm, and it's the basis pretty much on which all MCMC and all the cutting edge MCMC methodology that's being developed these days is based on this here.",
                    "label": 0
                },
                {
                    "sent": "So you can Bluff your way through any party full of computational statisticians and so forth.",
                    "label": 0
                },
                {
                    "sent": "Now you can understand what reverse ability and so forth and why it's so important.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, any questions?",
                    "label": 0
                },
                {
                    "sent": "Looks like you've been right.",
                    "label": 0
                },
                {
                    "sent": "This is this is discreet.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "So this is a discrete Markov process rather than a continuous one.",
                    "label": 0
                },
                {
                    "sent": "Yeah, and I'm not going to be talking about continuous.",
                    "label": 0
                },
                {
                    "sent": "Process is.",
                    "label": 0
                },
                {
                    "sent": "Actually, I am I tell a lie, I am.",
                    "label": 0
                },
                {
                    "sent": "But as an application.",
                    "label": 0
                },
                {
                    "sent": "The samples produced by this algorithm are going to be IE no.",
                    "label": 0
                },
                {
                    "sent": "Very good, so remember that for the Monte Carlo estimate.",
                    "label": 0
                },
                {
                    "sent": "And for the CLT, right?",
                    "label": 0
                },
                {
                    "sent": "So for the expression for the Monte Carlo error, so the variance of the estimate to hold?",
                    "label": 0
                },
                {
                    "sent": "Then the samples have to be IID.",
                    "label": 0
                },
                {
                    "sent": "No, we've devised a Markov chain.",
                    "label": 0
                },
                {
                    "sent": "With first order dependence, so the.",
                    "label": 0
                },
                {
                    "sent": "Samples are going to be.",
                    "label": 0
                },
                {
                    "sent": "Going to have first order correlation.",
                    "label": 0
                },
                {
                    "sent": "So what that means then is that the Monte Carlo error of the variance of the estimate is going to inflate, and it's going to inflate by a factor based on the covariance of the samples that come off this process.",
                    "label": 0
                },
                {
                    "sent": "Now there's a lot of work and some of the work that I'm going to talk about.",
                    "label": 0
                },
                {
                    "sent": "In later lectures is being done on how to, in essence, have almost effectively independent samples from the Markov chain, so these will be identically distributed, but they won't be independent, they will be correlated.",
                    "label": 0
                },
                {
                    "sent": "And if you're and what you find is that for really interesting problems, that level of correlation.",
                    "label": 0
                },
                {
                    "sent": "Can be really high, so although we've cracked the problem of being able to sample from the posterior distribution.",
                    "label": 0
                },
                {
                    "sent": "The efficiency of the estimates that we obtain from those samples is governed largely by how independent we can drive the samples from which we, you know.",
                    "label": 0
                },
                {
                    "sent": "We draw the samples from the chain, and I'm going to talk about these issues as we go along.",
                    "label": 0
                },
                {
                    "sent": "OK then what time do we knock off?",
                    "label": 0
                },
                {
                    "sent": "Oh great, good good good.",
                    "label": 0
                },
                {
                    "sent": "Can I finish?",
                    "label": 0
                },
                {
                    "sent": "I've got 2 little things here and then we'll stop for a little break, yeah.",
                    "label": 0
                },
                {
                    "sent": "Is that OK?",
                    "label": 0
                },
                {
                    "sent": "It's not OK, but you're going to.",
                    "label": 0
                },
                {
                    "sent": "You're going to love with it.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "So we've defined the kernel, a kernel that we know will satisfy reverse ability and will give us our invariant distribution.",
                    "label": 0
                },
                {
                    "sent": "But with that we can do some other things.",
                    "label": 0
                },
                {
                    "sent": "We can, for example, we can design other kernels by taking products or mixtures of them.",
                    "label": 0
                },
                {
                    "sent": "So I'm going to look at a product care no.",
                    "label": 0
                },
                {
                    "sent": "The reason for this is are the motivation for something like this is as follows.",
                    "label": 0
                },
                {
                    "sent": "Let's assume that we're trying to sample.",
                    "label": 0
                },
                {
                    "sent": "From a distribution which is random, variables have quite a high dimensionality.",
                    "label": 0
                },
                {
                    "sent": "Then what you probably find in what you do find is that the probability of acceptance is going to be very low unless you are very clever in the way that you devise your proposal distribution.",
                    "label": 0
                },
                {
                    "sent": "And as I said, I'm going to talk a lot about that in the coming lectures.",
                    "label": 0
                },
                {
                    "sent": "So if the target density is high dimensional multivariate, one thing that we could do is we could break up.",
                    "label": 1
                },
                {
                    "sent": "These vectors into little sub blocks and then we could try and run proposals unchains on these sub blocks right?",
                    "label": 0
                },
                {
                    "sent": "So this might be our kind of reasonable way of designing proposals that would allow us to have a reasonable level of acceptance probability.",
                    "label": 0
                },
                {
                    "sent": "But of course the question is, well, I mean reduce doing something like this, ensure convergence to the correct target.",
                    "label": 1
                },
                {
                    "sent": "So let's take a. OK, let's see.",
                    "label": 0
                },
                {
                    "sent": "The X is a vector know in a 2 dimensional space.",
                    "label": 0
                },
                {
                    "sent": "So X1 and X2 of the other components.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 1
                },
                {
                    "sent": "We're going to see that we've got a conditional transition kernel P1, which moves.",
                    "label": 0
                },
                {
                    "sent": "X1.",
                    "label": 0
                },
                {
                    "sent": "OK, so the X1 component into D1 conditional on.",
                    "label": 1
                },
                {
                    "sent": "X2 taking a particular value right and this transition Karen was going to have an invariant density which is going to be the conditional of X1.",
                    "label": 1
                },
                {
                    "sent": "Given a particular fixed value of X2 and likewise we have a transition care no P2.",
                    "label": 0
                },
                {
                    "sent": "Which does the same operation on the second component of the.",
                    "label": 0
                },
                {
                    "sent": "Of the vector and it will have its own invariant density Pi 2 given one.",
                    "label": 1
                },
                {
                    "sent": "Given a fixed value for X1.",
                    "label": 0
                },
                {
                    "sent": "And of course, the standard conditions apply.",
                    "label": 0
                },
                {
                    "sent": "In terms of invariants.",
                    "label": 0
                },
                {
                    "sent": "And what I'm stating is that the product of these two kernels.",
                    "label": 0
                },
                {
                    "sent": "Has an invariant density.",
                    "label": 0
                },
                {
                    "sent": "Which is the joint density that we are interested in?",
                    "label": 0
                },
                {
                    "sent": "Right now.",
                    "label": 0
                },
                {
                    "sent": "I've taken it to the simplest case where this is a 2 dimensional vector.",
                    "label": 0
                },
                {
                    "sent": "Right on each of these is just a univariate thing, but these could actually be blocks of different dimension, so this would all still hold.",
                    "label": 0
                },
                {
                    "sent": "OK could you could someone volunteer to prove this?",
                    "label": 0
                },
                {
                    "sent": "Why you bought here.",
                    "label": 0
                },
                {
                    "sent": "Let's see your hand up.",
                    "label": 0
                },
                {
                    "sent": "He's pretending it didn't seem.",
                    "label": 0
                },
                {
                    "sent": "OK, it's actually fairly straightforward and the mechanics are very similar to what we did for the.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The simple case, but let's just go through it.",
                    "label": 0
                },
                {
                    "sent": "So first of all, the product kernel.",
                    "label": 0
                },
                {
                    "sent": "So here's arcano.",
                    "label": 0
                },
                {
                    "sent": "And here's the invariant distribution.",
                    "label": 0
                },
                {
                    "sent": "K so we can just do a bit of jiggling about the key thing here is that we will split.",
                    "label": 0
                },
                {
                    "sent": "This density into its conditional and its unconditional component.",
                    "label": 0
                },
                {
                    "sent": "And what we will then find?",
                    "label": 0
                },
                {
                    "sent": "Is that this here by definition, is just going to be the conditional invariant for the transition kernel Pi one.",
                    "label": 0
                },
                {
                    "sent": "Now what we'll do is we'll.",
                    "label": 0
                },
                {
                    "sent": "Will rewrite this using Bayes rule so that this is \u03c0 of two given one.",
                    "label": 0
                },
                {
                    "sent": "Right, so I've just.",
                    "label": 0
                },
                {
                    "sent": "I've just rewritten this Miss form here.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "This of course comes out of the brackets these Council.",
                    "label": 0
                },
                {
                    "sent": "This of course.",
                    "label": 0
                },
                {
                    "sent": "The central, of course, then gives us the conditional distribution.",
                    "label": 0
                },
                {
                    "sent": "We are interested in and this product form.",
                    "label": 0
                },
                {
                    "sent": "Ensures that the.",
                    "label": 0
                },
                {
                    "sent": "The joint distribution comes out from the application of this product of transition kernels.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So it's all good.",
                    "label": 0
                },
                {
                    "sent": "I mean, if you've heard of the Gibbs sampler.",
                    "label": 0
                },
                {
                    "sent": "Well, not as many as I thought.",
                    "label": 0
                },
                {
                    "sent": "Well, the Gibbs sampler is nothing but.",
                    "label": 0
                },
                {
                    "sent": "A spatial instance of the.",
                    "label": 0
                },
                {
                    "sent": "Metropolis Hastings algorithm.",
                    "label": 0
                },
                {
                    "sent": "Because what we're going to do is we're going to say that we're going to set.",
                    "label": 0
                },
                {
                    "sent": "The transition kernels.",
                    "label": 0
                },
                {
                    "sent": "To be equal to the conditional distributions.",
                    "label": 0
                },
                {
                    "sent": "Right, so the exact conditional distributions that we are of the joint distribution that we are interested in.",
                    "label": 0
                },
                {
                    "sent": "So if we devise our acceptance probability and we plug these in, then again some primary school algebra takes us to the fact that these all cancel out and we end up with an acceptance probability of 1.",
                    "label": 0
                },
                {
                    "sent": "So in other words, if we can obtain the exact conditional distributions.",
                    "label": 0
                },
                {
                    "sent": "And simulate from those.",
                    "label": 0
                },
                {
                    "sent": "Right, we accept every draw.",
                    "label": 0
                },
                {
                    "sent": "With probability one and we know that by simulating repeatedly from these exact conditionals, then this will have this Markov chain will have an invariant distribution.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Which is the joint?",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And that we interested in so the Gibbs sampler, you know, as I said, is just.",
                    "label": 0
                },
                {
                    "sent": "Is just another choice of the whatever the transition kernel is for the Metropolis Hastings algorithm.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So I'll close on this.",
                    "label": 0
                },
                {
                    "sent": "Not close, I will break for this point here.",
                    "label": 0
                },
                {
                    "sent": "Let's take a bivariate Gaussian as an example, so we're going to see that our target distribution is a Gaussian.",
                    "label": 0
                },
                {
                    "sent": "Which is a mean of 0.",
                    "label": 0
                },
                {
                    "sent": "And has a covariance structure such that the variance is 1.",
                    "label": 0
                },
                {
                    "sent": "And the.",
                    "label": 0
                },
                {
                    "sent": "Covariance structure is governed by this coefficient rho here.",
                    "label": 0
                },
                {
                    "sent": "K. Now for the Metropolis Hastings algorithm, let's define a proposal mechanism.",
                    "label": 0
                },
                {
                    "sent": "Which is a normal.",
                    "label": 0
                },
                {
                    "sent": "And I guess the only thing that we can.",
                    "label": 0
                },
                {
                    "sent": "We can do here as we can see well, the covariance structure of our proposal mechanism is going to have some parameter with parameter Sigma.",
                    "label": 0
                },
                {
                    "sent": "OK so if I workout my acceptance probability for this target density then it again it just turns out to be the ratio of the unnormalized.",
                    "label": 0
                },
                {
                    "sent": "Densities of the target distribution, which is just going to be exponential at the proposal value over the exponential of this quadratic form at the current value.",
                    "label": 0
                },
                {
                    "sent": "No.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "Can I mean, given what we've been talking about?",
                    "label": 0
                },
                {
                    "sent": "Can you see any issues?",
                    "label": 0
                },
                {
                    "sent": "Kind of practical issues that may arise.",
                    "label": 0
                },
                {
                    "sent": "I.",
                    "label": 0
                },
                {
                    "sent": "Given.",
                    "label": 0
                },
                {
                    "sent": "The structure of our target density and the structure of our proposal.",
                    "label": 0
                },
                {
                    "sent": "Density.",
                    "label": 0
                },
                {
                    "sent": "OK, so those are a little bit about sampling can show off and maybe actually save what you think might be an issue here.",
                    "label": 0
                },
                {
                    "sent": "To near dinner so.",
                    "label": 0
                },
                {
                    "sent": "I'll put you out of your misery, so let's assume that rule was very large, something like .99.",
                    "label": 0
                },
                {
                    "sent": "Then we have a distribution that would look something a target distribution that's going to look something like this very long elongated sort of cigar shaped things similar to what new was showing earlier on today.",
                    "label": 0
                },
                {
                    "sent": "So that's our target distribution.",
                    "label": 0
                },
                {
                    "sent": "But our proposal.",
                    "label": 0
                },
                {
                    "sent": "Right is this vertical thing here, right?",
                    "label": 0
                },
                {
                    "sent": "So it's going to have.",
                    "label": 0
                },
                {
                    "sent": "Specticle covariance is radius.",
                    "label": 0
                },
                {
                    "sent": "Is proportional to Sigma.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So you can see that if we make our a bad choice for Sigma.",
                    "label": 0
                },
                {
                    "sent": "So let's say that we make Sigma look something like this here.",
                    "label": 0
                },
                {
                    "sent": "Then what's going to happen well?",
                    "label": 0
                },
                {
                    "sent": "If we are currently at this point, this is no yes.",
                    "label": 0
                },
                {
                    "sent": "Currently at this point here.",
                    "label": 0
                },
                {
                    "sent": "Right, I should actually.",
                    "label": 0
                },
                {
                    "sent": "Sample with replacement.",
                    "label": 0
                },
                {
                    "sent": "Without replacement I should see.",
                    "label": 0
                },
                {
                    "sent": "So let's say that Sigma is.",
                    "label": 0
                },
                {
                    "sent": "You know it's defining some sort of sphere like this, then you know it's very probable that we're going to get proposals.",
                    "label": 0
                },
                {
                    "sent": "In these regions here.",
                    "label": 0
                },
                {
                    "sent": "So what this means is that the probability of acceptance.",
                    "label": 0
                },
                {
                    "sent": "For these samples.",
                    "label": 0
                },
                {
                    "sent": "Is going to be very low.",
                    "label": 0
                },
                {
                    "sent": "Because of this ratio here.",
                    "label": 0
                },
                {
                    "sent": "Here, on the other hand, is probably not going to be too bad, but what this means is that the acceptance probability, so the number of proposals that you have to make before the chain actually moves anywhere is going to be very large, and so it's absolutely clear that this proposal mechanism is going to be really critical, and being able to devise an efficient chain and efficient chain.",
                    "label": 0
                },
                {
                    "sent": "What I mean by efficient, I mean efficient in terms of the computation.",
                    "label": 0
                },
                {
                    "sent": "Because there's going to be a cost associated with.",
                    "label": 0
                },
                {
                    "sent": "Making a proposal and then assessing whether it gets accepted or rejected.",
                    "label": 0
                },
                {
                    "sent": "But Furthermore you are asking the question about the iid nature of the chain.",
                    "label": 0
                },
                {
                    "sent": "Remember that if we make a proposal, so we're here.",
                    "label": 0
                },
                {
                    "sent": "We make a proposal here.",
                    "label": 0
                },
                {
                    "sent": "It gets rejected.",
                    "label": 0
                },
                {
                    "sent": "The chain stays where it is.",
                    "label": 0
                },
                {
                    "sent": "Who make another proposal?",
                    "label": 0
                },
                {
                    "sent": "It gets rejected.",
                    "label": 0
                },
                {
                    "sent": "The chain stays where it is, and So what you end up with is a chain that might be.",
                    "label": 0
                },
                {
                    "sent": "Staying in the same place for long periods of time and what does this do?",
                    "label": 0
                },
                {
                    "sent": "It adds to the correlation structure.",
                    "label": 0
                },
                {
                    "sent": "And therefore it inflates the variance of the.",
                    "label": 0
                },
                {
                    "sent": "Monte Carlo estimates that you're going to be using these samples for, so this in actual fact is a very serious issue.",
                    "label": 0
                },
                {
                    "sent": "And one that we're going to try and address later on.",
                    "label": 0
                },
                {
                    "sent": "So this seems to be quite troublesome.",
                    "label": 0
                },
                {
                    "sent": "We're going to have to tune this thing.",
                    "label": 0
                },
                {
                    "sent": "This is a pain, but our target density is a 2 dimensional Gaussian.",
                    "label": 1
                },
                {
                    "sent": "Well, this is great.",
                    "label": 1
                },
                {
                    "sent": "We can get the exact conditional distributions and have a Gibbs sampler.",
                    "label": 0
                },
                {
                    "sent": "So everything is going to be accepted.",
                    "label": 0
                },
                {
                    "sent": "Alright, everything succeeded with probability one, so the problem solved.",
                    "label": 0
                },
                {
                    "sent": "Well, is it really?",
                    "label": 1
                },
                {
                    "sent": "Let's look at the exact form of the exact conditionals.",
                    "label": 0
                },
                {
                    "sent": "So here we are here.",
                    "label": 0
                },
                {
                    "sent": "So for a current value of X2, then the exact conditional is equal to the coral efficient scales the the current value.",
                    "label": 0
                },
                {
                    "sent": "And then the variance is 1 minus row squared, and that's the same for both of these conditionals.",
                    "label": 0
                },
                {
                    "sent": "But it doesn't matter, we just simulate these.",
                    "label": 0
                },
                {
                    "sent": "We accept all of them.",
                    "label": 0
                },
                {
                    "sent": "Is there a problem here?",
                    "label": 0
                },
                {
                    "sent": "Yeah, what's the problem?",
                    "label": 0
                },
                {
                    "sent": "Close to one will say yeah, exactly so for the example that we've got here rule .99 or whatever.",
                    "label": 0
                },
                {
                    "sent": "Then it means that our little conditionals.",
                    "label": 0
                },
                {
                    "sent": "Write 4X1.",
                    "label": 0
                },
                {
                    "sent": "It's going to look something like this.",
                    "label": 0
                },
                {
                    "sent": "1 minus rule squared is going to be very small, so any moves are going to be tiny in this direction and likewise.",
                    "label": 0
                },
                {
                    "sent": "In the wide and the.",
                    "label": 0
                },
                {
                    "sent": "Yeah the X2 direction.",
                    "label": 0
                },
                {
                    "sent": "It's going to be very small, So what we end up doing is making these incredibly small.",
                    "label": 0
                },
                {
                    "sent": "Axis aligned moves, so the actual amount of time it's going to take to traverse the support of this distribution is going to be very long, and again, Furthermore becausw.",
                    "label": 0
                },
                {
                    "sent": "The chain is incrementing very in a very, very small steps.",
                    "label": 0
                },
                {
                    "sent": "The correlation is going to increase and therefore the Monte Carlo error that we see in our, whatever our estimates happened to be is going to increase.",
                    "label": 0
                },
                {
                    "sent": "So we have a problem.",
                    "label": 0
                },
                {
                    "sent": "And it turns out to be a very serious problem in the really interesting applications that.",
                    "label": 0
                },
                {
                    "sent": "Well, I.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "To work with.",
                    "label": 0
                },
                {
                    "sent": "I told a lie.",
                    "label": 0
                },
                {
                    "sent": "I said this was the last thing.",
                    "label": 0
                },
                {
                    "sent": "This is actually the last thing here and then and then you can all go for whatever you're going for.",
                    "label": 0
                },
                {
                    "sent": "So we talked about product kernels.",
                    "label": 0
                },
                {
                    "sent": "What about mixture?",
                    "label": 0
                },
                {
                    "sent": "Care knows?",
                    "label": 0
                },
                {
                    "sent": "So let's say again, we've got the same to transition kernels and we've got two transition kernels.",
                    "label": 0
                },
                {
                    "sent": "P1 and P2 and they both have in this case.",
                    "label": 0
                },
                {
                    "sent": "\u03a0 as the invariant density.",
                    "label": 1
                },
                {
                    "sent": "Now let's just define some probability gamma, and we set up our mixture kernel.",
                    "label": 0
                },
                {
                    "sent": "It looks like this.",
                    "label": 0
                },
                {
                    "sent": "So what's the invariant density of the transition kernel composed of this mixture here?",
                    "label": 1
                },
                {
                    "sent": "What's the invariant density that's invariant density of Pi one unpi 2?",
                    "label": 0
                },
                {
                    "sent": "P1 and P2's pie then puts the invariant density of this mixture.",
                    "label": 0
                },
                {
                    "sent": "Pie.",
                    "label": 0
                },
                {
                    "sent": "I.",
                    "label": 0
                },
                {
                    "sent": "It's too close to dinner, but you can convince yourself that it's Pi XI mean it's trivial.",
                    "label": 0
                },
                {
                    "sent": "What situations might this be useful so the product?",
                    "label": 0
                },
                {
                    "sent": "It was very clear that for multivariate distributions of product, kernel may prove to be useful, not about a mixture, care no.",
                    "label": 1
                },
                {
                    "sent": "When do you think it might be useful?",
                    "label": 0
                },
                {
                    "sent": "Are you saying I never want to do MCMC again after this so I don't care when or where it's useful?",
                    "label": 0
                },
                {
                    "sent": "I've lost enough.",
                    "label": 0
                },
                {
                    "sent": "Very.",
                    "label": 0
                },
                {
                    "sent": "Yeah, I mean adaptation is a very good point.",
                    "label": 0
                },
                {
                    "sent": "I would certainly allow you to adapt well in a very loose sense, it wouldn't be adaptive, but let's say that we had a distribution that looked like this.",
                    "label": 0
                },
                {
                    "sent": "I don't know if you can see that, but it's basically just one bump separated at the tails by another little bump.",
                    "label": 0
                },
                {
                    "sent": "Well, what you could and actually fight do here.",
                    "label": 0
                },
                {
                    "sent": "So the problem that we're going to have is that when the Markov chain is in here, remember that.",
                    "label": 0
                },
                {
                    "sent": "The Hastings ratio showed us that with that, if we make a proposal to move into a region of higher density, right, it's always going to be accepted.",
                    "label": 0
                },
                {
                    "sent": "And if we move, make a proposal to move into a region of lower density is going to be accepted with probability which is equal to the ratio of of the two probabilities.",
                    "label": 0
                },
                {
                    "sent": "So if we're here.",
                    "label": 0
                },
                {
                    "sent": "Right, and we make a proposal here.",
                    "label": 0
                },
                {
                    "sent": "Well, fine, we're going to do lots of exploration here, but we want to get over here.",
                    "label": 0
                },
                {
                    "sent": "So let's imagine that we make a proposal to here, while the probability of accepting such a move is going to be very small, so it could take a very, very long time.",
                    "label": 0
                },
                {
                    "sent": "Very large number of tries before eventually this move is accepted.",
                    "label": 0
                },
                {
                    "sent": "Then you can make the leap over to this other.",
                    "label": 0
                },
                {
                    "sent": "Bumper this other mode here.",
                    "label": 0
                },
                {
                    "sent": "So one thing that you could do is you could have two disks.",
                    "label": 0
                },
                {
                    "sent": "You could have two transition kernels, one which was for local moves and one which was for global moves.",
                    "label": 0
                },
                {
                    "sent": "So you could have one in essence, which covered everything here.",
                    "label": 0
                },
                {
                    "sent": "Right, so you could make moves from this region to this region under, say, part P2.",
                    "label": 1
                },
                {
                    "sent": "And then once you're in here, you would have your Pi one, which would be much, much smaller in terms of its variance, right?",
                    "label": 0
                },
                {
                    "sent": "So for multimodal distributions, or distributions that have ridges and all sorts of strange things, and then this mixture distribute this mixture, Kernow may actually be useful.",
                    "label": 0
                },
                {
                    "sent": "And it turns out indeed that it.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "That it is.",
                    "label": 0
                },
                {
                    "sent": "I'm.",
                    "label": 0
                },
                {
                    "sent": "OK, we talked about the fact that Monte Carlo estimates required IID samples.",
                    "label": 1
                },
                {
                    "sent": "And you created this slide here.",
                    "label": 0
                },
                {
                    "sent": "The other thing, of course, is how long do we have to wait before the chain is converged, and so forth, right?",
                    "label": 0
                },
                {
                    "sent": "And shall we take our?",
                    "label": 0
                },
                {
                    "sent": "I don't know 10 minute break.",
                    "label": 0
                },
                {
                    "sent": "Any questions?",
                    "label": 0
                },
                {
                    "sent": "What's for dinner?",
                    "label": 0
                },
                {
                    "sent": "OK, I see in 10 minutes.",
                    "label": 0
                }
            ]
        }
    }
}