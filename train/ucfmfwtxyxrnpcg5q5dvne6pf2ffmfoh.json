{
    "id": "ucfmfwtxyxrnpcg5q5dvne6pf2ffmfoh",
    "title": "Pattern Analysis over Graphs, and Bioinformatics Applications",
    "info": {
        "author": [
            "Jean-Philippe Vert, MINES ParisTech"
        ],
        "published": "Dec. 3, 2009",
        "recorded": "October 2009",
        "category": [
            "Top->Computer Science->Bioinformatics",
            "Top->Computer Science->Pattern Recognition",
            "Top->Mathematics->Graph Theory"
        ]
    },
    "url": "http://videolectures.net/aop09_vert_paog/",
    "segmentation": [
        [
            "So thank you, hello and thanks the organizers for this very nice workshop.",
            "So before we start and I on announcement would be quite easy.",
            "It's something you have the right to do right now if you're connected to the web is that my slides are on the web already.",
            "So if you want to have them during the lecture I will just show you how to do you click on my name and you reach.",
            "I think my homepage.",
            "Then on my home page you go to talks.",
            "And there the Third World, the one at the top, should be this talk and you just click on slides to get the slides OK.",
            "So that's in case you want to follow it the the thing, so I don't have any link to the Facebook group, which I'm not very good at Facebook, but you could imagine putting in there.",
            "So yeah, and also that I will try so this is not a real tutorial.",
            "This is more.",
            "I mean, I tried to make it look like a bit trying to tell you something in the shape of a course or tutorial, but obviously is very biased to what what I do myself is my colleagues and I will try through a few applications to explain you a few techniques that we and many others have been developing over the recent years.",
            "To solve problems, so I will just focus on one problem which is supervised classification.",
            "For data with structures, so as in all said, there would be a lot of graphs, but not only and I will try to show a bit how it relates to what we've been saying.",
            "The rest of the week.",
            "I mean, we've been looking at that, but we've also been talking of finding patterns so they're actually links.",
            "Ann, I hope to be able to show you that there are increasingly increasing links between, let's say, the machine learning and knowledge discovery communities in the sense that more and more we need efficient algorithms too.",
            "To solve optimization problems that occur in machine learning and to solve them, we more and more can use well known aggressors that existing data mining.",
            "So I try to give you a taste of what it is and I think this is a quite hot topic in these days."
        ],
        [
            "So, to clarify, let's take a few examples and I will try to keep these examples throughout the talk and show you how we can solve them in different ways.",
            "So the first example is a very crucial one in drug discovery to find drugs.",
            "So if you go to pharmaceutical company they want to make new medicines to solve to cure diseases and among the drug discovery process.",
            "There is one part of the process which can be done with computers or where computers can help is called globally virtual screening.",
            "And the idea is to say that basically so classical drug is just a small molecule, and on this picture you can.",
            "You can see several small molecules, so I just show six of them.",
            "But in fact if you go to a famous car companies, you have millions of them in databases and what the people do in these companies are typically testing some of those molecules to check if there are some effects on the disease or if they hit the target or the things so you can do that with hundreds of thousands or thousands of molecules.",
            "You do the tests and you measure the efficiency.",
            "And after some sometime in some money spent you can end up with such databases where you have lists of molecules and some have been detected to be active or let's say they have an effect positive effect that you want to induce like stop the disease progression and some don't.",
            "And then instead of, you know, testing all the millions of miracles they have in their databases.",
            "Plus the billions once they could generate, we can imagine using computers to take this as input.",
            "You know taking the database is the database of molecules with an activity and try to make a model to check if from the structure only we could be able to predict whether a numeric will be active or not.",
            "So obviously if we can do that, well we can speed up the screening process and we can also.",
            "Generate new molecules that we predict could be active and therefore a quicker detection of molecules of potential drugs and also cheaper one.",
            "OK, so when you see it from a machine learning point of view is just saying that you have a set of.",
            "In this case it looks like graphs.",
            "So from your graph will typically be molecule is seen as a graph when you see the atoms as the notes of the graphs and when you have a bond between atoms it becomes an edge of the graph.",
            "So this is clearly what this picture shows.",
            "So you have graphs, some of label positives and have a label negative and you want to train the model that will be later able to predict for a new molecule, and you graph whether it's active or not.",
            "So by the way, I will mostly talk off by informatic, but just a single slide to say that if you're not in this business, you may be interested too in what I would say, for instance, colleagues of mine in Paris or France is back and say dash, we are using basically the same methods for image classification, so it's just one among many possibilities.",
            "Many ways to represent objects as graphs.",
            "So in this case you can say that when you have an image, suppose you have an image of what we describe an image, so an image is a set of pixels, but a set of pixels.",
            "It's not very important informative, so there are many ways to extract descriptors for images and one approach representing images to 1st do a segmentation of the image into uniform regions and then to consider graph where each region is an odd and you put an edge between two regions which are adjusted to each other on the picture.",
            "So that's just one among many ways to represent one image by graph.",
            "OK, but in this graph of course we have the structure of the graph, which is important.",
            "It represents the relative positions of the signals an each.",
            "Now that each vertex itself contains a lot of information, you can summarize a region by the average color or some detectors, etc, and then so similar to my molecules, you can have machine learning problems in images like you know making a model that is able to differentiate between the pictures that contain an airplane and features and container.",
            "Animal, and this is the same for more problem of graphs with positive and negative labels and you want to make a model to discriminate between the two graphs.",
            "OK, so this this problem will be one that I will try to try to keep in mind and I will show different ways to solve it.",
            "Of course there are many other ways, but I will focus on a few strategies at least to explain."
        ],
        [
            "How we can do that?"
        ],
        [
            "Second type of problem that I will try to discuss is a is a well known problem in bioinformatics.",
            "We probably have heard about that it's about microarrays, so I will explain it later what microarrays are but typically in cancer diagnosis where I tried to work on, we can take patient with cancer extracted from the numerous small sample and measure on this sample what's called the expression of the genes so we can.",
            "End up for each tomorrow with a vector of descriptors that contains several 10s of thousands of numbers which are the level of expression of all the genes and typical problem we are facing.",
            "We are facing are when you have two types of tumors, like in this case which is a well known example, you have two types of leukemias with different outcomes and different treatments and what you would like to do is from the measurements.",
            "So you take a sample of blood in this case and from the measurement of the expression data you would like to be able to predict to classify your cancer's.",
            "ALLOAML and then to be able to adapt the treatment to the case.",
            "OK, so this is a well known problem.",
            "It has been well known in the last, let's say 10 years or so in statistique cause it's well known that is complex because you have many features and a few small number of samples.",
            "So it's sometimes cause a small energy problem.",
            "And what I would like to discuss in this in this talk is how to include some prior knowledge you may have, because in this case.",
            "I know the features are the genes will explain what these are, but you have 20,000 genes in human cell and these jeans are not just 20,000 features independent features.",
            "We know that many of the genes.",
            "Work together or some regulate each other or there out of knowledge about the jeans and typically one knowledge we can have about the jeans.",
            "So this kind of graph.",
            "So this graph on the right is a is a graph is a network where each node is a gene, so you know imagine that each node of this graph is 1 feature of this of this business and the question becomes, you could either just use these metrics to train a model to discriminate between LML and say you have 20,000 features, or you could try to say I have the data.",
            "Plus I have the prior knowledge.",
            "In this case, that some of the features are linked to each other and I will try to to discuss the question, how can we use this prior knowledge so the features line on the graph which is given a priori, how can we use this knowledge in order perhaps to help the computer learner nice discrimination?",
            "OK, so in this case we have high dimensional data with two samples, but a lot of prior knowledge which which can be in the.",
            "In this case there wouldn't be a graph.",
            "Sorry.",
            "So in this precise picture, the edges.",
            "So in this picture the jeans are what are called enzymes.",
            "OK and I mean OK for those of you know what ends up so you have jeans called enzymes and the edge here means that two enzymes work together in the pathway.",
            "I will tell more details later.",
            "OK, but you can imagine other semantics like another one on network is when you have physical interactions.",
            "So the genes make proteins and proteins can bind to each other and you can present this as a graph and say that I represent the set of all proteins and indicate which one can bind to each other and this tells me which one are working with each other."
        ],
        [
            "Finally, a last example that we also discuss is also related to this case to cancer diagnosis and prognosis, so again about classification of tumors.",
            "OK, we talk of diagnosis when we want to identify what class of tomorrow we have and we talk of prognosis when we want to predict what's going to happen in the future like this to know will give metastasis, and this one will not, so you can adapt the treatment so in prognosis.",
            "So you want to predict the future of the tumors.",
            "You can also use gene expression data and it's often used, but there are other data you can use in for instance in this picture.",
            "So it's a bit hard to see, but these are other measures we can do on the tumors.",
            "So in this case it's called comparative genomic hybridization, CGH, and what you see.",
            "So each think of each signal here is 1 one tomorrow.",
            "So here you have five aggressive tumor on the left and five non aggressive tumors on the right.",
            "And what do we measure is along the genome.",
            "The number of copies of DNA present in the cells.",
            "Again, I will explain a bit more later what what it means, but it turns out that in in tumors, so in a normal cell in most of your cells you have two copies of each chromosome.",
            "You know that's the basic thing we know, and if you take a sample of tomorrow, you don't have two copies.",
            "Some chromosomes are 3 * 4 * 5 times, etc, and we can measure that.",
            "So if you plug the number of copies along the genome and end up with a.",
            "Kind of time series.",
            "So in the X axis is the position in the genome, and Weibel to measure.",
            "If it's flat.",
            "So if that would mean that you have a normal genome and sometimes so.",
            "If you look here for instance in this.",
            "In this case you see that almost all your genome is OK, but you have a region where you have negative numbers.",
            "Probably the chromosomes have disappeared.",
            "Here the jeans are lacking there, and some regions are in larger numbers.",
            "You don't have two, but probably 3 or 4 copies, and so this is one way to characterize a team or two, and it's well known that this is related to the aggressiveness of the tumor.",
            "So we are confronted, typically with a machine learning problem where.",
            "The X, you know the data are profiles like this and we want to discriminate between the profiles on the left and profiles on the right.",
            "And again, you could say, well, profile is just a set of numbers.",
            "You could say if I have here 2000 measurements, you can say I have a vector dimension 2000, but obviously there is a structure here.",
            "OK, we can call that a pattern we would like to see in this kind of time series.",
            "What is other some patterns which allow us to discriminate between aggressive and non aggressive tumors and pattern will typically be identified regions where sort of the overexpression of original over copy number of origin could be predictive.",
            "And then we can go back to the biology check which genes are in this region and perhaps just some better other disease.",
            "What do the numbers mean?",
            "Job, not integers?",
            "I mean can their specialty Navy half press?",
            "I mean how?",
            "So yes, yes and no.",
            "So first the number.",
            "So here the numbers to be precise are log ratios.",
            "OK, so 0 means that you are normal, typically log ratio compared to a normal cell.",
            "So there are supposed to be you are.",
            "You have two copies.",
            "And then you can have 345.",
            "Now what you observe is that you don't have just, you know, discrete set of numbers is not log of three log of Forks iterates more complex, at least two reasons.",
            "One is that the technology is not perfect, so we have noise and it may not be very well.",
            "Scale and the other regions.",
            "Which is more important is that when you take a sample, the cells are not all the same.",
            "You know you take.",
            "Let's say you take you have a breast tumor.",
            "You extract budget sample and you have thousands of cells and they are not all the same.",
            "But when you do these experiments you miss them altogether and you extract the DNA.",
            "OK, So what you observe is more mixture of several cells from my F2 copies and I have 3 copies and therefore you end up with some average again.",
            "OK, so these are all the examples I will try to solve.",
            "So what's coming here is that in all these cases, from theoretical point of view you have data and you want data with labels to possible labels and you want to discriminate them.",
            "OK, so it's well known.",
            "Probably you know that you can say that we have a supervised classification problem in the sense that we have."
        ],
        [
            "So in this picture, white points and black points, so this could be active versus non active molecules, accuracy versus non aggressive tumors, or LL versus animal cetera.",
            "And what we would like to do at the."
        ],
        [
            "And in our case is find a way to discriminate them.",
            "So find a rule to separate the white from the Black Ann in the spirit of machine learning.",
            "What we want is not only to separate them, but more importantly to have a predictive model."
        ],
        [
            "Which would be able in the future step in the future to to associate a label to new data like."
        ],
        [
            "Two new points here and you would like to predict that the white is white and the black is black.",
            "OK, so it's not only making a difference, but it's making a predictive model that we have predictive power."
        ],
        [
            "Typically in all the all the problems I have shown are classical problems.",
            "You know machine learning is an all topic.",
            "You have a lot of methods to do that.",
            "What's a bit difficult in this case is that there are a few features shared by some or all of these problems.",
            "So in some cases we are in very high dimensions, so machine learning is not supposed to work very well in high dimension.",
            "And when you have 20,000 genes while you have them, so perhaps you should keep them and find algorithm that work in high dimension.",
            "This is often combined with the fact that we have few samples, so this is the.",
            "Large P small N problem with few samples in high dimension is not an easy situation.",
            "What's interesting in particularly relevant for this workshop is that some of the data structures and infrastructure can help us overcome the problem of dimensionality.",
            "Will see how, but by structure I mean that you know the graph will.",
            "Typically the graphs are not vectors.",
            "I kind of talk of the dimension of a graph is just an object, so there is a structure, but even the SGH professor, the time series you can see them as vectors.",
            "But there is some structure behind that you could say it's a noisy version of a piecewise constant thing, etc.",
            "So you can start to think of replacing the notion of dimension by national.",
            "Torture.",
            "I will skip the national federations data, which is also important, but not the topic of my talk.",
            "And in all these cases too.",
            "In fact, we have a lot of prior knowledge.",
            "So I talk of the pronunciation of the interactions between the genes.",
            "When you have 20,000 genes or when you have the time series, your prior knowledge can be that you measure things along the genome so you know that there could be some constraint coming from the fact that you are in the genome.",
            "So you could try to average, for instance, of our windows.",
            "So these are prior knowledge you have about the data.",
            "ETC and OK. Of course we would like so one of the discussion I will have is that we want to have.",
            "Real implementations of the methods, so in particular would be able to compute the things fast enough, which is not always the case.",
            "In particular case of the graphs we will see that one of the main bottlenecks today is that we can imagine many descriptors, but we cannot compute them efficiently, so we have to find tradeoffs between what we want to do and what we can do.",
            "And finally, and this is also rated in all these cases, we want to have a good predictive power.",
            "So we want to have a model that does a good job at predicting who will be black would be white, but also would like to have some models that we can interpret, like extracting knowledge from the model.",
            "And this is, I think.",
            "Completely related to the topic of, you know, finding patterns in the data, so I will not talk more about that, but I think this is a very important point that in the discussion of how to extract patterns from points, you know if I come back to the exam."
        ],
        [
            "Rules of example of molecules.",
            "One approach is to say OK, I'll take all the active molecules and I strike to frequent subgraphs, for instance, and this could be an interesting pattern because it's often frequent, let's say often frequently active and often not often frequented inactive.",
            "So this is one way to do, and many people do that.",
            "Here what I will focus about is more about creating a model that will be predictive, so be able to see."
        ],
        [
            "The positive from the negative and then try to understand what if the model is good, then it should contain interesting information and typically it could be based on the presence of some subgraphs or some other graphs, and these ones will not.",
            "Always be the ones which are frequent or not, because there will be more.",
            "The ones which are useful for the prediction.",
            "OK, this is slightly different so I would say that an obvious link between the machine learning approach and the pattern Discovery approach is that in the machine learning approach, probably we try to extract patterns not directly but based on.",
            "Based on the idea that if we have a good classifier that it should be based on some interesting features that then we can look at.",
            "OK, so let's.",
            "So I will try to keep these examples in nine entry, then one by one along along the discussion.",
            "But let's try to be just a little bit formal too, because we just to set up the notation, etc.",
            "So here's what we want to solve.",
            "Our problems of supervised classification, so I assume that I will call X the data disk and your graph vectorized version or whatever, and why the class which."
        ],
        [
            "In this case, would be binary, even though what are second you apply to regulation etc.",
            "We assume that we have a training set, so a training set is is a pair is a set of pairs XY.",
            "Like a molecule with active or inactive, this is 1 example and I have many of them.",
            "And my goal is from this training set to estimate a function F. That will be able to predict the label Y of an example X by every weeks.",
            "And ideally we would not have to be so after training would like to get a function F that is both accurate.",
            "So give good predictions an interpretable this is a difficult tradeoff.",
            "But this is weird."
        ],
        [
            "So you can take any book on machine learning to find many examples of ways to build a function F, and that in fact I will just focus on one particular case of functions, which of classifiers which are linear classifiers so you know already make a big.",
            "Just focus on the tiny part of the machine learning world, let's say OK, I just focus on linear function, even though with kernels and there was a talk about kernels earlier in the week, we know that if we have things for linear functions at least using the kernels, we can have nonlinear functions too, but I will focus on look at the kind of functions which are generated by linear functions, which means that the kind of things that will investigate our.",
            "I have an object X which is any object an what I mean by linear function is that from this object.",
            "Next we will extract descriptors or patterns or features.",
            "I don't know which one is the most correct, but we will extract a set set of patterns.",
            "And I don't say if peace finite or infinite, because again normally it should be finite.",
            "But if we use kernels, it could be infinite.",
            "OK, so let's just say that we have a vector of the scriptures and the set of functions.",
            "I will consider our functions ever fix which are linear combination of the descriptors.",
            "So typically the sum of beta I time F of X, Fire, Fire, victory and so the goal is so there.",
            "So here we have a training set and the goal is to estimate function beta an F will be so.",
            "In this case, real valued and you can threshold it to 0 to have position positive or negative."
        ],
        [
            "OK, so obviously there are two important questions which seem to be unrelated, but I think which are very related to each others and I will try to explain why.",
            "The first one is how to design the features.",
            "Typically I give you the molecules can represent a molecule as a vector.",
            "How do you choose the descriptors, the features and the second question is, once you have chosen the representation as vector, how do you infer the model?",
            "So you could say, well, once I have a vector, I apply your support vector machine.",
            "This is one way to do or I do FDA.",
            "This is another way to do or I do something else.",
            "It turns out that the two steps are not independent in the sense as, which as we see that there are.",
            "There are some descriptors you can use with less so, but none with VM's for instance, and there are descriptors you can use with SVN, but not with us all or with boosting, so it's not obvious at first sight, but because of the structure of the algorithms there are things you can do with different algorithms and with different descriptors.",
            "But so basically the.",
            "The rest of the talk will be devoted to talking about these questions.",
            "What are the ideas?",
            "What are the currents?",
            "I dies in the community to define strategies to design the features an and learn the weights from the training set."
        ],
        [
            "So to be more precise, this is the outline of the rest of the of the talk, so I will talk of three ideas.",
            "Basically, the first one will be the shortest parts, it's OK. Let's compute explicitly descriptors, so give me a graph and I give you a list of things you can compute.",
            "Let's say 100 descriptors, and then you compute them and you take your book on machine learning or your toolbox and machine learning, you run any algorithm on that.",
            "OK, so I will just focus on the case of graph.",
            "To illustrate that there are the scriptures which you can compute and descriptors which you cannot compute.",
            "In particular will focus on the ones you cannot compute to show that it's not so obvious to do.",
            "Let's set represent a graph by your vector.",
            "OK, but that's the first idea.",
            "Just make a list of descriptors, compute them and run your machine learning.",
            "Then I will spend some time on now a famous way to do which is using kernels.",
            "So the main result gave a nice introduction to can.",
            "Also the main idea here is that we know that we can often do more with kernels then with explicit computation of features, and we know many examples where you know for instance OK Now can be seen as some inner product in space where the dimension can be hard and you don't need to compute the descriptors.",
            "So clearly one natural ideas to say that.",
            "If you are stuck with a small number of descriptors, if you need to compute them, perhaps you can move to the space of kernels and design kernels to be able to work in spaces with many features.",
            "So we see that it's possible, but not always.",
            "And see about some limitations.",
            "I said in the case of graphs and another case of G networks.",
            "The third strategy I will discuss is something which is very fashionable these days in the machine learning communities.",
            "If you go to the conferences or whatever, it's saying that OK candles are nice, but in a sense so they are nice in some cases and are very powerful.",
            "But with kernels it's very hard to have interpretable model.",
            "This is one of many mutation you have.",
            "Seems a bit like a black box like I have a next model to predict the activity of molecules, but what are the important substructures you don't know?",
            "So there is another strategy that which is not new but which is gaining a lot of attention which is feature selection and in particular features.",
            "So feature session is that you start from a list of many candidate features and you build a model based on just a few features.",
            "OK, it's not.",
            "It's not a new idea, but what's a bit new is the algorithms used to do that.",
            "In particular convex algorithms like the using the what we call the L1 penalty that I will explain what it is and more and more what we see is that you can do not only feature selection, but if you have prior knowledge.",
            "About the features like the features are nodes of a graph or they are along the genome.",
            "Then you can extend the notion of sparsity.",
            "So feature selection to expression of patterns.",
            "OK, so we discuss a bit how you can encode, let's say penalties that allow you with some convex optimization problem to extract classification rules.",
            "So let's say 2 twin further vectors which not only are sparse but kind of specific structure like being piecewise constant or are being sparse.",
            "Level of subnetworks, etc.",
            "So I think this is a very.",
            "Interesting direction, and in this part I will also explain a bit that some people recently have proposed method to combine sparsity with.",
            "Mining of how you call that data.",
            "Mining of substructures like using the apriori algorithm as a subroutine to boosting in order to do sparse running in the space of subgraphs etc.",
            "So I think there is a strong link here between machine learning that uses a SGML boosting an mining Africans frequent subgraphs, for instance because one can be seen as a subroutine of the other one, and therefore end up with efficient algorithms to work in huge spaces.",
            "And then after that, if you're not too tired, I will conclude.",
            "So I must say that I have 114 slides, but I don't plan to talk of all the slides.",
            "I will do a selection but you can look at the size and we can discuss after the workshop.",
            "If you're interested to discuss more.",
            "OK, are there any questions at this?",
            "About this, so again, this is not a real cross.",
            "You know it's heavily biased to what what we did and what I know other people did, but it's not supposed to be fine in general.",
            "Introduction to the topic.",
            "So if there's no."
        ],
        [
            "The question let's start with the first idea, which is let's say the simplest one.",
            "OK, we have data, so normal ideas from data.",
            "You you extract descriptors and then you run machine learning on them so.",
            "Yes, there is a question.",
            "OK, so mother you are.",
            "Is that more like you know, general ratchet across places?",
            "Play music from this morning.",
            "Yeah.",
            "So I will talk about discriminative model.",
            "So all these things will be about.",
            "Let's say these are.",
            "This problem you have black points and white points and what I will discuss so I will try to combine the discussion of how to make descriptors and how to infer the weights in the case of linear models.",
            "OK, so these are all discriminative models linear based on features.",
            "And we focus on a few examples.",
            "Classification of graphs or expression data, or the things that try to highlight some general principles, and I think 3 general principles that can think about our computer explicitly descriptors and run machine learning or use kernels, or use sparse running innocence.",
            "And I will try just three straight through examples, but it can give on practical things.",
            "But it's all discriminative and it's all based on descriptors and in our functions.",
            "OK, so let's start with the 1st."
        ],
        [
            "So the first strategy we have, data, and we represent the data by your vector.",
            "OK, so typically I will just focus on one example which is classification of graph just to show that it's not.",
            "So there's nothing very new here, but it's not easy to do that like here.",
            "You have graphs, so you have active and nonactive graphs you would like to use your machine and tool box so and ideas you present a graph by your vector.",
            "So let's say one dimension could be.",
            "I count how many carbon atoms there are.",
            "This is 1 descriptor.",
            "I count how many aromatic bounds cycles they are.",
            "This is another script, or you can.",
            "Some things you can measure things, then you present a graph by your vector.",
            "You have a matrix of the scriptures and graphs and then you run the machine learning algorithm.",
            "So first, I mean before I spend, it's not obvious.",
            "I would like to to say an important message which is a bit unfortunate but important.",
            "In my talk, it will look like this is not very fancy and not very good idea to do SPC descriptors OK, because I will explain how to make fancy kernels and fancy sparse running.",
            "In practice, when you have to solve the problem like this problem from my experience and from discussion with other people, by far the best idea is to think of the good descriptors sense that.",
            "You know you could.",
            "There is a trend in machine learning saying OK, we make many descriptors, and we have Instagrams and we compare algorithms on the set of also grass etc.",
            "At the end.",
            "If you have the good descriptor than any algorithm will find a good classifier and will be interpretable.",
            "So I will just try to say that it's not because in my talk is a short part and not very fancy.",
            "One that is not important in practice.",
            "There are many cases, many machine learning problems where you should better spend time two months designing a good feature than two months.",
            "Making a new kernel and training multiple kernel learning and these things OK, so it's a bit unfortunate, but I think it's fair to say that the constructional feature is not.",
            "It's not a bad business, it's very crucial."
        ],
        [
            "OK, So what about the case of graphs?",
            "So here suppose we have the space of graphs on the left.",
            "While I say is that we're going to make."
        ],
        [
            "Descriptors so we can.",
            "We're going to map each graph into a vector space.",
            "I call it H here, but let's say a finite dimensional vector."
        ],
        [
            "And then we run some algorithm there to separate the blue from the."
        ],
        [
            "In fact, this is what is done every day in every pharmaceutical company like you can buy a software from.",
            "Open AI is a company that is very successful and and that represents.",
            "So here in this picture that represents a graph here.",
            "So a molecule here by your vector.",
            "So here in fact it's a vector of binary indicators.",
            "It's because it's small to store in memory, and it's based on the detection of the presence of substructures in your graph.",
            "So what the company did is design A set of.",
            "I think something like 900 basic structures they think are important to represent the molecule and then they have a fast algorithm.",
            "When you take a new molecule as input described by the fire noise coming through to compute the fingerprint, which is a set of bits 100101 that just checks if each of these 900 substructure is in the graph.",
            "And then once you have these descriptors, you run support vector machine on your networks or DLS or PLSS.",
            "Popular in came in for Matics or whatever you want.",
            "OK so this is basically the state of the art.",
            "In practical applications you gotta companies is what's done is not the only way to represent as a vector.",
            "This is a popular one.",
            "But in fact you have you have a book called the Handbook of Molecular Descriptor.",
            "I think there are 600 pages of features you can compute.",
            "OK, so there's a big community dedicated to what you can compute from.",
            "A miracle and then use that as input feature."
        ],
        [
            "But OK here.",
            "Obviously I mean you can buy the software from the company, but you could also think of the process.",
            "How did they end up with this list of features?",
            "Are they good or not so perfect there were good cause over the time they have improved it and they seem to be important features for many applications, but clearly you know there is a tradeoff here.",
            "'cause you could imagine having a lot of substructures.",
            "Lot of two index.",
            "So to represent your molecule as a vector of dimension 1000 or 10,000 or 1,000,000.",
            "In fact you can have many of them.",
            "So the question is where should you stop?",
            "Should you continue to add features, how do you select them?",
            "And in a sense you could say, well forgiven for one constraint in this field is speed and memory storage.",
            "So in this case they want to make a fingerprint over, let's say 1000 bits.",
            "So the question is if you can afford 1000 descriptors, which one should you choose?",
            "How to maximize the expressiveness in order to make too many clothes different of different pieces?",
            "If there's different, etc.",
            "And these are not obvious questions.",
            "So perhaps just restarted?",
            "Why it's not obvious?",
            "Let's think of what about, you know, having a Dictionary of all possible substructures?",
            "OK, you could say, well, I'm new in machine learning, so I don't see why I will take this once I have a machine.",
            "I have SVN that can work in infinite dimensions, so I there is no problem to limit that.",
            "So what about indexing a graph by all the subgraphs it contains?"
        ],
        [
            "And probably the people in the room involved in subgraph mining know already the answer.",
            "The."
        ],
        [
            "So so so.",
            "So what about?",
            "OK, I have a graph so this is a bit of stripe represent it.",
            "I have my molecule here.",
            "OK, this is a graph.",
            "Then from this graph I could say I will extract all the subgraphs.",
            "So two to make sure we all agree sub graph is simply.",
            "This is the bit wrong, but simple.",
            "What we spend that it is the selection of a subset of vertices and the edges that connect them together or not.",
            "So for instance from this graph I can extract all these subgraphs so you have a graph of size 1, two, three or four and you so here I just consider connected subgraphs for instance.",
            "OK, So what you could say is that given this graph, given this molecule, I can extract all these subgraphs.",
            "I can either detect if they are present or not, or I can count them and then I represent my money could buy a vector that for each candidate subgraphs so these ones are the ones which are present.",
            "But then you can imagine many other ones which are not present here.",
            "You just count how many times they occur and this is how you represent your molecule.",
            "OK, so when you say."
        ],
        [
            "This is a generalization of this with instead of these nicely chosen substructures, you take all possible substructures.",
            "So it turns out there are quite a few.",
            "In particular, if you take into account that you can have several different types of atoms, there are six common atoms plus many uncommon items.",
            "For each node you have different types of bounds.",
            "You can have symbol, double etc bounds, and then you can have different structures.",
            "You can end up with huge dictionaries."
        ],
        [
            "So OK, why not try so, can we?",
            "OK, can we photograph extract all possible subgraphs and made the vector disk?"
        ],
        [
            "So this is what we want to do.",
            "OK, we have a graph and you would like to to make the graph.",
            "Let's say of indicators.",
            "Of the occurrence of any possible sub graph within the graph.",
            "This would be my descrip."
        ],
        [
            "Unfortunately, it's not.",
            "It's well known and it's not difficult to show that this is not an easy task.",
            "OK, so in terms of computing computer science, we called that NP hard problem, which means that to compute these numbers even to compute one number.",
            "In fact there is no polynomial time algorithm that you will find, so it doesn't mean it's impossible, and I think that many people everyday solve NPR problem.",
            "But let's say that here it will take time.",
            "So this is NP hard problem and just to show that there is nothing hidden here is very easy to show that it's NP hard.",
            "'cause if you just look at, you know, suppose you have a graph with.",
            "N vertices with N nodes.",
            "And if you look at the bit that includes the fact that the linear chain so you take the linear graph with nodes, if you want to check whether the linear graph is present or not as a sub graph of your graph, it means that you need to find what."
        ],
        [
            "Called the Hamiltonian path in the graph, so Hamilton Path is just a path that goes through exactly once through all vertices.",
            "OK, if there is a Hamilton path, it means that this in our graph is a path.",
            "So you compute one and if there is no Hamilton path, it has to be 0.",
            "OK, so it means that just with this, so here I mean here.",
            "This is not the correct one here I have just two things, but if I take the indicator in this case.",
            "For the linear graph with five nodes, it will be one if and only if there is a Hamiltonian path in this original graph.",
            "And this problem is known to be NP complete.",
            "OK, so if we can compute this indicator, we can solve this NP complete problem and therefore we call that NP hard procedure OK, so just computing one bit here is already NP complete.",
            "So imagine computing all the features.",
            "It's not not so easy, so I think in this case it's not only NP complete, but in practice it will take time.",
            "When the size of the graph increases, if you have a graph of size 10 or 15 or 20 like molecules, it will take seconds, minutes, hours or longer.",
            "OK, so there's this here.",
            "You see, there is a serious limitation in the in the type of subgraphs you can use to index your graph.",
            "OK, even taking the simplest wonder in our path is not obvious to check it represents or not.",
            "So by the way, you could say well, so here was talking off using all subgraphs of sorry from this molecule.",
            "And here you can extract all subgraphs so you have linear ones and you have even more complex ones like you would like to try to cycle cetera.",
            "So of course an idea."
        ],
        [
            "To say, well, what about I just extract the path so the path of the linear subgraphs like from this molecule I can extract all the subgraphs which are linear.",
            "So I just removed the ones with cycles etc."
        ],
        [
            "And of course you could say, well, process can just index by molecule by the occurrence of linear subgraphs.",
            "And of course, is the same proof."
        ],
        [
            "It is also NP complete because again the just with one bit of a linear indicating the presence of a linear path as a sub graph.",
            "This is already NP hard, so even with this smaller space just in this, in the presence of path.",
            "Is impossible in practice when you want to do it on their arse."
        ],
        [
            "OK, so this is the first information that is not so obvious to just to anchor the graph as a vector that indicates the presence of substructures.",
            "And this is a very natural thing you would like to do.",
            "You know like if you want to have some interpretable model, we know that in chemistry the presence of some particular substructures may be responsible for the activity.",
            "So you would like to have these as features and it's not easy to compute, especially in our scale.",
            "So this is one of the reasons why the fingerprint I showed earlier.",
            "Sold by the company is limited.",
            "In fact it takes time to compute it.",
            "It depends on your computer, is it?",
            "Rabbit is not obvious to check the presence of subgraphs in a in a molecule.",
            "OK, so the main message is that OK, it's not easy to do it explicitly.",
            "We cannot compute that now.",
            "It doesn't mean that we cannot do anything, and in particular a lot of research has been done in order to follow the same spirit, but reducer bit more the set of things that indexer molecules.",
            "So here are just a few ideas that have been proposed always with the goal to represent a graph by your vector of counts of occurrences or something.",
            "So we saw that occurrences of subgraphs is too expensive to compute.",
            "Occurrences of path is too expensive to compute.",
            "What some people have done typically so I think is not exhaustive.",
            "You can have other ideas, but at least this is the this already gives you some ideas of what you can do.",
            "So."
        ],
        [
            "It is possible to preselect based on prior knowledge, for instance, a subset of subgraphs.",
            "This is typically the fingerprint I showed earlier, so you know that in chemistry this thing.",
            "This thing this thing important and you just focus on them.",
            "And even if it's a bit expensive to compute them well, you can probably do it in practice.",
            "Another idea, so I said all the path is too expensive, but you could say, well, I will just focus on the presence of path up to length K and you fix K equal to 5, six or seven, at least until you can compute them.",
            "So it's always.",
            "It's time to compute, but at least you can control the computation time, and if you take a small enough then you can index your graph by the presence of also a path of length one is just the terms, so you can be a terms of path of length two is an Atom bound to another Atom.",
            "You can compute then etc and you stop when when it's too expensive in terms of time.",
            "OK, so typically this is also so sorry I took off up and I earlier.",
            "In fact the fingerprint I showed this solved by your company name.",
            "DL and open eyes selling another.",
            "Fingerprint that computes the occurrence of path to length 8 in this case.",
            "Now there are other ideas, like instead of looking at all the paths.",
            "So in this case in the more recently in the machine learning community.",
            "Custom book Vault and an Kriegel proposed to just look at the shortest path.",
            "I have a slide on that.",
            "Another idea is to look at this so a bit like the you know the path all the path is not possible but you can receive the length and other ideas to look at all the subgraphs that up to K vertices like instead of looking at all the subgraphs in the molecule, you look at all the subgraphs up to K nodes and again you can.",
            "Somehow compute them, or at least find approximation to them.",
            "And of course process should have said that earlier is ready to the what I called data mining community and other ideas.",
            "You start from your database of molecules of millions of molecules.",
            "You first do a mining for the occurrence of.",
            "I mean, for the frequent subgraphs.",
            "So instead of taking all the subgraphs, you just take the the subgraphs that occur at least 20 times in your database, and then you just focus on them.",
            "So this is a way to reduce the list of subgraphs.",
            "And intuitively, to focus on the good ones.",
            "And here you have a parameter to select how many you can compute and how many, how much time you want, OK?"
        ],
        [
            "So probably just so wild about two of these ideas.",
            "So I mentioned you can just look at the shortest path.",
            "So what does that mean?",
            "It means that when you have this graph, instead of looking at all the path that goes through this is, you could say, well, if you pick two vertices, there is usually one or a small number of shortest path between them.",
            "So France between.",
            "This A and this ADA sorry between these A&B, the shortest path is AAAB OK so you can see it once and you don't count the path AAB ABB 'cause it has the same starting point, the same endpoint but it's longer.",
            "So of course if you just focus on the shortest path you index America by less path and in fact you can compute how many of them you have cause if you have N vertices then you have the order of N square pairs and squalid by two.",
            "And therefore you have all the other end square shortest path to consider an you can enumerate them with an algorithm named Floyd Washer."
        ],
        [
            "And end up with the computation of your fingerprint in polynomial time and to the phone.",
            "OK, so that's just to show that this is 1 ID to completely reduce the complexity of the problem.",
            "OK, you don't consider all the path, but just the shortest one.",
            "You can eliminate them efficiently and compute your fingerprint.",
            "The other idea was to."
        ],
        [
            "Look at all subgraphs.",
            "So this is.",
            "This was a difficult problem if you don't limit the size of the subgraphs, but now if you look at the presence of all subgraphs up to three vertices, you have a finite number of them, and usually you can compute them efficiently.",
            "And in fact, so you can think a bit of it if you just do some nice."
        ],
        [
            "Enumeration it's case as end to the case, or N is the size of the vertices and K is the size of the N is OK.",
            "The size of the graph you have N vertices in a graph and K is the size of the subgraphs.",
            "So typically you have enter the case sets of.",
            "Of gamers of versus.",
            "Now, if in the case of chemistry, for instance, we don't consider general graphs, these are graphs with a very small degree in the sense that the molecules have a limited number of neighbors.",
            "So this the presence of.",
            "K of subgraphs can be reduced to something like N times degree to K -- 1 because you first pick one vertex and then there are only D possible neighbors.",
            "You don't have minus one possible number, so in fact it is smaller and in fact you can.",
            "You know, depending on what you want to do, so this is the company to compute explicitly your descriptors.",
            "Now there is some people have proposed even recently more recently to do some sampling.",
            "OK, so to say, instead of computing exactly the descriptors, perhaps we can have some approximation of the vector of descriptors by randomly sampling the subgraphs, counting them, and we stop when we are.",
            "We have enough of them OK, and if you're sampling scheme is good enough then you can show that what you estimate is unbiased.",
            "So you do some estimation of your vector of descriptors.",
            "You can control how far it is from the good one using the tools that John showed in the previous talks.",
            "More distance between the empirical.",
            "What you measure, the frequency you measure, and the theoretical one so you can control that based on how many you you measure and this can give you some.",
            "So what's a bit strange here is that you will not always get the same result.",
            "From the graph, you can end up with different representations, But you can control how far they are, and this may be enough to solve your machine learning problem.",
            "OK, so these are all ideas to reduce the complexity of the problem and be able to compute these descriptors even though the original problem is NP complete.",
            "OK, so this was just a like an introduction and just to point out that let's say in the case of graphs which is of interest in chemistry and image processing etc.",
            "It's clearly not obvious to define interesting descriptors.",
            "And when we define descriptors as the presence of subgraphs, which intuitively is a good descriptor, then it's not obvious to compute them.",
            "It's even in."
        ],
        [
            "Sybil.",
            "So there have been several ideas to reduce the set of structures or speed up the computation an globally speaking.",
            "Once again, I would like to not to be too dogmatic about NP hard problems.",
            "There are many NP hard problems that are solved in practice, so perhaps for some databases is possible to index your graph by all the subgraphs.",
            "It depends on the size of the graph degrees, the side of databases drop.",
            "OK, so there are general results in particular reason.",
            "There's a question there.",
            "Descript.",
            "Based on the apartment.",
            "Effectiveness.",
            "Imagine that the North attributes are very important classification and how do you include the note?",
            "How do you make sure that your problem or any of this substructure based on distance feature vectors?",
            "OK, so so if I understand your question, I think I wasn't clear about that.",
            "In fact, I assume that my graphs, as you say, of attributes both on the vertices and in fact on the edges.",
            "And what I call a sub graph is an subgraphs attributes.",
            "And what I would like to compute is the presence of a sub graph with attributes as a subgraph of a group with attributes.",
            "So in this picture you see I have a graph with aysan bees and I have one that encodes a bound to A and there will be another one for the feature which is a bound to be for instance.",
            "So clearly in the features we keep track of the attributes.",
            "And of course, this can only work with discrete attributes.",
            "OK, like the type of atoms.",
            "I will not.",
            "I mean you can.",
            "In some cases you have continued such abuse like the electropositivity.",
            "All the things there are different ways to deal with that, including you can make them discrete.",
            "Or you can use kernels, or you can.",
            "Good things, but the attributes are in the features here.",
            "So in fact, all the complexity I mentioned about N, which is the size of the graphs, should be multiplied by the number of attributes and of the vertices and edges in fact.",
            "Sorry.",
            "How does pasta mean?",
            "Sleep mode sticker that you move in Windows.",
            "So sorry, so I mean for the shortest path, I mean the path to the shortest path to have attributes.",
            "OK, and here I said that the shortest path between A&B is AAAB.",
            "OK, so I mean I keep of course the attributes on the.",
            "Vertices of the of the of the path here.",
            "Is there any more question?"
        ],
        [
            "OK. Is it?",
            "How much time should I?",
            "I think it's.",
            "I think I did 2025 pages so I just OK. How long is this?",
            "Let's see, uh, well, if you give me the.",
            "5 to 10 minutes.",
            "I can make the introduction to kernels and then we will.",
            "OK, so.",
            "OK, that's the way I think he's the best.",
            "I know that after lunch it will be much more difficult to give the information to Colonel, so we just give it now.",
            "And in fact we already had some interaction to Colonel.",
            "So I just want to remind you."
        ],
        [
            "I mean by Canon."
        ],
        [
            "And then after lunch I will explain how we make journals.",
            "OK, so what's the magic and the idea of canals?",
            "It's just that we keep the same idea.",
            "So we have a set of objects, like the set of graphs and we want to represent them by vectors.",
            "Except that here we don't focus on the computation of the vectors, we just focus on computing something called the kernel.",
            "So a kernel between two objects, like 2 graphs, is the inner product in the future space.",
            "So you can imagine each graph you compute vectors represented your fire with fire this prime, and you compute the inner product and you obtain a number."
        ],
        [
            "And the famous.",
            "Kernel trick is that sometimes, at least in practice, it's possible to have some efficient computation of the kernel of the inner product.",
            "Without computing the features, and sometimes you cannot even compute features like you can walk in infinite dimensions, so you cannot compute the fireworks, but you can compute firewise scarify of its prime, and therefore you can imagine that with kernels you could enlarge the set of descriptors we can use.",
            "OK, you're not obliged to focus on a limited set.",
            "You can perhaps afford more features.",
            "Therefore kernel can be thought as a way to.",
            "Overcome some of the limitations or practical limitations computational limitations of designing a PC.",
            "Features 1 by 1.",
            "OK, so in particular a question could be I said that in the case of descriptors it's crazy to want to compute the presence of path in a graph.",
            "But now if I did, would say, well, perhaps I can use a camera trick, and even though I cannot compute the descriptors, is too computationally intensive, perhaps I can compute the inner product, then maybe some nice algorithm to compute the inner product and therefore I may be able to work in this space even though I cannot compute the descriptors.",
            "OK, there are many examples of not in the case of graph, but there are many examples of kernels where you can compute the inner product, but you cannot compute the.",
            "The features, so this is I would say the general idea, not only if I will show examples, but this is a generality to not to be limited by the computation of the script."
        ],
        [
            "Cause of patterns.",
            "Now when you think of kennels, well, different people have different, you know, intuition about kernels and I will just write to.",
            "So I will after I will take 2 examples of camels, one photograph and one for Mac arrays and I will try to discuss them with two ideas in mind.",
            "So to choose them, let me just remind you what why we use camels.",
            "And so these are stock was about kennels, kennel kennels, in machine learning.",
            "Typically means that you so you have.",
            "You have a descript you have fire vis, which is a vector to describe your vectors, and then we say that with the kernel you can infer a linear function in the feature space.",
            "OK, so using canals you can solve the problem, which is typically minimizing some empirical risk.",
            "Subject to a constraint on the Euclidean norm of the weight vectors in the feature space, this is typically support vector machine.",
            "This is Kernel Ridge regression.",
            "If you take a different loss.",
            "This is most of machine learning with can also follow this principle.",
            "OK, so I think both things are important in the sense that here we see that the features are important because it means that we work in the space defined by the features.",
            "So clearly when we think of making the kernel, we can think we can think of what are the features I would like to use.",
            "OK, I would like to use this presence of subgraphs address so you can say I will make a kernel in order to encode the presence of many interesting things, but the second part is I think in learning and this was.",
            "Almost clear in the previous talk is that there is a constraint you know you.",
            "You don't only minimize the empirical loss in the feature space, but you minimize it and so often is return as minimizing the empirical loss plus a penalty, and the penalty is the Euclidean norm of the weight vector, and in fact is the construction of the two things that made your learning OK.",
            "So not only should you define good features because you want to see them appear in the classifier, But then you can play in a sense with the metric you know the usual metric.",
            "The weights of the features in order to make the feature appear here."
        ],
        [
            "OK, so it may not be very clear for the Member, but I think there are two ways to.",
            "There are more than two ways, but I will discuss two ways to make kernels.",
            "First idea is.",
            "What features do I want in my kernel?",
            "Like you know, we said I would like to have the all the subgraphs or process can make a counter for subgraphs.",
            "This is 1 ID and another idea which probably is in many cases more relevant in applications is that is to see the kernel as inducing some regularity on the thing you want to estimate.",
            "OK, you say I want to find a classifier.",
            "Which minimizes the loss subject to some constraints, so the constraint is the Euclidean norm in the feature space.",
            "But this corresponds to some penalty in the original space.",
            "OK, and you really can think of a kernel as a way to define a penalty on the weight on the weight vector in the feature space or on the classifier in the original space, and therefore without thinking too much about the features you design just to say I want to make a kernel that induces this penalty which is very similar.",
            "Saying invasion learning on the prior you put on your classifier so you can look at the kernel's putting a prior undercuts failure and then the SVM as maximizing the posterior.",
            "Things.",
            "OK, so.",
            "Are we stop here?",
            "But after lunch we will see an example of in the case of graphs, how can we design kernels by thinking of the features we want to put in the feature space and in the case of microarrays, with the graphs with the jeans and graph, what kind of prior penalty do we want to put on the classifier to make it interpretable at the end?",
            "So and thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So thank you, hello and thanks the organizers for this very nice workshop.",
                    "label": 0
                },
                {
                    "sent": "So before we start and I on announcement would be quite easy.",
                    "label": 0
                },
                {
                    "sent": "It's something you have the right to do right now if you're connected to the web is that my slides are on the web already.",
                    "label": 1
                },
                {
                    "sent": "So if you want to have them during the lecture I will just show you how to do you click on my name and you reach.",
                    "label": 0
                },
                {
                    "sent": "I think my homepage.",
                    "label": 0
                },
                {
                    "sent": "Then on my home page you go to talks.",
                    "label": 1
                },
                {
                    "sent": "And there the Third World, the one at the top, should be this talk and you just click on slides to get the slides OK.",
                    "label": 0
                },
                {
                    "sent": "So that's in case you want to follow it the the thing, so I don't have any link to the Facebook group, which I'm not very good at Facebook, but you could imagine putting in there.",
                    "label": 0
                },
                {
                    "sent": "So yeah, and also that I will try so this is not a real tutorial.",
                    "label": 0
                },
                {
                    "sent": "This is more.",
                    "label": 0
                },
                {
                    "sent": "I mean, I tried to make it look like a bit trying to tell you something in the shape of a course or tutorial, but obviously is very biased to what what I do myself is my colleagues and I will try through a few applications to explain you a few techniques that we and many others have been developing over the recent years.",
                    "label": 0
                },
                {
                    "sent": "To solve problems, so I will just focus on one problem which is supervised classification.",
                    "label": 1
                },
                {
                    "sent": "For data with structures, so as in all said, there would be a lot of graphs, but not only and I will try to show a bit how it relates to what we've been saying.",
                    "label": 0
                },
                {
                    "sent": "The rest of the week.",
                    "label": 0
                },
                {
                    "sent": "I mean, we've been looking at that, but we've also been talking of finding patterns so they're actually links.",
                    "label": 0
                },
                {
                    "sent": "Ann, I hope to be able to show you that there are increasingly increasing links between, let's say, the machine learning and knowledge discovery communities in the sense that more and more we need efficient algorithms too.",
                    "label": 0
                },
                {
                    "sent": "To solve optimization problems that occur in machine learning and to solve them, we more and more can use well known aggressors that existing data mining.",
                    "label": 0
                },
                {
                    "sent": "So I try to give you a taste of what it is and I think this is a quite hot topic in these days.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So, to clarify, let's take a few examples and I will try to keep these examples throughout the talk and show you how we can solve them in different ways.",
                    "label": 0
                },
                {
                    "sent": "So the first example is a very crucial one in drug discovery to find drugs.",
                    "label": 1
                },
                {
                    "sent": "So if you go to pharmaceutical company they want to make new medicines to solve to cure diseases and among the drug discovery process.",
                    "label": 1
                },
                {
                    "sent": "There is one part of the process which can be done with computers or where computers can help is called globally virtual screening.",
                    "label": 0
                },
                {
                    "sent": "And the idea is to say that basically so classical drug is just a small molecule, and on this picture you can.",
                    "label": 0
                },
                {
                    "sent": "You can see several small molecules, so I just show six of them.",
                    "label": 0
                },
                {
                    "sent": "But in fact if you go to a famous car companies, you have millions of them in databases and what the people do in these companies are typically testing some of those molecules to check if there are some effects on the disease or if they hit the target or the things so you can do that with hundreds of thousands or thousands of molecules.",
                    "label": 0
                },
                {
                    "sent": "You do the tests and you measure the efficiency.",
                    "label": 0
                },
                {
                    "sent": "And after some sometime in some money spent you can end up with such databases where you have lists of molecules and some have been detected to be active or let's say they have an effect positive effect that you want to induce like stop the disease progression and some don't.",
                    "label": 0
                },
                {
                    "sent": "And then instead of, you know, testing all the millions of miracles they have in their databases.",
                    "label": 0
                },
                {
                    "sent": "Plus the billions once they could generate, we can imagine using computers to take this as input.",
                    "label": 0
                },
                {
                    "sent": "You know taking the database is the database of molecules with an activity and try to make a model to check if from the structure only we could be able to predict whether a numeric will be active or not.",
                    "label": 0
                },
                {
                    "sent": "So obviously if we can do that, well we can speed up the screening process and we can also.",
                    "label": 0
                },
                {
                    "sent": "Generate new molecules that we predict could be active and therefore a quicker detection of molecules of potential drugs and also cheaper one.",
                    "label": 0
                },
                {
                    "sent": "OK, so when you see it from a machine learning point of view is just saying that you have a set of.",
                    "label": 0
                },
                {
                    "sent": "In this case it looks like graphs.",
                    "label": 0
                },
                {
                    "sent": "So from your graph will typically be molecule is seen as a graph when you see the atoms as the notes of the graphs and when you have a bond between atoms it becomes an edge of the graph.",
                    "label": 0
                },
                {
                    "sent": "So this is clearly what this picture shows.",
                    "label": 0
                },
                {
                    "sent": "So you have graphs, some of label positives and have a label negative and you want to train the model that will be later able to predict for a new molecule, and you graph whether it's active or not.",
                    "label": 0
                },
                {
                    "sent": "So by the way, I will mostly talk off by informatic, but just a single slide to say that if you're not in this business, you may be interested too in what I would say, for instance, colleagues of mine in Paris or France is back and say dash, we are using basically the same methods for image classification, so it's just one among many possibilities.",
                    "label": 0
                },
                {
                    "sent": "Many ways to represent objects as graphs.",
                    "label": 0
                },
                {
                    "sent": "So in this case you can say that when you have an image, suppose you have an image of what we describe an image, so an image is a set of pixels, but a set of pixels.",
                    "label": 0
                },
                {
                    "sent": "It's not very important informative, so there are many ways to extract descriptors for images and one approach representing images to 1st do a segmentation of the image into uniform regions and then to consider graph where each region is an odd and you put an edge between two regions which are adjusted to each other on the picture.",
                    "label": 0
                },
                {
                    "sent": "So that's just one among many ways to represent one image by graph.",
                    "label": 0
                },
                {
                    "sent": "OK, but in this graph of course we have the structure of the graph, which is important.",
                    "label": 0
                },
                {
                    "sent": "It represents the relative positions of the signals an each.",
                    "label": 0
                },
                {
                    "sent": "Now that each vertex itself contains a lot of information, you can summarize a region by the average color or some detectors, etc, and then so similar to my molecules, you can have machine learning problems in images like you know making a model that is able to differentiate between the pictures that contain an airplane and features and container.",
                    "label": 0
                },
                {
                    "sent": "Animal, and this is the same for more problem of graphs with positive and negative labels and you want to make a model to discriminate between the two graphs.",
                    "label": 0
                },
                {
                    "sent": "OK, so this this problem will be one that I will try to try to keep in mind and I will show different ways to solve it.",
                    "label": 0
                },
                {
                    "sent": "Of course there are many other ways, but I will focus on a few strategies at least to explain.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "How we can do that?",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Second type of problem that I will try to discuss is a is a well known problem in bioinformatics.",
                    "label": 0
                },
                {
                    "sent": "We probably have heard about that it's about microarrays, so I will explain it later what microarrays are but typically in cancer diagnosis where I tried to work on, we can take patient with cancer extracted from the numerous small sample and measure on this sample what's called the expression of the genes so we can.",
                    "label": 0
                },
                {
                    "sent": "End up for each tomorrow with a vector of descriptors that contains several 10s of thousands of numbers which are the level of expression of all the genes and typical problem we are facing.",
                    "label": 0
                },
                {
                    "sent": "We are facing are when you have two types of tumors, like in this case which is a well known example, you have two types of leukemias with different outcomes and different treatments and what you would like to do is from the measurements.",
                    "label": 0
                },
                {
                    "sent": "So you take a sample of blood in this case and from the measurement of the expression data you would like to be able to predict to classify your cancer's.",
                    "label": 0
                },
                {
                    "sent": "ALLOAML and then to be able to adapt the treatment to the case.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is a well known problem.",
                    "label": 0
                },
                {
                    "sent": "It has been well known in the last, let's say 10 years or so in statistique cause it's well known that is complex because you have many features and a few small number of samples.",
                    "label": 0
                },
                {
                    "sent": "So it's sometimes cause a small energy problem.",
                    "label": 0
                },
                {
                    "sent": "And what I would like to discuss in this in this talk is how to include some prior knowledge you may have, because in this case.",
                    "label": 0
                },
                {
                    "sent": "I know the features are the genes will explain what these are, but you have 20,000 genes in human cell and these jeans are not just 20,000 features independent features.",
                    "label": 0
                },
                {
                    "sent": "We know that many of the genes.",
                    "label": 0
                },
                {
                    "sent": "Work together or some regulate each other or there out of knowledge about the jeans and typically one knowledge we can have about the jeans.",
                    "label": 0
                },
                {
                    "sent": "So this kind of graph.",
                    "label": 0
                },
                {
                    "sent": "So this graph on the right is a is a graph is a network where each node is a gene, so you know imagine that each node of this graph is 1 feature of this of this business and the question becomes, you could either just use these metrics to train a model to discriminate between LML and say you have 20,000 features, or you could try to say I have the data.",
                    "label": 0
                },
                {
                    "sent": "Plus I have the prior knowledge.",
                    "label": 0
                },
                {
                    "sent": "In this case, that some of the features are linked to each other and I will try to to discuss the question, how can we use this prior knowledge so the features line on the graph which is given a priori, how can we use this knowledge in order perhaps to help the computer learner nice discrimination?",
                    "label": 0
                },
                {
                    "sent": "OK, so in this case we have high dimensional data with two samples, but a lot of prior knowledge which which can be in the.",
                    "label": 0
                },
                {
                    "sent": "In this case there wouldn't be a graph.",
                    "label": 0
                },
                {
                    "sent": "Sorry.",
                    "label": 0
                },
                {
                    "sent": "So in this precise picture, the edges.",
                    "label": 0
                },
                {
                    "sent": "So in this picture the jeans are what are called enzymes.",
                    "label": 0
                },
                {
                    "sent": "OK and I mean OK for those of you know what ends up so you have jeans called enzymes and the edge here means that two enzymes work together in the pathway.",
                    "label": 0
                },
                {
                    "sent": "I will tell more details later.",
                    "label": 0
                },
                {
                    "sent": "OK, but you can imagine other semantics like another one on network is when you have physical interactions.",
                    "label": 0
                },
                {
                    "sent": "So the genes make proteins and proteins can bind to each other and you can present this as a graph and say that I represent the set of all proteins and indicate which one can bind to each other and this tells me which one are working with each other.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Finally, a last example that we also discuss is also related to this case to cancer diagnosis and prognosis, so again about classification of tumors.",
                    "label": 0
                },
                {
                    "sent": "OK, we talk of diagnosis when we want to identify what class of tomorrow we have and we talk of prognosis when we want to predict what's going to happen in the future like this to know will give metastasis, and this one will not, so you can adapt the treatment so in prognosis.",
                    "label": 0
                },
                {
                    "sent": "So you want to predict the future of the tumors.",
                    "label": 0
                },
                {
                    "sent": "You can also use gene expression data and it's often used, but there are other data you can use in for instance in this picture.",
                    "label": 0
                },
                {
                    "sent": "So it's a bit hard to see, but these are other measures we can do on the tumors.",
                    "label": 0
                },
                {
                    "sent": "So in this case it's called comparative genomic hybridization, CGH, and what you see.",
                    "label": 0
                },
                {
                    "sent": "So each think of each signal here is 1 one tomorrow.",
                    "label": 0
                },
                {
                    "sent": "So here you have five aggressive tumor on the left and five non aggressive tumors on the right.",
                    "label": 0
                },
                {
                    "sent": "And what do we measure is along the genome.",
                    "label": 0
                },
                {
                    "sent": "The number of copies of DNA present in the cells.",
                    "label": 0
                },
                {
                    "sent": "Again, I will explain a bit more later what what it means, but it turns out that in in tumors, so in a normal cell in most of your cells you have two copies of each chromosome.",
                    "label": 0
                },
                {
                    "sent": "You know that's the basic thing we know, and if you take a sample of tomorrow, you don't have two copies.",
                    "label": 0
                },
                {
                    "sent": "Some chromosomes are 3 * 4 * 5 times, etc, and we can measure that.",
                    "label": 0
                },
                {
                    "sent": "So if you plug the number of copies along the genome and end up with a.",
                    "label": 0
                },
                {
                    "sent": "Kind of time series.",
                    "label": 0
                },
                {
                    "sent": "So in the X axis is the position in the genome, and Weibel to measure.",
                    "label": 0
                },
                {
                    "sent": "If it's flat.",
                    "label": 0
                },
                {
                    "sent": "So if that would mean that you have a normal genome and sometimes so.",
                    "label": 0
                },
                {
                    "sent": "If you look here for instance in this.",
                    "label": 0
                },
                {
                    "sent": "In this case you see that almost all your genome is OK, but you have a region where you have negative numbers.",
                    "label": 0
                },
                {
                    "sent": "Probably the chromosomes have disappeared.",
                    "label": 0
                },
                {
                    "sent": "Here the jeans are lacking there, and some regions are in larger numbers.",
                    "label": 0
                },
                {
                    "sent": "You don't have two, but probably 3 or 4 copies, and so this is one way to characterize a team or two, and it's well known that this is related to the aggressiveness of the tumor.",
                    "label": 0
                },
                {
                    "sent": "So we are confronted, typically with a machine learning problem where.",
                    "label": 0
                },
                {
                    "sent": "The X, you know the data are profiles like this and we want to discriminate between the profiles on the left and profiles on the right.",
                    "label": 0
                },
                {
                    "sent": "And again, you could say, well, profile is just a set of numbers.",
                    "label": 0
                },
                {
                    "sent": "You could say if I have here 2000 measurements, you can say I have a vector dimension 2000, but obviously there is a structure here.",
                    "label": 0
                },
                {
                    "sent": "OK, we can call that a pattern we would like to see in this kind of time series.",
                    "label": 0
                },
                {
                    "sent": "What is other some patterns which allow us to discriminate between aggressive and non aggressive tumors and pattern will typically be identified regions where sort of the overexpression of original over copy number of origin could be predictive.",
                    "label": 0
                },
                {
                    "sent": "And then we can go back to the biology check which genes are in this region and perhaps just some better other disease.",
                    "label": 0
                },
                {
                    "sent": "What do the numbers mean?",
                    "label": 0
                },
                {
                    "sent": "Job, not integers?",
                    "label": 0
                },
                {
                    "sent": "I mean can their specialty Navy half press?",
                    "label": 0
                },
                {
                    "sent": "I mean how?",
                    "label": 0
                },
                {
                    "sent": "So yes, yes and no.",
                    "label": 0
                },
                {
                    "sent": "So first the number.",
                    "label": 0
                },
                {
                    "sent": "So here the numbers to be precise are log ratios.",
                    "label": 0
                },
                {
                    "sent": "OK, so 0 means that you are normal, typically log ratio compared to a normal cell.",
                    "label": 0
                },
                {
                    "sent": "So there are supposed to be you are.",
                    "label": 0
                },
                {
                    "sent": "You have two copies.",
                    "label": 0
                },
                {
                    "sent": "And then you can have 345.",
                    "label": 0
                },
                {
                    "sent": "Now what you observe is that you don't have just, you know, discrete set of numbers is not log of three log of Forks iterates more complex, at least two reasons.",
                    "label": 0
                },
                {
                    "sent": "One is that the technology is not perfect, so we have noise and it may not be very well.",
                    "label": 0
                },
                {
                    "sent": "Scale and the other regions.",
                    "label": 0
                },
                {
                    "sent": "Which is more important is that when you take a sample, the cells are not all the same.",
                    "label": 0
                },
                {
                    "sent": "You know you take.",
                    "label": 0
                },
                {
                    "sent": "Let's say you take you have a breast tumor.",
                    "label": 0
                },
                {
                    "sent": "You extract budget sample and you have thousands of cells and they are not all the same.",
                    "label": 0
                },
                {
                    "sent": "But when you do these experiments you miss them altogether and you extract the DNA.",
                    "label": 0
                },
                {
                    "sent": "OK, So what you observe is more mixture of several cells from my F2 copies and I have 3 copies and therefore you end up with some average again.",
                    "label": 0
                },
                {
                    "sent": "OK, so these are all the examples I will try to solve.",
                    "label": 0
                },
                {
                    "sent": "So what's coming here is that in all these cases, from theoretical point of view you have data and you want data with labels to possible labels and you want to discriminate them.",
                    "label": 0
                },
                {
                    "sent": "OK, so it's well known.",
                    "label": 0
                },
                {
                    "sent": "Probably you know that you can say that we have a supervised classification problem in the sense that we have.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So in this picture, white points and black points, so this could be active versus non active molecules, accuracy versus non aggressive tumors, or LL versus animal cetera.",
                    "label": 0
                },
                {
                    "sent": "And what we would like to do at the.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And in our case is find a way to discriminate them.",
                    "label": 0
                },
                {
                    "sent": "So find a rule to separate the white from the Black Ann in the spirit of machine learning.",
                    "label": 0
                },
                {
                    "sent": "What we want is not only to separate them, but more importantly to have a predictive model.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Which would be able in the future step in the future to to associate a label to new data like.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Two new points here and you would like to predict that the white is white and the black is black.",
                    "label": 0
                },
                {
                    "sent": "OK, so it's not only making a difference, but it's making a predictive model that we have predictive power.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Typically in all the all the problems I have shown are classical problems.",
                    "label": 0
                },
                {
                    "sent": "You know machine learning is an all topic.",
                    "label": 0
                },
                {
                    "sent": "You have a lot of methods to do that.",
                    "label": 0
                },
                {
                    "sent": "What's a bit difficult in this case is that there are a few features shared by some or all of these problems.",
                    "label": 0
                },
                {
                    "sent": "So in some cases we are in very high dimensions, so machine learning is not supposed to work very well in high dimension.",
                    "label": 0
                },
                {
                    "sent": "And when you have 20,000 genes while you have them, so perhaps you should keep them and find algorithm that work in high dimension.",
                    "label": 0
                },
                {
                    "sent": "This is often combined with the fact that we have few samples, so this is the.",
                    "label": 0
                },
                {
                    "sent": "Large P small N problem with few samples in high dimension is not an easy situation.",
                    "label": 1
                },
                {
                    "sent": "What's interesting in particularly relevant for this workshop is that some of the data structures and infrastructure can help us overcome the problem of dimensionality.",
                    "label": 0
                },
                {
                    "sent": "Will see how, but by structure I mean that you know the graph will.",
                    "label": 0
                },
                {
                    "sent": "Typically the graphs are not vectors.",
                    "label": 0
                },
                {
                    "sent": "I kind of talk of the dimension of a graph is just an object, so there is a structure, but even the SGH professor, the time series you can see them as vectors.",
                    "label": 0
                },
                {
                    "sent": "But there is some structure behind that you could say it's a noisy version of a piecewise constant thing, etc.",
                    "label": 0
                },
                {
                    "sent": "So you can start to think of replacing the notion of dimension by national.",
                    "label": 0
                },
                {
                    "sent": "Torture.",
                    "label": 0
                },
                {
                    "sent": "I will skip the national federations data, which is also important, but not the topic of my talk.",
                    "label": 0
                },
                {
                    "sent": "And in all these cases too.",
                    "label": 1
                },
                {
                    "sent": "In fact, we have a lot of prior knowledge.",
                    "label": 0
                },
                {
                    "sent": "So I talk of the pronunciation of the interactions between the genes.",
                    "label": 0
                },
                {
                    "sent": "When you have 20,000 genes or when you have the time series, your prior knowledge can be that you measure things along the genome so you know that there could be some constraint coming from the fact that you are in the genome.",
                    "label": 0
                },
                {
                    "sent": "So you could try to average, for instance, of our windows.",
                    "label": 0
                },
                {
                    "sent": "So these are prior knowledge you have about the data.",
                    "label": 0
                },
                {
                    "sent": "ETC and OK. Of course we would like so one of the discussion I will have is that we want to have.",
                    "label": 0
                },
                {
                    "sent": "Real implementations of the methods, so in particular would be able to compute the things fast enough, which is not always the case.",
                    "label": 0
                },
                {
                    "sent": "In particular case of the graphs we will see that one of the main bottlenecks today is that we can imagine many descriptors, but we cannot compute them efficiently, so we have to find tradeoffs between what we want to do and what we can do.",
                    "label": 0
                },
                {
                    "sent": "And finally, and this is also rated in all these cases, we want to have a good predictive power.",
                    "label": 0
                },
                {
                    "sent": "So we want to have a model that does a good job at predicting who will be black would be white, but also would like to have some models that we can interpret, like extracting knowledge from the model.",
                    "label": 0
                },
                {
                    "sent": "And this is, I think.",
                    "label": 0
                },
                {
                    "sent": "Completely related to the topic of, you know, finding patterns in the data, so I will not talk more about that, but I think this is a very important point that in the discussion of how to extract patterns from points, you know if I come back to the exam.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Rules of example of molecules.",
                    "label": 0
                },
                {
                    "sent": "One approach is to say OK, I'll take all the active molecules and I strike to frequent subgraphs, for instance, and this could be an interesting pattern because it's often frequent, let's say often frequently active and often not often frequented inactive.",
                    "label": 0
                },
                {
                    "sent": "So this is one way to do, and many people do that.",
                    "label": 0
                },
                {
                    "sent": "Here what I will focus about is more about creating a model that will be predictive, so be able to see.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The positive from the negative and then try to understand what if the model is good, then it should contain interesting information and typically it could be based on the presence of some subgraphs or some other graphs, and these ones will not.",
                    "label": 0
                },
                {
                    "sent": "Always be the ones which are frequent or not, because there will be more.",
                    "label": 0
                },
                {
                    "sent": "The ones which are useful for the prediction.",
                    "label": 0
                },
                {
                    "sent": "OK, this is slightly different so I would say that an obvious link between the machine learning approach and the pattern Discovery approach is that in the machine learning approach, probably we try to extract patterns not directly but based on.",
                    "label": 0
                },
                {
                    "sent": "Based on the idea that if we have a good classifier that it should be based on some interesting features that then we can look at.",
                    "label": 0
                },
                {
                    "sent": "OK, so let's.",
                    "label": 0
                },
                {
                    "sent": "So I will try to keep these examples in nine entry, then one by one along along the discussion.",
                    "label": 0
                },
                {
                    "sent": "But let's try to be just a little bit formal too, because we just to set up the notation, etc.",
                    "label": 0
                },
                {
                    "sent": "So here's what we want to solve.",
                    "label": 0
                },
                {
                    "sent": "Our problems of supervised classification, so I assume that I will call X the data disk and your graph vectorized version or whatever, and why the class which.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In this case, would be binary, even though what are second you apply to regulation etc.",
                    "label": 0
                },
                {
                    "sent": "We assume that we have a training set, so a training set is is a pair is a set of pairs XY.",
                    "label": 1
                },
                {
                    "sent": "Like a molecule with active or inactive, this is 1 example and I have many of them.",
                    "label": 1
                },
                {
                    "sent": "And my goal is from this training set to estimate a function F. That will be able to predict the label Y of an example X by every weeks.",
                    "label": 1
                },
                {
                    "sent": "And ideally we would not have to be so after training would like to get a function F that is both accurate.",
                    "label": 0
                },
                {
                    "sent": "So give good predictions an interpretable this is a difficult tradeoff.",
                    "label": 0
                },
                {
                    "sent": "But this is weird.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So you can take any book on machine learning to find many examples of ways to build a function F, and that in fact I will just focus on one particular case of functions, which of classifiers which are linear classifiers so you know already make a big.",
                    "label": 0
                },
                {
                    "sent": "Just focus on the tiny part of the machine learning world, let's say OK, I just focus on linear function, even though with kernels and there was a talk about kernels earlier in the week, we know that if we have things for linear functions at least using the kernels, we can have nonlinear functions too, but I will focus on look at the kind of functions which are generated by linear functions, which means that the kind of things that will investigate our.",
                    "label": 0
                },
                {
                    "sent": "I have an object X which is any object an what I mean by linear function is that from this object.",
                    "label": 0
                },
                {
                    "sent": "Next we will extract descriptors or patterns or features.",
                    "label": 1
                },
                {
                    "sent": "I don't know which one is the most correct, but we will extract a set set of patterns.",
                    "label": 0
                },
                {
                    "sent": "And I don't say if peace finite or infinite, because again normally it should be finite.",
                    "label": 0
                },
                {
                    "sent": "But if we use kernels, it could be infinite.",
                    "label": 1
                },
                {
                    "sent": "OK, so let's just say that we have a vector of the scriptures and the set of functions.",
                    "label": 0
                },
                {
                    "sent": "I will consider our functions ever fix which are linear combination of the descriptors.",
                    "label": 1
                },
                {
                    "sent": "So typically the sum of beta I time F of X, Fire, Fire, victory and so the goal is so there.",
                    "label": 0
                },
                {
                    "sent": "So here we have a training set and the goal is to estimate function beta an F will be so.",
                    "label": 0
                },
                {
                    "sent": "In this case, real valued and you can threshold it to 0 to have position positive or negative.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so obviously there are two important questions which seem to be unrelated, but I think which are very related to each others and I will try to explain why.",
                    "label": 0
                },
                {
                    "sent": "The first one is how to design the features.",
                    "label": 1
                },
                {
                    "sent": "Typically I give you the molecules can represent a molecule as a vector.",
                    "label": 0
                },
                {
                    "sent": "How do you choose the descriptors, the features and the second question is, once you have chosen the representation as vector, how do you infer the model?",
                    "label": 0
                },
                {
                    "sent": "So you could say, well, once I have a vector, I apply your support vector machine.",
                    "label": 0
                },
                {
                    "sent": "This is one way to do or I do FDA.",
                    "label": 0
                },
                {
                    "sent": "This is another way to do or I do something else.",
                    "label": 0
                },
                {
                    "sent": "It turns out that the two steps are not independent in the sense as, which as we see that there are.",
                    "label": 0
                },
                {
                    "sent": "There are some descriptors you can use with less so, but none with VM's for instance, and there are descriptors you can use with SVN, but not with us all or with boosting, so it's not obvious at first sight, but because of the structure of the algorithms there are things you can do with different algorithms and with different descriptors.",
                    "label": 0
                },
                {
                    "sent": "But so basically the.",
                    "label": 0
                },
                {
                    "sent": "The rest of the talk will be devoted to talking about these questions.",
                    "label": 0
                },
                {
                    "sent": "What are the ideas?",
                    "label": 0
                },
                {
                    "sent": "What are the currents?",
                    "label": 0
                },
                {
                    "sent": "I dies in the community to define strategies to design the features an and learn the weights from the training set.",
                    "label": 1
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So to be more precise, this is the outline of the rest of the of the talk, so I will talk of three ideas.",
                    "label": 0
                },
                {
                    "sent": "Basically, the first one will be the shortest parts, it's OK. Let's compute explicitly descriptors, so give me a graph and I give you a list of things you can compute.",
                    "label": 0
                },
                {
                    "sent": "Let's say 100 descriptors, and then you compute them and you take your book on machine learning or your toolbox and machine learning, you run any algorithm on that.",
                    "label": 0
                },
                {
                    "sent": "OK, so I will just focus on the case of graph.",
                    "label": 1
                },
                {
                    "sent": "To illustrate that there are the scriptures which you can compute and descriptors which you cannot compute.",
                    "label": 0
                },
                {
                    "sent": "In particular will focus on the ones you cannot compute to show that it's not so obvious to do.",
                    "label": 0
                },
                {
                    "sent": "Let's set represent a graph by your vector.",
                    "label": 0
                },
                {
                    "sent": "OK, but that's the first idea.",
                    "label": 0
                },
                {
                    "sent": "Just make a list of descriptors, compute them and run your machine learning.",
                    "label": 0
                },
                {
                    "sent": "Then I will spend some time on now a famous way to do which is using kernels.",
                    "label": 1
                },
                {
                    "sent": "So the main result gave a nice introduction to can.",
                    "label": 0
                },
                {
                    "sent": "Also the main idea here is that we know that we can often do more with kernels then with explicit computation of features, and we know many examples where you know for instance OK Now can be seen as some inner product in space where the dimension can be hard and you don't need to compute the descriptors.",
                    "label": 0
                },
                {
                    "sent": "So clearly one natural ideas to say that.",
                    "label": 0
                },
                {
                    "sent": "If you are stuck with a small number of descriptors, if you need to compute them, perhaps you can move to the space of kernels and design kernels to be able to work in spaces with many features.",
                    "label": 0
                },
                {
                    "sent": "So we see that it's possible, but not always.",
                    "label": 0
                },
                {
                    "sent": "And see about some limitations.",
                    "label": 0
                },
                {
                    "sent": "I said in the case of graphs and another case of G networks.",
                    "label": 0
                },
                {
                    "sent": "The third strategy I will discuss is something which is very fashionable these days in the machine learning communities.",
                    "label": 0
                },
                {
                    "sent": "If you go to the conferences or whatever, it's saying that OK candles are nice, but in a sense so they are nice in some cases and are very powerful.",
                    "label": 0
                },
                {
                    "sent": "But with kernels it's very hard to have interpretable model.",
                    "label": 0
                },
                {
                    "sent": "This is one of many mutation you have.",
                    "label": 0
                },
                {
                    "sent": "Seems a bit like a black box like I have a next model to predict the activity of molecules, but what are the important substructures you don't know?",
                    "label": 0
                },
                {
                    "sent": "So there is another strategy that which is not new but which is gaining a lot of attention which is feature selection and in particular features.",
                    "label": 0
                },
                {
                    "sent": "So feature session is that you start from a list of many candidate features and you build a model based on just a few features.",
                    "label": 0
                },
                {
                    "sent": "OK, it's not.",
                    "label": 0
                },
                {
                    "sent": "It's not a new idea, but what's a bit new is the algorithms used to do that.",
                    "label": 0
                },
                {
                    "sent": "In particular convex algorithms like the using the what we call the L1 penalty that I will explain what it is and more and more what we see is that you can do not only feature selection, but if you have prior knowledge.",
                    "label": 0
                },
                {
                    "sent": "About the features like the features are nodes of a graph or they are along the genome.",
                    "label": 0
                },
                {
                    "sent": "Then you can extend the notion of sparsity.",
                    "label": 1
                },
                {
                    "sent": "So feature selection to expression of patterns.",
                    "label": 0
                },
                {
                    "sent": "OK, so we discuss a bit how you can encode, let's say penalties that allow you with some convex optimization problem to extract classification rules.",
                    "label": 0
                },
                {
                    "sent": "So let's say 2 twin further vectors which not only are sparse but kind of specific structure like being piecewise constant or are being sparse.",
                    "label": 0
                },
                {
                    "sent": "Level of subnetworks, etc.",
                    "label": 0
                },
                {
                    "sent": "So I think this is a very.",
                    "label": 0
                },
                {
                    "sent": "Interesting direction, and in this part I will also explain a bit that some people recently have proposed method to combine sparsity with.",
                    "label": 0
                },
                {
                    "sent": "Mining of how you call that data.",
                    "label": 0
                },
                {
                    "sent": "Mining of substructures like using the apriori algorithm as a subroutine to boosting in order to do sparse running in the space of subgraphs etc.",
                    "label": 0
                },
                {
                    "sent": "So I think there is a strong link here between machine learning that uses a SGML boosting an mining Africans frequent subgraphs, for instance because one can be seen as a subroutine of the other one, and therefore end up with efficient algorithms to work in huge spaces.",
                    "label": 0
                },
                {
                    "sent": "And then after that, if you're not too tired, I will conclude.",
                    "label": 0
                },
                {
                    "sent": "So I must say that I have 114 slides, but I don't plan to talk of all the slides.",
                    "label": 0
                },
                {
                    "sent": "I will do a selection but you can look at the size and we can discuss after the workshop.",
                    "label": 0
                },
                {
                    "sent": "If you're interested to discuss more.",
                    "label": 0
                },
                {
                    "sent": "OK, are there any questions at this?",
                    "label": 0
                },
                {
                    "sent": "About this, so again, this is not a real cross.",
                    "label": 0
                },
                {
                    "sent": "You know it's heavily biased to what what we did and what I know other people did, but it's not supposed to be fine in general.",
                    "label": 0
                },
                {
                    "sent": "Introduction to the topic.",
                    "label": 0
                },
                {
                    "sent": "So if there's no.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The question let's start with the first idea, which is let's say the simplest one.",
                    "label": 0
                },
                {
                    "sent": "OK, we have data, so normal ideas from data.",
                    "label": 0
                },
                {
                    "sent": "You you extract descriptors and then you run machine learning on them so.",
                    "label": 0
                },
                {
                    "sent": "Yes, there is a question.",
                    "label": 0
                },
                {
                    "sent": "OK, so mother you are.",
                    "label": 0
                },
                {
                    "sent": "Is that more like you know, general ratchet across places?",
                    "label": 0
                },
                {
                    "sent": "Play music from this morning.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "So I will talk about discriminative model.",
                    "label": 0
                },
                {
                    "sent": "So all these things will be about.",
                    "label": 0
                },
                {
                    "sent": "Let's say these are.",
                    "label": 0
                },
                {
                    "sent": "This problem you have black points and white points and what I will discuss so I will try to combine the discussion of how to make descriptors and how to infer the weights in the case of linear models.",
                    "label": 0
                },
                {
                    "sent": "OK, so these are all discriminative models linear based on features.",
                    "label": 0
                },
                {
                    "sent": "And we focus on a few examples.",
                    "label": 0
                },
                {
                    "sent": "Classification of graphs or expression data, or the things that try to highlight some general principles, and I think 3 general principles that can think about our computer explicitly descriptors and run machine learning or use kernels, or use sparse running innocence.",
                    "label": 0
                },
                {
                    "sent": "And I will try just three straight through examples, but it can give on practical things.",
                    "label": 0
                },
                {
                    "sent": "But it's all discriminative and it's all based on descriptors and in our functions.",
                    "label": 0
                },
                {
                    "sent": "OK, so let's start with the 1st.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the first strategy we have, data, and we represent the data by your vector.",
                    "label": 0
                },
                {
                    "sent": "OK, so typically I will just focus on one example which is classification of graph just to show that it's not.",
                    "label": 0
                },
                {
                    "sent": "So there's nothing very new here, but it's not easy to do that like here.",
                    "label": 0
                },
                {
                    "sent": "You have graphs, so you have active and nonactive graphs you would like to use your machine and tool box so and ideas you present a graph by your vector.",
                    "label": 0
                },
                {
                    "sent": "So let's say one dimension could be.",
                    "label": 0
                },
                {
                    "sent": "I count how many carbon atoms there are.",
                    "label": 0
                },
                {
                    "sent": "This is 1 descriptor.",
                    "label": 0
                },
                {
                    "sent": "I count how many aromatic bounds cycles they are.",
                    "label": 0
                },
                {
                    "sent": "This is another script, or you can.",
                    "label": 0
                },
                {
                    "sent": "Some things you can measure things, then you present a graph by your vector.",
                    "label": 0
                },
                {
                    "sent": "You have a matrix of the scriptures and graphs and then you run the machine learning algorithm.",
                    "label": 0
                },
                {
                    "sent": "So first, I mean before I spend, it's not obvious.",
                    "label": 0
                },
                {
                    "sent": "I would like to to say an important message which is a bit unfortunate but important.",
                    "label": 0
                },
                {
                    "sent": "In my talk, it will look like this is not very fancy and not very good idea to do SPC descriptors OK, because I will explain how to make fancy kernels and fancy sparse running.",
                    "label": 0
                },
                {
                    "sent": "In practice, when you have to solve the problem like this problem from my experience and from discussion with other people, by far the best idea is to think of the good descriptors sense that.",
                    "label": 0
                },
                {
                    "sent": "You know you could.",
                    "label": 0
                },
                {
                    "sent": "There is a trend in machine learning saying OK, we make many descriptors, and we have Instagrams and we compare algorithms on the set of also grass etc.",
                    "label": 0
                },
                {
                    "sent": "At the end.",
                    "label": 0
                },
                {
                    "sent": "If you have the good descriptor than any algorithm will find a good classifier and will be interpretable.",
                    "label": 0
                },
                {
                    "sent": "So I will just try to say that it's not because in my talk is a short part and not very fancy.",
                    "label": 0
                },
                {
                    "sent": "One that is not important in practice.",
                    "label": 0
                },
                {
                    "sent": "There are many cases, many machine learning problems where you should better spend time two months designing a good feature than two months.",
                    "label": 0
                },
                {
                    "sent": "Making a new kernel and training multiple kernel learning and these things OK, so it's a bit unfortunate, but I think it's fair to say that the constructional feature is not.",
                    "label": 0
                },
                {
                    "sent": "It's not a bad business, it's very crucial.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, So what about the case of graphs?",
                    "label": 0
                },
                {
                    "sent": "So here suppose we have the space of graphs on the left.",
                    "label": 0
                },
                {
                    "sent": "While I say is that we're going to make.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Descriptors so we can.",
                    "label": 0
                },
                {
                    "sent": "We're going to map each graph into a vector space.",
                    "label": 1
                },
                {
                    "sent": "I call it H here, but let's say a finite dimensional vector.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then we run some algorithm there to separate the blue from the.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In fact, this is what is done every day in every pharmaceutical company like you can buy a software from.",
                    "label": 0
                },
                {
                    "sent": "Open AI is a company that is very successful and and that represents.",
                    "label": 0
                },
                {
                    "sent": "So here in this picture that represents a graph here.",
                    "label": 0
                },
                {
                    "sent": "So a molecule here by your vector.",
                    "label": 1
                },
                {
                    "sent": "So here in fact it's a vector of binary indicators.",
                    "label": 0
                },
                {
                    "sent": "It's because it's small to store in memory, and it's based on the detection of the presence of substructures in your graph.",
                    "label": 1
                },
                {
                    "sent": "So what the company did is design A set of.",
                    "label": 0
                },
                {
                    "sent": "I think something like 900 basic structures they think are important to represent the molecule and then they have a fast algorithm.",
                    "label": 0
                },
                {
                    "sent": "When you take a new molecule as input described by the fire noise coming through to compute the fingerprint, which is a set of bits 100101 that just checks if each of these 900 substructure is in the graph.",
                    "label": 0
                },
                {
                    "sent": "And then once you have these descriptors, you run support vector machine on your networks or DLS or PLSS.",
                    "label": 0
                },
                {
                    "sent": "Popular in came in for Matics or whatever you want.",
                    "label": 0
                },
                {
                    "sent": "OK so this is basically the state of the art.",
                    "label": 0
                },
                {
                    "sent": "In practical applications you gotta companies is what's done is not the only way to represent as a vector.",
                    "label": 0
                },
                {
                    "sent": "This is a popular one.",
                    "label": 0
                },
                {
                    "sent": "But in fact you have you have a book called the Handbook of Molecular Descriptor.",
                    "label": 0
                },
                {
                    "sent": "I think there are 600 pages of features you can compute.",
                    "label": 0
                },
                {
                    "sent": "OK, so there's a big community dedicated to what you can compute from.",
                    "label": 0
                },
                {
                    "sent": "A miracle and then use that as input feature.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "But OK here.",
                    "label": 0
                },
                {
                    "sent": "Obviously I mean you can buy the software from the company, but you could also think of the process.",
                    "label": 1
                },
                {
                    "sent": "How did they end up with this list of features?",
                    "label": 0
                },
                {
                    "sent": "Are they good or not so perfect there were good cause over the time they have improved it and they seem to be important features for many applications, but clearly you know there is a tradeoff here.",
                    "label": 0
                },
                {
                    "sent": "'cause you could imagine having a lot of substructures.",
                    "label": 0
                },
                {
                    "sent": "Lot of two index.",
                    "label": 0
                },
                {
                    "sent": "So to represent your molecule as a vector of dimension 1000 or 10,000 or 1,000,000.",
                    "label": 0
                },
                {
                    "sent": "In fact you can have many of them.",
                    "label": 0
                },
                {
                    "sent": "So the question is where should you stop?",
                    "label": 0
                },
                {
                    "sent": "Should you continue to add features, how do you select them?",
                    "label": 1
                },
                {
                    "sent": "And in a sense you could say, well forgiven for one constraint in this field is speed and memory storage.",
                    "label": 0
                },
                {
                    "sent": "So in this case they want to make a fingerprint over, let's say 1000 bits.",
                    "label": 0
                },
                {
                    "sent": "So the question is if you can afford 1000 descriptors, which one should you choose?",
                    "label": 0
                },
                {
                    "sent": "How to maximize the expressiveness in order to make too many clothes different of different pieces?",
                    "label": 0
                },
                {
                    "sent": "If there's different, etc.",
                    "label": 0
                },
                {
                    "sent": "And these are not obvious questions.",
                    "label": 0
                },
                {
                    "sent": "So perhaps just restarted?",
                    "label": 0
                },
                {
                    "sent": "Why it's not obvious?",
                    "label": 0
                },
                {
                    "sent": "Let's think of what about, you know, having a Dictionary of all possible substructures?",
                    "label": 0
                },
                {
                    "sent": "OK, you could say, well, I'm new in machine learning, so I don't see why I will take this once I have a machine.",
                    "label": 0
                },
                {
                    "sent": "I have SVN that can work in infinite dimensions, so I there is no problem to limit that.",
                    "label": 0
                },
                {
                    "sent": "So what about indexing a graph by all the subgraphs it contains?",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And probably the people in the room involved in subgraph mining know already the answer.",
                    "label": 0
                },
                {
                    "sent": "The.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So so so.",
                    "label": 0
                },
                {
                    "sent": "So what about?",
                    "label": 0
                },
                {
                    "sent": "OK, I have a graph so this is a bit of stripe represent it.",
                    "label": 0
                },
                {
                    "sent": "I have my molecule here.",
                    "label": 0
                },
                {
                    "sent": "OK, this is a graph.",
                    "label": 1
                },
                {
                    "sent": "Then from this graph I could say I will extract all the subgraphs.",
                    "label": 0
                },
                {
                    "sent": "So two to make sure we all agree sub graph is simply.",
                    "label": 0
                },
                {
                    "sent": "This is the bit wrong, but simple.",
                    "label": 0
                },
                {
                    "sent": "What we spend that it is the selection of a subset of vertices and the edges that connect them together or not.",
                    "label": 0
                },
                {
                    "sent": "So for instance from this graph I can extract all these subgraphs so you have a graph of size 1, two, three or four and you so here I just consider connected subgraphs for instance.",
                    "label": 0
                },
                {
                    "sent": "OK, So what you could say is that given this graph, given this molecule, I can extract all these subgraphs.",
                    "label": 0
                },
                {
                    "sent": "I can either detect if they are present or not, or I can count them and then I represent my money could buy a vector that for each candidate subgraphs so these ones are the ones which are present.",
                    "label": 0
                },
                {
                    "sent": "But then you can imagine many other ones which are not present here.",
                    "label": 0
                },
                {
                    "sent": "You just count how many times they occur and this is how you represent your molecule.",
                    "label": 0
                },
                {
                    "sent": "OK, so when you say.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is a generalization of this with instead of these nicely chosen substructures, you take all possible substructures.",
                    "label": 0
                },
                {
                    "sent": "So it turns out there are quite a few.",
                    "label": 0
                },
                {
                    "sent": "In particular, if you take into account that you can have several different types of atoms, there are six common atoms plus many uncommon items.",
                    "label": 0
                },
                {
                    "sent": "For each node you have different types of bounds.",
                    "label": 0
                },
                {
                    "sent": "You can have symbol, double etc bounds, and then you can have different structures.",
                    "label": 0
                },
                {
                    "sent": "You can end up with huge dictionaries.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So OK, why not try so, can we?",
                    "label": 0
                },
                {
                    "sent": "OK, can we photograph extract all possible subgraphs and made the vector disk?",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this is what we want to do.",
                    "label": 0
                },
                {
                    "sent": "OK, we have a graph and you would like to to make the graph.",
                    "label": 1
                },
                {
                    "sent": "Let's say of indicators.",
                    "label": 1
                },
                {
                    "sent": "Of the occurrence of any possible sub graph within the graph.",
                    "label": 0
                },
                {
                    "sent": "This would be my descrip.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Unfortunately, it's not.",
                    "label": 0
                },
                {
                    "sent": "It's well known and it's not difficult to show that this is not an easy task.",
                    "label": 0
                },
                {
                    "sent": "OK, so in terms of computing computer science, we called that NP hard problem, which means that to compute these numbers even to compute one number.",
                    "label": 0
                },
                {
                    "sent": "In fact there is no polynomial time algorithm that you will find, so it doesn't mean it's impossible, and I think that many people everyday solve NPR problem.",
                    "label": 0
                },
                {
                    "sent": "But let's say that here it will take time.",
                    "label": 0
                },
                {
                    "sent": "So this is NP hard problem and just to show that there is nothing hidden here is very easy to show that it's NP hard.",
                    "label": 0
                },
                {
                    "sent": "'cause if you just look at, you know, suppose you have a graph with.",
                    "label": 0
                },
                {
                    "sent": "N vertices with N nodes.",
                    "label": 1
                },
                {
                    "sent": "And if you look at the bit that includes the fact that the linear chain so you take the linear graph with nodes, if you want to check whether the linear graph is present or not as a sub graph of your graph, it means that you need to find what.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Called the Hamiltonian path in the graph, so Hamilton Path is just a path that goes through exactly once through all vertices.",
                    "label": 0
                },
                {
                    "sent": "OK, if there is a Hamilton path, it means that this in our graph is a path.",
                    "label": 0
                },
                {
                    "sent": "So you compute one and if there is no Hamilton path, it has to be 0.",
                    "label": 0
                },
                {
                    "sent": "OK, so it means that just with this, so here I mean here.",
                    "label": 0
                },
                {
                    "sent": "This is not the correct one here I have just two things, but if I take the indicator in this case.",
                    "label": 0
                },
                {
                    "sent": "For the linear graph with five nodes, it will be one if and only if there is a Hamiltonian path in this original graph.",
                    "label": 1
                },
                {
                    "sent": "And this problem is known to be NP complete.",
                    "label": 0
                },
                {
                    "sent": "OK, so if we can compute this indicator, we can solve this NP complete problem and therefore we call that NP hard procedure OK, so just computing one bit here is already NP complete.",
                    "label": 0
                },
                {
                    "sent": "So imagine computing all the features.",
                    "label": 0
                },
                {
                    "sent": "It's not not so easy, so I think in this case it's not only NP complete, but in practice it will take time.",
                    "label": 0
                },
                {
                    "sent": "When the size of the graph increases, if you have a graph of size 10 or 15 or 20 like molecules, it will take seconds, minutes, hours or longer.",
                    "label": 0
                },
                {
                    "sent": "OK, so there's this here.",
                    "label": 0
                },
                {
                    "sent": "You see, there is a serious limitation in the in the type of subgraphs you can use to index your graph.",
                    "label": 0
                },
                {
                    "sent": "OK, even taking the simplest wonder in our path is not obvious to check it represents or not.",
                    "label": 0
                },
                {
                    "sent": "So by the way, you could say well, so here was talking off using all subgraphs of sorry from this molecule.",
                    "label": 0
                },
                {
                    "sent": "And here you can extract all subgraphs so you have linear ones and you have even more complex ones like you would like to try to cycle cetera.",
                    "label": 0
                },
                {
                    "sent": "So of course an idea.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To say, well, what about I just extract the path so the path of the linear subgraphs like from this molecule I can extract all the subgraphs which are linear.",
                    "label": 0
                },
                {
                    "sent": "So I just removed the ones with cycles etc.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And of course you could say, well, process can just index by molecule by the occurrence of linear subgraphs.",
                    "label": 0
                },
                {
                    "sent": "And of course, is the same proof.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It is also NP complete because again the just with one bit of a linear indicating the presence of a linear path as a sub graph.",
                    "label": 0
                },
                {
                    "sent": "This is already NP hard, so even with this smaller space just in this, in the presence of path.",
                    "label": 0
                },
                {
                    "sent": "Is impossible in practice when you want to do it on their arse.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so this is the first information that is not so obvious to just to anchor the graph as a vector that indicates the presence of substructures.",
                    "label": 0
                },
                {
                    "sent": "And this is a very natural thing you would like to do.",
                    "label": 0
                },
                {
                    "sent": "You know like if you want to have some interpretable model, we know that in chemistry the presence of some particular substructures may be responsible for the activity.",
                    "label": 0
                },
                {
                    "sent": "So you would like to have these as features and it's not easy to compute, especially in our scale.",
                    "label": 0
                },
                {
                    "sent": "So this is one of the reasons why the fingerprint I showed earlier.",
                    "label": 0
                },
                {
                    "sent": "Sold by the company is limited.",
                    "label": 0
                },
                {
                    "sent": "In fact it takes time to compute it.",
                    "label": 0
                },
                {
                    "sent": "It depends on your computer, is it?",
                    "label": 0
                },
                {
                    "sent": "Rabbit is not obvious to check the presence of subgraphs in a in a molecule.",
                    "label": 0
                },
                {
                    "sent": "OK, so the main message is that OK, it's not easy to do it explicitly.",
                    "label": 0
                },
                {
                    "sent": "We cannot compute that now.",
                    "label": 0
                },
                {
                    "sent": "It doesn't mean that we cannot do anything, and in particular a lot of research has been done in order to follow the same spirit, but reducer bit more the set of things that indexer molecules.",
                    "label": 0
                },
                {
                    "sent": "So here are just a few ideas that have been proposed always with the goal to represent a graph by your vector of counts of occurrences or something.",
                    "label": 0
                },
                {
                    "sent": "So we saw that occurrences of subgraphs is too expensive to compute.",
                    "label": 0
                },
                {
                    "sent": "Occurrences of path is too expensive to compute.",
                    "label": 0
                },
                {
                    "sent": "What some people have done typically so I think is not exhaustive.",
                    "label": 0
                },
                {
                    "sent": "You can have other ideas, but at least this is the this already gives you some ideas of what you can do.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "It is possible to preselect based on prior knowledge, for instance, a subset of subgraphs.",
                    "label": 0
                },
                {
                    "sent": "This is typically the fingerprint I showed earlier, so you know that in chemistry this thing.",
                    "label": 0
                },
                {
                    "sent": "This thing this thing important and you just focus on them.",
                    "label": 0
                },
                {
                    "sent": "And even if it's a bit expensive to compute them well, you can probably do it in practice.",
                    "label": 0
                },
                {
                    "sent": "Another idea, so I said all the path is too expensive, but you could say, well, I will just focus on the presence of path up to length K and you fix K equal to 5, six or seven, at least until you can compute them.",
                    "label": 0
                },
                {
                    "sent": "So it's always.",
                    "label": 0
                },
                {
                    "sent": "It's time to compute, but at least you can control the computation time, and if you take a small enough then you can index your graph by the presence of also a path of length one is just the terms, so you can be a terms of path of length two is an Atom bound to another Atom.",
                    "label": 0
                },
                {
                    "sent": "You can compute then etc and you stop when when it's too expensive in terms of time.",
                    "label": 0
                },
                {
                    "sent": "OK, so typically this is also so sorry I took off up and I earlier.",
                    "label": 0
                },
                {
                    "sent": "In fact the fingerprint I showed this solved by your company name.",
                    "label": 0
                },
                {
                    "sent": "DL and open eyes selling another.",
                    "label": 0
                },
                {
                    "sent": "Fingerprint that computes the occurrence of path to length 8 in this case.",
                    "label": 0
                },
                {
                    "sent": "Now there are other ideas, like instead of looking at all the paths.",
                    "label": 0
                },
                {
                    "sent": "So in this case in the more recently in the machine learning community.",
                    "label": 0
                },
                {
                    "sent": "Custom book Vault and an Kriegel proposed to just look at the shortest path.",
                    "label": 0
                },
                {
                    "sent": "I have a slide on that.",
                    "label": 0
                },
                {
                    "sent": "Another idea is to look at this so a bit like the you know the path all the path is not possible but you can receive the length and other ideas to look at all the subgraphs that up to K vertices like instead of looking at all the subgraphs in the molecule, you look at all the subgraphs up to K nodes and again you can.",
                    "label": 1
                },
                {
                    "sent": "Somehow compute them, or at least find approximation to them.",
                    "label": 0
                },
                {
                    "sent": "And of course process should have said that earlier is ready to the what I called data mining community and other ideas.",
                    "label": 0
                },
                {
                    "sent": "You start from your database of molecules of millions of molecules.",
                    "label": 0
                },
                {
                    "sent": "You first do a mining for the occurrence of.",
                    "label": 0
                },
                {
                    "sent": "I mean, for the frequent subgraphs.",
                    "label": 0
                },
                {
                    "sent": "So instead of taking all the subgraphs, you just take the the subgraphs that occur at least 20 times in your database, and then you just focus on them.",
                    "label": 0
                },
                {
                    "sent": "So this is a way to reduce the list of subgraphs.",
                    "label": 0
                },
                {
                    "sent": "And intuitively, to focus on the good ones.",
                    "label": 0
                },
                {
                    "sent": "And here you have a parameter to select how many you can compute and how many, how much time you want, OK?",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So probably just so wild about two of these ideas.",
                    "label": 0
                },
                {
                    "sent": "So I mentioned you can just look at the shortest path.",
                    "label": 0
                },
                {
                    "sent": "So what does that mean?",
                    "label": 0
                },
                {
                    "sent": "It means that when you have this graph, instead of looking at all the path that goes through this is, you could say, well, if you pick two vertices, there is usually one or a small number of shortest path between them.",
                    "label": 0
                },
                {
                    "sent": "So France between.",
                    "label": 0
                },
                {
                    "sent": "This A and this ADA sorry between these A&B, the shortest path is AAAB OK so you can see it once and you don't count the path AAB ABB 'cause it has the same starting point, the same endpoint but it's longer.",
                    "label": 0
                },
                {
                    "sent": "So of course if you just focus on the shortest path you index America by less path and in fact you can compute how many of them you have cause if you have N vertices then you have the order of N square pairs and squalid by two.",
                    "label": 0
                },
                {
                    "sent": "And therefore you have all the other end square shortest path to consider an you can enumerate them with an algorithm named Floyd Washer.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And end up with the computation of your fingerprint in polynomial time and to the phone.",
                    "label": 0
                },
                {
                    "sent": "OK, so that's just to show that this is 1 ID to completely reduce the complexity of the problem.",
                    "label": 0
                },
                {
                    "sent": "OK, you don't consider all the path, but just the shortest one.",
                    "label": 0
                },
                {
                    "sent": "You can eliminate them efficiently and compute your fingerprint.",
                    "label": 0
                },
                {
                    "sent": "The other idea was to.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Look at all subgraphs.",
                    "label": 0
                },
                {
                    "sent": "So this is.",
                    "label": 0
                },
                {
                    "sent": "This was a difficult problem if you don't limit the size of the subgraphs, but now if you look at the presence of all subgraphs up to three vertices, you have a finite number of them, and usually you can compute them efficiently.",
                    "label": 1
                },
                {
                    "sent": "And in fact, so you can think a bit of it if you just do some nice.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Enumeration it's case as end to the case, or N is the size of the vertices and K is the size of the N is OK.",
                    "label": 0
                },
                {
                    "sent": "The size of the graph you have N vertices in a graph and K is the size of the subgraphs.",
                    "label": 0
                },
                {
                    "sent": "So typically you have enter the case sets of.",
                    "label": 0
                },
                {
                    "sent": "Of gamers of versus.",
                    "label": 0
                },
                {
                    "sent": "Now, if in the case of chemistry, for instance, we don't consider general graphs, these are graphs with a very small degree in the sense that the molecules have a limited number of neighbors.",
                    "label": 0
                },
                {
                    "sent": "So this the presence of.",
                    "label": 0
                },
                {
                    "sent": "K of subgraphs can be reduced to something like N times degree to K -- 1 because you first pick one vertex and then there are only D possible neighbors.",
                    "label": 0
                },
                {
                    "sent": "You don't have minus one possible number, so in fact it is smaller and in fact you can.",
                    "label": 0
                },
                {
                    "sent": "You know, depending on what you want to do, so this is the company to compute explicitly your descriptors.",
                    "label": 0
                },
                {
                    "sent": "Now there is some people have proposed even recently more recently to do some sampling.",
                    "label": 0
                },
                {
                    "sent": "OK, so to say, instead of computing exactly the descriptors, perhaps we can have some approximation of the vector of descriptors by randomly sampling the subgraphs, counting them, and we stop when we are.",
                    "label": 0
                },
                {
                    "sent": "We have enough of them OK, and if you're sampling scheme is good enough then you can show that what you estimate is unbiased.",
                    "label": 0
                },
                {
                    "sent": "So you do some estimation of your vector of descriptors.",
                    "label": 0
                },
                {
                    "sent": "You can control how far it is from the good one using the tools that John showed in the previous talks.",
                    "label": 0
                },
                {
                    "sent": "More distance between the empirical.",
                    "label": 0
                },
                {
                    "sent": "What you measure, the frequency you measure, and the theoretical one so you can control that based on how many you you measure and this can give you some.",
                    "label": 0
                },
                {
                    "sent": "So what's a bit strange here is that you will not always get the same result.",
                    "label": 0
                },
                {
                    "sent": "From the graph, you can end up with different representations, But you can control how far they are, and this may be enough to solve your machine learning problem.",
                    "label": 0
                },
                {
                    "sent": "OK, so these are all ideas to reduce the complexity of the problem and be able to compute these descriptors even though the original problem is NP complete.",
                    "label": 0
                },
                {
                    "sent": "OK, so this was just a like an introduction and just to point out that let's say in the case of graphs which is of interest in chemistry and image processing etc.",
                    "label": 0
                },
                {
                    "sent": "It's clearly not obvious to define interesting descriptors.",
                    "label": 0
                },
                {
                    "sent": "And when we define descriptors as the presence of subgraphs, which intuitively is a good descriptor, then it's not obvious to compute them.",
                    "label": 0
                },
                {
                    "sent": "It's even in.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Sybil.",
                    "label": 0
                },
                {
                    "sent": "So there have been several ideas to reduce the set of structures or speed up the computation an globally speaking.",
                    "label": 1
                },
                {
                    "sent": "Once again, I would like to not to be too dogmatic about NP hard problems.",
                    "label": 0
                },
                {
                    "sent": "There are many NP hard problems that are solved in practice, so perhaps for some databases is possible to index your graph by all the subgraphs.",
                    "label": 1
                },
                {
                    "sent": "It depends on the size of the graph degrees, the side of databases drop.",
                    "label": 0
                },
                {
                    "sent": "OK, so there are general results in particular reason.",
                    "label": 0
                },
                {
                    "sent": "There's a question there.",
                    "label": 0
                },
                {
                    "sent": "Descript.",
                    "label": 0
                },
                {
                    "sent": "Based on the apartment.",
                    "label": 0
                },
                {
                    "sent": "Effectiveness.",
                    "label": 0
                },
                {
                    "sent": "Imagine that the North attributes are very important classification and how do you include the note?",
                    "label": 0
                },
                {
                    "sent": "How do you make sure that your problem or any of this substructure based on distance feature vectors?",
                    "label": 0
                },
                {
                    "sent": "OK, so so if I understand your question, I think I wasn't clear about that.",
                    "label": 0
                },
                {
                    "sent": "In fact, I assume that my graphs, as you say, of attributes both on the vertices and in fact on the edges.",
                    "label": 0
                },
                {
                    "sent": "And what I call a sub graph is an subgraphs attributes.",
                    "label": 0
                },
                {
                    "sent": "And what I would like to compute is the presence of a sub graph with attributes as a subgraph of a group with attributes.",
                    "label": 0
                },
                {
                    "sent": "So in this picture you see I have a graph with aysan bees and I have one that encodes a bound to A and there will be another one for the feature which is a bound to be for instance.",
                    "label": 0
                },
                {
                    "sent": "So clearly in the features we keep track of the attributes.",
                    "label": 0
                },
                {
                    "sent": "And of course, this can only work with discrete attributes.",
                    "label": 0
                },
                {
                    "sent": "OK, like the type of atoms.",
                    "label": 0
                },
                {
                    "sent": "I will not.",
                    "label": 0
                },
                {
                    "sent": "I mean you can.",
                    "label": 0
                },
                {
                    "sent": "In some cases you have continued such abuse like the electropositivity.",
                    "label": 0
                },
                {
                    "sent": "All the things there are different ways to deal with that, including you can make them discrete.",
                    "label": 0
                },
                {
                    "sent": "Or you can use kernels, or you can.",
                    "label": 0
                },
                {
                    "sent": "Good things, but the attributes are in the features here.",
                    "label": 0
                },
                {
                    "sent": "So in fact, all the complexity I mentioned about N, which is the size of the graphs, should be multiplied by the number of attributes and of the vertices and edges in fact.",
                    "label": 0
                },
                {
                    "sent": "Sorry.",
                    "label": 0
                },
                {
                    "sent": "How does pasta mean?",
                    "label": 0
                },
                {
                    "sent": "Sleep mode sticker that you move in Windows.",
                    "label": 0
                },
                {
                    "sent": "So sorry, so I mean for the shortest path, I mean the path to the shortest path to have attributes.",
                    "label": 0
                },
                {
                    "sent": "OK, and here I said that the shortest path between A&B is AAAB.",
                    "label": 0
                },
                {
                    "sent": "OK, so I mean I keep of course the attributes on the.",
                    "label": 0
                },
                {
                    "sent": "Vertices of the of the of the path here.",
                    "label": 0
                },
                {
                    "sent": "Is there any more question?",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK. Is it?",
                    "label": 0
                },
                {
                    "sent": "How much time should I?",
                    "label": 0
                },
                {
                    "sent": "I think it's.",
                    "label": 0
                },
                {
                    "sent": "I think I did 2025 pages so I just OK. How long is this?",
                    "label": 0
                },
                {
                    "sent": "Let's see, uh, well, if you give me the.",
                    "label": 0
                },
                {
                    "sent": "5 to 10 minutes.",
                    "label": 0
                },
                {
                    "sent": "I can make the introduction to kernels and then we will.",
                    "label": 1
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "OK, that's the way I think he's the best.",
                    "label": 0
                },
                {
                    "sent": "I know that after lunch it will be much more difficult to give the information to Colonel, so we just give it now.",
                    "label": 0
                },
                {
                    "sent": "And in fact we already had some interaction to Colonel.",
                    "label": 0
                },
                {
                    "sent": "So I just want to remind you.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I mean by Canon.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And then after lunch I will explain how we make journals.",
                    "label": 0
                },
                {
                    "sent": "OK, so what's the magic and the idea of canals?",
                    "label": 0
                },
                {
                    "sent": "It's just that we keep the same idea.",
                    "label": 0
                },
                {
                    "sent": "So we have a set of objects, like the set of graphs and we want to represent them by vectors.",
                    "label": 0
                },
                {
                    "sent": "Except that here we don't focus on the computation of the vectors, we just focus on computing something called the kernel.",
                    "label": 1
                },
                {
                    "sent": "So a kernel between two objects, like 2 graphs, is the inner product in the future space.",
                    "label": 1
                },
                {
                    "sent": "So you can imagine each graph you compute vectors represented your fire with fire this prime, and you compute the inner product and you obtain a number.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And the famous.",
                    "label": 0
                },
                {
                    "sent": "Kernel trick is that sometimes, at least in practice, it's possible to have some efficient computation of the kernel of the inner product.",
                    "label": 1
                },
                {
                    "sent": "Without computing the features, and sometimes you cannot even compute features like you can walk in infinite dimensions, so you cannot compute the fireworks, but you can compute firewise scarify of its prime, and therefore you can imagine that with kernels you could enlarge the set of descriptors we can use.",
                    "label": 1
                },
                {
                    "sent": "OK, you're not obliged to focus on a limited set.",
                    "label": 0
                },
                {
                    "sent": "You can perhaps afford more features.",
                    "label": 0
                },
                {
                    "sent": "Therefore kernel can be thought as a way to.",
                    "label": 0
                },
                {
                    "sent": "Overcome some of the limitations or practical limitations computational limitations of designing a PC.",
                    "label": 0
                },
                {
                    "sent": "Features 1 by 1.",
                    "label": 0
                },
                {
                    "sent": "OK, so in particular a question could be I said that in the case of descriptors it's crazy to want to compute the presence of path in a graph.",
                    "label": 0
                },
                {
                    "sent": "But now if I did, would say, well, perhaps I can use a camera trick, and even though I cannot compute the descriptors, is too computationally intensive, perhaps I can compute the inner product, then maybe some nice algorithm to compute the inner product and therefore I may be able to work in this space even though I cannot compute the descriptors.",
                    "label": 0
                },
                {
                    "sent": "OK, there are many examples of not in the case of graph, but there are many examples of kernels where you can compute the inner product, but you cannot compute the.",
                    "label": 0
                },
                {
                    "sent": "The features, so this is I would say the general idea, not only if I will show examples, but this is a generality to not to be limited by the computation of the script.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Cause of patterns.",
                    "label": 0
                },
                {
                    "sent": "Now when you think of kennels, well, different people have different, you know, intuition about kernels and I will just write to.",
                    "label": 0
                },
                {
                    "sent": "So I will after I will take 2 examples of camels, one photograph and one for Mac arrays and I will try to discuss them with two ideas in mind.",
                    "label": 0
                },
                {
                    "sent": "So to choose them, let me just remind you what why we use camels.",
                    "label": 0
                },
                {
                    "sent": "And so these are stock was about kennels, kennel kennels, in machine learning.",
                    "label": 0
                },
                {
                    "sent": "Typically means that you so you have.",
                    "label": 0
                },
                {
                    "sent": "You have a descript you have fire vis, which is a vector to describe your vectors, and then we say that with the kernel you can infer a linear function in the feature space.",
                    "label": 0
                },
                {
                    "sent": "OK, so using canals you can solve the problem, which is typically minimizing some empirical risk.",
                    "label": 0
                },
                {
                    "sent": "Subject to a constraint on the Euclidean norm of the weight vectors in the feature space, this is typically support vector machine.",
                    "label": 1
                },
                {
                    "sent": "This is Kernel Ridge regression.",
                    "label": 0
                },
                {
                    "sent": "If you take a different loss.",
                    "label": 0
                },
                {
                    "sent": "This is most of machine learning with can also follow this principle.",
                    "label": 0
                },
                {
                    "sent": "OK, so I think both things are important in the sense that here we see that the features are important because it means that we work in the space defined by the features.",
                    "label": 0
                },
                {
                    "sent": "So clearly when we think of making the kernel, we can think we can think of what are the features I would like to use.",
                    "label": 0
                },
                {
                    "sent": "OK, I would like to use this presence of subgraphs address so you can say I will make a kernel in order to encode the presence of many interesting things, but the second part is I think in learning and this was.",
                    "label": 0
                },
                {
                    "sent": "Almost clear in the previous talk is that there is a constraint you know you.",
                    "label": 0
                },
                {
                    "sent": "You don't only minimize the empirical loss in the feature space, but you minimize it and so often is return as minimizing the empirical loss plus a penalty, and the penalty is the Euclidean norm of the weight vector, and in fact is the construction of the two things that made your learning OK.",
                    "label": 0
                },
                {
                    "sent": "So not only should you define good features because you want to see them appear in the classifier, But then you can play in a sense with the metric you know the usual metric.",
                    "label": 0
                },
                {
                    "sent": "The weights of the features in order to make the feature appear here.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so it may not be very clear for the Member, but I think there are two ways to.",
                    "label": 0
                },
                {
                    "sent": "There are more than two ways, but I will discuss two ways to make kernels.",
                    "label": 0
                },
                {
                    "sent": "First idea is.",
                    "label": 0
                },
                {
                    "sent": "What features do I want in my kernel?",
                    "label": 0
                },
                {
                    "sent": "Like you know, we said I would like to have the all the subgraphs or process can make a counter for subgraphs.",
                    "label": 0
                },
                {
                    "sent": "This is 1 ID and another idea which probably is in many cases more relevant in applications is that is to see the kernel as inducing some regularity on the thing you want to estimate.",
                    "label": 0
                },
                {
                    "sent": "OK, you say I want to find a classifier.",
                    "label": 0
                },
                {
                    "sent": "Which minimizes the loss subject to some constraints, so the constraint is the Euclidean norm in the feature space.",
                    "label": 0
                },
                {
                    "sent": "But this corresponds to some penalty in the original space.",
                    "label": 0
                },
                {
                    "sent": "OK, and you really can think of a kernel as a way to define a penalty on the weight on the weight vector in the feature space or on the classifier in the original space, and therefore without thinking too much about the features you design just to say I want to make a kernel that induces this penalty which is very similar.",
                    "label": 0
                },
                {
                    "sent": "Saying invasion learning on the prior you put on your classifier so you can look at the kernel's putting a prior undercuts failure and then the SVM as maximizing the posterior.",
                    "label": 0
                },
                {
                    "sent": "Things.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "Are we stop here?",
                    "label": 0
                },
                {
                    "sent": "But after lunch we will see an example of in the case of graphs, how can we design kernels by thinking of the features we want to put in the feature space and in the case of microarrays, with the graphs with the jeans and graph, what kind of prior penalty do we want to put on the classifier to make it interpretable at the end?",
                    "label": 0
                },
                {
                    "sent": "So and thank you.",
                    "label": 0
                }
            ]
        }
    }
}