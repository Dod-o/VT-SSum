{
    "id": "pji7snqtkownpwhwkiw6dqhtcdez4eus",
    "title": "Learning without overlearning",
    "info": {
        "author": [
            "Isabelle Guyon, Clopinet"
        ],
        "published": "July 4, 2007",
        "recorded": "July 2007",
        "category": [
            "Top->Computer Science->Machine Learning"
        ]
    },
    "url": "http://videolectures.net/bootcamp07_guyon_lwo/",
    "segmentation": [
        [
            "Good morning, welcome.",
            "When I guess today we're going to talk about the important problem of learning without over learning the first, you know, series of lectures.",
            "You've been hearing a lot about learning machines and how to train them.",
            "Today we're going to learn how not to overtrain them.",
            "That is how not to fit perfectly the training data.",
            "But look ahead for.",
            "Making predictions on unknown test data and trying to.",
            "Find the best possible learning machine that is going to be most predictive of future data and not just explain well the data we have seen so far."
        ],
        [
            "Spread the lecture I gave in the introduction.",
            "Learning machines include the linear discriminant functions including Nate Bias, which can be thought of as a linear discriminant function, kernel methods, neural networks, decision trees and many others, and learning as far as we're concerned means tuning parameters weights that we call either W or Alpha and threshold B and hyperparameters that include basis functions.",
            "Kernels number of units for neural network.",
            "In organizations we have an input matrix which consists of lines that are patterns in each pattern is composed of a number of features that compose the columns of our matrix, and there is a special column which is the target, which is what we're going to try to predict.",
            "And we call W weights.",
            "That way the columns of the matrix, whereas alphas are weights.",
            "That way the lines of the matrix and depending on the types of learning machine we are going to have either W weights or Alpha weights."
        ],
        [
            "At the end of the introduction lecture, yeah showed you this slide.",
            "And.",
            "It sets the basis for the problem of learning.",
            "First, we need to define a risk functional that.",
            "Defines you know what we want to achieve, what problem we have.",
            "And this risk functional is then going to be optimized, and that's the process of learning.",
            "There is function is a function of the parameters of the learning machine at assessing how much it is expected to fail on a given task.",
            "So in this graph here, I very, you know, simply represent in one dimension, so the parameter space usually is a huge dimensional space.",
            "But here we show only one parameter and the race functional which is a function of the learning machine represented here by F of X&W.",
            "It has a kind of a landscape here in parameter space and the goal of learning is to find Optima of this race functional."
        ],
        [
            "Here are some examples of risk functional for classification tasks where the target is either binary or categorical, that is, has one of several values, but a finite number of values.",
            "A typical way of assessing learning machines is to measure the error rate.",
            "So whether or not the output of the learning machine predicts correctly the label that you wanted to predict.",
            "In regression you have continuous outcomes and then a typical risk functional is the mean square error."
        ],
        [
            "So how to train?",
            "Well, first define a risk functional that is completely.",
            "Application related problem related and then find a method to optimize it and the typical method is gradient descent, but there are many other ways of optimizing risk functionals, including simulated annealing.",
            "Unity, Calgary Withams and mathematical programming methods.",
            "The gradient descent approach consists in going down the Hills.",
            "You know, in this landscape of the race, functional in W space, and you go into the direction of the steepest descent."
        ],
        [
            "So again, in the previous lecture I mentioned the fit versus robustness tradeoff problem.",
            "Here are two scatterplots, actually identical.",
            "But they are showing different.",
            "Decision boundaries.",
            "So here X1 and X2 represent 2 features.",
            "So for example, imagine that you have a problem in which you want to classify patients according to their weight and age and you have one population of patient who is at risk of heart attack.",
            "The Red Stars and one population of patients who is healthy the black circles.",
            "And you're trying to find the decision boundary that separates the right stars from the black circles in a way that now we're going to get new examples that you have not seen before.",
            "This decision boundary is going to be able to make predictions as to whether the patient is healthy or not.",
            "And the question is whether you're going to be better off drawing a simple line between the training examples or drawing a complex line that makes a perfect separation of the training examples in this way.",
            "So fit means exactly fitting the training data exactly, explaining the training examples.",
            "This case here exactly explained the training examples because all the red patients are on one side and all the black patients are on the other side.",
            "But now if we examine results on new unknown Thursday to the following situation may arise.",
            "Here you have new examples and they almost all fall on the right side of the decision boundary.",
            "There is only one mistake on the new examples.",
            "Anna, if overly the new examples on the second plot on the right side you see that you have many more mistakes made.",
            "And this is what typically happens in practical situation.",
            "If you're trying to explain to well the training data, you might make more mistakes in fact."
        ],
        [
            "On future test data.",
            "Here is another example of this problem that is known in the field as overfitting.",
            "And this time it's a regression problem.",
            "On the X axis you see the input.",
            "It's a 1 dimensional problem.",
            "In that case you have only one input an on the Y axis you see the Y, which is the outcome that you want to predict.",
            "So.",
            "What what I did here is that I drew at random some some points according to 10th degree polynomial.",
            "And then added some noise and it is possible with the learning machine to fit perfectly or almost perfectly the training points.",
            "Or it is possible to.",
            "To try to make some mistakes at the expense of making some mistakes.",
            "Perhaps you're not predicting as well the training points, but you're going to make better prediction on future data, so the target polynomial, the true polynomial according to which I drew the data, is the red one.",
            "But because I added some noise, then I got the blue crosses and it is up to you whether you believe that it's a better fit to use the grain polynomial here.",
            "That goes indeed through all the test points.",
            "I mean, sold through the training points, but it in between the training points.",
            "It's making predictions, so the problem of learning is very closely related to the problem of interpolation in statistics, and in this case you see that the green curve that is fitting very well the data points is making poor interpolation, so it's not predicting very well the red curve."
        ],
        [
            "So this problem is an old ages problem already in the 14th century.",
            "William of Ockham.",
            "Proposed a principle on how to build theories for scientific explanations of phenomenon.",
            "He summarized his thought in the well known quote Pruitt's, known as potential, seen necessitating.",
            "Which in English means of two theories providing similarly good predictions, prefer the simplest one.",
            "This is usually what we apply out of intuition in real life.",
            "If we have many possible explanations, we're not going to go after the most complex one.",
            "But it turns out that in the recent years there has been much theory around this principle.",
            "To find some explanation of why this possibly works.",
            "So in terms of machine learning, this translates into shave off the unnecessary parameters of your model.",
            "If you have, you know a very complex model.",
            "Probably you can throw away most of the parameters and then good get get better predictions and this is going to be at the heart of what we're going to be talking about when we're going to introduce the problem of feature selection.",
            "If you have a very large input parameter space.",
            "Then you can probably get rid of most of the features and get better prediction."
        ],
        [
            "Interestingly enough.",
            "The brain functions in a way that it uses that principle.",
            "The human brain is made out of billions of cells or neurons.",
            "Which are highly interconnected by synapses.",
            "And exposure to enrich environment with extrasensory and social stimulation enhances the connectivity of the synapses.",
            "But Interestingly enough, children and adolescents can lose.",
            "Lose them up to you know, 20,000,000 per day.",
            "So the brain is constantly learning new things by rearranging the synapses and reinforcing some synapses.",
            "But it's also pruning very, very heavily the unnecessary synapses, and that's part of the learning process is not just that we're getting brain damaged very rapidly."
        ],
        [
            "Artificial neurons have been modeled by my killigan pizzas, simple linear units as as I explained, like last time.",
            "And they make they're making prediction according to a function F of X, which is a simple dot product between the input vector X and a weight vector W. So it's a weighted sum of the inputs weighted by weights called WI, and this is what is represented, represented here.",
            "These are the inputs multiply by the weights that in in biological vocabulary are called synapses.",
            "And then the total input of the neuron is F of X and then the normal is performing a decision.",
            "Either it's firing or not firing Annina where neuron is just doing some classification.",
            "It's saying that the input is of one class.",
            "So that means the drone is active or the other class that Lauren is inactive.",
            "And in most of the problems we're going to consider in the next three hours, we're going to be considering two class classification problems, so the outputs are going to be binary plus one or minus one."
        ],
        [
            "In the last lecture introduced, his role is a very simple way of training neurons and helps rule just adjust the weights according to correlations between inputs and outputs.",
            "So there is a an incremental.",
            "An addition to the weight.",
            "Which is going to be proportional to the product between inputs and outputs.",
            "So between an XJ and the Y of the particular.",
            "So the index I here indicates the index of the pattern, so you presenting each pattern you incurring and you change in WJ.",
            "I'm reminding you that because now we're going to put these heads roll into the perspective of these so called weight decay or the decay of the synapses.",
            "So not only the synapses get rainforest all the time, when you seen you stimulate stimuli in the environment but also the synapses."
        ],
        [
            "Naturally decay.",
            "And this is how this translates in terms of heads rules.",
            "So heads or every time you see a new pattern I.",
            "You increase a little bit away, but simultaneously there is a decay of the wait, so you're replacing this simple rule that I talked to about last time, but this new rule here.",
            "You update your weight here by first decreasing it a little bit, but according to one minus gamma WJ and then you add the.",
            "Increment that is corresponding to your new stimuli."
        ],
        [
            "No.",
            "This weight decay.",
            "Corresponds really to what people are doing in statistics for overfitting avoidance.",
            "So here's an example of the example.",
            "Again of my regression problem, in which I have the target function, which is the red function.",
            "And I used it to draw my blue points.",
            "But of course I added some noise so they're not really on the red line.",
            "Now the problem is to find a polynomial that will approximate as well as possible my right polynomial, which I don't know right.",
            "It's unknown to me.",
            "And so first idea is that well, things you know the target function is attending the re polynomial.",
            "Let's take a learning machine that is also a tense degree polynomial and if I get the best possible fit then I get the green curve.",
            "Now what I'm going to do is that I'm going to use some weight decay and the effect of the weight decay is to pull the weights towards zero, and if I increase the weight decay then here I'm increasing the weight decay.",
            "You see what's happening is that my function is getting smoother Now if I increase it too much.",
            "Well, it's now getting worse because it's going towards the constant function, sorry.",
            "So you see that this way they can be a powerful means of avoiding to overfit, avoiding you know to go through all the training points, but making poor predictions in between the training points, poor interpolation.",
            "And it's it's effect is too smooth.",
            "The prediction curve.",
            "Right is that clear to everybody you have questions at this stage.",
            "OK, so.",
            "But you see that here we are."
        ],
        [
            "Doing too much of it.",
            "Weight decay can be applied like I explained before to linear units, but it can also be applied to multilayer perceptrons.",
            "And the principle is exactly the same.",
            "You replace the W. You replace the update rule that you have the original object rule.",
            "For example the backpropagation algorithm.",
            "By the same update rule, but you first decay the weights."
        ],
        [
            "In the next part of this lecture, I'm going to talk about the theoretical foundations underlying this principle of Occam and introduce weight decay.",
            "Now as a consequence of the theoretical foundations.",
            "And I'll be talking about structural risk minimization, Bayesian priors, minimum description length, and bias variance."
        ],
        [
            "Trade off.",
            "So first of all.",
            "Let's go back again to the problem of risk minimization.",
            "Formally.",
            "The learning problem is to find the best function F of X and some weight W. Minimizing a risk functional.",
            "Which.",
            "In principle, is going to be the integral over the distribution of over X&Y of your loss functional.",
            "So the last functional measures the discrepancy between your prediction F of X and the target Y.",
            "An imagine that you had, you know, an infinite number of points on which you could evaluate this loss function.",
            "The true risk would be you know the integral over this loss of the entire distribution of your X&Y.",
            "Data.",
            "Now the problem is that the distribution is usually unknown.",
            "But what you have instead are examples.",
            "So you have pairs of inputs and outputs, from which you can evaluate an approximation of your response."
        ],
        [
            "No.",
            "So here are some examples of loss functions you need not to remember.",
            "You know all of them just wanted to show you, particularly if you've been exposed before to various learning machines and learning algorithms.",
            "You can, you know, show on a simple graph that they're all related to one another.",
            "For classification problems, why is the target is binary?",
            "It's plus or minus one?",
            "And one characterizes often how well you know you making predictions by just multiplying why by F of X.",
            "So if YF of X has a positive sign, it means that you're making correct prediction.",
            "If wife of ex is a negative sign, you're making a wrong prediction.",
            "And so this is the value of the loss as a function of YF of X.",
            "And you have various loss functions.",
            "The square loss is sometimes used even for classification, and you know you have different loss functions.",
            "The the one that I've talked about before is the error rate.",
            "It corresponds to the 01 loss and so you have you incur penalty of 1 if YF of X is negative, making one penalty.",
            "If you are making a mistake in classification.",
            "And you incurring zero penalty if you're not making a mistake, but it's sometimes more convenient or better for optimization to have other loss functions, so you may want to have a penalty which increases as you go away from the decision boundary.",
            "This is the perceptron loss.",
            "And many algorithms incur also penalties even if you have a good classification.",
            "You may incur a penalty if you have a good classification, but you are within a certain margin area and so these are the margin losses which are like that.",
            "So all the losses, which incur penalties, even if you have already a good classification.",
            "All those you know, large margin methods and they include Adaboost, logic, boost all the boosting's and all the support vector machine based losses.",
            "So you don't need to remember all of this, but very simply, if I summarize and simplify this graph.",
            "Here you have wife of accent.",
            "And this is the loss.",
            "So the 01 loss.",
            "Don't you have a penalty if you're making a wrong classification?",
            "That is, if Y&F of X don't have the same sign and you don't have a penalty.",
            "If you're making a good classification.",
            "And most of the losses that are of interest, they they will be, you know, in an envelope like that.",
            "They will have a shape of that kind, right?",
            "You see that many of them have a shape of that kind.",
            "They do something like that.",
            "And what this means is that.",
            "Dear loss increases as as you make more and as you're further and further more and more wrong, right?",
            "If you really wrong, the last becomes very high, but the loss is not zero, even if you're right.",
            "Because if you are within a certain margin of the decision boundary, you're still incurring some error.",
            "So if we look at the scatterplot X, one X2 like we had before, and if we have examples from 2 classes.",
            "And we have now we are in the process of learning and we have a tentative decision boundary.",
            "The 01 loss will tell you that there will be errors for these two guys and you will incur penalties for these errors.",
            "Other losses that are of this kind here they will give you also penalty, for example that are close to the decision boundary.",
            "And are well classified, so you will have penalties also for these guys because they are.",
            "Close to the decision boundary, even though they are already well classified.",
            "So how do we approximate the risk functional if we don't know the true distribution?"
        ],
        [
            "The first simplest approximation is the empirical risk.",
            "So the empirical race is just the average of the loss over all the training examples.",
            "So let's say you know I'm computing a certain loss for the 01 loss.",
            "I would have one error here.",
            "1 error here and for the row, and lost the empirical risk will be the average of the errors.",
            "So if I have an examples and I've only two errors, the empirical eyes would be 2 over.",
            "I'm in that case.",
            "For classification we usually use the 01 loss to access specification performance even though during training we might have another loss functions like the one I explained.",
            "For reasons that will become clear later.",
            "In regression, again, we have often the square loss.",
            "Now.",
            "Approximations of our VF using just the empirical risk are not very good.",
            "People have figured out that it is better to have some safety safety margin an instead of using the empirical risk use the so-called guaranteed risk.",
            "What the guaranteed risk does for you is that it tells you that with a certain high probability 1 minus Delta.",
            "The tourist is not going to be larger than a certain bound that we could."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Good morning, welcome.",
                    "label": 0
                },
                {
                    "sent": "When I guess today we're going to talk about the important problem of learning without over learning the first, you know, series of lectures.",
                    "label": 1
                },
                {
                    "sent": "You've been hearing a lot about learning machines and how to train them.",
                    "label": 0
                },
                {
                    "sent": "Today we're going to learn how not to overtrain them.",
                    "label": 0
                },
                {
                    "sent": "That is how not to fit perfectly the training data.",
                    "label": 0
                },
                {
                    "sent": "But look ahead for.",
                    "label": 0
                },
                {
                    "sent": "Making predictions on unknown test data and trying to.",
                    "label": 0
                },
                {
                    "sent": "Find the best possible learning machine that is going to be most predictive of future data and not just explain well the data we have seen so far.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Spread the lecture I gave in the introduction.",
                    "label": 0
                },
                {
                    "sent": "Learning machines include the linear discriminant functions including Nate Bias, which can be thought of as a linear discriminant function, kernel methods, neural networks, decision trees and many others, and learning as far as we're concerned means tuning parameters weights that we call either W or Alpha and threshold B and hyperparameters that include basis functions.",
                    "label": 1
                },
                {
                    "sent": "Kernels number of units for neural network.",
                    "label": 0
                },
                {
                    "sent": "In organizations we have an input matrix which consists of lines that are patterns in each pattern is composed of a number of features that compose the columns of our matrix, and there is a special column which is the target, which is what we're going to try to predict.",
                    "label": 0
                },
                {
                    "sent": "And we call W weights.",
                    "label": 0
                },
                {
                    "sent": "That way the columns of the matrix, whereas alphas are weights.",
                    "label": 0
                },
                {
                    "sent": "That way the lines of the matrix and depending on the types of learning machine we are going to have either W weights or Alpha weights.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "At the end of the introduction lecture, yeah showed you this slide.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "It sets the basis for the problem of learning.",
                    "label": 0
                },
                {
                    "sent": "First, we need to define a risk functional that.",
                    "label": 0
                },
                {
                    "sent": "Defines you know what we want to achieve, what problem we have.",
                    "label": 0
                },
                {
                    "sent": "And this risk functional is then going to be optimized, and that's the process of learning.",
                    "label": 0
                },
                {
                    "sent": "There is function is a function of the parameters of the learning machine at assessing how much it is expected to fail on a given task.",
                    "label": 1
                },
                {
                    "sent": "So in this graph here, I very, you know, simply represent in one dimension, so the parameter space usually is a huge dimensional space.",
                    "label": 0
                },
                {
                    "sent": "But here we show only one parameter and the race functional which is a function of the learning machine represented here by F of X&W.",
                    "label": 0
                },
                {
                    "sent": "It has a kind of a landscape here in parameter space and the goal of learning is to find Optima of this race functional.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Here are some examples of risk functional for classification tasks where the target is either binary or categorical, that is, has one of several values, but a finite number of values.",
                    "label": 0
                },
                {
                    "sent": "A typical way of assessing learning machines is to measure the error rate.",
                    "label": 1
                },
                {
                    "sent": "So whether or not the output of the learning machine predicts correctly the label that you wanted to predict.",
                    "label": 0
                },
                {
                    "sent": "In regression you have continuous outcomes and then a typical risk functional is the mean square error.",
                    "label": 1
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So how to train?",
                    "label": 0
                },
                {
                    "sent": "Well, first define a risk functional that is completely.",
                    "label": 1
                },
                {
                    "sent": "Application related problem related and then find a method to optimize it and the typical method is gradient descent, but there are many other ways of optimizing risk functionals, including simulated annealing.",
                    "label": 1
                },
                {
                    "sent": "Unity, Calgary Withams and mathematical programming methods.",
                    "label": 0
                },
                {
                    "sent": "The gradient descent approach consists in going down the Hills.",
                    "label": 0
                },
                {
                    "sent": "You know, in this landscape of the race, functional in W space, and you go into the direction of the steepest descent.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So again, in the previous lecture I mentioned the fit versus robustness tradeoff problem.",
                    "label": 1
                },
                {
                    "sent": "Here are two scatterplots, actually identical.",
                    "label": 0
                },
                {
                    "sent": "But they are showing different.",
                    "label": 0
                },
                {
                    "sent": "Decision boundaries.",
                    "label": 0
                },
                {
                    "sent": "So here X1 and X2 represent 2 features.",
                    "label": 0
                },
                {
                    "sent": "So for example, imagine that you have a problem in which you want to classify patients according to their weight and age and you have one population of patient who is at risk of heart attack.",
                    "label": 0
                },
                {
                    "sent": "The Red Stars and one population of patients who is healthy the black circles.",
                    "label": 0
                },
                {
                    "sent": "And you're trying to find the decision boundary that separates the right stars from the black circles in a way that now we're going to get new examples that you have not seen before.",
                    "label": 0
                },
                {
                    "sent": "This decision boundary is going to be able to make predictions as to whether the patient is healthy or not.",
                    "label": 0
                },
                {
                    "sent": "And the question is whether you're going to be better off drawing a simple line between the training examples or drawing a complex line that makes a perfect separation of the training examples in this way.",
                    "label": 0
                },
                {
                    "sent": "So fit means exactly fitting the training data exactly, explaining the training examples.",
                    "label": 0
                },
                {
                    "sent": "This case here exactly explained the training examples because all the red patients are on one side and all the black patients are on the other side.",
                    "label": 0
                },
                {
                    "sent": "But now if we examine results on new unknown Thursday to the following situation may arise.",
                    "label": 0
                },
                {
                    "sent": "Here you have new examples and they almost all fall on the right side of the decision boundary.",
                    "label": 0
                },
                {
                    "sent": "There is only one mistake on the new examples.",
                    "label": 0
                },
                {
                    "sent": "Anna, if overly the new examples on the second plot on the right side you see that you have many more mistakes made.",
                    "label": 0
                },
                {
                    "sent": "And this is what typically happens in practical situation.",
                    "label": 0
                },
                {
                    "sent": "If you're trying to explain to well the training data, you might make more mistakes in fact.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "On future test data.",
                    "label": 0
                },
                {
                    "sent": "Here is another example of this problem that is known in the field as overfitting.",
                    "label": 0
                },
                {
                    "sent": "And this time it's a regression problem.",
                    "label": 0
                },
                {
                    "sent": "On the X axis you see the input.",
                    "label": 0
                },
                {
                    "sent": "It's a 1 dimensional problem.",
                    "label": 0
                },
                {
                    "sent": "In that case you have only one input an on the Y axis you see the Y, which is the outcome that you want to predict.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "What what I did here is that I drew at random some some points according to 10th degree polynomial.",
                    "label": 1
                },
                {
                    "sent": "And then added some noise and it is possible with the learning machine to fit perfectly or almost perfectly the training points.",
                    "label": 0
                },
                {
                    "sent": "Or it is possible to.",
                    "label": 0
                },
                {
                    "sent": "To try to make some mistakes at the expense of making some mistakes.",
                    "label": 0
                },
                {
                    "sent": "Perhaps you're not predicting as well the training points, but you're going to make better prediction on future data, so the target polynomial, the true polynomial according to which I drew the data, is the red one.",
                    "label": 0
                },
                {
                    "sent": "But because I added some noise, then I got the blue crosses and it is up to you whether you believe that it's a better fit to use the grain polynomial here.",
                    "label": 0
                },
                {
                    "sent": "That goes indeed through all the test points.",
                    "label": 0
                },
                {
                    "sent": "I mean, sold through the training points, but it in between the training points.",
                    "label": 0
                },
                {
                    "sent": "It's making predictions, so the problem of learning is very closely related to the problem of interpolation in statistics, and in this case you see that the green curve that is fitting very well the data points is making poor interpolation, so it's not predicting very well the red curve.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this problem is an old ages problem already in the 14th century.",
                    "label": 0
                },
                {
                    "sent": "William of Ockham.",
                    "label": 0
                },
                {
                    "sent": "Proposed a principle on how to build theories for scientific explanations of phenomenon.",
                    "label": 0
                },
                {
                    "sent": "He summarized his thought in the well known quote Pruitt's, known as potential, seen necessitating.",
                    "label": 0
                },
                {
                    "sent": "Which in English means of two theories providing similarly good predictions, prefer the simplest one.",
                    "label": 1
                },
                {
                    "sent": "This is usually what we apply out of intuition in real life.",
                    "label": 0
                },
                {
                    "sent": "If we have many possible explanations, we're not going to go after the most complex one.",
                    "label": 0
                },
                {
                    "sent": "But it turns out that in the recent years there has been much theory around this principle.",
                    "label": 0
                },
                {
                    "sent": "To find some explanation of why this possibly works.",
                    "label": 1
                },
                {
                    "sent": "So in terms of machine learning, this translates into shave off the unnecessary parameters of your model.",
                    "label": 0
                },
                {
                    "sent": "If you have, you know a very complex model.",
                    "label": 0
                },
                {
                    "sent": "Probably you can throw away most of the parameters and then good get get better predictions and this is going to be at the heart of what we're going to be talking about when we're going to introduce the problem of feature selection.",
                    "label": 0
                },
                {
                    "sent": "If you have a very large input parameter space.",
                    "label": 0
                },
                {
                    "sent": "Then you can probably get rid of most of the features and get better prediction.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Interestingly enough.",
                    "label": 0
                },
                {
                    "sent": "The brain functions in a way that it uses that principle.",
                    "label": 0
                },
                {
                    "sent": "The human brain is made out of billions of cells or neurons.",
                    "label": 1
                },
                {
                    "sent": "Which are highly interconnected by synapses.",
                    "label": 1
                },
                {
                    "sent": "And exposure to enrich environment with extrasensory and social stimulation enhances the connectivity of the synapses.",
                    "label": 0
                },
                {
                    "sent": "But Interestingly enough, children and adolescents can lose.",
                    "label": 0
                },
                {
                    "sent": "Lose them up to you know, 20,000,000 per day.",
                    "label": 0
                },
                {
                    "sent": "So the brain is constantly learning new things by rearranging the synapses and reinforcing some synapses.",
                    "label": 0
                },
                {
                    "sent": "But it's also pruning very, very heavily the unnecessary synapses, and that's part of the learning process is not just that we're getting brain damaged very rapidly.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Artificial neurons have been modeled by my killigan pizzas, simple linear units as as I explained, like last time.",
                    "label": 0
                },
                {
                    "sent": "And they make they're making prediction according to a function F of X, which is a simple dot product between the input vector X and a weight vector W. So it's a weighted sum of the inputs weighted by weights called WI, and this is what is represented, represented here.",
                    "label": 0
                },
                {
                    "sent": "These are the inputs multiply by the weights that in in biological vocabulary are called synapses.",
                    "label": 0
                },
                {
                    "sent": "And then the total input of the neuron is F of X and then the normal is performing a decision.",
                    "label": 0
                },
                {
                    "sent": "Either it's firing or not firing Annina where neuron is just doing some classification.",
                    "label": 0
                },
                {
                    "sent": "It's saying that the input is of one class.",
                    "label": 0
                },
                {
                    "sent": "So that means the drone is active or the other class that Lauren is inactive.",
                    "label": 0
                },
                {
                    "sent": "And in most of the problems we're going to consider in the next three hours, we're going to be considering two class classification problems, so the outputs are going to be binary plus one or minus one.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In the last lecture introduced, his role is a very simple way of training neurons and helps rule just adjust the weights according to correlations between inputs and outputs.",
                    "label": 0
                },
                {
                    "sent": "So there is a an incremental.",
                    "label": 0
                },
                {
                    "sent": "An addition to the weight.",
                    "label": 0
                },
                {
                    "sent": "Which is going to be proportional to the product between inputs and outputs.",
                    "label": 0
                },
                {
                    "sent": "So between an XJ and the Y of the particular.",
                    "label": 0
                },
                {
                    "sent": "So the index I here indicates the index of the pattern, so you presenting each pattern you incurring and you change in WJ.",
                    "label": 0
                },
                {
                    "sent": "I'm reminding you that because now we're going to put these heads roll into the perspective of these so called weight decay or the decay of the synapses.",
                    "label": 0
                },
                {
                    "sent": "So not only the synapses get rainforest all the time, when you seen you stimulate stimuli in the environment but also the synapses.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Naturally decay.",
                    "label": 0
                },
                {
                    "sent": "And this is how this translates in terms of heads rules.",
                    "label": 0
                },
                {
                    "sent": "So heads or every time you see a new pattern I.",
                    "label": 0
                },
                {
                    "sent": "You increase a little bit away, but simultaneously there is a decay of the wait, so you're replacing this simple rule that I talked to about last time, but this new rule here.",
                    "label": 0
                },
                {
                    "sent": "You update your weight here by first decreasing it a little bit, but according to one minus gamma WJ and then you add the.",
                    "label": 0
                },
                {
                    "sent": "Increment that is corresponding to your new stimuli.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "No.",
                    "label": 0
                },
                {
                    "sent": "This weight decay.",
                    "label": 0
                },
                {
                    "sent": "Corresponds really to what people are doing in statistics for overfitting avoidance.",
                    "label": 0
                },
                {
                    "sent": "So here's an example of the example.",
                    "label": 0
                },
                {
                    "sent": "Again of my regression problem, in which I have the target function, which is the red function.",
                    "label": 0
                },
                {
                    "sent": "And I used it to draw my blue points.",
                    "label": 0
                },
                {
                    "sent": "But of course I added some noise so they're not really on the red line.",
                    "label": 0
                },
                {
                    "sent": "Now the problem is to find a polynomial that will approximate as well as possible my right polynomial, which I don't know right.",
                    "label": 0
                },
                {
                    "sent": "It's unknown to me.",
                    "label": 0
                },
                {
                    "sent": "And so first idea is that well, things you know the target function is attending the re polynomial.",
                    "label": 0
                },
                {
                    "sent": "Let's take a learning machine that is also a tense degree polynomial and if I get the best possible fit then I get the green curve.",
                    "label": 0
                },
                {
                    "sent": "Now what I'm going to do is that I'm going to use some weight decay and the effect of the weight decay is to pull the weights towards zero, and if I increase the weight decay then here I'm increasing the weight decay.",
                    "label": 0
                },
                {
                    "sent": "You see what's happening is that my function is getting smoother Now if I increase it too much.",
                    "label": 0
                },
                {
                    "sent": "Well, it's now getting worse because it's going towards the constant function, sorry.",
                    "label": 0
                },
                {
                    "sent": "So you see that this way they can be a powerful means of avoiding to overfit, avoiding you know to go through all the training points, but making poor predictions in between the training points, poor interpolation.",
                    "label": 0
                },
                {
                    "sent": "And it's it's effect is too smooth.",
                    "label": 0
                },
                {
                    "sent": "The prediction curve.",
                    "label": 0
                },
                {
                    "sent": "Right is that clear to everybody you have questions at this stage.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "But you see that here we are.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Doing too much of it.",
                    "label": 0
                },
                {
                    "sent": "Weight decay can be applied like I explained before to linear units, but it can also be applied to multilayer perceptrons.",
                    "label": 1
                },
                {
                    "sent": "And the principle is exactly the same.",
                    "label": 0
                },
                {
                    "sent": "You replace the W. You replace the update rule that you have the original object rule.",
                    "label": 0
                },
                {
                    "sent": "For example the backpropagation algorithm.",
                    "label": 0
                },
                {
                    "sent": "By the same update rule, but you first decay the weights.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In the next part of this lecture, I'm going to talk about the theoretical foundations underlying this principle of Occam and introduce weight decay.",
                    "label": 0
                },
                {
                    "sent": "Now as a consequence of the theoretical foundations.",
                    "label": 0
                },
                {
                    "sent": "And I'll be talking about structural risk minimization, Bayesian priors, minimum description length, and bias variance.",
                    "label": 1
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Trade off.",
                    "label": 0
                },
                {
                    "sent": "So first of all.",
                    "label": 0
                },
                {
                    "sent": "Let's go back again to the problem of risk minimization.",
                    "label": 0
                },
                {
                    "sent": "Formally.",
                    "label": 0
                },
                {
                    "sent": "The learning problem is to find the best function F of X and some weight W. Minimizing a risk functional.",
                    "label": 1
                },
                {
                    "sent": "Which.",
                    "label": 0
                },
                {
                    "sent": "In principle, is going to be the integral over the distribution of over X&Y of your loss functional.",
                    "label": 0
                },
                {
                    "sent": "So the last functional measures the discrepancy between your prediction F of X and the target Y.",
                    "label": 0
                },
                {
                    "sent": "An imagine that you had, you know, an infinite number of points on which you could evaluate this loss function.",
                    "label": 0
                },
                {
                    "sent": "The true risk would be you know the integral over this loss of the entire distribution of your X&Y.",
                    "label": 0
                },
                {
                    "sent": "Data.",
                    "label": 0
                },
                {
                    "sent": "Now the problem is that the distribution is usually unknown.",
                    "label": 0
                },
                {
                    "sent": "But what you have instead are examples.",
                    "label": 0
                },
                {
                    "sent": "So you have pairs of inputs and outputs, from which you can evaluate an approximation of your response.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "No.",
                    "label": 0
                },
                {
                    "sent": "So here are some examples of loss functions you need not to remember.",
                    "label": 0
                },
                {
                    "sent": "You know all of them just wanted to show you, particularly if you've been exposed before to various learning machines and learning algorithms.",
                    "label": 0
                },
                {
                    "sent": "You can, you know, show on a simple graph that they're all related to one another.",
                    "label": 0
                },
                {
                    "sent": "For classification problems, why is the target is binary?",
                    "label": 0
                },
                {
                    "sent": "It's plus or minus one?",
                    "label": 0
                },
                {
                    "sent": "And one characterizes often how well you know you making predictions by just multiplying why by F of X.",
                    "label": 0
                },
                {
                    "sent": "So if YF of X has a positive sign, it means that you're making correct prediction.",
                    "label": 0
                },
                {
                    "sent": "If wife of ex is a negative sign, you're making a wrong prediction.",
                    "label": 0
                },
                {
                    "sent": "And so this is the value of the loss as a function of YF of X.",
                    "label": 0
                },
                {
                    "sent": "And you have various loss functions.",
                    "label": 0
                },
                {
                    "sent": "The square loss is sometimes used even for classification, and you know you have different loss functions.",
                    "label": 1
                },
                {
                    "sent": "The the one that I've talked about before is the error rate.",
                    "label": 0
                },
                {
                    "sent": "It corresponds to the 01 loss and so you have you incur penalty of 1 if YF of X is negative, making one penalty.",
                    "label": 0
                },
                {
                    "sent": "If you are making a mistake in classification.",
                    "label": 0
                },
                {
                    "sent": "And you incurring zero penalty if you're not making a mistake, but it's sometimes more convenient or better for optimization to have other loss functions, so you may want to have a penalty which increases as you go away from the decision boundary.",
                    "label": 1
                },
                {
                    "sent": "This is the perceptron loss.",
                    "label": 0
                },
                {
                    "sent": "And many algorithms incur also penalties even if you have a good classification.",
                    "label": 0
                },
                {
                    "sent": "You may incur a penalty if you have a good classification, but you are within a certain margin area and so these are the margin losses which are like that.",
                    "label": 0
                },
                {
                    "sent": "So all the losses, which incur penalties, even if you have already a good classification.",
                    "label": 0
                },
                {
                    "sent": "All those you know, large margin methods and they include Adaboost, logic, boost all the boosting's and all the support vector machine based losses.",
                    "label": 0
                },
                {
                    "sent": "So you don't need to remember all of this, but very simply, if I summarize and simplify this graph.",
                    "label": 0
                },
                {
                    "sent": "Here you have wife of accent.",
                    "label": 0
                },
                {
                    "sent": "And this is the loss.",
                    "label": 0
                },
                {
                    "sent": "So the 01 loss.",
                    "label": 0
                },
                {
                    "sent": "Don't you have a penalty if you're making a wrong classification?",
                    "label": 0
                },
                {
                    "sent": "That is, if Y&F of X don't have the same sign and you don't have a penalty.",
                    "label": 0
                },
                {
                    "sent": "If you're making a good classification.",
                    "label": 0
                },
                {
                    "sent": "And most of the losses that are of interest, they they will be, you know, in an envelope like that.",
                    "label": 0
                },
                {
                    "sent": "They will have a shape of that kind, right?",
                    "label": 0
                },
                {
                    "sent": "You see that many of them have a shape of that kind.",
                    "label": 0
                },
                {
                    "sent": "They do something like that.",
                    "label": 0
                },
                {
                    "sent": "And what this means is that.",
                    "label": 0
                },
                {
                    "sent": "Dear loss increases as as you make more and as you're further and further more and more wrong, right?",
                    "label": 0
                },
                {
                    "sent": "If you really wrong, the last becomes very high, but the loss is not zero, even if you're right.",
                    "label": 0
                },
                {
                    "sent": "Because if you are within a certain margin of the decision boundary, you're still incurring some error.",
                    "label": 0
                },
                {
                    "sent": "So if we look at the scatterplot X, one X2 like we had before, and if we have examples from 2 classes.",
                    "label": 0
                },
                {
                    "sent": "And we have now we are in the process of learning and we have a tentative decision boundary.",
                    "label": 0
                },
                {
                    "sent": "The 01 loss will tell you that there will be errors for these two guys and you will incur penalties for these errors.",
                    "label": 0
                },
                {
                    "sent": "Other losses that are of this kind here they will give you also penalty, for example that are close to the decision boundary.",
                    "label": 0
                },
                {
                    "sent": "And are well classified, so you will have penalties also for these guys because they are.",
                    "label": 0
                },
                {
                    "sent": "Close to the decision boundary, even though they are already well classified.",
                    "label": 1
                },
                {
                    "sent": "So how do we approximate the risk functional if we don't know the true distribution?",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The first simplest approximation is the empirical risk.",
                    "label": 0
                },
                {
                    "sent": "So the empirical race is just the average of the loss over all the training examples.",
                    "label": 0
                },
                {
                    "sent": "So let's say you know I'm computing a certain loss for the 01 loss.",
                    "label": 1
                },
                {
                    "sent": "I would have one error here.",
                    "label": 0
                },
                {
                    "sent": "1 error here and for the row, and lost the empirical risk will be the average of the errors.",
                    "label": 0
                },
                {
                    "sent": "So if I have an examples and I've only two errors, the empirical eyes would be 2 over.",
                    "label": 0
                },
                {
                    "sent": "I'm in that case.",
                    "label": 0
                },
                {
                    "sent": "For classification we usually use the 01 loss to access specification performance even though during training we might have another loss functions like the one I explained.",
                    "label": 0
                },
                {
                    "sent": "For reasons that will become clear later.",
                    "label": 0
                },
                {
                    "sent": "In regression, again, we have often the square loss.",
                    "label": 1
                },
                {
                    "sent": "Now.",
                    "label": 0
                },
                {
                    "sent": "Approximations of our VF using just the empirical risk are not very good.",
                    "label": 1
                },
                {
                    "sent": "People have figured out that it is better to have some safety safety margin an instead of using the empirical risk use the so-called guaranteed risk.",
                    "label": 1
                },
                {
                    "sent": "What the guaranteed risk does for you is that it tells you that with a certain high probability 1 minus Delta.",
                    "label": 0
                },
                {
                    "sent": "The tourist is not going to be larger than a certain bound that we could.",
                    "label": 0
                }
            ]
        }
    }
}