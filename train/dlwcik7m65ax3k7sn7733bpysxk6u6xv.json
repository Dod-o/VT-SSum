{
    "id": "dlwcik7m65ax3k7sn7733bpysxk6u6xv",
    "title": "Music of the (p)Spheres",
    "info": {
        "author": [
            "Alessandro Panconesi, Sapienza University of Rome"
        ],
        "published": "Feb. 25, 2007",
        "recorded": "May 2006",
        "category": [
            "Top->Computer Science->Machine Learning->Clustering"
        ]
    },
    "url": "http://videolectures.net/fws06_panconesi_m/",
    "segmentation": [
        [
            "So what I would like to describe to you is some joint work.",
            "With Rebecca Raghavan of Yahoo research.",
            "Then with early up full of Brown University and then with my research and Alessandro Di Bari, who are two PhD students in the Department in Rome at La Sapienza."
        ],
        [
            "OK, So what we're going to talk about is nearest neighbors.",
            "Now we know."
        ],
        [
            "So that in.",
            "Information retrieval applications with text data but also not only text data.",
            "We have our documents and these documents they are turned into points into Euclidean space.",
            "So our documents they become points vectors in some Euclidean space, so this can be a corpus.",
            "The collection of documents.",
            "Now what is the fundamental problem of a search engine?",
            "So the fundamental problem is that a query comes in.",
            "And the query is a document, so this becomes a point.",
            "And now what we want to do, what we want to return to the user are the closest points to the query.",
            "OK, so we have that this basic information retrieval task becomes a geometric problem.",
            "Now there's a lot of literature and lots of nice algorithms about this.",
            "Now the basic one of the basic things that you begin to observe is that the computational geometry literature.",
            "Gives a lot of interesting algorithms.",
            "But unfortunately for those algorithms, the dimension of the space is in the exponent.",
            "Now in text retrieval applications, the number of dimensions is in the order of 1,000,000.",
            "So if you have an algorithm with complex is 2 raised to 1,000,000, this is not going to be very efficient, so therefore you have to come up with different methods.",
            "Now concerning nearest neighbors.",
            "The question is with respect to or walk distance.",
            "So you can use the Euclidean distance, but you can also use the cosine similarity and we will be mostly interested in concerned with cosine similarity.",
            "Now, given the audience, I assume that you're familiar with this, if not.",
            "Then OK, now what we're going to do in our experiments.",
            "The experiments that I'm going to show to you is that we take our documents, our corpus, so these are turned into vectors, and now these vectors are normalized, so our search will happen on the units here on the surface of the units here."
        ],
        [
            "And there these two are very much related.",
            "In particular, the closest point with respect to this distance is also the closest point with respect to this metric and the second closest point with respect to this is also the second with respect to that and so on.",
            "So the ranking of the two is the same."
        ],
        [
            "Now what they would like to describe to you is a very simple randomized clustering technique to perform the nearest neighbor computation.",
            "And here is our."
        ],
        [
            "Shows so there is a.",
            "This is our corpus.",
            "These are our documents and there is a preprocessing step.",
            "To build a data structure, and then you're going to use the data structure later on when you're going to service the queries.",
            "So here is how the data structure is built.",
            "So you start by selecting square root an.",
            "The points at random, so you have any documents you select sample of size square root of N at random.",
            "And now you cluster.",
            "The space by associating every point to the closest leader.",
            "OK, and that's it, that's the data structure.",
            "Now how are you going to use the data structure now?",
            "The query comes in and the query.",
            "Is matched against the yellow points.",
            "And then the search is continued in the cluster of the closest leader.",
            "OK, so now if you use the square root and leaders on average, you're going to have a square root.",
            "You are going to have clusters of size square root of North, so therefore the cost of this is order of square root of North.",
            "Whereas if you have to do the naive algorithm that is going to match the query against every single point in the space, this is going to cost you order of North.",
            "Or more now, notice that here in this fashion you sort of use the geometric information.",
            "So if the point.",
            "Is here then this guys up there?",
            "They are very far geographically so they just one query.",
            "Just throw out lots of stuff so you prune away a lot of things."
        ],
        [
            "Now.",
            "So we implement this.",
            "And we did some experimental studies and we compare it against some of the state of the art solutions.",
            "So one of these state of the art solution is called P spheres.",
            "I know about spheres, I don't know about P, so I don't know why it's called peace fears.",
            "This is.",
            "The work by several people, one of whom is Rama Krishnan, who used to be a Wisconsin and then it's now.",
            "It's going to be very soon at Yahoo Research."
        ],
        [
            "And here how so I was curious about peace fears.",
            "Now there is this thing called the music of the peace fears.",
            "So apparently this is a philosophical concept that goes back to the Middle Ages and it's related to the motion of the planets.",
            "Now these planets are supposed to play some kind of music, but it's not a sound, it's a mathematical concept.",
            "Now this mathematical concept goes back to Pythagoras.",
            "And was created to be the originator of this semi mystical semi mathematical philosophy.",
            "And now the interesting thing is that this is also related to something of the weather and perhaps some Indian guys can explain to me what these words are and Huawei Pythagoras supposed to be a sub Goosen from.",
            "So it's a very interesting concept."
        ],
        [
            "So let me tell you what the PC's are.",
            "OK, peace fears two.",
            "They build a data structure and so there is an initial phase which is called a training phase and it's a training phase because not only do you need the documents, of course, but you also need a sample of the queries or you need to know the distribution of the queries.",
            "Now with this distribution of the queries you are going to build the data structure here."
        ],
        [
            "Is how it goes.",
            "So the first step is the same as we did before, so you select a certain number of leaders at random and now you."
        ],
        [
            "The center a certain number of balls around these leaders.",
            "So these are the initial clusters, so there is a parimeter are that tells you how big these spheres are.",
            "And now you start training the system in the following way so."
        ],
        [
            "The query comes in.",
            "This is your sample query.",
            "And it's here.",
            "And now you look at two things.",
            "You look at the closest point.",
            "And you also look at the closest leader.",
            "Now, in this case, the closest point is in the cluster in the peace fear of the closest leader.",
            "So therefore you don't do anything.",
            "The other case."
        ],
        [
            "Is when the query is here.",
            "The closest leader is this and the closest point is outside of the sphere and therefore now you enlarge.",
            "This peace fear."
        ],
        [
            "And for reasons that I do not fully understand, you also."
        ],
        [
            "In larger the same the other guys by the same amount.",
            "And you do this with lots of points.",
            "And then you are ready to confront the real world.",
            "So that's how his fears work.",
            "Now notice two things.",
            "So now these things are going to grow.",
            "And they're also going to overlap, so this overlap is very, very significant, as we shall see.",
            "So there is a huge block in space.",
            "The other thing which was a bit surprising to me was that in this case, at this stage this points are not covered, they do not belong to any piece here, so you're going to miss points.",
            "Again, this is noticeable sometime percent of the points you're going to miss.",
            "OK, so.",
            "This is."
        ],
        [
            "On other methods that we want to compare against and then there is another very nice method which is called rank aggregation.",
            "So this is related to some nice theoretical work, or John Kleinberg.",
            "And then if I'm not mistaken there is a body of work by Ron Fagin, Ravikumar, and Sivakumar who implemented this for nearest neighbor.",
            "And here is how."
        ],
        [
            "'cause it's very nice.",
            "So this is our corpus.",
            "These are our documents.",
            "And again, you're going to build a data structure and then you're going to use the data structure to answer the queries.",
            "So the data for the data structure you pick a random vector.",
            "And then you project."
        ],
        [
            "The documents on this random vector.",
            "How are you going to use it?"
        ],
        [
            "Now when the query comes in, the query will be projected also against on this random vector, and then you're going to see which document is closest to the query on this line.",
            "Of course, if you just one line, this is not going to be very effective, so you're going to use more than one."
        ],
        [
            "So you're going to use a red vector, a green vector, a blue vector, and so on, so forth, and therefore you're going to have a situation like this.",
            "So a given query on this line, the closest guy can be the blue guy.",
            "Now, if you if you go on a different line, the closest guy, maybe it's the yellow guy.",
            "So what are you going to do?",
            "We're going to take a majority vote, so rank aggregation is a so."
        ],
        [
            "Have an election.",
            "So you have the candidates which are the documents and you have the voters which are the random vectors.",
            "So now you project these on the project.",
            "The documents on the random vectors.",
            "Now when the query comes in you also project the query and then this guy say OK.",
            "In my case the closest guy is this guy and so this guy gets one vote.",
            "Then, though, I don't know the purple random vector will vote for this guy and so on.",
            "So you tell it these votes and then you have some rule to decide how to elect candidates.",
            "OK, so there are several variations on this idea.",
            "OK, now of course this methods were tested before and they were discovered to work well.",
            "They're sort of a state of the."
        ],
        [
            "Solutions, so we are very interested in comparing our method with this."
        ],
        [
            "Now the valuation now to devaluation you need to assess quality.",
            "Now the nice thing about this setup is that you know the optimum value.",
            "Now suppose that this is our corpus.",
            "Now you have a query and now you're going to rank the entire corpus with respect to the query, which means, so I have this thing here.",
            "So this is the closest guy.",
            "And then that's the second closest guy.",
            "That's the third closest guy.",
            "And so on.",
            "And this is the guy farthest away.",
            "Now a search engine is not going to give back to you the entire collection, so we're only interested in the closest."
        ],
        [
            "So suppose that our engine is going to retreat to return the 8 closest documents.",
            "So how do we assess the performance of our algorithm?",
            "So we run the."
        ],
        [
            "Um?",
            "And so you have this red dots.",
            "And now you're going to see how many of the top eight guys we hit.",
            "So in this case, this is four 4 / 8.",
            "So you have a 50% performance.",
            "So that's one measure of quality."
        ],
        [
            "That we're going to use.",
            "However, we know that in, so we know that we believe that cosine similarity is a good proxy for relevance.",
            "And."
        ],
        [
            "Oops, you're going to have situations like this.",
            "Suppose that this is our query.",
            "And these are the closest guys.",
            "But if you perturb this a bit, you're going to have a different set of points, which again is going to be very meaningful, so it's not really clear that this should be better than that.",
            "Now to take care of this, we."
        ],
        [
            "We use a natural measure which is competitive similarity, which is the average distance of query from S. So you have a set of points.",
            "And this set of points gets the score.",
            "What's the score?",
            "Is the average distance of these points from Q, and now you compare this."
        ],
        [
            "You consider the ratio between.",
            "Your set of points and the best set of points.",
            "In fact, we can see the normalized version of this, which is better for several reasons.",
            "But you can think of the 2nd way to assess quality in this way.",
            "Now."
        ],
        [
            "We performed.",
            "Study with the following data set so we have 100,000 documents which we downloaded from sites here.",
            "Now the number of dimension is very, very high, it's 400,000.",
            "Then we normalize this two unit vectors.",
            "And now the words were stemmed and stop words were removed.",
            "So that's our data set."
        ],
        [
            "And here we run experiments, So what do we measure so we measure 2 things so the quality with respect to those 2 measures that I explained earlier and then computational effort.",
            "So computational effort, we have some machine independent measures which I'm going to describe later, and we tried long and short queries."
        ],
        [
            "Now I should also point out that in the experiments that we performed there, regardless of the outcome, so of course we are interested in, so we hope that our random clustering is going to work well.",
            "But even if it didn't work well, the experiments would be interesting anyway.",
            "Becausw.",
            "To the best of my knowledge at least, this is the first empirical study of piece Viersen rank aggregation with respect to text data.",
            "So text data have the following two properties, so they have a huge number of dimensions and the vectors are very, very sparse.",
            "So you have 400,000 dimensions.",
            "Only a few of which are non 0, so this is very much different from the experimental studies that were done before and with which the two methods were assessed.",
            "So to give you an idea, the number of dimensions there is 20 or 30 OK and the vectors are very dense, so this is a different study.",
            "Now the outcome is extremely good.",
            "In fact it's so good, so our methods were so well, then nobody is going to believe us.",
            "So this paper is not going to be published anywhere, so please have your only chance to have a look at experiments."
        ],
        [
            "OK.",
            "So first we did some comparison of our random clustering method against the naive solution.",
            "So the next solution is.",
            "To rank the entire collection with respect to the query in some brute force fashion.",
            "And the.",
            "So this linear scan.",
            "We say that the computational effort of this is 1, so therefore we're going to measure the computational effort of other algorithms as a fraction of this.",
            "So the questions that we ask is suppose that I want to spend 15%.",
            "Of the time of the linear scan, how much quality can I get?",
            "Or suppose that I'm willing to spend 50% of the linear scan in times of computational effort.",
            "How much quality can I get OK?",
            "Now we played with our randomize scheme, so if you remember, we select these leaders at random.",
            "And then we cluster the points around these leaders.",
            "Now you can think of all sorts of optimization on top of this.",
            "So for instance, you could the cluster the leaders into meta leaders and then you can cluster the meta leaders in meta meta leaders.",
            "You can do all sorts of things.",
            "They very nice thing is that the simplest scheme, the one that I described to you, works the best.",
            "So all these gimmicks that I described you are down here in terms of so here on the Y axis you have quality.",
            "So to give you an idea with 15% of computational effort, you get to 9697% of the optimum in terms, OK?",
            "So the linear the simple thing works much better than that.",
            "Also."
        ],
        [
            "Once you have the clusters, you can ask OK. Perhaps instead, instead of the point themselves, I can use the centroids of the clusters, so if you do that, you get much better results.",
            "So the best way to get a succinct representation of the cluster is the centroid.",
            "No."
        ],
        [
            "Let's look at the comparison.",
            "These fears were so random cluster."
        ],
        [
            "Now in terms of quality, random clustering is much better.",
            "Now this is the best outcome, so I took the best performance of our peace fears.",
            "Now.",
            "Unfortunately, this is not very clear this picture so, but this thing here is peace fears and this thing above this random clustering.",
            "So for say this is .2 with .2% of the computational effort of the linear scale.",
            "With peace fears you get to 90% which is good.",
            "But with random clustering you get 98% which is much better.",
            "Also notice that this thing is going to flatten out and here you have one, so this is the link.",
            "The full cost and still you don't, you're not 100%.",
            "And again, in general, the random clustering were so that the difference is larger than this.",
            "Now what about space define?"
        ],
        [
            "Frontier.",
            "So there is a huge blow up of peace fears.",
            "So random clustering is essentially optimal.",
            "You just introduce square root and pointers links.",
            "So peace fears you play with the parameters you get.",
            "So for instance, 100 block of 120.",
            "So if you have a TB TB of data.",
            "If you use these fears, you have to store 120 terabytes of data.",
            "Now it can be much better than that, but.",
            "Never below 10 times, whereas random clustering is optimal."
        ],
        [
            "So what is the bottom line?",
            "Let's look at the spheres, so there's a significant space blow up.",
            "So as I described earlier, there is a partial coverage of corpus, so some points are in.",
            "They do not appear in any peace fears, so compare 2 random clustering.",
            "You get significantly lower quality for the same computational effort, and also you need to know the query distribution.",
            "So here you don't need to know anything at all.",
            "It's a very simple scheme.",
            "You don't need to know the query distribution, nothing.",
            "So you get better quality and you have optimal space.",
            "So I think that."
        ],
        [
            "This is very satisfying.",
            "Now what about recreation so ranked?"
        ],
        [
            "Aggression unfortunate is very disappointing, so this is on the X axis.",
            "You have the computational effort and on the Y axis you have quality measured as I described earlier.",
            "So here you can't see anything.",
            "Let's see, right?",
            "So the random clustering is up here.",
            "But rank aggregation is here, so you get here you are at 10 percent 15%.",
            "Twenty percent is very, very disappointing.",
            "Yeah I can put it anywhere.",
            "Now.",
            "So."
        ],
        [
            "This looks very fishy to us.",
            "So we checked the software.",
            "We checked this and that.",
            "So now we believe this.",
            "So we believe that rank agregation is not working well in this case.",
            "Now what is a possible explanation?",
            "So again, notice that this study with respect to previous study concerns very sparse vectors with a huge number of dimensions.",
            "Now we did try with dense vectors.",
            "We tried rank aggregation with dense vectors and the performance was much much much better.",
            "Also, in fact, regulation was introduced to give good approximation of Euclidean distance, so with respect to Euclidean distance we get the data one minute, 0 minutes, 30 seconds.",
            "So we get so we get results which are the same that were reported in the study."
        ],
        [
            "Now the future of that actions.",
            "So the conclusion, I think, is that this random clustering is remarkably effective now in this study.",
            "Also have an extremely cool generative model.",
            "I didn't have time to tell you about with which we can prove amazing things.",
            "Not not that fit.",
            "Now with this model we can actually prove mathematically that the random clustering performs.",
            "Well, OK, now the next thing to do is to see how this generative model fits the data.",
            "So if it's compatible with the.",
            "OK, so we are trying to combine.",
            "Random Sample with recreation.",
            "An interesting way, and it seems to work very nicely.",
            "And also we want to extend this clustering approach with the page rank, so with links and again we have some interesting things I would."
        ],
        [
            "Like to close with a challenge to the audience.",
            "So does anybody know the origin of the word Yahoo.",
            "And I think the answer is going to be very interesting.",
            "OK, thanks.",
            "OK, so we have a place.",
            "Another yard.",
            "OK, yet OK the answer, so the so.",
            "OK, that's the wrong answer, and it's very interesting why.",
            "I mean, it's true, but there is a.",
            "There is another reason why.",
            "I mean there is another meaning of the word you.",
            "Work.",
            "OK, great, so that's that's the correct answer, so it's from Gulliver's Journey by Jonathan Swift, so.",
            "Intended pun that.",
            "OK, you get a plus, OK?",
            "OK, the interesting thing so Yahoo is what yet another hierarchical blah.",
            "OK, so that's the nerd answer.",
            "But then also this is a species of Gulliver's Journey by Jonathan Swift, and in the end he so this is a. I mean, these are people and he discovers in the end that he himself is a Yahoo and we're all yahoos.",
            "OK thanks.",
            "With.",
            "Yeah.",
            "Sensible.",
            "I don't know sensitive.",
            "So you just take square root and points at random and.",
            "Different initial random points.",
            "Oh, so if the variance no it's not.",
            "It will be fine.",
            "Did you try to search in the two or three years glasses?",
            "Yeah yeah.",
            "So in practice then that's what you do.",
            "You don't.",
            "You don't look in the nearest classify.",
            "You take the 10 closest clusters.",
            "Didn't do it in the experiment.",
            "Experiment, experiment you do.",
            "Yeah, oh, you're doing, yeah.",
            "Did you ever write your message using some measures, for example, F measure of customer in order table?",
            "Is equality give you give you compare the result of clustering with expert opinion phrases or no no no.",
            "So this is we just just match with the.",
            "So we believe that cosine similarity is a good proxy for relevance.",
            "So we know the truth with respect to cosines to cosine similarity, and we match against that.",
            "And this is says the advantage that it's a purely mathematical notion.",
            "You don't need to, but no, we don't.",
            "Easy metal strongly rent on the spherical clusters but not the object or object in the form of some chains.",
            "Some chain approach it is I can consume it strongly, ranging from the spiritual simplicity.",
            "Yeah, so it's a spiritual thing.",
            "Thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So what I would like to describe to you is some joint work.",
                    "label": 0
                },
                {
                    "sent": "With Rebecca Raghavan of Yahoo research.",
                    "label": 0
                },
                {
                    "sent": "Then with early up full of Brown University and then with my research and Alessandro Di Bari, who are two PhD students in the Department in Rome at La Sapienza.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, So what we're going to talk about is nearest neighbors.",
                    "label": 0
                },
                {
                    "sent": "Now we know.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So that in.",
                    "label": 0
                },
                {
                    "sent": "Information retrieval applications with text data but also not only text data.",
                    "label": 0
                },
                {
                    "sent": "We have our documents and these documents they are turned into points into Euclidean space.",
                    "label": 0
                },
                {
                    "sent": "So our documents they become points vectors in some Euclidean space, so this can be a corpus.",
                    "label": 0
                },
                {
                    "sent": "The collection of documents.",
                    "label": 0
                },
                {
                    "sent": "Now what is the fundamental problem of a search engine?",
                    "label": 0
                },
                {
                    "sent": "So the fundamental problem is that a query comes in.",
                    "label": 0
                },
                {
                    "sent": "And the query is a document, so this becomes a point.",
                    "label": 0
                },
                {
                    "sent": "And now what we want to do, what we want to return to the user are the closest points to the query.",
                    "label": 0
                },
                {
                    "sent": "OK, so we have that this basic information retrieval task becomes a geometric problem.",
                    "label": 0
                },
                {
                    "sent": "Now there's a lot of literature and lots of nice algorithms about this.",
                    "label": 0
                },
                {
                    "sent": "Now the basic one of the basic things that you begin to observe is that the computational geometry literature.",
                    "label": 0
                },
                {
                    "sent": "Gives a lot of interesting algorithms.",
                    "label": 0
                },
                {
                    "sent": "But unfortunately for those algorithms, the dimension of the space is in the exponent.",
                    "label": 0
                },
                {
                    "sent": "Now in text retrieval applications, the number of dimensions is in the order of 1,000,000.",
                    "label": 0
                },
                {
                    "sent": "So if you have an algorithm with complex is 2 raised to 1,000,000, this is not going to be very efficient, so therefore you have to come up with different methods.",
                    "label": 0
                },
                {
                    "sent": "Now concerning nearest neighbors.",
                    "label": 0
                },
                {
                    "sent": "The question is with respect to or walk distance.",
                    "label": 0
                },
                {
                    "sent": "So you can use the Euclidean distance, but you can also use the cosine similarity and we will be mostly interested in concerned with cosine similarity.",
                    "label": 0
                },
                {
                    "sent": "Now, given the audience, I assume that you're familiar with this, if not.",
                    "label": 0
                },
                {
                    "sent": "Then OK, now what we're going to do in our experiments.",
                    "label": 0
                },
                {
                    "sent": "The experiments that I'm going to show to you is that we take our documents, our corpus, so these are turned into vectors, and now these vectors are normalized, so our search will happen on the units here on the surface of the units here.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And there these two are very much related.",
                    "label": 0
                },
                {
                    "sent": "In particular, the closest point with respect to this distance is also the closest point with respect to this metric and the second closest point with respect to this is also the second with respect to that and so on.",
                    "label": 0
                },
                {
                    "sent": "So the ranking of the two is the same.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now what they would like to describe to you is a very simple randomized clustering technique to perform the nearest neighbor computation.",
                    "label": 0
                },
                {
                    "sent": "And here is our.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Shows so there is a.",
                    "label": 0
                },
                {
                    "sent": "This is our corpus.",
                    "label": 0
                },
                {
                    "sent": "These are our documents and there is a preprocessing step.",
                    "label": 0
                },
                {
                    "sent": "To build a data structure, and then you're going to use the data structure later on when you're going to service the queries.",
                    "label": 0
                },
                {
                    "sent": "So here is how the data structure is built.",
                    "label": 0
                },
                {
                    "sent": "So you start by selecting square root an.",
                    "label": 0
                },
                {
                    "sent": "The points at random, so you have any documents you select sample of size square root of N at random.",
                    "label": 0
                },
                {
                    "sent": "And now you cluster.",
                    "label": 0
                },
                {
                    "sent": "The space by associating every point to the closest leader.",
                    "label": 1
                },
                {
                    "sent": "OK, and that's it, that's the data structure.",
                    "label": 0
                },
                {
                    "sent": "Now how are you going to use the data structure now?",
                    "label": 0
                },
                {
                    "sent": "The query comes in and the query.",
                    "label": 0
                },
                {
                    "sent": "Is matched against the yellow points.",
                    "label": 0
                },
                {
                    "sent": "And then the search is continued in the cluster of the closest leader.",
                    "label": 0
                },
                {
                    "sent": "OK, so now if you use the square root and leaders on average, you're going to have a square root.",
                    "label": 1
                },
                {
                    "sent": "You are going to have clusters of size square root of North, so therefore the cost of this is order of square root of North.",
                    "label": 0
                },
                {
                    "sent": "Whereas if you have to do the naive algorithm that is going to match the query against every single point in the space, this is going to cost you order of North.",
                    "label": 0
                },
                {
                    "sent": "Or more now, notice that here in this fashion you sort of use the geometric information.",
                    "label": 0
                },
                {
                    "sent": "So if the point.",
                    "label": 0
                },
                {
                    "sent": "Is here then this guys up there?",
                    "label": 0
                },
                {
                    "sent": "They are very far geographically so they just one query.",
                    "label": 0
                },
                {
                    "sent": "Just throw out lots of stuff so you prune away a lot of things.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now.",
                    "label": 0
                },
                {
                    "sent": "So we implement this.",
                    "label": 0
                },
                {
                    "sent": "And we did some experimental studies and we compare it against some of the state of the art solutions.",
                    "label": 0
                },
                {
                    "sent": "So one of these state of the art solution is called P spheres.",
                    "label": 0
                },
                {
                    "sent": "I know about spheres, I don't know about P, so I don't know why it's called peace fears.",
                    "label": 0
                },
                {
                    "sent": "This is.",
                    "label": 0
                },
                {
                    "sent": "The work by several people, one of whom is Rama Krishnan, who used to be a Wisconsin and then it's now.",
                    "label": 0
                },
                {
                    "sent": "It's going to be very soon at Yahoo Research.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And here how so I was curious about peace fears.",
                    "label": 1
                },
                {
                    "sent": "Now there is this thing called the music of the peace fears.",
                    "label": 1
                },
                {
                    "sent": "So apparently this is a philosophical concept that goes back to the Middle Ages and it's related to the motion of the planets.",
                    "label": 1
                },
                {
                    "sent": "Now these planets are supposed to play some kind of music, but it's not a sound, it's a mathematical concept.",
                    "label": 1
                },
                {
                    "sent": "Now this mathematical concept goes back to Pythagoras.",
                    "label": 0
                },
                {
                    "sent": "And was created to be the originator of this semi mystical semi mathematical philosophy.",
                    "label": 0
                },
                {
                    "sent": "And now the interesting thing is that this is also related to something of the weather and perhaps some Indian guys can explain to me what these words are and Huawei Pythagoras supposed to be a sub Goosen from.",
                    "label": 0
                },
                {
                    "sent": "So it's a very interesting concept.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So let me tell you what the PC's are.",
                    "label": 0
                },
                {
                    "sent": "OK, peace fears two.",
                    "label": 0
                },
                {
                    "sent": "They build a data structure and so there is an initial phase which is called a training phase and it's a training phase because not only do you need the documents, of course, but you also need a sample of the queries or you need to know the distribution of the queries.",
                    "label": 0
                },
                {
                    "sent": "Now with this distribution of the queries you are going to build the data structure here.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is how it goes.",
                    "label": 0
                },
                {
                    "sent": "So the first step is the same as we did before, so you select a certain number of leaders at random and now you.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The center a certain number of balls around these leaders.",
                    "label": 0
                },
                {
                    "sent": "So these are the initial clusters, so there is a parimeter are that tells you how big these spheres are.",
                    "label": 0
                },
                {
                    "sent": "And now you start training the system in the following way so.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The query comes in.",
                    "label": 0
                },
                {
                    "sent": "This is your sample query.",
                    "label": 0
                },
                {
                    "sent": "And it's here.",
                    "label": 0
                },
                {
                    "sent": "And now you look at two things.",
                    "label": 0
                },
                {
                    "sent": "You look at the closest point.",
                    "label": 0
                },
                {
                    "sent": "And you also look at the closest leader.",
                    "label": 0
                },
                {
                    "sent": "Now, in this case, the closest point is in the cluster in the peace fear of the closest leader.",
                    "label": 0
                },
                {
                    "sent": "So therefore you don't do anything.",
                    "label": 0
                },
                {
                    "sent": "The other case.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is when the query is here.",
                    "label": 0
                },
                {
                    "sent": "The closest leader is this and the closest point is outside of the sphere and therefore now you enlarge.",
                    "label": 0
                },
                {
                    "sent": "This peace fear.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And for reasons that I do not fully understand, you also.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In larger the same the other guys by the same amount.",
                    "label": 0
                },
                {
                    "sent": "And you do this with lots of points.",
                    "label": 0
                },
                {
                    "sent": "And then you are ready to confront the real world.",
                    "label": 0
                },
                {
                    "sent": "So that's how his fears work.",
                    "label": 0
                },
                {
                    "sent": "Now notice two things.",
                    "label": 0
                },
                {
                    "sent": "So now these things are going to grow.",
                    "label": 0
                },
                {
                    "sent": "And they're also going to overlap, so this overlap is very, very significant, as we shall see.",
                    "label": 0
                },
                {
                    "sent": "So there is a huge block in space.",
                    "label": 0
                },
                {
                    "sent": "The other thing which was a bit surprising to me was that in this case, at this stage this points are not covered, they do not belong to any piece here, so you're going to miss points.",
                    "label": 0
                },
                {
                    "sent": "Again, this is noticeable sometime percent of the points you're going to miss.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "This is.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "On other methods that we want to compare against and then there is another very nice method which is called rank aggregation.",
                    "label": 0
                },
                {
                    "sent": "So this is related to some nice theoretical work, or John Kleinberg.",
                    "label": 0
                },
                {
                    "sent": "And then if I'm not mistaken there is a body of work by Ron Fagin, Ravikumar, and Sivakumar who implemented this for nearest neighbor.",
                    "label": 0
                },
                {
                    "sent": "And here is how.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "'cause it's very nice.",
                    "label": 0
                },
                {
                    "sent": "So this is our corpus.",
                    "label": 0
                },
                {
                    "sent": "These are our documents.",
                    "label": 0
                },
                {
                    "sent": "And again, you're going to build a data structure and then you're going to use the data structure to answer the queries.",
                    "label": 0
                },
                {
                    "sent": "So the data for the data structure you pick a random vector.",
                    "label": 0
                },
                {
                    "sent": "And then you project.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The documents on this random vector.",
                    "label": 0
                },
                {
                    "sent": "How are you going to use it?",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now when the query comes in, the query will be projected also against on this random vector, and then you're going to see which document is closest to the query on this line.",
                    "label": 0
                },
                {
                    "sent": "Of course, if you just one line, this is not going to be very effective, so you're going to use more than one.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So you're going to use a red vector, a green vector, a blue vector, and so on, so forth, and therefore you're going to have a situation like this.",
                    "label": 0
                },
                {
                    "sent": "So a given query on this line, the closest guy can be the blue guy.",
                    "label": 0
                },
                {
                    "sent": "Now, if you if you go on a different line, the closest guy, maybe it's the yellow guy.",
                    "label": 0
                },
                {
                    "sent": "So what are you going to do?",
                    "label": 0
                },
                {
                    "sent": "We're going to take a majority vote, so rank aggregation is a so.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Have an election.",
                    "label": 0
                },
                {
                    "sent": "So you have the candidates which are the documents and you have the voters which are the random vectors.",
                    "label": 0
                },
                {
                    "sent": "So now you project these on the project.",
                    "label": 0
                },
                {
                    "sent": "The documents on the random vectors.",
                    "label": 0
                },
                {
                    "sent": "Now when the query comes in you also project the query and then this guy say OK.",
                    "label": 0
                },
                {
                    "sent": "In my case the closest guy is this guy and so this guy gets one vote.",
                    "label": 0
                },
                {
                    "sent": "Then, though, I don't know the purple random vector will vote for this guy and so on.",
                    "label": 0
                },
                {
                    "sent": "So you tell it these votes and then you have some rule to decide how to elect candidates.",
                    "label": 0
                },
                {
                    "sent": "OK, so there are several variations on this idea.",
                    "label": 0
                },
                {
                    "sent": "OK, now of course this methods were tested before and they were discovered to work well.",
                    "label": 0
                },
                {
                    "sent": "They're sort of a state of the.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Solutions, so we are very interested in comparing our method with this.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now the valuation now to devaluation you need to assess quality.",
                    "label": 0
                },
                {
                    "sent": "Now the nice thing about this setup is that you know the optimum value.",
                    "label": 0
                },
                {
                    "sent": "Now suppose that this is our corpus.",
                    "label": 0
                },
                {
                    "sent": "Now you have a query and now you're going to rank the entire corpus with respect to the query, which means, so I have this thing here.",
                    "label": 0
                },
                {
                    "sent": "So this is the closest guy.",
                    "label": 0
                },
                {
                    "sent": "And then that's the second closest guy.",
                    "label": 0
                },
                {
                    "sent": "That's the third closest guy.",
                    "label": 0
                },
                {
                    "sent": "And so on.",
                    "label": 0
                },
                {
                    "sent": "And this is the guy farthest away.",
                    "label": 0
                },
                {
                    "sent": "Now a search engine is not going to give back to you the entire collection, so we're only interested in the closest.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So suppose that our engine is going to retreat to return the 8 closest documents.",
                    "label": 0
                },
                {
                    "sent": "So how do we assess the performance of our algorithm?",
                    "label": 0
                },
                {
                    "sent": "So we run the.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "And so you have this red dots.",
                    "label": 0
                },
                {
                    "sent": "And now you're going to see how many of the top eight guys we hit.",
                    "label": 0
                },
                {
                    "sent": "So in this case, this is four 4 / 8.",
                    "label": 0
                },
                {
                    "sent": "So you have a 50% performance.",
                    "label": 0
                },
                {
                    "sent": "So that's one measure of quality.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That we're going to use.",
                    "label": 0
                },
                {
                    "sent": "However, we know that in, so we know that we believe that cosine similarity is a good proxy for relevance.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Oops, you're going to have situations like this.",
                    "label": 0
                },
                {
                    "sent": "Suppose that this is our query.",
                    "label": 0
                },
                {
                    "sent": "And these are the closest guys.",
                    "label": 0
                },
                {
                    "sent": "But if you perturb this a bit, you're going to have a different set of points, which again is going to be very meaningful, so it's not really clear that this should be better than that.",
                    "label": 0
                },
                {
                    "sent": "Now to take care of this, we.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We use a natural measure which is competitive similarity, which is the average distance of query from S. So you have a set of points.",
                    "label": 0
                },
                {
                    "sent": "And this set of points gets the score.",
                    "label": 0
                },
                {
                    "sent": "What's the score?",
                    "label": 0
                },
                {
                    "sent": "Is the average distance of these points from Q, and now you compare this.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You consider the ratio between.",
                    "label": 0
                },
                {
                    "sent": "Your set of points and the best set of points.",
                    "label": 0
                },
                {
                    "sent": "In fact, we can see the normalized version of this, which is better for several reasons.",
                    "label": 0
                },
                {
                    "sent": "But you can think of the 2nd way to assess quality in this way.",
                    "label": 0
                },
                {
                    "sent": "Now.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We performed.",
                    "label": 0
                },
                {
                    "sent": "Study with the following data set so we have 100,000 documents which we downloaded from sites here.",
                    "label": 0
                },
                {
                    "sent": "Now the number of dimension is very, very high, it's 400,000.",
                    "label": 0
                },
                {
                    "sent": "Then we normalize this two unit vectors.",
                    "label": 0
                },
                {
                    "sent": "And now the words were stemmed and stop words were removed.",
                    "label": 0
                },
                {
                    "sent": "So that's our data set.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And here we run experiments, So what do we measure so we measure 2 things so the quality with respect to those 2 measures that I explained earlier and then computational effort.",
                    "label": 0
                },
                {
                    "sent": "So computational effort, we have some machine independent measures which I'm going to describe later, and we tried long and short queries.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now I should also point out that in the experiments that we performed there, regardless of the outcome, so of course we are interested in, so we hope that our random clustering is going to work well.",
                    "label": 0
                },
                {
                    "sent": "But even if it didn't work well, the experiments would be interesting anyway.",
                    "label": 0
                },
                {
                    "sent": "Becausw.",
                    "label": 0
                },
                {
                    "sent": "To the best of my knowledge at least, this is the first empirical study of piece Viersen rank aggregation with respect to text data.",
                    "label": 0
                },
                {
                    "sent": "So text data have the following two properties, so they have a huge number of dimensions and the vectors are very, very sparse.",
                    "label": 0
                },
                {
                    "sent": "So you have 400,000 dimensions.",
                    "label": 0
                },
                {
                    "sent": "Only a few of which are non 0, so this is very much different from the experimental studies that were done before and with which the two methods were assessed.",
                    "label": 0
                },
                {
                    "sent": "So to give you an idea, the number of dimensions there is 20 or 30 OK and the vectors are very dense, so this is a different study.",
                    "label": 0
                },
                {
                    "sent": "Now the outcome is extremely good.",
                    "label": 0
                },
                {
                    "sent": "In fact it's so good, so our methods were so well, then nobody is going to believe us.",
                    "label": 0
                },
                {
                    "sent": "So this paper is not going to be published anywhere, so please have your only chance to have a look at experiments.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So first we did some comparison of our random clustering method against the naive solution.",
                    "label": 0
                },
                {
                    "sent": "So the next solution is.",
                    "label": 0
                },
                {
                    "sent": "To rank the entire collection with respect to the query in some brute force fashion.",
                    "label": 0
                },
                {
                    "sent": "And the.",
                    "label": 0
                },
                {
                    "sent": "So this linear scan.",
                    "label": 0
                },
                {
                    "sent": "We say that the computational effort of this is 1, so therefore we're going to measure the computational effort of other algorithms as a fraction of this.",
                    "label": 0
                },
                {
                    "sent": "So the questions that we ask is suppose that I want to spend 15%.",
                    "label": 0
                },
                {
                    "sent": "Of the time of the linear scan, how much quality can I get?",
                    "label": 0
                },
                {
                    "sent": "Or suppose that I'm willing to spend 50% of the linear scan in times of computational effort.",
                    "label": 0
                },
                {
                    "sent": "How much quality can I get OK?",
                    "label": 0
                },
                {
                    "sent": "Now we played with our randomize scheme, so if you remember, we select these leaders at random.",
                    "label": 0
                },
                {
                    "sent": "And then we cluster the points around these leaders.",
                    "label": 0
                },
                {
                    "sent": "Now you can think of all sorts of optimization on top of this.",
                    "label": 0
                },
                {
                    "sent": "So for instance, you could the cluster the leaders into meta leaders and then you can cluster the meta leaders in meta meta leaders.",
                    "label": 0
                },
                {
                    "sent": "You can do all sorts of things.",
                    "label": 0
                },
                {
                    "sent": "They very nice thing is that the simplest scheme, the one that I described to you, works the best.",
                    "label": 0
                },
                {
                    "sent": "So all these gimmicks that I described you are down here in terms of so here on the Y axis you have quality.",
                    "label": 0
                },
                {
                    "sent": "So to give you an idea with 15% of computational effort, you get to 9697% of the optimum in terms, OK?",
                    "label": 0
                },
                {
                    "sent": "So the linear the simple thing works much better than that.",
                    "label": 0
                },
                {
                    "sent": "Also.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Once you have the clusters, you can ask OK. Perhaps instead, instead of the point themselves, I can use the centroids of the clusters, so if you do that, you get much better results.",
                    "label": 0
                },
                {
                    "sent": "So the best way to get a succinct representation of the cluster is the centroid.",
                    "label": 1
                },
                {
                    "sent": "No.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Let's look at the comparison.",
                    "label": 0
                },
                {
                    "sent": "These fears were so random cluster.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now in terms of quality, random clustering is much better.",
                    "label": 0
                },
                {
                    "sent": "Now this is the best outcome, so I took the best performance of our peace fears.",
                    "label": 0
                },
                {
                    "sent": "Now.",
                    "label": 0
                },
                {
                    "sent": "Unfortunately, this is not very clear this picture so, but this thing here is peace fears and this thing above this random clustering.",
                    "label": 0
                },
                {
                    "sent": "So for say this is .2 with .2% of the computational effort of the linear scale.",
                    "label": 0
                },
                {
                    "sent": "With peace fears you get to 90% which is good.",
                    "label": 0
                },
                {
                    "sent": "But with random clustering you get 98% which is much better.",
                    "label": 0
                },
                {
                    "sent": "Also notice that this thing is going to flatten out and here you have one, so this is the link.",
                    "label": 0
                },
                {
                    "sent": "The full cost and still you don't, you're not 100%.",
                    "label": 0
                },
                {
                    "sent": "And again, in general, the random clustering were so that the difference is larger than this.",
                    "label": 0
                },
                {
                    "sent": "Now what about space define?",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Frontier.",
                    "label": 0
                },
                {
                    "sent": "So there is a huge blow up of peace fears.",
                    "label": 0
                },
                {
                    "sent": "So random clustering is essentially optimal.",
                    "label": 0
                },
                {
                    "sent": "You just introduce square root and pointers links.",
                    "label": 0
                },
                {
                    "sent": "So peace fears you play with the parameters you get.",
                    "label": 0
                },
                {
                    "sent": "So for instance, 100 block of 120.",
                    "label": 0
                },
                {
                    "sent": "So if you have a TB TB of data.",
                    "label": 0
                },
                {
                    "sent": "If you use these fears, you have to store 120 terabytes of data.",
                    "label": 0
                },
                {
                    "sent": "Now it can be much better than that, but.",
                    "label": 0
                },
                {
                    "sent": "Never below 10 times, whereas random clustering is optimal.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So what is the bottom line?",
                    "label": 0
                },
                {
                    "sent": "Let's look at the spheres, so there's a significant space blow up.",
                    "label": 0
                },
                {
                    "sent": "So as I described earlier, there is a partial coverage of corpus, so some points are in.",
                    "label": 0
                },
                {
                    "sent": "They do not appear in any peace fears, so compare 2 random clustering.",
                    "label": 0
                },
                {
                    "sent": "You get significantly lower quality for the same computational effort, and also you need to know the query distribution.",
                    "label": 0
                },
                {
                    "sent": "So here you don't need to know anything at all.",
                    "label": 0
                },
                {
                    "sent": "It's a very simple scheme.",
                    "label": 0
                },
                {
                    "sent": "You don't need to know the query distribution, nothing.",
                    "label": 0
                },
                {
                    "sent": "So you get better quality and you have optimal space.",
                    "label": 0
                },
                {
                    "sent": "So I think that.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is very satisfying.",
                    "label": 0
                },
                {
                    "sent": "Now what about recreation so ranked?",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Aggression unfortunate is very disappointing, so this is on the X axis.",
                    "label": 0
                },
                {
                    "sent": "You have the computational effort and on the Y axis you have quality measured as I described earlier.",
                    "label": 0
                },
                {
                    "sent": "So here you can't see anything.",
                    "label": 0
                },
                {
                    "sent": "Let's see, right?",
                    "label": 0
                },
                {
                    "sent": "So the random clustering is up here.",
                    "label": 0
                },
                {
                    "sent": "But rank aggregation is here, so you get here you are at 10 percent 15%.",
                    "label": 0
                },
                {
                    "sent": "Twenty percent is very, very disappointing.",
                    "label": 0
                },
                {
                    "sent": "Yeah I can put it anywhere.",
                    "label": 0
                },
                {
                    "sent": "Now.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This looks very fishy to us.",
                    "label": 0
                },
                {
                    "sent": "So we checked the software.",
                    "label": 0
                },
                {
                    "sent": "We checked this and that.",
                    "label": 0
                },
                {
                    "sent": "So now we believe this.",
                    "label": 0
                },
                {
                    "sent": "So we believe that rank agregation is not working well in this case.",
                    "label": 0
                },
                {
                    "sent": "Now what is a possible explanation?",
                    "label": 0
                },
                {
                    "sent": "So again, notice that this study with respect to previous study concerns very sparse vectors with a huge number of dimensions.",
                    "label": 0
                },
                {
                    "sent": "Now we did try with dense vectors.",
                    "label": 0
                },
                {
                    "sent": "We tried rank aggregation with dense vectors and the performance was much much much better.",
                    "label": 0
                },
                {
                    "sent": "Also, in fact, regulation was introduced to give good approximation of Euclidean distance, so with respect to Euclidean distance we get the data one minute, 0 minutes, 30 seconds.",
                    "label": 0
                },
                {
                    "sent": "So we get so we get results which are the same that were reported in the study.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now the future of that actions.",
                    "label": 0
                },
                {
                    "sent": "So the conclusion, I think, is that this random clustering is remarkably effective now in this study.",
                    "label": 0
                },
                {
                    "sent": "Also have an extremely cool generative model.",
                    "label": 0
                },
                {
                    "sent": "I didn't have time to tell you about with which we can prove amazing things.",
                    "label": 0
                },
                {
                    "sent": "Not not that fit.",
                    "label": 0
                },
                {
                    "sent": "Now with this model we can actually prove mathematically that the random clustering performs.",
                    "label": 0
                },
                {
                    "sent": "Well, OK, now the next thing to do is to see how this generative model fits the data.",
                    "label": 0
                },
                {
                    "sent": "So if it's compatible with the.",
                    "label": 0
                },
                {
                    "sent": "OK, so we are trying to combine.",
                    "label": 0
                },
                {
                    "sent": "Random Sample with recreation.",
                    "label": 0
                },
                {
                    "sent": "An interesting way, and it seems to work very nicely.",
                    "label": 0
                },
                {
                    "sent": "And also we want to extend this clustering approach with the page rank, so with links and again we have some interesting things I would.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Like to close with a challenge to the audience.",
                    "label": 0
                },
                {
                    "sent": "So does anybody know the origin of the word Yahoo.",
                    "label": 0
                },
                {
                    "sent": "And I think the answer is going to be very interesting.",
                    "label": 0
                },
                {
                    "sent": "OK, thanks.",
                    "label": 0
                },
                {
                    "sent": "OK, so we have a place.",
                    "label": 0
                },
                {
                    "sent": "Another yard.",
                    "label": 0
                },
                {
                    "sent": "OK, yet OK the answer, so the so.",
                    "label": 0
                },
                {
                    "sent": "OK, that's the wrong answer, and it's very interesting why.",
                    "label": 0
                },
                {
                    "sent": "I mean, it's true, but there is a.",
                    "label": 0
                },
                {
                    "sent": "There is another reason why.",
                    "label": 0
                },
                {
                    "sent": "I mean there is another meaning of the word you.",
                    "label": 0
                },
                {
                    "sent": "Work.",
                    "label": 0
                },
                {
                    "sent": "OK, great, so that's that's the correct answer, so it's from Gulliver's Journey by Jonathan Swift, so.",
                    "label": 0
                },
                {
                    "sent": "Intended pun that.",
                    "label": 0
                },
                {
                    "sent": "OK, you get a plus, OK?",
                    "label": 0
                },
                {
                    "sent": "OK, the interesting thing so Yahoo is what yet another hierarchical blah.",
                    "label": 0
                },
                {
                    "sent": "OK, so that's the nerd answer.",
                    "label": 0
                },
                {
                    "sent": "But then also this is a species of Gulliver's Journey by Jonathan Swift, and in the end he so this is a. I mean, these are people and he discovers in the end that he himself is a Yahoo and we're all yahoos.",
                    "label": 0
                },
                {
                    "sent": "OK thanks.",
                    "label": 0
                },
                {
                    "sent": "With.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Sensible.",
                    "label": 0
                },
                {
                    "sent": "I don't know sensitive.",
                    "label": 0
                },
                {
                    "sent": "So you just take square root and points at random and.",
                    "label": 0
                },
                {
                    "sent": "Different initial random points.",
                    "label": 0
                },
                {
                    "sent": "Oh, so if the variance no it's not.",
                    "label": 0
                },
                {
                    "sent": "It will be fine.",
                    "label": 0
                },
                {
                    "sent": "Did you try to search in the two or three years glasses?",
                    "label": 0
                },
                {
                    "sent": "Yeah yeah.",
                    "label": 0
                },
                {
                    "sent": "So in practice then that's what you do.",
                    "label": 0
                },
                {
                    "sent": "You don't.",
                    "label": 0
                },
                {
                    "sent": "You don't look in the nearest classify.",
                    "label": 0
                },
                {
                    "sent": "You take the 10 closest clusters.",
                    "label": 0
                },
                {
                    "sent": "Didn't do it in the experiment.",
                    "label": 0
                },
                {
                    "sent": "Experiment, experiment you do.",
                    "label": 0
                },
                {
                    "sent": "Yeah, oh, you're doing, yeah.",
                    "label": 0
                },
                {
                    "sent": "Did you ever write your message using some measures, for example, F measure of customer in order table?",
                    "label": 0
                },
                {
                    "sent": "Is equality give you give you compare the result of clustering with expert opinion phrases or no no no.",
                    "label": 0
                },
                {
                    "sent": "So this is we just just match with the.",
                    "label": 0
                },
                {
                    "sent": "So we believe that cosine similarity is a good proxy for relevance.",
                    "label": 0
                },
                {
                    "sent": "So we know the truth with respect to cosines to cosine similarity, and we match against that.",
                    "label": 0
                },
                {
                    "sent": "And this is says the advantage that it's a purely mathematical notion.",
                    "label": 0
                },
                {
                    "sent": "You don't need to, but no, we don't.",
                    "label": 0
                },
                {
                    "sent": "Easy metal strongly rent on the spherical clusters but not the object or object in the form of some chains.",
                    "label": 0
                },
                {
                    "sent": "Some chain approach it is I can consume it strongly, ranging from the spiritual simplicity.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so it's a spiritual thing.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                }
            ]
        }
    }
}