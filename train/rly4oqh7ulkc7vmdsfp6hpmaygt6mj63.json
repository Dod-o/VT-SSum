{
    "id": "rly4oqh7ulkc7vmdsfp6hpmaygt6mj63",
    "title": "Analyzing the Behavior of Deep Visual Question Answering Models",
    "info": {
        "author": [
            "Aishwarya Agrawal, Virginia Polytechnic Institute and State University"
        ],
        "published": "Aug. 23, 2016",
        "recorded": "August 2016",
        "category": [
            "Top->Computer Science->Machine Learning->Deep Learning",
            "Top->Computer Science->Machine Learning->Reinforcement Learning",
            "Top->Computer Science->Machine Learning->Unsupervised Learning"
        ]
    },
    "url": "http://videolectures.net/deeplearning2016_agrawal_answering_models/",
    "segmentation": [
        [
            "I'm a PhD student at Virginia Tech and aside and said, I'm going to talk about our work on analyzing the behavior of deeply care models, and this is going to be presented at MLP in next few months.",
            "This is a joint work with my advisor through Better and David Parekh.",
            "So for those of you."
        ],
        [
            "Not familiar with this line of research of V QV Q stands for Visual Question answering.",
            "So what is visual question answering?",
            "Let me give you an example.",
            "Given an image and a natural language, open ended questions such as what is the mustache made of the task for an artificial intelligence system is to generate a natural language answer, which in this case would be bananas."
        ],
        [
            "There have been a number of papers being published on different conferences and appearing on archive proposing deep models for visual Question answering.",
            "At CPR this year, they were three paper."
        ],
        [
            "As in one organization talking about Visual question answering."
        ],
        [
            "There was a challenge at CPR where the results of the visual Question answering Challenge were announced.",
            "They were third."
        ],
        [
            "Teams participating in the challenge.",
            "So there has been a lot of excitement around visual Question answering recently.",
            "However, there is a."
        ],
        [
            "Interesting observations to be made.",
            "It should be noted that the performance of most models is clustered around 60 to 66% compared to human performance, which is 83% particular data set.",
            "Yeah, so I should have mentioned this is on the V QA data set which is which is from my group.",
            "This is a weekly is a large scale data set consisting of hundreds of thousands of images and 1,000,000 answers.",
            "All the images are coming from Microsoft Coco and questions were collected from Amazon.",
            "Nickel and answers will also connect collected from Amazon Mechanical Turk.",
            "So it should also be noted that these mean 5% gap between top nine entries in the weekly Challenge.",
            "So how do we identify what are the most fruitful directions of making progress?",
            "How do we compare strengths and weaknesses of different models?",
            "How do we develop insights into the failure modes of different models?",
            "We believe that as."
        ],
        [
            "First step in understanding in this direction is to understand the behavior of current models.",
            "So in order to understand the behavior of these models, we will first analyze if current VK models generalize to normal instances."
        ],
        [
            "We will then see if current Wikia models listen to the entire question and then we will see."
        ],
        [
            "He is currently K models.",
            "Look at the image.",
            "I would like to mention that the techniques that I'm going to present to you now are applicable to all deeply care models.",
            "But in this task I will be focusing on two models, each coming from two major classes of VK models with attention and without attention.",
            "So the first model that I'm going to talk."
        ],
        [
            "Think about is not using any kind of attention is a vanilla CNN plus LTE model.",
            "This is from a weekly paper.",
            "It achieves an accuracy of 54% on the validation split of the week your data set.",
            "The second model."
        ],
        [
            "It uses attention on both the question and the image, and this is hierarchical Co attention from Lu at all.",
            "It achieves an accuracy of 57% on the validation split of the weaker data set.",
            "So let's look at let me walk you through the without attention model first."
        ],
        [
            "It is a 2 channel model image channel and the question channel image channel extracts image features using Ginette Question channel extracts question features using an STM.",
            "The two those two features are mapped to same dimension using fully connected layers.",
            "These these features are in pointwise multiplied and then pass through another fully connected layer to generate a softmax distribution over a predefined vocabulary of answers and finally the maximum confident answer is 2.",
            "This is the with the tank."
        ],
        [
            "Model given an input image and a question, what is the color of the word?"
        ],
        [
            "Embedding set extracted for the question at different levels.",
            "So why?"
        ],
        [
            "Level.",
            "This is phase level embedding and this is sentence level.",
            "Embedding image features are extracted using CNN's.",
            "At each level, Co attention is applied to both the image and the question.",
            "And the final answer is predicted using the Co attended features at each level of the hierarchy.",
            "OK, so let's look at."
        ],
        [
            "But we came out how we can models generalize to normal."
        ],
        [
            "Instances the question that we are interested in answering is the following.",
            "Do we create models make mistakes because test instances are two different from training instances?",
            "Specifically."
        ],
        [
            "Can lower test accuracy be attributed to test question image pairs being 2 first two different from training question image pairs?"
        ],
        [
            "Or can it be attributed to test question image pairs are familiar, but the labels are too different from the training labels."
        ],
        [
            "Let's first look at how models behave when test question image pairs are two different from training question image bills.",
            "So."
        ],
        [
            "So um, to analyze this, we first find out we first compute K nearest neighbor training pairs for every test question image pair.",
            "We then compute average distances between the K nearest neighbor training pairs and the test bill, and then we finally measure the correlation between the test accuracy and the average distance that we computed above.",
            "So now the question is in Word."
        ],
        [
            "Space do we compute these K nearest neighbors?",
            "So for the without attention model?",
            "So both the models we compute the K nearest neighbor in this space of combined question plus image embedding.",
            "This is model specific embedding."
        ],
        [
            "So for example, for the case of without attention model."
        ],
        [
            "As the embedding in which we compute the K nearest neighbors, this is just before passing through the fully connected layer."
        ],
        [
            "And for this model, this is again the embedding in which we compute the K nearest neighbors.",
            "So this embedding is encoding the information of both the question and the image.",
            "And so we observed that there is significant negative correlation, but."
        ],
        [
            "In the test accuracy and the distances of the test fails with training pairs and."
        ],
        [
            "Negative correlation is minus .41.",
            "Further, without attention model and minus .424 with attention model."
        ],
        [
            "So this energies tells us that we came.",
            "Orders tend to fail on novel instances."
        ],
        [
            "And hence we are calling them myopic."
        ],
        [
            "We also found that a significant percentage of mistakes can be successfully predicted."
        ],
        [
            "By checking the distance of Test Qi, perform the training nearest neighbors and so 67.5% of the mistakes can be predicted for without attention model and 66.7% of the mistakes can be predicted for with attention model."
        ],
        [
            "So this analysis not only exposes a reason for mistakes being made by models, but also provides a way for models to predict their own oncoming failures."
        ],
        [
            "This being more human, like by refusing to answer questions that are two different from the one seen in the training.",
            "So far, consider this example."
        ],
        [
            "For the given image and the question, what type of reception is being attended?"
        ],
        [
            "Did Alex cake as the answer?"
        ],
        [
            "It is the ground truth.",
            "Answer this wedding.",
            "Now let us look at the nearest neighbor question.",
            "An image players from the train."
        ],
        [
            "So we can see that when you simple question and image pairs a semantic semantically different from the test question, an image pairs probably explaining the mistake."
        ],
        [
            "Now let us see how models behave when the test question image pairs are familiar, but the labels test labels required are different from what models have seen during training.",
            "So again."
        ],
        [
            "We first compute the K nearest neighbor training pairs as we did in the previous experiment.",
            "And then in this case we compute the distance between the ground truth answers of the test pair and the ground truth answers of the training pairs.",
            "And we do this in this space of what to make.",
            "And then finally we measure correlation between the test accuracy and the average distance.",
            "So we again."
        ],
        [
            "Following that, there is a significant negative correlation between the test accuracy and the average distance."
        ],
        [
            "This correlation is minus 0.62.",
            "Further, without attention model and minus, again minus 2.62.",
            "Further with attention model."
        ],
        [
            "So this tells us that we create models tend to repeat answers that they have seen during training, but they fail when the answer required a test time is different.",
            "That's true for any machine learning.",
            "Right, but I will show you example where you can.",
            "If you have a specifically compositional model.",
            "It became clear that from an example."
        ],
        [
            "Consider this example.",
            "What color are the safety cones?"
        ],
        [
            "Model says Orange, but the ground."
        ],
        [
            "Good answer is green.",
            "Now let us look at the nearest neighbor training pairs."
        ],
        [
            "So the model has seen the question similar to what color are the safety cones in the training, but it has only seen orange cones.",
            "So this shows that today's models lag compositionality.",
            "Models I've seen cone into training and green for some other instance in the training, but they have not seen green and gold together, so modern slack compositionality if they know how to combine these two concepts.",
            "They will be able to answer this question green at testing.",
            "They said answer your question."
        ],
        [
            "Now let's look at whether we could models listen to the entire question.",
            "So in order to analyze this."
        ],
        [
            "We feed partial questions to the model, so for this image and the question how many houses are on the beach?",
            "The answer is 2, but we are interested in knowing what the model says when we just feed in the first word of the."
        ],
        [
            "First 2 words of the question and so on, along with the image.",
            "So we as I said, we."
        ],
        [
            "The model with partial questions of in."
        ],
        [
            "Policing length and then we compute the percentage of questions for which the responses to the partial question are same as the responses to the full question.",
            "So in."
        ],
        [
            "Split the X axis shows the length of the partial question, fed as input to the model and the Y axis shows the percentage of questions for which responses of these partial questions are same as full questions.",
            "We can see it."
        ],
        [
            "When only half of the question is fed as input to remodel the responses."
        ],
        [
            "For 41% of the questions are same as the responses for the full question.",
            "So this tells us that the model is listening to first few words more than the words.",
            "The words towards the end of the question."
        ],
        [
            "This is the same plot for the attention model and supply.",
            "In this case, the model can."
        ],
        [
            "Images on a predicted answer after listening to half of the question."
        ],
        [
            "More often.",
            "So we found that we came models converge on."
        ],
        [
            "Answers after listening to half of the question for a significant percentage of questions and this percentage."
        ],
        [
            "41% for without attention model and 49% for the with attention model."
        ],
        [
            "And hence we conclude that they often jump to conclusions."
        ],
        [
            "So this is a plot showing the accuracy of the model after when they spit out answers after listening to half of the question."
        ],
        [
            "So we can see that the accuracy after listening to half of the question is 37% for the without attention model and this accuracy is."
        ],
        [
            "88% of the final accuracy, which is 54%."
        ],
        [
            "This is for the with attention model.",
            "The accuracy after listening to half of the."
        ],
        [
            "Ocean is 42%, which is 74% of the."
        ],
        [
            "In electricity, which is 57%, let me show you something."
        ],
        [
            "Numbers.",
            "So for this image and the question is, are they playing a game?",
            "The model converges on the answer yes.",
            "After listening to the first 2 words.",
            "And in this case the answer is correct."
        ],
        [
            "So my impression of this data set is that whenever you're asking that question of are they the answers by its very strong sports.",
            "Yes, that is true.",
            "For binary questions, you're right, it is not like all the questions that have.",
            "Yes is the answer, but you will see 70% of the questions have.",
            "Yes they count with answer, but that is not true for all the different types of questions like the examples I'm going to show you.",
            "So for example how.",
            "How many houses are on the beach?",
            "The model says to just after listening to the first 2 words.",
            "So whenever it says how many it assumes, the answer is 2 and does not change its answer later and it gets incorrect because the correct answer is 6."
        ],
        [
            "Is the bench made up of metal?",
            "It says no.",
            "After listening to the phrase is the bench whereas the correct answer is yes."
        ],
        [
            "Similarly, what season of the Earth was this photo taken in?",
            "It says summer after listening to just two words, what season and the correct answer is spring?"
        ],
        [
            "So now let us look at whether these models look at the image."
        ],
        [
            "In order to analyze this, we compute how often model predicts the same answer for a given question across different images.",
            "So for this question, how many zebras and for the given image the model says 2, but we're interested in knowing what would model, say for this image."
        ],
        [
            "For this image for this image.",
            "So we first compute the."
        ],
        [
            "Centage of times, let's call it X.",
            "The responses do not change across images for a particular question and then we."
        ],
        [
            "But the histogram of X across questions."
        ],
        [
            "So in this plot I'm showing the histogram and the X axis shows the percentage of images for which the model produces the same answer, so the rightmost bin.",
            "Is that these are the questions for which the model produced the same answer across all the images?"
        ],
        [
            "And this is a cumulative plot which shows the percentage which shows the percentage of images for which the model produces percentage of questions for which the model produces the same answer for at least X percent of the images."
        ],
        [
            "So we can see that the model produces the same answer for at least half of the images for."
        ],
        [
            "At 56% of the questions.",
            "And this is the."
        ],
        [
            "Attention Model an in this case."
        ],
        [
            "They wanted their Dicks.",
            "The same answer for at least half of the images for."
        ],
        [
            "82% of the questions which is less than the attention without attention model."
        ],
        [
            "So we saw that we came models do not change their responses across images for significant percentage of questions."
        ],
        [
            "And they do so for 56% of the questions.",
            "In the case of without attention model and 42% of the questions in case case of with attention model."
        ],
        [
            "And hence we call them stubborn."
        ],
        [
            "We also saw that attention based models are less stubborn then non attention based models which is intuitive.",
            "So.",
            "For this quest."
        ],
        [
            "And what does the red sign say?"
        ],
        [
            "Modern thetics stop as the answer."
        ],
        [
            "For this image and it is correct."
        ],
        [
            "It does so for this image."
        ],
        [
            "For this image."
        ],
        [
            "This image.",
            "Similarly."
        ],
        [
            "I'm easy that is the monitor X2."
        ],
        [
            "For this image, but it also."
        ],
        [
            "Is 2 for this."
        ],
        [
            "Read this image."
        ],
        [
            "And this image."
        ],
        [
            "We also made another."
        ],
        [
            "Interesting observation that the accuracy of the questions for which the answer is same for at least half of the images."
        ],
        [
            "Is 50."
        ],
        [
            "6% which is greater."
        ],
        [
            "And the accuracy for the entire data set, which is 54%.",
            "And say."
        ],
        [
            "Is the case for."
        ],
        [
            "Attention based."
        ],
        [
            "Model the accuracy of the questions for which it is predicting the same answer across images is good."
        ],
        [
            "Other than the accuracy across the entire data set, so why is this the case?"
        ],
        [
            "We show you an example what covers the ground and the model says no.",
            "And this is correct for all the images, and this is so because this question what covers the ground has been asked in the data set only if the images have snow.",
            "So the model will always get it correct.",
            "So we observed that producing same response."
        ],
        [
            "This does not necessarily hurt.",
            "And it exposes late."
        ],
        [
            "All biases in the data set.",
            "So to conclude."
        ],
        [
            "We develop, we presented novel techniques for characterizing the behavior of today's deeply Kia models, and we found that today's models are they fail to generalize or novel instances.",
            "They tend to converge on a predicted answer after listening to half of the question, and they do not change their responses across images.",
            "For the given question.",
            "Before the wrapping up."
        ],
        [
            "I would like you to keep a few things in mind.",
            "The behavior of the key model that I talked earlier probably correct behavior given the data set it was trained on.",
            "These models are doing what is statistically favorable.",
            "But an analysis is about revealing the implications of that.",
            "It is good to know what the current behavior is.",
            "And 3rd, we want the community to think about whether this is the desired behavior in an intelligent, weaker system, and if not, how should we try to imitate?",
            "Should we train different classes of models or should we change the biases in the data set?",
            "And finally, we are using anthropomorphic objectives, such as stubborn, myopic too early.",
            "For pedagogical reasons.",
            "We these labels are just to communicate the behavior to you.",
            "We are not claiming that these models are human, like in any way.",
            "Thank you."
        ],
        [
            "And I would be happy to take your questions."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I'm a PhD student at Virginia Tech and aside and said, I'm going to talk about our work on analyzing the behavior of deeply care models, and this is going to be presented at MLP in next few months.",
                    "label": 1
                },
                {
                    "sent": "This is a joint work with my advisor through Better and David Parekh.",
                    "label": 0
                },
                {
                    "sent": "So for those of you.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Not familiar with this line of research of V QV Q stands for Visual Question answering.",
                    "label": 0
                },
                {
                    "sent": "So what is visual question answering?",
                    "label": 0
                },
                {
                    "sent": "Let me give you an example.",
                    "label": 0
                },
                {
                    "sent": "Given an image and a natural language, open ended questions such as what is the mustache made of the task for an artificial intelligence system is to generate a natural language answer, which in this case would be bananas.",
                    "label": 1
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "There have been a number of papers being published on different conferences and appearing on archive proposing deep models for visual Question answering.",
                    "label": 0
                },
                {
                    "sent": "At CPR this year, they were three paper.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "As in one organization talking about Visual question answering.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "There was a challenge at CPR where the results of the visual Question answering Challenge were announced.",
                    "label": 0
                },
                {
                    "sent": "They were third.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Teams participating in the challenge.",
                    "label": 0
                },
                {
                    "sent": "So there has been a lot of excitement around visual Question answering recently.",
                    "label": 0
                },
                {
                    "sent": "However, there is a.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Interesting observations to be made.",
                    "label": 0
                },
                {
                    "sent": "It should be noted that the performance of most models is clustered around 60 to 66% compared to human performance, which is 83% particular data set.",
                    "label": 1
                },
                {
                    "sent": "Yeah, so I should have mentioned this is on the V QA data set which is which is from my group.",
                    "label": 0
                },
                {
                    "sent": "This is a weekly is a large scale data set consisting of hundreds of thousands of images and 1,000,000 answers.",
                    "label": 0
                },
                {
                    "sent": "All the images are coming from Microsoft Coco and questions were collected from Amazon.",
                    "label": 0
                },
                {
                    "sent": "Nickel and answers will also connect collected from Amazon Mechanical Turk.",
                    "label": 0
                },
                {
                    "sent": "So it should also be noted that these mean 5% gap between top nine entries in the weekly Challenge.",
                    "label": 0
                },
                {
                    "sent": "So how do we identify what are the most fruitful directions of making progress?",
                    "label": 1
                },
                {
                    "sent": "How do we compare strengths and weaknesses of different models?",
                    "label": 0
                },
                {
                    "sent": "How do we develop insights into the failure modes of different models?",
                    "label": 0
                },
                {
                    "sent": "We believe that as.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "First step in understanding in this direction is to understand the behavior of current models.",
                    "label": 0
                },
                {
                    "sent": "So in order to understand the behavior of these models, we will first analyze if current VK models generalize to normal instances.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We will then see if current Wikia models listen to the entire question and then we will see.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "He is currently K models.",
                    "label": 0
                },
                {
                    "sent": "Look at the image.",
                    "label": 0
                },
                {
                    "sent": "I would like to mention that the techniques that I'm going to present to you now are applicable to all deeply care models.",
                    "label": 0
                },
                {
                    "sent": "But in this task I will be focusing on two models, each coming from two major classes of VK models with attention and without attention.",
                    "label": 0
                },
                {
                    "sent": "So the first model that I'm going to talk.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Think about is not using any kind of attention is a vanilla CNN plus LTE model.",
                    "label": 0
                },
                {
                    "sent": "This is from a weekly paper.",
                    "label": 0
                },
                {
                    "sent": "It achieves an accuracy of 54% on the validation split of the week your data set.",
                    "label": 0
                },
                {
                    "sent": "The second model.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "It uses attention on both the question and the image, and this is hierarchical Co attention from Lu at all.",
                    "label": 1
                },
                {
                    "sent": "It achieves an accuracy of 57% on the validation split of the weaker data set.",
                    "label": 1
                },
                {
                    "sent": "So let's look at let me walk you through the without attention model first.",
                    "label": 1
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It is a 2 channel model image channel and the question channel image channel extracts image features using Ginette Question channel extracts question features using an STM.",
                    "label": 0
                },
                {
                    "sent": "The two those two features are mapped to same dimension using fully connected layers.",
                    "label": 0
                },
                {
                    "sent": "These these features are in pointwise multiplied and then pass through another fully connected layer to generate a softmax distribution over a predefined vocabulary of answers and finally the maximum confident answer is 2.",
                    "label": 0
                },
                {
                    "sent": "This is the with the tank.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Model given an input image and a question, what is the color of the word?",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Embedding set extracted for the question at different levels.",
                    "label": 0
                },
                {
                    "sent": "So why?",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Level.",
                    "label": 0
                },
                {
                    "sent": "This is phase level embedding and this is sentence level.",
                    "label": 0
                },
                {
                    "sent": "Embedding image features are extracted using CNN's.",
                    "label": 0
                },
                {
                    "sent": "At each level, Co attention is applied to both the image and the question.",
                    "label": 0
                },
                {
                    "sent": "And the final answer is predicted using the Co attended features at each level of the hierarchy.",
                    "label": 0
                },
                {
                    "sent": "OK, so let's look at.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But we came out how we can models generalize to normal.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Instances the question that we are interested in answering is the following.",
                    "label": 0
                },
                {
                    "sent": "Do we create models make mistakes because test instances are two different from training instances?",
                    "label": 1
                },
                {
                    "sent": "Specifically.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Can lower test accuracy be attributed to test question image pairs being 2 first two different from training question image pairs?",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Or can it be attributed to test question image pairs are familiar, but the labels are too different from the training labels.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Let's first look at how models behave when test question image pairs are two different from training question image bills.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So um, to analyze this, we first find out we first compute K nearest neighbor training pairs for every test question image pair.",
                    "label": 0
                },
                {
                    "sent": "We then compute average distances between the K nearest neighbor training pairs and the test bill, and then we finally measure the correlation between the test accuracy and the average distance that we computed above.",
                    "label": 1
                },
                {
                    "sent": "So now the question is in Word.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Space do we compute these K nearest neighbors?",
                    "label": 0
                },
                {
                    "sent": "So for the without attention model?",
                    "label": 0
                },
                {
                    "sent": "So both the models we compute the K nearest neighbor in this space of combined question plus image embedding.",
                    "label": 0
                },
                {
                    "sent": "This is model specific embedding.",
                    "label": 1
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So for example, for the case of without attention model.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "As the embedding in which we compute the K nearest neighbors, this is just before passing through the fully connected layer.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And for this model, this is again the embedding in which we compute the K nearest neighbors.",
                    "label": 0
                },
                {
                    "sent": "So this embedding is encoding the information of both the question and the image.",
                    "label": 1
                },
                {
                    "sent": "And so we observed that there is significant negative correlation, but.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In the test accuracy and the distances of the test fails with training pairs and.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Negative correlation is minus .41.",
                    "label": 0
                },
                {
                    "sent": "Further, without attention model and minus .424 with attention model.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this energies tells us that we came.",
                    "label": 0
                },
                {
                    "sent": "Orders tend to fail on novel instances.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And hence we are calling them myopic.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We also found that a significant percentage of mistakes can be successfully predicted.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "By checking the distance of Test Qi, perform the training nearest neighbors and so 67.5% of the mistakes can be predicted for without attention model and 66.7% of the mistakes can be predicted for with attention model.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this analysis not only exposes a reason for mistakes being made by models, but also provides a way for models to predict their own oncoming failures.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This being more human, like by refusing to answer questions that are two different from the one seen in the training.",
                    "label": 0
                },
                {
                    "sent": "So far, consider this example.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For the given image and the question, what type of reception is being attended?",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Did Alex cake as the answer?",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "It is the ground truth.",
                    "label": 0
                },
                {
                    "sent": "Answer this wedding.",
                    "label": 0
                },
                {
                    "sent": "Now let us look at the nearest neighbor question.",
                    "label": 1
                },
                {
                    "sent": "An image players from the train.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we can see that when you simple question and image pairs a semantic semantically different from the test question, an image pairs probably explaining the mistake.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now let us see how models behave when the test question image pairs are familiar, but the labels test labels required are different from what models have seen during training.",
                    "label": 0
                },
                {
                    "sent": "So again.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We first compute the K nearest neighbor training pairs as we did in the previous experiment.",
                    "label": 0
                },
                {
                    "sent": "And then in this case we compute the distance between the ground truth answers of the test pair and the ground truth answers of the training pairs.",
                    "label": 1
                },
                {
                    "sent": "And we do this in this space of what to make.",
                    "label": 0
                },
                {
                    "sent": "And then finally we measure correlation between the test accuracy and the average distance.",
                    "label": 1
                },
                {
                    "sent": "So we again.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Following that, there is a significant negative correlation between the test accuracy and the average distance.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This correlation is minus 0.62.",
                    "label": 1
                },
                {
                    "sent": "Further, without attention model and minus, again minus 2.62.",
                    "label": 0
                },
                {
                    "sent": "Further with attention model.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this tells us that we create models tend to repeat answers that they have seen during training, but they fail when the answer required a test time is different.",
                    "label": 1
                },
                {
                    "sent": "That's true for any machine learning.",
                    "label": 0
                },
                {
                    "sent": "Right, but I will show you example where you can.",
                    "label": 0
                },
                {
                    "sent": "If you have a specifically compositional model.",
                    "label": 0
                },
                {
                    "sent": "It became clear that from an example.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Consider this example.",
                    "label": 0
                },
                {
                    "sent": "What color are the safety cones?",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Model says Orange, but the ground.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Good answer is green.",
                    "label": 0
                },
                {
                    "sent": "Now let us look at the nearest neighbor training pairs.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the model has seen the question similar to what color are the safety cones in the training, but it has only seen orange cones.",
                    "label": 1
                },
                {
                    "sent": "So this shows that today's models lag compositionality.",
                    "label": 0
                },
                {
                    "sent": "Models I've seen cone into training and green for some other instance in the training, but they have not seen green and gold together, so modern slack compositionality if they know how to combine these two concepts.",
                    "label": 0
                },
                {
                    "sent": "They will be able to answer this question green at testing.",
                    "label": 0
                },
                {
                    "sent": "They said answer your question.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now let's look at whether we could models listen to the entire question.",
                    "label": 0
                },
                {
                    "sent": "So in order to analyze this.",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We feed partial questions to the model, so for this image and the question how many houses are on the beach?",
                    "label": 0
                },
                {
                    "sent": "The answer is 2, but we are interested in knowing what the model says when we just feed in the first word of the.",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "First 2 words of the question and so on, along with the image.",
                    "label": 0
                },
                {
                    "sent": "So we as I said, we.",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The model with partial questions of in.",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Policing length and then we compute the percentage of questions for which the responses to the partial question are same as the responses to the full question.",
                    "label": 0
                },
                {
                    "sent": "So in.",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Split the X axis shows the length of the partial question, fed as input to the model and the Y axis shows the percentage of questions for which responses of these partial questions are same as full questions.",
                    "label": 0
                },
                {
                    "sent": "We can see it.",
                    "label": 0
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "When only half of the question is fed as input to remodel the responses.",
                    "label": 0
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "For 41% of the questions are same as the responses for the full question.",
                    "label": 1
                },
                {
                    "sent": "So this tells us that the model is listening to first few words more than the words.",
                    "label": 0
                },
                {
                    "sent": "The words towards the end of the question.",
                    "label": 0
                }
            ]
        },
        "clip_55": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is the same plot for the attention model and supply.",
                    "label": 0
                },
                {
                    "sent": "In this case, the model can.",
                    "label": 0
                }
            ]
        },
        "clip_56": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Images on a predicted answer after listening to half of the question.",
                    "label": 0
                }
            ]
        },
        "clip_57": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "More often.",
                    "label": 0
                },
                {
                    "sent": "So we found that we came models converge on.",
                    "label": 0
                }
            ]
        },
        "clip_58": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Answers after listening to half of the question for a significant percentage of questions and this percentage.",
                    "label": 0
                }
            ]
        },
        "clip_59": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "41% for without attention model and 49% for the with attention model.",
                    "label": 0
                }
            ]
        },
        "clip_60": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And hence we conclude that they often jump to conclusions.",
                    "label": 0
                }
            ]
        },
        "clip_61": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is a plot showing the accuracy of the model after when they spit out answers after listening to half of the question.",
                    "label": 0
                }
            ]
        },
        "clip_62": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we can see that the accuracy after listening to half of the question is 37% for the without attention model and this accuracy is.",
                    "label": 0
                }
            ]
        },
        "clip_63": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "88% of the final accuracy, which is 54%.",
                    "label": 0
                }
            ]
        },
        "clip_64": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is for the with attention model.",
                    "label": 0
                },
                {
                    "sent": "The accuracy after listening to half of the.",
                    "label": 0
                }
            ]
        },
        "clip_65": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Ocean is 42%, which is 74% of the.",
                    "label": 0
                }
            ]
        },
        "clip_66": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In electricity, which is 57%, let me show you something.",
                    "label": 0
                }
            ]
        },
        "clip_67": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Numbers.",
                    "label": 0
                },
                {
                    "sent": "So for this image and the question is, are they playing a game?",
                    "label": 0
                },
                {
                    "sent": "The model converges on the answer yes.",
                    "label": 0
                },
                {
                    "sent": "After listening to the first 2 words.",
                    "label": 0
                },
                {
                    "sent": "And in this case the answer is correct.",
                    "label": 0
                }
            ]
        },
        "clip_68": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So my impression of this data set is that whenever you're asking that question of are they the answers by its very strong sports.",
                    "label": 0
                },
                {
                    "sent": "Yes, that is true.",
                    "label": 0
                },
                {
                    "sent": "For binary questions, you're right, it is not like all the questions that have.",
                    "label": 0
                },
                {
                    "sent": "Yes is the answer, but you will see 70% of the questions have.",
                    "label": 0
                },
                {
                    "sent": "Yes they count with answer, but that is not true for all the different types of questions like the examples I'm going to show you.",
                    "label": 0
                },
                {
                    "sent": "So for example how.",
                    "label": 0
                },
                {
                    "sent": "How many houses are on the beach?",
                    "label": 0
                },
                {
                    "sent": "The model says to just after listening to the first 2 words.",
                    "label": 0
                },
                {
                    "sent": "So whenever it says how many it assumes, the answer is 2 and does not change its answer later and it gets incorrect because the correct answer is 6.",
                    "label": 0
                }
            ]
        },
        "clip_69": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is the bench made up of metal?",
                    "label": 0
                },
                {
                    "sent": "It says no.",
                    "label": 0
                },
                {
                    "sent": "After listening to the phrase is the bench whereas the correct answer is yes.",
                    "label": 0
                }
            ]
        },
        "clip_70": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Similarly, what season of the Earth was this photo taken in?",
                    "label": 0
                },
                {
                    "sent": "It says summer after listening to just two words, what season and the correct answer is spring?",
                    "label": 0
                }
            ]
        },
        "clip_71": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So now let us look at whether these models look at the image.",
                    "label": 0
                }
            ]
        },
        "clip_72": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In order to analyze this, we compute how often model predicts the same answer for a given question across different images.",
                    "label": 0
                },
                {
                    "sent": "So for this question, how many zebras and for the given image the model says 2, but we're interested in knowing what would model, say for this image.",
                    "label": 0
                }
            ]
        },
        "clip_73": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For this image for this image.",
                    "label": 0
                },
                {
                    "sent": "So we first compute the.",
                    "label": 0
                }
            ]
        },
        "clip_74": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Centage of times, let's call it X.",
                    "label": 0
                },
                {
                    "sent": "The responses do not change across images for a particular question and then we.",
                    "label": 0
                }
            ]
        },
        "clip_75": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But the histogram of X across questions.",
                    "label": 0
                }
            ]
        },
        "clip_76": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So in this plot I'm showing the histogram and the X axis shows the percentage of images for which the model produces the same answer, so the rightmost bin.",
                    "label": 0
                },
                {
                    "sent": "Is that these are the questions for which the model produced the same answer across all the images?",
                    "label": 0
                }
            ]
        },
        "clip_77": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And this is a cumulative plot which shows the percentage which shows the percentage of images for which the model produces percentage of questions for which the model produces the same answer for at least X percent of the images.",
                    "label": 0
                }
            ]
        },
        "clip_78": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we can see that the model produces the same answer for at least half of the images for.",
                    "label": 0
                }
            ]
        },
        "clip_79": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "At 56% of the questions.",
                    "label": 0
                },
                {
                    "sent": "And this is the.",
                    "label": 0
                }
            ]
        },
        "clip_80": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Attention Model an in this case.",
                    "label": 0
                }
            ]
        },
        "clip_81": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "They wanted their Dicks.",
                    "label": 0
                },
                {
                    "sent": "The same answer for at least half of the images for.",
                    "label": 0
                }
            ]
        },
        "clip_82": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "82% of the questions which is less than the attention without attention model.",
                    "label": 0
                }
            ]
        },
        "clip_83": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we saw that we came models do not change their responses across images for significant percentage of questions.",
                    "label": 0
                }
            ]
        },
        "clip_84": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And they do so for 56% of the questions.",
                    "label": 0
                },
                {
                    "sent": "In the case of without attention model and 42% of the questions in case case of with attention model.",
                    "label": 0
                }
            ]
        },
        "clip_85": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And hence we call them stubborn.",
                    "label": 0
                }
            ]
        },
        "clip_86": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We also saw that attention based models are less stubborn then non attention based models which is intuitive.",
                    "label": 1
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "For this quest.",
                    "label": 0
                }
            ]
        },
        "clip_87": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And what does the red sign say?",
                    "label": 0
                }
            ]
        },
        "clip_88": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Modern thetics stop as the answer.",
                    "label": 0
                }
            ]
        },
        "clip_89": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For this image and it is correct.",
                    "label": 0
                }
            ]
        },
        "clip_90": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It does so for this image.",
                    "label": 0
                }
            ]
        },
        "clip_91": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For this image.",
                    "label": 0
                }
            ]
        },
        "clip_92": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This image.",
                    "label": 0
                },
                {
                    "sent": "Similarly.",
                    "label": 0
                }
            ]
        },
        "clip_93": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I'm easy that is the monitor X2.",
                    "label": 0
                }
            ]
        },
        "clip_94": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For this image, but it also.",
                    "label": 0
                }
            ]
        },
        "clip_95": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is 2 for this.",
                    "label": 0
                }
            ]
        },
        "clip_96": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Read this image.",
                    "label": 0
                }
            ]
        },
        "clip_97": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And this image.",
                    "label": 0
                }
            ]
        },
        "clip_98": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We also made another.",
                    "label": 0
                }
            ]
        },
        "clip_99": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Interesting observation that the accuracy of the questions for which the answer is same for at least half of the images.",
                    "label": 0
                }
            ]
        },
        "clip_100": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is 50.",
                    "label": 0
                }
            ]
        },
        "clip_101": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "6% which is greater.",
                    "label": 0
                }
            ]
        },
        "clip_102": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And the accuracy for the entire data set, which is 54%.",
                    "label": 0
                },
                {
                    "sent": "And say.",
                    "label": 0
                }
            ]
        },
        "clip_103": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is the case for.",
                    "label": 0
                }
            ]
        },
        "clip_104": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Attention based.",
                    "label": 0
                }
            ]
        },
        "clip_105": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Model the accuracy of the questions for which it is predicting the same answer across images is good.",
                    "label": 0
                }
            ]
        },
        "clip_106": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Other than the accuracy across the entire data set, so why is this the case?",
                    "label": 0
                }
            ]
        },
        "clip_107": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We show you an example what covers the ground and the model says no.",
                    "label": 0
                },
                {
                    "sent": "And this is correct for all the images, and this is so because this question what covers the ground has been asked in the data set only if the images have snow.",
                    "label": 0
                },
                {
                    "sent": "So the model will always get it correct.",
                    "label": 0
                },
                {
                    "sent": "So we observed that producing same response.",
                    "label": 0
                }
            ]
        },
        "clip_108": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This does not necessarily hurt.",
                    "label": 0
                },
                {
                    "sent": "And it exposes late.",
                    "label": 0
                }
            ]
        },
        "clip_109": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "All biases in the data set.",
                    "label": 0
                },
                {
                    "sent": "So to conclude.",
                    "label": 0
                }
            ]
        },
        "clip_110": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We develop, we presented novel techniques for characterizing the behavior of today's deeply Kia models, and we found that today's models are they fail to generalize or novel instances.",
                    "label": 0
                },
                {
                    "sent": "They tend to converge on a predicted answer after listening to half of the question, and they do not change their responses across images.",
                    "label": 1
                },
                {
                    "sent": "For the given question.",
                    "label": 0
                },
                {
                    "sent": "Before the wrapping up.",
                    "label": 0
                }
            ]
        },
        "clip_111": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I would like you to keep a few things in mind.",
                    "label": 0
                },
                {
                    "sent": "The behavior of the key model that I talked earlier probably correct behavior given the data set it was trained on.",
                    "label": 1
                },
                {
                    "sent": "These models are doing what is statistically favorable.",
                    "label": 0
                },
                {
                    "sent": "But an analysis is about revealing the implications of that.",
                    "label": 0
                },
                {
                    "sent": "It is good to know what the current behavior is.",
                    "label": 0
                },
                {
                    "sent": "And 3rd, we want the community to think about whether this is the desired behavior in an intelligent, weaker system, and if not, how should we try to imitate?",
                    "label": 0
                },
                {
                    "sent": "Should we train different classes of models or should we change the biases in the data set?",
                    "label": 1
                },
                {
                    "sent": "And finally, we are using anthropomorphic objectives, such as stubborn, myopic too early.",
                    "label": 0
                },
                {
                    "sent": "For pedagogical reasons.",
                    "label": 0
                },
                {
                    "sent": "We these labels are just to communicate the behavior to you.",
                    "label": 0
                },
                {
                    "sent": "We are not claiming that these models are human, like in any way.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                }
            ]
        },
        "clip_112": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And I would be happy to take your questions.",
                    "label": 0
                }
            ]
        }
    }
}