{
    "id": "6og44tuqvbdrjnhlnpile7htebgnhq7r",
    "title": "A Comparison of Authorship Attribution Approaches Applied on the Morphologically Complex Language Using Internet Comments",
    "info": {
        "author": [
            "Jurgita Kapo\u010di\u016bt\u0117-Dzikien\u0117, Vytautas Magnus University"
        ],
        "published": "June 21, 2017",
        "recorded": "May 2017",
        "category": [
            "Top->Humanities->Languages",
            "Top->Computers->Digital Media",
            "Top->Computer Science->Social Media"
        ]
    },
    "url": "http://videolectures.net/clarinplusworkshop2017_kapociute_dzikiene_internet/",
    "segmentation": [
        [
            "So I'm gonna go."
        ],
        [
            "And I'm from Vito.",
            "Does Magnus University from here and.",
            "My talk is about authorship Attribution for the Lithuanian language using Inter."
        ],
        [
            "Add comments, so first of all, authorship Attribution is the task of identifying from the set of candidate orders.",
            "There's an actual order for some unonius text, and this task is possible to solve due to the existing human style arm, so is them.",
            "Somehow some persistent, uncontrolled habit of humans to express their thoughts in a specific unique ways.",
            "And the authorship Attribution is one of the oldest problems.",
            "It is they were started to solve it when we had no computational linguistics and no computers."
        ],
        [
            "Well, the first research works were done on the literary applications on the literary text, but now it drifted more towards more practical applications and forensics, electronic Commerce or security."
        ],
        [
            "And of course there are a lot of works in the world done done on this topic, but I can summarize that recently they are done on emails.",
            "Therefore messages online chats, Internet blocks, tweets and so the texts are getting shorter and the research field is non normative language and the numbers of orders are also increasing.",
            "Like dozens years ago, they were doing the research on just a few orders, or dozens of authors.",
            "Right now they're doing on hundreds of thousands and even hundreds of thousands authors."
        ],
        [
            "Well in Lithuania this this topic is rather knew well the concept of idea elect was presented in 1971 and there are a lot of descriptive words works and there are a lot of right now and research works done on parliamentary transcripts and less orders.",
            "But right now I want to talk."
        ],
        [
            "Out.",
            "The research which is done on 1000 candidate orders and I would like to show the results for you to compare.",
            "What is the huge difference compared with the other languages where they can achieve like the accuracy almost 90% or 80%.",
            "So on Lithuanian language it does not work that good.",
            "But first of all, about the corpus, the corpus of Internet comments was crowd from Delphite.",
            "Anet covers eight months of period of eight months.",
            "And the problem is that the those to text the enter those Internet comments are written anonymously.",
            "So to get the clean corpus for training and afterwards for testing we try to avoid dynamic IP problem when if the same pseudonym was used for writing from different IP addresses or if different pseudonyms were used under the same IP address.",
            "None of these orders were included into our corpus, so.",
            "The idea was to get as clean corpus as possible in this case because otherwise it is impossible to use it for training or for anything.",
            "Replies, meta information.",
            "Other things were filter out and of course the text should be longer than at least 30 symbols because otherwise it is impossible to solve there anything.",
            "And since it is Lithuanian language, we have the problem of diacritics and there were of course a lot of out of vocabulary words and etc and this corpus is publicly available.",
            "So this is the website."
        ],
        [
            "This is the statistics since we solved the problem for 10 orders, 100 orders and 1000 Waters.",
            "One because we wanted to compare the results."
        ],
        [
            "And the methods we were used to wear machine learning, naive base and some and support vector machine.",
            "Are you basis performed?",
            "Some kind of a baseline function here.",
            "Similarity based based using cosine similarity similarity based is also the part of machine learning, but in many many research works these methods are used separately compared.",
            "We also tested different feature types, lexical, Lemos and word level character.",
            "Tetra Grams in different dimensionality reduction techniques like entire featured set feature ranking with he squared using 30,000 features and we also used a random feature set.",
            "In case iterations with, which is especially which gave especially good results in Copel work.",
            "An English language."
        ],
        [
            "So this is the experimental setup.",
            "We use stratified data data set and 80 and 20% for training and testing.",
            "Sometimes people ask why we were not using 10 fold cross validation because we had a lot of data.",
            "So you have one of the colleague stopped before and said that we were getting more and more and more data.",
            "But then when we have a lot of data is it is impossible to process it or it takes like months or few months to process it?",
            "So we calculate that accuracies and up scores and we use mcnemar test to see if the differences are statistically."
        ],
        [
            "And if icant so this is the result for 10 candidate orders, so they are not so bad.",
            "In this case we can see that the results are like 72% of Acura."
        ],
        [
            "See here with the 100 candidate orders.",
            "Again, the accuracy drops up to 46.7%."
        ],
        [
            "This is terrible.",
            "You know we have 1000 orders, and right now I'm talking about the accuracy, which is about 26.7% and compared to English, what I already said.",
            "Where can achieve like 85% or even more in this similar task, but much more.",
            "Or which wich with bigger datasets.",
            "So.",
            "But the Lithuanian language it does not work.",
            "The message, the methods which work for the other languages does not work.",
            "I can stop here for long but."
        ],
        [
            "I want to summarize all the results that not all results are reasonable because they do not exceed random and majority baselines.",
            "And the problem here is with the lemma teiser which cannot cope with a non normative language.",
            "Machine Learning is is better compared to similarity based in our case on all datasets and character Tetra Grams on the larger data on a larger order sets gave better accuracy as well and the entire feature set also gave the better.",
            "Accuracy compared to the other dimensional theory."
        ],
        [
            "Action techniques.",
            "And the conclusions would be that they were the first comparative authorship Attribution results in terms of methods, feature times, dimensionality reduction techniques for Lithuanian.",
            "Unfortunately, we cannot boast, you know, we only start working in this field.",
            "We are Lithuanian language is not English language and we performed this research on the Internet comments, which is also very challenging because people usually use like block data tweet data where.",
            "Very easy to identify who is the actual author of particular comment.",
            "And we used quite a big order set of 1000 candidate orders and the best results were achieved with machine learning and character tetragram's.",
            "Our future works work consists of error analysis and improvements and expanded number of candidate authors and as well different types of non normative texts.",
            "So probably tweets texts from Facebook."
        ],
        [
            "So I I also want to thank other researchers who worked on this topic in two different projects.",
            "And also I want to thank colleagues not only from it as Magnus, but goodness University of Technology as well."
        ],
        [
            "And thank you for your attention."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So I'm gonna go.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And I'm from Vito.",
                    "label": 0
                },
                {
                    "sent": "Does Magnus University from here and.",
                    "label": 0
                },
                {
                    "sent": "My talk is about authorship Attribution for the Lithuanian language using Inter.",
                    "label": 1
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Add comments, so first of all, authorship Attribution is the task of identifying from the set of candidate orders.",
                    "label": 1
                },
                {
                    "sent": "There's an actual order for some unonius text, and this task is possible to solve due to the existing human style arm, so is them.",
                    "label": 0
                },
                {
                    "sent": "Somehow some persistent, uncontrolled habit of humans to express their thoughts in a specific unique ways.",
                    "label": 0
                },
                {
                    "sent": "And the authorship Attribution is one of the oldest problems.",
                    "label": 1
                },
                {
                    "sent": "It is they were started to solve it when we had no computational linguistics and no computers.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Well, the first research works were done on the literary applications on the literary text, but now it drifted more towards more practical applications and forensics, electronic Commerce or security.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And of course there are a lot of works in the world done done on this topic, but I can summarize that recently they are done on emails.",
                    "label": 0
                },
                {
                    "sent": "Therefore messages online chats, Internet blocks, tweets and so the texts are getting shorter and the research field is non normative language and the numbers of orders are also increasing.",
                    "label": 1
                },
                {
                    "sent": "Like dozens years ago, they were doing the research on just a few orders, or dozens of authors.",
                    "label": 0
                },
                {
                    "sent": "Right now they're doing on hundreds of thousands and even hundreds of thousands authors.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Well in Lithuania this this topic is rather knew well the concept of idea elect was presented in 1971 and there are a lot of descriptive words works and there are a lot of right now and research works done on parliamentary transcripts and less orders.",
                    "label": 0
                },
                {
                    "sent": "But right now I want to talk.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Out.",
                    "label": 0
                },
                {
                    "sent": "The research which is done on 1000 candidate orders and I would like to show the results for you to compare.",
                    "label": 0
                },
                {
                    "sent": "What is the huge difference compared with the other languages where they can achieve like the accuracy almost 90% or 80%.",
                    "label": 0
                },
                {
                    "sent": "So on Lithuanian language it does not work that good.",
                    "label": 0
                },
                {
                    "sent": "But first of all, about the corpus, the corpus of Internet comments was crowd from Delphite.",
                    "label": 0
                },
                {
                    "sent": "Anet covers eight months of period of eight months.",
                    "label": 0
                },
                {
                    "sent": "And the problem is that the those to text the enter those Internet comments are written anonymously.",
                    "label": 0
                },
                {
                    "sent": "So to get the clean corpus for training and afterwards for testing we try to avoid dynamic IP problem when if the same pseudonym was used for writing from different IP addresses or if different pseudonyms were used under the same IP address.",
                    "label": 1
                },
                {
                    "sent": "None of these orders were included into our corpus, so.",
                    "label": 0
                },
                {
                    "sent": "The idea was to get as clean corpus as possible in this case because otherwise it is impossible to use it for training or for anything.",
                    "label": 0
                },
                {
                    "sent": "Replies, meta information.",
                    "label": 0
                },
                {
                    "sent": "Other things were filter out and of course the text should be longer than at least 30 symbols because otherwise it is impossible to solve there anything.",
                    "label": 0
                },
                {
                    "sent": "And since it is Lithuanian language, we have the problem of diacritics and there were of course a lot of out of vocabulary words and etc and this corpus is publicly available.",
                    "label": 0
                },
                {
                    "sent": "So this is the website.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is the statistics since we solved the problem for 10 orders, 100 orders and 1000 Waters.",
                    "label": 0
                },
                {
                    "sent": "One because we wanted to compare the results.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And the methods we were used to wear machine learning, naive base and some and support vector machine.",
                    "label": 1
                },
                {
                    "sent": "Are you basis performed?",
                    "label": 0
                },
                {
                    "sent": "Some kind of a baseline function here.",
                    "label": 0
                },
                {
                    "sent": "Similarity based based using cosine similarity similarity based is also the part of machine learning, but in many many research works these methods are used separately compared.",
                    "label": 0
                },
                {
                    "sent": "We also tested different feature types, lexical, Lemos and word level character.",
                    "label": 0
                },
                {
                    "sent": "Tetra Grams in different dimensionality reduction techniques like entire featured set feature ranking with he squared using 30,000 features and we also used a random feature set.",
                    "label": 1
                },
                {
                    "sent": "In case iterations with, which is especially which gave especially good results in Copel work.",
                    "label": 0
                },
                {
                    "sent": "An English language.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this is the experimental setup.",
                    "label": 1
                },
                {
                    "sent": "We use stratified data data set and 80 and 20% for training and testing.",
                    "label": 0
                },
                {
                    "sent": "Sometimes people ask why we were not using 10 fold cross validation because we had a lot of data.",
                    "label": 0
                },
                {
                    "sent": "So you have one of the colleague stopped before and said that we were getting more and more and more data.",
                    "label": 0
                },
                {
                    "sent": "But then when we have a lot of data is it is impossible to process it or it takes like months or few months to process it?",
                    "label": 0
                },
                {
                    "sent": "So we calculate that accuracies and up scores and we use mcnemar test to see if the differences are statistically.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And if icant so this is the result for 10 candidate orders, so they are not so bad.",
                    "label": 0
                },
                {
                    "sent": "In this case we can see that the results are like 72% of Acura.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "See here with the 100 candidate orders.",
                    "label": 0
                },
                {
                    "sent": "Again, the accuracy drops up to 46.7%.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is terrible.",
                    "label": 0
                },
                {
                    "sent": "You know we have 1000 orders, and right now I'm talking about the accuracy, which is about 26.7% and compared to English, what I already said.",
                    "label": 0
                },
                {
                    "sent": "Where can achieve like 85% or even more in this similar task, but much more.",
                    "label": 0
                },
                {
                    "sent": "Or which wich with bigger datasets.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "But the Lithuanian language it does not work.",
                    "label": 0
                },
                {
                    "sent": "The message, the methods which work for the other languages does not work.",
                    "label": 0
                },
                {
                    "sent": "I can stop here for long but.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I want to summarize all the results that not all results are reasonable because they do not exceed random and majority baselines.",
                    "label": 1
                },
                {
                    "sent": "And the problem here is with the lemma teiser which cannot cope with a non normative language.",
                    "label": 0
                },
                {
                    "sent": "Machine Learning is is better compared to similarity based in our case on all datasets and character Tetra Grams on the larger data on a larger order sets gave better accuracy as well and the entire feature set also gave the better.",
                    "label": 0
                },
                {
                    "sent": "Accuracy compared to the other dimensional theory.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Action techniques.",
                    "label": 0
                },
                {
                    "sent": "And the conclusions would be that they were the first comparative authorship Attribution results in terms of methods, feature times, dimensionality reduction techniques for Lithuanian.",
                    "label": 1
                },
                {
                    "sent": "Unfortunately, we cannot boast, you know, we only start working in this field.",
                    "label": 0
                },
                {
                    "sent": "We are Lithuanian language is not English language and we performed this research on the Internet comments, which is also very challenging because people usually use like block data tweet data where.",
                    "label": 0
                },
                {
                    "sent": "Very easy to identify who is the actual author of particular comment.",
                    "label": 0
                },
                {
                    "sent": "And we used quite a big order set of 1000 candidate orders and the best results were achieved with machine learning and character tetragram's.",
                    "label": 1
                },
                {
                    "sent": "Our future works work consists of error analysis and improvements and expanded number of candidate authors and as well different types of non normative texts.",
                    "label": 0
                },
                {
                    "sent": "So probably tweets texts from Facebook.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So I I also want to thank other researchers who worked on this topic in two different projects.",
                    "label": 0
                },
                {
                    "sent": "And also I want to thank colleagues not only from it as Magnus, but goodness University of Technology as well.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And thank you for your attention.",
                    "label": 0
                }
            ]
        }
    }
}