{
    "id": "cxvsajrwvjebje6rnghvbqp5ndkvme2s",
    "title": "On the Convergence of the Convex-Concave Procedure",
    "info": {
        "author": [
            "Bharath K. Sriperumbudur, Department of Electrical and Computer Engineering, UC San Diego"
        ],
        "published": "Jan. 19, 2010",
        "recorded": "December 2009",
        "category": [
            "Top->Computer Science->Machine Learning->Kernel Methods->Support Vector Machines"
        ]
    },
    "url": "http://videolectures.net/nipsworkshops09_sriperumbudur_ccc/",
    "segmentation": [
        [
            "Is done jointly with my advisor language at UC San Diego.",
            "So here is outline on the top.",
            "So the idea of this work is to analyze the convergence of concave convex procedure.",
            "So we first start with using the connection program and then being a non convex program.",
            "I'll motivate like order applications of these in machine learning and then there's a procedure called the concave convex procedure which has been introduced to solve these kind of problems and I'll show how.",
            "This procedure is a special case."
        ],
        [
            "Cough medicine.",
            "Because being introduced, the artistic literature around like 1960s.",
            "Next I get to the main part of the talk, which is the convergence analysis of CCP, which requires some notions of point to set Maps, and then using the global convergence theory of iterative algorithms."
        ],
        [
            "I provide the convergence analysis of TCP and then end the talk with an open question regarding the local content analysis.",
            "OK, so.",
            "What is the DC program?",
            "So first of all, what is the DC function?",
            "Any real valued function F is called EC function if there exists like 2 can function.",
            "We can be expressed as the difference of convex lens.",
            "Nowadays the program is minimization of an objective, which is a DC function subject to the constraints.",
            "It has been shown that such programs are computationally hard to solve, and this being a non convex program so would wonder.",
            "I mean why do we need to care about such programs?",
            "Given that in machining optimization seems to be the popular approach, why do you need to care about this?",
            "They are important locations in learning.",
            "We, especially when you deal with problems, sparse PCA or do feature selection.",
            "SVM even translate to experience this kind of problem here showing that consider the problem of teams.",
            "So instead of using the usual L2 regularizer on W is a multi consumed.",
            "Is your brother an?",
            "So this program can be solved either as a."
        ],
        [
            "Discrete optimization problem or I can use an approximation Becauses account can be represented in this fact by using epsilon I can consider an approximation for this fact and using instead of using using this instead of the quality of double, you can get an approximate program can be done in this fashion and it can be shown this program is actually the objective is actually a difference of two convex functions subject to.",
            "Most constraints, so this is a classical DC program, so these type of problems as I said, appear whenever you have sparsity constraints in your program.",
            "Now to solve this program to solve this problem, Ulan Rangarajan, they proposed a procedure."
        ],
        [
            "Called the concave convex procedure, which basically you start with.",
            "You start with some some X not in your constraint set and.",
            "Use all the sequence of this kind of programs.",
            "Suppose if you are, if you is convex, use all the context that we assume, and since this is linear, xur objective is convex in X and if your constraints it is convex.",
            "What you're solving is a sequence of convex programs.",
            "So you do this procedure until convergence.",
            "So now the goal of this work is to study the convergence of this procedure.",
            "So you would ask what does this procedure actually converse true?",
            "Does it converge to some stationary point or local minimum or first of all, does this converge if it converges?",
            "Under what conditions does it converge?",
            "So before we get to this?",
            "Oh, let me introduce the majorization minimization algorithm, which is a very general scheme.",
            "An SCCP can be seen as a special case of this scheme.",
            "So the idea is this, suppose you want to minimize."
        ],
        [
            "Is a function F if obviously if it is convex, it's all cool, but if it's not convex, let's say, then the idea is to construct a majorization function G which satisfies these constraints in the sense G as a function of F is an upper bound on F as a function of X is an upper bound on F, and it coincides with F at X is equal to Y.",
            "So for people in machine learning.",
            "Such a kind of thing has been introduced as auxiliary function method when dealing with the non active metrics aggregation, but this kind of method had pleaded to.",
            "Like around 1960s by work done by numerous analysts.",
            "So the algorithm is you start with some initial start with Max, not constraint, and then you minimize this function G. You minimize an upper bound on F. And then you do this until you get some convergence and it can be shown that.",
            "This kind of decent property holds, so this simply follows from the definition and this follows from this minimization step, and this follows again from the definition.",
            "So at each iterate the function object value decreases, so that is the.",
            "That is the crux of this algorithm, and if you notice, the EM algorithm can be seen as a special case of this algorithm, because EM algorithm actually satisfies.",
            "Basically, it follows a similar procedure."
        ],
        [
            "So now we we do something called as a linear majorization, where we construct the majorization function G in this fashion.",
            "Since we is a convex function, we basically linearize the quality context function and therefore you get an upper bound on this function F in this fashion.",
            "So you choose your G in this way.",
            "And if you use it in.",
            "And we use it here.",
            "What you get is exactly the CCP, right?",
            "So what have you done so far?",
            "We basically linearizer the minus V, which is basically we linearize the concave part of this function, and we obtained a convex objective.",
            "And if your concerns at this convex, what you're doing doing is solving the sequence of convex programs.",
            "Now the idea of this work is actually to study the convergence analysis."
        ],
        [
            "This procedure.",
            "So first thing to note is joelinton collagen.",
            "Based on this kind of a decent property, they claim that the sequence the sequence of iterates that's generated by this algorithm.",
            "They said that this converges to a local minimum or a saddle point of the original DC program.",
            "Right?",
            "Oh, The thing is, as I mentioned, EM algorithm can be seen as a generalization of the EM algorithm and DM algorithm satisfies a similar kind of decent property.",
            "And it has been shown by Olsson and others that EM algorithm actually my converse your local minimum.",
            "So in this case you need to know that in the case of the EM algorithm you are doing a maximization step, which means instead of it converging to a local numerous appointed the local minimum.",
            "Exhibit cycling behavior in the sense suppose if you have a set of stationary points which can have the same likelihood value, then.",
            "Each time when you trade, the algorithm can give you one of the stationary points.",
            "Actually, it can cycle around the stationary points rather than give you giving rather than converging to a single point.",
            "So just based on this decent property, it's not simple to claim that the sequence of iterates generated by this CCP algorithm will converge to local minima.",
            "Marcel point.",
            "So now, as I mentioned, the goal is to analyze the convergence of CCP, and these are the questions we ask.",
            "So before we get to the."
        ],
        [
            "The convergence and also CCP.",
            "We need this notion of global convergence of iterative algorithms.",
            "I'll in a minute I'll I'll explain what the global convergence means, So what we have seen so far is CCP is actually neutral to algorithm, so it's an algorithm of this form where a is defined as a point to set map in the sense.",
            "Yeah, it takes a point in your input, SpaceX and it basically returns your set.",
            "And that set belongs to the power set of input space, or it can be or the power set of, why?",
            "Alright, so.",
            "The CCP that we've seen previously.",
            "It's actually a pointer set map which which starts at X not, and then gives you X one, and then just keeps on going.",
            "Now you would say the algorithm, yeah, is globally convergent in the sense you choose any initial point X, not the sequence of iterates generated by this algorithm.",
            "It converges to a .4 which is necessary.",
            "Optimality conditions hold, so this does not mean that the algorithm actually converts to some global optimum, it actually it basically means.",
            "Wherever I start my algorithm, I'm going to hit some point which satisfies the necessary optimality conditions.",
            "That's what that's what it means."
        ],
        [
            "Global conference OK so we need to basically state the results.",
            "We need certain properties on the pointer set Maps so the important property is the point to set map C. It has to be closed, so you'll see in like the next slide that the closure property of C is pretty important and this can be interpreted as suppose if C is a point to point map, then the closure property of C is equal to saying the point to point map is continuous.",
            "And so this is the definition of the fixed point of the pointer set map, where the output of the algorithm is essentially a Singleton set.",
            "The generalized fixer point means whatever input you give, it's contained in the set that is returned that's returned by your by your algorithm or the points map.",
            "OK, so you need this uniformly so uniformly compared with the point set to map is different to uniformly compact in this way, and you need these conditions in the result that's introduced this angle so."
        ],
        [
            "Of Zangl proposed this global convergence theorem, so again, global convergence is in the sense that I mentioned before that wherever whatever initial value start with, you always converge to some stationary point.",
            "Some point that satisfies the necessary optimality conditions.",
            "So Zangl presented a very general theorem for this kind of iterative algorithms now.",
            "And the point is set map.",
            "Yeah, it should satisfy these three conditions.",
            "The main thing being at this point is that map has to be closed.",
            "And here there is this notion of solution set and we'll see how we invoke this theorem to get convergence results for CCP.",
            "Oh OK, so this so under these conditions the result claims that the limit point of any convergence of sequence of of the traits that is generated by by this algorithm.",
            "Yay, it's actually within the solution set.",
            "And Furthermore the objective values converge to the objective value defendant the limit point.",
            "OK, so now we can give simply based on the angles global convergence theorem, we can give the global."
        ],
        [
            "Stadium for SCCP, so here this is our CCP algorithms is our points at map and here under these conditions that you and we are differentiable functions.",
            "Oh, then.",
            "We can, we can essentially state the result simply following angles theorem.",
            "Here it says the limit points of the sequence that generated by CP.",
            "Basically, the stationary points of the DC program.",
            "That I mentioned in the first light.",
            "So the idea of the proof is this way that we first show that the generalized fixed point of your of your pointer set map ACP.",
            "Any Jenny generalized fixed point is basically stationary point of your DC program.",
            "Now once you show that, now the idea is to analyze the behavior of the generalized fixed points of this algorithm.",
            "So the way we do is in those angles theorem.",
            "We choose the solution set gamma."
        ],
        [
            "To be a set of all generalized fixed points of this algorithm, and let us choose the function fee to be your object.",
            "If you minus V an.",
            "And by choosing these things and you can invoke wrangells global convergence theorem and it gives you the result that was shown in the previous slide.",
            "Now this result has some issues.",
            "The first thing is.",
            "The sequence might converge, or you can have a subsequence convergence.",
            "The next one is.",
            "You can have an oscillatory behavior which I mentioned in the case of EM.",
            "So suppose let's say.",
            "Sigma not Omeganaut is basically just set and.",
            "So the X1 and X2 are basically the generalized fixed points of this algorithm, and you can see that this algorithm can generate a sequence like this, so it does not converge to any of these stationary points, but then it keeps oscillating between these points.",
            "So how do we eliminate this kind of behavior?"
        ],
        [
            "So the way to do is you need to.",
            "You need to make you need some more stronger conditions on your functions.",
            "You and we.",
            "Basically you need them to be strictly convex so that you don't anymore deal with the generalistic set points, but will deal with the fixed points.",
            "So your point is at my officially becomes like a point to point map.",
            "So under these conditions you can show that actually you can have much stronger form of convergence, and if the setup station points if it is finite, then the sequence that is generated by your SCCP indeed it converges to one of the stationary points.",
            "So.",
            "The convergence analysis that I presented so far this can be extended to general DC programs.",
            "So in the analysis that I've done so far have assumed the constraints of this convex."
        ],
        [
            "So that I basically linearized only the only object.",
            "So I have this object to your physical you minus three and I only linearized the minus V part so that I get a convex objective.",
            "I still assume that my convex with the constraints of this convex.",
            "So here is a general DC program where the constraint is also a dysfunction.",
            "And recently, such a kind of problem was encountered while dealing with missing data problems in kernel methods and smaller and others.",
            "They propose something called a constraint conquer context procedure where they apply the similar technique of linearizing the minus, linearizing the concave parts in these DC functions, and they propose an algorithm like this so.",
            "Again, you end up in the similar kind of an iterative algorithm, which can be analyzed using angles theorem.",
            "So this is a.",
            "Here again this here I don't make the functions to be strictly convex, so if you have to click restrict convexity, you essentially end up the kind of results that you had seen in the global convergence theorem."
        ],
        [
            "So so far we have seen the global convergence analysis.",
            "SCCP, no one can ask like what is the rate of convergence so I don't have any.",
            "I don't have an answer to that.",
            "The other question is the the local convergence behavior of CCP.",
            "Suppose I say I choose initial point X, not, which is within epsilon ball of some local minimum, right?",
            "Then will the CCP sequence?",
            "Will it converge to that?",
            "Local minima are what happens to it?",
            "Ideally you would want it to convert to that local minima.",
            "So and if it converges, what is the rate of convergence?",
            "So this problem is still not solved, but I approach the problem by invoking by trying to invoke the proposition due to ostroski so.",
            "Pretty much all the conditions in the propagation are satisfied.",
            "To prove this result, except that you need the point to set map to be be fresher, differentiable."
        ],
        [
            "And it's not.",
            "It's not clear how to define the differentiability of such Maps and under what conditions on you and we actually you can define it first of all, whether whether you can weather the differential of such Maps exists.",
            "It's not clear, so it's still an open problem, so I'll be.",
            "I'll be happy to know if anyone has any ideas on how to do this.",
            "So to summarize.",
            "So in this talk I have.",
            "I mean, we have presented the work."
        ],
        [
            "About the global convergence analysis of CCP using the language theory of global convergence of iterative algorithms.",
            "And as you can see the the nice thing with angles theory is that it's applicable to any class of iterative algorithms.",
            "If you want to at least analyze their convergence behavior and doesn't Arctic sense, so some of the algorithms in machine learning or basically alternating musician algorithms or the non negative matrix factorization, which is also an alternating minimization algorithm.",
            "So the convergence proofs of all these algorithms can be obtained by making some conditions on on your on your.",
            "Program such that you can invoke the angles theorem to give some convergence guarantees.",
            "And as I mentioned, the local content analysis is still an open problem and I'll be happy to have any citations on that, thank you.",
            "Addington und.",
            "I think that by adding some little quadratic.",
            "That's good.",
            "Yeah, that seems to be.",
            "Yeah, so this is convex.",
            "T is actually not a tight restriction then.",
            "But will you be able to show that?",
            "Add this perturbation.",
            "You still reach the same.",
            "Solution.",
            "Because you had you had the same thing to work?",
            "That makes sense.",
            "What do you think the rate of local convergence?",
            "I mean, if that result holds, then maybe it will be linear.",
            "I believe at best.",
            "There are some results where they try to analyze the local convergence rate by.",
            "Right, but most of them are like unconstrained problems, right?",
            "I mean there is this work by I mean I forgot his name.",
            "So there is this work on convergence and also bound optimization algorithms.",
            "I mean, Umm will be is a bound optimization algorithm and but the kind of analysis that's being done is mainly unconstrained optimization, so you can deal with all the history and then yeah.",
            "So it's exactly they get like probably super super linear convergence, something like that.",
            "Do I don't know how that would compare to."
        ],
        [
            "I don't know, I'm not.",
            "Any help?"
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Is done jointly with my advisor language at UC San Diego.",
                    "label": 1
                },
                {
                    "sent": "So here is outline on the top.",
                    "label": 0
                },
                {
                    "sent": "So the idea of this work is to analyze the convergence of concave convex procedure.",
                    "label": 0
                },
                {
                    "sent": "So we first start with using the connection program and then being a non convex program.",
                    "label": 0
                },
                {
                    "sent": "I'll motivate like order applications of these in machine learning and then there's a procedure called the concave convex procedure which has been introduced to solve these kind of problems and I'll show how.",
                    "label": 0
                },
                {
                    "sent": "This procedure is a special case.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Cough medicine.",
                    "label": 0
                },
                {
                    "sent": "Because being introduced, the artistic literature around like 1960s.",
                    "label": 0
                },
                {
                    "sent": "Next I get to the main part of the talk, which is the convergence analysis of CCP, which requires some notions of point to set Maps, and then using the global convergence theory of iterative algorithms.",
                    "label": 1
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I provide the convergence analysis of TCP and then end the talk with an open question regarding the local content analysis.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "What is the DC program?",
                    "label": 0
                },
                {
                    "sent": "So first of all, what is the DC function?",
                    "label": 0
                },
                {
                    "sent": "Any real valued function F is called EC function if there exists like 2 can function.",
                    "label": 1
                },
                {
                    "sent": "We can be expressed as the difference of convex lens.",
                    "label": 0
                },
                {
                    "sent": "Nowadays the program is minimization of an objective, which is a DC function subject to the constraints.",
                    "label": 1
                },
                {
                    "sent": "It has been shown that such programs are computationally hard to solve, and this being a non convex program so would wonder.",
                    "label": 0
                },
                {
                    "sent": "I mean why do we need to care about such programs?",
                    "label": 1
                },
                {
                    "sent": "Given that in machining optimization seems to be the popular approach, why do you need to care about this?",
                    "label": 0
                },
                {
                    "sent": "They are important locations in learning.",
                    "label": 0
                },
                {
                    "sent": "We, especially when you deal with problems, sparse PCA or do feature selection.",
                    "label": 0
                },
                {
                    "sent": "SVM even translate to experience this kind of problem here showing that consider the problem of teams.",
                    "label": 0
                },
                {
                    "sent": "So instead of using the usual L2 regularizer on W is a multi consumed.",
                    "label": 0
                },
                {
                    "sent": "Is your brother an?",
                    "label": 0
                },
                {
                    "sent": "So this program can be solved either as a.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Discrete optimization problem or I can use an approximation Becauses account can be represented in this fact by using epsilon I can consider an approximation for this fact and using instead of using using this instead of the quality of double, you can get an approximate program can be done in this fashion and it can be shown this program is actually the objective is actually a difference of two convex functions subject to.",
                    "label": 0
                },
                {
                    "sent": "Most constraints, so this is a classical DC program, so these type of problems as I said, appear whenever you have sparsity constraints in your program.",
                    "label": 0
                },
                {
                    "sent": "Now to solve this program to solve this problem, Ulan Rangarajan, they proposed a procedure.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Called the concave convex procedure, which basically you start with.",
                    "label": 0
                },
                {
                    "sent": "You start with some some X not in your constraint set and.",
                    "label": 0
                },
                {
                    "sent": "Use all the sequence of this kind of programs.",
                    "label": 0
                },
                {
                    "sent": "Suppose if you are, if you is convex, use all the context that we assume, and since this is linear, xur objective is convex in X and if your constraints it is convex.",
                    "label": 0
                },
                {
                    "sent": "What you're solving is a sequence of convex programs.",
                    "label": 0
                },
                {
                    "sent": "So you do this procedure until convergence.",
                    "label": 1
                },
                {
                    "sent": "So now the goal of this work is to study the convergence of this procedure.",
                    "label": 1
                },
                {
                    "sent": "So you would ask what does this procedure actually converse true?",
                    "label": 0
                },
                {
                    "sent": "Does it converge to some stationary point or local minimum or first of all, does this converge if it converges?",
                    "label": 1
                },
                {
                    "sent": "Under what conditions does it converge?",
                    "label": 0
                },
                {
                    "sent": "So before we get to this?",
                    "label": 0
                },
                {
                    "sent": "Oh, let me introduce the majorization minimization algorithm, which is a very general scheme.",
                    "label": 0
                },
                {
                    "sent": "An SCCP can be seen as a special case of this scheme.",
                    "label": 0
                },
                {
                    "sent": "So the idea is this, suppose you want to minimize.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Is a function F if obviously if it is convex, it's all cool, but if it's not convex, let's say, then the idea is to construct a majorization function G which satisfies these constraints in the sense G as a function of F is an upper bound on F as a function of X is an upper bound on F, and it coincides with F at X is equal to Y.",
                    "label": 1
                },
                {
                    "sent": "So for people in machine learning.",
                    "label": 0
                },
                {
                    "sent": "Such a kind of thing has been introduced as auxiliary function method when dealing with the non active metrics aggregation, but this kind of method had pleaded to.",
                    "label": 0
                },
                {
                    "sent": "Like around 1960s by work done by numerous analysts.",
                    "label": 0
                },
                {
                    "sent": "So the algorithm is you start with some initial start with Max, not constraint, and then you minimize this function G. You minimize an upper bound on F. And then you do this until you get some convergence and it can be shown that.",
                    "label": 0
                },
                {
                    "sent": "This kind of decent property holds, so this simply follows from the definition and this follows from this minimization step, and this follows again from the definition.",
                    "label": 0
                },
                {
                    "sent": "So at each iterate the function object value decreases, so that is the.",
                    "label": 0
                },
                {
                    "sent": "That is the crux of this algorithm, and if you notice, the EM algorithm can be seen as a special case of this algorithm, because EM algorithm actually satisfies.",
                    "label": 0
                },
                {
                    "sent": "Basically, it follows a similar procedure.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So now we we do something called as a linear majorization, where we construct the majorization function G in this fashion.",
                    "label": 1
                },
                {
                    "sent": "Since we is a convex function, we basically linearize the quality context function and therefore you get an upper bound on this function F in this fashion.",
                    "label": 0
                },
                {
                    "sent": "So you choose your G in this way.",
                    "label": 0
                },
                {
                    "sent": "And if you use it in.",
                    "label": 0
                },
                {
                    "sent": "And we use it here.",
                    "label": 0
                },
                {
                    "sent": "What you get is exactly the CCP, right?",
                    "label": 1
                },
                {
                    "sent": "So what have you done so far?",
                    "label": 0
                },
                {
                    "sent": "We basically linearizer the minus V, which is basically we linearize the concave part of this function, and we obtained a convex objective.",
                    "label": 0
                },
                {
                    "sent": "And if your concerns at this convex, what you're doing doing is solving the sequence of convex programs.",
                    "label": 0
                },
                {
                    "sent": "Now the idea of this work is actually to study the convergence analysis.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This procedure.",
                    "label": 0
                },
                {
                    "sent": "So first thing to note is joelinton collagen.",
                    "label": 0
                },
                {
                    "sent": "Based on this kind of a decent property, they claim that the sequence the sequence of iterates that's generated by this algorithm.",
                    "label": 0
                },
                {
                    "sent": "They said that this converges to a local minimum or a saddle point of the original DC program.",
                    "label": 1
                },
                {
                    "sent": "Right?",
                    "label": 0
                },
                {
                    "sent": "Oh, The thing is, as I mentioned, EM algorithm can be seen as a generalization of the EM algorithm and DM algorithm satisfies a similar kind of decent property.",
                    "label": 1
                },
                {
                    "sent": "And it has been shown by Olsson and others that EM algorithm actually my converse your local minimum.",
                    "label": 1
                },
                {
                    "sent": "So in this case you need to know that in the case of the EM algorithm you are doing a maximization step, which means instead of it converging to a local numerous appointed the local minimum.",
                    "label": 0
                },
                {
                    "sent": "Exhibit cycling behavior in the sense suppose if you have a set of stationary points which can have the same likelihood value, then.",
                    "label": 0
                },
                {
                    "sent": "Each time when you trade, the algorithm can give you one of the stationary points.",
                    "label": 0
                },
                {
                    "sent": "Actually, it can cycle around the stationary points rather than give you giving rather than converging to a single point.",
                    "label": 0
                },
                {
                    "sent": "So just based on this decent property, it's not simple to claim that the sequence of iterates generated by this CCP algorithm will converge to local minima.",
                    "label": 0
                },
                {
                    "sent": "Marcel point.",
                    "label": 0
                },
                {
                    "sent": "So now, as I mentioned, the goal is to analyze the convergence of CCP, and these are the questions we ask.",
                    "label": 0
                },
                {
                    "sent": "So before we get to the.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The convergence and also CCP.",
                    "label": 0
                },
                {
                    "sent": "We need this notion of global convergence of iterative algorithms.",
                    "label": 1
                },
                {
                    "sent": "I'll in a minute I'll I'll explain what the global convergence means, So what we have seen so far is CCP is actually neutral to algorithm, so it's an algorithm of this form where a is defined as a point to set map in the sense.",
                    "label": 1
                },
                {
                    "sent": "Yeah, it takes a point in your input, SpaceX and it basically returns your set.",
                    "label": 0
                },
                {
                    "sent": "And that set belongs to the power set of input space, or it can be or the power set of, why?",
                    "label": 0
                },
                {
                    "sent": "Alright, so.",
                    "label": 1
                },
                {
                    "sent": "The CCP that we've seen previously.",
                    "label": 1
                },
                {
                    "sent": "It's actually a pointer set map which which starts at X not, and then gives you X one, and then just keeps on going.",
                    "label": 1
                },
                {
                    "sent": "Now you would say the algorithm, yeah, is globally convergent in the sense you choose any initial point X, not the sequence of iterates generated by this algorithm.",
                    "label": 0
                },
                {
                    "sent": "It converges to a .4 which is necessary.",
                    "label": 0
                },
                {
                    "sent": "Optimality conditions hold, so this does not mean that the algorithm actually converts to some global optimum, it actually it basically means.",
                    "label": 0
                },
                {
                    "sent": "Wherever I start my algorithm, I'm going to hit some point which satisfies the necessary optimality conditions.",
                    "label": 0
                },
                {
                    "sent": "That's what that's what it means.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Global conference OK so we need to basically state the results.",
                    "label": 0
                },
                {
                    "sent": "We need certain properties on the pointer set Maps so the important property is the point to set map C. It has to be closed, so you'll see in like the next slide that the closure property of C is pretty important and this can be interpreted as suppose if C is a point to point map, then the closure property of C is equal to saying the point to point map is continuous.",
                    "label": 1
                },
                {
                    "sent": "And so this is the definition of the fixed point of the pointer set map, where the output of the algorithm is essentially a Singleton set.",
                    "label": 0
                },
                {
                    "sent": "The generalized fixer point means whatever input you give, it's contained in the set that is returned that's returned by your by your algorithm or the points map.",
                    "label": 0
                },
                {
                    "sent": "OK, so you need this uniformly so uniformly compared with the point set to map is different to uniformly compact in this way, and you need these conditions in the result that's introduced this angle so.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Of Zangl proposed this global convergence theorem, so again, global convergence is in the sense that I mentioned before that wherever whatever initial value start with, you always converge to some stationary point.",
                    "label": 1
                },
                {
                    "sent": "Some point that satisfies the necessary optimality conditions.",
                    "label": 0
                },
                {
                    "sent": "So Zangl presented a very general theorem for this kind of iterative algorithms now.",
                    "label": 0
                },
                {
                    "sent": "And the point is set map.",
                    "label": 0
                },
                {
                    "sent": "Yeah, it should satisfy these three conditions.",
                    "label": 0
                },
                {
                    "sent": "The main thing being at this point is that map has to be closed.",
                    "label": 1
                },
                {
                    "sent": "And here there is this notion of solution set and we'll see how we invoke this theorem to get convergence results for CCP.",
                    "label": 0
                },
                {
                    "sent": "Oh OK, so this so under these conditions the result claims that the limit point of any convergence of sequence of of the traits that is generated by by this algorithm.",
                    "label": 0
                },
                {
                    "sent": "Yay, it's actually within the solution set.",
                    "label": 0
                },
                {
                    "sent": "And Furthermore the objective values converge to the objective value defendant the limit point.",
                    "label": 0
                },
                {
                    "sent": "OK, so now we can give simply based on the angles global convergence theorem, we can give the global.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Stadium for SCCP, so here this is our CCP algorithms is our points at map and here under these conditions that you and we are differentiable functions.",
                    "label": 0
                },
                {
                    "sent": "Oh, then.",
                    "label": 0
                },
                {
                    "sent": "We can, we can essentially state the result simply following angles theorem.",
                    "label": 0
                },
                {
                    "sent": "Here it says the limit points of the sequence that generated by CP.",
                    "label": 1
                },
                {
                    "sent": "Basically, the stationary points of the DC program.",
                    "label": 1
                },
                {
                    "sent": "That I mentioned in the first light.",
                    "label": 1
                },
                {
                    "sent": "So the idea of the proof is this way that we first show that the generalized fixed point of your of your pointer set map ACP.",
                    "label": 0
                },
                {
                    "sent": "Any Jenny generalized fixed point is basically stationary point of your DC program.",
                    "label": 0
                },
                {
                    "sent": "Now once you show that, now the idea is to analyze the behavior of the generalized fixed points of this algorithm.",
                    "label": 0
                },
                {
                    "sent": "So the way we do is in those angles theorem.",
                    "label": 0
                },
                {
                    "sent": "We choose the solution set gamma.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "To be a set of all generalized fixed points of this algorithm, and let us choose the function fee to be your object.",
                    "label": 1
                },
                {
                    "sent": "If you minus V an.",
                    "label": 0
                },
                {
                    "sent": "And by choosing these things and you can invoke wrangells global convergence theorem and it gives you the result that was shown in the previous slide.",
                    "label": 0
                },
                {
                    "sent": "Now this result has some issues.",
                    "label": 0
                },
                {
                    "sent": "The first thing is.",
                    "label": 0
                },
                {
                    "sent": "The sequence might converge, or you can have a subsequence convergence.",
                    "label": 0
                },
                {
                    "sent": "The next one is.",
                    "label": 0
                },
                {
                    "sent": "You can have an oscillatory behavior which I mentioned in the case of EM.",
                    "label": 0
                },
                {
                    "sent": "So suppose let's say.",
                    "label": 0
                },
                {
                    "sent": "Sigma not Omeganaut is basically just set and.",
                    "label": 1
                },
                {
                    "sent": "So the X1 and X2 are basically the generalized fixed points of this algorithm, and you can see that this algorithm can generate a sequence like this, so it does not converge to any of these stationary points, but then it keeps oscillating between these points.",
                    "label": 0
                },
                {
                    "sent": "So how do we eliminate this kind of behavior?",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the way to do is you need to.",
                    "label": 0
                },
                {
                    "sent": "You need to make you need some more stronger conditions on your functions.",
                    "label": 0
                },
                {
                    "sent": "You and we.",
                    "label": 0
                },
                {
                    "sent": "Basically you need them to be strictly convex so that you don't anymore deal with the generalistic set points, but will deal with the fixed points.",
                    "label": 1
                },
                {
                    "sent": "So your point is at my officially becomes like a point to point map.",
                    "label": 0
                },
                {
                    "sent": "So under these conditions you can show that actually you can have much stronger form of convergence, and if the setup station points if it is finite, then the sequence that is generated by your SCCP indeed it converges to one of the stationary points.",
                    "label": 1
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "The convergence analysis that I presented so far this can be extended to general DC programs.",
                    "label": 0
                },
                {
                    "sent": "So in the analysis that I've done so far have assumed the constraints of this convex.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So that I basically linearized only the only object.",
                    "label": 0
                },
                {
                    "sent": "So I have this object to your physical you minus three and I only linearized the minus V part so that I get a convex objective.",
                    "label": 0
                },
                {
                    "sent": "I still assume that my convex with the constraints of this convex.",
                    "label": 0
                },
                {
                    "sent": "So here is a general DC program where the constraint is also a dysfunction.",
                    "label": 0
                },
                {
                    "sent": "And recently, such a kind of problem was encountered while dealing with missing data problems in kernel methods and smaller and others.",
                    "label": 0
                },
                {
                    "sent": "They propose something called a constraint conquer context procedure where they apply the similar technique of linearizing the minus, linearizing the concave parts in these DC functions, and they propose an algorithm like this so.",
                    "label": 0
                },
                {
                    "sent": "Again, you end up in the similar kind of an iterative algorithm, which can be analyzed using angles theorem.",
                    "label": 0
                },
                {
                    "sent": "So this is a.",
                    "label": 0
                },
                {
                    "sent": "Here again this here I don't make the functions to be strictly convex, so if you have to click restrict convexity, you essentially end up the kind of results that you had seen in the global convergence theorem.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So so far we have seen the global convergence analysis.",
                    "label": 0
                },
                {
                    "sent": "SCCP, no one can ask like what is the rate of convergence so I don't have any.",
                    "label": 0
                },
                {
                    "sent": "I don't have an answer to that.",
                    "label": 0
                },
                {
                    "sent": "The other question is the the local convergence behavior of CCP.",
                    "label": 0
                },
                {
                    "sent": "Suppose I say I choose initial point X, not, which is within epsilon ball of some local minimum, right?",
                    "label": 0
                },
                {
                    "sent": "Then will the CCP sequence?",
                    "label": 0
                },
                {
                    "sent": "Will it converge to that?",
                    "label": 0
                },
                {
                    "sent": "Local minima are what happens to it?",
                    "label": 0
                },
                {
                    "sent": "Ideally you would want it to convert to that local minima.",
                    "label": 0
                },
                {
                    "sent": "So and if it converges, what is the rate of convergence?",
                    "label": 0
                },
                {
                    "sent": "So this problem is still not solved, but I approach the problem by invoking by trying to invoke the proposition due to ostroski so.",
                    "label": 0
                },
                {
                    "sent": "Pretty much all the conditions in the propagation are satisfied.",
                    "label": 0
                },
                {
                    "sent": "To prove this result, except that you need the point to set map to be be fresher, differentiable.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And it's not.",
                    "label": 0
                },
                {
                    "sent": "It's not clear how to define the differentiability of such Maps and under what conditions on you and we actually you can define it first of all, whether whether you can weather the differential of such Maps exists.",
                    "label": 0
                },
                {
                    "sent": "It's not clear, so it's still an open problem, so I'll be.",
                    "label": 0
                },
                {
                    "sent": "I'll be happy to know if anyone has any ideas on how to do this.",
                    "label": 0
                },
                {
                    "sent": "So to summarize.",
                    "label": 0
                },
                {
                    "sent": "So in this talk I have.",
                    "label": 0
                },
                {
                    "sent": "I mean, we have presented the work.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "About the global convergence analysis of CCP using the language theory of global convergence of iterative algorithms.",
                    "label": 1
                },
                {
                    "sent": "And as you can see the the nice thing with angles theory is that it's applicable to any class of iterative algorithms.",
                    "label": 0
                },
                {
                    "sent": "If you want to at least analyze their convergence behavior and doesn't Arctic sense, so some of the algorithms in machine learning or basically alternating musician algorithms or the non negative matrix factorization, which is also an alternating minimization algorithm.",
                    "label": 0
                },
                {
                    "sent": "So the convergence proofs of all these algorithms can be obtained by making some conditions on on your on your.",
                    "label": 0
                },
                {
                    "sent": "Program such that you can invoke the angles theorem to give some convergence guarantees.",
                    "label": 0
                },
                {
                    "sent": "And as I mentioned, the local content analysis is still an open problem and I'll be happy to have any citations on that, thank you.",
                    "label": 0
                },
                {
                    "sent": "Addington und.",
                    "label": 0
                },
                {
                    "sent": "I think that by adding some little quadratic.",
                    "label": 0
                },
                {
                    "sent": "That's good.",
                    "label": 0
                },
                {
                    "sent": "Yeah, that seems to be.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so this is convex.",
                    "label": 0
                },
                {
                    "sent": "T is actually not a tight restriction then.",
                    "label": 0
                },
                {
                    "sent": "But will you be able to show that?",
                    "label": 0
                },
                {
                    "sent": "Add this perturbation.",
                    "label": 0
                },
                {
                    "sent": "You still reach the same.",
                    "label": 0
                },
                {
                    "sent": "Solution.",
                    "label": 0
                },
                {
                    "sent": "Because you had you had the same thing to work?",
                    "label": 0
                },
                {
                    "sent": "That makes sense.",
                    "label": 0
                },
                {
                    "sent": "What do you think the rate of local convergence?",
                    "label": 0
                },
                {
                    "sent": "I mean, if that result holds, then maybe it will be linear.",
                    "label": 0
                },
                {
                    "sent": "I believe at best.",
                    "label": 0
                },
                {
                    "sent": "There are some results where they try to analyze the local convergence rate by.",
                    "label": 0
                },
                {
                    "sent": "Right, but most of them are like unconstrained problems, right?",
                    "label": 0
                },
                {
                    "sent": "I mean there is this work by I mean I forgot his name.",
                    "label": 0
                },
                {
                    "sent": "So there is this work on convergence and also bound optimization algorithms.",
                    "label": 0
                },
                {
                    "sent": "I mean, Umm will be is a bound optimization algorithm and but the kind of analysis that's being done is mainly unconstrained optimization, so you can deal with all the history and then yeah.",
                    "label": 0
                },
                {
                    "sent": "So it's exactly they get like probably super super linear convergence, something like that.",
                    "label": 0
                },
                {
                    "sent": "Do I don't know how that would compare to.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I don't know, I'm not.",
                    "label": 0
                },
                {
                    "sent": "Any help?",
                    "label": 0
                }
            ]
        }
    }
}