{
    "id": "36wk7wiodvtjkbay4ikezsf2lykxoyuf",
    "title": "Discovering Frequent Subgraphs over Uncertain Graph Databases under Probabilistic Semantics",
    "info": {
        "author": [
            "Zhaonian Zou, Harbin Institute of Technology"
        ],
        "published": "Oct. 1, 2010",
        "recorded": "July 2010",
        "category": [
            "Top->Computer Science->Data Mining",
            "Top->Computer Science->Databases"
        ]
    },
    "url": "http://videolectures.net/kdd2010_zou_dfs/",
    "segmentation": [
        [
            "Good afternoon, I want I'm joining though from Harbin Institute of Technology, China and in this 10 minutes I will show you my recent work done jointly with Professor Hong Kong and Professor Change only also from a Chai tea and this work is on mining.",
            "Frequent stop or patterns from uncertain graph data and and you under new semantics called probabilistic semantics."
        ],
        [
            "I will first overview the background and give the model of a certain graph data followed by the problem statement.",
            "Next I will give the algorithm its theoretical analysis and the experimental results.",
            "Finally, I will summarize this work and show the future."
        ],
        [
            "And your recent years of mining has played an important role in large number of applications such as valve mattix, social networks and the Internet and so on."
        ],
        [
            "Recent research have found that uncertainties inherent in graph data.",
            "Due to the data errors in completely incompleteness, impressive imprecision and so on an for example.",
            "Protein, protein interaction network or PPI network for shots is uncertain.",
            "Graph where nodes reprezent proteins and edges represent PPI's, due to the limitation of PPI detection techniques, hppy is associated is often associated with the number.",
            "Indicating the probability of this PPI existing in practice.",
            "Another example is where this is the topologies of wireless sensor networks, where the number on each edge represents the probability of the wireless link working normally.",
            "So this I certain graph data rates many new challenges for graph mining."
        ],
        [
            "The first challenge is in data model.",
            "It requires the data model to represent graphs and uncertainties and more sophisticated semantics at the second challenge is in the semantics.",
            "It means existing graph.",
            "Many problems that were defined on certain graph data don't make sense on certain graph data.",
            "And the last challenge is in the computing computing the computational complexity of uncertain graph mining.",
            "It's usually much higher.",
            "Anna."
        ],
        [
            "As far as we know, the recent work on I sent about mining include frequent stopper pattern mining and top K maximal cliques mining.",
            "In this paper and who we study at frequents type of pattern mining at the new semantic called probabilistic semantics.",
            "Outlet, let's look at the model."
        ],
        [
            "Cinegraph date.",
            "As an instant tax, a certain graph is just a weighted graph.",
            "The number on each vertex is the probability of the vertex existing in practice, and the number on each edge is the conditional probability of the edge existing.",
            "In practice, given its endpoints.",
            "In semantics, it means we can toss a biased coin for each vertex.",
            "Then we get a subset of vertices, and then we toss a coin for each of the edge between the vertices we just select it and then we get a subset of edges and so we get a certain graph."
        ],
        [
            "For example, this is a certain graph that we can obtain from the the uncertain graph.",
            "And the probability that this implicated graph is obtained can be computed by this equation, which is very easy to explain."
        ],
        [
            "And by enumerating all the cases, we can get all implicated graphs and their probabilities.",
            "It's easy to prove that a certain graph represents an probability distribution.",
            "Overall, it's implicated graphs."
        ],
        [
            "Another concept in this model is uncertain graph database.",
            "It is simply a set of uncertain graphs and by selecting one implicated graph for each uncertain graph, we get a set of certain graph.",
            "Which is formally called implicated graph database, and more formally, it is defined in this way, and the probability that these implicated graph databases obtained can be computed by this equation.",
            "So by enumerating all the combinations, we actually can get all the implicated graph databases and their probabilities, so it's easy to prove a certain graph database represents a probability distribution.",
            "Overall, it's implicated graph databases, so this is model based on this model we define the problem."
        ],
        [
            "So before that, let's recap.",
            "What is the frequent stuff about Peyton Manning?",
            "And in traditional definition, to support a subpattern, the importance of a subpattern.",
            "It is measured by the support that is the proportion of graphs that contain this sub graph and the problem is, given a certain grafted, given a graph database and threshhold output of subgraphs with support no less than this right hold.",
            "But this definition doesn't work on ice and graph data cause a sub graph is not certainly content in any uncertain graph."
        ],
        [
            "So we've given you definition where a subgraph is measured by its five frequent probability.",
            "That is, the probability of this subgroup having support no less than five across all implicated graph databases.",
            "So the problem is like this, given a certain graph database, two thresholds.",
            "Suppose Reinhold file and confidence threshold Tau.",
            "We output all subgraphs with five frequent probability at least."
        ],
        [
            "Stop so we have two hardness results about this problem.",
            "The first one is it is sharp, P hard to count, all to count the number of frequent subgraph patterns.",
            "Second one is it is sharp P hard to compute 5 frequent probability of any subgraph pattern.",
            "So due to this hardness results all the existing algorithm cannot work for this problem and we use a proxy mining too so."
        ],
        [
            "This problem, so the goal of the mining is.",
            "Here it is.",
            "All the subpatterns.",
            "It's intractable to exactly compute all of them, so we compute a larger set, including all the frequent ones and a fraction of infrequent ones, but each infrequent one must have five frequent probability no less than two minus epsilon.",
            "Epsilon is the error bar is the error tolerance.",
            "So the overall price."
        ],
        [
            "Leader of the algorithm is like this given on graft graph database, we organize all subgraphs into a search tree and then do depth first search on this surgery.",
            "For each sub graph, we test whether it's five.",
            "Frequent probability is not outside the outer boundary and it's probably and it's probable to be in within the inner boundary.",
            "If the answer is yes, then we.",
            "Outputs if dami depth versus is descendants.",
            "If it it also yes, then we output it.",
            "So for some cases the five frequent of this sub graph is outside the inner boundary outside the right boundary, then it is discarded.",
            "Also, all its descendants can be discarded due to the property of frequent probability that we continue to do depth first search like this until all until no subgraphs need to be examined.",
            "So the key.",
            "So the key of the this algorithm is too fast determine whether the 5% probability of sub graph must be no less than this value and probability, and probably no less than Tau.",
            "The."
        ],
        [
            "Other to do this checking is very simple.",
            "The first step we approximate the five frequent probability using an interval and then check the following conditions.",
            "If the interval is in one of these positions that we output it.",
            "Otherwise if it is in one of dispositions, then we discard it.",
            "So the key steps is the step one to do this.",
            "To do this step one we we propose."
        ],
        [
            "And then they make a programming based method.",
            "It's recursive equation is like this due to the time limit.",
            "I don't exploit and when all the elements of this table have been computed, we can get final result by summing up all the element TIGN such that that inequality is satisfied and this is."
        ],
        [
            "Illustration of the procedure we feel.",
            "The tables are in this order and finally we sum up all the elements in the in the Dark Room.",
            "Been apart of we notice that some input of this over the dynamic programming is sharp P hard to compute, so our intuitive idea to make this dynamic programming practical is too.",
            "Computer to use some estimated value instead of the exact values.",
            "So to get this estimate values.",
            "At.",
            "OK, let's finish this site and we propose an randomized algorithm.",
            "In our previous work and."
        ],
        [
            "It is a randomized algorithm, so to guarantee the output of dynamic programming is within error epsilon and with probability at least one might start.",
            "We just need to require the randomized algorithm to guarantee each estimated value is within error like this and succeed with probability like this.",
            "So this is the main idea of the our approach.",
            "The the theoretical."
        ],
        [
            "A bond of this algorithm is that any frequent stop graph is up to output as a result with at least lower bound.",
            "OK, OK then this is the theoretical result of our algorithm.",
            "OK, thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Good afternoon, I want I'm joining though from Harbin Institute of Technology, China and in this 10 minutes I will show you my recent work done jointly with Professor Hong Kong and Professor Change only also from a Chai tea and this work is on mining.",
                    "label": 0
                },
                {
                    "sent": "Frequent stop or patterns from uncertain graph data and and you under new semantics called probabilistic semantics.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I will first overview the background and give the model of a certain graph data followed by the problem statement.",
                    "label": 1
                },
                {
                    "sent": "Next I will give the algorithm its theoretical analysis and the experimental results.",
                    "label": 0
                },
                {
                    "sent": "Finally, I will summarize this work and show the future.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And your recent years of mining has played an important role in large number of applications such as valve mattix, social networks and the Internet and so on.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Recent research have found that uncertainties inherent in graph data.",
                    "label": 1
                },
                {
                    "sent": "Due to the data errors in completely incompleteness, impressive imprecision and so on an for example.",
                    "label": 0
                },
                {
                    "sent": "Protein, protein interaction network or PPI network for shots is uncertain.",
                    "label": 0
                },
                {
                    "sent": "Graph where nodes reprezent proteins and edges represent PPI's, due to the limitation of PPI detection techniques, hppy is associated is often associated with the number.",
                    "label": 0
                },
                {
                    "sent": "Indicating the probability of this PPI existing in practice.",
                    "label": 1
                },
                {
                    "sent": "Another example is where this is the topologies of wireless sensor networks, where the number on each edge represents the probability of the wireless link working normally.",
                    "label": 1
                },
                {
                    "sent": "So this I certain graph data rates many new challenges for graph mining.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The first challenge is in data model.",
                    "label": 0
                },
                {
                    "sent": "It requires the data model to represent graphs and uncertainties and more sophisticated semantics at the second challenge is in the semantics.",
                    "label": 0
                },
                {
                    "sent": "It means existing graph.",
                    "label": 0
                },
                {
                    "sent": "Many problems that were defined on certain graph data don't make sense on certain graph data.",
                    "label": 1
                },
                {
                    "sent": "And the last challenge is in the computing computing the computational complexity of uncertain graph mining.",
                    "label": 0
                },
                {
                    "sent": "It's usually much higher.",
                    "label": 0
                },
                {
                    "sent": "Anna.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "As far as we know, the recent work on I sent about mining include frequent stopper pattern mining and top K maximal cliques mining.",
                    "label": 1
                },
                {
                    "sent": "In this paper and who we study at frequents type of pattern mining at the new semantic called probabilistic semantics.",
                    "label": 0
                },
                {
                    "sent": "Outlet, let's look at the model.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Cinegraph date.",
                    "label": 0
                },
                {
                    "sent": "As an instant tax, a certain graph is just a weighted graph.",
                    "label": 0
                },
                {
                    "sent": "The number on each vertex is the probability of the vertex existing in practice, and the number on each edge is the conditional probability of the edge existing.",
                    "label": 1
                },
                {
                    "sent": "In practice, given its endpoints.",
                    "label": 1
                },
                {
                    "sent": "In semantics, it means we can toss a biased coin for each vertex.",
                    "label": 0
                },
                {
                    "sent": "Then we get a subset of vertices, and then we toss a coin for each of the edge between the vertices we just select it and then we get a subset of edges and so we get a certain graph.",
                    "label": 1
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For example, this is a certain graph that we can obtain from the the uncertain graph.",
                    "label": 0
                },
                {
                    "sent": "And the probability that this implicated graph is obtained can be computed by this equation, which is very easy to explain.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And by enumerating all the cases, we can get all implicated graphs and their probabilities.",
                    "label": 1
                },
                {
                    "sent": "It's easy to prove that a certain graph represents an probability distribution.",
                    "label": 1
                },
                {
                    "sent": "Overall, it's implicated graphs.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Another concept in this model is uncertain graph database.",
                    "label": 1
                },
                {
                    "sent": "It is simply a set of uncertain graphs and by selecting one implicated graph for each uncertain graph, we get a set of certain graph.",
                    "label": 0
                },
                {
                    "sent": "Which is formally called implicated graph database, and more formally, it is defined in this way, and the probability that these implicated graph databases obtained can be computed by this equation.",
                    "label": 0
                },
                {
                    "sent": "So by enumerating all the combinations, we actually can get all the implicated graph databases and their probabilities, so it's easy to prove a certain graph database represents a probability distribution.",
                    "label": 1
                },
                {
                    "sent": "Overall, it's implicated graph databases, so this is model based on this model we define the problem.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So before that, let's recap.",
                    "label": 0
                },
                {
                    "sent": "What is the frequent stuff about Peyton Manning?",
                    "label": 0
                },
                {
                    "sent": "And in traditional definition, to support a subpattern, the importance of a subpattern.",
                    "label": 0
                },
                {
                    "sent": "It is measured by the support that is the proportion of graphs that contain this sub graph and the problem is, given a certain grafted, given a graph database and threshhold output of subgraphs with support no less than this right hold.",
                    "label": 1
                },
                {
                    "sent": "But this definition doesn't work on ice and graph data cause a sub graph is not certainly content in any uncertain graph.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we've given you definition where a subgraph is measured by its five frequent probability.",
                    "label": 0
                },
                {
                    "sent": "That is, the probability of this subgroup having support no less than five across all implicated graph databases.",
                    "label": 1
                },
                {
                    "sent": "So the problem is like this, given a certain graph database, two thresholds.",
                    "label": 1
                },
                {
                    "sent": "Suppose Reinhold file and confidence threshold Tau.",
                    "label": 0
                },
                {
                    "sent": "We output all subgraphs with five frequent probability at least.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Stop so we have two hardness results about this problem.",
                    "label": 1
                },
                {
                    "sent": "The first one is it is sharp, P hard to count, all to count the number of frequent subgraph patterns.",
                    "label": 1
                },
                {
                    "sent": "Second one is it is sharp P hard to compute 5 frequent probability of any subgraph pattern.",
                    "label": 0
                },
                {
                    "sent": "So due to this hardness results all the existing algorithm cannot work for this problem and we use a proxy mining too so.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This problem, so the goal of the mining is.",
                    "label": 0
                },
                {
                    "sent": "Here it is.",
                    "label": 0
                },
                {
                    "sent": "All the subpatterns.",
                    "label": 0
                },
                {
                    "sent": "It's intractable to exactly compute all of them, so we compute a larger set, including all the frequent ones and a fraction of infrequent ones, but each infrequent one must have five frequent probability no less than two minus epsilon.",
                    "label": 1
                },
                {
                    "sent": "Epsilon is the error bar is the error tolerance.",
                    "label": 0
                },
                {
                    "sent": "So the overall price.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Leader of the algorithm is like this given on graft graph database, we organize all subgraphs into a search tree and then do depth first search on this surgery.",
                    "label": 1
                },
                {
                    "sent": "For each sub graph, we test whether it's five.",
                    "label": 0
                },
                {
                    "sent": "Frequent probability is not outside the outer boundary and it's probably and it's probable to be in within the inner boundary.",
                    "label": 0
                },
                {
                    "sent": "If the answer is yes, then we.",
                    "label": 0
                },
                {
                    "sent": "Outputs if dami depth versus is descendants.",
                    "label": 0
                },
                {
                    "sent": "If it it also yes, then we output it.",
                    "label": 0
                },
                {
                    "sent": "So for some cases the five frequent of this sub graph is outside the inner boundary outside the right boundary, then it is discarded.",
                    "label": 0
                },
                {
                    "sent": "Also, all its descendants can be discarded due to the property of frequent probability that we continue to do depth first search like this until all until no subgraphs need to be examined.",
                    "label": 0
                },
                {
                    "sent": "So the key.",
                    "label": 0
                },
                {
                    "sent": "So the key of the this algorithm is too fast determine whether the 5% probability of sub graph must be no less than this value and probability, and probably no less than Tau.",
                    "label": 1
                },
                {
                    "sent": "The.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Other to do this checking is very simple.",
                    "label": 0
                },
                {
                    "sent": "The first step we approximate the five frequent probability using an interval and then check the following conditions.",
                    "label": 1
                },
                {
                    "sent": "If the interval is in one of these positions that we output it.",
                    "label": 0
                },
                {
                    "sent": "Otherwise if it is in one of dispositions, then we discard it.",
                    "label": 0
                },
                {
                    "sent": "So the key steps is the step one to do this.",
                    "label": 1
                },
                {
                    "sent": "To do this step one we we propose.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And then they make a programming based method.",
                    "label": 0
                },
                {
                    "sent": "It's recursive equation is like this due to the time limit.",
                    "label": 1
                },
                {
                    "sent": "I don't exploit and when all the elements of this table have been computed, we can get final result by summing up all the element TIGN such that that inequality is satisfied and this is.",
                    "label": 1
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Illustration of the procedure we feel.",
                    "label": 0
                },
                {
                    "sent": "The tables are in this order and finally we sum up all the elements in the in the Dark Room.",
                    "label": 0
                },
                {
                    "sent": "Been apart of we notice that some input of this over the dynamic programming is sharp P hard to compute, so our intuitive idea to make this dynamic programming practical is too.",
                    "label": 1
                },
                {
                    "sent": "Computer to use some estimated value instead of the exact values.",
                    "label": 0
                },
                {
                    "sent": "So to get this estimate values.",
                    "label": 0
                },
                {
                    "sent": "At.",
                    "label": 0
                },
                {
                    "sent": "OK, let's finish this site and we propose an randomized algorithm.",
                    "label": 0
                },
                {
                    "sent": "In our previous work and.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "It is a randomized algorithm, so to guarantee the output of dynamic programming is within error epsilon and with probability at least one might start.",
                    "label": 1
                },
                {
                    "sent": "We just need to require the randomized algorithm to guarantee each estimated value is within error like this and succeed with probability like this.",
                    "label": 0
                },
                {
                    "sent": "So this is the main idea of the our approach.",
                    "label": 0
                },
                {
                    "sent": "The the theoretical.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "A bond of this algorithm is that any frequent stop graph is up to output as a result with at least lower bound.",
                    "label": 1
                },
                {
                    "sent": "OK, OK then this is the theoretical result of our algorithm.",
                    "label": 0
                },
                {
                    "sent": "OK, thank you.",
                    "label": 0
                }
            ]
        }
    }
}