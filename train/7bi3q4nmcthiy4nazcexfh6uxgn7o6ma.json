{
    "id": "7bi3q4nmcthiy4nazcexfh6uxgn7o6ma",
    "title": "The Graph-guided Group Lasso",
    "info": {
        "author": [
            "Zi Wang, Department of Mathematics, Imperial College London"
        ],
        "published": "Aug. 26, 2013",
        "recorded": "July 2013",
        "category": [
            "Top->Computer Science->Optimization Methods",
            "Top->Computer Science->Machine Learning->Kernel Methods->Support Vector Machines",
            "Top->Computer Science->Compressed Sensing",
            "Top->Computer Science->Machine Learning->Regularization"
        ]
    },
    "url": "http://videolectures.net/roks2013_wang_graph/",
    "segmentation": [
        [
            "To give you a guideline on outlying out this spring."
        ],
        [
            "Patient, the first part will be talking about its biological motivations, IE where the problem derives and what sort of information is available to solve the problem.",
            "And Secondly I'll talk about some statistical modeling in process, which is how to formulate the problem and how to incorporate those prior knowledge available which is originally coming from the by informatics part."
        ],
        [
            "And next I will present you the two versions of the group Guided Graph Guided Group with a SU.",
            "Depending on how you interpret a particular sort of biological information at heterogeneous levels, and then the estimation algorithms.",
            "And finally I'll be showing you."
        ],
        [
            "Do some preliminary results and some."
        ],
        [
            "Future works.",
            "OK, a quick introduction to the biology.",
            "So as we know."
        ],
        [
            "The human and the entire set of 23 human chromosomes is called a genome, and the genome is composed of 3 billion based pairs."
        ],
        [
            "And the genetic variation that says at a single base pair is called a snip, and we know and snips account for many genetic very genetic variations between people such as appearances and disease and reaction to grass."
        ],
        [
            "And our objective here is to identify the most important predictors, for example, snips that account for the variability of a quantitative trait."
        ],
        [
            "OK, some notation of how to formulate this problem so we have access into times people dicta matrix and why.",
            "At the end of the versions of univariate continuous response and you have a bitter and you have absolutely and then we use a linear regression model, which is one of the standard approach and were excellent.",
            "Why are column wise centered such that the Intercept term can be dropped?"
        ],
        [
            "And in all generally square asked images minimizes the square loss function and the penalized linear regression, which is you add a penalty penalty term P on the coefficient which is called the penalty term such that particular objectives can be obtained.",
            "And some."
        ],
        [
            "The most famous man.",
            "An penalized regression model includes a penalty terms, such as the last Sue and Elastic Net."
        ],
        [
            "However, on those models, they tend to assess each an snips or each predictors individually, without taking into account of the readily available biological and prior knowledge."
        ],
        [
            "Each.",
            "Now what sort of?"
        ],
        [
            "Biological knowledge are available here where they come in various types.",
            "One of them would be variable grouping where you have multiple snips come from from 1 gene draw, often jointly carry out genetic functionalities, and then it is not."
        ],
        [
            "To have nips grouped into jeans.",
            "So the."
        ],
        [
            "Bio information you have would be a petition of predictors into groups where in this case we assume the groups are non overlapping."
        ],
        [
            "So the desired sparsity part and you have would be some of the groups are not important.",
            "Therefore all the elements would have zero coefficient and where the within those important groups you identify the most important predictors such as those marked in red."
        ],
        [
            "And there are some existing literatures which.",
            "Actually incorporate this and information on Snips Group into jeans and they observed an enhanced power in identifying the true snips."
        ],
        [
            "The other type of information available is you have a quantified pairwise relationship between the predictors.",
            "And in this case your predictor is going to be jeans, so that you have genes belonging to the same pathway now often expressed similarly in risk."
        ],
        [
            "Bonds.",
            "And naturally you have a gene regulatory network where the nodes correspond to the jeans and the edge corresponds to a quantified pairwise relationship on.",
            "Obviously the larger that age, where is it represents a stronger relationship."
        ],
        [
            "And the desired sparse Department is that the connected variables."
        ],
        [
            "Encourage to be selected together.",
            "On the."
        ],
        [
            "At work.",
            "And one of the examples which use this.",
            "Formation in that context by Lee and Lee, and that paper.",
            "OK, so up to now if you think about the problem and think about the solutions that we have.",
            "So we have snips grouped into jeans and then we have the gene network and we know they're using the gene network and guide the selection of genes.",
            "So it's natural.",
            "And then to think right we can use the network together selection of genes and within each gene we use some other sort of penalty functions so that to guide us the selection of the important snips within the jeans.",
            "And also this can be applied to newer image study where."
        ],
        [
            "The grouping might be due to region of interest and the quantified para pairwise relationships might be due to water flow between these regions.",
            "The desired sparse Department of the Graph guided group LAZU would be so you have several components in the network and in the network you have the some selective subnetworks which tend to be connected such as those black nodes, and within those selected nodes I either selected groups, you identify several important snips."
        ],
        [
            "So the cool part is how to incorporate the information which is actually.",
            "If you look at this picture, you see, well, there's an edge between two nodes, but if you zoom in, you found out that is not actually 2 about two nodes, but to set up nodes.",
            "So how do you use this information and pass it on to the small nose and naive solution?"
        ],
        [
            "We should be well before talking about that and just some more notation accent when beta is defined before and let R = R one R2 be a petition of the predictors and you know the size, just some standard notation, and then if there's a capital letter IXI, then that corresponds to the end times I submatrix it is lower, case letter is just denote column and then that GB the given network.",
            "With that, except via correspond to the groups in R and the weight of the edge is denoted by WCL with logging.",
            "Just assume WCS greater than zero, because you can always add mine assigned to a particular column in the predictor matrix such that the meaning of the weight will be."
        ],
        [
            "1st.",
            "OK, so the first interpretation, which is quite naive, so you have suppose this is your bigger node in the network and then another nodes which are connected and then you just construct a subnetwork as the complete bipartite graph from every nodes belonging to Group I and two every nodes belonging to group J."
        ],
        [
            "Tell an hour proposed GLP one has the objective function which is the square loss and plus three penalty functions and the first one for those of you who were working in this area recognized.",
            "This is actually the group let Sue and then the second one is luzu and if a combined P1 and P2, what those two functions penalty functions do is that they identify the important groups and the.",
            "Important snips within those groups, and this function P3 is.",
            "An Laplacian penalty where you penalize each pair of the.",
            "Predictors and weighted by the weight given at the group level.",
            "So intuitively, even look at this and then the fact is the coefficient of beyond BJ abit ion, Peter J would be pushed towards each other, so that in particular if your beta I is selected and beta J wouldn't be selected.",
            "If you do not use the network then this penalty would drive those to estimate to a middle value so that both coefficient estimate would be known."
        ],
        [
            "0.",
            "And some theoretical results if you just consider what this graph penalty does and would define, the following terms were just just just for notation shorthand and this gamma I is.",
            "If you look at their do realize this is actually a weighted average of the coefficient estimate that belonging to the group that is connected to the Group of interest and then you see a smoothing impact can be quantified by this.",
            "Amount, So what is tells us is that if you look at it, you see all those terms in the right hand side.",
            "They are constant, so effectively if you increase this regularization parameter mu, which means you have a stronger belief that the network is correct and so that the right hand side would tend to be 0, so that the left hand side you observe what we call the smoothing effect, which is to say the.",
            "Difference between the two?",
            "Interested predict coefficient coefficient of the interested predictors would be shrunk towards the weighted average of all their direct neighbors."
        ],
        [
            "However, in this naive version might have a side effect.",
            "If you look at this illustration picture, we are smoothing between this red predictor and this blue one, and then we also have a smoothing effect on this blue one.",
            "The red one.",
            "Therefore inevitably you have indirect smoothing effect between these two red guys, which means.",
            "If you.",
            "Look back on to that and then if there two predicts is coming from coming from the same group, these terms actually would be 0 and then those two coefficient estimate would be.",
            "We tend to be equal and this is not an ideal case, but cause if you wanted to add variable selection within the group, you do not want the effect to be pushed towards each other and then well even in the case where they become UN identifiable.",
            "And guided by that, we propose the second version of that."
        ],
        [
            "UGL, which if we look at this we see this edge.",
            "Surely it's just what is being said is that if you select that group and then the other group should be encouraged to select it.",
            "However, it doesn't mean that every pair of them should be encouraged to be selected together.",
            "Therefore we."
        ],
        [
            "We replace the graph penalty in GG well, one by this penalty, which penalizes the average coefficient of the two groups.",
            "And of course, by adding that penalty you are."
        ],
        [
            "Assuming a constraint where each individual coefficient coefficient estimates are non negative, because otherwise you might have well the bitter I bar is zero.",
            "However, every single element of it actually important."
        ],
        [
            "So the smoothing in fact for GL2 would take that form, and in particular where this D is a quantitative.",
            "That depends on the average coefficient, and you see that the right hand side is constant.",
            "Apart from this regularization parameter, mu and asmu tends to Infinity.",
            "This D would be 0, which says the smoothing effect.",
            "Not on the individual coefficient, but the average coefficient for the groups."
        ],
        [
            "And the corollary for that is that if XI and XJ belong to the same group, and then their difference between the coefficients, actually they it is free of mu.",
            "So what does that mean?",
            "Anne."
        ],
        [
            "Let me give you an illustration and using some toy example, but here when you compare the two models is is a bit."
        ],
        [
            "Ricky Becausw let's just ignore the lesser penalty and only do variable selection at group level.",
            "But then how would you align those Lambda ones and those two mus because they have different meaning in in the two models.",
            "So the solu?"
        ],
        [
            "Vision is that you tune Lambda one so that both models select the same number of groups and you tune the moon such that by this measure and the smoothing effect is.",
            "Equally strong in both models.",
            "OK, so."
        ],
        [
            "And this is an illustration of a toy.",
            "Later we have 60 predictor spectation into 6 equal groups and here we just assume Group One contains predictor one to 10 and Group 2 contains predictor 11 to 20 etc.",
            "And we assume the Group 123 and six they correspond to the true groups.",
            "Anwer four and five.",
            "They correspond to the noise groups and the strength of the signal is represented by the size of the.",
            "Of the note obviously note you do not talk about the size of note about.",
            "The coast.",
            "And so the natural structure is that.",
            "So what we would expect is that if we only ask the model to select three groups, so Group 1, two and six, they are identified.",
            "In the ideal case.",
            "However, if you do sort of apply the GL model and where you make yourself this network.",
            "Structure and then the smoothing effect tells us that actually 123 and the effect will be roughly get regularize to the same value so that you select 123 rather than 1, two and six when the Fusion parameter is large.",
            "So this is what we get."
        ],
        [
            "For small meal, for GGG are one and you can see the red dots represent true variables and blue dots represent noise variables, so that the true variables are singled out and so is here.",
            "What is not very ideal is that you've got this blue dots here, which makes it very difficult to identify.",
            "The true effects from here, but what can be verified is that Group One, Group 2 and group six.",
            "They are identified."
        ],
        [
            "And when you increase meal to a large value as said, you select Group 1, two and three and you do not send that Group 6, which is good.",
            "What is good here is that those predictors the true predictor within the Group One identified and however the smoothing effect for the naive version, the GLP one, and.",
            "Leads to the case where those and it's rather difficult to identify the true predictors from this cluster because they all tend to be rather similar."
        ],
        [
            "So now let's move to GLP two.",
            "When Mu is small, you identify those true predictors and you select Group 6.",
            "But what's really interesting is that when you have a relatively larger mu, it doesn't have to be as large, nice, incredibly large value.",
            "Then you start to observe that which is you still select Group One, Group 2, and then you select the Group 3, however.",
            "I'm by the positive constraint and those values are either strong to 0 or very."
        ],
        [
            "Close to zero, which means you have a higher chance to identify the true snips or the true predictors lying in the group, which have a relatively weaker signal strength."
        ],
        [
            "And the estimation algorithms will we just took a quite standard approach and where you just."
        ],
        [
            "An reformulate this penalty term as."
        ],
        [
            "We're in this matrix form where you have beta prime times out and speaker, and the entries in the arrow is defined just that and what is good is that the."
        ],
        [
            "Then you penalty function can be reformulated as these terms so that if"
        ],
        [
            "If you rewrite this L as you, you prime well you can do this because L is positive summit definite by construction.",
            "And then if you have reformulated now why Star next door matrix though as those and then the optimization problem of Gigi?"
        ],
        [
            "One is equivalent to.",
            "A sparse group Luzu model which can be solved by the standard blockwise coordinate descent algorithm.",
            "Like"
        ],
        [
            "Twice for GG GL two, you have another matrix.",
            "L was certainly different from GL1, where the I just entry is defined according to that."
        ],
        [
            "Those equations and then you can reformulate it as an in the exact same form in terms of Eckstein and why Star so that both optimization problem can be solved using the standard algorithms."
        ],
        [
            "I know my tongue and shouldn't be focusing on this, but just to give you the outline that we also develop parallel version of the estimation algorithm wherein each step you update a subset of the groups in parallel and this is an application of the work by Rick Drake and Target and they have a more general formulation of the problem that can be parallelized and.",
            "From the very limited experience with the observed larger than 10 times speedup compared with the non parallel algorithm written in C."
        ],
        [
            "And to give you the outline of this parallel coordinate descent algorithm.",
            "So basically start from the data you choose, the initial estimate and that KB one, and randomly pick a set of blocks from R and let us just call them K1 to K Anne, and in parallel you update the the chosen groups by function 5, where five corresponds to another optimization problem.",
            "And the fight is defined so that each step the expected value of the realization of the objective function is smaller.",
            "And then the previous one.",
            "And you just earn iterate this process until convergence.",
            "And definitely you require more steps to for the for the algorithm to converge compared to the non parallel version but.",
            "It does have some speedup.",
            "Will cap some quite substantial speedup, and in particular when you apply this to the real application where you end tends to be something like 500 and where you pay the number of predictors can be up to.",
            "200 or 400K."
        ],
        [
            "Write some preliminary result that little bit larger scale of data.",
            "Where you fix the the group variable grouping and but you, you do generate the network and you compute the wise from the from the generated beater and the absolute and you access columnwise, normalized and why is centered."
        ],
        [
            "What is important there is the natural networks for GGG El Modo's an with.",
            "Divide the net the according to the quality according to the relevance of the network to the study.",
            "We divide them into three types, where the first I've seen formative where the true variables are connected, not necessarily in one component, though, whereas there are very few links between true variables and noise variables, which means just as the example that I showed you on the toy data.",
            "And because some groups they might carry rather weak signal, but if they are connected to their groups that carrying a strong signal and then you get a higher chance for those groups to be selected, and then that corresponds to the case where the network is informative and the networks being uninformative means that all pairs of variables are connected with roughly equal probabilities and in the worst case you have a noisy network where the true variables are noise variables.",
            "Woman, almost bipartite graph and the true variables are rarely linked.",
            "Then so that the the strength of the signals they sort of diverged in two different directions, and then you making the problem even more difficult to identify the true.",
            "Groups"
        ],
        [
            "And some illustration of the networks, and this would correspond to an informative network because you you can observe that P1, which is the probability and that too true groups to signal groups are connected, is significantly larger than P12, which is a probability of connection between true group and the noise group.",
            "And here is an example of a noisy network where you.",
            "We have an almost bipartite graph between the true class of true groups and the class of noise groups and and the.",
            "And groups are rarely linked.",
            "You can see P1 is rather small.",
            "And then if you evaluate if you generate evaluate the performance on multiple datasets and also multiple networks and then."
        ],
        [
            "You have.",
            "Anne."
        ],
        [
            "You can evaluate the result via Roc curve where you blocked the true positive rate against the false positive rate and you see GLP one and display stronger and power than the group.",
            "Let's do."
        ],
        [
            "And there are some future works to do, which is to complete the simulation study on GLP two and study the performance of JGL Motors on the three types of networks.",
            "Actually we we did have done some of the studies but not on the huge scale scale of the database service.",
            "Do a little bit struggling to try to get the.",
            "The algorithm written in CUDA and the parallel algorithm for GL2 to work, but on the scale smaller scale the data you do actually expect and boost in power when the network is.",
            "Informative or an uninformative?",
            "And when the network is noisy and you might get a boost in power, but you might not depend really, depending on how the connection probabilities are.",
            "And the real application to the tumor data set."
        ],
        [
            "An yeah which would be collaborating with Doctor at Carrie from Imperial College and Peter Nash from Imperial College.",
            "London's well and just to thank those people and in particular my supervisor Doctor Giovanni Montana and that."
        ],
        [
            "Be it.",
            "Thank you very much."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To give you a guideline on outlying out this spring.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Patient, the first part will be talking about its biological motivations, IE where the problem derives and what sort of information is available to solve the problem.",
                    "label": 0
                },
                {
                    "sent": "And Secondly I'll talk about some statistical modeling in process, which is how to formulate the problem and how to incorporate those prior knowledge available which is originally coming from the by informatics part.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And next I will present you the two versions of the group Guided Graph Guided Group with a SU.",
                    "label": 0
                },
                {
                    "sent": "Depending on how you interpret a particular sort of biological information at heterogeneous levels, and then the estimation algorithms.",
                    "label": 0
                },
                {
                    "sent": "And finally I'll be showing you.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Do some preliminary results and some.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Future works.",
                    "label": 0
                },
                {
                    "sent": "OK, a quick introduction to the biology.",
                    "label": 0
                },
                {
                    "sent": "So as we know.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The human and the entire set of 23 human chromosomes is called a genome, and the genome is composed of 3 billion based pairs.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And the genetic variation that says at a single base pair is called a snip, and we know and snips account for many genetic very genetic variations between people such as appearances and disease and reaction to grass.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And our objective here is to identify the most important predictors, for example, snips that account for the variability of a quantitative trait.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, some notation of how to formulate this problem so we have access into times people dicta matrix and why.",
                    "label": 0
                },
                {
                    "sent": "At the end of the versions of univariate continuous response and you have a bitter and you have absolutely and then we use a linear regression model, which is one of the standard approach and were excellent.",
                    "label": 0
                },
                {
                    "sent": "Why are column wise centered such that the Intercept term can be dropped?",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And in all generally square asked images minimizes the square loss function and the penalized linear regression, which is you add a penalty penalty term P on the coefficient which is called the penalty term such that particular objectives can be obtained.",
                    "label": 0
                },
                {
                    "sent": "And some.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The most famous man.",
                    "label": 0
                },
                {
                    "sent": "An penalized regression model includes a penalty terms, such as the last Sue and Elastic Net.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "However, on those models, they tend to assess each an snips or each predictors individually, without taking into account of the readily available biological and prior knowledge.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Each.",
                    "label": 0
                },
                {
                    "sent": "Now what sort of?",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Biological knowledge are available here where they come in various types.",
                    "label": 0
                },
                {
                    "sent": "One of them would be variable grouping where you have multiple snips come from from 1 gene draw, often jointly carry out genetic functionalities, and then it is not.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To have nips grouped into jeans.",
                    "label": 0
                },
                {
                    "sent": "So the.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Bio information you have would be a petition of predictors into groups where in this case we assume the groups are non overlapping.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the desired sparsity part and you have would be some of the groups are not important.",
                    "label": 0
                },
                {
                    "sent": "Therefore all the elements would have zero coefficient and where the within those important groups you identify the most important predictors such as those marked in red.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And there are some existing literatures which.",
                    "label": 0
                },
                {
                    "sent": "Actually incorporate this and information on Snips Group into jeans and they observed an enhanced power in identifying the true snips.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The other type of information available is you have a quantified pairwise relationship between the predictors.",
                    "label": 0
                },
                {
                    "sent": "And in this case your predictor is going to be jeans, so that you have genes belonging to the same pathway now often expressed similarly in risk.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Bonds.",
                    "label": 0
                },
                {
                    "sent": "And naturally you have a gene regulatory network where the nodes correspond to the jeans and the edge corresponds to a quantified pairwise relationship on.",
                    "label": 1
                },
                {
                    "sent": "Obviously the larger that age, where is it represents a stronger relationship.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And the desired sparse Department is that the connected variables.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Encourage to be selected together.",
                    "label": 0
                },
                {
                    "sent": "On the.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "At work.",
                    "label": 0
                },
                {
                    "sent": "And one of the examples which use this.",
                    "label": 0
                },
                {
                    "sent": "Formation in that context by Lee and Lee, and that paper.",
                    "label": 0
                },
                {
                    "sent": "OK, so up to now if you think about the problem and think about the solutions that we have.",
                    "label": 0
                },
                {
                    "sent": "So we have snips grouped into jeans and then we have the gene network and we know they're using the gene network and guide the selection of genes.",
                    "label": 0
                },
                {
                    "sent": "So it's natural.",
                    "label": 0
                },
                {
                    "sent": "And then to think right we can use the network together selection of genes and within each gene we use some other sort of penalty functions so that to guide us the selection of the important snips within the jeans.",
                    "label": 0
                },
                {
                    "sent": "And also this can be applied to newer image study where.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The grouping might be due to region of interest and the quantified para pairwise relationships might be due to water flow between these regions.",
                    "label": 0
                },
                {
                    "sent": "The desired sparse Department of the Graph guided group LAZU would be so you have several components in the network and in the network you have the some selective subnetworks which tend to be connected such as those black nodes, and within those selected nodes I either selected groups, you identify several important snips.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the cool part is how to incorporate the information which is actually.",
                    "label": 1
                },
                {
                    "sent": "If you look at this picture, you see, well, there's an edge between two nodes, but if you zoom in, you found out that is not actually 2 about two nodes, but to set up nodes.",
                    "label": 0
                },
                {
                    "sent": "So how do you use this information and pass it on to the small nose and naive solution?",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We should be well before talking about that and just some more notation accent when beta is defined before and let R = R one R2 be a petition of the predictors and you know the size, just some standard notation, and then if there's a capital letter IXI, then that corresponds to the end times I submatrix it is lower, case letter is just denote column and then that GB the given network.",
                    "label": 1
                },
                {
                    "sent": "With that, except via correspond to the groups in R and the weight of the edge is denoted by WCL with logging.",
                    "label": 1
                },
                {
                    "sent": "Just assume WCS greater than zero, because you can always add mine assigned to a particular column in the predictor matrix such that the meaning of the weight will be.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "1st.",
                    "label": 0
                },
                {
                    "sent": "OK, so the first interpretation, which is quite naive, so you have suppose this is your bigger node in the network and then another nodes which are connected and then you just construct a subnetwork as the complete bipartite graph from every nodes belonging to Group I and two every nodes belonging to group J.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Tell an hour proposed GLP one has the objective function which is the square loss and plus three penalty functions and the first one for those of you who were working in this area recognized.",
                    "label": 0
                },
                {
                    "sent": "This is actually the group let Sue and then the second one is luzu and if a combined P1 and P2, what those two functions penalty functions do is that they identify the important groups and the.",
                    "label": 0
                },
                {
                    "sent": "Important snips within those groups, and this function P3 is.",
                    "label": 0
                },
                {
                    "sent": "An Laplacian penalty where you penalize each pair of the.",
                    "label": 0
                },
                {
                    "sent": "Predictors and weighted by the weight given at the group level.",
                    "label": 0
                },
                {
                    "sent": "So intuitively, even look at this and then the fact is the coefficient of beyond BJ abit ion, Peter J would be pushed towards each other, so that in particular if your beta I is selected and beta J wouldn't be selected.",
                    "label": 0
                },
                {
                    "sent": "If you do not use the network then this penalty would drive those to estimate to a middle value so that both coefficient estimate would be known.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "0.",
                    "label": 0
                },
                {
                    "sent": "And some theoretical results if you just consider what this graph penalty does and would define, the following terms were just just just for notation shorthand and this gamma I is.",
                    "label": 0
                },
                {
                    "sent": "If you look at their do realize this is actually a weighted average of the coefficient estimate that belonging to the group that is connected to the Group of interest and then you see a smoothing impact can be quantified by this.",
                    "label": 0
                },
                {
                    "sent": "Amount, So what is tells us is that if you look at it, you see all those terms in the right hand side.",
                    "label": 0
                },
                {
                    "sent": "They are constant, so effectively if you increase this regularization parameter mu, which means you have a stronger belief that the network is correct and so that the right hand side would tend to be 0, so that the left hand side you observe what we call the smoothing effect, which is to say the.",
                    "label": 0
                },
                {
                    "sent": "Difference between the two?",
                    "label": 0
                },
                {
                    "sent": "Interested predict coefficient coefficient of the interested predictors would be shrunk towards the weighted average of all their direct neighbors.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "However, in this naive version might have a side effect.",
                    "label": 1
                },
                {
                    "sent": "If you look at this illustration picture, we are smoothing between this red predictor and this blue one, and then we also have a smoothing effect on this blue one.",
                    "label": 0
                },
                {
                    "sent": "The red one.",
                    "label": 0
                },
                {
                    "sent": "Therefore inevitably you have indirect smoothing effect between these two red guys, which means.",
                    "label": 0
                },
                {
                    "sent": "If you.",
                    "label": 0
                },
                {
                    "sent": "Look back on to that and then if there two predicts is coming from coming from the same group, these terms actually would be 0 and then those two coefficient estimate would be.",
                    "label": 1
                },
                {
                    "sent": "We tend to be equal and this is not an ideal case, but cause if you wanted to add variable selection within the group, you do not want the effect to be pushed towards each other and then well even in the case where they become UN identifiable.",
                    "label": 0
                },
                {
                    "sent": "And guided by that, we propose the second version of that.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "UGL, which if we look at this we see this edge.",
                    "label": 0
                },
                {
                    "sent": "Surely it's just what is being said is that if you select that group and then the other group should be encouraged to select it.",
                    "label": 0
                },
                {
                    "sent": "However, it doesn't mean that every pair of them should be encouraged to be selected together.",
                    "label": 1
                },
                {
                    "sent": "Therefore we.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We replace the graph penalty in GG well, one by this penalty, which penalizes the average coefficient of the two groups.",
                    "label": 0
                },
                {
                    "sent": "And of course, by adding that penalty you are.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Assuming a constraint where each individual coefficient coefficient estimates are non negative, because otherwise you might have well the bitter I bar is zero.",
                    "label": 0
                },
                {
                    "sent": "However, every single element of it actually important.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the smoothing in fact for GL2 would take that form, and in particular where this D is a quantitative.",
                    "label": 0
                },
                {
                    "sent": "That depends on the average coefficient, and you see that the right hand side is constant.",
                    "label": 0
                },
                {
                    "sent": "Apart from this regularization parameter, mu and asmu tends to Infinity.",
                    "label": 0
                },
                {
                    "sent": "This D would be 0, which says the smoothing effect.",
                    "label": 0
                },
                {
                    "sent": "Not on the individual coefficient, but the average coefficient for the groups.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And the corollary for that is that if XI and XJ belong to the same group, and then their difference between the coefficients, actually they it is free of mu.",
                    "label": 1
                },
                {
                    "sent": "So what does that mean?",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Let me give you an illustration and using some toy example, but here when you compare the two models is is a bit.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Ricky Becausw let's just ignore the lesser penalty and only do variable selection at group level.",
                    "label": 0
                },
                {
                    "sent": "But then how would you align those Lambda ones and those two mus because they have different meaning in in the two models.",
                    "label": 0
                },
                {
                    "sent": "So the solu?",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Vision is that you tune Lambda one so that both models select the same number of groups and you tune the moon such that by this measure and the smoothing effect is.",
                    "label": 0
                },
                {
                    "sent": "Equally strong in both models.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And this is an illustration of a toy.",
                    "label": 0
                },
                {
                    "sent": "Later we have 60 predictor spectation into 6 equal groups and here we just assume Group One contains predictor one to 10 and Group 2 contains predictor 11 to 20 etc.",
                    "label": 1
                },
                {
                    "sent": "And we assume the Group 123 and six they correspond to the true groups.",
                    "label": 0
                },
                {
                    "sent": "Anwer four and five.",
                    "label": 0
                },
                {
                    "sent": "They correspond to the noise groups and the strength of the signal is represented by the size of the.",
                    "label": 0
                },
                {
                    "sent": "Of the note obviously note you do not talk about the size of note about.",
                    "label": 0
                },
                {
                    "sent": "The coast.",
                    "label": 0
                },
                {
                    "sent": "And so the natural structure is that.",
                    "label": 0
                },
                {
                    "sent": "So what we would expect is that if we only ask the model to select three groups, so Group 1, two and six, they are identified.",
                    "label": 0
                },
                {
                    "sent": "In the ideal case.",
                    "label": 0
                },
                {
                    "sent": "However, if you do sort of apply the GL model and where you make yourself this network.",
                    "label": 0
                },
                {
                    "sent": "Structure and then the smoothing effect tells us that actually 123 and the effect will be roughly get regularize to the same value so that you select 123 rather than 1, two and six when the Fusion parameter is large.",
                    "label": 0
                },
                {
                    "sent": "So this is what we get.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "For small meal, for GGG are one and you can see the red dots represent true variables and blue dots represent noise variables, so that the true variables are singled out and so is here.",
                    "label": 1
                },
                {
                    "sent": "What is not very ideal is that you've got this blue dots here, which makes it very difficult to identify.",
                    "label": 0
                },
                {
                    "sent": "The true effects from here, but what can be verified is that Group One, Group 2 and group six.",
                    "label": 0
                },
                {
                    "sent": "They are identified.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And when you increase meal to a large value as said, you select Group 1, two and three and you do not send that Group 6, which is good.",
                    "label": 0
                },
                {
                    "sent": "What is good here is that those predictors the true predictor within the Group One identified and however the smoothing effect for the naive version, the GLP one, and.",
                    "label": 0
                },
                {
                    "sent": "Leads to the case where those and it's rather difficult to identify the true predictors from this cluster because they all tend to be rather similar.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So now let's move to GLP two.",
                    "label": 0
                },
                {
                    "sent": "When Mu is small, you identify those true predictors and you select Group 6.",
                    "label": 0
                },
                {
                    "sent": "But what's really interesting is that when you have a relatively larger mu, it doesn't have to be as large, nice, incredibly large value.",
                    "label": 0
                },
                {
                    "sent": "Then you start to observe that which is you still select Group One, Group 2, and then you select the Group 3, however.",
                    "label": 0
                },
                {
                    "sent": "I'm by the positive constraint and those values are either strong to 0 or very.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Close to zero, which means you have a higher chance to identify the true snips or the true predictors lying in the group, which have a relatively weaker signal strength.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And the estimation algorithms will we just took a quite standard approach and where you just.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "An reformulate this penalty term as.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We're in this matrix form where you have beta prime times out and speaker, and the entries in the arrow is defined just that and what is good is that the.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Then you penalty function can be reformulated as these terms so that if",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "If you rewrite this L as you, you prime well you can do this because L is positive summit definite by construction.",
                    "label": 0
                },
                {
                    "sent": "And then if you have reformulated now why Star next door matrix though as those and then the optimization problem of Gigi?",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "One is equivalent to.",
                    "label": 0
                },
                {
                    "sent": "A sparse group Luzu model which can be solved by the standard blockwise coordinate descent algorithm.",
                    "label": 0
                },
                {
                    "sent": "Like",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Twice for GG GL two, you have another matrix.",
                    "label": 0
                },
                {
                    "sent": "L was certainly different from GL1, where the I just entry is defined according to that.",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Those equations and then you can reformulate it as an in the exact same form in terms of Eckstein and why Star so that both optimization problem can be solved using the standard algorithms.",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I know my tongue and shouldn't be focusing on this, but just to give you the outline that we also develop parallel version of the estimation algorithm wherein each step you update a subset of the groups in parallel and this is an application of the work by Rick Drake and Target and they have a more general formulation of the problem that can be parallelized and.",
                    "label": 0
                },
                {
                    "sent": "From the very limited experience with the observed larger than 10 times speedup compared with the non parallel algorithm written in C.",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And to give you the outline of this parallel coordinate descent algorithm.",
                    "label": 1
                },
                {
                    "sent": "So basically start from the data you choose, the initial estimate and that KB one, and randomly pick a set of blocks from R and let us just call them K1 to K Anne, and in parallel you update the the chosen groups by function 5, where five corresponds to another optimization problem.",
                    "label": 1
                },
                {
                    "sent": "And the fight is defined so that each step the expected value of the realization of the objective function is smaller.",
                    "label": 0
                },
                {
                    "sent": "And then the previous one.",
                    "label": 0
                },
                {
                    "sent": "And you just earn iterate this process until convergence.",
                    "label": 0
                },
                {
                    "sent": "And definitely you require more steps to for the for the algorithm to converge compared to the non parallel version but.",
                    "label": 0
                },
                {
                    "sent": "It does have some speedup.",
                    "label": 0
                },
                {
                    "sent": "Will cap some quite substantial speedup, and in particular when you apply this to the real application where you end tends to be something like 500 and where you pay the number of predictors can be up to.",
                    "label": 0
                },
                {
                    "sent": "200 or 400K.",
                    "label": 0
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Write some preliminary result that little bit larger scale of data.",
                    "label": 0
                },
                {
                    "sent": "Where you fix the the group variable grouping and but you, you do generate the network and you compute the wise from the from the generated beater and the absolute and you access columnwise, normalized and why is centered.",
                    "label": 0
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "What is important there is the natural networks for GGG El Modo's an with.",
                    "label": 0
                },
                {
                    "sent": "Divide the net the according to the quality according to the relevance of the network to the study.",
                    "label": 0
                },
                {
                    "sent": "We divide them into three types, where the first I've seen formative where the true variables are connected, not necessarily in one component, though, whereas there are very few links between true variables and noise variables, which means just as the example that I showed you on the toy data.",
                    "label": 1
                },
                {
                    "sent": "And because some groups they might carry rather weak signal, but if they are connected to their groups that carrying a strong signal and then you get a higher chance for those groups to be selected, and then that corresponds to the case where the network is informative and the networks being uninformative means that all pairs of variables are connected with roughly equal probabilities and in the worst case you have a noisy network where the true variables are noise variables.",
                    "label": 1
                },
                {
                    "sent": "Woman, almost bipartite graph and the true variables are rarely linked.",
                    "label": 0
                },
                {
                    "sent": "Then so that the the strength of the signals they sort of diverged in two different directions, and then you making the problem even more difficult to identify the true.",
                    "label": 0
                },
                {
                    "sent": "Groups",
                    "label": 0
                }
            ]
        },
        "clip_55": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And some illustration of the networks, and this would correspond to an informative network because you you can observe that P1, which is the probability and that too true groups to signal groups are connected, is significantly larger than P12, which is a probability of connection between true group and the noise group.",
                    "label": 0
                },
                {
                    "sent": "And here is an example of a noisy network where you.",
                    "label": 1
                },
                {
                    "sent": "We have an almost bipartite graph between the true class of true groups and the class of noise groups and and the.",
                    "label": 0
                },
                {
                    "sent": "And groups are rarely linked.",
                    "label": 0
                },
                {
                    "sent": "You can see P1 is rather small.",
                    "label": 0
                },
                {
                    "sent": "And then if you evaluate if you generate evaluate the performance on multiple datasets and also multiple networks and then.",
                    "label": 0
                }
            ]
        },
        "clip_56": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You have.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                }
            ]
        },
        "clip_57": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You can evaluate the result via Roc curve where you blocked the true positive rate against the false positive rate and you see GLP one and display stronger and power than the group.",
                    "label": 0
                },
                {
                    "sent": "Let's do.",
                    "label": 0
                }
            ]
        },
        "clip_58": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And there are some future works to do, which is to complete the simulation study on GLP two and study the performance of JGL Motors on the three types of networks.",
                    "label": 1
                },
                {
                    "sent": "Actually we we did have done some of the studies but not on the huge scale scale of the database service.",
                    "label": 0
                },
                {
                    "sent": "Do a little bit struggling to try to get the.",
                    "label": 0
                },
                {
                    "sent": "The algorithm written in CUDA and the parallel algorithm for GL2 to work, but on the scale smaller scale the data you do actually expect and boost in power when the network is.",
                    "label": 0
                },
                {
                    "sent": "Informative or an uninformative?",
                    "label": 0
                },
                {
                    "sent": "And when the network is noisy and you might get a boost in power, but you might not depend really, depending on how the connection probabilities are.",
                    "label": 1
                },
                {
                    "sent": "And the real application to the tumor data set.",
                    "label": 0
                }
            ]
        },
        "clip_59": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "An yeah which would be collaborating with Doctor at Carrie from Imperial College and Peter Nash from Imperial College.",
                    "label": 0
                },
                {
                    "sent": "London's well and just to thank those people and in particular my supervisor Doctor Giovanni Montana and that.",
                    "label": 0
                }
            ]
        },
        "clip_60": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Be it.",
                    "label": 0
                },
                {
                    "sent": "Thank you very much.",
                    "label": 0
                }
            ]
        }
    }
}