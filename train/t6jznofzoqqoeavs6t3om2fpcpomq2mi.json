{
    "id": "t6jznofzoqqoeavs6t3om2fpcpomq2mi",
    "title": "Graph Kernels for RDF data",
    "info": {
        "author": [
            "Achim Rettinger, Institute of Applied Informatics and Formal Description Methods (AIFB), Karlsruhe Institute of Technology (KIT)"
        ],
        "published": "July 4, 2012",
        "recorded": "May 2012",
        "category": [
            "Top->Computer Science->Machine Learning",
            "Top->Computer Science->Semantic Web->RDF - Resource Description Framework",
            "Top->Computer Science->Data Mining",
            "Top->Computer Science->Machine Learning->Kernel Methods",
            "Top->Computer Science->Semantic Web->OWL - Web Ontology Language"
        ]
    },
    "url": "http://videolectures.net/eswc2012_rettinger_rdf_data/",
    "segmentation": [
        [
            "So OK, this is joint work with Gouta and Steven.",
            "My name is Aaron Rettinger.",
            "Anne.",
            "So those two are former colleagues at AFP.",
            "And Walter did most of the work, especially the empirical evaluation.",
            "So the vision was when we started."
        ],
        [
            "This research was that if you have given any data in RDF format like for example here, this social networks with persons that might have interests and that might know each other.",
            "You want to solve any standard statistical relational learning tasks, like for example.",
            "Property value prediction so."
        ],
        [
            "That means in this example, maybe predict the likelihood that person 200 might also be female.",
            "Or link prediction which is."
        ],
        [
            "Which predicts the instance of a predicate.",
            "So in this case you could want to predict if person 100 might also be interested in topic 110.",
            "And maybe even some unsupervised task which could."
        ],
        [
            "B.",
            "How similar are two entity instances so persons and this case, so which which could be grouped together which is called machine learning, typically called clustering, sometimes also called group detection.",
            "In statistical relational learning.",
            "And maybe also additional tasks that I didn't show here in the example which are class membership prediction or entity resolution.",
            "And if this is not enough, we wanted to."
        ],
        [
            "Some constraints on that on top, so we wanted to use readily available learning algorithms we want.",
            "Didn't want to invent another learning algorithm that can solve this task, and we wanted to exploit the specific art of RDF crafts.",
            "But rely only on the graph structure and the labels so that there's no manual effort needed.",
            "So for example 2.",
            "Come up with some specific hour rules compared with stuff.",
            "So no domain adaptation is needed.",
            "OK, so.",
            "The thing in the related work that comes closest to this."
        ],
        [
            "Task is the good old kernel trick which has."
        ],
        [
            "Been researched in machine learning for.",
            "Decade now and it's very well established.",
            "The basic idea is that you D couple the data representation, so in this case the RDF graph from the learning algorithm and then use any machine learning algorithm that can have a kernel matrix as an input so the kernel matrix in this case is all combinations of instances.",
            "That is, put into this kernel function.",
            "And there are a lot of kernel machines out there.",
            "The most popular support vector machine support vector regression, kernel K means, and those can solve different tasks.",
            "For example, classification, prediction, clustering, regression and so on.",
            "So the problem basically boils down to how to define this kernel on graph graphs.",
            "I'm.",
            "The fire here present.",
            "So for those of you who are not familiar with this concept, the files represent the transformation function with us, which does not need to be calculated explicitly.",
            "If you define it properly, but can be calculated in a combined step together with the product, so traditional Phi has an input, the input to the five function is a feature vector, and it Maps it to even larger feature vector, and then you can calculate the cross product and in the end you get one single value real value again which somehow describes the similarity of the two entity instances that you put into the into the.",
            "Function.",
            "In our case here we input an RDF graph to this function.",
            "This function produces a vector that then can be evaluated with the dot product again to one single.",
            "Real value.",
            "And so, how do we know that we end up with a valid kernel function that can be used for a machine learning for a kernel machine?",
            "There are different ways to prove this.",
            "There's like the mathematical way which we need to prove that your kernel function is finitely positive semi definite function, or you can simply do it by showing that this explicit mapping and the dot product calculating those two steps separately produces the same as your kernel function in a closed form.",
            "OK.",
            "So now, as I said before, this is a very very researched area.",
            "But we still think we."
        ],
        [
            "On the spot that hasn't been researched that much and there are two different types of approaches.",
            "That somehow related to our approach.",
            "So on the one side we have the kernel methods that were specifically derived for ontologies.",
            "Here are some of the related works.",
            "So the for instance the bluedorn kernel, they use domain specific features and they basically count the overlap of two entity instance type types.",
            "And they they tuned their kernel on on the data set.",
            "Then there are some kernels from fanatsy at all, and they in most cases rely on some description logic rules, which then can deductively classify the instances two classes and they basically count the overlap of those classes.",
            "For each instance, and so can save, they are similar.",
            "OK then.",
            "The last one which was presented last year at this conference here is from bit said I.",
            "And they used the two step approach where they first.",
            "Find the pattern in the graph that seems to be most effective for.",
            "For predicting what the actual tasks or doing the prediction, and then after this step they solved it with a genetic algorithm, I think they actually apply the support vector machine.",
            "So in our opinion.",
            "Those in many cases those approaches can be too specific in regard in different dimensions.",
            "So for example, regarding the representation.",
            "So they might assume that you have some owl DL ontology on top of your RDF graph that can be used for deductive reasoning and influencing which which classes the entities belong.",
            "Another dimension could be the task.",
            "So for example, the triple patterns can only be used for classification tasks, not for clustering.",
            "Cause this optimization step already needs feedback from the class label, so unsupervised methods cannot be used here.",
            "Or they can only be used with one specific kernel machine.",
            "So again, if you can only solve a classification task then you can do as you can use a support vector machine, but you cannot use this for for a clustering task.",
            "OK. Then on the other hand, there's a huge area of research on kernel methods on general graphs that's maybe not that well known here in the semantic web community, but in the machine learning Community, this has also been researched heavily for years an what they mostly apply their kernels to is.",
            "Buy into the biomedical domain so gene networks and comperable networks.",
            "So there are also different approaches that basically use different ways of counting features in those graphs, and those general graphs that could be walks, path cycles or trees.",
            "But the main difference is that they assume general graphs and not RDF graphs so.",
            "What we mean by what we would buy, we think that there are two general is.",
            "First of all, they usually don't have a unique naming assumption.",
            "That means that.",
            "The Note label in the graph appears very often, so not only once in the graphs that they are looking at.",
            "Then they typically have a small number of different node labels, where in RDF graphs you have a huge number of different node labels.",
            "They have a low decree.",
            "So that means the number of edges outgoing of each node are very small.",
            "In RDF you can have a huge number of edges per node.",
            "They often they have no edge labels and their graphs are often also not directed, so it's.",
            "It is used usable for general graphs, but they don't exploit the specific specific characteristics of an RDF graph.",
            "OK, so our approach is somewhere in the middle.",
            "We try to fill this gap between the two approaches.",
            "OK, so once again our goal is to."
        ],
        [
            "To define a kernel function which can be used with any kernel machine with any standard kernel machine and thus can solve any standard statistical relation learning task where there exists a suitable kernel machine.",
            "We want to hand handle any RDF data, so as we work only on this syntax, no adjustments need to be made to handle specific data representations like our DL.",
            "And.",
            "We still want to exploit the specifics of RDF.",
            "OK so I just gave you the motivation and.",
            "Talked about the related work.",
            "Now I want to talk about the."
        ],
        [
            "Families of RDF kernels that we proposed in our work, which are based on intersection graphs and intersection trees.",
            "So starting with the intersection graphs.",
            "This."
        ],
        [
            "Is how you calculate an intersection graph as in.",
            "Input we have the RDF graph and the two entity instances that we want to calculate the kernel.",
            "Um?",
            "To give you an example, that's the same example as before the instance graph."
        ],
        [
            "For the two entities.",
            "So in this case we are looking at person 100.",
            "In person 200 is a breadth first search across the graph, starting from each of the entities.",
            "And this would mean for person.",
            "200 This means this would be the instance graph becausw.",
            "We have directed links, so we cannot follow it in the other directions for person 100, this would be the instance graph as we are only looking at two hops in this case."
        ],
        [
            "In this example, so the machine learning would not be considered.",
            "Oh no."
        ],
        [
            "Coming to the next step.",
            "We now we still have those two graphs.",
            "What we now can do is we can intersect those two graphs.",
            "Using this formula, So what it basically does?"
        ],
        [
            "All vertices and associated edges appear in the instance graph.",
            "Are extracted from the both instance graph and appear.",
            "Then in the intersection graph so the intersection graph contains a given sub graph if it contains a given sub graph.",
            "This sub graph is also subgraph of each of the two input graphs.",
            "So coming back to the example, the intersection of the two instance graphs would look like this.",
            "OK, and now we're at a step where you can apply all those measures from."
        ],
        [
            "General graph kernels where we can now count the features in this graph.",
            "So this could be again walks, paths, connected subgraphs and so on.",
            "So but we need to make sure that we end up with a valid kernel function."
        ],
        [
            "And what we showed in the paper is I don't want to go into the details too much.",
            "Is that any set of edge induced subgraphs is a valid kernel function produces a valid kernel function?",
            "So this is the definition for the edge induced subgraph, which maybe in a more intuitive way means that you for every vertice that should be in the edge into sub graph.",
            "Of the intersection graph, they need to be all incoming and outgoing edges in the edge induced sub graph and then.",
            "You can just count the standard features, so the simplest one would be just edges.",
            "You could also do walks and path up to a length of an arbitrary number, and the most complex then would be connected edge induced subgraphs.",
            "Adam.",
            "OK. Now."
        ],
        [
            "Briefly coming to the intersection trees.",
            "So.",
            "We still have the problem that it's not very efficient or we can calculate this more efficiently because we still have those two steps where we first extract the instance graph and then intersect the graph.",
            "So we came up with the intersection trees which can do this in one step.",
            "So you basically start crawling the graph from the two entity instances and compute the intersection tree in one step.",
            "This is.",
            "This has some problems becausw you need to have some way to deal with cycles.",
            "I don't want to go into the details.",
            "They are in the paper, but what we basically did, we just considered this those nodes twice in our tree.",
            "OK.",
            "So finally, coming to the evaluation."
        ],
        [
            "We evaluated this on two of the statistical relational learning tasks.",
            "Starting with property value Pridie."
        ],
        [
            "Action.",
            "As a multi multi label learning problem we use support vector machines for that.",
            "The data set is data set about persons publication, research, research topics, research group in projects with quite a large number of entities and persons, and the task was to predict if a person is a member of a research group.",
            "And we trained.",
            "So what do you typically typically do?",
            "If you want to use a support vector machine for multi label learning problem, you train one classifier for each class.",
            "So for each research research group and try to predict if this person should be member of this research group.",
            "And evaluation measures averaged over those classifiers.",
            "Yeah, we have evaluated this but leave one out cross validation.",
            "Here we show the results for one."
        ],
        [
            "Of the more general and one of the.",
            "More specific approaches and.",
            "What you can see is that we be achieved comperable performances to both approaches, where the approach the more specific approach by Blue Dawn and I is a little bit better, but you have to keep in mind that they had to in this for this data set and Rd.",
            "Yeah, specific evaluated specific types there that they defined by hand before.",
            "And there are more much more experiments in the paper, but I decided not to show all of them so that it's not getting confused.",
            "The second task is also classical statistical relational learning tasks where you try."
        ],
        [
            "To predict links between entities in this case.",
            "Want to recommend if friend might also know another person in a social network.",
            "We used friend of a friend data from live Journal with.",
            "Yeah.",
            "8000 instances of known instances of their nose relation and the task was predict the unknown.",
            "The likelihood of the unknown knows relations.",
            "As the classification models model.",
            "Anne.",
            "You cannot directly."
        ],
        [
            "Life support vector machine to this problem cause it's not a simple classification problem anymore.",
            "But we came up with this reformulation of the kernels to also make it suitable for a support vector machine.",
            "So what?",
            "What we thought would be intuitive is that what you want to compare is subject object pairs and by simple kernel arithmetics you can rewrite those.",
            "So what you want to compare is subject object triples, but you can rewrite this.",
            "By in two kernels.",
            "So this is equivalent to writing it in two kernels where you only compare the subject and the object, and this is exactly then the problem as before, but you need to just add up two kernels.",
            "And the Alpha and the better you can wait the kernels differently.",
            "OK, here are the results we compare."
        ],
        [
            "Add this to the Suns approach.",
            "Which is an approach that I have not mentioned before.",
            "It's in the standard version.",
            "It's not kernel based.",
            "And it's based on matrix factorization, which has been proven to be extremely good on link prediction task like for the Netflix Challenge and so on.",
            "So here you can see that we considerably outperformed that, but we have to admit that the comparison is not completely fair.",
            "As we figured out later, because for those people who went to the tutorial on Monday, the Suns framework is also only a framework where we can plug in different.",
            "Matrix factorization techniques, and it seems we picked the one that cannot do inductive predictions, which means that if you.",
            "If you have a subject or object that's not in the training set, you cannot make predictions for this for this.",
            "For this subject.",
            "And this probably results in this very bad beep ref.",
            "Measure, so I guess we would have to rerun the experiments using a different matrix factorization approach.",
            "I think it was non negative matrix factorization or some.",
            "Which the the one we used.",
            "OK.",
            "So in summary.",
            "We introduced."
        ],
        [
            "Two families of kernel functions for RDF graph, which can be used with any kernel machine.",
            "And might solve any associated Learning task task.",
            "They can be applied to.",
            "Any RDF graph while exploiting the specifics of the RDF graph, and they show comparative performance to more specific and more general approaches and what I haven't shown here is that the.",
            "The computational complexity is usually much better, so for the general graphs they often didn't finish in our experiments at all, because they cannot deal with the correct characteristics of RDF graphs, so it takes much too long to converge for them.",
            "OK, some future works.",
            "So we would like to test this with."
        ],
        [
            "Other kernel machines I already talked to FOCA and would be nice to try this in the Sun ceramic.",
            "There's also a kernelized version of the Suns framework.",
            "So this sounds very promising, because you can then have the structural information about the network and the matrix factorization.",
            "The power of the matrix factorization approach combined.",
            "And what's also very would be very interesting to investigate.",
            "Is that so we found out what we proposed is just a family of Colonel.",
            "So they are still a lot of parameters that can be used.",
            "So the first thing of course is which what are you counting on?",
            "You counting paths or edges or even subtrees?",
            "And then of course, how deep do you traverse the graphs and so these are all parameters that can be adjusted in our family of kernels.",
            "And we found out that RDF graphs are also very different.",
            "So an RDF graph in the domain of a social network looks completely different to RDF graph about.",
            "I don't know a DB pedia, RDF graph or something like that.",
            "So what we found out that the performance depends of course.",
            "On the the account that you really choose in the end and the type of the RDF graph, so it would be nice to investigate this and maybe come up with some general rules where you can say if the characteristics of the aircraft that you're looking is this.",
            "In this please use.",
            "I don't know a tree kernel with random walks and to a depth of whatever.",
            "This would be interesting.",
            "OK, thanks a lot and I'm open for questions."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So OK, this is joint work with Gouta and Steven.",
                    "label": 0
                },
                {
                    "sent": "My name is Aaron Rettinger.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "So those two are former colleagues at AFP.",
                    "label": 0
                },
                {
                    "sent": "And Walter did most of the work, especially the empirical evaluation.",
                    "label": 0
                },
                {
                    "sent": "So the vision was when we started.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This research was that if you have given any data in RDF format like for example here, this social networks with persons that might have interests and that might know each other.",
                    "label": 1
                },
                {
                    "sent": "You want to solve any standard statistical relational learning tasks, like for example.",
                    "label": 1
                },
                {
                    "sent": "Property value prediction so.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That means in this example, maybe predict the likelihood that person 200 might also be female.",
                    "label": 0
                },
                {
                    "sent": "Or link prediction which is.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Which predicts the instance of a predicate.",
                    "label": 0
                },
                {
                    "sent": "So in this case you could want to predict if person 100 might also be interested in topic 110.",
                    "label": 0
                },
                {
                    "sent": "And maybe even some unsupervised task which could.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "B.",
                    "label": 0
                },
                {
                    "sent": "How similar are two entity instances so persons and this case, so which which could be grouped together which is called machine learning, typically called clustering, sometimes also called group detection.",
                    "label": 0
                },
                {
                    "sent": "In statistical relational learning.",
                    "label": 0
                },
                {
                    "sent": "And maybe also additional tasks that I didn't show here in the example which are class membership prediction or entity resolution.",
                    "label": 0
                },
                {
                    "sent": "And if this is not enough, we wanted to.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Some constraints on that on top, so we wanted to use readily available learning algorithms we want.",
                    "label": 1
                },
                {
                    "sent": "Didn't want to invent another learning algorithm that can solve this task, and we wanted to exploit the specific art of RDF crafts.",
                    "label": 0
                },
                {
                    "sent": "But rely only on the graph structure and the labels so that there's no manual effort needed.",
                    "label": 1
                },
                {
                    "sent": "So for example 2.",
                    "label": 0
                },
                {
                    "sent": "Come up with some specific hour rules compared with stuff.",
                    "label": 0
                },
                {
                    "sent": "So no domain adaptation is needed.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "The thing in the related work that comes closest to this.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Task is the good old kernel trick which has.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Been researched in machine learning for.",
                    "label": 0
                },
                {
                    "sent": "Decade now and it's very well established.",
                    "label": 0
                },
                {
                    "sent": "The basic idea is that you D couple the data representation, so in this case the RDF graph from the learning algorithm and then use any machine learning algorithm that can have a kernel matrix as an input so the kernel matrix in this case is all combinations of instances.",
                    "label": 0
                },
                {
                    "sent": "That is, put into this kernel function.",
                    "label": 0
                },
                {
                    "sent": "And there are a lot of kernel machines out there.",
                    "label": 0
                },
                {
                    "sent": "The most popular support vector machine support vector regression, kernel K means, and those can solve different tasks.",
                    "label": 0
                },
                {
                    "sent": "For example, classification, prediction, clustering, regression and so on.",
                    "label": 0
                },
                {
                    "sent": "So the problem basically boils down to how to define this kernel on graph graphs.",
                    "label": 0
                },
                {
                    "sent": "I'm.",
                    "label": 0
                },
                {
                    "sent": "The fire here present.",
                    "label": 0
                },
                {
                    "sent": "So for those of you who are not familiar with this concept, the files represent the transformation function with us, which does not need to be calculated explicitly.",
                    "label": 0
                },
                {
                    "sent": "If you define it properly, but can be calculated in a combined step together with the product, so traditional Phi has an input, the input to the five function is a feature vector, and it Maps it to even larger feature vector, and then you can calculate the cross product and in the end you get one single value real value again which somehow describes the similarity of the two entity instances that you put into the into the.",
                    "label": 0
                },
                {
                    "sent": "Function.",
                    "label": 0
                },
                {
                    "sent": "In our case here we input an RDF graph to this function.",
                    "label": 0
                },
                {
                    "sent": "This function produces a vector that then can be evaluated with the dot product again to one single.",
                    "label": 0
                },
                {
                    "sent": "Real value.",
                    "label": 0
                },
                {
                    "sent": "And so, how do we know that we end up with a valid kernel function that can be used for a machine learning for a kernel machine?",
                    "label": 0
                },
                {
                    "sent": "There are different ways to prove this.",
                    "label": 0
                },
                {
                    "sent": "There's like the mathematical way which we need to prove that your kernel function is finitely positive semi definite function, or you can simply do it by showing that this explicit mapping and the dot product calculating those two steps separately produces the same as your kernel function in a closed form.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So now, as I said before, this is a very very researched area.",
                    "label": 0
                },
                {
                    "sent": "But we still think we.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "On the spot that hasn't been researched that much and there are two different types of approaches.",
                    "label": 0
                },
                {
                    "sent": "That somehow related to our approach.",
                    "label": 0
                },
                {
                    "sent": "So on the one side we have the kernel methods that were specifically derived for ontologies.",
                    "label": 1
                },
                {
                    "sent": "Here are some of the related works.",
                    "label": 0
                },
                {
                    "sent": "So the for instance the bluedorn kernel, they use domain specific features and they basically count the overlap of two entity instance type types.",
                    "label": 0
                },
                {
                    "sent": "And they they tuned their kernel on on the data set.",
                    "label": 0
                },
                {
                    "sent": "Then there are some kernels from fanatsy at all, and they in most cases rely on some description logic rules, which then can deductively classify the instances two classes and they basically count the overlap of those classes.",
                    "label": 0
                },
                {
                    "sent": "For each instance, and so can save, they are similar.",
                    "label": 0
                },
                {
                    "sent": "OK then.",
                    "label": 0
                },
                {
                    "sent": "The last one which was presented last year at this conference here is from bit said I.",
                    "label": 0
                },
                {
                    "sent": "And they used the two step approach where they first.",
                    "label": 0
                },
                {
                    "sent": "Find the pattern in the graph that seems to be most effective for.",
                    "label": 0
                },
                {
                    "sent": "For predicting what the actual tasks or doing the prediction, and then after this step they solved it with a genetic algorithm, I think they actually apply the support vector machine.",
                    "label": 0
                },
                {
                    "sent": "So in our opinion.",
                    "label": 1
                },
                {
                    "sent": "Those in many cases those approaches can be too specific in regard in different dimensions.",
                    "label": 0
                },
                {
                    "sent": "So for example, regarding the representation.",
                    "label": 0
                },
                {
                    "sent": "So they might assume that you have some owl DL ontology on top of your RDF graph that can be used for deductive reasoning and influencing which which classes the entities belong.",
                    "label": 0
                },
                {
                    "sent": "Another dimension could be the task.",
                    "label": 0
                },
                {
                    "sent": "So for example, the triple patterns can only be used for classification tasks, not for clustering.",
                    "label": 0
                },
                {
                    "sent": "Cause this optimization step already needs feedback from the class label, so unsupervised methods cannot be used here.",
                    "label": 0
                },
                {
                    "sent": "Or they can only be used with one specific kernel machine.",
                    "label": 0
                },
                {
                    "sent": "So again, if you can only solve a classification task then you can do as you can use a support vector machine, but you cannot use this for for a clustering task.",
                    "label": 0
                },
                {
                    "sent": "OK. Then on the other hand, there's a huge area of research on kernel methods on general graphs that's maybe not that well known here in the semantic web community, but in the machine learning Community, this has also been researched heavily for years an what they mostly apply their kernels to is.",
                    "label": 0
                },
                {
                    "sent": "Buy into the biomedical domain so gene networks and comperable networks.",
                    "label": 0
                },
                {
                    "sent": "So there are also different approaches that basically use different ways of counting features in those graphs, and those general graphs that could be walks, path cycles or trees.",
                    "label": 0
                },
                {
                    "sent": "But the main difference is that they assume general graphs and not RDF graphs so.",
                    "label": 0
                },
                {
                    "sent": "What we mean by what we would buy, we think that there are two general is.",
                    "label": 0
                },
                {
                    "sent": "First of all, they usually don't have a unique naming assumption.",
                    "label": 0
                },
                {
                    "sent": "That means that.",
                    "label": 0
                },
                {
                    "sent": "The Note label in the graph appears very often, so not only once in the graphs that they are looking at.",
                    "label": 0
                },
                {
                    "sent": "Then they typically have a small number of different node labels, where in RDF graphs you have a huge number of different node labels.",
                    "label": 0
                },
                {
                    "sent": "They have a low decree.",
                    "label": 0
                },
                {
                    "sent": "So that means the number of edges outgoing of each node are very small.",
                    "label": 0
                },
                {
                    "sent": "In RDF you can have a huge number of edges per node.",
                    "label": 0
                },
                {
                    "sent": "They often they have no edge labels and their graphs are often also not directed, so it's.",
                    "label": 0
                },
                {
                    "sent": "It is used usable for general graphs, but they don't exploit the specific specific characteristics of an RDF graph.",
                    "label": 1
                },
                {
                    "sent": "OK, so our approach is somewhere in the middle.",
                    "label": 0
                },
                {
                    "sent": "We try to fill this gap between the two approaches.",
                    "label": 0
                },
                {
                    "sent": "OK, so once again our goal is to.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "To define a kernel function which can be used with any kernel machine with any standard kernel machine and thus can solve any standard statistical relation learning task where there exists a suitable kernel machine.",
                    "label": 1
                },
                {
                    "sent": "We want to hand handle any RDF data, so as we work only on this syntax, no adjustments need to be made to handle specific data representations like our DL.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 1
                },
                {
                    "sent": "We still want to exploit the specifics of RDF.",
                    "label": 0
                },
                {
                    "sent": "OK so I just gave you the motivation and.",
                    "label": 0
                },
                {
                    "sent": "Talked about the related work.",
                    "label": 0
                },
                {
                    "sent": "Now I want to talk about the.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Families of RDF kernels that we proposed in our work, which are based on intersection graphs and intersection trees.",
                    "label": 1
                },
                {
                    "sent": "So starting with the intersection graphs.",
                    "label": 0
                },
                {
                    "sent": "This.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Is how you calculate an intersection graph as in.",
                    "label": 1
                },
                {
                    "sent": "Input we have the RDF graph and the two entity instances that we want to calculate the kernel.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 1
                },
                {
                    "sent": "To give you an example, that's the same example as before the instance graph.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "For the two entities.",
                    "label": 0
                },
                {
                    "sent": "So in this case we are looking at person 100.",
                    "label": 0
                },
                {
                    "sent": "In person 200 is a breadth first search across the graph, starting from each of the entities.",
                    "label": 1
                },
                {
                    "sent": "And this would mean for person.",
                    "label": 1
                },
                {
                    "sent": "200 This means this would be the instance graph becausw.",
                    "label": 0
                },
                {
                    "sent": "We have directed links, so we cannot follow it in the other directions for person 100, this would be the instance graph as we are only looking at two hops in this case.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In this example, so the machine learning would not be considered.",
                    "label": 0
                },
                {
                    "sent": "Oh no.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Coming to the next step.",
                    "label": 0
                },
                {
                    "sent": "We now we still have those two graphs.",
                    "label": 0
                },
                {
                    "sent": "What we now can do is we can intersect those two graphs.",
                    "label": 0
                },
                {
                    "sent": "Using this formula, So what it basically does?",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "All vertices and associated edges appear in the instance graph.",
                    "label": 0
                },
                {
                    "sent": "Are extracted from the both instance graph and appear.",
                    "label": 0
                },
                {
                    "sent": "Then in the intersection graph so the intersection graph contains a given sub graph if it contains a given sub graph.",
                    "label": 1
                },
                {
                    "sent": "This sub graph is also subgraph of each of the two input graphs.",
                    "label": 1
                },
                {
                    "sent": "So coming back to the example, the intersection of the two instance graphs would look like this.",
                    "label": 0
                },
                {
                    "sent": "OK, and now we're at a step where you can apply all those measures from.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "General graph kernels where we can now count the features in this graph.",
                    "label": 0
                },
                {
                    "sent": "So this could be again walks, paths, connected subgraphs and so on.",
                    "label": 0
                },
                {
                    "sent": "So but we need to make sure that we end up with a valid kernel function.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And what we showed in the paper is I don't want to go into the details too much.",
                    "label": 0
                },
                {
                    "sent": "Is that any set of edge induced subgraphs is a valid kernel function produces a valid kernel function?",
                    "label": 1
                },
                {
                    "sent": "So this is the definition for the edge induced subgraph, which maybe in a more intuitive way means that you for every vertice that should be in the edge into sub graph.",
                    "label": 1
                },
                {
                    "sent": "Of the intersection graph, they need to be all incoming and outgoing edges in the edge induced sub graph and then.",
                    "label": 0
                },
                {
                    "sent": "You can just count the standard features, so the simplest one would be just edges.",
                    "label": 0
                },
                {
                    "sent": "You could also do walks and path up to a length of an arbitrary number, and the most complex then would be connected edge induced subgraphs.",
                    "label": 1
                },
                {
                    "sent": "Adam.",
                    "label": 0
                },
                {
                    "sent": "OK. Now.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Briefly coming to the intersection trees.",
                    "label": 1
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "We still have the problem that it's not very efficient or we can calculate this more efficiently because we still have those two steps where we first extract the instance graph and then intersect the graph.",
                    "label": 0
                },
                {
                    "sent": "So we came up with the intersection trees which can do this in one step.",
                    "label": 0
                },
                {
                    "sent": "So you basically start crawling the graph from the two entity instances and compute the intersection tree in one step.",
                    "label": 1
                },
                {
                    "sent": "This is.",
                    "label": 0
                },
                {
                    "sent": "This has some problems becausw you need to have some way to deal with cycles.",
                    "label": 0
                },
                {
                    "sent": "I don't want to go into the details.",
                    "label": 0
                },
                {
                    "sent": "They are in the paper, but what we basically did, we just considered this those nodes twice in our tree.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So finally, coming to the evaluation.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We evaluated this on two of the statistical relational learning tasks.",
                    "label": 0
                },
                {
                    "sent": "Starting with property value Pridie.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Action.",
                    "label": 0
                },
                {
                    "sent": "As a multi multi label learning problem we use support vector machines for that.",
                    "label": 0
                },
                {
                    "sent": "The data set is data set about persons publication, research, research topics, research group in projects with quite a large number of entities and persons, and the task was to predict if a person is a member of a research group.",
                    "label": 1
                },
                {
                    "sent": "And we trained.",
                    "label": 0
                },
                {
                    "sent": "So what do you typically typically do?",
                    "label": 0
                },
                {
                    "sent": "If you want to use a support vector machine for multi label learning problem, you train one classifier for each class.",
                    "label": 0
                },
                {
                    "sent": "So for each research research group and try to predict if this person should be member of this research group.",
                    "label": 1
                },
                {
                    "sent": "And evaluation measures averaged over those classifiers.",
                    "label": 0
                },
                {
                    "sent": "Yeah, we have evaluated this but leave one out cross validation.",
                    "label": 0
                },
                {
                    "sent": "Here we show the results for one.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Of the more general and one of the.",
                    "label": 0
                },
                {
                    "sent": "More specific approaches and.",
                    "label": 0
                },
                {
                    "sent": "What you can see is that we be achieved comperable performances to both approaches, where the approach the more specific approach by Blue Dawn and I is a little bit better, but you have to keep in mind that they had to in this for this data set and Rd.",
                    "label": 0
                },
                {
                    "sent": "Yeah, specific evaluated specific types there that they defined by hand before.",
                    "label": 0
                },
                {
                    "sent": "And there are more much more experiments in the paper, but I decided not to show all of them so that it's not getting confused.",
                    "label": 0
                },
                {
                    "sent": "The second task is also classical statistical relational learning tasks where you try.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "To predict links between entities in this case.",
                    "label": 1
                },
                {
                    "sent": "Want to recommend if friend might also know another person in a social network.",
                    "label": 0
                },
                {
                    "sent": "We used friend of a friend data from live Journal with.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 1
                },
                {
                    "sent": "8000 instances of known instances of their nose relation and the task was predict the unknown.",
                    "label": 1
                },
                {
                    "sent": "The likelihood of the unknown knows relations.",
                    "label": 0
                },
                {
                    "sent": "As the classification models model.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "You cannot directly.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Life support vector machine to this problem cause it's not a simple classification problem anymore.",
                    "label": 0
                },
                {
                    "sent": "But we came up with this reformulation of the kernels to also make it suitable for a support vector machine.",
                    "label": 0
                },
                {
                    "sent": "So what?",
                    "label": 0
                },
                {
                    "sent": "What we thought would be intuitive is that what you want to compare is subject object pairs and by simple kernel arithmetics you can rewrite those.",
                    "label": 0
                },
                {
                    "sent": "So what you want to compare is subject object triples, but you can rewrite this.",
                    "label": 0
                },
                {
                    "sent": "By in two kernels.",
                    "label": 0
                },
                {
                    "sent": "So this is equivalent to writing it in two kernels where you only compare the subject and the object, and this is exactly then the problem as before, but you need to just add up two kernels.",
                    "label": 0
                },
                {
                    "sent": "And the Alpha and the better you can wait the kernels differently.",
                    "label": 0
                },
                {
                    "sent": "OK, here are the results we compare.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Add this to the Suns approach.",
                    "label": 0
                },
                {
                    "sent": "Which is an approach that I have not mentioned before.",
                    "label": 0
                },
                {
                    "sent": "It's in the standard version.",
                    "label": 0
                },
                {
                    "sent": "It's not kernel based.",
                    "label": 0
                },
                {
                    "sent": "And it's based on matrix factorization, which has been proven to be extremely good on link prediction task like for the Netflix Challenge and so on.",
                    "label": 0
                },
                {
                    "sent": "So here you can see that we considerably outperformed that, but we have to admit that the comparison is not completely fair.",
                    "label": 0
                },
                {
                    "sent": "As we figured out later, because for those people who went to the tutorial on Monday, the Suns framework is also only a framework where we can plug in different.",
                    "label": 0
                },
                {
                    "sent": "Matrix factorization techniques, and it seems we picked the one that cannot do inductive predictions, which means that if you.",
                    "label": 0
                },
                {
                    "sent": "If you have a subject or object that's not in the training set, you cannot make predictions for this for this.",
                    "label": 0
                },
                {
                    "sent": "For this subject.",
                    "label": 0
                },
                {
                    "sent": "And this probably results in this very bad beep ref.",
                    "label": 0
                },
                {
                    "sent": "Measure, so I guess we would have to rerun the experiments using a different matrix factorization approach.",
                    "label": 0
                },
                {
                    "sent": "I think it was non negative matrix factorization or some.",
                    "label": 0
                },
                {
                    "sent": "Which the the one we used.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So in summary.",
                    "label": 0
                },
                {
                    "sent": "We introduced.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Two families of kernel functions for RDF graph, which can be used with any kernel machine.",
                    "label": 1
                },
                {
                    "sent": "And might solve any associated Learning task task.",
                    "label": 0
                },
                {
                    "sent": "They can be applied to.",
                    "label": 1
                },
                {
                    "sent": "Any RDF graph while exploiting the specifics of the RDF graph, and they show comparative performance to more specific and more general approaches and what I haven't shown here is that the.",
                    "label": 0
                },
                {
                    "sent": "The computational complexity is usually much better, so for the general graphs they often didn't finish in our experiments at all, because they cannot deal with the correct characteristics of RDF graphs, so it takes much too long to converge for them.",
                    "label": 0
                },
                {
                    "sent": "OK, some future works.",
                    "label": 0
                },
                {
                    "sent": "So we would like to test this with.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Other kernel machines I already talked to FOCA and would be nice to try this in the Sun ceramic.",
                    "label": 1
                },
                {
                    "sent": "There's also a kernelized version of the Suns framework.",
                    "label": 0
                },
                {
                    "sent": "So this sounds very promising, because you can then have the structural information about the network and the matrix factorization.",
                    "label": 0
                },
                {
                    "sent": "The power of the matrix factorization approach combined.",
                    "label": 0
                },
                {
                    "sent": "And what's also very would be very interesting to investigate.",
                    "label": 0
                },
                {
                    "sent": "Is that so we found out what we proposed is just a family of Colonel.",
                    "label": 0
                },
                {
                    "sent": "So they are still a lot of parameters that can be used.",
                    "label": 0
                },
                {
                    "sent": "So the first thing of course is which what are you counting on?",
                    "label": 0
                },
                {
                    "sent": "You counting paths or edges or even subtrees?",
                    "label": 0
                },
                {
                    "sent": "And then of course, how deep do you traverse the graphs and so these are all parameters that can be adjusted in our family of kernels.",
                    "label": 0
                },
                {
                    "sent": "And we found out that RDF graphs are also very different.",
                    "label": 0
                },
                {
                    "sent": "So an RDF graph in the domain of a social network looks completely different to RDF graph about.",
                    "label": 0
                },
                {
                    "sent": "I don't know a DB pedia, RDF graph or something like that.",
                    "label": 0
                },
                {
                    "sent": "So what we found out that the performance depends of course.",
                    "label": 0
                },
                {
                    "sent": "On the the account that you really choose in the end and the type of the RDF graph, so it would be nice to investigate this and maybe come up with some general rules where you can say if the characteristics of the aircraft that you're looking is this.",
                    "label": 0
                },
                {
                    "sent": "In this please use.",
                    "label": 0
                },
                {
                    "sent": "I don't know a tree kernel with random walks and to a depth of whatever.",
                    "label": 0
                },
                {
                    "sent": "This would be interesting.",
                    "label": 0
                },
                {
                    "sent": "OK, thanks a lot and I'm open for questions.",
                    "label": 0
                }
            ]
        }
    }
}