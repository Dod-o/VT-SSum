{
    "id": "j63yjv4zzt3laanht74tmfbokfsspp6x",
    "title": "Single Image 3D Interpreter Network",
    "info": {
        "author": [
            "Jiajun Wu, Department of Electrical Engineering and Computer Science, Massachusetts Institute of Technology, MIT"
        ],
        "published": "Oct. 24, 2016",
        "recorded": "October 2016",
        "category": [
            "Top->Computer Science->Computer Vision"
        ]
    },
    "url": "http://videolectures.net/eccv2016_wu_single_image/",
    "segmentation": [
        [
            "Hi everyone, I'm judging from MIT so today I'm going to present our work single image through the interpreter network so this is joint work with Changshu who is also Co first author and Joseph Lemuel Dantean, Josh Nabam, Antonio Torralba and Bill Freeman from MIT, Stanford, Facebook and Google.",
            "So let's start with some simple images by look."
        ],
        [
            "At this image of sofa and image of swivel."
        ],
        [
            "Sure, and."
        ],
        [
            "Image of this here.",
            "So what do we humans really perceive from these images?",
            "So apparently we."
        ],
        [
            "Editor 3D object structure as well is exposed and we also see its appearance and texture.",
            "So we humans."
        ],
        [
            "Do recover very rich through the information from just a single image, so this would also be our task in this paper."
        ],
        [
            "It is to do a single image through the object perception."
        ],
        [
            "So the input to our system will just be a single RGB image and output will be the estimated 3D object structure and post.",
            "So this has been a very traditional problem in computer vision.",
            "There has been many related works.",
            "Of air."
        ],
        [
            "Straightforward approach is just try to label many 3D objects on every 2D images, just like this newly proposed data set option as 3D from Sean at all in this ecv.",
            "So such a large data set could be very helpful to the community as well.",
            "However, these datasets are also very expensive and time consuming to obtain, especially if you want to make a large scale in general."
        ],
        [
            "So as an alternative, people are thinking about using 3D synthetic models.",
            "You just take a lot of them and try to render them in various poses in front of various backgrounds.",
            "OK, this in this way you can get almost infinite number of training data.",
            "However, as we can see from the screen, the rendered images are usually not as real as what we as the images we see in daily lives, so they suffer from a domain transfer problem.",
            "So different from these two approaches, here we propose a third one which aim to aim to get the best of both worlds."
        ],
        [
            "Instead of directly estimating 3D object structure imposed from the single input image, we decide to propose."
        ],
        [
            "Is to use an intermediate 2D representation, where in our work we choose to use the heat Maps of 2D key points.",
            "So by doing this we're decomposing the original problem into two subproblems.",
            "The first one is to estimate."
        ],
        [
            "The heat Maps of 2D key points given the RGB 2D image by doing with.",
            "By doing this what we need in this step is only the real images with their 2D labels of keypoint locations.",
            "We require no 3D labels in this step at all.",
            "And for the second step."
        ],
        [
            "Now we already have the heat Maps of key points.",
            "Then we try to recover the 3D object structure imposed from these keymaps for this step, what we need is the synthetic 3D models.",
            "Now remember that here instead of rendering the original image, all we need to render, it's just these heat Maps.",
            "So here the map serving as an abstraction of the original image and during the rendering there is no need to worry about rendering all the low level textures and different appearances and possible occlusions.",
            "We just need to render these heatmaps."
        ],
        [
            "So in these two steps as we can see, what we need is the 2D key point labels and the 3DS insider models.",
            "We require no 3D labels for objects in image, so this is this is our like in general framework.",
            "They're having similar frameworks in like post estimations and face estimations.",
            "But here in this paper we want to make it generalizes to general object categories."
        ],
        [
            "So this is again our first main contribution.",
            "That is, we propose to use real 2D keypoint labels on images and synthetic 3D object models for 3D structure, an post estimation and we propose to use here Maps of key points as an intermediate 2D representation to connect the input to the image and output 3D objects.",
            "So now let's go to some."
        ],
        [
            "Details like what could be our 3D object representation.",
            "So there has been many of them available, like the voxels which has been very popular these days due to it's nice combination with convolutional neural networks.",
            "And there have been many."
        ],
        [
            "As they have been in the field for a really long time and they're able to capture the fine details of the objects."
        ],
        [
            "But in this paper we choose to use 3D object skeletons.",
            "We choose to skeletons becauses naturally encodes the symmetric semantic and geometric shape prior of the object and also contains the key point information nicely which we use as our intermediate 2D representation.",
            "Our skeleton represent."
        ],
        [
            "And is defined as follows.",
            "1st for each object category, we manually designs base shapes which captures the possible deformations of the object of that category.",
            "For example, for cheers these deformations could be the length of legs and could be the angle between the back and the bottom.",
            "Then we make an assumption."
        ],
        [
            "That estimate is 3D object structure can be characterized by a linear combination of these base shapes.",
            "Where introduced, the structural parameter Alpha.",
            "Now let's look into the problem that how we are really seeing this 3D object from a 2D image."
        ],
        [
            "So apparently, given this in 3D space there is 3D rotation parameter R and there is 3D translation."
        ],
        [
            "Parameter T. And at the end, because we're seeing this object from a sing."
        ],
        [
            "Viewpoint there is a 3D to 2D projection parameter P, so these speedy parameters that projection P rotation R and structural parameter Alpha and translation TI really do parameters.",
            "We'd like to estimate.",
            "So going back to our framework, given image, we first try to recover the heat map."
        ],
        [
            "Key points in 2D space and then from the heat Maps we try to recover these three parameters PR offer anti so very intuitive design will be."
        ],
        [
            "I have a two step network where the first component is to do 2D key point estimation.",
            "So here we choose."
        ],
        [
            "Use a multiscale convolutional neural network which is inspired or actually as an extension of the of the network proposed by Thompson at all in CVP or 2015.",
            "So in."
        ],
        [
            "Parts we use again 2D annotated image data.",
            "The input is just RGB image and output will be estimated.",
            "Keypoint here Maps and the second component."
        ],
        [
            "It would be a 3D interpreter."
        ],
        [
            "Here we just use a multilayer perceptual network, and."
        ],
        [
            "For this part, as we said earlier, we use 3D synthetic data for training, so the input would be the rendered.",
            "He Maps of key points and output will be the 3D parameters PR authenti.",
            "Look"
        ],
        [
            "Bunny these two come out components.",
            "We just get our intuitive naive design of our network.",
            "So let's look at some initial."
        ],
        [
            "Given an image."
        ],
        [
            "This is the estimated.",
            "He Maps of key points and this is."
        ],
        [
            "The final estimated skeleton.",
            "So we see that OK seems to be working fine.",
            "It's generally captured the rough structure and post of the object, but apparently it's not perfect, especially for the estimated sweetie skeleton.",
            "The estimated their corresponding to the keypoints doesn't really align with the 2D key points of the object in the original image.",
            "So the."
        ],
        [
            "This could be becausw, as we observed in our experiments, that errors in the first stage that it in the key point estimation stage get propagated into the second stage.",
            "So is there a problem?",
            "Is there a solution that we can alleviate this problem?",
            "So."
        ],
        [
            "Very intuitive thought, would be OK. Let's just try to do end to end training to give an image, let's try to directly supervise it.",
            "To estimate the object structure imposed.",
            "However, this is not really possible because we don't want to use the very expensive 3D labels.",
            "However, Rick."
        ],
        [
            "Or that we do have the 2D keep on labels of the objects in image.",
            "So is it possible for us to use these two D labels of keypoint locations to refine our estimation of the 3D object structure?",
            "I turned out to be possible because."
        ],
        [
            "If we revisit how we get these key points from our 3D structure, we go back to this formula and we see that this is actually fully."
        ],
        [
            "Pressable, so the 3D to 2D projection thing is actually fully differentiable, so we can actually solve this problem by propose a 3D to 2D projection layer, which takes the estimated 3D structure imposed as inputs and try to compute the corresponding coordinates of keypoint locations, and then given we have the ground truth of these keypoint locations, we can use them as a supervision to refine our estimation of the three D3D object.",
            "So."
        ],
        [
            "This will be the third stage of our training.",
            "That is, we use.",
            "We propose a 3D to 2D projection layer so that enables end to end training and for this stage will again use our 2D annotated real data.",
            "The input is in single RGB image and the output is key point coordinates.",
            "But here instead of just training the 2D key point estimation part, we treat the entire network end to end which includes the 2D point estimation part, the 3D interpreter and the 3D to 2D projection layer.",
            "So the objective function for this stage will just be to minimize the reprojection error of the two D coordinates."
        ],
        [
            "So our training tire paradigm therefore contains 3 steps."
        ],
        [
            "The first to do the 2D, keep an estimation and 2nd."
        ],
        [
            "Is to train the 3D interpreter and the third."
        ],
        [
            "Is to find to the entire network network end to end.",
            "So this framework has also other interpretations.",
            "For example, we can see we can see this 3D to 2D projection layer as maximizing the likelihood given certain geometric prior.",
            "But again, although there are other like optimization methods which pose similar formulation where the first to introduce it to your network do end to end, we can also see this the first 2 components like the key points and the 3D interpreter estimator as an analysis or inference step, while the three D2D projection layer.",
            "It's a very simple graphics engine, so this can be seen as the inverse graphics and re render framework."
        ],
        [
            "She will now let's look at the refined results again.",
            "Given image.",
            "This is our initial estimation and by incorporating this 3D to 2D projection layer and to do N 2 and fine tuning, here is the."
        ],
        [
            "New results we get.",
            "We see that we get a much better at estimation of the original structure and pose of the object in the image and the estimated 2D key points actually align with the original key points in the images."
        ],
        [
            "So this is actually our second main idea or our second contribution.",
            "That is, we propose a 3D to 2D projection layer for N2 and training of the entire network.",
            "So now let's go to a more."
        ],
        [
            "Thorough evaluation of results.",
            "We first see some qualitative results, so for all our training we did our training on the our newly proposed key .5 data set, which contains objects of five categories of furniture, and for each category there are roughly 2000 training images available."
        ],
        [
            "We did our testing on multiple datasets.",
            "The first is our key .5 datasets.",
            "So given let's look at this bad, you see we're estimating structure and viewpoint of the bad pretty accurately.",
            "Especially given this is not an easy image because there is a cultural background and color.",
            "The background is very similar to the color of the object.",
            "And we also tested."
        ],
        [
            "Performance on two other datasets.",
            "One is the IKEA datasets which proposed by Lim at all in 2013.",
            "Again, this is a pretty hard case because the swivel chair is occluded by a wide table.",
            "Again, we can do it pretty well.",
            "And we."
        ],
        [
            "Tested on the more General Sun database proposed by Salvador in 2011, so our algorithm works well for the case of a sofa.",
            "N4K"
        ],
        [
            "Is overcrowded chair?",
            "So here by testing our algorithm on multiple datasets, we also show that our algorithm is not suffering from a data set bias problem."
        ],
        [
            "So now let's go to a more quantitative evaluation.",
            "So first for estimating 3D structure, we."
        ],
        [
            "Did our evaluation on IKEA datasets where we have ground truth CD labels available?",
            "For this, for this part we compare with the optimization based method proposed by Joe Adult in 2016."
        ],
        [
            "So we see that are going to achieve a much better performance than Joe.",
            "However, we do want to make the point that Becausw Joetta is actually an essentially an optimization method.",
            "They really require very accurate keypoint locations, and because we know 2D keypoint locations on general images really hard, so arguing performs better because we are more robust to the in accuracies in 2D point estimation.",
            "And for."
        ],
        [
            "Point estimation again, we did our quantitative study on IKEA day."
        ],
        [
            "Set and for this we compare with the paper from Sue Adult in ICC 2015."
        ],
        [
            "Again, we achieved some much better performance.",
            "I think this is because Sue at all is method which use almost purely synthetic data for training.",
            "But our method tried to combine the real annotations of 2D key points on images as well as the 3D synthetic models.",
            "So."
        ],
        [
            "For a different setting, we want to do localization and beautiful and estimation jointly.",
            "So given an image you want to."
        ],
        [
            "Detector object and they want to estimate its 3D structure."
        ],
        [
            "Viewpoint so our framework can be used to do this by a combination with some detection framework here."
        ],
        [
            "We choose to use the standard RCN.",
            "We tested our performance on the."
        ],
        [
            "Scale 3D plus datasets proposed by cellar Door in 2014 and we see that our algorithm achieves comperable performance with the state of the art, which is the viewpoints and key points paper from UC Berkeley.",
            "And again, we also want to make an additional point that our algorithm is just trained.",
            "Our key .5 datasets and we didn't really use any labels from the Pascal 3D plus data set.",
            "This is different from the other competitors.",
            "So now let's look at another application."
        ],
        [
            "Means and why this algorithm can be useful?",
            "So first this is a visualization of the test images of cheers.",
            "According to their info viewpoints.",
            "So we project all the test images into a 2D plane and we see that the nicely forms are manifold where the orientation of the chair rotates from left to right.",
            "And as another application, we see that how we can retrieve images by its posts now given as."
        ],
        [
            "3D object of three of a swivel chair we graduate rotates it.",
            "We want to retrieve objects of similar posts to the input and see that our algorithm can do pretty well on this.",
            "So to conclude."
        ],
        [
            "In this problem in this, in this paper we stayed.",
            "We studied the problem of single image 3D object perception."
        ],
        [
            "We propose 2 main contributions.",
            "The first one is we propose to use route to the labels as well as synthetic 3D objects.",
            "Again, we require no CD labels of the real objects in images for training and to do this we propose to use key points.",
            "Here Maps as our intermediate representation."
        ],
        [
            "And our second contribution, as we propose a 3D to 2D projection layer which enables NQ and training of the network.",
            "Which also makes it possible for us to refine our 3D estimation using 2D labels only.",
            "Thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Hi everyone, I'm judging from MIT so today I'm going to present our work single image through the interpreter network so this is joint work with Changshu who is also Co first author and Joseph Lemuel Dantean, Josh Nabam, Antonio Torralba and Bill Freeman from MIT, Stanford, Facebook and Google.",
                    "label": 0
                },
                {
                    "sent": "So let's start with some simple images by look.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "At this image of sofa and image of swivel.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Sure, and.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Image of this here.",
                    "label": 0
                },
                {
                    "sent": "So what do we humans really perceive from these images?",
                    "label": 1
                },
                {
                    "sent": "So apparently we.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Editor 3D object structure as well is exposed and we also see its appearance and texture.",
                    "label": 0
                },
                {
                    "sent": "So we humans.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Do recover very rich through the information from just a single image, so this would also be our task in this paper.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It is to do a single image through the object perception.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the input to our system will just be a single RGB image and output will be the estimated 3D object structure and post.",
                    "label": 0
                },
                {
                    "sent": "So this has been a very traditional problem in computer vision.",
                    "label": 0
                },
                {
                    "sent": "There has been many related works.",
                    "label": 0
                },
                {
                    "sent": "Of air.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Straightforward approach is just try to label many 3D objects on every 2D images, just like this newly proposed data set option as 3D from Sean at all in this ecv.",
                    "label": 0
                },
                {
                    "sent": "So such a large data set could be very helpful to the community as well.",
                    "label": 0
                },
                {
                    "sent": "However, these datasets are also very expensive and time consuming to obtain, especially if you want to make a large scale in general.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So as an alternative, people are thinking about using 3D synthetic models.",
                    "label": 1
                },
                {
                    "sent": "You just take a lot of them and try to render them in various poses in front of various backgrounds.",
                    "label": 0
                },
                {
                    "sent": "OK, this in this way you can get almost infinite number of training data.",
                    "label": 0
                },
                {
                    "sent": "However, as we can see from the screen, the rendered images are usually not as real as what we as the images we see in daily lives, so they suffer from a domain transfer problem.",
                    "label": 0
                },
                {
                    "sent": "So different from these two approaches, here we propose a third one which aim to aim to get the best of both worlds.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Instead of directly estimating 3D object structure imposed from the single input image, we decide to propose.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is to use an intermediate 2D representation, where in our work we choose to use the heat Maps of 2D key points.",
                    "label": 0
                },
                {
                    "sent": "So by doing this we're decomposing the original problem into two subproblems.",
                    "label": 0
                },
                {
                    "sent": "The first one is to estimate.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The heat Maps of 2D key points given the RGB 2D image by doing with.",
                    "label": 0
                },
                {
                    "sent": "By doing this what we need in this step is only the real images with their 2D labels of keypoint locations.",
                    "label": 1
                },
                {
                    "sent": "We require no 3D labels in this step at all.",
                    "label": 0
                },
                {
                    "sent": "And for the second step.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now we already have the heat Maps of key points.",
                    "label": 0
                },
                {
                    "sent": "Then we try to recover the 3D object structure imposed from these keymaps for this step, what we need is the synthetic 3D models.",
                    "label": 1
                },
                {
                    "sent": "Now remember that here instead of rendering the original image, all we need to render, it's just these heat Maps.",
                    "label": 0
                },
                {
                    "sent": "So here the map serving as an abstraction of the original image and during the rendering there is no need to worry about rendering all the low level textures and different appearances and possible occlusions.",
                    "label": 0
                },
                {
                    "sent": "We just need to render these heatmaps.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So in these two steps as we can see, what we need is the 2D key point labels and the 3DS insider models.",
                    "label": 0
                },
                {
                    "sent": "We require no 3D labels for objects in image, so this is this is our like in general framework.",
                    "label": 0
                },
                {
                    "sent": "They're having similar frameworks in like post estimations and face estimations.",
                    "label": 0
                },
                {
                    "sent": "But here in this paper we want to make it generalizes to general object categories.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this is again our first main contribution.",
                    "label": 0
                },
                {
                    "sent": "That is, we propose to use real 2D keypoint labels on images and synthetic 3D object models for 3D structure, an post estimation and we propose to use here Maps of key points as an intermediate 2D representation to connect the input to the image and output 3D objects.",
                    "label": 1
                },
                {
                    "sent": "So now let's go to some.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Details like what could be our 3D object representation.",
                    "label": 1
                },
                {
                    "sent": "So there has been many of them available, like the voxels which has been very popular these days due to it's nice combination with convolutional neural networks.",
                    "label": 0
                },
                {
                    "sent": "And there have been many.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "As they have been in the field for a really long time and they're able to capture the fine details of the objects.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But in this paper we choose to use 3D object skeletons.",
                    "label": 0
                },
                {
                    "sent": "We choose to skeletons becauses naturally encodes the symmetric semantic and geometric shape prior of the object and also contains the key point information nicely which we use as our intermediate 2D representation.",
                    "label": 0
                },
                {
                    "sent": "Our skeleton represent.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And is defined as follows.",
                    "label": 0
                },
                {
                    "sent": "1st for each object category, we manually designs base shapes which captures the possible deformations of the object of that category.",
                    "label": 0
                },
                {
                    "sent": "For example, for cheers these deformations could be the length of legs and could be the angle between the back and the bottom.",
                    "label": 0
                },
                {
                    "sent": "Then we make an assumption.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That estimate is 3D object structure can be characterized by a linear combination of these base shapes.",
                    "label": 0
                },
                {
                    "sent": "Where introduced, the structural parameter Alpha.",
                    "label": 0
                },
                {
                    "sent": "Now let's look into the problem that how we are really seeing this 3D object from a 2D image.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So apparently, given this in 3D space there is 3D rotation parameter R and there is 3D translation.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Parameter T. And at the end, because we're seeing this object from a sing.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Viewpoint there is a 3D to 2D projection parameter P, so these speedy parameters that projection P rotation R and structural parameter Alpha and translation TI really do parameters.",
                    "label": 0
                },
                {
                    "sent": "We'd like to estimate.",
                    "label": 0
                },
                {
                    "sent": "So going back to our framework, given image, we first try to recover the heat map.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Key points in 2D space and then from the heat Maps we try to recover these three parameters PR offer anti so very intuitive design will be.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I have a two step network where the first component is to do 2D key point estimation.",
                    "label": 0
                },
                {
                    "sent": "So here we choose.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Use a multiscale convolutional neural network which is inspired or actually as an extension of the of the network proposed by Thompson at all in CVP or 2015.",
                    "label": 0
                },
                {
                    "sent": "So in.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Parts we use again 2D annotated image data.",
                    "label": 1
                },
                {
                    "sent": "The input is just RGB image and output will be estimated.",
                    "label": 0
                },
                {
                    "sent": "Keypoint here Maps and the second component.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It would be a 3D interpreter.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here we just use a multilayer perceptual network, and.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "For this part, as we said earlier, we use 3D synthetic data for training, so the input would be the rendered.",
                    "label": 1
                },
                {
                    "sent": "He Maps of key points and output will be the 3D parameters PR authenti.",
                    "label": 0
                },
                {
                    "sent": "Look",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Bunny these two come out components.",
                    "label": 0
                },
                {
                    "sent": "We just get our intuitive naive design of our network.",
                    "label": 0
                },
                {
                    "sent": "So let's look at some initial.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Given an image.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is the estimated.",
                    "label": 0
                },
                {
                    "sent": "He Maps of key points and this is.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The final estimated skeleton.",
                    "label": 0
                },
                {
                    "sent": "So we see that OK seems to be working fine.",
                    "label": 0
                },
                {
                    "sent": "It's generally captured the rough structure and post of the object, but apparently it's not perfect, especially for the estimated sweetie skeleton.",
                    "label": 0
                },
                {
                    "sent": "The estimated their corresponding to the keypoints doesn't really align with the 2D key points of the object in the original image.",
                    "label": 0
                },
                {
                    "sent": "So the.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This could be becausw, as we observed in our experiments, that errors in the first stage that it in the key point estimation stage get propagated into the second stage.",
                    "label": 1
                },
                {
                    "sent": "So is there a problem?",
                    "label": 0
                },
                {
                    "sent": "Is there a solution that we can alleviate this problem?",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Very intuitive thought, would be OK. Let's just try to do end to end training to give an image, let's try to directly supervise it.",
                    "label": 0
                },
                {
                    "sent": "To estimate the object structure imposed.",
                    "label": 0
                },
                {
                    "sent": "However, this is not really possible because we don't want to use the very expensive 3D labels.",
                    "label": 1
                },
                {
                    "sent": "However, Rick.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Or that we do have the 2D keep on labels of the objects in image.",
                    "label": 0
                },
                {
                    "sent": "So is it possible for us to use these two D labels of keypoint locations to refine our estimation of the 3D object structure?",
                    "label": 0
                },
                {
                    "sent": "I turned out to be possible because.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "If we revisit how we get these key points from our 3D structure, we go back to this formula and we see that this is actually fully.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Pressable, so the 3D to 2D projection thing is actually fully differentiable, so we can actually solve this problem by propose a 3D to 2D projection layer, which takes the estimated 3D structure imposed as inputs and try to compute the corresponding coordinates of keypoint locations, and then given we have the ground truth of these keypoint locations, we can use them as a supervision to refine our estimation of the three D3D object.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This will be the third stage of our training.",
                    "label": 0
                },
                {
                    "sent": "That is, we use.",
                    "label": 0
                },
                {
                    "sent": "We propose a 3D to 2D projection layer so that enables end to end training and for this stage will again use our 2D annotated real data.",
                    "label": 0
                },
                {
                    "sent": "The input is in single RGB image and the output is key point coordinates.",
                    "label": 0
                },
                {
                    "sent": "But here instead of just training the 2D key point estimation part, we treat the entire network end to end which includes the 2D point estimation part, the 3D interpreter and the 3D to 2D projection layer.",
                    "label": 1
                },
                {
                    "sent": "So the objective function for this stage will just be to minimize the reprojection error of the two D coordinates.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So our training tire paradigm therefore contains 3 steps.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The first to do the 2D, keep an estimation and 2nd.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is to train the 3D interpreter and the third.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is to find to the entire network network end to end.",
                    "label": 0
                },
                {
                    "sent": "So this framework has also other interpretations.",
                    "label": 0
                },
                {
                    "sent": "For example, we can see we can see this 3D to 2D projection layer as maximizing the likelihood given certain geometric prior.",
                    "label": 0
                },
                {
                    "sent": "But again, although there are other like optimization methods which pose similar formulation where the first to introduce it to your network do end to end, we can also see this the first 2 components like the key points and the 3D interpreter estimator as an analysis or inference step, while the three D2D projection layer.",
                    "label": 0
                },
                {
                    "sent": "It's a very simple graphics engine, so this can be seen as the inverse graphics and re render framework.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "She will now let's look at the refined results again.",
                    "label": 1
                },
                {
                    "sent": "Given image.",
                    "label": 0
                },
                {
                    "sent": "This is our initial estimation and by incorporating this 3D to 2D projection layer and to do N 2 and fine tuning, here is the.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "New results we get.",
                    "label": 0
                },
                {
                    "sent": "We see that we get a much better at estimation of the original structure and pose of the object in the image and the estimated 2D key points actually align with the original key points in the images.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this is actually our second main idea or our second contribution.",
                    "label": 0
                },
                {
                    "sent": "That is, we propose a 3D to 2D projection layer for N2 and training of the entire network.",
                    "label": 1
                },
                {
                    "sent": "So now let's go to a more.",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Thorough evaluation of results.",
                    "label": 0
                },
                {
                    "sent": "We first see some qualitative results, so for all our training we did our training on the our newly proposed key .5 data set, which contains objects of five categories of furniture, and for each category there are roughly 2000 training images available.",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We did our testing on multiple datasets.",
                    "label": 0
                },
                {
                    "sent": "The first is our key .5 datasets.",
                    "label": 0
                },
                {
                    "sent": "So given let's look at this bad, you see we're estimating structure and viewpoint of the bad pretty accurately.",
                    "label": 0
                },
                {
                    "sent": "Especially given this is not an easy image because there is a cultural background and color.",
                    "label": 0
                },
                {
                    "sent": "The background is very similar to the color of the object.",
                    "label": 0
                },
                {
                    "sent": "And we also tested.",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Performance on two other datasets.",
                    "label": 0
                },
                {
                    "sent": "One is the IKEA datasets which proposed by Lim at all in 2013.",
                    "label": 0
                },
                {
                    "sent": "Again, this is a pretty hard case because the swivel chair is occluded by a wide table.",
                    "label": 0
                },
                {
                    "sent": "Again, we can do it pretty well.",
                    "label": 0
                },
                {
                    "sent": "And we.",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Tested on the more General Sun database proposed by Salvador in 2011, so our algorithm works well for the case of a sofa.",
                    "label": 0
                },
                {
                    "sent": "N4K",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is overcrowded chair?",
                    "label": 0
                },
                {
                    "sent": "So here by testing our algorithm on multiple datasets, we also show that our algorithm is not suffering from a data set bias problem.",
                    "label": 0
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So now let's go to a more quantitative evaluation.",
                    "label": 0
                },
                {
                    "sent": "So first for estimating 3D structure, we.",
                    "label": 0
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Did our evaluation on IKEA datasets where we have ground truth CD labels available?",
                    "label": 0
                },
                {
                    "sent": "For this, for this part we compare with the optimization based method proposed by Joe Adult in 2016.",
                    "label": 0
                }
            ]
        },
        "clip_55": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we see that are going to achieve a much better performance than Joe.",
                    "label": 0
                },
                {
                    "sent": "However, we do want to make the point that Becausw Joetta is actually an essentially an optimization method.",
                    "label": 0
                },
                {
                    "sent": "They really require very accurate keypoint locations, and because we know 2D keypoint locations on general images really hard, so arguing performs better because we are more robust to the in accuracies in 2D point estimation.",
                    "label": 0
                },
                {
                    "sent": "And for.",
                    "label": 0
                }
            ]
        },
        "clip_56": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Point estimation again, we did our quantitative study on IKEA day.",
                    "label": 0
                }
            ]
        },
        "clip_57": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Set and for this we compare with the paper from Sue Adult in ICC 2015.",
                    "label": 0
                }
            ]
        },
        "clip_58": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Again, we achieved some much better performance.",
                    "label": 0
                },
                {
                    "sent": "I think this is because Sue at all is method which use almost purely synthetic data for training.",
                    "label": 0
                },
                {
                    "sent": "But our method tried to combine the real annotations of 2D key points on images as well as the 3D synthetic models.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_59": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For a different setting, we want to do localization and beautiful and estimation jointly.",
                    "label": 0
                },
                {
                    "sent": "So given an image you want to.",
                    "label": 0
                }
            ]
        },
        "clip_60": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Detector object and they want to estimate its 3D structure.",
                    "label": 0
                }
            ]
        },
        "clip_61": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Viewpoint so our framework can be used to do this by a combination with some detection framework here.",
                    "label": 0
                }
            ]
        },
        "clip_62": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We choose to use the standard RCN.",
                    "label": 0
                },
                {
                    "sent": "We tested our performance on the.",
                    "label": 0
                }
            ]
        },
        "clip_63": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Scale 3D plus datasets proposed by cellar Door in 2014 and we see that our algorithm achieves comperable performance with the state of the art, which is the viewpoints and key points paper from UC Berkeley.",
                    "label": 0
                },
                {
                    "sent": "And again, we also want to make an additional point that our algorithm is just trained.",
                    "label": 0
                },
                {
                    "sent": "Our key .5 datasets and we didn't really use any labels from the Pascal 3D plus data set.",
                    "label": 1
                },
                {
                    "sent": "This is different from the other competitors.",
                    "label": 0
                },
                {
                    "sent": "So now let's look at another application.",
                    "label": 0
                }
            ]
        },
        "clip_64": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Means and why this algorithm can be useful?",
                    "label": 0
                },
                {
                    "sent": "So first this is a visualization of the test images of cheers.",
                    "label": 0
                },
                {
                    "sent": "According to their info viewpoints.",
                    "label": 0
                },
                {
                    "sent": "So we project all the test images into a 2D plane and we see that the nicely forms are manifold where the orientation of the chair rotates from left to right.",
                    "label": 0
                },
                {
                    "sent": "And as another application, we see that how we can retrieve images by its posts now given as.",
                    "label": 0
                }
            ]
        },
        "clip_65": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "3D object of three of a swivel chair we graduate rotates it.",
                    "label": 0
                },
                {
                    "sent": "We want to retrieve objects of similar posts to the input and see that our algorithm can do pretty well on this.",
                    "label": 0
                },
                {
                    "sent": "So to conclude.",
                    "label": 0
                }
            ]
        },
        "clip_66": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In this problem in this, in this paper we stayed.",
                    "label": 0
                },
                {
                    "sent": "We studied the problem of single image 3D object perception.",
                    "label": 0
                }
            ]
        },
        "clip_67": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We propose 2 main contributions.",
                    "label": 0
                },
                {
                    "sent": "The first one is we propose to use route to the labels as well as synthetic 3D objects.",
                    "label": 1
                },
                {
                    "sent": "Again, we require no CD labels of the real objects in images for training and to do this we propose to use key points.",
                    "label": 0
                },
                {
                    "sent": "Here Maps as our intermediate representation.",
                    "label": 0
                }
            ]
        },
        "clip_68": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And our second contribution, as we propose a 3D to 2D projection layer which enables NQ and training of the network.",
                    "label": 0
                },
                {
                    "sent": "Which also makes it possible for us to refine our 3D estimation using 2D labels only.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                }
            ]
        }
    }
}