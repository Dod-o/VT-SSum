{
    "id": "pdthce2mnqd3r46a46q5diryg76sxprr",
    "title": "Structured Event Entity Resolution in Humanitarian Domains",
    "info": {
        "author": [
            "Mayank Kejriwal, Information Sciences Institute (ISI), University of Southern California"
        ],
        "published": "Nov. 22, 2018",
        "recorded": "October 2018",
        "category": [
            "Top->Computer Science->Semantic Web"
        ]
    },
    "url": "http://videolectures.net/iswc2018_kejriwal_structured_event/",
    "segmentation": [
        [
            "So this is this is work that I did with two of my graduate students Jing and how she, and have since graduated and moved on.",
            "And with Pedro Zach Lee who leads a group and it's also in collaboration with Next Century Corporation which is a company that's based in Washington DC.",
            "And also I want to acknowledge DARPA for funding this research.",
            "So with that, you know, let me."
        ],
        [
            "Jump straight into the problem, so I'm sure I don't need to convince any of you that humanitarian crisis are very real and we seem to be facing more and more of them as time goes on.",
            "These are floods that occurred in South India just a few months ago.",
            "You know we."
        ],
        [
            "Just had a hurricane Michael over here so you know developed countries too.",
            "It's a big problem.",
            "It's claiming lives.",
            "This is an earthquake in Nepal in 2015.",
            "You can see here that the damage is very different.",
            "You know when you have earthquakes versus floods, you know you have the problems are different.",
            "You have to evacuate people and so on.",
            "So the needs are very different.",
            "You know we tend to plug these things into, you know, one phrase which is humanitarian domains but in reality every crisis is very different and so this is something that I hope you'll keep in mind.",
            "As we go through this process."
        ],
        [
            "Station and then as a third example, you know food shortages you know yet another set of problems that occurs with that in Africa we have very experiencing the worst drought in 60 years, 12 million people affected.",
            "This is also humanitarian crises.",
            "It's a natural disaster in its own way, and notice how all three countries that I showed you are developing countries so the damage tends to hit them higher than here.",
            "They just don't have the resources or do not prepare it sometimes.",
            "All these disasters, it affects them very deeply."
        ],
        [
            "And so you know, just to put a cap on it.",
            "the UN actually came up with some numbers in 2017 and what they said was that, according to their estimates, about 130 million people affected by natural disasters, which is 5 times the population of Australia.",
            "So if you take nothing else from this talk, I hope you'll remember this statistic, which is 5 times the population of Australia in 2017 affected by natural disasters.",
            "The amount of money that is needed to actually help these people is about 22 billion.",
            "Guess how much we have?",
            "You know less than half and not only."
        ],
        [
            "Right, but if you see the trend, you know the level of funding seems to be flattening, whereas the requested funds seems to be increasing very sleepy.",
            "So this gap, which is almost $10,000,000, is actually going up and up and up.",
            "So it's a very serious problem."
        ],
        [
            "And you know what we can take away from this is that there's a lot of potential for technology for these kinds of problems.",
            "We can't.",
            "We may not be able to cover the 10 billion dollar gap, but if we can develop technology that helps, then we ought to do."
        ],
        [
            "So.",
            "So let me introduce you to at least one problem you know which the semantic web can help with a lot, and that is event information retrieval, so you know when the all the three examples that I pointed out earlier.",
            "If you think about it, you know there are all kinds of things happening on the ground, so with Nepal for example, which is the easiest case, let's say the earthquake hits.",
            "You know that's an event, you know the epicenter of the earthquake is so and so it's hit over here at this time we can think of that as an event.",
            "Right, it's reported separately.",
            "Usually now after that imagine that building collapses.",
            "People need rescue.",
            "There are refugees outside the airport, and so on and so forth.",
            "All of these are events which are kind of unraveling on the ground, and each one of them potentially requires a response.",
            "And imagine that you're an analyst or yard someone from a humanitarian agency.",
            "You go in and you know you are interested.",
            "Let's say you have 10 tons of food which you're interested in disbursing.",
            "You are given to understand that there might be a crisis of food shortage somewhere.",
            "Maybe an area has been cut off and you want more cases like that.",
            "You have all this information coming in from social media from the web, and what you would really like to do is to understand fully the situation that is unraveling from all your information sources.",
            "It's a very specific kind of retrieval problem, and."
        ],
        [
            "Give you an example of how difficult it can be.",
            "I want to show you this busy slide.",
            "It's a little bit busy, although I've tried to make it as beautiful as possible.",
            "It's even busier when you try to look at the formal representation, but on top you have this event on teologi.",
            "It's just a very small fragment.",
            "It contains a lot more inside event ontology you have what's called a situation frame.",
            "That's a very specific name that DARPA has chosen for it.",
            "Essentially, it's meant to indicate a situation that's what they really mean by an event, and every situation for him, you know, has some kind of string or description has provenance which have not shown here.",
            "Has entities associated with it.",
            "So in the actual event knowledge graph you can see two examples.",
            "This is an example using the earthquake in Turkey in 2011 and you have you know Turkish rescuers hunting for survivors.",
            "On the other hand, you have the Red Cross or the Red Cross and which has become involved.",
            "Both of these are part of the same event, but they look different now.",
            "You might imagine that OK, the date is very similar and the location is very similar, but at the same point in time Turkey was also going through a refugee crisis.",
            "So it's not just it's not easy to see what makes 2 events the same event, or are sequences in one event could be similar.",
            "Entities could be that a text description is similar.",
            "Could be the dates could be the time, so there's a set of clues that sort of determine when two events are part of the same sequence of events, and so figuring this out automatically figuring out when two events are the same event at multiple levels of granularity is a difficult problem, and what we address over here."
        ],
        [
            "A second scenario is clustering, so this happens after the event has happened, usually or if multiple events are happening at the same time, so you know.",
            "Again, building might be collapsing, you may have a crisis here or crisis there.",
            "There may be other crisis happening in other parts of the world for this one what you want to do is cluster documents and this could be agglomerative.",
            "It could be hierarchical, so we have a hierarchical set of clusters at different levels of granularity, but again it's an event information retrieval problem.",
            "You want to figure out when to situation frames in our formal.",
            "Framework refer to the same underlying event and for those of you who are familiar with the entity resolution problem, you know it's also called instance matching record linkage entity resolution that this is a problem we've dealt with time and again in our community and in other communities.",
            "It sort of boils down to figuring out when two situation frames should be linked, but in reality your situation frame is not just an entity and that makes a problem a lot harder."
        ],
        [
            "Now we can still frame it as a machine learning problem, so the idea is you have two situation frames.",
            "They two nodes in the Knowledge Graph at the end of the day you're trying to figure out the same as link between these two ur eyes if you will.",
            "Which are referring to the same city which are referring to two situation frames and you know if we frame it as a machine learning problem, we can sort of think about this as you know you send into situation frames into a classifier and you want to know you know when it refers to the same frame.",
            "You know yes know which probability kind of task.",
            "And then the problem becomes that you know how do we represent this?",
            "What are the features that we extract?",
            "Because what happens is that with entities we have, this problem is well understood.",
            "We know that we have, you know string matching is a very good kind of heuristic feature which is used a lot.",
            "You also have other things like if you have dates, then you know there's deep matching.",
            "If you have locations, you can try to do some kind of entity linking with the fall in the same administrative boundary.",
            "So for entities this problem is kind of well understood.",
            "But we don't really know how to get a good feature representation for the events at missing because they have so much more.",
            "They have common entities.",
            "They have text similarity, they have time, location all kinds of other similarity.",
            "So how do we get a good feature representation?"
        ],
        [
            "Add.",
            "You know, given that we're focusing so much on embeddings, you know one thing that we could focus on is maybe just looking at the text descriptions so we look at the text descriptions and we get a text embedding of each situation.",
            "You know that's the most obvious thing.",
            "The idea is that we embed the text, the description of the situation in some kind of vector space, and hopefully it looks like what you see over here, but it sort of naturally clusters the same situations you know, tend to fall in the same region of the."
        ],
        [
            "Actor space.",
            "Another idea is you know manual features, so this could be capturing some of our intuitions.",
            "For example, we could represent each situation as a bag of words, or as a bag of entities, and then try to compute the similarity between the bags of words between the bags of entities.",
            "We could separately take locations, organizations, person, entities, and to come up with these very manual features.",
            "This is how we used to do it.",
            "You know, before these embeddings became so big and there's still useful.",
            "There's still capture intuitions that maybe the embedding."
        ],
        [
            "Modern.",
            "And then finally we could think about, you know, embedding the Knowledge Graph itself, so you know some of the papers both this year and last year, and even in years before that have dealt with graph embeddings alot.",
            "So the idea is that if you can embed the entire knowledge graph and the details of how we can do this around the paper, but you know the core idea is you take the Knowledge graph and an embed the nodes in the knowledge Graph into a vector space."
        ],
        [
            "Three very different ways of looking at these are looking at features and in our system.",
            "What we do is that we try to combine all of them are intuition is that all of them are useful and what we do is that given a pair of documents, a pair of situations, we get the graph embedding.",
            "We get the text embedding and then the man will need to find features, work on pairs of events you know.",
            "Unlike the embeddings and so you know two situations going and we get a single vector for the manually defined features and then we concatenate all of them.",
            "And then you send it into your favorite machine learning classifier clustering, which you know hopefully gives you some kind of answer on whether the same event or not the same man that.",
            "So far it sounds very simple, but the main idea, you know, uh, the main question here is that with this really work, because we're trying to combine, you know, two different kinds of embeddings.",
            "Grind in dependently graph interacts with trying to combine manual features and it's completely unknown at this point whether we can actually do that.",
            "But you can combine such feature spaces.",
            "And what works?",
            "What doesn't work?",
            "How much training data do you need so that those are some of the experimental questions that we actually did in the paper?",
            "More than 35% of the papers actually given to experiments on all kinds of different disasters and key."
        ],
        [
            "I just want to show you a snapshot of some of the important results, but we have more than four or five different experiments that's in the paper and I do encourage you to read that if you're more interested."
        ],
        [
            "So for our evaluations, we can do it.",
            "We gather data from the relief web portal.",
            "This is actually a website and we scraped data with our partners from this.",
            "As you can see, we try to look at many different disasters and disaster types.",
            "So here you see floods, earthquakes, cyclones, all of them are represented and if you look at the very last column, the number of clusters is the number of unique events and we have 74 class in the first 174 different instances of floods in different parts of the world.",
            "Different instances of earthquakes.",
            "Miscellaneous is you can think of it as a long tail.",
            "This is things like refugee crises, some other kind of disaster which is not represented in the first four, and so on.",
            "So we really try to be very rigorous and say something very general about this."
        ],
        [
            "Stone.",
            "And our main experimental questions are only concerned with, you know if we try to combine these three.",
            "If we look at it individually, what happens if we try pairwise combinations?",
            "So maybe not embedding and text embedding or node embedding and manual features.",
            "What really happens?",
            "Does it work?",
            "What does it tell us about such kind of systems?"
        ],
        [
            "So the first experiment was to really measure the effects of feature augmentation.",
            "You know which features work well together and which features Don."
        ],
        [
            "And what we find so here, MMD, you know, just we just going back to the previous slide.",
            "M is, you know, manually crafted features an is node, embeddings and TS text embedding.",
            "What we find is that augmentation does help.",
            "So when you look at M&T, you actually get the highest results in most of the cases.",
            "In fact, you get good results with just 15% training data.",
            "And if you use random forest classifier, then it keeps on improving.",
            "But even with small amounts of training data we still get pretty good results.",
            "Notice that if you just use manual features, if you just use node embeddings, not as good, manual features are no dividing seemed to be synergistic and we also tried text in isolation and it worked really badly.",
            "So that was kind of our first proof.",
            "We also tried LDA, standard text, text embedding, etc.",
            "We found that you know text does not actually work well in this situation.",
            "If you think back to the Turkish example, the earthquake and the Red Cross arrival there was very little text similarity between them, so lots of false positive."
        ],
        [
            "Screen pen so I can experiment was can we transfer train classifiers?",
            "This is important because when the disaster strikes you want to start getting you want to set up an information retrieval system within 24 hours if possible to have maximum impact.",
            "So you don't want to wait forever before you test.",
            "And so in this one."
        ],
        [
            "What we did was that we used that say earthquakes for training and then we tested on everything else.",
            "So floods, you know all the rest of them.",
            "So we completely changed not only the disaster where disaster type and of course this is Christian.",
            "Recall F measure we find out, you know results are obviously much worse than if you try to train on earthquakes and test on a different side of earthquakes.",
            "But it's still very guard in the sense that the manual features and the node events together do quite well.",
            "We find over here.",
            "In fact there augmentation doesn't help if you actually include.",
            "Jacks then it holds the results, so it's not always the case that adding more or having text is always useful, so this was the first evidence of that."
        ],
        [
            "And then finally I want to show you some visualizations that show that our knowledge graph embeddings actually do a lot better than text embeddings.",
            "They add a lot of value."
        ],
        [
            "For we show you over floods in earthquakes in the people you have for all five categories, but you can see on the right hand side the text seems to be all over the place.",
            "On the left hand side you do see some clusters forming.",
            "We reused colors for the disasters for different disasters, but you can kind of see that especially for earthquakes and landslides you actually get really good clusters in a completely unsupervised way.",
            "So graph embeddings done right can be."
        ],
        [
            "Very helpful.",
            "And this is for the entire corpus, so earthquakes flags every disaster more than more than 506 hundred disasters combined globally, embedded and visualized.",
            "Again, we reuse colors, but you can kind of see that graph embeddings do really well on this problem, and this is due to the way we construct the graph.",
            "The situation frames the entities, the connections between the entities, so you can't just model it as any graph.",
            "You have to model it a certain way to get right on."
        ],
        [
            "So.",
            "Now in the last one to two minutes that we have left, I want to show you some of the impacts that we've had."
        ],
        [
            "So the DARPA program, which finds this, is actually not interested in English or in major languages like the one spoken in Europe, they're actually interested in low resource languages.",
            "They want to build these systems for languages for which we don't have an LP tools of the shelf.",
            "We don't have Google Translate for many of these languages because these are the most vulnerable populations.",
            "These are the ones that tend to be ignored.",
            "They communicate via SMS, for example, on the ground.",
            "They usually don't even do social media.",
            "I'm."
        ],
        [
            "The system into which we embedded our retrieval system is called hard text enabled humanitarian operations.",
            "In real time.",
            "It uses a lot of different things.",
            "Entity Resolution, network analysis, route planning and all of."
        ],
        [
            "Eventually shows up on agree, so in this case we actually have something up and running for eager.",
            "Eager is a language spoken in northern China.",
            "You can kind of see it on the map over there.",
            "There's some dense clusters and at the time this was done there was no translation available for this.",
            "We worked with a lot of NLP groups to set up translation systems very quickly.",
            "We're an event resolution on that and on the right hand side it's not very visible, but you can kind of see you know it, sort of already identifies medical shelter, food.",
            "And then it sort of tells you where you know the different needs.",
            "Are there is some noise in the system, but overall it gives you a lot of intelligence into what you need to do and where you need to go, and then just some."
        ],
        [
            "Other examples, this was my nipple again, you can see that noise, especially location linking, so all those other places don't really.",
            "It turns out a noisy but you have this big dense cluster in the middle which really helps you to zone in on that and work with the noise."
        ],
        [
            "Then then finally, Central African Republic."
        ],
        [
            "Anne."
        ],
        [
            "And you know, just I want to end by just thanking all our partners.",
            "So especially with respect to the GUI, it's been featured in Darpa's 60th anniversary.",
            "We have also done live action exercise in Macedonia.",
            "We've demo'd this too.",
            "And, uh, an army organization in Nepal.",
            "So we are rolling the system out.",
            "They'll be a lot more transitions next year.",
            "This project will last at least another one year and I want to thank all our partners who have been setting up the machine translation system that have been collaborating with us on the on.",
            "Getting the data into the grey.",
            "And with that, I'll conclude and open for questions."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is this is work that I did with two of my graduate students Jing and how she, and have since graduated and moved on.",
                    "label": 0
                },
                {
                    "sent": "And with Pedro Zach Lee who leads a group and it's also in collaboration with Next Century Corporation which is a company that's based in Washington DC.",
                    "label": 0
                },
                {
                    "sent": "And also I want to acknowledge DARPA for funding this research.",
                    "label": 0
                },
                {
                    "sent": "So with that, you know, let me.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Jump straight into the problem, so I'm sure I don't need to convince any of you that humanitarian crisis are very real and we seem to be facing more and more of them as time goes on.",
                    "label": 0
                },
                {
                    "sent": "These are floods that occurred in South India just a few months ago.",
                    "label": 0
                },
                {
                    "sent": "You know we.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Just had a hurricane Michael over here so you know developed countries too.",
                    "label": 0
                },
                {
                    "sent": "It's a big problem.",
                    "label": 0
                },
                {
                    "sent": "It's claiming lives.",
                    "label": 0
                },
                {
                    "sent": "This is an earthquake in Nepal in 2015.",
                    "label": 0
                },
                {
                    "sent": "You can see here that the damage is very different.",
                    "label": 0
                },
                {
                    "sent": "You know when you have earthquakes versus floods, you know you have the problems are different.",
                    "label": 0
                },
                {
                    "sent": "You have to evacuate people and so on.",
                    "label": 0
                },
                {
                    "sent": "So the needs are very different.",
                    "label": 0
                },
                {
                    "sent": "You know we tend to plug these things into, you know, one phrase which is humanitarian domains but in reality every crisis is very different and so this is something that I hope you'll keep in mind.",
                    "label": 0
                },
                {
                    "sent": "As we go through this process.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Station and then as a third example, you know food shortages you know yet another set of problems that occurs with that in Africa we have very experiencing the worst drought in 60 years, 12 million people affected.",
                    "label": 0
                },
                {
                    "sent": "This is also humanitarian crises.",
                    "label": 0
                },
                {
                    "sent": "It's a natural disaster in its own way, and notice how all three countries that I showed you are developing countries so the damage tends to hit them higher than here.",
                    "label": 0
                },
                {
                    "sent": "They just don't have the resources or do not prepare it sometimes.",
                    "label": 0
                },
                {
                    "sent": "All these disasters, it affects them very deeply.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And so you know, just to put a cap on it.",
                    "label": 0
                },
                {
                    "sent": "the UN actually came up with some numbers in 2017 and what they said was that, according to their estimates, about 130 million people affected by natural disasters, which is 5 times the population of Australia.",
                    "label": 0
                },
                {
                    "sent": "So if you take nothing else from this talk, I hope you'll remember this statistic, which is 5 times the population of Australia in 2017 affected by natural disasters.",
                    "label": 0
                },
                {
                    "sent": "The amount of money that is needed to actually help these people is about 22 billion.",
                    "label": 0
                },
                {
                    "sent": "Guess how much we have?",
                    "label": 0
                },
                {
                    "sent": "You know less than half and not only.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Right, but if you see the trend, you know the level of funding seems to be flattening, whereas the requested funds seems to be increasing very sleepy.",
                    "label": 0
                },
                {
                    "sent": "So this gap, which is almost $10,000,000, is actually going up and up and up.",
                    "label": 0
                },
                {
                    "sent": "So it's a very serious problem.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And you know what we can take away from this is that there's a lot of potential for technology for these kinds of problems.",
                    "label": 0
                },
                {
                    "sent": "We can't.",
                    "label": 0
                },
                {
                    "sent": "We may not be able to cover the 10 billion dollar gap, but if we can develop technology that helps, then we ought to do.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "So let me introduce you to at least one problem you know which the semantic web can help with a lot, and that is event information retrieval, so you know when the all the three examples that I pointed out earlier.",
                    "label": 1
                },
                {
                    "sent": "If you think about it, you know there are all kinds of things happening on the ground, so with Nepal for example, which is the easiest case, let's say the earthquake hits.",
                    "label": 0
                },
                {
                    "sent": "You know that's an event, you know the epicenter of the earthquake is so and so it's hit over here at this time we can think of that as an event.",
                    "label": 0
                },
                {
                    "sent": "Right, it's reported separately.",
                    "label": 0
                },
                {
                    "sent": "Usually now after that imagine that building collapses.",
                    "label": 0
                },
                {
                    "sent": "People need rescue.",
                    "label": 0
                },
                {
                    "sent": "There are refugees outside the airport, and so on and so forth.",
                    "label": 0
                },
                {
                    "sent": "All of these are events which are kind of unraveling on the ground, and each one of them potentially requires a response.",
                    "label": 0
                },
                {
                    "sent": "And imagine that you're an analyst or yard someone from a humanitarian agency.",
                    "label": 0
                },
                {
                    "sent": "You go in and you know you are interested.",
                    "label": 0
                },
                {
                    "sent": "Let's say you have 10 tons of food which you're interested in disbursing.",
                    "label": 0
                },
                {
                    "sent": "You are given to understand that there might be a crisis of food shortage somewhere.",
                    "label": 0
                },
                {
                    "sent": "Maybe an area has been cut off and you want more cases like that.",
                    "label": 0
                },
                {
                    "sent": "You have all this information coming in from social media from the web, and what you would really like to do is to understand fully the situation that is unraveling from all your information sources.",
                    "label": 0
                },
                {
                    "sent": "It's a very specific kind of retrieval problem, and.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Give you an example of how difficult it can be.",
                    "label": 0
                },
                {
                    "sent": "I want to show you this busy slide.",
                    "label": 0
                },
                {
                    "sent": "It's a little bit busy, although I've tried to make it as beautiful as possible.",
                    "label": 0
                },
                {
                    "sent": "It's even busier when you try to look at the formal representation, but on top you have this event on teologi.",
                    "label": 0
                },
                {
                    "sent": "It's just a very small fragment.",
                    "label": 0
                },
                {
                    "sent": "It contains a lot more inside event ontology you have what's called a situation frame.",
                    "label": 0
                },
                {
                    "sent": "That's a very specific name that DARPA has chosen for it.",
                    "label": 0
                },
                {
                    "sent": "Essentially, it's meant to indicate a situation that's what they really mean by an event, and every situation for him, you know, has some kind of string or description has provenance which have not shown here.",
                    "label": 0
                },
                {
                    "sent": "Has entities associated with it.",
                    "label": 0
                },
                {
                    "sent": "So in the actual event knowledge graph you can see two examples.",
                    "label": 0
                },
                {
                    "sent": "This is an example using the earthquake in Turkey in 2011 and you have you know Turkish rescuers hunting for survivors.",
                    "label": 0
                },
                {
                    "sent": "On the other hand, you have the Red Cross or the Red Cross and which has become involved.",
                    "label": 0
                },
                {
                    "sent": "Both of these are part of the same event, but they look different now.",
                    "label": 0
                },
                {
                    "sent": "You might imagine that OK, the date is very similar and the location is very similar, but at the same point in time Turkey was also going through a refugee crisis.",
                    "label": 0
                },
                {
                    "sent": "So it's not just it's not easy to see what makes 2 events the same event, or are sequences in one event could be similar.",
                    "label": 0
                },
                {
                    "sent": "Entities could be that a text description is similar.",
                    "label": 0
                },
                {
                    "sent": "Could be the dates could be the time, so there's a set of clues that sort of determine when two events are part of the same sequence of events, and so figuring this out automatically figuring out when two events are the same event at multiple levels of granularity is a difficult problem, and what we address over here.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "A second scenario is clustering, so this happens after the event has happened, usually or if multiple events are happening at the same time, so you know.",
                    "label": 0
                },
                {
                    "sent": "Again, building might be collapsing, you may have a crisis here or crisis there.",
                    "label": 0
                },
                {
                    "sent": "There may be other crisis happening in other parts of the world for this one what you want to do is cluster documents and this could be agglomerative.",
                    "label": 0
                },
                {
                    "sent": "It could be hierarchical, so we have a hierarchical set of clusters at different levels of granularity, but again it's an event information retrieval problem.",
                    "label": 1
                },
                {
                    "sent": "You want to figure out when to situation frames in our formal.",
                    "label": 0
                },
                {
                    "sent": "Framework refer to the same underlying event and for those of you who are familiar with the entity resolution problem, you know it's also called instance matching record linkage entity resolution that this is a problem we've dealt with time and again in our community and in other communities.",
                    "label": 0
                },
                {
                    "sent": "It sort of boils down to figuring out when two situation frames should be linked, but in reality your situation frame is not just an entity and that makes a problem a lot harder.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now we can still frame it as a machine learning problem, so the idea is you have two situation frames.",
                    "label": 0
                },
                {
                    "sent": "They two nodes in the Knowledge Graph at the end of the day you're trying to figure out the same as link between these two ur eyes if you will.",
                    "label": 0
                },
                {
                    "sent": "Which are referring to the same city which are referring to two situation frames and you know if we frame it as a machine learning problem, we can sort of think about this as you know you send into situation frames into a classifier and you want to know you know when it refers to the same frame.",
                    "label": 0
                },
                {
                    "sent": "You know yes know which probability kind of task.",
                    "label": 0
                },
                {
                    "sent": "And then the problem becomes that you know how do we represent this?",
                    "label": 0
                },
                {
                    "sent": "What are the features that we extract?",
                    "label": 0
                },
                {
                    "sent": "Because what happens is that with entities we have, this problem is well understood.",
                    "label": 0
                },
                {
                    "sent": "We know that we have, you know string matching is a very good kind of heuristic feature which is used a lot.",
                    "label": 0
                },
                {
                    "sent": "You also have other things like if you have dates, then you know there's deep matching.",
                    "label": 0
                },
                {
                    "sent": "If you have locations, you can try to do some kind of entity linking with the fall in the same administrative boundary.",
                    "label": 0
                },
                {
                    "sent": "So for entities this problem is kind of well understood.",
                    "label": 0
                },
                {
                    "sent": "But we don't really know how to get a good feature representation for the events at missing because they have so much more.",
                    "label": 0
                },
                {
                    "sent": "They have common entities.",
                    "label": 0
                },
                {
                    "sent": "They have text similarity, they have time, location all kinds of other similarity.",
                    "label": 0
                },
                {
                    "sent": "So how do we get a good feature representation?",
                    "label": 1
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Add.",
                    "label": 0
                },
                {
                    "sent": "You know, given that we're focusing so much on embeddings, you know one thing that we could focus on is maybe just looking at the text descriptions so we look at the text descriptions and we get a text embedding of each situation.",
                    "label": 0
                },
                {
                    "sent": "You know that's the most obvious thing.",
                    "label": 0
                },
                {
                    "sent": "The idea is that we embed the text, the description of the situation in some kind of vector space, and hopefully it looks like what you see over here, but it sort of naturally clusters the same situations you know, tend to fall in the same region of the.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Actor space.",
                    "label": 0
                },
                {
                    "sent": "Another idea is you know manual features, so this could be capturing some of our intuitions.",
                    "label": 0
                },
                {
                    "sent": "For example, we could represent each situation as a bag of words, or as a bag of entities, and then try to compute the similarity between the bags of words between the bags of entities.",
                    "label": 0
                },
                {
                    "sent": "We could separately take locations, organizations, person, entities, and to come up with these very manual features.",
                    "label": 0
                },
                {
                    "sent": "This is how we used to do it.",
                    "label": 0
                },
                {
                    "sent": "You know, before these embeddings became so big and there's still useful.",
                    "label": 0
                },
                {
                    "sent": "There's still capture intuitions that maybe the embedding.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Modern.",
                    "label": 0
                },
                {
                    "sent": "And then finally we could think about, you know, embedding the Knowledge Graph itself, so you know some of the papers both this year and last year, and even in years before that have dealt with graph embeddings alot.",
                    "label": 0
                },
                {
                    "sent": "So the idea is that if you can embed the entire knowledge graph and the details of how we can do this around the paper, but you know the core idea is you take the Knowledge graph and an embed the nodes in the knowledge Graph into a vector space.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Three very different ways of looking at these are looking at features and in our system.",
                    "label": 0
                },
                {
                    "sent": "What we do is that we try to combine all of them are intuition is that all of them are useful and what we do is that given a pair of documents, a pair of situations, we get the graph embedding.",
                    "label": 0
                },
                {
                    "sent": "We get the text embedding and then the man will need to find features, work on pairs of events you know.",
                    "label": 0
                },
                {
                    "sent": "Unlike the embeddings and so you know two situations going and we get a single vector for the manually defined features and then we concatenate all of them.",
                    "label": 1
                },
                {
                    "sent": "And then you send it into your favorite machine learning classifier clustering, which you know hopefully gives you some kind of answer on whether the same event or not the same man that.",
                    "label": 0
                },
                {
                    "sent": "So far it sounds very simple, but the main idea, you know, uh, the main question here is that with this really work, because we're trying to combine, you know, two different kinds of embeddings.",
                    "label": 0
                },
                {
                    "sent": "Grind in dependently graph interacts with trying to combine manual features and it's completely unknown at this point whether we can actually do that.",
                    "label": 0
                },
                {
                    "sent": "But you can combine such feature spaces.",
                    "label": 0
                },
                {
                    "sent": "And what works?",
                    "label": 0
                },
                {
                    "sent": "What doesn't work?",
                    "label": 0
                },
                {
                    "sent": "How much training data do you need so that those are some of the experimental questions that we actually did in the paper?",
                    "label": 0
                },
                {
                    "sent": "More than 35% of the papers actually given to experiments on all kinds of different disasters and key.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I just want to show you a snapshot of some of the important results, but we have more than four or five different experiments that's in the paper and I do encourage you to read that if you're more interested.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So for our evaluations, we can do it.",
                    "label": 0
                },
                {
                    "sent": "We gather data from the relief web portal.",
                    "label": 0
                },
                {
                    "sent": "This is actually a website and we scraped data with our partners from this.",
                    "label": 0
                },
                {
                    "sent": "As you can see, we try to look at many different disasters and disaster types.",
                    "label": 0
                },
                {
                    "sent": "So here you see floods, earthquakes, cyclones, all of them are represented and if you look at the very last column, the number of clusters is the number of unique events and we have 74 class in the first 174 different instances of floods in different parts of the world.",
                    "label": 0
                },
                {
                    "sent": "Different instances of earthquakes.",
                    "label": 0
                },
                {
                    "sent": "Miscellaneous is you can think of it as a long tail.",
                    "label": 0
                },
                {
                    "sent": "This is things like refugee crises, some other kind of disaster which is not represented in the first four, and so on.",
                    "label": 0
                },
                {
                    "sent": "So we really try to be very rigorous and say something very general about this.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Stone.",
                    "label": 0
                },
                {
                    "sent": "And our main experimental questions are only concerned with, you know if we try to combine these three.",
                    "label": 0
                },
                {
                    "sent": "If we look at it individually, what happens if we try pairwise combinations?",
                    "label": 0
                },
                {
                    "sent": "So maybe not embedding and text embedding or node embedding and manual features.",
                    "label": 0
                },
                {
                    "sent": "What really happens?",
                    "label": 0
                },
                {
                    "sent": "Does it work?",
                    "label": 0
                },
                {
                    "sent": "What does it tell us about such kind of systems?",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the first experiment was to really measure the effects of feature augmentation.",
                    "label": 0
                },
                {
                    "sent": "You know which features work well together and which features Don.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And what we find so here, MMD, you know, just we just going back to the previous slide.",
                    "label": 0
                },
                {
                    "sent": "M is, you know, manually crafted features an is node, embeddings and TS text embedding.",
                    "label": 0
                },
                {
                    "sent": "What we find is that augmentation does help.",
                    "label": 0
                },
                {
                    "sent": "So when you look at M&T, you actually get the highest results in most of the cases.",
                    "label": 0
                },
                {
                    "sent": "In fact, you get good results with just 15% training data.",
                    "label": 1
                },
                {
                    "sent": "And if you use random forest classifier, then it keeps on improving.",
                    "label": 0
                },
                {
                    "sent": "But even with small amounts of training data we still get pretty good results.",
                    "label": 0
                },
                {
                    "sent": "Notice that if you just use manual features, if you just use node embeddings, not as good, manual features are no dividing seemed to be synergistic and we also tried text in isolation and it worked really badly.",
                    "label": 0
                },
                {
                    "sent": "So that was kind of our first proof.",
                    "label": 0
                },
                {
                    "sent": "We also tried LDA, standard text, text embedding, etc.",
                    "label": 0
                },
                {
                    "sent": "We found that you know text does not actually work well in this situation.",
                    "label": 0
                },
                {
                    "sent": "If you think back to the Turkish example, the earthquake and the Red Cross arrival there was very little text similarity between them, so lots of false positive.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Screen pen so I can experiment was can we transfer train classifiers?",
                    "label": 1
                },
                {
                    "sent": "This is important because when the disaster strikes you want to start getting you want to set up an information retrieval system within 24 hours if possible to have maximum impact.",
                    "label": 0
                },
                {
                    "sent": "So you don't want to wait forever before you test.",
                    "label": 0
                },
                {
                    "sent": "And so in this one.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "What we did was that we used that say earthquakes for training and then we tested on everything else.",
                    "label": 0
                },
                {
                    "sent": "So floods, you know all the rest of them.",
                    "label": 0
                },
                {
                    "sent": "So we completely changed not only the disaster where disaster type and of course this is Christian.",
                    "label": 0
                },
                {
                    "sent": "Recall F measure we find out, you know results are obviously much worse than if you try to train on earthquakes and test on a different side of earthquakes.",
                    "label": 0
                },
                {
                    "sent": "But it's still very guard in the sense that the manual features and the node events together do quite well.",
                    "label": 0
                },
                {
                    "sent": "We find over here.",
                    "label": 0
                },
                {
                    "sent": "In fact there augmentation doesn't help if you actually include.",
                    "label": 0
                },
                {
                    "sent": "Jacks then it holds the results, so it's not always the case that adding more or having text is always useful, so this was the first evidence of that.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then finally I want to show you some visualizations that show that our knowledge graph embeddings actually do a lot better than text embeddings.",
                    "label": 0
                },
                {
                    "sent": "They add a lot of value.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For we show you over floods in earthquakes in the people you have for all five categories, but you can see on the right hand side the text seems to be all over the place.",
                    "label": 0
                },
                {
                    "sent": "On the left hand side you do see some clusters forming.",
                    "label": 0
                },
                {
                    "sent": "We reused colors for the disasters for different disasters, but you can kind of see that especially for earthquakes and landslides you actually get really good clusters in a completely unsupervised way.",
                    "label": 0
                },
                {
                    "sent": "So graph embeddings done right can be.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Very helpful.",
                    "label": 0
                },
                {
                    "sent": "And this is for the entire corpus, so earthquakes flags every disaster more than more than 506 hundred disasters combined globally, embedded and visualized.",
                    "label": 0
                },
                {
                    "sent": "Again, we reuse colors, but you can kind of see that graph embeddings do really well on this problem, and this is due to the way we construct the graph.",
                    "label": 0
                },
                {
                    "sent": "The situation frames the entities, the connections between the entities, so you can't just model it as any graph.",
                    "label": 0
                },
                {
                    "sent": "You have to model it a certain way to get right on.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Now in the last one to two minutes that we have left, I want to show you some of the impacts that we've had.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the DARPA program, which finds this, is actually not interested in English or in major languages like the one spoken in Europe, they're actually interested in low resource languages.",
                    "label": 0
                },
                {
                    "sent": "They want to build these systems for languages for which we don't have an LP tools of the shelf.",
                    "label": 0
                },
                {
                    "sent": "We don't have Google Translate for many of these languages because these are the most vulnerable populations.",
                    "label": 0
                },
                {
                    "sent": "These are the ones that tend to be ignored.",
                    "label": 0
                },
                {
                    "sent": "They communicate via SMS, for example, on the ground.",
                    "label": 0
                },
                {
                    "sent": "They usually don't even do social media.",
                    "label": 0
                },
                {
                    "sent": "I'm.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The system into which we embedded our retrieval system is called hard text enabled humanitarian operations.",
                    "label": 1
                },
                {
                    "sent": "In real time.",
                    "label": 0
                },
                {
                    "sent": "It uses a lot of different things.",
                    "label": 0
                },
                {
                    "sent": "Entity Resolution, network analysis, route planning and all of.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Eventually shows up on agree, so in this case we actually have something up and running for eager.",
                    "label": 0
                },
                {
                    "sent": "Eager is a language spoken in northern China.",
                    "label": 0
                },
                {
                    "sent": "You can kind of see it on the map over there.",
                    "label": 0
                },
                {
                    "sent": "There's some dense clusters and at the time this was done there was no translation available for this.",
                    "label": 0
                },
                {
                    "sent": "We worked with a lot of NLP groups to set up translation systems very quickly.",
                    "label": 0
                },
                {
                    "sent": "We're an event resolution on that and on the right hand side it's not very visible, but you can kind of see you know it, sort of already identifies medical shelter, food.",
                    "label": 0
                },
                {
                    "sent": "And then it sort of tells you where you know the different needs.",
                    "label": 0
                },
                {
                    "sent": "Are there is some noise in the system, but overall it gives you a lot of intelligence into what you need to do and where you need to go, and then just some.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Other examples, this was my nipple again, you can see that noise, especially location linking, so all those other places don't really.",
                    "label": 0
                },
                {
                    "sent": "It turns out a noisy but you have this big dense cluster in the middle which really helps you to zone in on that and work with the noise.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Then then finally, Central African Republic.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Anne.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And you know, just I want to end by just thanking all our partners.",
                    "label": 0
                },
                {
                    "sent": "So especially with respect to the GUI, it's been featured in Darpa's 60th anniversary.",
                    "label": 0
                },
                {
                    "sent": "We have also done live action exercise in Macedonia.",
                    "label": 0
                },
                {
                    "sent": "We've demo'd this too.",
                    "label": 0
                },
                {
                    "sent": "And, uh, an army organization in Nepal.",
                    "label": 0
                },
                {
                    "sent": "So we are rolling the system out.",
                    "label": 0
                },
                {
                    "sent": "They'll be a lot more transitions next year.",
                    "label": 0
                },
                {
                    "sent": "This project will last at least another one year and I want to thank all our partners who have been setting up the machine translation system that have been collaborating with us on the on.",
                    "label": 0
                },
                {
                    "sent": "Getting the data into the grey.",
                    "label": 0
                },
                {
                    "sent": "And with that, I'll conclude and open for questions.",
                    "label": 0
                }
            ]
        }
    }
}