{
    "id": "7tqddfkmffxsqacqdyikgwwgfedu742f",
    "title": "SPLODGE: Systematic Generation of SPARQL Benchmark Queries for Linked Open Data",
    "info": {
        "author": [
            "Olaf G\u00f6rlitz, Institute for Web Science and Technologies (WeST), University of Koblenz-Landau"
        ],
        "published": "Dec. 3, 2012",
        "recorded": "November 2012",
        "category": [
            "Top->Computer Science->Semantic Web->SPARQL",
            "Top->Computer Science->Semantic Web->Linked Data"
        ]
    },
    "url": "http://videolectures.net/iswc2012_goerlitz_splodge/",
    "segmentation": [
        [
            "Hello everybody, my name is Olaf girl.",
            "It's from the University of Koblenz.",
            "I'm going to talk about Splodge and the systematic generation of sparkle benchmark queries for linked open data."
        ],
        [
            "So well.",
            "Link data Federation.",
            "What's that we want to do?",
            "Is Parker queries on top of the link data cloud, so of course I also included this picture here to show the complexity of this task."
        ],
        [
            "We have a problem here which is quite like the hen and egg problem becausw while we need distributed queries to be executed on such a big data cloud and to be used in Federation implementations.",
            "But actually they're not many useful queries out there in the wild, and so because we are also not having good Federation implementations, we cannot generate more queries we could use here because it's hard to get data.",
            "Known from this cloud and know what's actually in there?",
            "Which vocabulary is used for this useful there?",
            "So the problem is, I've also experienced this when implementing configuration implementation.",
            "How to test it?",
            "How to benchmark it, and so on because I don't have the queries and there's actually not much benchmarks out there.",
            "But"
        ],
        [
            "But it would be nice to have some sort of benchmark queries here.",
            "We could actually use for testing these systems.",
            "And as he should know, there's the Lehigh University benchmark.",
            "The building sparkle benchmark, espido benchmark.",
            "These are synthetic benchmarks.",
            "They have a specific domain with highly structured data, or have data generators you can scale up, and there are quite some sophisticated queries in there.",
            "But actually because they are centralized, they are not suitable for Federation scenario.",
            "You cannot just partition the data and apply it there.",
            "Well, since last year there's the Fed bench benchmark.",
            "It was specially designed for evaluating Federation implementations.",
            "You have pending datasets in there roughly 170 million triples, 25 henti queries which should be suitable to test these datasets.",
            "Well, I would say it's a bit to fix the link data cloud is much larger and you want to have a testbed where you can actually benchmark sort of in the scale of the holding data cloud.",
            "So there was some motivation to say, OK, we were.",
            "We would really like to have a scalable, flexible and also expressive link data benchmark here, because this is not enough."
        ],
        [
            "So the outline now is that I'm going to present the benchmark idea.",
            "We had the methodology we applied and then also show you some evaluation results."
        ],
        [
            "Having said that, so the main features we would like to have a scalability flexibility of the benchmark and also expressiveness that means we want to use real link datasets.",
            "Any real link datasets?",
            "And customize them in a benchmark scenario that really allows us to do scalable testing or Federation implementations.",
            "And of course the queries should be including typical queries and complex queries and so forth.",
            "Taking all that together should be provided by Splodge.",
            "If you're wondering about the name, but that means."
        ],
        [
            "That's the Semantic Sparkle benchmark for generator for linked open data.",
            "Well."
        ],
        [
            "The letters join in a different way."
        ],
        [
            "Um?",
            "So what do we want for such a benchmark?",
            "We want to define certain query characteristics, characteristics we want to cover.",
            "We want to have automatic query generation for any kind of datasets and then also we need some sort of validation that the queries we generated a sort of useful for the benchmark.",
            "Which means the first point is well, to define query characteristics.",
            "We can customize the benchmark.",
            "When we do the automatic regeneration, we can generate random queries.",
            "Any type of random queries across the datasets.",
            "And the validation should ensure that the queries we generated actually returned results that we wanted to do them actually also happens because just random queries do not give us any results in the link data cloud."
        ],
        [
            "OK.",
            "This is just a big big picture we have in mind here for the methodology and the tool set you have the link data cloud you put in some configuration and then the magic happens and you get benchmark queries out of this.",
            "We did divide this in three parts.",
            "That's parameterization of the queries.",
            "Then the generation and finally the query validation."
        ],
        [
            "OK, now let's have a look at our methodology."
        ],
        [
            "These are the three parts I just mentioned.",
            "We start with the first part.",
            "We want to define typical and challenging distributed queries that we can use as benchmark queries.",
            "Well, there are no Federated query locks available.",
            "Well, there queer locks for DB pedia, some other datasets.",
            "It's quite nice, but we cannot derive anything from these query logs we could use for the Federation scenario.",
            "We could derive some information, but not.",
            "To talk with the distributed nature, here we have in mind so anyway.",
            "We analyzed this query logs and also of the Fed Bench benchmark to get a feeling of what is actually necessary to have a benchmark on Federated datasets.",
            "Just to give you an impression, this is one of the queries used in the Fed bench benchmark, and it's about some life science theater.",
            "You query something from drug bang, KB, cake and so on, and you have certain relations in there between the data.",
            "You're the resources you are asking for.",
            "So we had to look at this.",
            "And."
        ],
        [
            "Then we tried to figure out what is important for benchmark here.",
            "So first there's the algebra of your queries.",
            "You would like to evaluate so.",
            "Well, you have certain crew from select for his concert freeze join types which may increase the complexity.",
            "Conjunctive joins the chunk of joins, left joins and then result modifications, and I will not just iterate over everything sparkled.",
            "1 one is also much more things you could do here.",
            "Then what is important for us is the structure of the queries you have certain variable patterns in the triple patterns you have in sparkle queries.",
            "These are joined in different ways.",
            "You have star joins, parts, joints and also combinations thereof and but you might also encounter across products in queries.",
            "And then third thing is, well, we want to ensure certain cardinality aspects.",
            "So we want to ensure that we cover certain amount of data sources.",
            "We want to ensure that the query has certain complexity in the number of joins or triple patterns that are included and we want to ensure that a certain number of results can be returned by the queries."
        ],
        [
            "But I would like to focus now on our main query parameter, which is this joint structure.",
            "So we have to look at the fetch bench fears actually, and which you can see.",
            "Is there certain structures in the queries so the nodes are just subjects objects and the errors are the predicate connecting the variables in the queries.",
            "So you can see.",
            "They are POS joints in there and they also start joints in their combinations thereof, and variables are bound in certain ways and so on.",
            "But this structure is quite interesting because we want to have something like this in a benchmark really to cover these certain aspects of how the data is connected because.",
            "In this structure, different triple patterns which you have here can be matched to different data sources.",
            "Because in a Federation benchmark you want to retrieve the different results from different data sources matching across the data source boundaries."
        ],
        [
            "OK, the different parameters are then the number of triple patterns, number of data sources, result size and so on.",
            "So what we define as a query is parameterized in our scenario by the number of triple patterns in the number of sources that this query should spend for such a pass drawing.",
            "Then we also include the description of Star joins, which means while there's a resource which is described but different attributes, and we also define some sort of anchor nodes, so we know how this joined into other.",
            "Joint patterns like the star join is adjoined by a subject or joined by object, for example."
        ],
        [
            "OK, just have an example here.",
            "How then the current generation works.",
            "So let's assume we have divine defined query pattern like this where you have many triple patterns combined in Star joints and pass joints.",
            "We would like to iterate, iteratively build this query by just adding random triple patterns starting with one triple pattern, then extending it to a certain parts of a certain length.",
            "Adding more triple patterns there to generate the next part of the path and then also completed with the star joint structures.",
            "How can we ensure that the results for such a query or what that we actually get results for such a query?",
            "Well, we need some background knowledge here.",
            "Because, well, just random doesn't work here.",
            "And well, what kind of background knowledge can be used?",
            "At what level of detail?",
            "Because you know, as we have heard in the talk before, if you have some statistical information about the datasets we are aiming for, then we need to keep these statistics and so on, and it grows in size.",
            "The more statistics you use.",
            "So we decided to concentrate on predicate combinations here.",
            "That means.",
            "If you have a past like joint structure in there, you know well there's a predicate like all same as is connecting to some other node, and this is a very F type something.",
            "And we can easily just collect this information for the datasets put in an index and use it for the query construction.",
            "Well, for the star joint patterns you also can just collect these statistical information.",
            "So how do we keep it actually on how is it provided in our?"
        ],
        [
            "Our system, we actually use two different things.",
            "So first is statistic about link predicates.",
            "That's just the first part, so we have in our index information about OK which predicate in a triple pattern is connected to another private pattern with another predicate.",
            "Because we're looking at the Federation scenario, we keep this information also for the data sources, so we know that same errors occurs in a triple in DB pedia.",
            "And then you can connect to another data source for an arbitrary resource to RDF type engineer names in the triple pattern.",
            "And we also keep information and how many triples triples are actually there in these data sources.",
            "For the star.",
            "Joints be used to characteristic sets introduced last year by Norman Mercator, and this is sort of like just information about which triple or which predicates Co occur in triple patterns with the same subject.",
            "They are joined over and this is also quite useful information.",
            "We can collect this information for every data source we have here and know how many triple patterns are there in this data source which is Co occurring with another predicate in other purple patterns in this data source."
        ],
        [
            "OK, so assume we have the query here and we want to start to connect three triple patterns with predicate P1P 2P3.",
            "What we do is we look in the index.",
            "We find information about the connection of P1 to P2 and then we just try to extend this parse by combining it with another pair we have there in the index.",
            "We can extend this further and further depending on how long this path should be.",
            "For the characteristic sets, well, we can use them to just generate these star shaped joint patterns here.",
            "And let me say we can also use the information from the index to compute joint selectivity here.",
            "But for most, the indexes in this phase used to just see what combinations are actually possible to constructing the query."
        ],
        [
            "We can also well fit the characteristics it's built more than Gent joins over two trip patterns.",
            "But as I have said before.",
            "We need to verify that the queries we are actually building also returned results.",
            "And how to evaluate that?",
            "Well, we would have to evaluate it on the real data set in the Real Federation system.",
            "But there is none which can actually do this.",
            "Especially since we want to also generate complicated queries, you cannot just generate it, wait for 8 hours, and then see if it returns any results.",
            "So we have to do something different here, and we decided to compute some sort of confidence value that says, OK, we assume that this query really is capable of returning results and we just use the minimum joint selectivity we have.",
            "Here we have the information in the index, we can just compute it and say, OK, we use a certain threshold and if it's.",
            "Above this threshold we assume that the query we generated can actually return results in this scenario."
        ],
        [
            "OK, so well, the evaluation should now show that the queries we produce really can do this and achieve what we wanted to.",
            "Also, we want to verify that the generation of valid trees actually happens, that they can return results for us and we want to compare different variations of our current generation algorithm here and see which one is best."
        ],
        [
            "Therefore we use three different approaches, so the baseline is just randomly selecting predicates for the queries we put there in the triple patterns.",
            "Random means, well, we still sort of look in the index that we get predicates which are actually occurring in the data sources, so it's not fully random, but still sort of just randomly pick something.",
            "Then the Lite version of our approach uses the background knowledge just explained until now and then, the full version just applies this minimum selectivity threshold comparison and we have chosen to use three different thresholds, which says OK, it's based on the joint selectivity, so the.",
            "Higher the number, the higher the threshold that we applied to say OK, this should be more or less more generic queries.",
            "We assume we get more query answers there."
        ],
        [
            "And then we measure the number of queries which do not have empty results and also the results per query we get.",
            "Our evaluation is using real link data.",
            "We generate random queries and just put it all the data in the Triple Store and the valuator's.",
            "OK, so the billion triple challenge from last year was used.",
            "And the random queries.",
            "Before this evaluation focused on queries which have pause or which include powers across different datasets, 'cause we want to achieve a benchmark that can generate queries for the Federation.",
            "We also say we want to have passed shape queries which spend different datasets.",
            "So basically we have queries where each ripple pattern implies the next top to different data set, which is really the most complex thing you could do here.",
            "And we just generated 100 crisper badge which we then run on the billion triple Challenge data which was put into the Triple Store.",
            "Queries essentially look like this.",
            "So we have for example five triple patterns joined together in the past.",
            "So variable one lesson there too is object and then subject of the next triple pattern.",
            "Problem is, well, how can we put all the data in a single triple store?",
            "We just took the triples, removed the context and put everything into RDF three weeks because that was the only triple store we could find so far which can really handle this whole data set."
        ],
        [
            "OK, so now we have a look at the results we obtained here.",
            "First, how many of our queries of the 100 query batches can actually return results?",
            "The baseline is there.",
            "None of the queries could actually return results because random selection of predicates for these queries does work.",
            "It's just no results.",
            "Then we have the Lite version without checking the similarity of the selectivity of the joints as the white bar, and you can see well, there's something if you have just three trip patterns joined or you have.",
            "Over 20 results out of over 20 queries out of 100, which returned results.",
            "But if we raise threshold we apply there for the similarity of the selectivity of the joints, the number of queries goes up which can actually return results.",
            "So we have around 60 queries which can return results for joining parts of three or four triple patterns while it goes down.",
            "The longer the pass will be because it's more.",
            "Unlikely to have a query which is spanning multiple data sources which can still return results based on the heuristics we apply, but I would say this is quite a nice result that we actually get in most cases of our highest threshold over 50%."
        ],
        [
            "So then looking at the number of results we get from our queries, you can see well this ranges from one query to couple of million results, one result, two couple of million results.",
            "And we also plotted here the quintiles of 20 and 80% and the mean value.",
            "It's a bit hard to interpret this right now because we didn't make any.",
            "Assumptions here that how many queries should be returned and we didn't enforce it.",
            "We just had a look at how many results did decrease, actually return and.",
            "With the statistics we used you can also see that."
        ],
        [
            "Well, this plot shows the number of estimated results we would get and the number of actual results we would get then and the line says well, if it's there, we actually just have her exact the estimated number of results we would get for the queries, but there's just a lot of spread in here, which is, as most of you should know, having.",
            "Statistics applied for selectivity estimation of joints.",
            "The more joints you have, the more error you introduce and the more widespread it is here.",
            "So we could not achieve so far to say, OK, we want to have this amount of results actually returned by the query.",
            "This is one of the next steps we would like to look into, but right now this is sort of like OK. For this we have to live with that spread we have here."
        ],
        [
            "Then we also had to look into the crews we get so quite a couple of numbers.",
            "Have a look there.",
            "Most of the queries we have here is just well.",
            "Vocabulary from RDF RDF's Hour, which means well.",
            "This is generic vocabulary that was taken from our statistics and assumed that we would have.",
            "Crews that spend data sources using this vocabulary as it predicates.",
            "Then if you look actually at RDF type, an hour equivalent class what is plotted there is the percentage of the occurrence of this predicate in our queries and the rank it has for the different algorithms we applied.",
            "And this is quite stable.",
            "So RDF type is almost always the first rank equivalent class is almost always the 7th rank is quite stable.",
            "But you can also see that goes exact match or all same as has for a lower threshold is used more often in the queries, but when we raise the threshold it's not used that often anymore in the queries we produce.",
            "So for the highest thresholds goes exact match is thrown out and also our same S which we would have assumed that is often used to spend different data sources is not that used.",
            "With our selectivity estimation as much as we would have expected, that's quite interesting.",
            "Well, and then there's also, I don't know what it is.",
            "It's Samantha Target type raising that similarity threshold.",
            "Brings it to the 4th rank.",
            "So it's the fourth most used predicate in the queries we produce.",
            "Quite interesting.",
            "I don't know what it is, but that's how it was.",
            "Yeah, the results we're getting here.",
            "Also, you can see raising this selectivity threshold also reduces the number of predicates that overall Lewiston queries."
        ],
        [
            "Let me quickly conclude.",
            "So what spot provides its flex flexible query characterization and parameterization for benchmark?",
            "And we provide the methodology for systematic and scalable prior generation.",
            "We're offering this as open source, it's not fully implemented everything yet, but we would like to bring it to the Community because we think it's useful and well.",
            "This is not really a benchmark yet.",
            "This is just methodology and tool set for generating one and there was yesterday interesting talk.",
            "What should the benchmark have?",
            "Actually by Maria Civita and we would say?",
            "If we get together and just say, how does a benchmark look like, we can use our two splodge, the framework to just generate such benchmarks for Link Data, Federation and well, we could also use it for interactive sparkle query construction actually.",
            "Any question?"
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Hello everybody, my name is Olaf girl.",
                    "label": 0
                },
                {
                    "sent": "It's from the University of Koblenz.",
                    "label": 1
                },
                {
                    "sent": "I'm going to talk about Splodge and the systematic generation of sparkle benchmark queries for linked open data.",
                    "label": 1
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So well.",
                    "label": 0
                },
                {
                    "sent": "Link data Federation.",
                    "label": 0
                },
                {
                    "sent": "What's that we want to do?",
                    "label": 0
                },
                {
                    "sent": "Is Parker queries on top of the link data cloud, so of course I also included this picture here to show the complexity of this task.",
                    "label": 1
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We have a problem here which is quite like the hen and egg problem becausw while we need distributed queries to be executed on such a big data cloud and to be used in Federation implementations.",
                    "label": 1
                },
                {
                    "sent": "But actually they're not many useful queries out there in the wild, and so because we are also not having good Federation implementations, we cannot generate more queries we could use here because it's hard to get data.",
                    "label": 0
                },
                {
                    "sent": "Known from this cloud and know what's actually in there?",
                    "label": 0
                },
                {
                    "sent": "Which vocabulary is used for this useful there?",
                    "label": 0
                },
                {
                    "sent": "So the problem is, I've also experienced this when implementing configuration implementation.",
                    "label": 1
                },
                {
                    "sent": "How to test it?",
                    "label": 0
                },
                {
                    "sent": "How to benchmark it, and so on because I don't have the queries and there's actually not much benchmarks out there.",
                    "label": 0
                },
                {
                    "sent": "But",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "But it would be nice to have some sort of benchmark queries here.",
                    "label": 0
                },
                {
                    "sent": "We could actually use for testing these systems.",
                    "label": 0
                },
                {
                    "sent": "And as he should know, there's the Lehigh University benchmark.",
                    "label": 0
                },
                {
                    "sent": "The building sparkle benchmark, espido benchmark.",
                    "label": 0
                },
                {
                    "sent": "These are synthetic benchmarks.",
                    "label": 0
                },
                {
                    "sent": "They have a specific domain with highly structured data, or have data generators you can scale up, and there are quite some sophisticated queries in there.",
                    "label": 1
                },
                {
                    "sent": "But actually because they are centralized, they are not suitable for Federation scenario.",
                    "label": 0
                },
                {
                    "sent": "You cannot just partition the data and apply it there.",
                    "label": 0
                },
                {
                    "sent": "Well, since last year there's the Fed bench benchmark.",
                    "label": 0
                },
                {
                    "sent": "It was specially designed for evaluating Federation implementations.",
                    "label": 1
                },
                {
                    "sent": "You have pending datasets in there roughly 170 million triples, 25 henti queries which should be suitable to test these datasets.",
                    "label": 0
                },
                {
                    "sent": "Well, I would say it's a bit to fix the link data cloud is much larger and you want to have a testbed where you can actually benchmark sort of in the scale of the holding data cloud.",
                    "label": 0
                },
                {
                    "sent": "So there was some motivation to say, OK, we were.",
                    "label": 0
                },
                {
                    "sent": "We would really like to have a scalable, flexible and also expressive link data benchmark here, because this is not enough.",
                    "label": 1
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the outline now is that I'm going to present the benchmark idea.",
                    "label": 0
                },
                {
                    "sent": "We had the methodology we applied and then also show you some evaluation results.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Having said that, so the main features we would like to have a scalability flexibility of the benchmark and also expressiveness that means we want to use real link datasets.",
                    "label": 0
                },
                {
                    "sent": "Any real link datasets?",
                    "label": 0
                },
                {
                    "sent": "And customize them in a benchmark scenario that really allows us to do scalable testing or Federation implementations.",
                    "label": 0
                },
                {
                    "sent": "And of course the queries should be including typical queries and complex queries and so forth.",
                    "label": 0
                },
                {
                    "sent": "Taking all that together should be provided by Splodge.",
                    "label": 0
                },
                {
                    "sent": "If you're wondering about the name, but that means.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That's the Semantic Sparkle benchmark for generator for linked open data.",
                    "label": 0
                },
                {
                    "sent": "Well.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The letters join in a different way.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "So what do we want for such a benchmark?",
                    "label": 1
                },
                {
                    "sent": "We want to define certain query characteristics, characteristics we want to cover.",
                    "label": 0
                },
                {
                    "sent": "We want to have automatic query generation for any kind of datasets and then also we need some sort of validation that the queries we generated a sort of useful for the benchmark.",
                    "label": 1
                },
                {
                    "sent": "Which means the first point is well, to define query characteristics.",
                    "label": 0
                },
                {
                    "sent": "We can customize the benchmark.",
                    "label": 1
                },
                {
                    "sent": "When we do the automatic regeneration, we can generate random queries.",
                    "label": 0
                },
                {
                    "sent": "Any type of random queries across the datasets.",
                    "label": 0
                },
                {
                    "sent": "And the validation should ensure that the queries we generated actually returned results that we wanted to do them actually also happens because just random queries do not give us any results in the link data cloud.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "This is just a big big picture we have in mind here for the methodology and the tool set you have the link data cloud you put in some configuration and then the magic happens and you get benchmark queries out of this.",
                    "label": 1
                },
                {
                    "sent": "We did divide this in three parts.",
                    "label": 0
                },
                {
                    "sent": "That's parameterization of the queries.",
                    "label": 1
                },
                {
                    "sent": "Then the generation and finally the query validation.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, now let's have a look at our methodology.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "These are the three parts I just mentioned.",
                    "label": 0
                },
                {
                    "sent": "We start with the first part.",
                    "label": 0
                },
                {
                    "sent": "We want to define typical and challenging distributed queries that we can use as benchmark queries.",
                    "label": 1
                },
                {
                    "sent": "Well, there are no Federated query locks available.",
                    "label": 0
                },
                {
                    "sent": "Well, there queer locks for DB pedia, some other datasets.",
                    "label": 1
                },
                {
                    "sent": "It's quite nice, but we cannot derive anything from these query logs we could use for the Federation scenario.",
                    "label": 0
                },
                {
                    "sent": "We could derive some information, but not.",
                    "label": 0
                },
                {
                    "sent": "To talk with the distributed nature, here we have in mind so anyway.",
                    "label": 0
                },
                {
                    "sent": "We analyzed this query logs and also of the Fed Bench benchmark to get a feeling of what is actually necessary to have a benchmark on Federated datasets.",
                    "label": 0
                },
                {
                    "sent": "Just to give you an impression, this is one of the queries used in the Fed bench benchmark, and it's about some life science theater.",
                    "label": 0
                },
                {
                    "sent": "You query something from drug bang, KB, cake and so on, and you have certain relations in there between the data.",
                    "label": 0
                },
                {
                    "sent": "You're the resources you are asking for.",
                    "label": 0
                },
                {
                    "sent": "So we had to look at this.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Then we tried to figure out what is important for benchmark here.",
                    "label": 0
                },
                {
                    "sent": "So first there's the algebra of your queries.",
                    "label": 0
                },
                {
                    "sent": "You would like to evaluate so.",
                    "label": 0
                },
                {
                    "sent": "Well, you have certain crew from select for his concert freeze join types which may increase the complexity.",
                    "label": 0
                },
                {
                    "sent": "Conjunctive joins the chunk of joins, left joins and then result modifications, and I will not just iterate over everything sparkled.",
                    "label": 0
                },
                {
                    "sent": "1 one is also much more things you could do here.",
                    "label": 0
                },
                {
                    "sent": "Then what is important for us is the structure of the queries you have certain variable patterns in the triple patterns you have in sparkle queries.",
                    "label": 0
                },
                {
                    "sent": "These are joined in different ways.",
                    "label": 0
                },
                {
                    "sent": "You have star joins, parts, joints and also combinations thereof and but you might also encounter across products in queries.",
                    "label": 0
                },
                {
                    "sent": "And then third thing is, well, we want to ensure certain cardinality aspects.",
                    "label": 0
                },
                {
                    "sent": "So we want to ensure that we cover certain amount of data sources.",
                    "label": 0
                },
                {
                    "sent": "We want to ensure that the query has certain complexity in the number of joins or triple patterns that are included and we want to ensure that a certain number of results can be returned by the queries.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "But I would like to focus now on our main query parameter, which is this joint structure.",
                    "label": 1
                },
                {
                    "sent": "So we have to look at the fetch bench fears actually, and which you can see.",
                    "label": 0
                },
                {
                    "sent": "Is there certain structures in the queries so the nodes are just subjects objects and the errors are the predicate connecting the variables in the queries.",
                    "label": 0
                },
                {
                    "sent": "So you can see.",
                    "label": 0
                },
                {
                    "sent": "They are POS joints in there and they also start joints in their combinations thereof, and variables are bound in certain ways and so on.",
                    "label": 0
                },
                {
                    "sent": "But this structure is quite interesting because we want to have something like this in a benchmark really to cover these certain aspects of how the data is connected because.",
                    "label": 0
                },
                {
                    "sent": "In this structure, different triple patterns which you have here can be matched to different data sources.",
                    "label": 0
                },
                {
                    "sent": "Because in a Federation benchmark you want to retrieve the different results from different data sources matching across the data source boundaries.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, the different parameters are then the number of triple patterns, number of data sources, result size and so on.",
                    "label": 1
                },
                {
                    "sent": "So what we define as a query is parameterized in our scenario by the number of triple patterns in the number of sources that this query should spend for such a pass drawing.",
                    "label": 0
                },
                {
                    "sent": "Then we also include the description of Star joins, which means while there's a resource which is described but different attributes, and we also define some sort of anchor nodes, so we know how this joined into other.",
                    "label": 0
                },
                {
                    "sent": "Joint patterns like the star join is adjoined by a subject or joined by object, for example.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, just have an example here.",
                    "label": 0
                },
                {
                    "sent": "How then the current generation works.",
                    "label": 0
                },
                {
                    "sent": "So let's assume we have divine defined query pattern like this where you have many triple patterns combined in Star joints and pass joints.",
                    "label": 0
                },
                {
                    "sent": "We would like to iterate, iteratively build this query by just adding random triple patterns starting with one triple pattern, then extending it to a certain parts of a certain length.",
                    "label": 1
                },
                {
                    "sent": "Adding more triple patterns there to generate the next part of the path and then also completed with the star joint structures.",
                    "label": 0
                },
                {
                    "sent": "How can we ensure that the results for such a query or what that we actually get results for such a query?",
                    "label": 0
                },
                {
                    "sent": "Well, we need some background knowledge here.",
                    "label": 1
                },
                {
                    "sent": "Because, well, just random doesn't work here.",
                    "label": 0
                },
                {
                    "sent": "And well, what kind of background knowledge can be used?",
                    "label": 0
                },
                {
                    "sent": "At what level of detail?",
                    "label": 1
                },
                {
                    "sent": "Because you know, as we have heard in the talk before, if you have some statistical information about the datasets we are aiming for, then we need to keep these statistics and so on, and it grows in size.",
                    "label": 1
                },
                {
                    "sent": "The more statistics you use.",
                    "label": 0
                },
                {
                    "sent": "So we decided to concentrate on predicate combinations here.",
                    "label": 0
                },
                {
                    "sent": "That means.",
                    "label": 0
                },
                {
                    "sent": "If you have a past like joint structure in there, you know well there's a predicate like all same as is connecting to some other node, and this is a very F type something.",
                    "label": 0
                },
                {
                    "sent": "And we can easily just collect this information for the datasets put in an index and use it for the query construction.",
                    "label": 0
                },
                {
                    "sent": "Well, for the star joint patterns you also can just collect these statistical information.",
                    "label": 0
                },
                {
                    "sent": "So how do we keep it actually on how is it provided in our?",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Our system, we actually use two different things.",
                    "label": 0
                },
                {
                    "sent": "So first is statistic about link predicates.",
                    "label": 0
                },
                {
                    "sent": "That's just the first part, so we have in our index information about OK which predicate in a triple pattern is connected to another private pattern with another predicate.",
                    "label": 0
                },
                {
                    "sent": "Because we're looking at the Federation scenario, we keep this information also for the data sources, so we know that same errors occurs in a triple in DB pedia.",
                    "label": 0
                },
                {
                    "sent": "And then you can connect to another data source for an arbitrary resource to RDF type engineer names in the triple pattern.",
                    "label": 0
                },
                {
                    "sent": "And we also keep information and how many triples triples are actually there in these data sources.",
                    "label": 0
                },
                {
                    "sent": "For the star.",
                    "label": 0
                },
                {
                    "sent": "Joints be used to characteristic sets introduced last year by Norman Mercator, and this is sort of like just information about which triple or which predicates Co occur in triple patterns with the same subject.",
                    "label": 0
                },
                {
                    "sent": "They are joined over and this is also quite useful information.",
                    "label": 0
                },
                {
                    "sent": "We can collect this information for every data source we have here and know how many triple patterns are there in this data source which is Co occurring with another predicate in other purple patterns in this data source.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so assume we have the query here and we want to start to connect three triple patterns with predicate P1P 2P3.",
                    "label": 0
                },
                {
                    "sent": "What we do is we look in the index.",
                    "label": 0
                },
                {
                    "sent": "We find information about the connection of P1 to P2 and then we just try to extend this parse by combining it with another pair we have there in the index.",
                    "label": 0
                },
                {
                    "sent": "We can extend this further and further depending on how long this path should be.",
                    "label": 0
                },
                {
                    "sent": "For the characteristic sets, well, we can use them to just generate these star shaped joint patterns here.",
                    "label": 0
                },
                {
                    "sent": "And let me say we can also use the information from the index to compute joint selectivity here.",
                    "label": 0
                },
                {
                    "sent": "But for most, the indexes in this phase used to just see what combinations are actually possible to constructing the query.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We can also well fit the characteristics it's built more than Gent joins over two trip patterns.",
                    "label": 0
                },
                {
                    "sent": "But as I have said before.",
                    "label": 0
                },
                {
                    "sent": "We need to verify that the queries we are actually building also returned results.",
                    "label": 0
                },
                {
                    "sent": "And how to evaluate that?",
                    "label": 1
                },
                {
                    "sent": "Well, we would have to evaluate it on the real data set in the Real Federation system.",
                    "label": 0
                },
                {
                    "sent": "But there is none which can actually do this.",
                    "label": 0
                },
                {
                    "sent": "Especially since we want to also generate complicated queries, you cannot just generate it, wait for 8 hours, and then see if it returns any results.",
                    "label": 0
                },
                {
                    "sent": "So we have to do something different here, and we decided to compute some sort of confidence value that says, OK, we assume that this query really is capable of returning results and we just use the minimum joint selectivity we have.",
                    "label": 0
                },
                {
                    "sent": "Here we have the information in the index, we can just compute it and say, OK, we use a certain threshold and if it's.",
                    "label": 0
                },
                {
                    "sent": "Above this threshold we assume that the query we generated can actually return results in this scenario.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so well, the evaluation should now show that the queries we produce really can do this and achieve what we wanted to.",
                    "label": 0
                },
                {
                    "sent": "Also, we want to verify that the generation of valid trees actually happens, that they can return results for us and we want to compare different variations of our current generation algorithm here and see which one is best.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Therefore we use three different approaches, so the baseline is just randomly selecting predicates for the queries we put there in the triple patterns.",
                    "label": 0
                },
                {
                    "sent": "Random means, well, we still sort of look in the index that we get predicates which are actually occurring in the data sources, so it's not fully random, but still sort of just randomly pick something.",
                    "label": 0
                },
                {
                    "sent": "Then the Lite version of our approach uses the background knowledge just explained until now and then, the full version just applies this minimum selectivity threshold comparison and we have chosen to use three different thresholds, which says OK, it's based on the joint selectivity, so the.",
                    "label": 0
                },
                {
                    "sent": "Higher the number, the higher the threshold that we applied to say OK, this should be more or less more generic queries.",
                    "label": 0
                },
                {
                    "sent": "We assume we get more query answers there.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And then we measure the number of queries which do not have empty results and also the results per query we get.",
                    "label": 0
                },
                {
                    "sent": "Our evaluation is using real link data.",
                    "label": 0
                },
                {
                    "sent": "We generate random queries and just put it all the data in the Triple Store and the valuator's.",
                    "label": 0
                },
                {
                    "sent": "OK, so the billion triple challenge from last year was used.",
                    "label": 0
                },
                {
                    "sent": "And the random queries.",
                    "label": 0
                },
                {
                    "sent": "Before this evaluation focused on queries which have pause or which include powers across different datasets, 'cause we want to achieve a benchmark that can generate queries for the Federation.",
                    "label": 0
                },
                {
                    "sent": "We also say we want to have passed shape queries which spend different datasets.",
                    "label": 0
                },
                {
                    "sent": "So basically we have queries where each ripple pattern implies the next top to different data set, which is really the most complex thing you could do here.",
                    "label": 0
                },
                {
                    "sent": "And we just generated 100 crisper badge which we then run on the billion triple Challenge data which was put into the Triple Store.",
                    "label": 1
                },
                {
                    "sent": "Queries essentially look like this.",
                    "label": 0
                },
                {
                    "sent": "So we have for example five triple patterns joined together in the past.",
                    "label": 0
                },
                {
                    "sent": "So variable one lesson there too is object and then subject of the next triple pattern.",
                    "label": 0
                },
                {
                    "sent": "Problem is, well, how can we put all the data in a single triple store?",
                    "label": 0
                },
                {
                    "sent": "We just took the triples, removed the context and put everything into RDF three weeks because that was the only triple store we could find so far which can really handle this whole data set.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so now we have a look at the results we obtained here.",
                    "label": 0
                },
                {
                    "sent": "First, how many of our queries of the 100 query batches can actually return results?",
                    "label": 0
                },
                {
                    "sent": "The baseline is there.",
                    "label": 0
                },
                {
                    "sent": "None of the queries could actually return results because random selection of predicates for these queries does work.",
                    "label": 0
                },
                {
                    "sent": "It's just no results.",
                    "label": 0
                },
                {
                    "sent": "Then we have the Lite version without checking the similarity of the selectivity of the joints as the white bar, and you can see well, there's something if you have just three trip patterns joined or you have.",
                    "label": 0
                },
                {
                    "sent": "Over 20 results out of over 20 queries out of 100, which returned results.",
                    "label": 0
                },
                {
                    "sent": "But if we raise threshold we apply there for the similarity of the selectivity of the joints, the number of queries goes up which can actually return results.",
                    "label": 0
                },
                {
                    "sent": "So we have around 60 queries which can return results for joining parts of three or four triple patterns while it goes down.",
                    "label": 0
                },
                {
                    "sent": "The longer the pass will be because it's more.",
                    "label": 0
                },
                {
                    "sent": "Unlikely to have a query which is spanning multiple data sources which can still return results based on the heuristics we apply, but I would say this is quite a nice result that we actually get in most cases of our highest threshold over 50%.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So then looking at the number of results we get from our queries, you can see well this ranges from one query to couple of million results, one result, two couple of million results.",
                    "label": 0
                },
                {
                    "sent": "And we also plotted here the quintiles of 20 and 80% and the mean value.",
                    "label": 0
                },
                {
                    "sent": "It's a bit hard to interpret this right now because we didn't make any.",
                    "label": 0
                },
                {
                    "sent": "Assumptions here that how many queries should be returned and we didn't enforce it.",
                    "label": 0
                },
                {
                    "sent": "We just had a look at how many results did decrease, actually return and.",
                    "label": 0
                },
                {
                    "sent": "With the statistics we used you can also see that.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Well, this plot shows the number of estimated results we would get and the number of actual results we would get then and the line says well, if it's there, we actually just have her exact the estimated number of results we would get for the queries, but there's just a lot of spread in here, which is, as most of you should know, having.",
                    "label": 0
                },
                {
                    "sent": "Statistics applied for selectivity estimation of joints.",
                    "label": 0
                },
                {
                    "sent": "The more joints you have, the more error you introduce and the more widespread it is here.",
                    "label": 0
                },
                {
                    "sent": "So we could not achieve so far to say, OK, we want to have this amount of results actually returned by the query.",
                    "label": 0
                },
                {
                    "sent": "This is one of the next steps we would like to look into, but right now this is sort of like OK. For this we have to live with that spread we have here.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Then we also had to look into the crews we get so quite a couple of numbers.",
                    "label": 0
                },
                {
                    "sent": "Have a look there.",
                    "label": 0
                },
                {
                    "sent": "Most of the queries we have here is just well.",
                    "label": 0
                },
                {
                    "sent": "Vocabulary from RDF RDF's Hour, which means well.",
                    "label": 0
                },
                {
                    "sent": "This is generic vocabulary that was taken from our statistics and assumed that we would have.",
                    "label": 0
                },
                {
                    "sent": "Crews that spend data sources using this vocabulary as it predicates.",
                    "label": 0
                },
                {
                    "sent": "Then if you look actually at RDF type, an hour equivalent class what is plotted there is the percentage of the occurrence of this predicate in our queries and the rank it has for the different algorithms we applied.",
                    "label": 0
                },
                {
                    "sent": "And this is quite stable.",
                    "label": 0
                },
                {
                    "sent": "So RDF type is almost always the first rank equivalent class is almost always the 7th rank is quite stable.",
                    "label": 0
                },
                {
                    "sent": "But you can also see that goes exact match or all same as has for a lower threshold is used more often in the queries, but when we raise the threshold it's not used that often anymore in the queries we produce.",
                    "label": 0
                },
                {
                    "sent": "So for the highest thresholds goes exact match is thrown out and also our same S which we would have assumed that is often used to spend different data sources is not that used.",
                    "label": 0
                },
                {
                    "sent": "With our selectivity estimation as much as we would have expected, that's quite interesting.",
                    "label": 0
                },
                {
                    "sent": "Well, and then there's also, I don't know what it is.",
                    "label": 0
                },
                {
                    "sent": "It's Samantha Target type raising that similarity threshold.",
                    "label": 0
                },
                {
                    "sent": "Brings it to the 4th rank.",
                    "label": 0
                },
                {
                    "sent": "So it's the fourth most used predicate in the queries we produce.",
                    "label": 0
                },
                {
                    "sent": "Quite interesting.",
                    "label": 0
                },
                {
                    "sent": "I don't know what it is, but that's how it was.",
                    "label": 0
                },
                {
                    "sent": "Yeah, the results we're getting here.",
                    "label": 0
                },
                {
                    "sent": "Also, you can see raising this selectivity threshold also reduces the number of predicates that overall Lewiston queries.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Let me quickly conclude.",
                    "label": 0
                },
                {
                    "sent": "So what spot provides its flex flexible query characterization and parameterization for benchmark?",
                    "label": 1
                },
                {
                    "sent": "And we provide the methodology for systematic and scalable prior generation.",
                    "label": 1
                },
                {
                    "sent": "We're offering this as open source, it's not fully implemented everything yet, but we would like to bring it to the Community because we think it's useful and well.",
                    "label": 0
                },
                {
                    "sent": "This is not really a benchmark yet.",
                    "label": 0
                },
                {
                    "sent": "This is just methodology and tool set for generating one and there was yesterday interesting talk.",
                    "label": 0
                },
                {
                    "sent": "What should the benchmark have?",
                    "label": 0
                },
                {
                    "sent": "Actually by Maria Civita and we would say?",
                    "label": 0
                },
                {
                    "sent": "If we get together and just say, how does a benchmark look like, we can use our two splodge, the framework to just generate such benchmarks for Link Data, Federation and well, we could also use it for interactive sparkle query construction actually.",
                    "label": 0
                },
                {
                    "sent": "Any question?",
                    "label": 0
                }
            ]
        }
    }
}