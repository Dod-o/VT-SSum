{
    "id": "m6rupfdsza5f5fka7s63ouik45me56sc",
    "title": "A Simpler Unified Analysis of Budget Perceptrons",
    "info": {
        "author": [
            "Ilya Sutskever, Department of Computer Science, University of Toronto"
        ],
        "published": "Aug. 26, 2009",
        "recorded": "June 2009",
        "category": [
            "Top->Computer Science->Machine Learning->On-line Learning"
        ]
    },
    "url": "http://videolectures.net/icml09_sutskever_asua/",
    "segmentation": [
        [
            "OK, I'll start.",
            "Thank you very much for coming to my talk.",
            "My name is Elise covering from the University of Toronto and I will tell you about some work I've done and understanding budget perception slightly better.",
            "So I'll start with the last slide."
        ],
        [
            "With the summary and conclusion, so there are two algorithms which are budget perceptions which occur which you care about in this talk that we forget Ronan the randomized budget perception.",
            "And in this talk, my main result.",
            "Showing that both algorithms are falling the gradient of an L2 regularizer hinge loss on the points in which they make mistakes, plus some noise, and then using this observation we can prove their regret bounds using online convex programming results.",
            "Relatively easily without using heavy math, so that's it."
        ],
        [
            "It's not, let's start.",
            "I'll tell you a bit about perceptions, so the perception algorithm is an algorithm is an algorithm for binary classification.",
            "Give it an example X which is a vector in high dimensional space.",
            "It has a weight vector.",
            "W Anet classifies things based on the sign of the inner product and whenever it makes a mistake, it updates their sign.",
            "It updates the weights using the Delta rule.",
            "In other words, it does.",
            "It takes the truth minus predictions times the vector analysis.",
            "So if there's no mistake, there is no update and as a result we get the W is a linear combination of the vectors in which a mistake was made.",
            "So."
        ],
        [
            "If the data is low dimensional then we may want to nonlinear classifier because we can come up with problems for which a linear classifier is not satisfying so."
        ],
        [
            "And it's possible to use the kernel, the kernel perception, which is exactly like the perception, except that we classify 5X instead of X, but otherwise conceptually is exactly the same.",
            "We say that P. The prediction is the sign of the inner product between 5X and W, the weight vector, and then we update the weights exactly as usual.",
            "We say that W equals W plus truth minus prediction, which is the Delta rule times 5X.",
            "So if you make no mistake, we make no update.",
            "And as before W as a linear combination, but this time of 5X, so conceptually it's very simple.",
            "I expect this is.",
            "This is something we should all be familiar with, but if we use the if."
        ],
        [
            "Use the kernel perception.",
            "Then we get a non linear decision boundary which is good whenever we have low dimensional data.",
            "As far as I know for high dimensional data nonlinearities become less important because it's pretty difficult for high dimensional data to be non linearly separable.",
            "So."
        ],
        [
            "The problem, so the perception perception algorithm is very nice because it's online.",
            "It has all the perceptual learning all the perception guarantees.",
            "It's easy to implement, but the best thing about it is that computing these inner products W in a product 5X.",
            "Takes linear time in a number of errors, so if you make many errors during training, we expect this.",
            "This inner product will become slow and it will slow down learning.",
            "So for example, if you make 10,000 errors it will become pretty much infeasibly slow."
        ],
        [
            "So here is a picture which illustrates the situation.",
            "Mechanic Perception maintains a set of maintains W, which is a set of vector which is linear combinations of five of the mistakes it made, and these bars represent the signs of the coefficients in linear combination and then the perception has a fixed learning rate as it always does.",
            "The magnitude of these coefficients is always the same, but the sign may differ.",
            "Now."
        ],
        [
            "This is the problem of so if you make too many mistakes, are learning become slow and this is a problem and there are a number of solutions which are all based on the following rough idea.",
            "It says that if we let's say that we put a strict upper bound on the number of vectors we allow, we will maintain.",
            "So let's say we will maintain, we will carry not more than be vectors.",
            "So B stands for the budget.",
            "Figure if you can be vectors, then we know that we know that our algorithm will not become extremely slow.",
            "There is a bound on how slow it will be, and in order to implement it the philosophy goes like this.",
            "Suppose we run our perception and suddenly we make a mistake.",
            "So if you want to add a vector, two are set to vectors we carry, we must first remove vector, so that's it.",
            "So that's how we maintain the budget.",
            "And there are four algorithms as far as I know for doing.",
            "Perceptions on, but on a budget, and I will care about two of them which have formal guarantees, and these are the forget run and the randomized budget perception.",
            "So I will explain these algorithms.",
            "Right now there."
        ],
        [
            "Very simple, so this is a simplified version of the forget run.",
            "So in order to remove a vector we take a weight vector.",
            "And scale it down.",
            "And then we removed all this vector and then we add the vector image making mistake so.",
            "Pictorially."
        ],
        [
            "Here is the weight vector we maintain.",
            "Visit the mistakes in which we made, but notice that here X ends on the B and not on M because we don't carry more than vectors.",
            "So the first vector which is so here let X 1B, the vector in which you made the last mistake.",
            "So you'll have a high coefficient.",
            "X2 will have a smaller coefficient because every time we scaled vector down extremely have an even smaller coefficient in absolute value, and the last vector will have a tiny coefficient.",
            "If you make enough of if we have make a sufficient amount of the scaling down.",
            "So here the hope is that if this is small enough, then by removing it we don't hurt performance a lot and at the same time if we scale things down only slightly, we don't hurt performance too much either.",
            "So that's the idea here.",
            "And this thing can be proved to work nearly as well as the best.",
            "As is the best fixed hyperplane over normal certain size.",
            "So this is the simplification, so I'll go over it again.",
            "We scaled vector down, then we remove the vector with the.",
            "Then we remove the X vector with the smallest weight and then we add the new vector which make the mistake.",
            "So now this is the first algorithm which you care about.",
            "The second algorithm should care about is the randomized."
        ],
        [
            "What is perception which says the following?",
            "Suppose you want to add a vector to your.",
            "Suppose we run the perception and we made a mistake.",
            "So now we want to add a vector set.",
            "So we need to remove something.",
            "What do we remove?",
            "We remove something, it's random, so it's really simple.",
            "Just pick a vector, remove that random done, and now at the vector.",
            "So this is the randomized perception.",
            "So."
        ],
        [
            "Here's how it looks like you have.",
            "We have a.",
            "We have the points, make mistakes and we carry only be of them and we just pick one at random and we removed.",
            "Very simple."
        ],
        [
            "So.",
            "Now, both of these algorithms have regret bounds which which relates the number of errors, the total number of errors they make to the hinge, loss of fixed linear classifier, plus some error terms, and I will state the regret bounds which I was able to prove using my technique which are very similar.",
            "There are almost the same as the original regret bounds, just the technique is a bit different so.",
            "The number of errors for the forget run or the expected number of errors for the randomized budget.",
            "Perception is less than some constant of the hinge loss of some vector with the hinge loss is the hinge loss on all the examples on all the examples we've seen, plus some constant times the budget where.",
            "Via competitive against vectors of order square root whose norm is of order square root of B for the randomized budget.",
            "Perception and vector vectors of order square root of order whose norm is awarded square root of B over log before they forget run, which is also which is also the same as in the original results.",
            "And now."
        ],
        [
            "So far I told you existing stuff.",
            "I didn't say anything you yet.",
            "Everything that said so far was old results.",
            "Now here is my.",
            "Here is the main observation which relates these two algorithms.",
            "And which makes it?",
            "Which concept which makes it conceptually easy to prove the regret bounds?",
            "So both algorithms here is the main here is if you forget everything, this is the slide you should remember.",
            "Both algorithms follow the gradient of the hinge loss.",
            "Of the errors plus L2 regularization.",
            "Both algorithms follow the gradient plus different types of noise.",
            "Specifically, the forget run has small deterministic noise in the gradient and the randomized budget perception has zero mean noise in the gradient, which is very structured and which is nothing like Gaussian noise for example.",
            "But it doesn't matter this observation.",
            "1st So this shows us in some sense where these algorithms are coming from.",
            "Just different, we simply add different noise to L2 regularizer hinge losses.",
            "That's the first thing.",
            "The second thing.",
            "We only run.",
            "The only run, so this.",
            "So here we are doing gradient descent on various on very different loss functions, but we only update the parameter whenever whenever we make a mistake.",
            "If you don't make a mistake, we simply ignore the point.",
            "So here's here's how both algorithms look like.",
            "We run the perceptron and whenever and whenever we make a mistake we compute the grade.",
            "The update of weight by following the gradient of this function.",
            "Plus some kind of noise, that's it.",
            "And now I will show you how using this.",
            "Using this observation we can prove their regret bounds using Zinkevich theorem."
        ],
        [
            "I'm.",
            "So let's let's look at the simplified forget rent so they forget run.",
            "So when I say simplified forget run, I mean that the constant factor by which we scale things down is always the same.",
            "We just pick some number and scalar vector down by some number.",
            "So this operation is what you get when you follow the gradient of an L2 regularization.",
            "Because the gradient of an L2 regularization grows as your vector grows, this is simple.",
            "This is small deterministic noise, because we expect that the constant by which we scale things down.",
            "If it's small enough and B is large enough, then this thing is going to be pretty small, so this will be small deterministic noise.",
            "Now this this term right here is the gradient of the hinge loss.",
            "Whenever we make a mistake.",
            "So whenever making mistake, the gradient of the change looks like this.",
            "That's it, so therefore this justifies the fact that we forget run is in fact an instance of this algorithm.",
            "Now let's go to the randomized budget."
        ],
        [
            "Section in the randomized budget perception we also have to update the first updates, remove a support vector from the supports at random, and the 2nd update is updating is incorporating the new point.",
            "So the new point is incorporated also, but is also the gradient of the hinge loss, so that's easy.",
            "It's exactly like before.",
            "If you take the hinge loss on the points we mistakenly differentiate it, we will get this kind of gradient.",
            "But now.",
            "What I claim which, which is also very simple, is that if you remove a support vector at random, this is like we remove W / B plus some noise.",
            "So basically here is what I claim when we do the randomized, But the randomized budget perception is following the gradient of the hinge loss plus an L2 regularization plus some noise.",
            "Here is the reason.",
            "When we remove a support vector at random, we can just ask.",
            "You could ask us what's the average thing we remove and the average."
        ],
        [
            "You remove can be seen to be equal to W / B.",
            "So if you have so if W is the sum of the terms.",
            "And we pick a term.",
            "It's random than expected value of a term is just W Overby becausw.",
            "The expectation is the sum over all possibilities times the probability and the sum of all these things is just W. So this is it.",
            "This is the second important observation.",
            "It's not complicated at all.",
            "It's simple.",
            "I want I want it to be understood by everyone.",
            "That in the randomized budget perception, when you remove a support vector at random, we are following an unbiased estimate of the gradient of an L2 regularization, so that's it.",
            "This is.",
            "The this is this is the justification for the observation and now I will outline the way in which I apply Zinkevich theorem and a version of it in order."
        ],
        [
            "Regret bounds.",
            "So Zinkevich theorem tells us that if we have a sequence of functions and we do gradient descent, then the performance of our algorithm will be nearly as good as the performance of any fixed point inside.",
            "So in other words, if you run if you do online gradient descent on these functions, LM on our errors, then the total loss we will experience will be compara bulto the loss of any fixed weight that may know all the examples even after they were given."
        ],
        [
            "So if we apply it, we get a bound that looks like this.",
            "We can say that our algorithm, which is what I said right now, the performance of our algorithm.",
            "So by the way, I should point out in case you forgot that LM is the hinge loss of the EMS example with W M + L two regularization.",
            "So the performance of our algorithm on this function is less than the performance of anything fixed plus some term which which is called the regret.",
            "Yes.",
            "I can I have a slide for that.",
            "It's bit long, but.",
            "How much time do I have?",
            "5 minutes.",
            "You know, OK, fine."
        ],
        [
            "That's good, so I'll just spend one minute Zinkevich theorem says that if you have a sequence of convex functions, if you have a sequence of convex functions and if we do online gradient descent on these functions.",
            "Then the loss over us and let Xanna let the axis be the sequence of gradient points, which we do.",
            "Then the loss that our algorithm within the total loss feature algorithm experiences is less than the loss of anything fixed in advance plus some error term which depends on various parameters.",
            "But basically it says that if you do online, if you do online learning but you don't know the sequence of functions, you can relate your performance to the performance of something which knows all the functions in advance but is not allowed to change on every function.",
            "So I will now I want to outline how I play."
        ],
        [
            "The how apply Zinkevich theorem to be forgetful.",
            "So I just say one thing and then forget run.",
            "We have errors in the gradient, but it's very easy to take the proof of Sienkiewicz theorem to run it with errors in the gradient and you get an extra term in the regret, but it's very easy.",
            "It works out just fine.",
            "So what we get is the following by applying Sienkiewicz theorem we get the loss of our algorithm.",
            "So OK here's what I'll do.",
            "I will take Sienkiewicz theorem and I'll apply it only on the functions on the hinge.",
            "Loss is on which I make a mistake.",
            "If I don't make a mistake I don't update my parameters technology functions.",
            "Now I take this sum.",
            "The performance of my algorithm is smaller than the performance of anything fixed, which is not too large, and now this is a parameter I don't tell you how large how large vectors allowed to be now, because this is the hinge loss of a pawn, a mistake.",
            "Then it's bigger than one.",
            "This is Lt regular exchange loss and if it's and if it makes a mistake is bigger than one.",
            "Therefore the sum of all the mistakes is going to be bigger than the number of mistakes.",
            "This is a famous trick.",
            "If you seen this examples where the hinge loss is bigger than zero, one more.",
            "So that's exactly what's going on.",
            "So the number of mistakes is less than the total.",
            "Then the total Lt regularization loss and now we get that this is less than something which depends on the L2 regularization loss of a competing vector, and we will get a factor of EM on the right hand side.",
            "So we just need to tweak the parameters to make sure that the constant factor next to me here is smaller than one.",
            "If the constant factor next to me here is smaller than one, then we can pull them to this side and we get that M times some constant is less than the hinge loss of W plus some other terms, and that's it.",
            "And this is what we do.",
            "Forget run now for the random."
        ],
        [
            "What is perception?",
            "We do something slightly differently, which is a trick from.",
            "A paper by.",
            "Flaxman, Tom and Kelly and mcmane.",
            "When we say the following here, this is a randomized perception, slightly more complicated because we have noise and the set of X make mistakes is different every time.",
            "So what we do is what they do is really nice trick.",
            "They say let us add noise to the functions so that doing gradient descent to the noisy functions exactly like doing gradient descent of the normal functions plus noise.",
            "And then we apply Sinkovich theorem on the noisy functions an average and it works out.",
            "And finally I will say one last point.",
            "But we."
        ],
        [
            "Makes it so think of each singular motions of variance for tracking.",
            "In other words, think of this theorem is not only competitive against a fixed vector, but it's also competitive against the sequence of slowly changing vectors.",
            "So if you say I want to be, I want my algorithm to perform as well as something that changes as long as the change is not very large and the learning rate is not very small, then we will also get regret bound and the proof is also very easy, just takes encouraged them and look at the proof and we had some terms and it all works out.",
            "The no thinking is required, we just we just do a straightforward derivation and by using the tracking variant.",
            "We can get bounds for the both the forgotten and the randomized budget perception, which are competitive not against the single fixed hypothesis, but against a sequence of lowering hypothesis and other."
        ],
        [
            "Finish here, thank you."
        ],
        [
            "Impression.",
            "I have a yes.",
            "From applying your technique to more sophisticated budget algorithms.",
            "Probably so it depends on algorithm, but as long if you have applied.",
            "Because they are more expensive in terms of the number of.",
            "Super vectors, so I didn't.",
            "I'm not familiar with these algorithms, but if as long as you can say as long as you can express the second or algorithm as something which is where you follow the gradient of something nice, like an L2 regularization, regularization or something else which which we know and we can say well, what we really do is this gradient plus some noise whether it's deterministic and stochastic.",
            "Then we can definitely apply this technique.",
            "It has to be a great yes, so as long as you can relate your algorithm to gradient descent scheme you can immediately.",
            "Immediately apply this idea.",
            "And it kind of you can have both stochastic indeterminacy approximation.",
            "Zinkevich theorem is very robust.",
            "Questions.",
            "So let's thank the speaker."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, I'll start.",
                    "label": 0
                },
                {
                    "sent": "Thank you very much for coming to my talk.",
                    "label": 0
                },
                {
                    "sent": "My name is Elise covering from the University of Toronto and I will tell you about some work I've done and understanding budget perception slightly better.",
                    "label": 1
                },
                {
                    "sent": "So I'll start with the last slide.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "With the summary and conclusion, so there are two algorithms which are budget perceptions which occur which you care about in this talk that we forget Ronan the randomized budget perception.",
                    "label": 1
                },
                {
                    "sent": "And in this talk, my main result.",
                    "label": 0
                },
                {
                    "sent": "Showing that both algorithms are falling the gradient of an L2 regularizer hinge loss on the points in which they make mistakes, plus some noise, and then using this observation we can prove their regret bounds using online convex programming results.",
                    "label": 0
                },
                {
                    "sent": "Relatively easily without using heavy math, so that's it.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It's not, let's start.",
                    "label": 0
                },
                {
                    "sent": "I'll tell you a bit about perceptions, so the perception algorithm is an algorithm is an algorithm for binary classification.",
                    "label": 0
                },
                {
                    "sent": "Give it an example X which is a vector in high dimensional space.",
                    "label": 0
                },
                {
                    "sent": "It has a weight vector.",
                    "label": 0
                },
                {
                    "sent": "W Anet classifies things based on the sign of the inner product and whenever it makes a mistake, it updates their sign.",
                    "label": 0
                },
                {
                    "sent": "It updates the weights using the Delta rule.",
                    "label": 0
                },
                {
                    "sent": "In other words, it does.",
                    "label": 0
                },
                {
                    "sent": "It takes the truth minus predictions times the vector analysis.",
                    "label": 0
                },
                {
                    "sent": "So if there's no mistake, there is no update and as a result we get the W is a linear combination of the vectors in which a mistake was made.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "If the data is low dimensional then we may want to nonlinear classifier because we can come up with problems for which a linear classifier is not satisfying so.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And it's possible to use the kernel, the kernel perception, which is exactly like the perception, except that we classify 5X instead of X, but otherwise conceptually is exactly the same.",
                    "label": 0
                },
                {
                    "sent": "We say that P. The prediction is the sign of the inner product between 5X and W, the weight vector, and then we update the weights exactly as usual.",
                    "label": 0
                },
                {
                    "sent": "We say that W equals W plus truth minus prediction, which is the Delta rule times 5X.",
                    "label": 0
                },
                {
                    "sent": "So if you make no mistake, we make no update.",
                    "label": 0
                },
                {
                    "sent": "And as before W as a linear combination, but this time of 5X, so conceptually it's very simple.",
                    "label": 0
                },
                {
                    "sent": "I expect this is.",
                    "label": 0
                },
                {
                    "sent": "This is something we should all be familiar with, but if we use the if.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Use the kernel perception.",
                    "label": 0
                },
                {
                    "sent": "Then we get a non linear decision boundary which is good whenever we have low dimensional data.",
                    "label": 0
                },
                {
                    "sent": "As far as I know for high dimensional data nonlinearities become less important because it's pretty difficult for high dimensional data to be non linearly separable.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The problem, so the perception perception algorithm is very nice because it's online.",
                    "label": 0
                },
                {
                    "sent": "It has all the perceptual learning all the perception guarantees.",
                    "label": 1
                },
                {
                    "sent": "It's easy to implement, but the best thing about it is that computing these inner products W in a product 5X.",
                    "label": 0
                },
                {
                    "sent": "Takes linear time in a number of errors, so if you make many errors during training, we expect this.",
                    "label": 1
                },
                {
                    "sent": "This inner product will become slow and it will slow down learning.",
                    "label": 0
                },
                {
                    "sent": "So for example, if you make 10,000 errors it will become pretty much infeasibly slow.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here is a picture which illustrates the situation.",
                    "label": 0
                },
                {
                    "sent": "Mechanic Perception maintains a set of maintains W, which is a set of vector which is linear combinations of five of the mistakes it made, and these bars represent the signs of the coefficients in linear combination and then the perception has a fixed learning rate as it always does.",
                    "label": 0
                },
                {
                    "sent": "The magnitude of these coefficients is always the same, but the sign may differ.",
                    "label": 0
                },
                {
                    "sent": "Now.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This is the problem of so if you make too many mistakes, are learning become slow and this is a problem and there are a number of solutions which are all based on the following rough idea.",
                    "label": 0
                },
                {
                    "sent": "It says that if we let's say that we put a strict upper bound on the number of vectors we allow, we will maintain.",
                    "label": 0
                },
                {
                    "sent": "So let's say we will maintain, we will carry not more than be vectors.",
                    "label": 1
                },
                {
                    "sent": "So B stands for the budget.",
                    "label": 1
                },
                {
                    "sent": "Figure if you can be vectors, then we know that we know that our algorithm will not become extremely slow.",
                    "label": 0
                },
                {
                    "sent": "There is a bound on how slow it will be, and in order to implement it the philosophy goes like this.",
                    "label": 0
                },
                {
                    "sent": "Suppose we run our perception and suddenly we make a mistake.",
                    "label": 0
                },
                {
                    "sent": "So if you want to add a vector, two are set to vectors we carry, we must first remove vector, so that's it.",
                    "label": 1
                },
                {
                    "sent": "So that's how we maintain the budget.",
                    "label": 0
                },
                {
                    "sent": "And there are four algorithms as far as I know for doing.",
                    "label": 0
                },
                {
                    "sent": "Perceptions on, but on a budget, and I will care about two of them which have formal guarantees, and these are the forget run and the randomized budget perception.",
                    "label": 0
                },
                {
                    "sent": "So I will explain these algorithms.",
                    "label": 0
                },
                {
                    "sent": "Right now there.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Very simple, so this is a simplified version of the forget run.",
                    "label": 0
                },
                {
                    "sent": "So in order to remove a vector we take a weight vector.",
                    "label": 0
                },
                {
                    "sent": "And scale it down.",
                    "label": 0
                },
                {
                    "sent": "And then we removed all this vector and then we add the vector image making mistake so.",
                    "label": 0
                },
                {
                    "sent": "Pictorially.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here is the weight vector we maintain.",
                    "label": 0
                },
                {
                    "sent": "Visit the mistakes in which we made, but notice that here X ends on the B and not on M because we don't carry more than vectors.",
                    "label": 0
                },
                {
                    "sent": "So the first vector which is so here let X 1B, the vector in which you made the last mistake.",
                    "label": 0
                },
                {
                    "sent": "So you'll have a high coefficient.",
                    "label": 0
                },
                {
                    "sent": "X2 will have a smaller coefficient because every time we scaled vector down extremely have an even smaller coefficient in absolute value, and the last vector will have a tiny coefficient.",
                    "label": 0
                },
                {
                    "sent": "If you make enough of if we have make a sufficient amount of the scaling down.",
                    "label": 0
                },
                {
                    "sent": "So here the hope is that if this is small enough, then by removing it we don't hurt performance a lot and at the same time if we scale things down only slightly, we don't hurt performance too much either.",
                    "label": 0
                },
                {
                    "sent": "So that's the idea here.",
                    "label": 0
                },
                {
                    "sent": "And this thing can be proved to work nearly as well as the best.",
                    "label": 0
                },
                {
                    "sent": "As is the best fixed hyperplane over normal certain size.",
                    "label": 0
                },
                {
                    "sent": "So this is the simplification, so I'll go over it again.",
                    "label": 0
                },
                {
                    "sent": "We scaled vector down, then we remove the vector with the.",
                    "label": 0
                },
                {
                    "sent": "Then we remove the X vector with the smallest weight and then we add the new vector which make the mistake.",
                    "label": 0
                },
                {
                    "sent": "So now this is the first algorithm which you care about.",
                    "label": 0
                },
                {
                    "sent": "The second algorithm should care about is the randomized.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "What is perception which says the following?",
                    "label": 0
                },
                {
                    "sent": "Suppose you want to add a vector to your.",
                    "label": 0
                },
                {
                    "sent": "Suppose we run the perception and we made a mistake.",
                    "label": 0
                },
                {
                    "sent": "So now we want to add a vector set.",
                    "label": 0
                },
                {
                    "sent": "So we need to remove something.",
                    "label": 0
                },
                {
                    "sent": "What do we remove?",
                    "label": 0
                },
                {
                    "sent": "We remove something, it's random, so it's really simple.",
                    "label": 0
                },
                {
                    "sent": "Just pick a vector, remove that random done, and now at the vector.",
                    "label": 0
                },
                {
                    "sent": "So this is the randomized perception.",
                    "label": 1
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here's how it looks like you have.",
                    "label": 0
                },
                {
                    "sent": "We have a.",
                    "label": 0
                },
                {
                    "sent": "We have the points, make mistakes and we carry only be of them and we just pick one at random and we removed.",
                    "label": 0
                },
                {
                    "sent": "Very simple.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Now, both of these algorithms have regret bounds which which relates the number of errors, the total number of errors they make to the hinge, loss of fixed linear classifier, plus some error terms, and I will state the regret bounds which I was able to prove using my technique which are very similar.",
                    "label": 0
                },
                {
                    "sent": "There are almost the same as the original regret bounds, just the technique is a bit different so.",
                    "label": 0
                },
                {
                    "sent": "The number of errors for the forget run or the expected number of errors for the randomized budget.",
                    "label": 1
                },
                {
                    "sent": "Perception is less than some constant of the hinge loss of some vector with the hinge loss is the hinge loss on all the examples on all the examples we've seen, plus some constant times the budget where.",
                    "label": 0
                },
                {
                    "sent": "Via competitive against vectors of order square root whose norm is of order square root of B for the randomized budget.",
                    "label": 0
                },
                {
                    "sent": "Perception and vector vectors of order square root of order whose norm is awarded square root of B over log before they forget run, which is also which is also the same as in the original results.",
                    "label": 0
                },
                {
                    "sent": "And now.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So far I told you existing stuff.",
                    "label": 0
                },
                {
                    "sent": "I didn't say anything you yet.",
                    "label": 0
                },
                {
                    "sent": "Everything that said so far was old results.",
                    "label": 0
                },
                {
                    "sent": "Now here is my.",
                    "label": 0
                },
                {
                    "sent": "Here is the main observation which relates these two algorithms.",
                    "label": 0
                },
                {
                    "sent": "And which makes it?",
                    "label": 0
                },
                {
                    "sent": "Which concept which makes it conceptually easy to prove the regret bounds?",
                    "label": 0
                },
                {
                    "sent": "So both algorithms here is the main here is if you forget everything, this is the slide you should remember.",
                    "label": 1
                },
                {
                    "sent": "Both algorithms follow the gradient of the hinge loss.",
                    "label": 0
                },
                {
                    "sent": "Of the errors plus L2 regularization.",
                    "label": 0
                },
                {
                    "sent": "Both algorithms follow the gradient plus different types of noise.",
                    "label": 0
                },
                {
                    "sent": "Specifically, the forget run has small deterministic noise in the gradient and the randomized budget perception has zero mean noise in the gradient, which is very structured and which is nothing like Gaussian noise for example.",
                    "label": 0
                },
                {
                    "sent": "But it doesn't matter this observation.",
                    "label": 0
                },
                {
                    "sent": "1st So this shows us in some sense where these algorithms are coming from.",
                    "label": 0
                },
                {
                    "sent": "Just different, we simply add different noise to L2 regularizer hinge losses.",
                    "label": 0
                },
                {
                    "sent": "That's the first thing.",
                    "label": 0
                },
                {
                    "sent": "The second thing.",
                    "label": 0
                },
                {
                    "sent": "We only run.",
                    "label": 0
                },
                {
                    "sent": "The only run, so this.",
                    "label": 0
                },
                {
                    "sent": "So here we are doing gradient descent on various on very different loss functions, but we only update the parameter whenever whenever we make a mistake.",
                    "label": 0
                },
                {
                    "sent": "If you don't make a mistake, we simply ignore the point.",
                    "label": 0
                },
                {
                    "sent": "So here's here's how both algorithms look like.",
                    "label": 0
                },
                {
                    "sent": "We run the perceptron and whenever and whenever we make a mistake we compute the grade.",
                    "label": 0
                },
                {
                    "sent": "The update of weight by following the gradient of this function.",
                    "label": 0
                },
                {
                    "sent": "Plus some kind of noise, that's it.",
                    "label": 0
                },
                {
                    "sent": "And now I will show you how using this.",
                    "label": 0
                },
                {
                    "sent": "Using this observation we can prove their regret bounds using Zinkevich theorem.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I'm.",
                    "label": 0
                },
                {
                    "sent": "So let's let's look at the simplified forget rent so they forget run.",
                    "label": 0
                },
                {
                    "sent": "So when I say simplified forget run, I mean that the constant factor by which we scale things down is always the same.",
                    "label": 0
                },
                {
                    "sent": "We just pick some number and scalar vector down by some number.",
                    "label": 0
                },
                {
                    "sent": "So this operation is what you get when you follow the gradient of an L2 regularization.",
                    "label": 0
                },
                {
                    "sent": "Because the gradient of an L2 regularization grows as your vector grows, this is simple.",
                    "label": 1
                },
                {
                    "sent": "This is small deterministic noise, because we expect that the constant by which we scale things down.",
                    "label": 0
                },
                {
                    "sent": "If it's small enough and B is large enough, then this thing is going to be pretty small, so this will be small deterministic noise.",
                    "label": 0
                },
                {
                    "sent": "Now this this term right here is the gradient of the hinge loss.",
                    "label": 1
                },
                {
                    "sent": "Whenever we make a mistake.",
                    "label": 0
                },
                {
                    "sent": "So whenever making mistake, the gradient of the change looks like this.",
                    "label": 0
                },
                {
                    "sent": "That's it, so therefore this justifies the fact that we forget run is in fact an instance of this algorithm.",
                    "label": 0
                },
                {
                    "sent": "Now let's go to the randomized budget.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Section in the randomized budget perception we also have to update the first updates, remove a support vector from the supports at random, and the 2nd update is updating is incorporating the new point.",
                    "label": 0
                },
                {
                    "sent": "So the new point is incorporated also, but is also the gradient of the hinge loss, so that's easy.",
                    "label": 0
                },
                {
                    "sent": "It's exactly like before.",
                    "label": 0
                },
                {
                    "sent": "If you take the hinge loss on the points we mistakenly differentiate it, we will get this kind of gradient.",
                    "label": 0
                },
                {
                    "sent": "But now.",
                    "label": 0
                },
                {
                    "sent": "What I claim which, which is also very simple, is that if you remove a support vector at random, this is like we remove W / B plus some noise.",
                    "label": 0
                },
                {
                    "sent": "So basically here is what I claim when we do the randomized, But the randomized budget perception is following the gradient of the hinge loss plus an L2 regularization plus some noise.",
                    "label": 1
                },
                {
                    "sent": "Here is the reason.",
                    "label": 0
                },
                {
                    "sent": "When we remove a support vector at random, we can just ask.",
                    "label": 0
                },
                {
                    "sent": "You could ask us what's the average thing we remove and the average.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "You remove can be seen to be equal to W / B.",
                    "label": 1
                },
                {
                    "sent": "So if you have so if W is the sum of the terms.",
                    "label": 0
                },
                {
                    "sent": "And we pick a term.",
                    "label": 0
                },
                {
                    "sent": "It's random than expected value of a term is just W Overby becausw.",
                    "label": 0
                },
                {
                    "sent": "The expectation is the sum over all possibilities times the probability and the sum of all these things is just W. So this is it.",
                    "label": 0
                },
                {
                    "sent": "This is the second important observation.",
                    "label": 0
                },
                {
                    "sent": "It's not complicated at all.",
                    "label": 0
                },
                {
                    "sent": "It's simple.",
                    "label": 0
                },
                {
                    "sent": "I want I want it to be understood by everyone.",
                    "label": 0
                },
                {
                    "sent": "That in the randomized budget perception, when you remove a support vector at random, we are following an unbiased estimate of the gradient of an L2 regularization, so that's it.",
                    "label": 0
                },
                {
                    "sent": "This is.",
                    "label": 0
                },
                {
                    "sent": "The this is this is the justification for the observation and now I will outline the way in which I apply Zinkevich theorem and a version of it in order.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Regret bounds.",
                    "label": 0
                },
                {
                    "sent": "So Zinkevich theorem tells us that if we have a sequence of functions and we do gradient descent, then the performance of our algorithm will be nearly as good as the performance of any fixed point inside.",
                    "label": 0
                },
                {
                    "sent": "So in other words, if you run if you do online gradient descent on these functions, LM on our errors, then the total loss we will experience will be compara bulto the loss of any fixed weight that may know all the examples even after they were given.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So if we apply it, we get a bound that looks like this.",
                    "label": 0
                },
                {
                    "sent": "We can say that our algorithm, which is what I said right now, the performance of our algorithm.",
                    "label": 0
                },
                {
                    "sent": "So by the way, I should point out in case you forgot that LM is the hinge loss of the EMS example with W M + L two regularization.",
                    "label": 0
                },
                {
                    "sent": "So the performance of our algorithm on this function is less than the performance of anything fixed plus some term which which is called the regret.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "I can I have a slide for that.",
                    "label": 0
                },
                {
                    "sent": "It's bit long, but.",
                    "label": 0
                },
                {
                    "sent": "How much time do I have?",
                    "label": 0
                },
                {
                    "sent": "5 minutes.",
                    "label": 0
                },
                {
                    "sent": "You know, OK, fine.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "That's good, so I'll just spend one minute Zinkevich theorem says that if you have a sequence of convex functions, if you have a sequence of convex functions and if we do online gradient descent on these functions.",
                    "label": 1
                },
                {
                    "sent": "Then the loss over us and let Xanna let the axis be the sequence of gradient points, which we do.",
                    "label": 0
                },
                {
                    "sent": "Then the loss that our algorithm within the total loss feature algorithm experiences is less than the loss of anything fixed in advance plus some error term which depends on various parameters.",
                    "label": 0
                },
                {
                    "sent": "But basically it says that if you do online, if you do online learning but you don't know the sequence of functions, you can relate your performance to the performance of something which knows all the functions in advance but is not allowed to change on every function.",
                    "label": 0
                },
                {
                    "sent": "So I will now I want to outline how I play.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The how apply Zinkevich theorem to be forgetful.",
                    "label": 0
                },
                {
                    "sent": "So I just say one thing and then forget run.",
                    "label": 0
                },
                {
                    "sent": "We have errors in the gradient, but it's very easy to take the proof of Sienkiewicz theorem to run it with errors in the gradient and you get an extra term in the regret, but it's very easy.",
                    "label": 0
                },
                {
                    "sent": "It works out just fine.",
                    "label": 0
                },
                {
                    "sent": "So what we get is the following by applying Sienkiewicz theorem we get the loss of our algorithm.",
                    "label": 0
                },
                {
                    "sent": "So OK here's what I'll do.",
                    "label": 0
                },
                {
                    "sent": "I will take Sienkiewicz theorem and I'll apply it only on the functions on the hinge.",
                    "label": 0
                },
                {
                    "sent": "Loss is on which I make a mistake.",
                    "label": 0
                },
                {
                    "sent": "If I don't make a mistake I don't update my parameters technology functions.",
                    "label": 0
                },
                {
                    "sent": "Now I take this sum.",
                    "label": 0
                },
                {
                    "sent": "The performance of my algorithm is smaller than the performance of anything fixed, which is not too large, and now this is a parameter I don't tell you how large how large vectors allowed to be now, because this is the hinge loss of a pawn, a mistake.",
                    "label": 0
                },
                {
                    "sent": "Then it's bigger than one.",
                    "label": 0
                },
                {
                    "sent": "This is Lt regular exchange loss and if it's and if it makes a mistake is bigger than one.",
                    "label": 0
                },
                {
                    "sent": "Therefore the sum of all the mistakes is going to be bigger than the number of mistakes.",
                    "label": 0
                },
                {
                    "sent": "This is a famous trick.",
                    "label": 0
                },
                {
                    "sent": "If you seen this examples where the hinge loss is bigger than zero, one more.",
                    "label": 0
                },
                {
                    "sent": "So that's exactly what's going on.",
                    "label": 0
                },
                {
                    "sent": "So the number of mistakes is less than the total.",
                    "label": 0
                },
                {
                    "sent": "Then the total Lt regularization loss and now we get that this is less than something which depends on the L2 regularization loss of a competing vector, and we will get a factor of EM on the right hand side.",
                    "label": 0
                },
                {
                    "sent": "So we just need to tweak the parameters to make sure that the constant factor next to me here is smaller than one.",
                    "label": 1
                },
                {
                    "sent": "If the constant factor next to me here is smaller than one, then we can pull them to this side and we get that M times some constant is less than the hinge loss of W plus some other terms, and that's it.",
                    "label": 0
                },
                {
                    "sent": "And this is what we do.",
                    "label": 0
                },
                {
                    "sent": "Forget run now for the random.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "What is perception?",
                    "label": 0
                },
                {
                    "sent": "We do something slightly differently, which is a trick from.",
                    "label": 0
                },
                {
                    "sent": "A paper by.",
                    "label": 0
                },
                {
                    "sent": "Flaxman, Tom and Kelly and mcmane.",
                    "label": 0
                },
                {
                    "sent": "When we say the following here, this is a randomized perception, slightly more complicated because we have noise and the set of X make mistakes is different every time.",
                    "label": 0
                },
                {
                    "sent": "So what we do is what they do is really nice trick.",
                    "label": 0
                },
                {
                    "sent": "They say let us add noise to the functions so that doing gradient descent to the noisy functions exactly like doing gradient descent of the normal functions plus noise.",
                    "label": 1
                },
                {
                    "sent": "And then we apply Sinkovich theorem on the noisy functions an average and it works out.",
                    "label": 0
                },
                {
                    "sent": "And finally I will say one last point.",
                    "label": 0
                },
                {
                    "sent": "But we.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Makes it so think of each singular motions of variance for tracking.",
                    "label": 0
                },
                {
                    "sent": "In other words, think of this theorem is not only competitive against a fixed vector, but it's also competitive against the sequence of slowly changing vectors.",
                    "label": 1
                },
                {
                    "sent": "So if you say I want to be, I want my algorithm to perform as well as something that changes as long as the change is not very large and the learning rate is not very small, then we will also get regret bound and the proof is also very easy, just takes encouraged them and look at the proof and we had some terms and it all works out.",
                    "label": 0
                },
                {
                    "sent": "The no thinking is required, we just we just do a straightforward derivation and by using the tracking variant.",
                    "label": 0
                },
                {
                    "sent": "We can get bounds for the both the forgotten and the randomized budget perception, which are competitive not against the single fixed hypothesis, but against a sequence of lowering hypothesis and other.",
                    "label": 1
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Finish here, thank you.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Impression.",
                    "label": 0
                },
                {
                    "sent": "I have a yes.",
                    "label": 0
                },
                {
                    "sent": "From applying your technique to more sophisticated budget algorithms.",
                    "label": 0
                },
                {
                    "sent": "Probably so it depends on algorithm, but as long if you have applied.",
                    "label": 0
                },
                {
                    "sent": "Because they are more expensive in terms of the number of.",
                    "label": 0
                },
                {
                    "sent": "Super vectors, so I didn't.",
                    "label": 0
                },
                {
                    "sent": "I'm not familiar with these algorithms, but if as long as you can say as long as you can express the second or algorithm as something which is where you follow the gradient of something nice, like an L2 regularization, regularization or something else which which we know and we can say well, what we really do is this gradient plus some noise whether it's deterministic and stochastic.",
                    "label": 0
                },
                {
                    "sent": "Then we can definitely apply this technique.",
                    "label": 0
                },
                {
                    "sent": "It has to be a great yes, so as long as you can relate your algorithm to gradient descent scheme you can immediately.",
                    "label": 0
                },
                {
                    "sent": "Immediately apply this idea.",
                    "label": 0
                },
                {
                    "sent": "And it kind of you can have both stochastic indeterminacy approximation.",
                    "label": 0
                },
                {
                    "sent": "Zinkevich theorem is very robust.",
                    "label": 0
                },
                {
                    "sent": "Questions.",
                    "label": 0
                },
                {
                    "sent": "So let's thank the speaker.",
                    "label": 0
                }
            ]
        }
    }
}