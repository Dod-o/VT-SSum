{
    "id": "dqekjjqqansd42eap6325pkihbk5w2tr",
    "title": "Dense 3D Face Alignment from 2D Videos in Real-Time",
    "info": {
        "author": [
            "Laszlo Attila Jeni, Robotics Institute, School of Computer Science, Carnegie Mellon University"
        ],
        "published": "July 2, 2015",
        "recorded": "May 2015",
        "category": [
            "Top->Computer Science->Computer Vision",
            "Top->Computer Science->Computer Vision->Face & Gesture Analysis"
        ]
    },
    "url": "http://videolectures.net/fgconference2015_jeni_2d_videos/",
    "segmentation": [
        [
            "Good afternoon everyone.",
            "My name is Leslie.",
            "I'm with the Carnegie Mellon University.",
            "And I will be presenting a new face alignment method, 3D dance face lineman from 2D videos in real time.",
            "Mike Walters are Jeffrey F, Co and Tokyo, Canada."
        ],
        [
            "Let's start face alignment is a problem automatically locating a detailed facial landmarks across different subjects, illuminations and viewpoints.",
            "Previous methods can be divided into 2 broad categories, two based method, 2D based network locator, relatively small number of 2D fiducial points in real time, while 3D based methods fit our high resolution 3D model offline at a much higher computational cost and usually require manual initialization.",
            "In the last few years, in particular, 2D methods has reached a mature state with the emergence of discriminative shape regression methods.",
            "And most previous work has emphasized only two D face tracking and registration.",
            "Relatively neglected.",
            "This application of these cascade methods for dense 3D face alignment."
        ],
        [
            "Our method takes or single to the image of a person's face and registers so dense 3D shape in real time.",
            "For each frame.",
            "The algorithm used utilizes fast cascade regression framework, train on high resolution 3D face cancel or posed an spontaneous emotional expressions.",
            "The algorithm first estimates location of a dense set of markers and their visibility and then reconstruct the face shapes by fitting apart based 3D model.",
            "Because no, no assumptions are required about the illumination or the surface properties.",
            "The method can be applied in a wide.",
            "Range of imaging conditions that include two DVD or or multiview video."
        ],
        [
            "First, I'd like to talk about the model building process."
        ],
        [
            "We are interested in building a dense linear shape model.",
            "The shape model is defined by our 3D mesh, and in particular the 3D vertex locations of the mesh.",
            "We call these landmarks.",
            "We can assume that apart from scaling, rotation and translation, all the samples can be approximated by means of a linear subspace.",
            "There are 3D point distribution model that you can see on the top row describes this nonrigid shape variations and linearly.",
            "And composes it with our global rigid transformation, placing the shape in the image frame.",
            "One can assume that.",
            "The prior of these parameters can follow a normal distribution and can apply a PCA principal component analyzes to calculate this linear subspace.",
            "This approach has been used successfully in a broad range of face alignment techniques such as active appearance models or 3D morphable models.",
            "The procedure would risk result in a holistic shape model with a high compression rate, but on the other hand it's components has a global reach and a lack of semantic meaning."
        ],
        [
            "So instead of the holistic model, we propose a different method.",
            "We can categorize the deformation on the face into two separate subsets.",
            "One of them is Arrearages subset that can describe the shape of the face and only just subset that would.",
            "Describe the facial expressions so you can see the original model on the top and a holistic part based model on the bottom to build such a linear subspace that describes the expression, the formation we follow the method of Tenno at all.",
            "The goal is to build a model that is composed of a collection of PCA part models that are independent with trained and shares of boundaries.",
            "The model generalizes to unseen data better.",
            "Then the traditional holistic approaches so you can see that instead of 1 subspace, we have two separate subspace, one of them handling the phase shift variations.",
            "The other deals with the expressions."
        ],
        [
            "The method was made possible in part by training on 2 high resolution 3D datasets.",
            "The BP for the interview 3D datasets.",
            "Together they can't consist more than 300,000 in high resolution face scans.",
            "That 3D models ranging resolution between 30 to 50,000 vertexes and for each sequence in the BP 40 has been faxed coded by expert coders.",
            "For the training we selected 3000 frames from each data set, so 6000 in total.",
            "In their view, for DV uniformly sampled sequences in the BP 4 DV, used effects code 2 effects quotes provided with the data set to include a wide variety of expressions.",
            "Some of these 3D meshes in the two datasets were corrupted or noisy.",
            "We manually inspected these, remove them from the training set."
        ],
        [
            "Usually most of the face alignment techniques.",
            "The annotation is done using 2D images.",
            "When the annotator selects the locations of fiducial points around permanent facial features, for example, four frontal faces are reliable.",
            "Annotation can be achieved.",
            "You can see it for example on the left side.",
            "But as the first orientation varies from full frontal harbor annotation points, lose the correspondence pose variation results in self occlusion that confines landmark annotation.",
            "For example, consider the juline points and some of the eyebrow markers.",
            "If you're a noted, these images in 2D, those points won't correspond to the same locations on their face.",
            "Which increase in growth with increasing rotations and also see it as self occlusion annotations no longer correspond to the same landmarks.",
            "This issue can be alleviated by using 3D face scans and on rotating the 3D face scans them self instead of the 2D images."
        ],
        [
            "We selected the 6000 images annotated manually, then bit 77 landmarks corresponding to facial fiducial points.",
            "You can see the template on the left side and the core set of markers has the same semantic meaning across all the subjects and expressions.",
            "Here we can see the annotated annotated measures with the annotated markers and the corresponding depth Maps.",
            "Since the annotation is completely in 3D, we can identify self included.",
            "Markers from every pose."
        ],
        [
            "And we are interested in a model where we can easily control the level of detail of the 3D mesh.",
            "To build such a Model, V employed coarse to fine mesh refinement method that kind of resembles a square root 3 subdivision scheme.",
            "We started from reference shippan triangulate at 77 point mesh.",
            "Since this annotation corresponds to fiducial points an not based on uniform sampling or surface complexity.",
            "Applying the original subdivision food result, unnecessary details are on those points.",
            "Therefore, in every step we apply the sub.",
            "The subdivision only on the triangle with the larger surface area.",
            "And project the centroid back on the dance mash.",
            "This procedure results in a tessellation with all the vertices are evenly distributed on the surface.",
            "Follow the original geometry and the level of details can be easily managed since we are adding more than more vertices to the mesh."
        ],
        [
            "Another problem with the training samples is the semantic correspondence between them.",
            "While this core set of manually annotated markers has the same semantic meaning, actual subject as X and the expressions to create a dense model.",
            "That spans the date of multiple subjects and requires establishing a dense point to point correspondence.",
            "So for example, in this case the eye corners, mouth corners and these markers are beer with all the same semantic meaning across all the subjects."
        ],
        [
            "However, we need a dense correspondence between them.",
            "There's many methods to achieve this.",
            "This study we used our new.",
            "Shape feature descriptor called Wave kernel signature."
        ],
        [
            "This.",
            "This is to share based descriptors so we are not using any appearance features.",
            "We are using only the 3D Surface properties to match these landmarks across subjects and expressions and after we have these correspondence we can build or linear face model.",
            "To talk about the bit about the model fitting."
        ],
        [
            "We need for the training data sets.",
            "So far I thought about the 3D measures, however the automatic face alignment requires a large number of training.",
            "Examples of annotated images.",
            "We use the three to 6000 annotated measures.",
            "From each mesh, we generate a 63 different views in 20 degrees of your rotations and 50 degrees of pitch rotations, resulting more than 300,000 images.",
            "For each view we can calculate the corresponding rotated 3D markers and the 3D projections with self occlusions.",
            "I just show up.",
            "Process of."
        ],
        [
            "The alignment process.",
            "So we start from a single to the image in the beginning.",
            "And we use a Viola Jones face detector to find the face on the image and this bounding box will provide the initial configuration of the landmarks so you can see this parse template landmarks.",
            "And we extract binary features are on these landmarks.",
            "And finally, never regress or matrix sequences that move these landmarks to the ground locations.",
            "And as you can see in four steps, it converges to the right location.",
            "Sometimes the process is noisy.",
            "This can be alleviated with begging and after the alignment the feed the high resolution 3D model on these markers that refines the 3D pose and the 3D shape of the face.",
            "The result is a high resolution 3D dense mesh that can be used for analyzes or synthesis.",
            "Purposes.",
            "And I just sure short the tracking video.",
            "As you can see, the fitting is really smooth.",
            "Sometimes it can fail on the juline area, but.",
            "Most of the times it's.",
            "Really precise.",
            "So."
        ],
        [
            "I like to highlight only one part of the features and these are the binary features.",
            "Binary features has the main computation order advantage that they are really compact and really fast.",
            "That's why we are using it several magnitudes faster than SIFT or Hog features."
        ],
        [
            "But I like to show a couple of experiments."
        ],
        [
            "We did experiments with different feature spaces.",
            "We compare Sift features with the binary features with different markers.",
            "As you can see, after you can see on the X axis the number of cascades required for the fitting.",
            "You can see over four or five cascades.",
            "The method saturates and reached a plateau.",
            "Binary features slightly better than SIFT features in this case."
        ],
        [
            "Another quest."
        ],
        [
            "Is the level of the detail of the 3D image what level of detail would we need?",
            "You can see on the top row the measures that 3D meshes with different level of details 77, marker two 1000 markers and you can see the differences between the ground truth mesh and the reconstructed mesh.",
            "You can see as the level of detail increases, we get a much more."
        ],
        [
            "Precise reconstruction, you can see the same here over 1000 vertices.",
            "There's no more gain in the reconstruction.",
            "On the left side."
        ],
        [
            "You can see a single view reconstruction.",
            "In this case we only hallucinating a 3D shape per frame.",
            "You can see the number of observed verticals and we can see that we don't need to measure more than 200 vertices to a precise reconstruction.",
            "And their methods quickly converges to a lower error recognition and on the right side you can see the multiview reconstruction where we are using multiple views.",
            "If you are using for example 45 degrees profile view image, the reconstruction error is much lower than the single image based recognition."
        ],
        [
            "I like to conclude the talk.",
            "So basically we presented a method that works in using 2D images and reconstructor dense 3D mesh algorithm estimates are set of markers, an fit support based 3D model on it."
        ],
        [
            "We also have our demo session today later.",
            "Please stop by a tour desk and you can try the real time demo and the software will be available online on the website.",
            "Thank you very much."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Good afternoon everyone.",
                    "label": 0
                },
                {
                    "sent": "My name is Leslie.",
                    "label": 0
                },
                {
                    "sent": "I'm with the Carnegie Mellon University.",
                    "label": 0
                },
                {
                    "sent": "And I will be presenting a new face alignment method, 3D dance face lineman from 2D videos in real time.",
                    "label": 1
                },
                {
                    "sent": "Mike Walters are Jeffrey F, Co and Tokyo, Canada.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Let's start face alignment is a problem automatically locating a detailed facial landmarks across different subjects, illuminations and viewpoints.",
                    "label": 0
                },
                {
                    "sent": "Previous methods can be divided into 2 broad categories, two based method, 2D based network locator, relatively small number of 2D fiducial points in real time, while 3D based methods fit our high resolution 3D model offline at a much higher computational cost and usually require manual initialization.",
                    "label": 1
                },
                {
                    "sent": "In the last few years, in particular, 2D methods has reached a mature state with the emergence of discriminative shape regression methods.",
                    "label": 0
                },
                {
                    "sent": "And most previous work has emphasized only two D face tracking and registration.",
                    "label": 0
                },
                {
                    "sent": "Relatively neglected.",
                    "label": 0
                },
                {
                    "sent": "This application of these cascade methods for dense 3D face alignment.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Our method takes or single to the image of a person's face and registers so dense 3D shape in real time.",
                    "label": 0
                },
                {
                    "sent": "For each frame.",
                    "label": 0
                },
                {
                    "sent": "The algorithm used utilizes fast cascade regression framework, train on high resolution 3D face cancel or posed an spontaneous emotional expressions.",
                    "label": 0
                },
                {
                    "sent": "The algorithm first estimates location of a dense set of markers and their visibility and then reconstruct the face shapes by fitting apart based 3D model.",
                    "label": 0
                },
                {
                    "sent": "Because no, no assumptions are required about the illumination or the surface properties.",
                    "label": 0
                },
                {
                    "sent": "The method can be applied in a wide.",
                    "label": 0
                },
                {
                    "sent": "Range of imaging conditions that include two DVD or or multiview video.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "First, I'd like to talk about the model building process.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We are interested in building a dense linear shape model.",
                    "label": 0
                },
                {
                    "sent": "The shape model is defined by our 3D mesh, and in particular the 3D vertex locations of the mesh.",
                    "label": 0
                },
                {
                    "sent": "We call these landmarks.",
                    "label": 0
                },
                {
                    "sent": "We can assume that apart from scaling, rotation and translation, all the samples can be approximated by means of a linear subspace.",
                    "label": 0
                },
                {
                    "sent": "There are 3D point distribution model that you can see on the top row describes this nonrigid shape variations and linearly.",
                    "label": 0
                },
                {
                    "sent": "And composes it with our global rigid transformation, placing the shape in the image frame.",
                    "label": 0
                },
                {
                    "sent": "One can assume that.",
                    "label": 0
                },
                {
                    "sent": "The prior of these parameters can follow a normal distribution and can apply a PCA principal component analyzes to calculate this linear subspace.",
                    "label": 0
                },
                {
                    "sent": "This approach has been used successfully in a broad range of face alignment techniques such as active appearance models or 3D morphable models.",
                    "label": 0
                },
                {
                    "sent": "The procedure would risk result in a holistic shape model with a high compression rate, but on the other hand it's components has a global reach and a lack of semantic meaning.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So instead of the holistic model, we propose a different method.",
                    "label": 0
                },
                {
                    "sent": "We can categorize the deformation on the face into two separate subsets.",
                    "label": 0
                },
                {
                    "sent": "One of them is Arrearages subset that can describe the shape of the face and only just subset that would.",
                    "label": 0
                },
                {
                    "sent": "Describe the facial expressions so you can see the original model on the top and a holistic part based model on the bottom to build such a linear subspace that describes the expression, the formation we follow the method of Tenno at all.",
                    "label": 1
                },
                {
                    "sent": "The goal is to build a model that is composed of a collection of PCA part models that are independent with trained and shares of boundaries.",
                    "label": 0
                },
                {
                    "sent": "The model generalizes to unseen data better.",
                    "label": 0
                },
                {
                    "sent": "Then the traditional holistic approaches so you can see that instead of 1 subspace, we have two separate subspace, one of them handling the phase shift variations.",
                    "label": 0
                },
                {
                    "sent": "The other deals with the expressions.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The method was made possible in part by training on 2 high resolution 3D datasets.",
                    "label": 0
                },
                {
                    "sent": "The BP for the interview 3D datasets.",
                    "label": 0
                },
                {
                    "sent": "Together they can't consist more than 300,000 in high resolution face scans.",
                    "label": 0
                },
                {
                    "sent": "That 3D models ranging resolution between 30 to 50,000 vertexes and for each sequence in the BP 40 has been faxed coded by expert coders.",
                    "label": 0
                },
                {
                    "sent": "For the training we selected 3000 frames from each data set, so 6000 in total.",
                    "label": 0
                },
                {
                    "sent": "In their view, for DV uniformly sampled sequences in the BP 4 DV, used effects code 2 effects quotes provided with the data set to include a wide variety of expressions.",
                    "label": 0
                },
                {
                    "sent": "Some of these 3D meshes in the two datasets were corrupted or noisy.",
                    "label": 0
                },
                {
                    "sent": "We manually inspected these, remove them from the training set.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Usually most of the face alignment techniques.",
                    "label": 0
                },
                {
                    "sent": "The annotation is done using 2D images.",
                    "label": 0
                },
                {
                    "sent": "When the annotator selects the locations of fiducial points around permanent facial features, for example, four frontal faces are reliable.",
                    "label": 0
                },
                {
                    "sent": "Annotation can be achieved.",
                    "label": 0
                },
                {
                    "sent": "You can see it for example on the left side.",
                    "label": 0
                },
                {
                    "sent": "But as the first orientation varies from full frontal harbor annotation points, lose the correspondence pose variation results in self occlusion that confines landmark annotation.",
                    "label": 0
                },
                {
                    "sent": "For example, consider the juline points and some of the eyebrow markers.",
                    "label": 0
                },
                {
                    "sent": "If you're a noted, these images in 2D, those points won't correspond to the same locations on their face.",
                    "label": 0
                },
                {
                    "sent": "Which increase in growth with increasing rotations and also see it as self occlusion annotations no longer correspond to the same landmarks.",
                    "label": 0
                },
                {
                    "sent": "This issue can be alleviated by using 3D face scans and on rotating the 3D face scans them self instead of the 2D images.",
                    "label": 1
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We selected the 6000 images annotated manually, then bit 77 landmarks corresponding to facial fiducial points.",
                    "label": 0
                },
                {
                    "sent": "You can see the template on the left side and the core set of markers has the same semantic meaning across all the subjects and expressions.",
                    "label": 0
                },
                {
                    "sent": "Here we can see the annotated annotated measures with the annotated markers and the corresponding depth Maps.",
                    "label": 0
                },
                {
                    "sent": "Since the annotation is completely in 3D, we can identify self included.",
                    "label": 0
                },
                {
                    "sent": "Markers from every pose.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And we are interested in a model where we can easily control the level of detail of the 3D mesh.",
                    "label": 0
                },
                {
                    "sent": "To build such a Model, V employed coarse to fine mesh refinement method that kind of resembles a square root 3 subdivision scheme.",
                    "label": 0
                },
                {
                    "sent": "We started from reference shippan triangulate at 77 point mesh.",
                    "label": 0
                },
                {
                    "sent": "Since this annotation corresponds to fiducial points an not based on uniform sampling or surface complexity.",
                    "label": 0
                },
                {
                    "sent": "Applying the original subdivision food result, unnecessary details are on those points.",
                    "label": 0
                },
                {
                    "sent": "Therefore, in every step we apply the sub.",
                    "label": 0
                },
                {
                    "sent": "The subdivision only on the triangle with the larger surface area.",
                    "label": 0
                },
                {
                    "sent": "And project the centroid back on the dance mash.",
                    "label": 1
                },
                {
                    "sent": "This procedure results in a tessellation with all the vertices are evenly distributed on the surface.",
                    "label": 0
                },
                {
                    "sent": "Follow the original geometry and the level of details can be easily managed since we are adding more than more vertices to the mesh.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Another problem with the training samples is the semantic correspondence between them.",
                    "label": 0
                },
                {
                    "sent": "While this core set of manually annotated markers has the same semantic meaning, actual subject as X and the expressions to create a dense model.",
                    "label": 0
                },
                {
                    "sent": "That spans the date of multiple subjects and requires establishing a dense point to point correspondence.",
                    "label": 0
                },
                {
                    "sent": "So for example, in this case the eye corners, mouth corners and these markers are beer with all the same semantic meaning across all the subjects.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "However, we need a dense correspondence between them.",
                    "label": 0
                },
                {
                    "sent": "There's many methods to achieve this.",
                    "label": 0
                },
                {
                    "sent": "This study we used our new.",
                    "label": 0
                },
                {
                    "sent": "Shape feature descriptor called Wave kernel signature.",
                    "label": 1
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This.",
                    "label": 0
                },
                {
                    "sent": "This is to share based descriptors so we are not using any appearance features.",
                    "label": 0
                },
                {
                    "sent": "We are using only the 3D Surface properties to match these landmarks across subjects and expressions and after we have these correspondence we can build or linear face model.",
                    "label": 0
                },
                {
                    "sent": "To talk about the bit about the model fitting.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We need for the training data sets.",
                    "label": 0
                },
                {
                    "sent": "So far I thought about the 3D measures, however the automatic face alignment requires a large number of training.",
                    "label": 0
                },
                {
                    "sent": "Examples of annotated images.",
                    "label": 0
                },
                {
                    "sent": "We use the three to 6000 annotated measures.",
                    "label": 0
                },
                {
                    "sent": "From each mesh, we generate a 63 different views in 20 degrees of your rotations and 50 degrees of pitch rotations, resulting more than 300,000 images.",
                    "label": 0
                },
                {
                    "sent": "For each view we can calculate the corresponding rotated 3D markers and the 3D projections with self occlusions.",
                    "label": 0
                },
                {
                    "sent": "I just show up.",
                    "label": 0
                },
                {
                    "sent": "Process of.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The alignment process.",
                    "label": 0
                },
                {
                    "sent": "So we start from a single to the image in the beginning.",
                    "label": 0
                },
                {
                    "sent": "And we use a Viola Jones face detector to find the face on the image and this bounding box will provide the initial configuration of the landmarks so you can see this parse template landmarks.",
                    "label": 0
                },
                {
                    "sent": "And we extract binary features are on these landmarks.",
                    "label": 0
                },
                {
                    "sent": "And finally, never regress or matrix sequences that move these landmarks to the ground locations.",
                    "label": 0
                },
                {
                    "sent": "And as you can see in four steps, it converges to the right location.",
                    "label": 0
                },
                {
                    "sent": "Sometimes the process is noisy.",
                    "label": 0
                },
                {
                    "sent": "This can be alleviated with begging and after the alignment the feed the high resolution 3D model on these markers that refines the 3D pose and the 3D shape of the face.",
                    "label": 0
                },
                {
                    "sent": "The result is a high resolution 3D dense mesh that can be used for analyzes or synthesis.",
                    "label": 0
                },
                {
                    "sent": "Purposes.",
                    "label": 0
                },
                {
                    "sent": "And I just sure short the tracking video.",
                    "label": 0
                },
                {
                    "sent": "As you can see, the fitting is really smooth.",
                    "label": 0
                },
                {
                    "sent": "Sometimes it can fail on the juline area, but.",
                    "label": 0
                },
                {
                    "sent": "Most of the times it's.",
                    "label": 0
                },
                {
                    "sent": "Really precise.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I like to highlight only one part of the features and these are the binary features.",
                    "label": 0
                },
                {
                    "sent": "Binary features has the main computation order advantage that they are really compact and really fast.",
                    "label": 0
                },
                {
                    "sent": "That's why we are using it several magnitudes faster than SIFT or Hog features.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But I like to show a couple of experiments.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We did experiments with different feature spaces.",
                    "label": 0
                },
                {
                    "sent": "We compare Sift features with the binary features with different markers.",
                    "label": 0
                },
                {
                    "sent": "As you can see, after you can see on the X axis the number of cascades required for the fitting.",
                    "label": 0
                },
                {
                    "sent": "You can see over four or five cascades.",
                    "label": 0
                },
                {
                    "sent": "The method saturates and reached a plateau.",
                    "label": 0
                },
                {
                    "sent": "Binary features slightly better than SIFT features in this case.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Another quest.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is the level of the detail of the 3D image what level of detail would we need?",
                    "label": 0
                },
                {
                    "sent": "You can see on the top row the measures that 3D meshes with different level of details 77, marker two 1000 markers and you can see the differences between the ground truth mesh and the reconstructed mesh.",
                    "label": 0
                },
                {
                    "sent": "You can see as the level of detail increases, we get a much more.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Precise reconstruction, you can see the same here over 1000 vertices.",
                    "label": 0
                },
                {
                    "sent": "There's no more gain in the reconstruction.",
                    "label": 0
                },
                {
                    "sent": "On the left side.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You can see a single view reconstruction.",
                    "label": 0
                },
                {
                    "sent": "In this case we only hallucinating a 3D shape per frame.",
                    "label": 0
                },
                {
                    "sent": "You can see the number of observed verticals and we can see that we don't need to measure more than 200 vertices to a precise reconstruction.",
                    "label": 0
                },
                {
                    "sent": "And their methods quickly converges to a lower error recognition and on the right side you can see the multiview reconstruction where we are using multiple views.",
                    "label": 0
                },
                {
                    "sent": "If you are using for example 45 degrees profile view image, the reconstruction error is much lower than the single image based recognition.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I like to conclude the talk.",
                    "label": 0
                },
                {
                    "sent": "So basically we presented a method that works in using 2D images and reconstructor dense 3D mesh algorithm estimates are set of markers, an fit support based 3D model on it.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We also have our demo session today later.",
                    "label": 0
                },
                {
                    "sent": "Please stop by a tour desk and you can try the real time demo and the software will be available online on the website.",
                    "label": 0
                },
                {
                    "sent": "Thank you very much.",
                    "label": 0
                }
            ]
        }
    }
}