{
    "id": "inpdpj3ddvgrdvnwut4hqzsjzh7cxfdn",
    "title": "Universal Artificial Intelligence",
    "info": {
        "author": [
            "Marcus Hutter, Australian National University"
        ],
        "published": "April 1, 2009",
        "recorded": "February 2009",
        "category": [
            "Top->Computer Science->Artificial Intelligence"
        ]
    },
    "url": "http://videolectures.net/ssll09_hutter_uai/",
    "segmentation": [
        [
            "OK, welcome to the last lecture for the Machine Learning Summer School.",
            "I hope you had fun so far because now it ends.",
            "I know.",
            "OK, we're in the eye part here and.",
            "So there should be logicians here, and machine learners, and in this lecture, so you have heard you know a lot about artificial intelligence now and machine learning and pure logic and logic.",
            "This is relevant or related to AI.",
            "And.",
            "This lecture is about first stepping back and thinking about the philosophical foundations of AI.",
            "And then I come to a theory which is in a mathematical sense a complete theory of AI.",
            "I mean, you have seen all these bits and pieces of it.",
            "I understand, I mean this or this or that.",
            "So is there an overall overarching say, not framework, but real definition like in many other fields?",
            "I mean, for instance a simple example like playing a 0 sum game you all know Mini Max to the end.",
            "Probably have heard that is the optimal strategy.",
            "Index it OK. Now you can start and you know build touristics and derive more efficient algorithms, but you know where to start from.",
            "And 2nd third of our about this of this lecture is about is there such a general definition?",
            "And for general agents, not just for 0 sum games but more general.",
            "OK, so here's a."
        ],
        [
            "Overview slide I guess we don't have a pointer again.",
            "Anybody having a laser pointer?",
            "Sorry.",
            "Yeah, that's the last option.",
            "I know.",
            "OK, use the internal mouse.",
            "Even worse, OK.",
            "Locked.",
            "OK, I think I get the mouse for the second hour.",
            "OK, so here's an overview slide.",
            "If you don't get it, no problem.",
            "I present exactly the same slide at the end of the three hours and hopefully then everything is clear.",
            "OK, so the general setup is for prediction and the last into last extent I will talk about prediction.",
            "Predicting the future is important part for being able to act intelligently.",
            "And you first have to understand this and then I come to the action part.",
            "So for prediction.",
            "What you have is you have a sequence of data like weather data, Sun, Sun, Sun, Sun, Sun, Sun, maybe sometimes rain, sun, sun, sun.",
            "What is the weather tomorrow?",
            "The ultimate goal is actually usually not the prediction itself.",
            "But it is a purpose, and the purpose is either to maximize your profit or your happiness or your minimize your loss or something like that.",
            "In most frameworks what you do is you start with a class of hypothesis.",
            "Where the data could be drawn from.",
            "And statistically, you have a likelihood that the probability of your data given the different hypothesis.",
            "And one estimate would be the maximum likelihood.",
            "You just take the hypothesis, yeah, which by definition maximizes likelihood.",
            "OK, that's a reasonable principle.",
            "For simple cases, the problem is if your model class is too large it overfits and it won't work.",
            "OK. Abbasian take some prior over the hypothesis class computes the posterior.",
            "It's just the likely times the prior.",
            "And then takes the maximum.",
            "Which avoids the overfitting problem, but we need Additionally a prior.",
            "OK, and they are principles to get the prior right.",
            "But is there?",
            "Completely general principle, and the answer is yes, and it's based on epic chorus and Occam's razor principles.",
            "Let's feel there are still so fickle principles.",
            "Which explain later, but these are quite wake and to quantify that you need, Gore complexity which will introduce the notion of.",
            "Information content in objects.",
            "And but you put everything together.",
            "You get a universal prediction scheme, and you can roughly say.",
            "It works if.",
            "And somehow only if if the true hypothesis is really in your class.",
            "If you consider the two hypothesis.",
            "And the final step we have to do is we have to extend this universal scheme for prediction.",
            "I'm two sequential decision theory.",
            "We have an agent which influences the environment.",
            "OK, so that's the outline of.",
            "Of these three hours."
        ],
        [
            "OK, so so this.",
            "Roughly half hour for each item.",
            "Philosophical issues, basean stuff.",
            "Then inductive inference then account to something which is a little bit off topic what which.",
            "Hopefully convinces you that some of these quite theoretical concepts can be useful quite directly.",
            "Also in practice, so that's the most impressive application.",
            "This universal similarity metric.",
            "And then finally, the definition of universal artificial."
        ],
        [
            "Elections and wrap up.",
            "OK, the philosophical part.",
            "Is this here?",
            "Let's start with."
        ],
        [
            "Some philosophical problems in inductive inference.",
            "So the first question is of course, does it work and why does it work and how does it work?",
            "Then how to choose the model class?",
            "How to choose the prior becomes a little bit technical.",
            "How to make optimal decisions in unknown environments?",
            "It's decision decision theoretic part and what is intelligence?",
            "Everybody has a feeling about it, but is there formal deafen?"
        ],
        [
            "So before I come to that, let me give you an analogy.",
            "I try to.",
            "Display here, in which state machine learning or AI is?",
            "So let's take analogy analogy from complexity theory, so complexity theory.",
            "The goal is there to find fast algorithm solving problems and to show lower bounds on their computation time.",
            "OK, that's one definition.",
            "So if you dig a little bit deeper, all these terms are rigorously defined, so we know what an algorithm is.",
            "We know what the Turing machine is, what a problem classes computation time.",
            "They're all mathematical definitions.",
            "But if you look at.",
            "This discipline or other disciplines.",
            "Most disciplines started in a quite wake.",
            "State, for example, set theory was not always, you know, based on axioms, and you had the famous Russell.",
            "Paradox or Russell set?",
            "I'm logical reasoning was informal.",
            "At Great Times, and now is completely formalized.",
            "Infinity's email calculus.",
            "Newton has big problems with it and invented the formal way of doing it.",
            "In physics there are other examples, like every temperature energy there, well defined mathematical definitions nowadays.",
            "And quantum field theories are in nearly a mathematical theory now.",
            "So OK, most disciplines start in formal and then get completely formalized.",
            "So if you look at machine learning.",
            "So what does machine learning try to do?",
            "It tries to build and understand systems that learn from past data, make good predictions, are able to generalize, act intelligently, or whatever you find for definitions in the Internet.",
            "And if you try to look for precise definitions of these terms, you either find none or a lot of different definitions.",
            "So most of these terms are vaguely defined, or there are many alternatives.",
            "The machine learning is not yet at the stage.",
            "We can say look, I mean this is well defined mathematically and the rest is just deduction.",
            "And you could.",
            "View.",
            "One of the goals of this lecture to show how close you can get, I mean to a formal definition of.",
            "Machine learning or AI.",
            "So here's some induction examples the most."
        ],
        [
            "Famous one, or at least probably oldest one is to predict Miss Piehler plus.",
            "So I asked the following question.",
            "So what is the probability that the sun will rise tomorrow?",
            "Given that it had risen for the last D days, OK, and you could.",
            "Maybe a little bit unusual problem, I mean, but the reasonable question becausw say if you think that doomsday is quite plausable tomorrow, you would probably, you know, leave this lecture and have some more fun.",
            "Or state here the solution of problem I don't know depends on your loss function.",
            "OK, so one answer would be peace undefined becausw.",
            "There has never been an experiment that tested the existence of the sun tomorrow.",
            "That is sort of denying the possibility of doing adduction at all.",
            "Hume had arguments in this direction, and he didn't deny, I mean.",
            "Obviously we all do induction and it somehow works, but can be justified.",
            "So maybe it's just my gut feeling.",
            "Or you say the probability is 1 big cause the sun rose in all past experiments, so that would be a frequentist estimate.",
            "End times out of end the sun or D times out of the the sun rose.",
            "You could also take a more.",
            "Far.",
            "Yeah, another statistical view, you estimate.",
            "The proportions of style that explode per day from historic data.",
            "And then you say it's 1 minus epsilon.",
            "Or they lost the blue point.",
            "It would be a physicist approach.",
            "You take the type, type, age, size and temperature of the Suns or the physical data and estimate the probability that it explodes in a supernova or something.",
            "I need to get some result.",
            "In LA plus.",
            "Set the probability should be D + 1 / D + 2.",
            "Reduce the length of the history and I will derive this and if you forget everything about this lecture, just take two things or comes razor principle.",
            "I will explain and this Laplace rule.",
            "So that's really, really something fundamental and important.",
            "In Bayes rule, of course.",
            "OK, So what we have here?",
            "We have many answers and many justifications.",
            "So what is the right answer?",
            "What is the best answer?"
        ],
        [
            "Here's another example, so.",
            "Who wants to predict this sequence here?",
            "1415 and so on.",
            "Um?",
            "For some it looks pretty random, so if you make a frequency estimate you would see that every digit occurs approximately equally often.",
            "So you would say probably you know the next digit, the probability is just you know 10% for each possibility.",
            "Or you see that it's just the digits after \u03c0. Digits after the comma, so 3.1415 and then of course I mean you start Mathematica and you compute the next digit and say oh, very likely it's 5.",
            "Because you detect some pattern.",
            "In this sequence you see some structure and once you see it, you wouldn't pretty uniform distribution for the next.",
            "Symbol.",
            "But I mean can be sure about it, that the five is next.",
            "Warehouse where should we be?"
        ],
        [
            "OK, that is close to IQ test.",
            "I mean IQ tests what you have your sequences of numbers.",
            "I mean the most simple IQ test would be 1234.",
            "What comes next?",
            "And.",
            "I guess most of you will answer 5.",
            "'cause there's a simple pattern.",
            "I mean, it's just always, you know, adding one.",
            "But you can also justify it 29 it just take this nice 4th order polynomial and if you evaluate it at 1234 it also gives you 1234.",
            "And then you plug in five and you get 29.",
            "So I mean that.",
            "Definitely explains you know the past sequence and gives you a prediction.",
            "They are serious researchers.",
            "Who tell you that it's just?",
            "Social convention.",
            "To predict 5.",
            "I think this is ridiculous.",
            "OK. Um?",
            "I'll take the next sequence.",
            "It is a little bit more tricky.",
            "So I should hide it somehow.",
            "OK, here's the answer.",
            "So I mean, if you look at it, it looks like the digits of \u03c0 and 61 would be the natural next.",
            "Item.",
            "But if you know something about simple groups and they have orders, the number of elements and they have exactly the sequence, but then there's a simple group which has 60 elements.",
            "The first simple group which is not of prime.",
            "Order, So what would you do in IQ test?",
            "So who would predict 61?",
            "Who would predict 60?",
            "OK.",
            "So here social convention is maybe closer to the truth, you predict 61 B cause you think about OK, you know many people know about primes, but very few people know about simple groups.",
            "So the guy who designed it is probably knew about primes, and so this is your argument and.",
            "You can.",
            "In a certain sense, formalized rigorously this argument.",
            "So what you do is you take your social background knowledge.",
            "They take Wikipedia and then you try to predict the sequence relative to this background knowledge.",
            "And if you formalize that and do it properly, the system will predict indeed 61.",
            "I mean, if there's another civilization which starts with simple groups and all you know the Wikipedia page is there, you know, talk about simple groups, then you would predict 60.",
            "OK yeah, this is a nice website.",
            "This last link so often in research what you have is you have.",
            "Some problem.",
            "And it depends on some parameter N and you ask some questions.",
            "And often the answer is, say some number.",
            "So for N = 1 you get an answer in equal 2 and you can compute it by hand and you want to find the pattern.",
            "Because once you have the patterns, or maybe then you can prove that this pattern is really there and it's not so often not so obvious.",
            "I mean like 1234 or the primes, so you just type in your sequence here and it has a huge database and some CB smart algorithms for generalization.",
            "And it gives you all.",
            "Possible underlying.",
            "I'm.",
            "Regularity is the system knows of Orkin identified with.",
            "So at least once in my life it was useful.",
            "I wanted to prove something couldn't do it or computed before end equal 12345 typed it in, got some answer out for this sequence, hit the result in verifying the result is often much easier than driving it, so it's a real cool side.",
            "OK.",
            "So so."
        ],
        [
            "Add, you know some examples and some explanations for these examples are physics, explanations are.",
            "Social explanations and others for the polynomial didn't give an explanation because it's obvious.",
            "But if you think about it, what is unifying all these explanations?",
            "They're all biased towards simplicity somehow, and that is actually what all comes.",
            "Razor tells you.",
            "You should use the simplest explanation.",
            "So this line, which is consistent with the path data.",
            "And use it for prediction.",
            "And if you go through these examples, except maybe for the simple group example you have to.",
            "I mean this principle still works, but you have to be a little more careful.",
            "This principle really gives you the right answer.",
            "On an intuitive level, I mean, I haven't formalized anything in yet.",
            "And actually all comes Razor, there's even more.",
            "It serves as a foundation of machine learning in general.",
            "So not just for induction and is even a fundamental principle.",
            "Or maybe the definition.",
            "What scientists do?",
            "I mean you have your data and you want to understand the data.",
            "What does understanding the data mean?",
            "We normally you construct models for this data.",
            "OK, for every day to have a simple model and not simple.",
            "I have one model, namely the data itself.",
            "It's a model of the data, but it's pretty stupid.",
            "So what you try to find is to try to find a simple model.",
            "And the primary reason is not becausw you would not be able to deal with the complex model.",
            "Because the simpler model for some reason.",
            "Turns out to be useful, more useful in many cases than the more complex model.",
            "Basically, with overfitting in these things.",
            "So far so good.",
            "Problem is that everything is awake so far.",
            "So that's not a formal mathematical objective principle.",
            "So what is simple for one might be complex for another.",
            "And.",
            "Um, I would do the devote most of a lot of my time to formalizing this principle."
        ],
        [
            "Here's another example.",
            "I will not solve it here, just yeah.",
            "Yeah, I'll do that later.",
            "In terms of, of complexity.",
            "OK, here's another nice example from philosophy.",
            "You have two hypothesis.",
            "One is all emeralds are green and the other one is all emeralds found till 2010 are green.",
            "And then thereafter there suddenly blue.",
            "So, which hypothesis more plausible?",
            "And of course you all say H1 is more plausible, and what is the justification?",
            "Yeah, you can invoke Arkansas razor.",
            "The first hypothesis is simpler than the 2nd.",
            "Just count the number of letters.",
            "For instance.",
            "In this case I mean.",
            "It's a measure of simplicity.",
            "Since I have no pointer.",
            "You gotta change something here.",
            "Try this song.",
            "OK. Yeah.",
            "Yeah.",
            "Yeah.",
            "I don't like this particular example, but I mean we can stay with it.",
            "Of course you can fail.",
            "You have some data which have.",
            "Some regulatory or maybe some usefulness or not, and then you make some conclusion and then later you find out reality is more complex.",
            "Then you have to revise your model.",
            "And you made an error.",
            "And it might have been better to start with a more complex model.",
            "But I will show you a result which more or less shows that it's always better to start with a simple model and then you count the number of revisions you have to make in your model.",
            "And this number is fairly small and in a certain sense optimal.",
            "So you would converge.",
            "Having enough normally data or in this case may be enough written enough, you know useful papers about it, you would converge.",
            "Must be something really new.",
            "You may have different looks very good.",
            "Yeah, that's that's a reasonable bias, isn't it?",
            "I mean, if something is really different.",
            "Normally you need a little bit more convincing proof that you know.",
            "That is good.",
            "OK, here's another nice paradox.",
            "Yeah, the logicians will like that more.",
            "So.",
            "Assume you want to confirm the rules that are implies B."
        ],
        [
            "So for instance, that all Ravens are black, so if something has the property of being a Raven, it has also the property of being black.",
            "And normally what you do is you go out and you observe Ravens and you know black Raven, other black Raven, black Raven and once you have enough you say oh this rule is plausable.",
            "You can never be sure.",
            "Of course yeah, but you can say you know maybe 99% or you make some qualitative measure.",
            "OK, that's how you confirm implications or rules.",
            "So now let's abstract and look at R and paying.",
            "Don't forget the interpretation.",
            "So here obviously ever replace R by not B&B by not R, and I believe that one now.",
            "It's proper then I have to believe in the second one so that.",
            "If you have not been instances with the property of not R, it must confirm the rule, not B implies not R. I mean, it's it's the same, just enough.",
            "The Contraposition, who has seen the confirmation paradox before?",
            "OK, someone at all so.",
            "I'm so, so far so good.",
            "But now we know, or you know, that are implied.",
            "Speed is logically equivalent to not be implies not R. That means that also the second instance is that don't be.",
            "Instance is not.",
            "R must imply the first rule because they imply you know the second rule.",
            "In the second rule is logically equivalent to the first one.",
            "OK, let's use that.",
            "So here we say, Ravens and blackness are NP.",
            "And of course, if you observe black Ravens, it confirms hypothesis.",
            "Zero everybody.",
            "I hope everybody agrees to that.",
            "But now I can use.",
            "The logical #3 and just take White Sox.",
            "Becausw White Sox are not black, not Ravens.",
            "So they confirmed the rule that all not Ravens are not black objects are not Raven, so it confirms the rule that all Ravens are black.",
            "So that makes life much simpler.",
            "Just open my drawer and look at the number of my white socks and conclude that all Ravens are black.",
            "Yeah.",
            "Oh yeah, yeah, yeah.",
            "Yeah.",
            "Yes.",
            "No, no, I don't think so for all X. Raven of X implies Blackness of Axis and I only do the counter positioning in in the inner thing.",
            "No, no, I mean.",
            "Wait, wait.",
            "I mean this is the point of induction versus deduction.",
            "I mean, if you do detection, you observe the whole universe to conclude something, but do you do that?",
            "What do you tell?",
            "You know a 5 year old child.",
            "Do you think all Ravens are black or not?",
            "And then you say are probably all Ravens are black.",
            "Have you observed all black Ravens in the world?",
            "I guess not.",
            "Yes, sure.",
            "I mean, if you if you define a paradox as logical contradiction.",
            "It is a paradox in the following sense look.",
            "Do you believe that this is a reasonable principle?",
            "Observing black Ravens.",
            "Confirms the hypothesis.",
            "That all Ravens are black.",
            "I mean, you can never be sure with induction, yeah, but you can, you know be more and more convinced formalized that somehow with probabilities or with other types of us.",
            "So do you believe that this is a reasonable principle?",
            "Yes, and if you believe that this is reasonable, you must also believe that observing white socks helps you in confirming this hypothesis.",
            "So if you if you accept.",
            "1.",
            "You have a.",
            "You have to accept this one here the last line.",
            "At least it looks like it, and it works.",
            "I mean there's a paradox, yeah?",
            "They grew OK. We will come back to that.",
            "Yeah, and.",
            "Yeah, I don't have the time to talk about the solution, but I mean one thing is.",
            "That this is not the real solution, but I mean that's a good starting point that while our so.",
            "You can say or imply speed.",
            "If you go to probabilities, you say that the probability of being black given a Raven.",
            "Is 1.",
            "If you translate this rule, this would be the probability of, not.",
            "Raven given not blackness.",
            "Is equal to 1.",
            "Logically.",
            "These two are the same.",
            "But these two probabilities can be completely different.",
            "You can show that if this probability is 1, then this must also be one.",
            "So in the extreme case of probabilities being one or zero.",
            "You have this tight.",
            "Um?",
            "Connection.",
            "But if this probability is smaller than one, say 0.9, this can be anything even 0.01 or something.",
            "So you lose this.",
            "I'm.",
            "Tight connection in the contraposition, so that's just a hint.",
            "The full story is much longer.",
            "There.",
            "I think at least hundred 100 papers about this problem.",
            "You know the typical philosophical blah blah papers, but also some good philosophical.",
            "But they also.",
            "A number of philosophers who know some math and we have some here at the end you.",
            "So Alan Hyatt, for instance.",
            "Um?",
            "Yeah, so also good papers with the best.",
            "I mean, if you're the best reading to start with is Patrick.",
            "Maja there's a 2004 paper in some edited book which is not so easy to access.",
            "And then there's an older 1999 paper which is.",
            "Yeah.",
            "Better this, but this is OK if you can't get grab the other one.",
            "And there's of course my paper, which finally solves it.",
            "2000 unusable universal prediction and.",
            "Confirmation or something, so that's the confirmation paradox."
        ],
        [
            "OK, so now we go back to the grew Emerald, yeah.",
            "So we're wondering which my love.",
            "How about this one?",
            "Very simple this letter so it's easy.",
            "But that seems.",
            "Yeah, I know this example, and that's not a complete solution.",
            "I mean, maybe you presented to the others.",
            "I mean, you redefine the language.",
            "I'm instead of green and blue.",
            "You talk about grew and clean, which are defined so that the swap at 2010 and then hypothesis to get simpler than hypothesis.",
            "One, and I mean this is sort of.",
            "Deeper paradox and I have.",
            "Some answers to it.",
            "But it's still open.",
            "OK, I mean the we can discuss that.",
            "Maybe in the break or after Watts it's it's.",
            "It's.",
            "It's subtle and you know it's not that I can present one formula and that's it and solved.",
            "OK, so."
        ],
        [
            "That is now the last slide of the philosophy part.",
            "I guess so.",
            "So the general problem set up just repeat from the first slide.",
            "Am I look at sequence prediction problems?",
            "Because most induction problems can be phrased like that.",
            "For instance, even a classification problem.",
            "I mean what you have there, you have features and class labels, so you have this.",
            "Feature class label.",
            "So you have a data set like that.",
            "What do you do with it?",
            "I mean, you have a new instance in some point.",
            "And you want to predict the class label.",
            "OK, so that's the sequence prediction problem.",
            "You have feature class label feature, class, label feature, blah blah blah feature class label feature.",
            "What comes next.",
            "OK, I mentioned it already that.",
            "Prediction itself is not the ultimate goal, but you want to do something with the prediction.",
            "So maximize your profit or minimize your loss.",
            "I will mostly consider you know this.",
            "Second decision theoretic.",
            "Step on top of it.",
            "And.",
            "Maybe you wonder at some point in other machine and electrodes they were always the issue about noise and useful data and separate them and having these models I will not talk about separating noise from useful data becausw in this very abstract framework.",
            "You Luckily don't need to do that, so that is very convenient.",
            "OK, so that's the setup."
        ],
        [
            "There's another slide.",
            "What I do in this lecture and whatnot, so the blue things I will discuss or touch at least, and the black things not.",
            "So I will talk more about the machine learning angle rather than the good old patient AI.",
            "Angle.",
            "Mentioned already, that induction is ultimately used for decision-making so.",
            "They will concentrate on that.",
            "I will not go in tell much about classification and regression or any IID stuff, But the sequence prediction stuff and an ID stuff.",
            "I will mostly talk about online learning, so you make a prediction or a decision, then you get the next observation and you learn from it and you improve.",
            "And then you make another prediction or action and you learn.",
            "I think I can.",
            "Keep this, I mean you can just read it.",
            "This.",
            "To talk to me, I hope somebody of the others in the machine learning have told you the difference between supervised learning, unsupervised learning, reinforcement learning and who wants an explanation of that.",
            "No OK good.",
            "I'm."
        ],
        [
            "So.",
            "So that's the set up a little bit more formally.",
            "I'm at times T123.",
            "You have a predictor, which means your prediction.",
            "YT index P means predictor, P is doing it based on past observations, X one up to T -- 1.",
            "Then you observe the XT&P suffer some loss which depends on the prediction in the two outcome.",
            "And.",
            "Then you add up the total loss from time one up to you know the time you die or you get bored.",
            "So this is your total loss and you want.",
            "Of course you know to minimize your loss somehow.",
            "Here's the classical weather forecasting example, and here's my personal loss function.",
            "So you have sunny and rainy and they have the possible outcomes and the possible predictions or decissions are umbrella and sunglasses.",
            "I mean here you have a tight connection between sun and sunglasses, umbrella and rain, but it could be completely different spaces.",
            "I mean, often it's exactly the same space or closely related, but it doesn't have to be.",
            "And then I mean the best.",
            "Option is if it's sunny and you have your sunglasses, there is zero loss and the worst thing is you have your sunglasses and it rains because if you had umbrella I mean at least you don't get that.",
            "And this loss function days.",
            "Essentially, all theory for a good loss function, because this is the definition of your problem or what your personal goal is.",
            "So everybody has his own loss function.",
            "Sorry.",
            "You know, maybe I know Australians are different because he is always sunny and you are happy with the rain.",
            "But I come from Germany.",
            "And we like son, 'cause you know, we don't get it every day.",
            "So what was the question?",
            "Yeah.",
            "Yes, still prefer some to rain.",
            "We got a list.",
            "Yeah, but look.",
            "I mean look, I take my umbrella and go out and it's still sunny.",
            "I closed umbrella or mean even over usage and then I have a shade so it's nice weather.",
            "But I mean, maybe you're different.",
            "So put some other numbers in.",
            "So I prefer sun over rain.",
            "Whatever I take my umbrella on my sunglasses.",
            "So that's.",
            "Yeah, I mean often these loss functions you're right, this is a little bit of an unused loss function.",
            "Normally you have you say AB and you do or predict something AB and then you say if you do it correctly you have zero.",
            "Lausanne often it's.",
            "It is diagonal, which is not the case here, so it's.",
            "Unusual, but OK that happens and it shows you that it's important to.",
            "Be careful about the loss.",
            "OK.",
            "So that was the easy part."
        ],
        [
            "Anymore questions.",
            "So now let's I'm become more mathematical.",
            "Still a little bit more philosophy for the logicians.",
            "Probabilities can mean many things, and I give some interpretations.",
            "Then I come to the important base.",
            "In Laplace rule I mentioned at the beginning.",
            "So this you should remember.",
            "Another nice paradox, the envelope paradox and then some real hard results.",
            "I mean not so hard, but I mean no.",
            "Math.",
            "Um?"
        ],
        [
            "OK, so uncertain probability.",
            "So the aim of probability is to describe uncertainty.",
            "OK, so they're very sources.",
            "There's a frequentist point of view that you just, you know, count the relative frequency.",
            "Or you.",
            "That only works for IID data.",
            "I have more slides on that or your objective instances.",
            "Randomness is a real property of the world.",
            "Say the Atom decays with a certain probability and it's a property of the physical world.",
            "Or in AI you often have the subjective stance that probabilities are just degrees of belief of an agent.",
            "So for instance, if I say, it's implausible that extraterrestrials exist.",
            "I mean, either they exist or not.",
            "But I cannot believe over it, so it can be quite certain save is 90% probability, whatever that means."
        ],
        [
            "So the frequency is that what you learn in school.",
            "So you have independent identically trials.",
            "Certain so flip coins.",
            "You look how often some event occurs.",
            "So for instance head, you divide it by the length of the sequence that it gives the frequency estimate, and what you can show is that in the limit for long sequences this converges.",
            "To sum real number between, of course zero and one.",
            "And you say this is the probability of the event.",
            "OK. What is wrong with that?",
            "Can't be anything wrong with it, but there is.",
            "OK, here's the example.",
            "I just gave you tossing off a fair coin for coin would converge to 1/2.",
            "But that's not really true.",
            "It does not always converge to 1/2.",
            "If you flip the coin its head, you flip another time it's head, head, head, head.",
            "And so on, and then it converges to one.",
            "So I have proved that it does not converge to 1/2.",
            "Now, you'll probably say I mean look.",
            "I mean, this is extremely unlikely that this happens.",
            "Yes, you're right, but it may happen.",
            "So you can say with high probability it converges to 1/2.",
            "So, but what does probability mean?",
            "I mean, this is supposed to define probability and now you start, you know, with an intuitive notion of probability.",
            "So the definition is circular.",
            "So it's not that easy.",
            "The next refinement would be hard look.",
            "I know the probability for infinitely long sequence is 1, so at least I have reduced the problem of defining what probability means to the problem of.",
            "What does probability one mean?",
            "Which is, you know, some step forward and there's I will not go into that.",
            "There's kernels principle and he said everything which happens with probability one in statistics happens for sure.",
            "In the real world.",
            "It's a principle.",
            "Which is a reasonable principle.",
            "I mean, find a counterexample.",
            "So and then I mean that is one way to define probabilities and make sense out of them.",
            "And there are others.",
            "Sense out of frequent."
        ],
        [
            "Probabilities OK, the objective.",
            "Interpretations that real aspects of the world.",
            "You make some experiments and it was some physical render process.",
            "And here's the formal definition, which.",
            "You haven't sample space, you have some event.",
            "And you have some IID experiments now.",
            "OK, so.",
            "So then you write down some axioms here.",
            "Here there's a standard probability axioms, and if you have IID experiments then you can show that this probability axioms are satisfied and now you forget about the ID and say, OK, you know this is my starting point.",
            "This is my exams start from another question that.",
            "And that's axiomatic probability theory and measure theory.",
            "I mean you learn.",
            "I'm in your math courses.",
            "And then if somebody wants to apply it and interpret it.",
            "I mean it's not.",
            "The problem of the mathematician.",
            "I don't care, you just proved theorems.",
            "OK, that's the objective."
        ],
        [
            "Interpretation and the subjective interpretation as degrees of belief.",
            "I mentioned that.",
            "And normally you you require that is greater than 0.",
            "Otherwise it's either undefined or you define it.",
            "Somehow, you know either zero or one.",
            "Sometimes it's useful to give it a value, but strict in strict measure theory it's undefined.",
            "I'm.",
            "Not really, because I mean what happens is the following and even in measure theory books you see that people get sloppy and.",
            "Although they are mathematicians, but if it's a good book at the beginning, it explains what is going on.",
            "If you condition on a probability 0 event.",
            "And you forget about that.",
            "It's undefined and just proceed.",
            "You just do nonsense.",
            "But this nonsense happens with probability 0.",
            "So with probability one, what you're doing makes still sense.",
            "So all theorems you conclude still hold, but you have to add the qualifier only with probability one.",
            "So there are a lot of theorems in probability theory and.",
            "Where you think, Oh my, why is this probability one statement there cause it may be not defined.",
            "Yeah.",
            "They would rightly probability of some event.",
            "They save level stuff while we stayed with 180 or one.",
            "That is something that we can condition overlay or something, but it is a. Yeah.",
            "No, but what is the answer?",
            "I mean?",
            "I mean, if the probability of.",
            "A is 0 whatever age you may use.",
            "Link your sequence over ever consider.",
            "And then you ask the probability of being given a.",
            "What's that?",
            "By definition, the conditional probability is defined to be P of A and B / P of B, which is 0 / 0.",
            "It can be considered arbitrary, you say.",
            "Your divided by zero, yeah?",
            "Anne.",
            "Yeah, there's one important cases, yeah, but for instance.",
            "OK, mathematically what you can do is you can define versions of conditional probability.",
            "I don't know whether you refer to that, and indeed it occurs.",
            "For instance if you have.",
            "Two real numbers X&Y and you have a probability density of that then.",
            "I mean, formally you can compute the probability density of X given Y is the ratio, because these are densities, then are not zero.",
            "But if you ask what is the probability?",
            "That X is in some SpaceX given a particular Y.",
            "You have.",
            "P of something in the denominator get asked for the probability of Y.",
            "But if you have, if this is a real number and you have a probability density, then the probability of any particular point is 0.",
            "In this case, I mean we all do it and extremely useful to assign a number, and you typically don't do it with relative support with densities, which is sort of a derivative.",
            "Yeah.",
            "Yeah.",
            "So that would be a.",
            "A less trivial extension than just defining it randomly to be one or zero, but there is.",
            "Um?",
            "How is it?",
            "Paradox called on the sphere got the name from some guy with B.",
            "No, no no, not not this one.",
            "I will motional simple one.",
            "I'm.",
            "Do the following.",
            "Take a uniform distribution on a sphere.",
            "Yeah.",
            "Anne.",
            "Now assume your data point landed on the equator.",
            "And ask what is the probability distribution on this ring given that your data point landed on this ring.",
            "So the probability of.",
            "Yeah, just what I said.",
            "And if the distribution was uniform on the sphere, well, OK.",
            "I mean, it should be then uniform on the ring, and this is what you get out.",
            "Now doing the most knife calculation in polar coordinates, now you ask for this ring here.",
            "And what you get is a non uniform distribution.",
            "Yeah, it's still uniform on the sphere.",
            "So if you then look at it, what happens?",
            "It depends on your parameterization of the sphere or so it's original uniform which has nothing to do with the parameterization.",
            "And then you may go to polar coordinates and then you get different answers depending you know how you do the coordinates and that is totally absurd.",
            "That's some paradox by BI think.",
            "Yeah, and that's the problem.",
            "If you take a ring off.",
            "Equal with here, yeah, then it's uniform, but if you take it with polar coordinates then this ring is narrower here than here.",
            "And this is the solution.",
            "Yeah, but I mean the limit is a ring.",
            "So why should I be so careful about, you know?",
            "How I take it and what does it mean?",
            "I mean, I asked the question, what is the probability given that the point landed on the ring?",
            "And why I'm not allowed to take it nonuniform?",
            "What is the right and what is wrong answer?",
            "So yes, you can extend it.",
            "But it's partly arbitrary.",
            "And for real numbers, the arbitrariness you can.",
            "Sort of reduce it, but not completely.",
            "Anne.",
            "OK, 4 degrees of belief.",
            "You start with a conditional belief function.",
            "So what is my belief in a given B?",
            "So these are the two arguments.",
            "And you wanted this belief function roughly corresponds to common sense.",
            "I mean, you believe some things, and if something happens, you change your belief and you have some feeling about it, I will not formalize that here.",
            "That is what Cox did in 1946.",
            "He came up with some very reasonable properties for this belief function, which.",
            "You would probably accept and they are extremely weak, they're just more or less functional dependencies.",
            "So for instance, if the belief of B.",
            "Is a function of.",
            "Given A is a function of DNA, then the belief of not being given a should be enough.",
            "Now OK, now this is too trivial.",
            "Then I know it's not trivial then not be given a should be, should have the same functional relationship, not we're not assuming that probabilities sum to one or anything, because I mean there's just believes any real numbers.",
            "OK, if you start with this week's axioms, you can show that this belief function.",
            "Is isomorphic to a probability function which satisfies Kolmogorov axioms?",
            "That means there is a bijection and actually continuously differentiable from belief.",
            "So this belief values.",
            "Might be real values, not necessarily in 01, but you can find a function.",
            "Which is an injection such that.",
            "This year satisfies, golf axioms, and since these values are.",
            "I mean, you don't really care about.",
            "The.",
            "The particular value you care about the relations and about the order, and in any case I mean if this satisfies, golf.",
            "Except you can always go back by taking them.",
            "You know the inverse function of the probability to get your Billy function back.",
            "Is a bijection, yes?",
            "Is a bijection between.",
            "Yeah yeah.",
            "OK.",
            "So what he has shown so if you accept this reasonable.",
            "Assumption about how beliefs should behave.",
            "Then police.",
            "Follow the same rules as objective probabilities and then the same as frequentist probabilities and that is very nice because now you can forget about everything I said.",
            "You just use Kolmogorov axioms of probability and do your computation.",
            "Yeah, because all these probabilities.",
            "Follow the same rules.",
            "There are subtleties.",
            "I mean, you start with some.",
            "Plausable axioms, but maybe they're not as possible as you know.",
            "They first look at and you can try to modify and remove them and their communities who are not satisfied with that.",
            "And you know, invent different kinds of probabilities are probabilities, lower probabilities.",
            "OK function at all kinds of things, yeah, but to 1st order approximation you can always use standard probabilities.",
            "OK, now we come to.",
            "Space famous rule.",
            "So.",
            "Let D be some possible."
        ],
        [
            "Later.",
            "And.",
            "The probability is not zero.",
            "So it might happen and you have a countable class of hypothesis which are mutually exclusive.",
            "That means that one of them is true and not more than one of them.",
            "You have some a priore belief.",
            "Over the hypothesis, these are now.",
            "Subjective probabilities so apriori I believe.",
            "General relativity is crap, and Newton is right because you know, it's much simpler, but then I have some observations and so on.",
            "OK so my upper or belief.",
            "Then I have my likelihood function.",
            "This is more or less defining, but the hypothesis means.",
            "I mean, these are just symbols, Ch.",
            "What does it mean?",
            "Hypothesis it means sampling model normally and the likelihood specifies the sampling model OK. And.",
            "What you want is after you've seen the data you want to update, you believe.",
            "Or should you believe afterwards.",
            "And Bayes rule tells you how to do that and.",
            "I just presume that everybody has seen that before.",
            "And this follows easily for Commodore.",
            "From kolmogorov's axioms.",
            "The interesting thing is, I mean it's an exercise worth to do once you take the axioms.",
            "And you try to derive that, but really only using the axioms are not something intuitively, you know, and what you will see is that these actions are really sufficient.",
            "You don't need more, and you need all of them.",
            "Is that a question?",
            "End.",
            "If I'm.",
            "You have an infinite.",
            "I mean if you have finitely many.",
            "Classes you don't need the countable additivity, and if you have a countable class then you need this last action.",
            "The countable additivity, in order to derive this rule.",
            "Yeah.",
            "This is your prior app, yeah?",
            "This is the denominator here.",
            "It's called the evidence.",
            "It's.",
            "Quite tricky to impossible to interpret that it's a very important object.",
            "So formally, you have.",
            "The probability of a you can ride as the probability of a given B * P or B.",
            "Lose the probability of a given, not B.",
            "Times period not be easily follows from their actions.",
            "Set up.",
            "Sorry again.",
            "So OK, POV would only be 0 if we were impossible.",
            "Under all possible hypothesis.",
            "OK.",
            "It's cool my brain.",
            "Are you a boy?",
            "Yes, I mean if you have that you're talking about now, real numbers and probabilities would be 0.",
            "Then you have to replace everything by probability densities.",
            "Just before.",
            "Yeah.",
            "Yeah, then.",
            "Yes, then this is a density.",
            "Yeah, then it's the case, yeah, you mean.",
            "I'm a little bit.",
            "Sort of sloppy.",
            "I always only.",
            "Or nearly always only considered discreet.",
            "Space is countable, space is finite spaces.",
            "To make life simpler.",
            "Because in the continuous case I mean, this is one of the problems you have in the continuous case.",
            "I mean, we discussed the density case.",
            "That's one way.",
            "And but you have to be careful.",
            "And but you know, maybe there's something I don't know.",
            "Yeah.",
            "Can you show me the pages in the book?",
            "Think about every space is discrete and finite.",
            "And then you don't have the problem.",
            "For instance, the two books by fellow this old statistics book.",
            "I mean he strictly separates the discrete finite case and then you can derive all everything which is of principle interest in the continuous case is then just a lot of technical difficulties.",
            "And it's nice to separate them.",
            "And I do that here.",
            "I will not talk about continuous stuff.",
            "I mean, for instance I discretize time.",
            "I mean, in physics you have continuous time, but that's an enormous complication.",
            "I mean, sometimes it makes things simpler.",
            "So it's easier conceptually to stay discrete."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, welcome to the last lecture for the Machine Learning Summer School.",
                    "label": 1
                },
                {
                    "sent": "I hope you had fun so far because now it ends.",
                    "label": 0
                },
                {
                    "sent": "I know.",
                    "label": 0
                },
                {
                    "sent": "OK, we're in the eye part here and.",
                    "label": 0
                },
                {
                    "sent": "So there should be logicians here, and machine learners, and in this lecture, so you have heard you know a lot about artificial intelligence now and machine learning and pure logic and logic.",
                    "label": 0
                },
                {
                    "sent": "This is relevant or related to AI.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "This lecture is about first stepping back and thinking about the philosophical foundations of AI.",
                    "label": 0
                },
                {
                    "sent": "And then I come to a theory which is in a mathematical sense a complete theory of AI.",
                    "label": 0
                },
                {
                    "sent": "I mean, you have seen all these bits and pieces of it.",
                    "label": 0
                },
                {
                    "sent": "I understand, I mean this or this or that.",
                    "label": 0
                },
                {
                    "sent": "So is there an overall overarching say, not framework, but real definition like in many other fields?",
                    "label": 0
                },
                {
                    "sent": "I mean, for instance a simple example like playing a 0 sum game you all know Mini Max to the end.",
                    "label": 0
                },
                {
                    "sent": "Probably have heard that is the optimal strategy.",
                    "label": 0
                },
                {
                    "sent": "Index it OK. Now you can start and you know build touristics and derive more efficient algorithms, but you know where to start from.",
                    "label": 0
                },
                {
                    "sent": "And 2nd third of our about this of this lecture is about is there such a general definition?",
                    "label": 0
                },
                {
                    "sent": "And for general agents, not just for 0 sum games but more general.",
                    "label": 0
                },
                {
                    "sent": "OK, so here's a.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Overview slide I guess we don't have a pointer again.",
                    "label": 0
                },
                {
                    "sent": "Anybody having a laser pointer?",
                    "label": 0
                },
                {
                    "sent": "Sorry.",
                    "label": 0
                },
                {
                    "sent": "Yeah, that's the last option.",
                    "label": 0
                },
                {
                    "sent": "I know.",
                    "label": 0
                },
                {
                    "sent": "OK, use the internal mouse.",
                    "label": 0
                },
                {
                    "sent": "Even worse, OK.",
                    "label": 0
                },
                {
                    "sent": "Locked.",
                    "label": 0
                },
                {
                    "sent": "OK, I think I get the mouse for the second hour.",
                    "label": 0
                },
                {
                    "sent": "OK, so here's an overview slide.",
                    "label": 0
                },
                {
                    "sent": "If you don't get it, no problem.",
                    "label": 0
                },
                {
                    "sent": "I present exactly the same slide at the end of the three hours and hopefully then everything is clear.",
                    "label": 0
                },
                {
                    "sent": "OK, so the general setup is for prediction and the last into last extent I will talk about prediction.",
                    "label": 0
                },
                {
                    "sent": "Predicting the future is important part for being able to act intelligently.",
                    "label": 0
                },
                {
                    "sent": "And you first have to understand this and then I come to the action part.",
                    "label": 0
                },
                {
                    "sent": "So for prediction.",
                    "label": 0
                },
                {
                    "sent": "What you have is you have a sequence of data like weather data, Sun, Sun, Sun, Sun, Sun, Sun, maybe sometimes rain, sun, sun, sun.",
                    "label": 0
                },
                {
                    "sent": "What is the weather tomorrow?",
                    "label": 0
                },
                {
                    "sent": "The ultimate goal is actually usually not the prediction itself.",
                    "label": 1
                },
                {
                    "sent": "But it is a purpose, and the purpose is either to maximize your profit or your happiness or your minimize your loss or something like that.",
                    "label": 0
                },
                {
                    "sent": "In most frameworks what you do is you start with a class of hypothesis.",
                    "label": 1
                },
                {
                    "sent": "Where the data could be drawn from.",
                    "label": 0
                },
                {
                    "sent": "And statistically, you have a likelihood that the probability of your data given the different hypothesis.",
                    "label": 0
                },
                {
                    "sent": "And one estimate would be the maximum likelihood.",
                    "label": 0
                },
                {
                    "sent": "You just take the hypothesis, yeah, which by definition maximizes likelihood.",
                    "label": 0
                },
                {
                    "sent": "OK, that's a reasonable principle.",
                    "label": 0
                },
                {
                    "sent": "For simple cases, the problem is if your model class is too large it overfits and it won't work.",
                    "label": 0
                },
                {
                    "sent": "OK. Abbasian take some prior over the hypothesis class computes the posterior.",
                    "label": 0
                },
                {
                    "sent": "It's just the likely times the prior.",
                    "label": 0
                },
                {
                    "sent": "And then takes the maximum.",
                    "label": 0
                },
                {
                    "sent": "Which avoids the overfitting problem, but we need Additionally a prior.",
                    "label": 0
                },
                {
                    "sent": "OK, and they are principles to get the prior right.",
                    "label": 0
                },
                {
                    "sent": "But is there?",
                    "label": 0
                },
                {
                    "sent": "Completely general principle, and the answer is yes, and it's based on epic chorus and Occam's razor principles.",
                    "label": 0
                },
                {
                    "sent": "Let's feel there are still so fickle principles.",
                    "label": 0
                },
                {
                    "sent": "Which explain later, but these are quite wake and to quantify that you need, Gore complexity which will introduce the notion of.",
                    "label": 0
                },
                {
                    "sent": "Information content in objects.",
                    "label": 0
                },
                {
                    "sent": "And but you put everything together.",
                    "label": 0
                },
                {
                    "sent": "You get a universal prediction scheme, and you can roughly say.",
                    "label": 0
                },
                {
                    "sent": "It works if.",
                    "label": 0
                },
                {
                    "sent": "And somehow only if if the true hypothesis is really in your class.",
                    "label": 0
                },
                {
                    "sent": "If you consider the two hypothesis.",
                    "label": 0
                },
                {
                    "sent": "And the final step we have to do is we have to extend this universal scheme for prediction.",
                    "label": 0
                },
                {
                    "sent": "I'm two sequential decision theory.",
                    "label": 1
                },
                {
                    "sent": "We have an agent which influences the environment.",
                    "label": 0
                },
                {
                    "sent": "OK, so that's the outline of.",
                    "label": 0
                },
                {
                    "sent": "Of these three hours.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so so this.",
                    "label": 0
                },
                {
                    "sent": "Roughly half hour for each item.",
                    "label": 0
                },
                {
                    "sent": "Philosophical issues, basean stuff.",
                    "label": 0
                },
                {
                    "sent": "Then inductive inference then account to something which is a little bit off topic what which.",
                    "label": 1
                },
                {
                    "sent": "Hopefully convinces you that some of these quite theoretical concepts can be useful quite directly.",
                    "label": 0
                },
                {
                    "sent": "Also in practice, so that's the most impressive application.",
                    "label": 0
                },
                {
                    "sent": "This universal similarity metric.",
                    "label": 0
                },
                {
                    "sent": "And then finally, the definition of universal artificial.",
                    "label": 1
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Elections and wrap up.",
                    "label": 0
                },
                {
                    "sent": "OK, the philosophical part.",
                    "label": 0
                },
                {
                    "sent": "Is this here?",
                    "label": 0
                },
                {
                    "sent": "Let's start with.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Some philosophical problems in inductive inference.",
                    "label": 0
                },
                {
                    "sent": "So the first question is of course, does it work and why does it work and how does it work?",
                    "label": 0
                },
                {
                    "sent": "Then how to choose the model class?",
                    "label": 1
                },
                {
                    "sent": "How to choose the prior becomes a little bit technical.",
                    "label": 0
                },
                {
                    "sent": "How to make optimal decisions in unknown environments?",
                    "label": 1
                },
                {
                    "sent": "It's decision decision theoretic part and what is intelligence?",
                    "label": 0
                },
                {
                    "sent": "Everybody has a feeling about it, but is there formal deafen?",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So before I come to that, let me give you an analogy.",
                    "label": 0
                },
                {
                    "sent": "I try to.",
                    "label": 0
                },
                {
                    "sent": "Display here, in which state machine learning or AI is?",
                    "label": 0
                },
                {
                    "sent": "So let's take analogy analogy from complexity theory, so complexity theory.",
                    "label": 0
                },
                {
                    "sent": "The goal is there to find fast algorithm solving problems and to show lower bounds on their computation time.",
                    "label": 1
                },
                {
                    "sent": "OK, that's one definition.",
                    "label": 0
                },
                {
                    "sent": "So if you dig a little bit deeper, all these terms are rigorously defined, so we know what an algorithm is.",
                    "label": 1
                },
                {
                    "sent": "We know what the Turing machine is, what a problem classes computation time.",
                    "label": 0
                },
                {
                    "sent": "They're all mathematical definitions.",
                    "label": 0
                },
                {
                    "sent": "But if you look at.",
                    "label": 0
                },
                {
                    "sent": "This discipline or other disciplines.",
                    "label": 0
                },
                {
                    "sent": "Most disciplines started in a quite wake.",
                    "label": 0
                },
                {
                    "sent": "State, for example, set theory was not always, you know, based on axioms, and you had the famous Russell.",
                    "label": 0
                },
                {
                    "sent": "Paradox or Russell set?",
                    "label": 0
                },
                {
                    "sent": "I'm logical reasoning was informal.",
                    "label": 0
                },
                {
                    "sent": "At Great Times, and now is completely formalized.",
                    "label": 0
                },
                {
                    "sent": "Infinity's email calculus.",
                    "label": 0
                },
                {
                    "sent": "Newton has big problems with it and invented the formal way of doing it.",
                    "label": 0
                },
                {
                    "sent": "In physics there are other examples, like every temperature energy there, well defined mathematical definitions nowadays.",
                    "label": 0
                },
                {
                    "sent": "And quantum field theories are in nearly a mathematical theory now.",
                    "label": 0
                },
                {
                    "sent": "So OK, most disciplines start in formal and then get completely formalized.",
                    "label": 0
                },
                {
                    "sent": "So if you look at machine learning.",
                    "label": 0
                },
                {
                    "sent": "So what does machine learning try to do?",
                    "label": 0
                },
                {
                    "sent": "It tries to build and understand systems that learn from past data, make good predictions, are able to generalize, act intelligently, or whatever you find for definitions in the Internet.",
                    "label": 1
                },
                {
                    "sent": "And if you try to look for precise definitions of these terms, you either find none or a lot of different definitions.",
                    "label": 0
                },
                {
                    "sent": "So most of these terms are vaguely defined, or there are many alternatives.",
                    "label": 0
                },
                {
                    "sent": "The machine learning is not yet at the stage.",
                    "label": 0
                },
                {
                    "sent": "We can say look, I mean this is well defined mathematically and the rest is just deduction.",
                    "label": 0
                },
                {
                    "sent": "And you could.",
                    "label": 0
                },
                {
                    "sent": "View.",
                    "label": 0
                },
                {
                    "sent": "One of the goals of this lecture to show how close you can get, I mean to a formal definition of.",
                    "label": 0
                },
                {
                    "sent": "Machine learning or AI.",
                    "label": 0
                },
                {
                    "sent": "So here's some induction examples the most.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Famous one, or at least probably oldest one is to predict Miss Piehler plus.",
                    "label": 0
                },
                {
                    "sent": "So I asked the following question.",
                    "label": 0
                },
                {
                    "sent": "So what is the probability that the sun will rise tomorrow?",
                    "label": 1
                },
                {
                    "sent": "Given that it had risen for the last D days, OK, and you could.",
                    "label": 0
                },
                {
                    "sent": "Maybe a little bit unusual problem, I mean, but the reasonable question becausw say if you think that doomsday is quite plausable tomorrow, you would probably, you know, leave this lecture and have some more fun.",
                    "label": 0
                },
                {
                    "sent": "Or state here the solution of problem I don't know depends on your loss function.",
                    "label": 0
                },
                {
                    "sent": "OK, so one answer would be peace undefined becausw.",
                    "label": 0
                },
                {
                    "sent": "There has never been an experiment that tested the existence of the sun tomorrow.",
                    "label": 1
                },
                {
                    "sent": "That is sort of denying the possibility of doing adduction at all.",
                    "label": 0
                },
                {
                    "sent": "Hume had arguments in this direction, and he didn't deny, I mean.",
                    "label": 0
                },
                {
                    "sent": "Obviously we all do induction and it somehow works, but can be justified.",
                    "label": 1
                },
                {
                    "sent": "So maybe it's just my gut feeling.",
                    "label": 0
                },
                {
                    "sent": "Or you say the probability is 1 big cause the sun rose in all past experiments, so that would be a frequentist estimate.",
                    "label": 0
                },
                {
                    "sent": "End times out of end the sun or D times out of the the sun rose.",
                    "label": 1
                },
                {
                    "sent": "You could also take a more.",
                    "label": 0
                },
                {
                    "sent": "Far.",
                    "label": 0
                },
                {
                    "sent": "Yeah, another statistical view, you estimate.",
                    "label": 0
                },
                {
                    "sent": "The proportions of style that explode per day from historic data.",
                    "label": 0
                },
                {
                    "sent": "And then you say it's 1 minus epsilon.",
                    "label": 0
                },
                {
                    "sent": "Or they lost the blue point.",
                    "label": 1
                },
                {
                    "sent": "It would be a physicist approach.",
                    "label": 0
                },
                {
                    "sent": "You take the type, type, age, size and temperature of the Suns or the physical data and estimate the probability that it explodes in a supernova or something.",
                    "label": 0
                },
                {
                    "sent": "I need to get some result.",
                    "label": 1
                },
                {
                    "sent": "In LA plus.",
                    "label": 0
                },
                {
                    "sent": "Set the probability should be D + 1 / D + 2.",
                    "label": 0
                },
                {
                    "sent": "Reduce the length of the history and I will derive this and if you forget everything about this lecture, just take two things or comes razor principle.",
                    "label": 0
                },
                {
                    "sent": "I will explain and this Laplace rule.",
                    "label": 0
                },
                {
                    "sent": "So that's really, really something fundamental and important.",
                    "label": 0
                },
                {
                    "sent": "In Bayes rule, of course.",
                    "label": 0
                },
                {
                    "sent": "OK, So what we have here?",
                    "label": 0
                },
                {
                    "sent": "We have many answers and many justifications.",
                    "label": 0
                },
                {
                    "sent": "So what is the right answer?",
                    "label": 0
                },
                {
                    "sent": "What is the best answer?",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Here's another example, so.",
                    "label": 0
                },
                {
                    "sent": "Who wants to predict this sequence here?",
                    "label": 0
                },
                {
                    "sent": "1415 and so on.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "For some it looks pretty random, so if you make a frequency estimate you would see that every digit occurs approximately equally often.",
                    "label": 1
                },
                {
                    "sent": "So you would say probably you know the next digit, the probability is just you know 10% for each possibility.",
                    "label": 1
                },
                {
                    "sent": "Or you see that it's just the digits after \u03c0. Digits after the comma, so 3.1415 and then of course I mean you start Mathematica and you compute the next digit and say oh, very likely it's 5.",
                    "label": 0
                },
                {
                    "sent": "Because you detect some pattern.",
                    "label": 0
                },
                {
                    "sent": "In this sequence you see some structure and once you see it, you wouldn't pretty uniform distribution for the next.",
                    "label": 0
                },
                {
                    "sent": "Symbol.",
                    "label": 0
                },
                {
                    "sent": "But I mean can be sure about it, that the five is next.",
                    "label": 0
                },
                {
                    "sent": "Warehouse where should we be?",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, that is close to IQ test.",
                    "label": 0
                },
                {
                    "sent": "I mean IQ tests what you have your sequences of numbers.",
                    "label": 0
                },
                {
                    "sent": "I mean the most simple IQ test would be 1234.",
                    "label": 0
                },
                {
                    "sent": "What comes next?",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "I guess most of you will answer 5.",
                    "label": 0
                },
                {
                    "sent": "'cause there's a simple pattern.",
                    "label": 0
                },
                {
                    "sent": "I mean, it's just always, you know, adding one.",
                    "label": 0
                },
                {
                    "sent": "But you can also justify it 29 it just take this nice 4th order polynomial and if you evaluate it at 1234 it also gives you 1234.",
                    "label": 0
                },
                {
                    "sent": "And then you plug in five and you get 29.",
                    "label": 0
                },
                {
                    "sent": "So I mean that.",
                    "label": 0
                },
                {
                    "sent": "Definitely explains you know the past sequence and gives you a prediction.",
                    "label": 0
                },
                {
                    "sent": "They are serious researchers.",
                    "label": 0
                },
                {
                    "sent": "Who tell you that it's just?",
                    "label": 0
                },
                {
                    "sent": "Social convention.",
                    "label": 0
                },
                {
                    "sent": "To predict 5.",
                    "label": 0
                },
                {
                    "sent": "I think this is ridiculous.",
                    "label": 1
                },
                {
                    "sent": "OK. Um?",
                    "label": 1
                },
                {
                    "sent": "I'll take the next sequence.",
                    "label": 0
                },
                {
                    "sent": "It is a little bit more tricky.",
                    "label": 0
                },
                {
                    "sent": "So I should hide it somehow.",
                    "label": 0
                },
                {
                    "sent": "OK, here's the answer.",
                    "label": 0
                },
                {
                    "sent": "So I mean, if you look at it, it looks like the digits of \u03c0 and 61 would be the natural next.",
                    "label": 0
                },
                {
                    "sent": "Item.",
                    "label": 0
                },
                {
                    "sent": "But if you know something about simple groups and they have orders, the number of elements and they have exactly the sequence, but then there's a simple group which has 60 elements.",
                    "label": 1
                },
                {
                    "sent": "The first simple group which is not of prime.",
                    "label": 0
                },
                {
                    "sent": "Order, So what would you do in IQ test?",
                    "label": 0
                },
                {
                    "sent": "So who would predict 61?",
                    "label": 0
                },
                {
                    "sent": "Who would predict 60?",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So here social convention is maybe closer to the truth, you predict 61 B cause you think about OK, you know many people know about primes, but very few people know about simple groups.",
                    "label": 0
                },
                {
                    "sent": "So the guy who designed it is probably knew about primes, and so this is your argument and.",
                    "label": 0
                },
                {
                    "sent": "You can.",
                    "label": 0
                },
                {
                    "sent": "In a certain sense, formalized rigorously this argument.",
                    "label": 0
                },
                {
                    "sent": "So what you do is you take your social background knowledge.",
                    "label": 0
                },
                {
                    "sent": "They take Wikipedia and then you try to predict the sequence relative to this background knowledge.",
                    "label": 1
                },
                {
                    "sent": "And if you formalize that and do it properly, the system will predict indeed 61.",
                    "label": 0
                },
                {
                    "sent": "I mean, if there's another civilization which starts with simple groups and all you know the Wikipedia page is there, you know, talk about simple groups, then you would predict 60.",
                    "label": 0
                },
                {
                    "sent": "OK yeah, this is a nice website.",
                    "label": 0
                },
                {
                    "sent": "This last link so often in research what you have is you have.",
                    "label": 0
                },
                {
                    "sent": "Some problem.",
                    "label": 0
                },
                {
                    "sent": "And it depends on some parameter N and you ask some questions.",
                    "label": 0
                },
                {
                    "sent": "And often the answer is, say some number.",
                    "label": 0
                },
                {
                    "sent": "So for N = 1 you get an answer in equal 2 and you can compute it by hand and you want to find the pattern.",
                    "label": 0
                },
                {
                    "sent": "Because once you have the patterns, or maybe then you can prove that this pattern is really there and it's not so often not so obvious.",
                    "label": 0
                },
                {
                    "sent": "I mean like 1234 or the primes, so you just type in your sequence here and it has a huge database and some CB smart algorithms for generalization.",
                    "label": 1
                },
                {
                    "sent": "And it gives you all.",
                    "label": 0
                },
                {
                    "sent": "Possible underlying.",
                    "label": 0
                },
                {
                    "sent": "I'm.",
                    "label": 0
                },
                {
                    "sent": "Regularity is the system knows of Orkin identified with.",
                    "label": 0
                },
                {
                    "sent": "So at least once in my life it was useful.",
                    "label": 0
                },
                {
                    "sent": "I wanted to prove something couldn't do it or computed before end equal 12345 typed it in, got some answer out for this sequence, hit the result in verifying the result is often much easier than driving it, so it's a real cool side.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So so.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Add, you know some examples and some explanations for these examples are physics, explanations are.",
                    "label": 0
                },
                {
                    "sent": "Social explanations and others for the polynomial didn't give an explanation because it's obvious.",
                    "label": 0
                },
                {
                    "sent": "But if you think about it, what is unifying all these explanations?",
                    "label": 0
                },
                {
                    "sent": "They're all biased towards simplicity somehow, and that is actually what all comes.",
                    "label": 0
                },
                {
                    "sent": "Razor tells you.",
                    "label": 0
                },
                {
                    "sent": "You should use the simplest explanation.",
                    "label": 1
                },
                {
                    "sent": "So this line, which is consistent with the path data.",
                    "label": 0
                },
                {
                    "sent": "And use it for prediction.",
                    "label": 1
                },
                {
                    "sent": "And if you go through these examples, except maybe for the simple group example you have to.",
                    "label": 0
                },
                {
                    "sent": "I mean this principle still works, but you have to be a little more careful.",
                    "label": 0
                },
                {
                    "sent": "This principle really gives you the right answer.",
                    "label": 0
                },
                {
                    "sent": "On an intuitive level, I mean, I haven't formalized anything in yet.",
                    "label": 0
                },
                {
                    "sent": "And actually all comes Razor, there's even more.",
                    "label": 1
                },
                {
                    "sent": "It serves as a foundation of machine learning in general.",
                    "label": 1
                },
                {
                    "sent": "So not just for induction and is even a fundamental principle.",
                    "label": 0
                },
                {
                    "sent": "Or maybe the definition.",
                    "label": 0
                },
                {
                    "sent": "What scientists do?",
                    "label": 0
                },
                {
                    "sent": "I mean you have your data and you want to understand the data.",
                    "label": 0
                },
                {
                    "sent": "What does understanding the data mean?",
                    "label": 0
                },
                {
                    "sent": "We normally you construct models for this data.",
                    "label": 0
                },
                {
                    "sent": "OK, for every day to have a simple model and not simple.",
                    "label": 0
                },
                {
                    "sent": "I have one model, namely the data itself.",
                    "label": 0
                },
                {
                    "sent": "It's a model of the data, but it's pretty stupid.",
                    "label": 0
                },
                {
                    "sent": "So what you try to find is to try to find a simple model.",
                    "label": 0
                },
                {
                    "sent": "And the primary reason is not becausw you would not be able to deal with the complex model.",
                    "label": 0
                },
                {
                    "sent": "Because the simpler model for some reason.",
                    "label": 0
                },
                {
                    "sent": "Turns out to be useful, more useful in many cases than the more complex model.",
                    "label": 1
                },
                {
                    "sent": "Basically, with overfitting in these things.",
                    "label": 0
                },
                {
                    "sent": "So far so good.",
                    "label": 1
                },
                {
                    "sent": "Problem is that everything is awake so far.",
                    "label": 0
                },
                {
                    "sent": "So that's not a formal mathematical objective principle.",
                    "label": 0
                },
                {
                    "sent": "So what is simple for one might be complex for another.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "Um, I would do the devote most of a lot of my time to formalizing this principle.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Here's another example.",
                    "label": 0
                },
                {
                    "sent": "I will not solve it here, just yeah.",
                    "label": 0
                },
                {
                    "sent": "Yeah, I'll do that later.",
                    "label": 0
                },
                {
                    "sent": "In terms of, of complexity.",
                    "label": 0
                },
                {
                    "sent": "OK, here's another nice example from philosophy.",
                    "label": 0
                },
                {
                    "sent": "You have two hypothesis.",
                    "label": 0
                },
                {
                    "sent": "One is all emeralds are green and the other one is all emeralds found till 2010 are green.",
                    "label": 1
                },
                {
                    "sent": "And then thereafter there suddenly blue.",
                    "label": 1
                },
                {
                    "sent": "So, which hypothesis more plausible?",
                    "label": 1
                },
                {
                    "sent": "And of course you all say H1 is more plausible, and what is the justification?",
                    "label": 0
                },
                {
                    "sent": "Yeah, you can invoke Arkansas razor.",
                    "label": 0
                },
                {
                    "sent": "The first hypothesis is simpler than the 2nd.",
                    "label": 0
                },
                {
                    "sent": "Just count the number of letters.",
                    "label": 0
                },
                {
                    "sent": "For instance.",
                    "label": 0
                },
                {
                    "sent": "In this case I mean.",
                    "label": 0
                },
                {
                    "sent": "It's a measure of simplicity.",
                    "label": 0
                },
                {
                    "sent": "Since I have no pointer.",
                    "label": 0
                },
                {
                    "sent": "You gotta change something here.",
                    "label": 0
                },
                {
                    "sent": "Try this song.",
                    "label": 0
                },
                {
                    "sent": "OK. Yeah.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "I don't like this particular example, but I mean we can stay with it.",
                    "label": 0
                },
                {
                    "sent": "Of course you can fail.",
                    "label": 0
                },
                {
                    "sent": "You have some data which have.",
                    "label": 0
                },
                {
                    "sent": "Some regulatory or maybe some usefulness or not, and then you make some conclusion and then later you find out reality is more complex.",
                    "label": 0
                },
                {
                    "sent": "Then you have to revise your model.",
                    "label": 0
                },
                {
                    "sent": "And you made an error.",
                    "label": 0
                },
                {
                    "sent": "And it might have been better to start with a more complex model.",
                    "label": 0
                },
                {
                    "sent": "But I will show you a result which more or less shows that it's always better to start with a simple model and then you count the number of revisions you have to make in your model.",
                    "label": 0
                },
                {
                    "sent": "And this number is fairly small and in a certain sense optimal.",
                    "label": 0
                },
                {
                    "sent": "So you would converge.",
                    "label": 0
                },
                {
                    "sent": "Having enough normally data or in this case may be enough written enough, you know useful papers about it, you would converge.",
                    "label": 0
                },
                {
                    "sent": "Must be something really new.",
                    "label": 0
                },
                {
                    "sent": "You may have different looks very good.",
                    "label": 0
                },
                {
                    "sent": "Yeah, that's that's a reasonable bias, isn't it?",
                    "label": 0
                },
                {
                    "sent": "I mean, if something is really different.",
                    "label": 0
                },
                {
                    "sent": "Normally you need a little bit more convincing proof that you know.",
                    "label": 0
                },
                {
                    "sent": "That is good.",
                    "label": 0
                },
                {
                    "sent": "OK, here's another nice paradox.",
                    "label": 0
                },
                {
                    "sent": "Yeah, the logicians will like that more.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Assume you want to confirm the rules that are implies B.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So for instance, that all Ravens are black, so if something has the property of being a Raven, it has also the property of being black.",
                    "label": 0
                },
                {
                    "sent": "And normally what you do is you go out and you observe Ravens and you know black Raven, other black Raven, black Raven and once you have enough you say oh this rule is plausable.",
                    "label": 0
                },
                {
                    "sent": "You can never be sure.",
                    "label": 0
                },
                {
                    "sent": "Of course yeah, but you can say you know maybe 99% or you make some qualitative measure.",
                    "label": 0
                },
                {
                    "sent": "OK, that's how you confirm implications or rules.",
                    "label": 0
                },
                {
                    "sent": "So now let's abstract and look at R and paying.",
                    "label": 0
                },
                {
                    "sent": "Don't forget the interpretation.",
                    "label": 0
                },
                {
                    "sent": "So here obviously ever replace R by not B&B by not R, and I believe that one now.",
                    "label": 0
                },
                {
                    "sent": "It's proper then I have to believe in the second one so that.",
                    "label": 0
                },
                {
                    "sent": "If you have not been instances with the property of not R, it must confirm the rule, not B implies not R. I mean, it's it's the same, just enough.",
                    "label": 0
                },
                {
                    "sent": "The Contraposition, who has seen the confirmation paradox before?",
                    "label": 0
                },
                {
                    "sent": "OK, someone at all so.",
                    "label": 0
                },
                {
                    "sent": "I'm so, so far so good.",
                    "label": 0
                },
                {
                    "sent": "But now we know, or you know, that are implied.",
                    "label": 0
                },
                {
                    "sent": "Speed is logically equivalent to not be implies not R. That means that also the second instance is that don't be.",
                    "label": 0
                },
                {
                    "sent": "Instance is not.",
                    "label": 0
                },
                {
                    "sent": "R must imply the first rule because they imply you know the second rule.",
                    "label": 0
                },
                {
                    "sent": "In the second rule is logically equivalent to the first one.",
                    "label": 0
                },
                {
                    "sent": "OK, let's use that.",
                    "label": 0
                },
                {
                    "sent": "So here we say, Ravens and blackness are NP.",
                    "label": 0
                },
                {
                    "sent": "And of course, if you observe black Ravens, it confirms hypothesis.",
                    "label": 0
                },
                {
                    "sent": "Zero everybody.",
                    "label": 0
                },
                {
                    "sent": "I hope everybody agrees to that.",
                    "label": 0
                },
                {
                    "sent": "But now I can use.",
                    "label": 0
                },
                {
                    "sent": "The logical #3 and just take White Sox.",
                    "label": 0
                },
                {
                    "sent": "Becausw White Sox are not black, not Ravens.",
                    "label": 0
                },
                {
                    "sent": "So they confirmed the rule that all not Ravens are not black objects are not Raven, so it confirms the rule that all Ravens are black.",
                    "label": 1
                },
                {
                    "sent": "So that makes life much simpler.",
                    "label": 0
                },
                {
                    "sent": "Just open my drawer and look at the number of my white socks and conclude that all Ravens are black.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Oh yeah, yeah, yeah.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "No, no, I don't think so for all X. Raven of X implies Blackness of Axis and I only do the counter positioning in in the inner thing.",
                    "label": 0
                },
                {
                    "sent": "No, no, I mean.",
                    "label": 0
                },
                {
                    "sent": "Wait, wait.",
                    "label": 0
                },
                {
                    "sent": "I mean this is the point of induction versus deduction.",
                    "label": 0
                },
                {
                    "sent": "I mean, if you do detection, you observe the whole universe to conclude something, but do you do that?",
                    "label": 0
                },
                {
                    "sent": "What do you tell?",
                    "label": 0
                },
                {
                    "sent": "You know a 5 year old child.",
                    "label": 0
                },
                {
                    "sent": "Do you think all Ravens are black or not?",
                    "label": 0
                },
                {
                    "sent": "And then you say are probably all Ravens are black.",
                    "label": 0
                },
                {
                    "sent": "Have you observed all black Ravens in the world?",
                    "label": 0
                },
                {
                    "sent": "I guess not.",
                    "label": 0
                },
                {
                    "sent": "Yes, sure.",
                    "label": 0
                },
                {
                    "sent": "I mean, if you if you define a paradox as logical contradiction.",
                    "label": 0
                },
                {
                    "sent": "It is a paradox in the following sense look.",
                    "label": 0
                },
                {
                    "sent": "Do you believe that this is a reasonable principle?",
                    "label": 0
                },
                {
                    "sent": "Observing black Ravens.",
                    "label": 0
                },
                {
                    "sent": "Confirms the hypothesis.",
                    "label": 0
                },
                {
                    "sent": "That all Ravens are black.",
                    "label": 0
                },
                {
                    "sent": "I mean, you can never be sure with induction, yeah, but you can, you know be more and more convinced formalized that somehow with probabilities or with other types of us.",
                    "label": 0
                },
                {
                    "sent": "So do you believe that this is a reasonable principle?",
                    "label": 0
                },
                {
                    "sent": "Yes, and if you believe that this is reasonable, you must also believe that observing white socks helps you in confirming this hypothesis.",
                    "label": 0
                },
                {
                    "sent": "So if you if you accept.",
                    "label": 0
                },
                {
                    "sent": "1.",
                    "label": 0
                },
                {
                    "sent": "You have a.",
                    "label": 0
                },
                {
                    "sent": "You have to accept this one here the last line.",
                    "label": 0
                },
                {
                    "sent": "At least it looks like it, and it works.",
                    "label": 0
                },
                {
                    "sent": "I mean there's a paradox, yeah?",
                    "label": 0
                },
                {
                    "sent": "They grew OK. We will come back to that.",
                    "label": 0
                },
                {
                    "sent": "Yeah, and.",
                    "label": 0
                },
                {
                    "sent": "Yeah, I don't have the time to talk about the solution, but I mean one thing is.",
                    "label": 0
                },
                {
                    "sent": "That this is not the real solution, but I mean that's a good starting point that while our so.",
                    "label": 0
                },
                {
                    "sent": "You can say or imply speed.",
                    "label": 0
                },
                {
                    "sent": "If you go to probabilities, you say that the probability of being black given a Raven.",
                    "label": 0
                },
                {
                    "sent": "Is 1.",
                    "label": 0
                },
                {
                    "sent": "If you translate this rule, this would be the probability of, not.",
                    "label": 0
                },
                {
                    "sent": "Raven given not blackness.",
                    "label": 0
                },
                {
                    "sent": "Is equal to 1.",
                    "label": 0
                },
                {
                    "sent": "Logically.",
                    "label": 0
                },
                {
                    "sent": "These two are the same.",
                    "label": 0
                },
                {
                    "sent": "But these two probabilities can be completely different.",
                    "label": 0
                },
                {
                    "sent": "You can show that if this probability is 1, then this must also be one.",
                    "label": 0
                },
                {
                    "sent": "So in the extreme case of probabilities being one or zero.",
                    "label": 0
                },
                {
                    "sent": "You have this tight.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Connection.",
                    "label": 0
                },
                {
                    "sent": "But if this probability is smaller than one, say 0.9, this can be anything even 0.01 or something.",
                    "label": 0
                },
                {
                    "sent": "So you lose this.",
                    "label": 0
                },
                {
                    "sent": "I'm.",
                    "label": 0
                },
                {
                    "sent": "Tight connection in the contraposition, so that's just a hint.",
                    "label": 0
                },
                {
                    "sent": "The full story is much longer.",
                    "label": 0
                },
                {
                    "sent": "There.",
                    "label": 0
                },
                {
                    "sent": "I think at least hundred 100 papers about this problem.",
                    "label": 0
                },
                {
                    "sent": "You know the typical philosophical blah blah papers, but also some good philosophical.",
                    "label": 0
                },
                {
                    "sent": "But they also.",
                    "label": 0
                },
                {
                    "sent": "A number of philosophers who know some math and we have some here at the end you.",
                    "label": 0
                },
                {
                    "sent": "So Alan Hyatt, for instance.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Yeah, so also good papers with the best.",
                    "label": 0
                },
                {
                    "sent": "I mean, if you're the best reading to start with is Patrick.",
                    "label": 0
                },
                {
                    "sent": "Maja there's a 2004 paper in some edited book which is not so easy to access.",
                    "label": 0
                },
                {
                    "sent": "And then there's an older 1999 paper which is.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Better this, but this is OK if you can't get grab the other one.",
                    "label": 0
                },
                {
                    "sent": "And there's of course my paper, which finally solves it.",
                    "label": 0
                },
                {
                    "sent": "2000 unusable universal prediction and.",
                    "label": 0
                },
                {
                    "sent": "Confirmation or something, so that's the confirmation paradox.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so now we go back to the grew Emerald, yeah.",
                    "label": 0
                },
                {
                    "sent": "So we're wondering which my love.",
                    "label": 0
                },
                {
                    "sent": "How about this one?",
                    "label": 0
                },
                {
                    "sent": "Very simple this letter so it's easy.",
                    "label": 0
                },
                {
                    "sent": "But that seems.",
                    "label": 0
                },
                {
                    "sent": "Yeah, I know this example, and that's not a complete solution.",
                    "label": 0
                },
                {
                    "sent": "I mean, maybe you presented to the others.",
                    "label": 0
                },
                {
                    "sent": "I mean, you redefine the language.",
                    "label": 0
                },
                {
                    "sent": "I'm instead of green and blue.",
                    "label": 0
                },
                {
                    "sent": "You talk about grew and clean, which are defined so that the swap at 2010 and then hypothesis to get simpler than hypothesis.",
                    "label": 0
                },
                {
                    "sent": "One, and I mean this is sort of.",
                    "label": 0
                },
                {
                    "sent": "Deeper paradox and I have.",
                    "label": 0
                },
                {
                    "sent": "Some answers to it.",
                    "label": 0
                },
                {
                    "sent": "But it's still open.",
                    "label": 0
                },
                {
                    "sent": "OK, I mean the we can discuss that.",
                    "label": 0
                },
                {
                    "sent": "Maybe in the break or after Watts it's it's.",
                    "label": 0
                },
                {
                    "sent": "It's.",
                    "label": 0
                },
                {
                    "sent": "It's subtle and you know it's not that I can present one formula and that's it and solved.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "That is now the last slide of the philosophy part.",
                    "label": 0
                },
                {
                    "sent": "I guess so.",
                    "label": 0
                },
                {
                    "sent": "So the general problem set up just repeat from the first slide.",
                    "label": 0
                },
                {
                    "sent": "Am I look at sequence prediction problems?",
                    "label": 1
                },
                {
                    "sent": "Because most induction problems can be phrased like that.",
                    "label": 1
                },
                {
                    "sent": "For instance, even a classification problem.",
                    "label": 0
                },
                {
                    "sent": "I mean what you have there, you have features and class labels, so you have this.",
                    "label": 0
                },
                {
                    "sent": "Feature class label.",
                    "label": 0
                },
                {
                    "sent": "So you have a data set like that.",
                    "label": 0
                },
                {
                    "sent": "What do you do with it?",
                    "label": 0
                },
                {
                    "sent": "I mean, you have a new instance in some point.",
                    "label": 1
                },
                {
                    "sent": "And you want to predict the class label.",
                    "label": 0
                },
                {
                    "sent": "OK, so that's the sequence prediction problem.",
                    "label": 0
                },
                {
                    "sent": "You have feature class label feature, class, label feature, blah blah blah feature class label feature.",
                    "label": 0
                },
                {
                    "sent": "What comes next.",
                    "label": 0
                },
                {
                    "sent": "OK, I mentioned it already that.",
                    "label": 0
                },
                {
                    "sent": "Prediction itself is not the ultimate goal, but you want to do something with the prediction.",
                    "label": 0
                },
                {
                    "sent": "So maximize your profit or minimize your loss.",
                    "label": 0
                },
                {
                    "sent": "I will mostly consider you know this.",
                    "label": 0
                },
                {
                    "sent": "Second decision theoretic.",
                    "label": 0
                },
                {
                    "sent": "Step on top of it.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "Maybe you wonder at some point in other machine and electrodes they were always the issue about noise and useful data and separate them and having these models I will not talk about separating noise from useful data becausw in this very abstract framework.",
                    "label": 0
                },
                {
                    "sent": "You Luckily don't need to do that, so that is very convenient.",
                    "label": 0
                },
                {
                    "sent": "OK, so that's the setup.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "There's another slide.",
                    "label": 0
                },
                {
                    "sent": "What I do in this lecture and whatnot, so the blue things I will discuss or touch at least, and the black things not.",
                    "label": 1
                },
                {
                    "sent": "So I will talk more about the machine learning angle rather than the good old patient AI.",
                    "label": 1
                },
                {
                    "sent": "Angle.",
                    "label": 0
                },
                {
                    "sent": "Mentioned already, that induction is ultimately used for decision-making so.",
                    "label": 0
                },
                {
                    "sent": "They will concentrate on that.",
                    "label": 1
                },
                {
                    "sent": "I will not go in tell much about classification and regression or any IID stuff, But the sequence prediction stuff and an ID stuff.",
                    "label": 0
                },
                {
                    "sent": "I will mostly talk about online learning, so you make a prediction or a decision, then you get the next observation and you learn from it and you improve.",
                    "label": 0
                },
                {
                    "sent": "And then you make another prediction or action and you learn.",
                    "label": 0
                },
                {
                    "sent": "I think I can.",
                    "label": 0
                },
                {
                    "sent": "Keep this, I mean you can just read it.",
                    "label": 0
                },
                {
                    "sent": "This.",
                    "label": 0
                },
                {
                    "sent": "To talk to me, I hope somebody of the others in the machine learning have told you the difference between supervised learning, unsupervised learning, reinforcement learning and who wants an explanation of that.",
                    "label": 1
                },
                {
                    "sent": "No OK good.",
                    "label": 0
                },
                {
                    "sent": "I'm.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "So that's the set up a little bit more formally.",
                    "label": 0
                },
                {
                    "sent": "I'm at times T123.",
                    "label": 0
                },
                {
                    "sent": "You have a predictor, which means your prediction.",
                    "label": 0
                },
                {
                    "sent": "YT index P means predictor, P is doing it based on past observations, X one up to T -- 1.",
                    "label": 1
                },
                {
                    "sent": "Then you observe the XT&P suffer some loss which depends on the prediction in the two outcome.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "Then you add up the total loss from time one up to you know the time you die or you get bored.",
                    "label": 0
                },
                {
                    "sent": "So this is your total loss and you want.",
                    "label": 0
                },
                {
                    "sent": "Of course you know to minimize your loss somehow.",
                    "label": 0
                },
                {
                    "sent": "Here's the classical weather forecasting example, and here's my personal loss function.",
                    "label": 0
                },
                {
                    "sent": "So you have sunny and rainy and they have the possible outcomes and the possible predictions or decissions are umbrella and sunglasses.",
                    "label": 0
                },
                {
                    "sent": "I mean here you have a tight connection between sun and sunglasses, umbrella and rain, but it could be completely different spaces.",
                    "label": 0
                },
                {
                    "sent": "I mean, often it's exactly the same space or closely related, but it doesn't have to be.",
                    "label": 0
                },
                {
                    "sent": "And then I mean the best.",
                    "label": 0
                },
                {
                    "sent": "Option is if it's sunny and you have your sunglasses, there is zero loss and the worst thing is you have your sunglasses and it rains because if you had umbrella I mean at least you don't get that.",
                    "label": 0
                },
                {
                    "sent": "And this loss function days.",
                    "label": 0
                },
                {
                    "sent": "Essentially, all theory for a good loss function, because this is the definition of your problem or what your personal goal is.",
                    "label": 0
                },
                {
                    "sent": "So everybody has his own loss function.",
                    "label": 0
                },
                {
                    "sent": "Sorry.",
                    "label": 0
                },
                {
                    "sent": "You know, maybe I know Australians are different because he is always sunny and you are happy with the rain.",
                    "label": 0
                },
                {
                    "sent": "But I come from Germany.",
                    "label": 0
                },
                {
                    "sent": "And we like son, 'cause you know, we don't get it every day.",
                    "label": 0
                },
                {
                    "sent": "So what was the question?",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Yes, still prefer some to rain.",
                    "label": 0
                },
                {
                    "sent": "We got a list.",
                    "label": 0
                },
                {
                    "sent": "Yeah, but look.",
                    "label": 0
                },
                {
                    "sent": "I mean look, I take my umbrella and go out and it's still sunny.",
                    "label": 0
                },
                {
                    "sent": "I closed umbrella or mean even over usage and then I have a shade so it's nice weather.",
                    "label": 0
                },
                {
                    "sent": "But I mean, maybe you're different.",
                    "label": 0
                },
                {
                    "sent": "So put some other numbers in.",
                    "label": 0
                },
                {
                    "sent": "So I prefer sun over rain.",
                    "label": 0
                },
                {
                    "sent": "Whatever I take my umbrella on my sunglasses.",
                    "label": 0
                },
                {
                    "sent": "So that's.",
                    "label": 0
                },
                {
                    "sent": "Yeah, I mean often these loss functions you're right, this is a little bit of an unused loss function.",
                    "label": 0
                },
                {
                    "sent": "Normally you have you say AB and you do or predict something AB and then you say if you do it correctly you have zero.",
                    "label": 0
                },
                {
                    "sent": "Lausanne often it's.",
                    "label": 0
                },
                {
                    "sent": "It is diagonal, which is not the case here, so it's.",
                    "label": 0
                },
                {
                    "sent": "Unusual, but OK that happens and it shows you that it's important to.",
                    "label": 0
                },
                {
                    "sent": "Be careful about the loss.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So that was the easy part.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Anymore questions.",
                    "label": 0
                },
                {
                    "sent": "So now let's I'm become more mathematical.",
                    "label": 0
                },
                {
                    "sent": "Still a little bit more philosophy for the logicians.",
                    "label": 0
                },
                {
                    "sent": "Probabilities can mean many things, and I give some interpretations.",
                    "label": 0
                },
                {
                    "sent": "Then I come to the important base.",
                    "label": 0
                },
                {
                    "sent": "In Laplace rule I mentioned at the beginning.",
                    "label": 0
                },
                {
                    "sent": "So this you should remember.",
                    "label": 0
                },
                {
                    "sent": "Another nice paradox, the envelope paradox and then some real hard results.",
                    "label": 1
                },
                {
                    "sent": "I mean not so hard, but I mean no.",
                    "label": 0
                },
                {
                    "sent": "Math.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so uncertain probability.",
                    "label": 0
                },
                {
                    "sent": "So the aim of probability is to describe uncertainty.",
                    "label": 1
                },
                {
                    "sent": "OK, so they're very sources.",
                    "label": 1
                },
                {
                    "sent": "There's a frequentist point of view that you just, you know, count the relative frequency.",
                    "label": 0
                },
                {
                    "sent": "Or you.",
                    "label": 0
                },
                {
                    "sent": "That only works for IID data.",
                    "label": 0
                },
                {
                    "sent": "I have more slides on that or your objective instances.",
                    "label": 1
                },
                {
                    "sent": "Randomness is a real property of the world.",
                    "label": 0
                },
                {
                    "sent": "Say the Atom decays with a certain probability and it's a property of the physical world.",
                    "label": 0
                },
                {
                    "sent": "Or in AI you often have the subjective stance that probabilities are just degrees of belief of an agent.",
                    "label": 0
                },
                {
                    "sent": "So for instance, if I say, it's implausible that extraterrestrials exist.",
                    "label": 0
                },
                {
                    "sent": "I mean, either they exist or not.",
                    "label": 0
                },
                {
                    "sent": "But I cannot believe over it, so it can be quite certain save is 90% probability, whatever that means.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the frequency is that what you learn in school.",
                    "label": 0
                },
                {
                    "sent": "So you have independent identically trials.",
                    "label": 1
                },
                {
                    "sent": "Certain so flip coins.",
                    "label": 1
                },
                {
                    "sent": "You look how often some event occurs.",
                    "label": 0
                },
                {
                    "sent": "So for instance head, you divide it by the length of the sequence that it gives the frequency estimate, and what you can show is that in the limit for long sequences this converges.",
                    "label": 1
                },
                {
                    "sent": "To sum real number between, of course zero and one.",
                    "label": 0
                },
                {
                    "sent": "And you say this is the probability of the event.",
                    "label": 1
                },
                {
                    "sent": "OK. What is wrong with that?",
                    "label": 0
                },
                {
                    "sent": "Can't be anything wrong with it, but there is.",
                    "label": 0
                },
                {
                    "sent": "OK, here's the example.",
                    "label": 1
                },
                {
                    "sent": "I just gave you tossing off a fair coin for coin would converge to 1/2.",
                    "label": 0
                },
                {
                    "sent": "But that's not really true.",
                    "label": 0
                },
                {
                    "sent": "It does not always converge to 1/2.",
                    "label": 0
                },
                {
                    "sent": "If you flip the coin its head, you flip another time it's head, head, head, head.",
                    "label": 1
                },
                {
                    "sent": "And so on, and then it converges to one.",
                    "label": 0
                },
                {
                    "sent": "So I have proved that it does not converge to 1/2.",
                    "label": 0
                },
                {
                    "sent": "Now, you'll probably say I mean look.",
                    "label": 0
                },
                {
                    "sent": "I mean, this is extremely unlikely that this happens.",
                    "label": 0
                },
                {
                    "sent": "Yes, you're right, but it may happen.",
                    "label": 0
                },
                {
                    "sent": "So you can say with high probability it converges to 1/2.",
                    "label": 0
                },
                {
                    "sent": "So, but what does probability mean?",
                    "label": 0
                },
                {
                    "sent": "I mean, this is supposed to define probability and now you start, you know, with an intuitive notion of probability.",
                    "label": 0
                },
                {
                    "sent": "So the definition is circular.",
                    "label": 0
                },
                {
                    "sent": "So it's not that easy.",
                    "label": 0
                },
                {
                    "sent": "The next refinement would be hard look.",
                    "label": 0
                },
                {
                    "sent": "I know the probability for infinitely long sequence is 1, so at least I have reduced the problem of defining what probability means to the problem of.",
                    "label": 0
                },
                {
                    "sent": "What does probability one mean?",
                    "label": 0
                },
                {
                    "sent": "Which is, you know, some step forward and there's I will not go into that.",
                    "label": 0
                },
                {
                    "sent": "There's kernels principle and he said everything which happens with probability one in statistics happens for sure.",
                    "label": 0
                },
                {
                    "sent": "In the real world.",
                    "label": 0
                },
                {
                    "sent": "It's a principle.",
                    "label": 0
                },
                {
                    "sent": "Which is a reasonable principle.",
                    "label": 0
                },
                {
                    "sent": "I mean, find a counterexample.",
                    "label": 0
                },
                {
                    "sent": "So and then I mean that is one way to define probabilities and make sense out of them.",
                    "label": 0
                },
                {
                    "sent": "And there are others.",
                    "label": 0
                },
                {
                    "sent": "Sense out of frequent.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Probabilities OK, the objective.",
                    "label": 0
                },
                {
                    "sent": "Interpretations that real aspects of the world.",
                    "label": 1
                },
                {
                    "sent": "You make some experiments and it was some physical render process.",
                    "label": 0
                },
                {
                    "sent": "And here's the formal definition, which.",
                    "label": 0
                },
                {
                    "sent": "You haven't sample space, you have some event.",
                    "label": 0
                },
                {
                    "sent": "And you have some IID experiments now.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "So then you write down some axioms here.",
                    "label": 0
                },
                {
                    "sent": "Here there's a standard probability axioms, and if you have IID experiments then you can show that this probability axioms are satisfied and now you forget about the ID and say, OK, you know this is my starting point.",
                    "label": 0
                },
                {
                    "sent": "This is my exams start from another question that.",
                    "label": 0
                },
                {
                    "sent": "And that's axiomatic probability theory and measure theory.",
                    "label": 0
                },
                {
                    "sent": "I mean you learn.",
                    "label": 0
                },
                {
                    "sent": "I'm in your math courses.",
                    "label": 0
                },
                {
                    "sent": "And then if somebody wants to apply it and interpret it.",
                    "label": 0
                },
                {
                    "sent": "I mean it's not.",
                    "label": 1
                },
                {
                    "sent": "The problem of the mathematician.",
                    "label": 0
                },
                {
                    "sent": "I don't care, you just proved theorems.",
                    "label": 0
                },
                {
                    "sent": "OK, that's the objective.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Interpretation and the subjective interpretation as degrees of belief.",
                    "label": 1
                },
                {
                    "sent": "I mentioned that.",
                    "label": 0
                },
                {
                    "sent": "And normally you you require that is greater than 0.",
                    "label": 0
                },
                {
                    "sent": "Otherwise it's either undefined or you define it.",
                    "label": 0
                },
                {
                    "sent": "Somehow, you know either zero or one.",
                    "label": 0
                },
                {
                    "sent": "Sometimes it's useful to give it a value, but strict in strict measure theory it's undefined.",
                    "label": 0
                },
                {
                    "sent": "I'm.",
                    "label": 0
                },
                {
                    "sent": "Not really, because I mean what happens is the following and even in measure theory books you see that people get sloppy and.",
                    "label": 0
                },
                {
                    "sent": "Although they are mathematicians, but if it's a good book at the beginning, it explains what is going on.",
                    "label": 0
                },
                {
                    "sent": "If you condition on a probability 0 event.",
                    "label": 0
                },
                {
                    "sent": "And you forget about that.",
                    "label": 0
                },
                {
                    "sent": "It's undefined and just proceed.",
                    "label": 0
                },
                {
                    "sent": "You just do nonsense.",
                    "label": 0
                },
                {
                    "sent": "But this nonsense happens with probability 0.",
                    "label": 0
                },
                {
                    "sent": "So with probability one, what you're doing makes still sense.",
                    "label": 0
                },
                {
                    "sent": "So all theorems you conclude still hold, but you have to add the qualifier only with probability one.",
                    "label": 0
                },
                {
                    "sent": "So there are a lot of theorems in probability theory and.",
                    "label": 0
                },
                {
                    "sent": "Where you think, Oh my, why is this probability one statement there cause it may be not defined.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "They would rightly probability of some event.",
                    "label": 0
                },
                {
                    "sent": "They save level stuff while we stayed with 180 or one.",
                    "label": 0
                },
                {
                    "sent": "That is something that we can condition overlay or something, but it is a. Yeah.",
                    "label": 0
                },
                {
                    "sent": "No, but what is the answer?",
                    "label": 0
                },
                {
                    "sent": "I mean?",
                    "label": 0
                },
                {
                    "sent": "I mean, if the probability of.",
                    "label": 0
                },
                {
                    "sent": "A is 0 whatever age you may use.",
                    "label": 0
                },
                {
                    "sent": "Link your sequence over ever consider.",
                    "label": 0
                },
                {
                    "sent": "And then you ask the probability of being given a.",
                    "label": 0
                },
                {
                    "sent": "What's that?",
                    "label": 0
                },
                {
                    "sent": "By definition, the conditional probability is defined to be P of A and B / P of B, which is 0 / 0.",
                    "label": 0
                },
                {
                    "sent": "It can be considered arbitrary, you say.",
                    "label": 0
                },
                {
                    "sent": "Your divided by zero, yeah?",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "Yeah, there's one important cases, yeah, but for instance.",
                    "label": 0
                },
                {
                    "sent": "OK, mathematically what you can do is you can define versions of conditional probability.",
                    "label": 0
                },
                {
                    "sent": "I don't know whether you refer to that, and indeed it occurs.",
                    "label": 0
                },
                {
                    "sent": "For instance if you have.",
                    "label": 0
                },
                {
                    "sent": "Two real numbers X&Y and you have a probability density of that then.",
                    "label": 0
                },
                {
                    "sent": "I mean, formally you can compute the probability density of X given Y is the ratio, because these are densities, then are not zero.",
                    "label": 0
                },
                {
                    "sent": "But if you ask what is the probability?",
                    "label": 0
                },
                {
                    "sent": "That X is in some SpaceX given a particular Y.",
                    "label": 0
                },
                {
                    "sent": "You have.",
                    "label": 0
                },
                {
                    "sent": "P of something in the denominator get asked for the probability of Y.",
                    "label": 0
                },
                {
                    "sent": "But if you have, if this is a real number and you have a probability density, then the probability of any particular point is 0.",
                    "label": 0
                },
                {
                    "sent": "In this case, I mean we all do it and extremely useful to assign a number, and you typically don't do it with relative support with densities, which is sort of a derivative.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "So that would be a.",
                    "label": 0
                },
                {
                    "sent": "A less trivial extension than just defining it randomly to be one or zero, but there is.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "How is it?",
                    "label": 0
                },
                {
                    "sent": "Paradox called on the sphere got the name from some guy with B.",
                    "label": 0
                },
                {
                    "sent": "No, no no, not not this one.",
                    "label": 0
                },
                {
                    "sent": "I will motional simple one.",
                    "label": 0
                },
                {
                    "sent": "I'm.",
                    "label": 0
                },
                {
                    "sent": "Do the following.",
                    "label": 0
                },
                {
                    "sent": "Take a uniform distribution on a sphere.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "Now assume your data point landed on the equator.",
                    "label": 0
                },
                {
                    "sent": "And ask what is the probability distribution on this ring given that your data point landed on this ring.",
                    "label": 0
                },
                {
                    "sent": "So the probability of.",
                    "label": 0
                },
                {
                    "sent": "Yeah, just what I said.",
                    "label": 0
                },
                {
                    "sent": "And if the distribution was uniform on the sphere, well, OK.",
                    "label": 0
                },
                {
                    "sent": "I mean, it should be then uniform on the ring, and this is what you get out.",
                    "label": 0
                },
                {
                    "sent": "Now doing the most knife calculation in polar coordinates, now you ask for this ring here.",
                    "label": 0
                },
                {
                    "sent": "And what you get is a non uniform distribution.",
                    "label": 0
                },
                {
                    "sent": "Yeah, it's still uniform on the sphere.",
                    "label": 0
                },
                {
                    "sent": "So if you then look at it, what happens?",
                    "label": 0
                },
                {
                    "sent": "It depends on your parameterization of the sphere or so it's original uniform which has nothing to do with the parameterization.",
                    "label": 0
                },
                {
                    "sent": "And then you may go to polar coordinates and then you get different answers depending you know how you do the coordinates and that is totally absurd.",
                    "label": 0
                },
                {
                    "sent": "That's some paradox by BI think.",
                    "label": 0
                },
                {
                    "sent": "Yeah, and that's the problem.",
                    "label": 0
                },
                {
                    "sent": "If you take a ring off.",
                    "label": 0
                },
                {
                    "sent": "Equal with here, yeah, then it's uniform, but if you take it with polar coordinates then this ring is narrower here than here.",
                    "label": 1
                },
                {
                    "sent": "And this is the solution.",
                    "label": 0
                },
                {
                    "sent": "Yeah, but I mean the limit is a ring.",
                    "label": 0
                },
                {
                    "sent": "So why should I be so careful about, you know?",
                    "label": 0
                },
                {
                    "sent": "How I take it and what does it mean?",
                    "label": 0
                },
                {
                    "sent": "I mean, I asked the question, what is the probability given that the point landed on the ring?",
                    "label": 0
                },
                {
                    "sent": "And why I'm not allowed to take it nonuniform?",
                    "label": 0
                },
                {
                    "sent": "What is the right and what is wrong answer?",
                    "label": 0
                },
                {
                    "sent": "So yes, you can extend it.",
                    "label": 1
                },
                {
                    "sent": "But it's partly arbitrary.",
                    "label": 0
                },
                {
                    "sent": "And for real numbers, the arbitrariness you can.",
                    "label": 0
                },
                {
                    "sent": "Sort of reduce it, but not completely.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "OK, 4 degrees of belief.",
                    "label": 0
                },
                {
                    "sent": "You start with a conditional belief function.",
                    "label": 0
                },
                {
                    "sent": "So what is my belief in a given B?",
                    "label": 1
                },
                {
                    "sent": "So these are the two arguments.",
                    "label": 0
                },
                {
                    "sent": "And you wanted this belief function roughly corresponds to common sense.",
                    "label": 0
                },
                {
                    "sent": "I mean, you believe some things, and if something happens, you change your belief and you have some feeling about it, I will not formalize that here.",
                    "label": 0
                },
                {
                    "sent": "That is what Cox did in 1946.",
                    "label": 0
                },
                {
                    "sent": "He came up with some very reasonable properties for this belief function, which.",
                    "label": 0
                },
                {
                    "sent": "You would probably accept and they are extremely weak, they're just more or less functional dependencies.",
                    "label": 0
                },
                {
                    "sent": "So for instance, if the belief of B.",
                    "label": 0
                },
                {
                    "sent": "Is a function of.",
                    "label": 0
                },
                {
                    "sent": "Given A is a function of DNA, then the belief of not being given a should be enough.",
                    "label": 0
                },
                {
                    "sent": "Now OK, now this is too trivial.",
                    "label": 0
                },
                {
                    "sent": "Then I know it's not trivial then not be given a should be, should have the same functional relationship, not we're not assuming that probabilities sum to one or anything, because I mean there's just believes any real numbers.",
                    "label": 0
                },
                {
                    "sent": "OK, if you start with this week's axioms, you can show that this belief function.",
                    "label": 0
                },
                {
                    "sent": "Is isomorphic to a probability function which satisfies Kolmogorov axioms?",
                    "label": 1
                },
                {
                    "sent": "That means there is a bijection and actually continuously differentiable from belief.",
                    "label": 0
                },
                {
                    "sent": "So this belief values.",
                    "label": 0
                },
                {
                    "sent": "Might be real values, not necessarily in 01, but you can find a function.",
                    "label": 0
                },
                {
                    "sent": "Which is an injection such that.",
                    "label": 0
                },
                {
                    "sent": "This year satisfies, golf axioms, and since these values are.",
                    "label": 0
                },
                {
                    "sent": "I mean, you don't really care about.",
                    "label": 0
                },
                {
                    "sent": "The.",
                    "label": 0
                },
                {
                    "sent": "The particular value you care about the relations and about the order, and in any case I mean if this satisfies, golf.",
                    "label": 0
                },
                {
                    "sent": "Except you can always go back by taking them.",
                    "label": 0
                },
                {
                    "sent": "You know the inverse function of the probability to get your Billy function back.",
                    "label": 0
                },
                {
                    "sent": "Is a bijection, yes?",
                    "label": 0
                },
                {
                    "sent": "Is a bijection between.",
                    "label": 0
                },
                {
                    "sent": "Yeah yeah.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So what he has shown so if you accept this reasonable.",
                    "label": 0
                },
                {
                    "sent": "Assumption about how beliefs should behave.",
                    "label": 0
                },
                {
                    "sent": "Then police.",
                    "label": 0
                },
                {
                    "sent": "Follow the same rules as objective probabilities and then the same as frequentist probabilities and that is very nice because now you can forget about everything I said.",
                    "label": 1
                },
                {
                    "sent": "You just use Kolmogorov axioms of probability and do your computation.",
                    "label": 0
                },
                {
                    "sent": "Yeah, because all these probabilities.",
                    "label": 0
                },
                {
                    "sent": "Follow the same rules.",
                    "label": 0
                },
                {
                    "sent": "There are subtleties.",
                    "label": 0
                },
                {
                    "sent": "I mean, you start with some.",
                    "label": 0
                },
                {
                    "sent": "Plausable axioms, but maybe they're not as possible as you know.",
                    "label": 0
                },
                {
                    "sent": "They first look at and you can try to modify and remove them and their communities who are not satisfied with that.",
                    "label": 0
                },
                {
                    "sent": "And you know, invent different kinds of probabilities are probabilities, lower probabilities.",
                    "label": 0
                },
                {
                    "sent": "OK function at all kinds of things, yeah, but to 1st order approximation you can always use standard probabilities.",
                    "label": 0
                },
                {
                    "sent": "OK, now we come to.",
                    "label": 0
                },
                {
                    "sent": "Space famous rule.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Let D be some possible.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Later.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "The probability is not zero.",
                    "label": 0
                },
                {
                    "sent": "So it might happen and you have a countable class of hypothesis which are mutually exclusive.",
                    "label": 1
                },
                {
                    "sent": "That means that one of them is true and not more than one of them.",
                    "label": 0
                },
                {
                    "sent": "You have some a priore belief.",
                    "label": 0
                },
                {
                    "sent": "Over the hypothesis, these are now.",
                    "label": 0
                },
                {
                    "sent": "Subjective probabilities so apriori I believe.",
                    "label": 0
                },
                {
                    "sent": "General relativity is crap, and Newton is right because you know, it's much simpler, but then I have some observations and so on.",
                    "label": 0
                },
                {
                    "sent": "OK so my upper or belief.",
                    "label": 0
                },
                {
                    "sent": "Then I have my likelihood function.",
                    "label": 0
                },
                {
                    "sent": "This is more or less defining, but the hypothesis means.",
                    "label": 0
                },
                {
                    "sent": "I mean, these are just symbols, Ch.",
                    "label": 0
                },
                {
                    "sent": "What does it mean?",
                    "label": 0
                },
                {
                    "sent": "Hypothesis it means sampling model normally and the likelihood specifies the sampling model OK. And.",
                    "label": 0
                },
                {
                    "sent": "What you want is after you've seen the data you want to update, you believe.",
                    "label": 0
                },
                {
                    "sent": "Or should you believe afterwards.",
                    "label": 0
                },
                {
                    "sent": "And Bayes rule tells you how to do that and.",
                    "label": 0
                },
                {
                    "sent": "I just presume that everybody has seen that before.",
                    "label": 0
                },
                {
                    "sent": "And this follows easily for Commodore.",
                    "label": 0
                },
                {
                    "sent": "From kolmogorov's axioms.",
                    "label": 0
                },
                {
                    "sent": "The interesting thing is, I mean it's an exercise worth to do once you take the axioms.",
                    "label": 0
                },
                {
                    "sent": "And you try to derive that, but really only using the axioms are not something intuitively, you know, and what you will see is that these actions are really sufficient.",
                    "label": 0
                },
                {
                    "sent": "You don't need more, and you need all of them.",
                    "label": 0
                },
                {
                    "sent": "Is that a question?",
                    "label": 0
                },
                {
                    "sent": "End.",
                    "label": 0
                },
                {
                    "sent": "If I'm.",
                    "label": 0
                },
                {
                    "sent": "You have an infinite.",
                    "label": 0
                },
                {
                    "sent": "I mean if you have finitely many.",
                    "label": 0
                },
                {
                    "sent": "Classes you don't need the countable additivity, and if you have a countable class then you need this last action.",
                    "label": 0
                },
                {
                    "sent": "The countable additivity, in order to derive this rule.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "This is your prior app, yeah?",
                    "label": 0
                },
                {
                    "sent": "This is the denominator here.",
                    "label": 0
                },
                {
                    "sent": "It's called the evidence.",
                    "label": 0
                },
                {
                    "sent": "It's.",
                    "label": 0
                },
                {
                    "sent": "Quite tricky to impossible to interpret that it's a very important object.",
                    "label": 0
                },
                {
                    "sent": "So formally, you have.",
                    "label": 0
                },
                {
                    "sent": "The probability of a you can ride as the probability of a given B * P or B.",
                    "label": 0
                },
                {
                    "sent": "Lose the probability of a given, not B.",
                    "label": 0
                },
                {
                    "sent": "Times period not be easily follows from their actions.",
                    "label": 0
                },
                {
                    "sent": "Set up.",
                    "label": 0
                },
                {
                    "sent": "Sorry again.",
                    "label": 0
                },
                {
                    "sent": "So OK, POV would only be 0 if we were impossible.",
                    "label": 0
                },
                {
                    "sent": "Under all possible hypothesis.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "It's cool my brain.",
                    "label": 0
                },
                {
                    "sent": "Are you a boy?",
                    "label": 0
                },
                {
                    "sent": "Yes, I mean if you have that you're talking about now, real numbers and probabilities would be 0.",
                    "label": 0
                },
                {
                    "sent": "Then you have to replace everything by probability densities.",
                    "label": 0
                },
                {
                    "sent": "Just before.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Yeah, then.",
                    "label": 0
                },
                {
                    "sent": "Yes, then this is a density.",
                    "label": 0
                },
                {
                    "sent": "Yeah, then it's the case, yeah, you mean.",
                    "label": 0
                },
                {
                    "sent": "I'm a little bit.",
                    "label": 0
                },
                {
                    "sent": "Sort of sloppy.",
                    "label": 0
                },
                {
                    "sent": "I always only.",
                    "label": 0
                },
                {
                    "sent": "Or nearly always only considered discreet.",
                    "label": 0
                },
                {
                    "sent": "Space is countable, space is finite spaces.",
                    "label": 0
                },
                {
                    "sent": "To make life simpler.",
                    "label": 0
                },
                {
                    "sent": "Because in the continuous case I mean, this is one of the problems you have in the continuous case.",
                    "label": 0
                },
                {
                    "sent": "I mean, we discussed the density case.",
                    "label": 0
                },
                {
                    "sent": "That's one way.",
                    "label": 0
                },
                {
                    "sent": "And but you have to be careful.",
                    "label": 0
                },
                {
                    "sent": "And but you know, maybe there's something I don't know.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Can you show me the pages in the book?",
                    "label": 0
                },
                {
                    "sent": "Think about every space is discrete and finite.",
                    "label": 0
                },
                {
                    "sent": "And then you don't have the problem.",
                    "label": 0
                },
                {
                    "sent": "For instance, the two books by fellow this old statistics book.",
                    "label": 0
                },
                {
                    "sent": "I mean he strictly separates the discrete finite case and then you can derive all everything which is of principle interest in the continuous case is then just a lot of technical difficulties.",
                    "label": 0
                },
                {
                    "sent": "And it's nice to separate them.",
                    "label": 0
                },
                {
                    "sent": "And I do that here.",
                    "label": 0
                },
                {
                    "sent": "I will not talk about continuous stuff.",
                    "label": 0
                },
                {
                    "sent": "I mean, for instance I discretize time.",
                    "label": 0
                },
                {
                    "sent": "I mean, in physics you have continuous time, but that's an enormous complication.",
                    "label": 0
                },
                {
                    "sent": "I mean, sometimes it makes things simpler.",
                    "label": 0
                },
                {
                    "sent": "So it's easier conceptually to stay discrete.",
                    "label": 0
                }
            ]
        }
    }
}