{
    "id": "irqckoa7qoqq4xpvczr3onoinqufgzkj",
    "title": "Empirical Bernstein boosting",
    "info": {
        "author": [
            "Pannaga Shivaswamy, Department of Computer Science, Columbia University"
        ],
        "published": "June 3, 2010",
        "recorded": "May 2010",
        "category": [
            "Top->Computer Science->Machine Learning->Boosting",
            "Top->Computer Science->Machine Learning->Statistical Learning"
        ]
    },
    "url": "http://videolectures.net/aistats2010_shivaswamy_ebb/",
    "segmentation": [
        [
            "So today I'm going to talk about empirical Bernstein boosting.",
            "This is joint work with my advisor, Tony's over at Columbia University."
        ],
        [
            "So in many machine learning algorithms one key thing that we see is to minimize some objective and one very popular objective is empirical risk minimization.",
            "What is empirical risk minimization?",
            "It's just some loss evaluated on the training examples and the mean of the loss on the training examples is minimized, so it's at the core of many machine learning algorithms.",
            "I can give a bunch of example."
        ],
        [
            "For example, our boost minimizes empirical risk with an exponential loss support vector machine with a hinge loss.",
            "There are numerous regression algorithms with which minimize squared loss, absolute loss epsilon, incentive insensitive loss, and so on, so by no means this is a comprehensive list.",
            "There are so many."
        ],
        [
            "Other losses, but the idea in all of this is to minimize the mean loss on the training examples so."
        ],
        [
            "One natural question is how about this second order moment of the loss?",
            "How can we also exploit that in in the objective function so that we get something better?",
            "And how can we do it in a more principled way?",
            "So in particular, I'm going to show how we can derive a nice boosting algorithm that would do this."
        ],
        [
            "So.",
            "Before I get into any of the details.",
            "So in fact there have been some previous work which actually make use of both 1st and 2nd order moments.",
            "For example, classic Fisher linear discriminant.",
            "If you have two classes, all the points are mapped onto a hyperplane such that the two means are far apart and the variance of each class is."
        ],
        [
            "Small and then there was also a second order perceptron which is like the classic perceptron algorithm, but it has an update rule which also includes widening of the data, and in fact it had better mistake bounds comp."
        ],
        [
            "Two classic perceptron algorithm.",
            "Then we also had proposed a notion of relative margin where we don't just measure the margin in an absolute sense but only with respect to the."
        ],
        [
            "Spread of the data.",
            "And recently there has been some work based on PAC Bayes bound minimization, also known as the Gaussian margin machines, where they assume a Gaussian prior on the hyperplanes and they obtain a prior by minimizing the PAC Bayes bound."
        ],
        [
            "And also there is another line of work called confidence weighted learning.",
            "I think they also have a presentation tomorrow on a related paper, so where?",
            "Where they also make Gaussian assumptions and they make use of both 1st and 2nd order moments for learning."
        ],
        [
            "So before getting into any of the details, I'll just give you a quick overview of how empirical risk minimization is motivated.",
            "So many people here might be familiar with this, so just bear with me.",
            "So if we have a fixed distribution and if we have an IID sample drawn from the distribution and the key here is that the random variable should be bounded.",
            "Here I'm assuming that there between zero and one, then with probability at least one minus Delta.",
            "The expected value of the random variable is upper bounded by the empirical mean plus some terms which actually go to 0."
        ],
        [
            "Anne.",
            "And in fact, we can extend that to your bounded loss if we have a fixed function F from some domain X to real values, and if we have X1Y1 pairs, then we can define a loss on ffxi, I and so we can apply the same to Delos so."
        ],
        [
            "So we get this result, and in fact we can go a step further.",
            "And if you have a class of functions here for simplicity, I'm assuming that it's a class with finite number of functions.",
            "We can make the bound hold for all the functions in the function class so that that's a unit."
        ],
        [
            "I'm convergence result, and roughly, that's that's what motivates empirical risk minimization.",
            "That is, to minimize the first term on the right hand side."
        ],
        [
            "So now I have a natural question is how do we include variance information?",
            "So this was the Hoeffding's inequality, exactly what I showed before but not that I'm no longer saying that with probability 1 minus Delta and all that."
        ],
        [
            "So there is another classic inequality, called the Bernstein's inequality, which actually makes use of variance information.",
            "So as you can see the second term there contains the variance, but it's the true variance and the good thing about this bound is that it is much tighter.",
            "It can be much tighter compared to of links inequality to see that.",
            "In an extreme case, consider a case where the variance is 0, then empirical mean converges to true mean at a rate of 1 / N versus orfano rootin for offerings inequality.",
            "But this is a severe limitation, that is that the variances.",
            "Covariance and why is this a limitation in machine learning problems?",
            "Often we neither know the distribution or the variance, so we don't have an idea of how to get the variance."
        ],
        [
            "So this is exactly what I showed you on the previous slide.",
            "Luckily we have some recent results."
        ],
        [
            "Rich which is which appeared in last court.",
            "So in this inequality, instead of the true variance, we have the empirical variance and this no longer has that caveat that we require the.",
            "True variance, because it's it's all defined using the data, and in fact we can just apply this."
        ],
        [
            "For any bounded loss function and.",
            "That there and we can also have a uniform convergence version of this bound, and that suggests sample variance penalization, which is to not just minimize the empirical risk, but also include this term in the optimization.",
            "Not that there isn't natural tradeoff.",
            "Between between these two quantities.",
            "And that's given by Lambda and.",
            "But in fact it turns out that it's hard to estimate that Lambda up theory, because if you see that bound that we of Z has some factors multiplying it, which would include log of two over Delta.",
            "And Moreover, if you write a uniform convergence of version of the bound, it would also include some complexity terms, so it's we don't know a priori how to fix that.",
            "Lambda."
        ],
        [
            "So now what I'll show is.",
            "So first we have the idea of sample variance penalization.",
            "One natural question is is it?",
            "Is it any different on losses that are of interest to us.",
            "So the first obvious loss is the 01 loss, which is 1.",
            "If you make an error zero if you don't make an error so.",
            "If a behavior is defined to be this sum of 0 and losses average of 0 and losses, then it's easy to show that the empirical variance is just that, an."
        ],
        [
            "And that that means empirical risk minimization is to just minimize P hat whereas."
        ],
        [
            "Sample variance penalization is to minimize P hat plus Lambda Times Square root of P hat times 1 -- P."
        ],
        [
            "And it turns out that sample variance penalization is.",
            "The term there.",
            "Heart rate OK so.",
            "This is monotonic in the hat.",
            "So minimizing this.",
            "OK. OK. Yeah, so since the expression that we got for sample variance penalization is monotonic in P hat minimizing that is equivalent to empirical risk minimization in the reserve of interest, which is P had between 0."
        ],
        [
            ".5.",
            "So it turns out that sample variance penalization on zero and Loss view spec, empirical risk minimization for any Lambda, not that in the.",
            "For a particular loss in general for Lambda equal to 0 anyway, sweeping gives back here."
        ],
        [
            "So next, can we apply and typically?",
            "People don't minimize 01 loss because it's a hard problem and what we do in machine learning is to minimize typically act convex, upper bound and loss functions on such loss function is the exponential loss.",
            "We'll see how we can minimize the bound with an exponential loss.",
            "Now I am assuming that the labels are plus or minus one and we want to.",
            "Minimize the expression that I have shown there where which includes the risk term plus the empirical variance term."
        ],
        [
            "Traded off by some parameter.",
            "And so part of the reason why boost Adaboost is particularly successful is because of the simplicity of the update rule, and so we want to derive a clean boosting algorithm to do this minimization.",
            "So we have to do some manipulation here.",
            "So we start with the expression given there instead of doing that, I pose it as an optimization problem where.",
            "I minimize the empirical risk subject to a constraint on the variance."
        ],
        [
            "Equivalently, I can just do this where I just squared both the objective and the."
        ],
        [
            "Constraint and instead I write it as a Lagrangian optimization problem, but I'm not going to derive the dual of this problem or anything like that, since B is."
        ],
        [
            "Typically a fixed constant.",
            "I'm just going to minimize this, and it turns out that we can derive a nice boost boosting type algorithm to minimize this loss."
        ],
        [
            "And to do this we just start with the equations that I showed."
        ],
        [
            "On the last slide.",
            "And like in Adaboost, we fixed the family of functions to be the sum of the OR the.",
            "Combinations of the weak learners."
        ],
        [
            "And we iteratively minimize the objective so the details of deriving the rule can be seen in the paper so."
        ],
        [
            "I'll show how the update rule differs, so first I'll."
        ],
        [
            "Show Adaboost it basically gradually minimizes the function shown there, but in an iterative fashion.",
            "Weights are initialized uniformly across all the examples in each step of the algorithm, we obtain a weak learner and the weight of the weak learner is said to be what I've shown.",
            "It just contains some of the weights of the correctly classified and misclassified examples.",
            "And if an example is correctly classified, its weight is reduced.",
            "If it's misclassified its race, its weight is increased both exponentially.",
            "And finally the."
        ],
        [
            "Weights are normalized.",
            "So today."
        ],
        [
            "So sample variance penalization instead we minimize.",
            "From the quantity that."
        ],
        [
            "Shown there and what we have shown is that just with this update rule, which also just includes some of the weights and some of the squares of the.",
            "Wait, we get an update rule and as you can see if we put Lambda equal to 0, this gives back the same choice of Alpha Acerra boost."
        ],
        [
            "So.",
            "But now that we have a different algorithm, how does it compare with some known algorithms?",
            "So we evaluated it on several benchmark datasets.",
            "We just used decision stump as the weak learner.",
            "And all of the parameters such as Lambda and and.",
            "Also there were some parameters for some other methods.",
            "It turned them using a validation set and we did boosting until there was no drop in validation error in 50 iterations and the method with which we compared with the first one is Sarah Boost.",
            "That's a natural choice because we are comparing empirical risk minimization versus sample variance penalization.",
            "Then we also had two versions of boosting called the RLP Boost and our QP Boost which are just regularised LP boost and regularised.",
            "QP boost, they just take the.",
            "Outputs obtained from Adaboost and just optimize the weights with some regularization and also with soft margin boosting, which is boosting, which allows some of the examples to be misclassified."
        ],
        [
            "Sofa station show the results.",
            "Adaboost versus empirical Bernstein boosting.",
            "So I have 17 different datasets and two methods.",
            "What I've shown is the mean error and the standard deviation of the error.",
            "As you can see on all the datasets eboost obtains.",
            "Much smaller error compared to Adaboost."
        ],
        [
            "And then.",
            "When I include all the methods, eBay was still as well, but it seems so ABR is named the author scale for the soft margin boosting, so I will return it as ABR.",
            "So it seems that IBO stand ABR sort of tide.",
            "So one natural question is.",
            "Is there a qualitative difference between the two solutions, or why is it that those two results are tide?"
        ],
        [
            "So to see that we looked at the margin distribution of the.",
            "Margin distribution obtained by the algorithms on datasets.",
            "I'm just showing to cases which are typical.",
            "And what this show is?",
            "So this is on the X axis, it's the margin which is just via times F of XI, but normalized with the weights.",
            "And so if you take a particular point on on any of these curves, that would say how many of the examples had margin less than or equal to.",
            "That particular margin.",
            "So what we can see is that with soft margin boosting, that is a long tail here, which indicates that.",
            "Many of the examples are allowed to be misclassified.",
            "And the red curve is even given by their boost and the boost margin distribution shows that it has a much smaller variance.",
            "So the key point here is that.",
            "Download these two methods obtained, sort of similar results.",
            "There is a fundamental difference in the quality of the solutions that they obtain, and Moreover note that we can also have a soft margin boosting which would which could minimize sample variance penalization."
        ],
        [
            "And finally, just out of curiosity, I just obtained the.",
            "Mean margin and the standard deviation of the margin for all the methods on all the problems.",
            "What what we what we can see is that this ABR or the soft margin boosting typically obtains much larger margin but also accompanied with much large variance, whereas E Boost typically obtains somewhat smaller margin compared to Adaboost.",
            "But also with much smaller variance.",
            "So yeah, and in terms of generalization error boost, although it has a smaller absolute margin, does better than Adaboost."
        ],
        [
            "So in conclusion, we proposed novel boosting algorithm which has been well motivated and it's very easy to implement the stats, easiest Adaboost and it showed superior perfor."
        ],
        [
            "Once compared to Adaboost.",
            "So what this paper shows is that sample variance penalization is viable."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So today I'm going to talk about empirical Bernstein boosting.",
                    "label": 0
                },
                {
                    "sent": "This is joint work with my advisor, Tony's over at Columbia University.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So in many machine learning algorithms one key thing that we see is to minimize some objective and one very popular objective is empirical risk minimization.",
                    "label": 0
                },
                {
                    "sent": "What is empirical risk minimization?",
                    "label": 1
                },
                {
                    "sent": "It's just some loss evaluated on the training examples and the mean of the loss on the training examples is minimized, so it's at the core of many machine learning algorithms.",
                    "label": 0
                },
                {
                    "sent": "I can give a bunch of example.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "For example, our boost minimizes empirical risk with an exponential loss support vector machine with a hinge loss.",
                    "label": 1
                },
                {
                    "sent": "There are numerous regression algorithms with which minimize squared loss, absolute loss epsilon, incentive insensitive loss, and so on, so by no means this is a comprehensive list.",
                    "label": 0
                },
                {
                    "sent": "There are so many.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Other losses, but the idea in all of this is to minimize the mean loss on the training examples so.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "One natural question is how about this second order moment of the loss?",
                    "label": 1
                },
                {
                    "sent": "How can we also exploit that in in the objective function so that we get something better?",
                    "label": 0
                },
                {
                    "sent": "And how can we do it in a more principled way?",
                    "label": 0
                },
                {
                    "sent": "So in particular, I'm going to show how we can derive a nice boosting algorithm that would do this.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Before I get into any of the details.",
                    "label": 0
                },
                {
                    "sent": "So in fact there have been some previous work which actually make use of both 1st and 2nd order moments.",
                    "label": 0
                },
                {
                    "sent": "For example, classic Fisher linear discriminant.",
                    "label": 1
                },
                {
                    "sent": "If you have two classes, all the points are mapped onto a hyperplane such that the two means are far apart and the variance of each class is.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Small and then there was also a second order perceptron which is like the classic perceptron algorithm, but it has an update rule which also includes widening of the data, and in fact it had better mistake bounds comp.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Two classic perceptron algorithm.",
                    "label": 0
                },
                {
                    "sent": "Then we also had proposed a notion of relative margin where we don't just measure the margin in an absolute sense but only with respect to the.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Spread of the data.",
                    "label": 0
                },
                {
                    "sent": "And recently there has been some work based on PAC Bayes bound minimization, also known as the Gaussian margin machines, where they assume a Gaussian prior on the hyperplanes and they obtain a prior by minimizing the PAC Bayes bound.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And also there is another line of work called confidence weighted learning.",
                    "label": 1
                },
                {
                    "sent": "I think they also have a presentation tomorrow on a related paper, so where?",
                    "label": 0
                },
                {
                    "sent": "Where they also make Gaussian assumptions and they make use of both 1st and 2nd order moments for learning.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So before getting into any of the details, I'll just give you a quick overview of how empirical risk minimization is motivated.",
                    "label": 0
                },
                {
                    "sent": "So many people here might be familiar with this, so just bear with me.",
                    "label": 0
                },
                {
                    "sent": "So if we have a fixed distribution and if we have an IID sample drawn from the distribution and the key here is that the random variable should be bounded.",
                    "label": 0
                },
                {
                    "sent": "Here I'm assuming that there between zero and one, then with probability at least one minus Delta.",
                    "label": 1
                },
                {
                    "sent": "The expected value of the random variable is upper bounded by the empirical mean plus some terms which actually go to 0.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "And in fact, we can extend that to your bounded loss if we have a fixed function F from some domain X to real values, and if we have X1Y1 pairs, then we can define a loss on ffxi, I and so we can apply the same to Delos so.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we get this result, and in fact we can go a step further.",
                    "label": 0
                },
                {
                    "sent": "And if you have a class of functions here for simplicity, I'm assuming that it's a class with finite number of functions.",
                    "label": 0
                },
                {
                    "sent": "We can make the bound hold for all the functions in the function class so that that's a unit.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I'm convergence result, and roughly, that's that's what motivates empirical risk minimization.",
                    "label": 0
                },
                {
                    "sent": "That is, to minimize the first term on the right hand side.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So now I have a natural question is how do we include variance information?",
                    "label": 0
                },
                {
                    "sent": "So this was the Hoeffding's inequality, exactly what I showed before but not that I'm no longer saying that with probability 1 minus Delta and all that.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So there is another classic inequality, called the Bernstein's inequality, which actually makes use of variance information.",
                    "label": 0
                },
                {
                    "sent": "So as you can see the second term there contains the variance, but it's the true variance and the good thing about this bound is that it is much tighter.",
                    "label": 0
                },
                {
                    "sent": "It can be much tighter compared to of links inequality to see that.",
                    "label": 1
                },
                {
                    "sent": "In an extreme case, consider a case where the variance is 0, then empirical mean converges to true mean at a rate of 1 / N versus orfano rootin for offerings inequality.",
                    "label": 0
                },
                {
                    "sent": "But this is a severe limitation, that is that the variances.",
                    "label": 0
                },
                {
                    "sent": "Covariance and why is this a limitation in machine learning problems?",
                    "label": 0
                },
                {
                    "sent": "Often we neither know the distribution or the variance, so we don't have an idea of how to get the variance.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is exactly what I showed you on the previous slide.",
                    "label": 0
                },
                {
                    "sent": "Luckily we have some recent results.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Rich which is which appeared in last court.",
                    "label": 0
                },
                {
                    "sent": "So in this inequality, instead of the true variance, we have the empirical variance and this no longer has that caveat that we require the.",
                    "label": 0
                },
                {
                    "sent": "True variance, because it's it's all defined using the data, and in fact we can just apply this.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "For any bounded loss function and.",
                    "label": 0
                },
                {
                    "sent": "That there and we can also have a uniform convergence version of this bound, and that suggests sample variance penalization, which is to not just minimize the empirical risk, but also include this term in the optimization.",
                    "label": 1
                },
                {
                    "sent": "Not that there isn't natural tradeoff.",
                    "label": 0
                },
                {
                    "sent": "Between between these two quantities.",
                    "label": 0
                },
                {
                    "sent": "And that's given by Lambda and.",
                    "label": 0
                },
                {
                    "sent": "But in fact it turns out that it's hard to estimate that Lambda up theory, because if you see that bound that we of Z has some factors multiplying it, which would include log of two over Delta.",
                    "label": 0
                },
                {
                    "sent": "And Moreover, if you write a uniform convergence of version of the bound, it would also include some complexity terms, so it's we don't know a priori how to fix that.",
                    "label": 0
                },
                {
                    "sent": "Lambda.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So now what I'll show is.",
                    "label": 0
                },
                {
                    "sent": "So first we have the idea of sample variance penalization.",
                    "label": 0
                },
                {
                    "sent": "One natural question is is it?",
                    "label": 0
                },
                {
                    "sent": "Is it any different on losses that are of interest to us.",
                    "label": 0
                },
                {
                    "sent": "So the first obvious loss is the 01 loss, which is 1.",
                    "label": 1
                },
                {
                    "sent": "If you make an error zero if you don't make an error so.",
                    "label": 0
                },
                {
                    "sent": "If a behavior is defined to be this sum of 0 and losses average of 0 and losses, then it's easy to show that the empirical variance is just that, an.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And that that means empirical risk minimization is to just minimize P hat whereas.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Sample variance penalization is to minimize P hat plus Lambda Times Square root of P hat times 1 -- P.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And it turns out that sample variance penalization is.",
                    "label": 0
                },
                {
                    "sent": "The term there.",
                    "label": 0
                },
                {
                    "sent": "Heart rate OK so.",
                    "label": 0
                },
                {
                    "sent": "This is monotonic in the hat.",
                    "label": 0
                },
                {
                    "sent": "So minimizing this.",
                    "label": 0
                },
                {
                    "sent": "OK. OK. Yeah, so since the expression that we got for sample variance penalization is monotonic in P hat minimizing that is equivalent to empirical risk minimization in the reserve of interest, which is P had between 0.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": ".5.",
                    "label": 0
                },
                {
                    "sent": "So it turns out that sample variance penalization on zero and Loss view spec, empirical risk minimization for any Lambda, not that in the.",
                    "label": 0
                },
                {
                    "sent": "For a particular loss in general for Lambda equal to 0 anyway, sweeping gives back here.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So next, can we apply and typically?",
                    "label": 0
                },
                {
                    "sent": "People don't minimize 01 loss because it's a hard problem and what we do in machine learning is to minimize typically act convex, upper bound and loss functions on such loss function is the exponential loss.",
                    "label": 0
                },
                {
                    "sent": "We'll see how we can minimize the bound with an exponential loss.",
                    "label": 1
                },
                {
                    "sent": "Now I am assuming that the labels are plus or minus one and we want to.",
                    "label": 1
                },
                {
                    "sent": "Minimize the expression that I have shown there where which includes the risk term plus the empirical variance term.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Traded off by some parameter.",
                    "label": 0
                },
                {
                    "sent": "And so part of the reason why boost Adaboost is particularly successful is because of the simplicity of the update rule, and so we want to derive a clean boosting algorithm to do this minimization.",
                    "label": 0
                },
                {
                    "sent": "So we have to do some manipulation here.",
                    "label": 0
                },
                {
                    "sent": "So we start with the expression given there instead of doing that, I pose it as an optimization problem where.",
                    "label": 0
                },
                {
                    "sent": "I minimize the empirical risk subject to a constraint on the variance.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Equivalently, I can just do this where I just squared both the objective and the.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Constraint and instead I write it as a Lagrangian optimization problem, but I'm not going to derive the dual of this problem or anything like that, since B is.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Typically a fixed constant.",
                    "label": 0
                },
                {
                    "sent": "I'm just going to minimize this, and it turns out that we can derive a nice boost boosting type algorithm to minimize this loss.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And to do this we just start with the equations that I showed.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "On the last slide.",
                    "label": 0
                },
                {
                    "sent": "And like in Adaboost, we fixed the family of functions to be the sum of the OR the.",
                    "label": 0
                },
                {
                    "sent": "Combinations of the weak learners.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we iteratively minimize the objective so the details of deriving the rule can be seen in the paper so.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I'll show how the update rule differs, so first I'll.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Show Adaboost it basically gradually minimizes the function shown there, but in an iterative fashion.",
                    "label": 0
                },
                {
                    "sent": "Weights are initialized uniformly across all the examples in each step of the algorithm, we obtain a weak learner and the weight of the weak learner is said to be what I've shown.",
                    "label": 1
                },
                {
                    "sent": "It just contains some of the weights of the correctly classified and misclassified examples.",
                    "label": 0
                },
                {
                    "sent": "And if an example is correctly classified, its weight is reduced.",
                    "label": 0
                },
                {
                    "sent": "If it's misclassified its race, its weight is increased both exponentially.",
                    "label": 0
                },
                {
                    "sent": "And finally the.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Weights are normalized.",
                    "label": 0
                },
                {
                    "sent": "So today.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So sample variance penalization instead we minimize.",
                    "label": 0
                },
                {
                    "sent": "From the quantity that.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Shown there and what we have shown is that just with this update rule, which also just includes some of the weights and some of the squares of the.",
                    "label": 0
                },
                {
                    "sent": "Wait, we get an update rule and as you can see if we put Lambda equal to 0, this gives back the same choice of Alpha Acerra boost.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "But now that we have a different algorithm, how does it compare with some known algorithms?",
                    "label": 0
                },
                {
                    "sent": "So we evaluated it on several benchmark datasets.",
                    "label": 1
                },
                {
                    "sent": "We just used decision stump as the weak learner.",
                    "label": 0
                },
                {
                    "sent": "And all of the parameters such as Lambda and and.",
                    "label": 0
                },
                {
                    "sent": "Also there were some parameters for some other methods.",
                    "label": 0
                },
                {
                    "sent": "It turned them using a validation set and we did boosting until there was no drop in validation error in 50 iterations and the method with which we compared with the first one is Sarah Boost.",
                    "label": 1
                },
                {
                    "sent": "That's a natural choice because we are comparing empirical risk minimization versus sample variance penalization.",
                    "label": 0
                },
                {
                    "sent": "Then we also had two versions of boosting called the RLP Boost and our QP Boost which are just regularised LP boost and regularised.",
                    "label": 0
                },
                {
                    "sent": "QP boost, they just take the.",
                    "label": 0
                },
                {
                    "sent": "Outputs obtained from Adaboost and just optimize the weights with some regularization and also with soft margin boosting, which is boosting, which allows some of the examples to be misclassified.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Sofa station show the results.",
                    "label": 0
                },
                {
                    "sent": "Adaboost versus empirical Bernstein boosting.",
                    "label": 0
                },
                {
                    "sent": "So I have 17 different datasets and two methods.",
                    "label": 0
                },
                {
                    "sent": "What I've shown is the mean error and the standard deviation of the error.",
                    "label": 0
                },
                {
                    "sent": "As you can see on all the datasets eboost obtains.",
                    "label": 0
                },
                {
                    "sent": "Much smaller error compared to Adaboost.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then.",
                    "label": 0
                },
                {
                    "sent": "When I include all the methods, eBay was still as well, but it seems so ABR is named the author scale for the soft margin boosting, so I will return it as ABR.",
                    "label": 0
                },
                {
                    "sent": "So it seems that IBO stand ABR sort of tide.",
                    "label": 0
                },
                {
                    "sent": "So one natural question is.",
                    "label": 0
                },
                {
                    "sent": "Is there a qualitative difference between the two solutions, or why is it that those two results are tide?",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So to see that we looked at the margin distribution of the.",
                    "label": 0
                },
                {
                    "sent": "Margin distribution obtained by the algorithms on datasets.",
                    "label": 0
                },
                {
                    "sent": "I'm just showing to cases which are typical.",
                    "label": 0
                },
                {
                    "sent": "And what this show is?",
                    "label": 0
                },
                {
                    "sent": "So this is on the X axis, it's the margin which is just via times F of XI, but normalized with the weights.",
                    "label": 0
                },
                {
                    "sent": "And so if you take a particular point on on any of these curves, that would say how many of the examples had margin less than or equal to.",
                    "label": 0
                },
                {
                    "sent": "That particular margin.",
                    "label": 0
                },
                {
                    "sent": "So what we can see is that with soft margin boosting, that is a long tail here, which indicates that.",
                    "label": 0
                },
                {
                    "sent": "Many of the examples are allowed to be misclassified.",
                    "label": 0
                },
                {
                    "sent": "And the red curve is even given by their boost and the boost margin distribution shows that it has a much smaller variance.",
                    "label": 0
                },
                {
                    "sent": "So the key point here is that.",
                    "label": 0
                },
                {
                    "sent": "Download these two methods obtained, sort of similar results.",
                    "label": 0
                },
                {
                    "sent": "There is a fundamental difference in the quality of the solutions that they obtain, and Moreover note that we can also have a soft margin boosting which would which could minimize sample variance penalization.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And finally, just out of curiosity, I just obtained the.",
                    "label": 0
                },
                {
                    "sent": "Mean margin and the standard deviation of the margin for all the methods on all the problems.",
                    "label": 0
                },
                {
                    "sent": "What what we what we can see is that this ABR or the soft margin boosting typically obtains much larger margin but also accompanied with much large variance, whereas E Boost typically obtains somewhat smaller margin compared to Adaboost.",
                    "label": 0
                },
                {
                    "sent": "But also with much smaller variance.",
                    "label": 0
                },
                {
                    "sent": "So yeah, and in terms of generalization error boost, although it has a smaller absolute margin, does better than Adaboost.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So in conclusion, we proposed novel boosting algorithm which has been well motivated and it's very easy to implement the stats, easiest Adaboost and it showed superior perfor.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Once compared to Adaboost.",
                    "label": 0
                },
                {
                    "sent": "So what this paper shows is that sample variance penalization is viable.",
                    "label": 0
                }
            ]
        }
    }
}