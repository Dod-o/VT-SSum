{
    "id": "ftgt6z44pm6656sduuvg2qx3onx2snr4",
    "title": "Game Theory for Security: Lessons learned from deployed applications",
    "info": {
        "author": [
            "Milind Tambe, Computer Science Department, University of Southern California",
            "Christopher Kiekintveld, Department of Computer Science, University of Texas at El Paso"
        ],
        "published": "Sept. 23, 2011",
        "recorded": "July 2011",
        "category": [
            "Top->Mathematics->Game Theory"
        ]
    },
    "url": "http://videolectures.net/uai2011_tambe_kiekintveld_game/",
    "segmentation": [
        [
            "Alright, so.",
            "Plan for this.",
            "Victor."
        ],
        [
            "Bill will be something like this.",
            "So first of all, let me just say a couple of words about ourselves.",
            "I'm at the University of Southern California professor of Computer Science and Chris is at the University of Texas at El Paso.",
            "Is been there a year as an assistant professor?",
            "And the outline and plan for the presentation here is that all begin talking about real world applications that we've developed.",
            "This will be followed by Chris giving you background and basics of security games and the scaling up to complex actions and Bayesian security games and so forth.",
            "I'll come back towards the end.",
            "With.",
            "Addressing human behavior.",
            "And the fact that there's observationally uncertainty in these domains, and some of these things, we will explain as we go forward.",
            "I'll talk also about evaluation, and then we'll get into a discussion.",
            "Roughly speaking, you're saying about 5 minutes introduction, so that's this portion.",
            "15 minutes of discussion towards the end and that leaves us about 100 minutes, and so it'll be 50 minutes for me and 50 for Chris.",
            "And that's the way we planned this out.",
            "But we welcome your questions, of course, and we can dynamically change the plan as needed.",
            "By the way, can everybody hear me OK at the end, yeah."
        ],
        [
            "Alright, so we'll start with this motivating real world."
        ],
        [
            "Allegations.",
            "So we have to.",
            "The motivation here is infrastructure security.",
            "We have to protect our ports or airports or critical national infrastructure.",
            "And yet we have a limited security resources.",
            "Which means that we may have to do selective checking.",
            "But our adversary can monitor our defenses and exploit any patterns.",
            "For example, this is the Los Angeles International Airport.",
            "If we patrol this airport 9:00 AM, we are always a terminal.",
            "1:10 AM always a terminal.",
            "2:11 AM at Terminal 3 and so on.",
            "An adversary will observe that an exploit that pattern.",
            "In fact, over the history of my legs, they've been six separate attacks or plans of attack.",
            "Some Fortunately, have been thwarted.",
            "These are with guns and bombs, and so forth, and all the attackers have lived within 50 miles of the airport, giving them an ample opportunity to conduct surveillance.",
            "So this leads to a very important challenge, which is how do we protect our infrastructure given that different targets of different weights, we don't have enough resources to protect everything 24 hours a day.",
            "And yet, our adversary can monitor our defenses and respond to whatever it is that we do.",
            "So game theory can."
        ],
        [
            "Help us here, and in particular what we face is this challenge of many targets.",
            "Fuel."
        ],
        [
            "Resources and we will be looking to.",
            "Bayesian Stackelberg games.",
            "In order to assign our limited resources to these targets.",
            "And I'll explain this notion of Bayesian Stackelberg games, sure."
        ],
        [
            "So I'll start here by giving an intuitive description, and then Chris will come in and get more into details of this.",
            "So just as an example, consider this simple airport with two terminals, terminal one and two.",
            "Terminal 1 happens to be more important than Terminal 2, so there's targets with different weights.",
            "Now, supposing there's one police units and not enough resources to be at both terminals.",
            "So the police always knowing terminal one is more important.",
            "Try to protect Terminal 1 everyday.",
            "Well the adversary will observe that an attack Terminal 2.",
            "So the adversary here gets a positive reward.",
            "The second number is always for the adversary, the first for the police and the police get a negative reward because the police are at Terminal one and the adversary is Attack Terminal 2.",
            "If now the police switch tactics and they're always at Terminal 2.",
            "The adversary will now obviously Attack Terminal 1's adversary.",
            "Again gets a positive reward.",
            "The police get a negative reward.",
            "So any deterministic strategy?",
            "An adversary can defeat.",
            "If the police were to use a mixed strategy randomized strategy, so that's a 60% of the time there at Terminal one and 40% of the time, there are Terminal 2.",
            "An adversary conducting surveillance will know yes 60% of the time.",
            "They're here, and 40% of the time they're there.",
            "But what they'll do tomorrow remains unpredictable.",
            "And this increases.",
            "Adversary uncertainty and costs and improves police expected reward.",
            "These kinds of games are called Stackelberg Games because the security forces commit first.",
            "And the adversary responds.",
            "We will also refer to Bayesian Stackelberg Games, which I'll not talk about here and Chris will expand on that a little bit later because there is uncertainty over adversary types.",
            "What we're interested in is optimal allocation of our limited security resources.",
            "I said 60% of the time at Terminal One and 40% at Terminal 2, but 6040 may not be the right mix.",
            "It could be 7030 or it could be 5050.",
            "Figuring out the right allocation of security resources.",
            "The large number of targets is a difficult challenge.",
            "Now for a two by two game we can solve this by hand.",
            "But when it comes to hundreds of targets and 10s of police units, the problem already becomes very, very difficult.",
            "In fact, what we are interested in is called a strong Stackelberg equilibrium.",
            "Of these Bayesian Stackelberg games, the problem is known to be NP hard.",
            "Our contributions have been more in terms of coming up with fast algorithms to solve these problems and we will explain how they work.",
            "At the moment though, let me step back and talk to you a little bit about the applications that have been developed using this as the underlying mechanism.",
            "And as I said, this is just at this point.",
            "Just to give you an intuitive description of what's going on and then we will get into more detail in the second, when Chris in the second half when Chris takes off."
        ],
        [
            "So I'll begin here with the first application that we diploid, and this is at the Los Angeles International Airport.",
            "So armor stands for Assistant for randomized monitoring over roots and the word assistant happens to be very important in getting it deployed.",
            "So the problem that the alleged police came to us with was OK, we have large numbers of inbound or six inbound roads into LX.",
            "But there aren't enough police officers to man checkpoints on all of the roads at all times of the day.",
            "So the question then becomes where and when would you set up these checkpoints?",
            "Similarly, there is 8 terminals at LX.",
            "But there's only maybe three or four dogs dog teams that are available at any one point, and so the question is, where and when would you send these dock teams for patrolling?",
            "Knowing that adversaries may be interested in exploring a big truck bomb, and that there's different numbers of people at the airport at different times, and they shift over the duration of the day.",
            "So both these problems can be cast in terms of the Stackelberg Games framework that I mentioned earlier.",
            "Anne solved in order to generate a schedule for the police.",
            "So in the case of checkpoints that tells them where and when to set up these checkpoints for the dog teams, it tells them OK in the morning.",
            "At this time send Team 1, three and seven to Terminals 2, four and six.",
            "Then after sometime switch the dog teams the move to some other terminals, and so on and so on, so they get a printed schedule and they can obey that schedule.",
            "The main point here is that it's a randomized schedule which has taken into account target weights and the fact that there is surveillance that may be going on.",
            "So this system.",
            "They approached us in April of 2007.",
            "By August of 2007, since we already had our algorithms created and so forth, we delivered the software to them, and it's been in use ever since and is considered one of the best practices for security at LAX.",
            "So this was our first diploid."
        ],
        [
            "Application.",
            "And I have now going to show you a small video.",
            "Hopefully it all works.",
            "It's from a.",
            "A new station in LA.",
            "Unfortunately I couldn't get the kind of video that they could get myself, so I'm going to show it to you, but I've really edited it down to the minimum duration possible, so sorry to impose a news clip on you, or hopefully it's OK.",
            "Very sophisticated tools to help keep us safe.",
            "Harbor is one of them, but I cannot steal it.",
            "Not Kevlar.",
            "Silicon Armor is a computer program created by students at USC, will shoot those networks that SharePoint familiar scene, LAN some 50,000 vehicles today streaming in this airport, most encountering officers and their dogs, or just wait group.",
            "Others are stopped.",
            "How you doing?",
            "Computer generated.",
            "Schedule.",
            "So far this year, in January 22, guns, including assault rifles and 1000 rounds of ammunition, were series from one man's big Port Security Chief, James Bond.",
            "Junior says Armor is a valuable supplement to what his officers do.",
            "Humans schedule things that you need to follow the patterns that based upon their own set of extensions, intuition, even if you're trying to ramp.",
            "In the long run over my readers move forward.",
            "Watch.",
            "Result of theoretical work at USC by computer science grad student with a Homeland Security create.",
            "So I'll I've deleted the rest of this."
        ],
        [
            "Video.",
            "So this is the kind of interface that we may.",
            "Have so they will say how many doctors they have in them for the morning shift for the evening shift and so forth.",
            "How many days they want to schedule and then it has input all of the flight data and number of passengers and all that and uses that to then generate the schedules that generate a randomized patrols for these canine units."
        ],
        [
            "So that's the one of the first applications, and I'm going to go through a series of applications, hopefully quickly and then hand over to Chris.",
            "The second one here is for the Federal Air Marshall Service.",
            "These are undercover police officers.",
            "This is the last line of defense against the hijackers.",
            "So if you look at the problem that they face, there's you know 27,000 domestic flights, 2000 international flights per day, but there aren't enough air marshals to be on all of these flights, and so the question is how do we allocate air marshals to flights, knowing that different flights have different risks?",
            "And again, they may be surveillance where air marshals may be detected and so forth, and so on to randomize, allocation of air marshals to flights."
        ],
        [
            "So.",
            "This is a massive scheduling problem.",
            "There are lots of constraints in terms of the fact that we need tours the duty hours off hours, all sorts of things, but at the same time we have to do this.",
            "Dealing with the adversary who may be conducting surveillance and have to do randomization of our schedules to avoid predictability.",
            "Again, covering high risk flights more often and so forth.",
            "Again, by casting this problem as a Stackelberg game, we can try to solve it, but you can now see that the problem has really grown quite large with just hundred flights and ten officers.",
            "We have a huge number of combinations, but in reality of course the problem is much much bigger.",
            "I can't.",
            "I'm not saying we can solve this whole problem right now.",
            "This remains an open challenge.",
            "What we have focused on is more of just the international sector and already that even there the problem is really complex."
        ],
        [
            "So we've developed a system called Irish.",
            "Witcher?",
            "Is an interface here, so it was delivered to the air marshals in the spring of 2009 and since October of 2009 it's been in use to schedule air marshals on international flights, so some of you may have flown US air carriers from the United States to here.",
            "You know you may weather or not.",
            "There was an Air Marshall on that flight may have been determined by the system."
        ],
        [
            "Another thing that another application we've worked on is something called Protect.",
            "Now you can see that we've spent enormous amounts of precious research time coming up with all these acronyms.",
            "OK, so this is really a lot of very important problems.",
            "Scientific challenges that were solved.",
            "So look how much time it took to come up with such a big acronym here.",
            "So protect is for randomizing patrols for the Coast Guard for the of US Coast Guard, it's diploid in Boston right now it's being tested.",
            "Given the success in Boston, the next stop here is to go to New York to Randomize Coast Guard operations for boats and helicopters, and so forth in New York and if that goes OK and then expand to other port."
        ],
        [
            "Um?",
            "Guards is again you can see the acronym there under evaluation for national deployment by the Transportation Security Administration, so.",
            "You know the TSA is involved with the.",
            "Of course.",
            "Many of us know about the TSA and checking passengers daily at US airports and so forth, so we're not involved with that at all.",
            "What we are involved with this?",
            "The activities that they do in the background for perfecting the airport and this is to do infrastructure protection, patrols and so forth.",
            "Guard is a system under evaluation.",
            "The basic idea here is you have some number of security officers.",
            "You have a large number of operations.",
            "The check for security throughout the airport so people aren't going off on the runways or whatever, and we want to allocate these officers time to these different activities throughout the day.",
            "In a randomized fashion.",
            "If this works, the goal here would be to to apply to all of the 4 / 400 airports in the United States, and again the problem has been cast in terms of a Stackelberg game.",
            "It's been delivered.",
            "The system is being tested at an airport, so we had written this paper and we had mentioned the name of the airport paper came back with the name of the airport scratched, so the message we took away is that we're not supposed to say where exactly the system is deployed, so I will not say that, but it is actually deployed."
        ],
        [
            "This that potential applix.",
            "So those are applications that are diploid or in transition, but there are potential applications worldwide.",
            "I grew up in the city of Mumbai which unfortunately continues to be a target of terror attacks repeatedly.",
            "Even today, as you may have seen in the news, there were attacks in Mumbai in 2008.",
            "Of course, there's these attacks.",
            "For example, this hotel on fire not too far away from where I grew up anyway.",
            "In response to these police set of randomized checkpoints in the city.",
            "So in one of my summer trips there are walking along the oceanfront in police, van pulled up and they put up these checkpoints.",
            "This checkpoint and so forth.",
            "And I I I certainly yes, this is randomized checkpoints in the city I can.",
            "Tell you how to set up randomized check once.",
            "I'm sort of trying to go towards the police trying to tell them you know what I could do for them and so on and so forth.",
            "And I realize this is really a bad, bad idea because this is a surveillance of their activities and so on.",
            "So I moved away from there, but later on I did get an audience with the larger room of officer."
        ],
        [
            "And so the question they posed for us is this.",
            "Supposing we knew that the attackers are coming in from the sea and we want to set up checkpoints in the city, where would we set it up?",
            "We can cause this problem as a Stackelberg game now, but in this case it's on a graph where there are these entry points, their targets in the city, and we cannot.",
            "We have to put up randomized checkpoints, because again, there can be surveillance, and therefore you want to, and you don't have enough resources to protect the whole set of targets exactly.",
            "And so this is a very difficult challenge once you take into account all of the constraints we've done.",
            "So we've made some progress.",
            "But solving this problem exactly for the whole city of Mumbai is a real is a real big open challenge.",
            "You can solve it for we can solve it only for a small part of Southern Mumbai.",
            "It's just not enough.",
            "But if you solve this.",
            "Police in Mumbai can use this.",
            "Use your ID."
        ],
        [
            "But there are many many applications beyond just counterterrorism.",
            "For example, the Los Angeles Sheriff's Department is interested in saying, well, how can you use this game theoretic approaches for not only counterterrorism, but crime suppression, in even for checking for ticketless travelers in the city in on the on the train system.",
            "So lost in Los Angeles, there isn't a barrier system, so.",
            "People can just get on the train if they want to.",
            "And so the question then is the police set up police to randomize checks, and so the question is where and when should they do these checks?",
            "But there are others, Customs and Border protection to check for drug interdiction for illegal stopping illegal migration if we are in some countries when USA, it or other types of aid flows in health supplies go to different corners of the country, but they get pilfered along the way.",
            "People who may steal these supplies along the way.",
            "Again, you can do randomized checking to stop the theft of these supplies.",
            "Pollution checks cyber security robot patrolling lots and lots of different applications that can all work on the same idea of randomized checking using a game theoretic approach, and in particular this notion of Bayesian stacker."
        ],
        [
            "Games.",
            "So."
        ],
        [
            "The question we come to is how do we assign limited resources to defend these targets?",
            "An approach we've taken is a game theoretic approach.",
            "A Bayesian Stackelberg games approach, and the main point I want to emphasize here is that we are not claiming that we've solved this problem.",
            "There are many, many interesting research challenges here, but we've certainly made an improvement over what was being done there before in terms of people doing things by hand or other techniques that were used before these tech."
        ],
        [
            "Replied there's a number of publications.",
            "If you wanted to follow up on this work at.",
            "In terms of major venues at Arm's AAA each guy.",
            "Major AI Journal articles, and there's a book coming out security and game theory this fall, and this is the this is a website you can go to to get more publications and so on.",
            "At this point I'll hand over to Chris, who will go into the basics of theoretical.",
            "Change the microphone.",
            "OK, can everyone hear me in the back for good?",
            "OK, thank you very much.",
            "One for the wonderful introduction.",
            "So now I hope you're all very motivated to learn about the details of these security games and the algorithms that we've developed.",
            "To solve these kinds of games."
        ],
        [
            "So over the next 50 minutes or so, I'm going to start by talking about some of the background and basic models and how we frame these security situations within a game theoretic context.",
            "And then I'm going to talk about two directions that we've pushed in terms of algorithm development.",
            "The first is scaling to complex, very large action spaces.",
            "And then we'll start talking about how we handle various kinds of uncertainty.",
            "I'll start by talking about how we handle payoff uncertainty, and then turn it over to Mullins to talk about how we handle uncertainty about human behavior and other aspects of these games."
        ],
        [
            "So basic security game.",
            "Please get more complicated in different kinds of ways.",
            "Most of the games that we talking bout have this sort of underlying dynamic, so we have two players, a defender and attacker.",
            "And there's a set of targets the attacker is trying to attack some target within this set of targets, and the defender has some resources that they can allocate to try to defend this set of targets against attacks.",
            "The pay offs are going to define a reward or penalty for each of the two players.",
            "And we distinguish between the case of a successful or unsuccessful attack.",
            "So if the attacker chooses to attack a target that's defended, their unsuccessful, and if the target is undefended, then we say that they're successful."
        ],
        [
            "One issue that often comes up is whether or not security games should always be modeled as zero.",
            "Sum games and the answer, at least in the kinds of applications we worked on working on, is often no.",
            "So it turns out that these.",
            "There's a lot that goes into evaluating potential attacks on targets, including things like potential casualties, the economic costs of attacking a particular target, and the symbolic value of targets, and what we've learned from talking with domain experts is that.",
            "So the defenders and the attackers may not weigh these different elements of the outcomes in the same way, right?",
            "So the attackers may care more about, for example, the symbolic value, whereas the defenders care more about the loss of life or casualties.",
            "So in a lot of our algorithms we make it weaker assumption.",
            "Then the zero sum assumption, which is that the payos are sort of moving in the same direction, but not necessarily with the same magnitude.",
            "So in particular.",
            "For a particular target.",
            "If that target is attacked, we say that.",
            "The payoff has to be better for the defender if that target is defended as opposed to if it's undefended and vice versa for the attacker, so attackers prefer to attack undefended targets versus dependent targets.",
            "An defenders prefer the opposite."
        ],
        [
            "So let's look at an example of a very simple security game.",
            "Here we have two players.",
            "We have the police.",
            "And an attacker and the police are going to make a decision here between deploying the resource.",
            "They only have one resource in this example, and they're going to play that resource to either target one or Target 2.",
            "While the attacker is making a decision to attack either target one or target too.",
            "Those of you that are familiar with game theory will probably recognize this as a simple normal form game.",
            "It's two players, two actions.",
            "And we can fill in the pay offs into this game matrix.",
            "So over here if if the defender chooses to defend target one and the attacker chooses to attack target one, the defender gets a higher pay off, so they get a path of 1 and the attacker gets loses and gets a path of negative one.",
            "We fill in the past with the rest of the targets.",
            "So in this example we have Target 2 seems to be a little bit more important because we have larger magnitude pay offs for that target.",
            "But this is not a 0 sum game, so here we have a value of two for the defender and a value of only negative one for the attacker.",
            "So now that we have a representation of this conflict between the defender in the attacker, we can apply our standard game theoretic tool set to try to analyze."
        ],
        [
            "This game, so in particular we can look at things like best response.",
            "So we can say if the defender chooses to defend target one, what is the attacker's best response?",
            "So to do that, we just need to compare the two possible strategies for the attacker here, so the attacker can get either negative one by attacking target one or two by tacking tar."
        ],
        [
            "Two so of course the best response is for the attacker to choose Target 2."
        ],
        [
            "Similarly, we can do the same kind of analysis at the defenders, choosing to defend Target 2, and in that case the attacker prefers to attack Target 1.",
            "Now is Montauk to lot about.",
            "What we're really interested here is in."
        ],
        [
            "Randomize strategies, so if we look at the class of mixed strategies or probability distributions over pure strategies for the defender.",
            "And let's start with a very simple one.",
            "So if the defender just flips the coin and says half of that, I'm going to target 1/2 of the time.",
            "Go to Target 2 and we can look at what the outcomes are.",
            "So if the attacker chose to attack Target 1/2 the time you get a half of 1 and half of the time you get a path of negative one.",
            "That's an expected payoff of 0.",
            "An if the attacker chooses to attack target 1/2 of the time, you get negative two half the time you get 2.",
            "So again you have an expected path of zero and one of the things to notice is that it's better for the defender than either of the two peer strategy pay offs which were negative one and negative 2.",
            "OK."
        ],
        [
            "So if we extend these ideas of taking mixed strategies and best responses, we can arrive at the most famous solution concept in game theory, which is that a Nash equilibrium.",
            "So a Nash equilibrium profile for this game is going to be a pair of mixed strategies for the attacker and the defender such that both players are playing a best response to the other player strategy.",
            "So that solution has the property that neither player can improve their payoff by changing to a different strategy, given what the other player is doing."
        ],
        [
            "If we compute the Nash equilibrium for this game, we get a somewhat intuitive result.",
            "Here the defender should should defend target 260% of the time in target 140% of the time, so they're more frequently patrolling that more important target.",
            "And Meanwhile the attacker is choosing 67% of the time to attack the less valuable target target one and 33% of the time to attack Target 2, which is the more valuable target."
        ],
        [
            "Now, for security games we often use a variation of Nash equilibrium that allows us to model the surveillance that hackers can do before launching an attack.",
            "So is Melinda mentioned in a lot of the real world domains, we know that attackers are very.",
            "They spend a lot of time and a lot of effort trying to plan attacks, particularly against valuable targets such as LAX.",
            "Or an international flight.",
            "In the case of the air marshals.",
            "So we want to capture that in our game model and the way that we do this is by using Stackelberg games.",
            "So in the Stackelberg game model, the defender has to has to move first, they have to commit to a mix strategy particular security policy.",
            "And then the attacker is able to observe that policy by, for example, gathering insider information, sending somebody through, sending somebody to the LAX airport for six months to try to figure out you know what is the distribution over where the checkpoints are placed in the airport.",
            "That sort of thing.",
            "So Defender chooses a mix strategy and the attacker gets to choose an exact optimal response to that strategy.",
            "So for this kind of stockel board game, the solution concept is a strong Stackelberg equilibrium.",
            "Which is an optimal strategy for the defender under the assumption that the attacker is going to choose an optimal response to that strategy."
        ],
        [
            "So there's a paper actually before all this work on security games got started in 2006 by conference and home that laid out an algorithm for solving this for solving Stackelberg games in general.",
            "I.",
            "So it's pretty.",
            "It's framed in terms of a mixed integer program here, and I'm not going to go through all the details of the notation, But basically this is so.",
            "This entire linear program is finding the optimal value for the defender, assuming that an attacker chooses a particular response action.",
            "So, given that our linear program says that we're maximizing the expected path for the defender.",
            "This line gives a constraint that.",
            "The action we've chosen for the attacker has to be optimal, so.",
            "The payoff for that particular action is greater than or equal to the payoff for any other possible action the attacker could take an these last two constraints are just.",
            "Clarifying the constraints on the defender has to choose a legal probability distribution.",
            "Over their possible actions.",
            "So if we solve.",
            "One of these linear programs for every possible action.",
            "Of the attacker.",
            "And take the maximum over the values that are returned.",
            "That gives us the optimal solution to the game.",
            "So we're solving.",
            "That's why this is called a multi linear programming formulation.",
            "Because we're solving a number of different linear programs and then taking the maximum over.",
            "The strategies for those.",
            "So many of the algorithms that we'll see going forward have this sort of integer programming style approach under."
        ],
        [
            "Item.",
            "So the algorithms that we've been developing over the last five or six years to handle large, complex security games focus on a number of different research challenges.",
            "The first set of research challenges are related to the problem of having very large, complex action spaces.",
            "And these action spaces can be complicated, either because there's a very large number of defender actions.",
            "In the case of the air marshals, we have many, many possible air marshals, and we have complex constraints about how these air marshals can be scheduled, so that leads to a very large possible action space for the defenders.",
            "And in the case of Dubai example that will mention briefly we have a lot of possible strategies for the attackers because attack actions in that case are modeled as possible path through graph.",
            "I'll talk more about the different challenges than certainty when we get to that part of the talk, but there's also a lot of different kinds of uncertainty that we can have in these games that also makes them very complex and challenging."
        ],
        [
            "Solve.",
            "So this is a slide that gives a subset of the algorithms that we've developed over the last six years an I ran out of room on the slide so I couldn't put all of the algorithms that we've developed, but you can see that there's a lot of different algorithms for different domains that scale well in different dimensions, whether they handle very large numbers of defender actions, very large numbers of attacker actions, different kinds of payoff structures, uncertainty over payoff structures.",
            "And different kinds of scheduling constraints.",
            "So the schedule constraints particularly relevant to things like the air Marshals domain and as mentioned, we've had a lot of graduate students put a lot of effort into coming up with nice acronyms for these games.",
            "Are for these solution algorithms.",
            "But to try to avoid some of the confusion of having to keep track of all these different names during the talk, we're actually going to refer to most of them by the applications.",
            "For example, armor Iris 123 and four."
        ],
        [
            "So.",
            "The problem of scaling to complex action spaces became very clear when we first started looking at the federal air Marshals domain after."
        ],
        [
            "We had already solved the develop the armor system for the LAX airport.",
            "So the game matrices that were being solved for the LX Airport were on the order of a few 100 actions for each player.",
            "And when we.",
            "Took exactly the same approach and tried to formulate a game matrix for the air marshals problem we ended up with millions of possible strategies for the defenders and thousands of possible strategies for the attackers.",
            "And in fact, example with only 100 flight flights, antenn air marshals and remember the real problem is 30,000 flights.",
            "An 3000 air marshals.",
            "I just generated 1.7 * 10 to 13 possible actions for the defender in the sort of naive representation.",
            "So just applying the same algorithms have been used for armor, there was no hope of solving this.",
            "We could solve up to about 20 flights, but then after that point we ran out of memory entirely.",
            "So we've developed a couple of different approaches actually for handling games with such large and complex defender strategy spaces.",
            "I need to go through each of these briefly, but both of them rely on not enumerating the entire space of possible strategies, so we have to reason either over a more compact representation of this space, or a restricted part of the strategy space."
        ],
        [
            "So the first idea.",
            "Was to reason over what we call marginals instead of the full joint probabilities, so.",
            "This example appear.",
            "Gives us a problem with where we have 10 possible tours for air marshals and three air marshals, so the raw strategy space here would be possible.",
            "Combinations of these tours so we send Air Marshall one flight Flight 2 or one Air Marshall 2IN Flight 2 or 2 three and so on.",
            "So it turns out there's 120 possible combinations here and in the representation of the strategy space we would have to have a probability for each of these possible combinations of tours.",
            "So, given that we could use a integer programming formulation similar to the one I showed you before, But the problem is that the number of variables is is exponential in the number of.",
            "In the number of air marshals that you have.",
            "So this integer program does not scale very well at all.",
            "We looked at the actual payoff matrices that were generated by this process and we noticed.",
            "There seems to be an awful lot of repetition in the payoff, so this strongly suggests that there is some sort of structure here that we can exploit in actually coming up with the.",
            "A better, more scalable solution approach an we came up with the representation.",
            "Which allows us to reason just over with all the marginal probabilities on the targets.",
            "So that is the probability that there's going to be some Air Marshall on each of the possible flights.",
            "That reduces this size of the strategy space dramatically, so in this case we have 10 variables instead of 120 variables that we need to represent the defender strategy space.",
            "I.",
            "Now one of the the complexities here is that we're actually not generating an explicit schedule for the defender to follow, but instead were saying you need to have some Air Marshall on each of these flights with this probability.",
            "So afterwards we have to do a post processing step to find what the actual strategy is for the defenders, and it turns out that that's only possible if we have very simple tours.",
            "So if we have tours of restricted size, in this case up to size 2.",
            "So the other approach is I'm going to show you in a moment, works for arbitrarily large and arbitrarily complex scheduling constraints.",
            "Um?",
            "But this approach of reasoning just over the marginals works for relatively simple scheduling constraints."
        ],
        [
            "Given that approach, we can come up with another linear programming formulation, and so these are starting to get more and more complicated.",
            "I'm not going to go into."
        ],
        [
            "Details of that.",
            "I do want to talk talk you through an algorithm we have for the simplest possible case because I think this actually gives some nice intuition for what these solutions actually look like.",
            "This is a very fast polynomial time algorithm.",
            "It works for a very restricted case where every resource or every air Marshall, for example that you have is exactly identical.",
            "They can cover exactly 1 target.",
            "Ann any any of your resources can cover any of the possible targets.",
            "In addition, we have the payoff assumption that the payoff have to be moving in sort of the opposite direction, so they don't have to be exactly 07.",
            "So this is an example where we have 4 air marshals or four flights and we're going to allocate one Air Marshall to cover these four flights.",
            "The attackers paths are shown in this table over here, so if the flight is uncovered, the attacker gets a path of four for attacking the first Flight, 3 for attacking the 2nd two.",
            "In one, we're going to keep things simple and say if any of these flights is covered, the attacker always gets a payoff of 0.",
            "And just for your intuition, you can assume that the path for this or 0 sum, so the defender is getting exactly the opposite path that the attacker is getting.",
            "So these bars here represent the attackers expected payoff for attacking each of the four targets.",
            "Given this, this defender coverage strategy.",
            "So right now we have all zero, so the defender is covering each of these targets with zero percent probability.",
            "And the attacker is getting the exact uncovered paths that we have here."
        ],
        [
            "I.",
            "We can define a very useful notion called the attack set, which is going to be the set of targets that the attacker is willing to attack.",
            "So the attacker is getting the maximum expected payoff for attacking some set of targets an right now there's exactly 1 target in that set, which is the target here that has the highest bar."
        ],
        [
            "So our first observation is that it can never be optimal or never benefits the defender to add additional coverage to something that's outside of the attack set.",
            "The attacker is always going to take something within that attack set, because it's the best response, right?",
            "And remember our equilibrium solution concept says that the attacker has to choose the best response strategy.",
            "So this tells us something immediately about where we have to assign the first bit of coverage probability here.",
            "So we need to assign coverage to this target that has the highest set.",
            "And we need to keep doing that until the expected payoff is equal to the next highest expected payoff.",
            "For the attacker."
        ],
        [
            "And simply by doing a little bit of algebra, we can compute exactly what the right coverage is necessary for those two to be equal is and.",
            "So now we have two targets in our tax set.",
            "We have two targets and the Packers win 22."
        ],
        [
            "Our second observation is that.",
            "It never benefits the defender to add coverage to just one of those targets in the attack set.",
            "The reason is that as soon as you start adding coverage to one of the targets, it's no longer in the attack set because the attacker is worse off attacking that then the other targets in the attack set.",
            "So what we really need is to is to sort of add coverage to these two targets in such a way that the attacker is expected payoff moves down by the exact same amount.",
            "It sort of moves down in lockstep until it reaches this third target over here."
        ],
        [
            "And again, doing a little bit of algebra with the payoff so we can, we can compute the coverage probabilities that are required for the pass through the attacker.",
            "For these first 2 targets to equal the path to the third target."
        ],
        [
            "Now if we try to do that for the 4th target.",
            "We come up with with the problem because now we need we need more coverage probability that we actually have.",
            "We only have one Air Marshall, so we can't allocate that Air Marshall 75% of the time.",
            "This target 66% of the time to this target etc.",
            "So what that tells us is that.",
            "In the optimal solution, the attacker is never going to be.",
            "It's never going to be the best strategy for the attacker to take this."
        ],
        [
            "Target.",
            "If we go back one step though, we still have some additional coverage that we can assign and we want to assign it to these three targets in such a way that the we've assigned all of this probability in the optimal way."
        ],
        [
            "And again, I'm not going to show you the equations, but there's just by doing a little bit of algebra we can come up with the right ratios to add that coverage probability, and so all those bars move down at the same rate.",
            "And that gives us what is the optimal coverage strategy for the defender in this case?"
        ],
        [
            "As we've been pushing forward on developing the next generations of that system, we've had to develop approaches that were able to handle more complex scheduling constraints.",
            "Then we could handle with the original approach, or just reasoning over the marginals.",
            "So we've started to explore a different kind of solution called branch and price.",
            "This is an approach that comes to us.",
            "From the operations research community and its approach that's used to solve very very large integer programming problems.",
            "It works by using a combination of branch and bound search over integer variables.",
            "An column generation which I'll describe to you in a moment.",
            "First, most of you are probably familiar with basic branch inbound solution methods.",
            "This is a branch of boundary for our problem.",
            "The orange nodes here represent problems where we have restricted where we've selected a particular target for the attacker to attack, so this is the attackers choosing to attack Target 1.",
            "Packers choosing to attack Target 2 all the way up to N. And if we solve each of those nodes, that gives us a lower bound on the defenders optimal payoff.",
            "The entire problem space.",
            "The blue nodes up here represent nodes where the attacker so.",
            "This blue note is where the attacker can choose any target at all.",
            "This blue node is where the attacker could choose any target other than target one, etc.",
            "So it turns out that we can compute upper bounds for these blue nodes using one of those two algorithms that I showed you before, so we can relax the scheduling constraints of the actual problem and we can solve it using that simplest version of the problem.",
            "It runs very fast in polynomial time, and that this is a very fast way to compute upper bounds for these blue nodes.",
            "For the.",
            "Orange or red nodes?",
            "I can't quite tell what color that is on this projector, but for the orange nodes we have to use this approach called column Jenner."
        ],
        [
            "And I'm going to give you a very, very brief overview of column generation.",
            "The problem is that.",
            "These orange nodes are actually very very large, so these orange nodes in the natural representation have that exponential strategy space for the defender.",
            "The COM generation approach works a bit differently than the approach of reasoning for marginal zone that reasons over.",
            "A subset or a small set of support for the strategy space.",
            "So we start by defining a master problem, which is going to be solved for a restricted, very restricted set of the possible strategies for the defender.",
            "Then we find the optimal strategies for that set of possible strategies."
        ],
        [
            "And then we solve what's called the slave problem.",
            "So the slave problem is basically going to generate additional strategies to add to our master problem.",
            "Une scheduled mental break.",
            "Now we've had a moment to process everything that we've gone through so far, so I will.",
            "So remember, so we're using a branch inbound approach over these.",
            "But the integer variables in our formulation, which are specifying which targets are being attacked.",
            "And I was talking about how we use the column generation approach to solve these very large linear programs in each of the lower bound nodes.",
            "So we're starting with the master problem, which is solving the problem over restricted number of the possible joint strategies for the defender.",
            "And once we've solved that for the restricted problem, we solve the slave problem and the slave problem basically answers to questions for us.",
            "The first is, can we improve the defenders payoff in their stricted problem by adding some some additional strategy from the defender space into that restricted problem, and if so, which is the best one to add to that restricted problem?",
            "So we came up with a minimum cost network flow representation which will answer both of those two questions using the paradigm of reducing or minimizing the reduced costs.",
            "This is a standard technique in linear programming.",
            "I given this we solve this network flow formulation that returns the next strategy to add to our master problem.",
            "We solve that problem.",
            "It gives us the next gratitude.",
            "We do this iteratively until that first condition holds and we know that we can't improve the solution anymore by adding anymore of the defender strategies into the reduced the restricted problem.",
            "Basically what this is exploiting is the fact that we can get optimal solutions that have a very small support in the space of the defender strategies.",
            "So even though there may be millions or 10s of millions or trillions of strategies for defender, we can find an optimal strategy.",
            "With support or positive probabilities for maybe 10 or 100 of those possible pure strategies."
        ],
        [
            "Again, we have some some runtime results here.",
            "It turns out that the algorithm for the arbitrary scheduling case runs roughly as fast as the best algorithm we have for the that uses just the marginals and we can scale up quite well to very large numbers of targets.",
            "Very complex schedules as well."
        ],
        [
            "OK, so I want to shift gears now so those those were approaches for dealing with the dealing with the problem of having very large complex defender strategies.",
            "Defender strategy spaces.",
            "So I want to talk about modeling different kinds of uncertainty in these games.",
            "And we're going to start by dealing with the case.",
            "The payoff uncertainty, which leads us down the road of trying to solve instances of Bayesian Stackelberg games."
        ],
        [
            "And what we found in these in working in these real world security domains is that there is a lot of different kinds of uncertainty that we have to account for.",
            "We have uncertainty about the kinds of decision-making processes that the attackers are using.",
            "We have uncertainty about with the way that the attackers are actually able to observe the defender strategy in the real world.",
            "We have uncertainty about how the attackers are assessing the possible payoff.",
            "How much do they value attacking one target versus another target?",
            "We have uncertainty about what the capabilities of the attackers are.",
            "What kinds of technologies do they have access to?",
            "Where are they at?",
            "Any particular time?",
            "And we even have uncertainty about how well the defenders will execute.",
            "The actions that we assigned for them.",
            "So if we tell the police to go and set up a checkpoint on this particular Rd, but they get called off to do something more important and respond to threats somewhere else in the airport, they may not even execute the strategy exactly as it's been presented to them.",
            "So all these are topics of ongoing research.",
            "We're going to present just a few of them to you today."
        ],
        [
            "So from the very first implementations of the armor system for ELEX, we've been concerned about the issue of not knowing exactly what the attackers pay offs are.",
            "So for example.",
            "One issue that came up when we were talking to the experts there was that there might be different kinds of attackers.",
            "There might be some attackers who were very sophisticated, very highly capable terrorist organizations or other attackers who were local gangs, or maybe disgruntled employees at the airport, and that these attackers might have very different capabilities leading to different pay offs if they were to launch an attack.",
            "So we can represent that as a Bayesian game where we have.",
            "Instead of a single payoff matrix, we have here a situation with three different possible attacker types, so we have three different path matrices representing the payoff for those different types, and we also have a probability distribution over these possible attacker types.",
            "The standard way of solving this using the existing algorithms would be to two.",
            "We call Harsanyi transformation.",
            "Basically we take these individual path matrices and we transform them into a larger payoff matrix in which the attackers action space is now an action for each of the possible types.",
            "So this corresponds to attacker type one choosing action one Type 2, choosing action one Type 3, choosing action one, and we have an action in this game for every possible combination of actions by the attacker types.",
            "If we were to apply the multiple LP's method to that we could solve this kind of game using this on your transformation.",
            "But unfortunately we do know that these are NP hard problems, so that approach really does not scale."
        ],
        [
            "Terribly well.",
            "Add.",
            "In the original Armor application that developed an algorithm called Dobbs, which was a more efficient integer programming formulation of this that avoids the Harsanyi trans."
        ],
        [
            "Formation the approach of using the Harsanyi transformation an applying multiple peas is basically these two lines and the dog's algorithm that avoids her signing transformation.",
            "Is these two lines?",
            "Unfortunately, we have a log scale over here, so this is still even.",
            "Those lines look linear, they're still scaling exponentially as we increase the number of types.",
            "But this was at least sufficient for the LAX problem.",
            "We had relatively small action spaces, and we were interested in a relatively limited set of potential attacker types.",
            "As I started working on larger and larger versions of these games and became interested in modeling more and more different kinds of attacker types, we were motivated to do more work to try to scale up these solution algorithms for Bayesian games further."
        ],
        [
            "So this tree here represents a Bayesian game, each level in the tree.",
            "Is the action choice for a different kind of attacker type?",
            "So this is attacker type one choose action, one attacker type, One chooses action two and then the second level.",
            "Here is the action choice for attacker Type 2.",
            "This is basically equivalent to this person new transformation and the problem here is that you have an exponential number of these nodes.",
            "At the bottom of the tree.",
            "And if we were to do that straightforward approach, just applying the multiple LP's method to this history, basically that means that we have to solve an exponential number of linear programs to actually get a solution.",
            "But now that we have it in this tree form, we can return to our notion of using branch and bound search to try to improve the speed of these solution methods.",
            "And if we're able to find some nice bounding rules or efficient search heuristics for operating this space of attacker types, we can potentially speed up the results of the algorithm by having by avoiding a lot of these computations at the at the leaf nodes."
        ],
        [
            "And the idea that we use.",
            "For this is basically to solve restricted, more simplified versions of these games first, and to use the results of those in.",
            "Be more general versions of the game.",
            "So this is another tree.",
            "Actually, each of these nodes.",
            "Here is one of those trees that I showed you in the previous slide, so this node represents the full game.",
            "Here we have a game with four possible attacker types.",
            "This node is the game restricted to only attacker type one and hacker type 2.",
            "This note is attacker type 3 attacker Type 4 and these bottom nodes here are attacker type 123 and four.",
            "So the way that we solve this is we solve first these nodes with only a single attacker type.",
            "So we assume that the defender knows exactly which of the four attacker types he's facing, and we find an optimal strategy for the defender against each of these types individually.",
            "We then use the information from that to derive branching and bounding rules for solving these.",
            "These nodes that are higher in the tree, so we take the solution for type one and Type 2 and we solve Now a larger game that has the attacker or defender facing two attackers of type one or type 2, and we solve this other game and then we propagate the information from those solutions up to the full game.",
            "I also mentioned that we can actually speed up the solution to these individual nodes using the same sort of column generation approach that we used for scaling.",
            "Two very large defender strategy spaces.",
            "Yes.",
            "Step three and four yes.",
            "Will the company?",
            "So the root node here is the node that has all possible combinations.",
            "Yeah, so solving each of these games is an approximation, but when we actually solve this node at the top, we get the exact solution.",
            "OK, so we're using approximate solutions in a sense.",
            "In essence, to guide the search for the exact solution.",
            "In the root node."
        ],
        [
            "Just to show you the some of the computational results for how that works.",
            "This is the original method, and this is actually the method believe that.",
            "That's right, so this is the branch and bound that doesn't do that sort of breakdown and use the results of these simpler.",
            "Simplified games, the green node here is this full hierarchical method where we solve the individual types 1st and propagate that information up the tree and you can see that up to six types, which is about the largest game that we could solve for the previous methods.",
            "We're still doing quite well.",
            "And in fact, using this approach we were able to get up to 50 different attacker types.",
            "In under an hour and just to give you a sense of how large a game that really is, if we were to break that down into use, the multiple LP's approach that means we would need to solve 8.9 * 10 to the 34 different linear programs.",
            "So by using the information from the simpler games we're able to prune out an awful lot of the computation from that full game."
        ],
        [
            "So the kinds of algorithms I talked to you so far are good for modeling different kinds of distinct attacker types.",
            "So now I want to give you a quick introduction to a different kind of game that we've looked at.",
            "That's good for modeling a different kind of payoff uncertainty.",
            "And the problem here is that in specifying each of these game models, we basically have to fill in the pay offs for each of these different possible combinations of actions.",
            "So we're doing this based on.",
            "Essentially, what the experts tell us they're using historical data intelligence information.",
            "Lots of information of different kinds to try to find out, try to answer these questions about, well, how much would an attacker prefer to attack this target versus this target versus target?",
            "How much more valuable is this flight than another flight?",
            "And as we've made reference to before, there's a lot that goes into that, so they might be thinking about what is the likely number of casualties if we do this kind of attack on this particular target, what is the economic cost?",
            "What is the?",
            "The symbolic value.",
            "How do we weight all of these things?",
            "And the point here is that we don't actually have the exact numbers.",
            "So there is information available to help us make these judgments, especially relative judgments, right?",
            "So we can say, well, this flight is much larger than another flight and so forth, but it's very hard to pin these numbers down exactly.",
            "So we've looked at is a different version of this game where we allow the payoff to be specified using distributions instead of point estimates for the payoff."
        ],
        [
            "So here we have for each target in our in all the previous work that we showed you, we would have had a single payoff for a potential attack on the target when it was covered, and intentional attack potential attack on that target windows uncovered.",
            "So now we've taken that we've replaced that with a distribution over possible pay offs for each of those cases, and we have two of these distributions for each day."
        ],
        [
            "Git.",
            "So basically what this is is an infinite Bayesian soccer game.",
            "So now we have an infinite number of possible attacker types and we have a distribution over the infinite space of possible attacker types defined by the distributions over these individual pay offs."
        ],
        [
            "As we think about solving these infinite Bayesian Stackelberg games, first of all I should say that we're not able to solve them exactly, so we're talking about approximate methods for solving these these games and we can break it down into 2 steps.",
            "So supposing we had a specific defender strategy that we're interested in evaluating a specific coverage strategy that places a certain amount of coverage on each of the possible targets."
        ],
        [
            "We can ask the question of what is the attacker strategy and what we really care about is what is the probability that the attackers are going to choose to attack each of the possible targets.",
            "Given the defender strategy and these distributions over the possible playoffs."
        ],
        [
            "So that's question one.",
            "And then, given that attacker response function.",
            "We want to be able to search over the space of possible defender strategies to find the optimal strategy for the defender.",
            "Given the attacker response."
        ],
        [
            "We've looked at a number of different ways to approximate each of these questions.",
            "So first the attack vector.",
            "Simplest approach is basically to sample.",
            "Use Monte Carlo sampling to sample a number of distinct possible attacker types.",
            "Option two is to do a whole bunch of math to drive very complicated equation, specifying exactly what the attacker probabilities are.",
            "Unfortunately, don't have closed form solution, so we can only do numerical approximation on that.",
            "To try to find to try to estimate exactly what the attacker response function is.",
            "And then we've looked at a number of different ways to try to approximately optimize the defenders strategy.",
            "Given this attacker computations."
        ],
        [
            "It turns out that in this case, doing all the fancy matthan coming up with the numerical approximations loses quite badly to the simple Monte Carlo approach.",
            "So this is the.",
            "Summation error versus runtime an.",
            "The Monte Carlo sampling approach is giving us very, very accurate solutions much more quickly than the piecewise constant approximation method that we use.",
            "So most of the remaining work focuses on using the Monte Carlo approximation for the attacker types."
        ],
        [
            "As I said, we've looked at a number of different possible ways to approximate the defender strategy.",
            "I will point out two baseline measures that we used to test against.",
            "The first is just using a uniform random strategy.",
            "And the second one is basically ignoring the uncertainty in the problem.",
            "So if we solve the problem exactly using the mean of each path distribution, that is this baseline and I would argue that that's actually a very good approximation of what's being done when we force our end users to say exactly what the payoff is for a particular cell in these matrices, without using some sort of distributional assumption.",
            "We can use a number of different methods.",
            "Including.",
            "Both the armor method and the HP HP GS method to try to do exact optimization given a set, a set of sampled attacker types.",
            "And we can use a variety of different methods to do approximate optimization, including things like replicator dynamics and other methods."
        ],
        [
            "So I want to show you just very quickly the results.",
            "From this we have on the Y axis.",
            "Here the defenders expected payoff and here we're varying the amount of uncertainty that Defender has about the attackers pay offs.",
            "And what I want to point out is that both of the baseline measures are down here, so using the mean of each payoff distribution as a point estimate is giving you roughly the same performance as just doing something completely random.",
            "This line here is trying to do an exact optimization for a small set of attacker types.",
            "And the top three lines here are doing some sort of approximate optimization with a much larger set of sampled attacker types, so we can see.",
            "By doing by approximating a solution to this infinite Bayesian Stackelberg game, you're getting a much higher payoff than using either exact solution with a mean approximation of those distributions, or using a small number of sampled attacker types and exact."
        ],
        [
            "Station.",
            "This slide actually shows that that tradeoff quite clearly.",
            "So here we have increased, slowly increasing the number of sample attacker types, and you can see that the pay offs are improving dramatically as we start to increase the number of sample attacker types and are used to approximate the attacker response.",
            "So the key here is that we need.",
            "We need to get it to devote enough for computational resources to getting a good approximation of that attacker response, and it's worth trading off finding an exact optimization for the defender strategy.",
            "To get a better approximation of the attacker's response."
        ],
        [
            "So we think that these distributions are very useful modeling paradigm for.",
            "Particularly, modeling uncertainty in that knowledge acquisition phase and some of the existing approaches of using point estimates or small numbers of possible attacker types generate really poor poor performance when we look at them in this context."
        ],
        [
            "So I'm going to turn it over to Melinda again and he's going to talk about human behavior and observation alternative."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Alright, so.",
                    "label": 0
                },
                {
                    "sent": "Plan for this.",
                    "label": 0
                },
                {
                    "sent": "Victor.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Bill will be something like this.",
                    "label": 0
                },
                {
                    "sent": "So first of all, let me just say a couple of words about ourselves.",
                    "label": 0
                },
                {
                    "sent": "I'm at the University of Southern California professor of Computer Science and Chris is at the University of Texas at El Paso.",
                    "label": 0
                },
                {
                    "sent": "Is been there a year as an assistant professor?",
                    "label": 0
                },
                {
                    "sent": "And the outline and plan for the presentation here is that all begin talking about real world applications that we've developed.",
                    "label": 0
                },
                {
                    "sent": "This will be followed by Chris giving you background and basics of security games and the scaling up to complex actions and Bayesian security games and so forth.",
                    "label": 1
                },
                {
                    "sent": "I'll come back towards the end.",
                    "label": 0
                },
                {
                    "sent": "With.",
                    "label": 0
                },
                {
                    "sent": "Addressing human behavior.",
                    "label": 0
                },
                {
                    "sent": "And the fact that there's observationally uncertainty in these domains, and some of these things, we will explain as we go forward.",
                    "label": 0
                },
                {
                    "sent": "I'll talk also about evaluation, and then we'll get into a discussion.",
                    "label": 0
                },
                {
                    "sent": "Roughly speaking, you're saying about 5 minutes introduction, so that's this portion.",
                    "label": 0
                },
                {
                    "sent": "15 minutes of discussion towards the end and that leaves us about 100 minutes, and so it'll be 50 minutes for me and 50 for Chris.",
                    "label": 0
                },
                {
                    "sent": "And that's the way we planned this out.",
                    "label": 0
                },
                {
                    "sent": "But we welcome your questions, of course, and we can dynamically change the plan as needed.",
                    "label": 0
                },
                {
                    "sent": "By the way, can everybody hear me OK at the end, yeah.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Alright, so we'll start with this motivating real world.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Allegations.",
                    "label": 0
                },
                {
                    "sent": "So we have to.",
                    "label": 0
                },
                {
                    "sent": "The motivation here is infrastructure security.",
                    "label": 0
                },
                {
                    "sent": "We have to protect our ports or airports or critical national infrastructure.",
                    "label": 0
                },
                {
                    "sent": "And yet we have a limited security resources.",
                    "label": 1
                },
                {
                    "sent": "Which means that we may have to do selective checking.",
                    "label": 0
                },
                {
                    "sent": "But our adversary can monitor our defenses and exploit any patterns.",
                    "label": 0
                },
                {
                    "sent": "For example, this is the Los Angeles International Airport.",
                    "label": 0
                },
                {
                    "sent": "If we patrol this airport 9:00 AM, we are always a terminal.",
                    "label": 0
                },
                {
                    "sent": "1:10 AM always a terminal.",
                    "label": 0
                },
                {
                    "sent": "2:11 AM at Terminal 3 and so on.",
                    "label": 0
                },
                {
                    "sent": "An adversary will observe that an exploit that pattern.",
                    "label": 0
                },
                {
                    "sent": "In fact, over the history of my legs, they've been six separate attacks or plans of attack.",
                    "label": 0
                },
                {
                    "sent": "Some Fortunately, have been thwarted.",
                    "label": 0
                },
                {
                    "sent": "These are with guns and bombs, and so forth, and all the attackers have lived within 50 miles of the airport, giving them an ample opportunity to conduct surveillance.",
                    "label": 0
                },
                {
                    "sent": "So this leads to a very important challenge, which is how do we protect our infrastructure given that different targets of different weights, we don't have enough resources to protect everything 24 hours a day.",
                    "label": 0
                },
                {
                    "sent": "And yet, our adversary can monitor our defenses and respond to whatever it is that we do.",
                    "label": 0
                },
                {
                    "sent": "So game theory can.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Help us here, and in particular what we face is this challenge of many targets.",
                    "label": 0
                },
                {
                    "sent": "Fuel.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Resources and we will be looking to.",
                    "label": 0
                },
                {
                    "sent": "Bayesian Stackelberg games.",
                    "label": 0
                },
                {
                    "sent": "In order to assign our limited resources to these targets.",
                    "label": 0
                },
                {
                    "sent": "And I'll explain this notion of Bayesian Stackelberg games, sure.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So I'll start here by giving an intuitive description, and then Chris will come in and get more into details of this.",
                    "label": 0
                },
                {
                    "sent": "So just as an example, consider this simple airport with two terminals, terminal one and two.",
                    "label": 0
                },
                {
                    "sent": "Terminal 1 happens to be more important than Terminal 2, so there's targets with different weights.",
                    "label": 0
                },
                {
                    "sent": "Now, supposing there's one police units and not enough resources to be at both terminals.",
                    "label": 0
                },
                {
                    "sent": "So the police always knowing terminal one is more important.",
                    "label": 0
                },
                {
                    "sent": "Try to protect Terminal 1 everyday.",
                    "label": 0
                },
                {
                    "sent": "Well the adversary will observe that an attack Terminal 2.",
                    "label": 0
                },
                {
                    "sent": "So the adversary here gets a positive reward.",
                    "label": 0
                },
                {
                    "sent": "The second number is always for the adversary, the first for the police and the police get a negative reward because the police are at Terminal one and the adversary is Attack Terminal 2.",
                    "label": 0
                },
                {
                    "sent": "If now the police switch tactics and they're always at Terminal 2.",
                    "label": 0
                },
                {
                    "sent": "The adversary will now obviously Attack Terminal 1's adversary.",
                    "label": 0
                },
                {
                    "sent": "Again gets a positive reward.",
                    "label": 0
                },
                {
                    "sent": "The police get a negative reward.",
                    "label": 0
                },
                {
                    "sent": "So any deterministic strategy?",
                    "label": 0
                },
                {
                    "sent": "An adversary can defeat.",
                    "label": 0
                },
                {
                    "sent": "If the police were to use a mixed strategy randomized strategy, so that's a 60% of the time there at Terminal one and 40% of the time, there are Terminal 2.",
                    "label": 0
                },
                {
                    "sent": "An adversary conducting surveillance will know yes 60% of the time.",
                    "label": 0
                },
                {
                    "sent": "They're here, and 40% of the time they're there.",
                    "label": 0
                },
                {
                    "sent": "But what they'll do tomorrow remains unpredictable.",
                    "label": 0
                },
                {
                    "sent": "And this increases.",
                    "label": 0
                },
                {
                    "sent": "Adversary uncertainty and costs and improves police expected reward.",
                    "label": 0
                },
                {
                    "sent": "These kinds of games are called Stackelberg Games because the security forces commit first.",
                    "label": 0
                },
                {
                    "sent": "And the adversary responds.",
                    "label": 0
                },
                {
                    "sent": "We will also refer to Bayesian Stackelberg Games, which I'll not talk about here and Chris will expand on that a little bit later because there is uncertainty over adversary types.",
                    "label": 0
                },
                {
                    "sent": "What we're interested in is optimal allocation of our limited security resources.",
                    "label": 0
                },
                {
                    "sent": "I said 60% of the time at Terminal One and 40% at Terminal 2, but 6040 may not be the right mix.",
                    "label": 0
                },
                {
                    "sent": "It could be 7030 or it could be 5050.",
                    "label": 0
                },
                {
                    "sent": "Figuring out the right allocation of security resources.",
                    "label": 0
                },
                {
                    "sent": "The large number of targets is a difficult challenge.",
                    "label": 0
                },
                {
                    "sent": "Now for a two by two game we can solve this by hand.",
                    "label": 0
                },
                {
                    "sent": "But when it comes to hundreds of targets and 10s of police units, the problem already becomes very, very difficult.",
                    "label": 0
                },
                {
                    "sent": "In fact, what we are interested in is called a strong Stackelberg equilibrium.",
                    "label": 0
                },
                {
                    "sent": "Of these Bayesian Stackelberg games, the problem is known to be NP hard.",
                    "label": 1
                },
                {
                    "sent": "Our contributions have been more in terms of coming up with fast algorithms to solve these problems and we will explain how they work.",
                    "label": 0
                },
                {
                    "sent": "At the moment though, let me step back and talk to you a little bit about the applications that have been developed using this as the underlying mechanism.",
                    "label": 0
                },
                {
                    "sent": "And as I said, this is just at this point.",
                    "label": 0
                },
                {
                    "sent": "Just to give you an intuitive description of what's going on and then we will get into more detail in the second, when Chris in the second half when Chris takes off.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So I'll begin here with the first application that we diploid, and this is at the Los Angeles International Airport.",
                    "label": 0
                },
                {
                    "sent": "So armor stands for Assistant for randomized monitoring over roots and the word assistant happens to be very important in getting it deployed.",
                    "label": 0
                },
                {
                    "sent": "So the problem that the alleged police came to us with was OK, we have large numbers of inbound or six inbound roads into LX.",
                    "label": 0
                },
                {
                    "sent": "But there aren't enough police officers to man checkpoints on all of the roads at all times of the day.",
                    "label": 0
                },
                {
                    "sent": "So the question then becomes where and when would you set up these checkpoints?",
                    "label": 0
                },
                {
                    "sent": "Similarly, there is 8 terminals at LX.",
                    "label": 0
                },
                {
                    "sent": "But there's only maybe three or four dogs dog teams that are available at any one point, and so the question is, where and when would you send these dock teams for patrolling?",
                    "label": 0
                },
                {
                    "sent": "Knowing that adversaries may be interested in exploring a big truck bomb, and that there's different numbers of people at the airport at different times, and they shift over the duration of the day.",
                    "label": 0
                },
                {
                    "sent": "So both these problems can be cast in terms of the Stackelberg Games framework that I mentioned earlier.",
                    "label": 0
                },
                {
                    "sent": "Anne solved in order to generate a schedule for the police.",
                    "label": 0
                },
                {
                    "sent": "So in the case of checkpoints that tells them where and when to set up these checkpoints for the dog teams, it tells them OK in the morning.",
                    "label": 0
                },
                {
                    "sent": "At this time send Team 1, three and seven to Terminals 2, four and six.",
                    "label": 0
                },
                {
                    "sent": "Then after sometime switch the dog teams the move to some other terminals, and so on and so on, so they get a printed schedule and they can obey that schedule.",
                    "label": 0
                },
                {
                    "sent": "The main point here is that it's a randomized schedule which has taken into account target weights and the fact that there is surveillance that may be going on.",
                    "label": 0
                },
                {
                    "sent": "So this system.",
                    "label": 0
                },
                {
                    "sent": "They approached us in April of 2007.",
                    "label": 0
                },
                {
                    "sent": "By August of 2007, since we already had our algorithms created and so forth, we delivered the software to them, and it's been in use ever since and is considered one of the best practices for security at LAX.",
                    "label": 0
                },
                {
                    "sent": "So this was our first diploid.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Application.",
                    "label": 0
                },
                {
                    "sent": "And I have now going to show you a small video.",
                    "label": 0
                },
                {
                    "sent": "Hopefully it all works.",
                    "label": 0
                },
                {
                    "sent": "It's from a.",
                    "label": 0
                },
                {
                    "sent": "A new station in LA.",
                    "label": 0
                },
                {
                    "sent": "Unfortunately I couldn't get the kind of video that they could get myself, so I'm going to show it to you, but I've really edited it down to the minimum duration possible, so sorry to impose a news clip on you, or hopefully it's OK.",
                    "label": 0
                },
                {
                    "sent": "Very sophisticated tools to help keep us safe.",
                    "label": 0
                },
                {
                    "sent": "Harbor is one of them, but I cannot steal it.",
                    "label": 0
                },
                {
                    "sent": "Not Kevlar.",
                    "label": 0
                },
                {
                    "sent": "Silicon Armor is a computer program created by students at USC, will shoot those networks that SharePoint familiar scene, LAN some 50,000 vehicles today streaming in this airport, most encountering officers and their dogs, or just wait group.",
                    "label": 0
                },
                {
                    "sent": "Others are stopped.",
                    "label": 0
                },
                {
                    "sent": "How you doing?",
                    "label": 0
                },
                {
                    "sent": "Computer generated.",
                    "label": 0
                },
                {
                    "sent": "Schedule.",
                    "label": 0
                },
                {
                    "sent": "So far this year, in January 22, guns, including assault rifles and 1000 rounds of ammunition, were series from one man's big Port Security Chief, James Bond.",
                    "label": 0
                },
                {
                    "sent": "Junior says Armor is a valuable supplement to what his officers do.",
                    "label": 0
                },
                {
                    "sent": "Humans schedule things that you need to follow the patterns that based upon their own set of extensions, intuition, even if you're trying to ramp.",
                    "label": 0
                },
                {
                    "sent": "In the long run over my readers move forward.",
                    "label": 0
                },
                {
                    "sent": "Watch.",
                    "label": 0
                },
                {
                    "sent": "Result of theoretical work at USC by computer science grad student with a Homeland Security create.",
                    "label": 0
                },
                {
                    "sent": "So I'll I've deleted the rest of this.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Video.",
                    "label": 0
                },
                {
                    "sent": "So this is the kind of interface that we may.",
                    "label": 0
                },
                {
                    "sent": "Have so they will say how many doctors they have in them for the morning shift for the evening shift and so forth.",
                    "label": 0
                },
                {
                    "sent": "How many days they want to schedule and then it has input all of the flight data and number of passengers and all that and uses that to then generate the schedules that generate a randomized patrols for these canine units.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So that's the one of the first applications, and I'm going to go through a series of applications, hopefully quickly and then hand over to Chris.",
                    "label": 0
                },
                {
                    "sent": "The second one here is for the Federal Air Marshall Service.",
                    "label": 0
                },
                {
                    "sent": "These are undercover police officers.",
                    "label": 0
                },
                {
                    "sent": "This is the last line of defense against the hijackers.",
                    "label": 0
                },
                {
                    "sent": "So if you look at the problem that they face, there's you know 27,000 domestic flights, 2000 international flights per day, but there aren't enough air marshals to be on all of these flights, and so the question is how do we allocate air marshals to flights, knowing that different flights have different risks?",
                    "label": 0
                },
                {
                    "sent": "And again, they may be surveillance where air marshals may be detected and so forth, and so on to randomize, allocation of air marshals to flights.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "This is a massive scheduling problem.",
                    "label": 0
                },
                {
                    "sent": "There are lots of constraints in terms of the fact that we need tours the duty hours off hours, all sorts of things, but at the same time we have to do this.",
                    "label": 0
                },
                {
                    "sent": "Dealing with the adversary who may be conducting surveillance and have to do randomization of our schedules to avoid predictability.",
                    "label": 0
                },
                {
                    "sent": "Again, covering high risk flights more often and so forth.",
                    "label": 0
                },
                {
                    "sent": "Again, by casting this problem as a Stackelberg game, we can try to solve it, but you can now see that the problem has really grown quite large with just hundred flights and ten officers.",
                    "label": 0
                },
                {
                    "sent": "We have a huge number of combinations, but in reality of course the problem is much much bigger.",
                    "label": 0
                },
                {
                    "sent": "I can't.",
                    "label": 0
                },
                {
                    "sent": "I'm not saying we can solve this whole problem right now.",
                    "label": 0
                },
                {
                    "sent": "This remains an open challenge.",
                    "label": 0
                },
                {
                    "sent": "What we have focused on is more of just the international sector and already that even there the problem is really complex.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we've developed a system called Irish.",
                    "label": 0
                },
                {
                    "sent": "Witcher?",
                    "label": 0
                },
                {
                    "sent": "Is an interface here, so it was delivered to the air marshals in the spring of 2009 and since October of 2009 it's been in use to schedule air marshals on international flights, so some of you may have flown US air carriers from the United States to here.",
                    "label": 0
                },
                {
                    "sent": "You know you may weather or not.",
                    "label": 0
                },
                {
                    "sent": "There was an Air Marshall on that flight may have been determined by the system.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Another thing that another application we've worked on is something called Protect.",
                    "label": 0
                },
                {
                    "sent": "Now you can see that we've spent enormous amounts of precious research time coming up with all these acronyms.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is really a lot of very important problems.",
                    "label": 0
                },
                {
                    "sent": "Scientific challenges that were solved.",
                    "label": 0
                },
                {
                    "sent": "So look how much time it took to come up with such a big acronym here.",
                    "label": 0
                },
                {
                    "sent": "So protect is for randomizing patrols for the Coast Guard for the of US Coast Guard, it's diploid in Boston right now it's being tested.",
                    "label": 0
                },
                {
                    "sent": "Given the success in Boston, the next stop here is to go to New York to Randomize Coast Guard operations for boats and helicopters, and so forth in New York and if that goes OK and then expand to other port.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Guards is again you can see the acronym there under evaluation for national deployment by the Transportation Security Administration, so.",
                    "label": 0
                },
                {
                    "sent": "You know the TSA is involved with the.",
                    "label": 0
                },
                {
                    "sent": "Of course.",
                    "label": 0
                },
                {
                    "sent": "Many of us know about the TSA and checking passengers daily at US airports and so forth, so we're not involved with that at all.",
                    "label": 0
                },
                {
                    "sent": "What we are involved with this?",
                    "label": 0
                },
                {
                    "sent": "The activities that they do in the background for perfecting the airport and this is to do infrastructure protection, patrols and so forth.",
                    "label": 0
                },
                {
                    "sent": "Guard is a system under evaluation.",
                    "label": 0
                },
                {
                    "sent": "The basic idea here is you have some number of security officers.",
                    "label": 0
                },
                {
                    "sent": "You have a large number of operations.",
                    "label": 0
                },
                {
                    "sent": "The check for security throughout the airport so people aren't going off on the runways or whatever, and we want to allocate these officers time to these different activities throughout the day.",
                    "label": 0
                },
                {
                    "sent": "In a randomized fashion.",
                    "label": 0
                },
                {
                    "sent": "If this works, the goal here would be to to apply to all of the 4 / 400 airports in the United States, and again the problem has been cast in terms of a Stackelberg game.",
                    "label": 0
                },
                {
                    "sent": "It's been delivered.",
                    "label": 0
                },
                {
                    "sent": "The system is being tested at an airport, so we had written this paper and we had mentioned the name of the airport paper came back with the name of the airport scratched, so the message we took away is that we're not supposed to say where exactly the system is deployed, so I will not say that, but it is actually deployed.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This that potential applix.",
                    "label": 0
                },
                {
                    "sent": "So those are applications that are diploid or in transition, but there are potential applications worldwide.",
                    "label": 0
                },
                {
                    "sent": "I grew up in the city of Mumbai which unfortunately continues to be a target of terror attacks repeatedly.",
                    "label": 0
                },
                {
                    "sent": "Even today, as you may have seen in the news, there were attacks in Mumbai in 2008.",
                    "label": 0
                },
                {
                    "sent": "Of course, there's these attacks.",
                    "label": 0
                },
                {
                    "sent": "For example, this hotel on fire not too far away from where I grew up anyway.",
                    "label": 0
                },
                {
                    "sent": "In response to these police set of randomized checkpoints in the city.",
                    "label": 0
                },
                {
                    "sent": "So in one of my summer trips there are walking along the oceanfront in police, van pulled up and they put up these checkpoints.",
                    "label": 0
                },
                {
                    "sent": "This checkpoint and so forth.",
                    "label": 0
                },
                {
                    "sent": "And I I I certainly yes, this is randomized checkpoints in the city I can.",
                    "label": 0
                },
                {
                    "sent": "Tell you how to set up randomized check once.",
                    "label": 0
                },
                {
                    "sent": "I'm sort of trying to go towards the police trying to tell them you know what I could do for them and so on and so forth.",
                    "label": 0
                },
                {
                    "sent": "And I realize this is really a bad, bad idea because this is a surveillance of their activities and so on.",
                    "label": 0
                },
                {
                    "sent": "So I moved away from there, but later on I did get an audience with the larger room of officer.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And so the question they posed for us is this.",
                    "label": 0
                },
                {
                    "sent": "Supposing we knew that the attackers are coming in from the sea and we want to set up checkpoints in the city, where would we set it up?",
                    "label": 0
                },
                {
                    "sent": "We can cause this problem as a Stackelberg game now, but in this case it's on a graph where there are these entry points, their targets in the city, and we cannot.",
                    "label": 0
                },
                {
                    "sent": "We have to put up randomized checkpoints, because again, there can be surveillance, and therefore you want to, and you don't have enough resources to protect the whole set of targets exactly.",
                    "label": 0
                },
                {
                    "sent": "And so this is a very difficult challenge once you take into account all of the constraints we've done.",
                    "label": 0
                },
                {
                    "sent": "So we've made some progress.",
                    "label": 0
                },
                {
                    "sent": "But solving this problem exactly for the whole city of Mumbai is a real is a real big open challenge.",
                    "label": 0
                },
                {
                    "sent": "You can solve it for we can solve it only for a small part of Southern Mumbai.",
                    "label": 0
                },
                {
                    "sent": "It's just not enough.",
                    "label": 0
                },
                {
                    "sent": "But if you solve this.",
                    "label": 0
                },
                {
                    "sent": "Police in Mumbai can use this.",
                    "label": 0
                },
                {
                    "sent": "Use your ID.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But there are many many applications beyond just counterterrorism.",
                    "label": 0
                },
                {
                    "sent": "For example, the Los Angeles Sheriff's Department is interested in saying, well, how can you use this game theoretic approaches for not only counterterrorism, but crime suppression, in even for checking for ticketless travelers in the city in on the on the train system.",
                    "label": 0
                },
                {
                    "sent": "So lost in Los Angeles, there isn't a barrier system, so.",
                    "label": 0
                },
                {
                    "sent": "People can just get on the train if they want to.",
                    "label": 0
                },
                {
                    "sent": "And so the question then is the police set up police to randomize checks, and so the question is where and when should they do these checks?",
                    "label": 0
                },
                {
                    "sent": "But there are others, Customs and Border protection to check for drug interdiction for illegal stopping illegal migration if we are in some countries when USA, it or other types of aid flows in health supplies go to different corners of the country, but they get pilfered along the way.",
                    "label": 0
                },
                {
                    "sent": "People who may steal these supplies along the way.",
                    "label": 0
                },
                {
                    "sent": "Again, you can do randomized checking to stop the theft of these supplies.",
                    "label": 0
                },
                {
                    "sent": "Pollution checks cyber security robot patrolling lots and lots of different applications that can all work on the same idea of randomized checking using a game theoretic approach, and in particular this notion of Bayesian stacker.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Games.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The question we come to is how do we assign limited resources to defend these targets?",
                    "label": 0
                },
                {
                    "sent": "An approach we've taken is a game theoretic approach.",
                    "label": 0
                },
                {
                    "sent": "A Bayesian Stackelberg games approach, and the main point I want to emphasize here is that we are not claiming that we've solved this problem.",
                    "label": 0
                },
                {
                    "sent": "There are many, many interesting research challenges here, but we've certainly made an improvement over what was being done there before in terms of people doing things by hand or other techniques that were used before these tech.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Replied there's a number of publications.",
                    "label": 0
                },
                {
                    "sent": "If you wanted to follow up on this work at.",
                    "label": 0
                },
                {
                    "sent": "In terms of major venues at Arm's AAA each guy.",
                    "label": 0
                },
                {
                    "sent": "Major AI Journal articles, and there's a book coming out security and game theory this fall, and this is the this is a website you can go to to get more publications and so on.",
                    "label": 0
                },
                {
                    "sent": "At this point I'll hand over to Chris, who will go into the basics of theoretical.",
                    "label": 0
                },
                {
                    "sent": "Change the microphone.",
                    "label": 0
                },
                {
                    "sent": "OK, can everyone hear me in the back for good?",
                    "label": 0
                },
                {
                    "sent": "OK, thank you very much.",
                    "label": 0
                },
                {
                    "sent": "One for the wonderful introduction.",
                    "label": 0
                },
                {
                    "sent": "So now I hope you're all very motivated to learn about the details of these security games and the algorithms that we've developed.",
                    "label": 0
                },
                {
                    "sent": "To solve these kinds of games.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So over the next 50 minutes or so, I'm going to start by talking about some of the background and basic models and how we frame these security situations within a game theoretic context.",
                    "label": 0
                },
                {
                    "sent": "And then I'm going to talk about two directions that we've pushed in terms of algorithm development.",
                    "label": 0
                },
                {
                    "sent": "The first is scaling to complex, very large action spaces.",
                    "label": 0
                },
                {
                    "sent": "And then we'll start talking about how we handle various kinds of uncertainty.",
                    "label": 0
                },
                {
                    "sent": "I'll start by talking about how we handle payoff uncertainty, and then turn it over to Mullins to talk about how we handle uncertainty about human behavior and other aspects of these games.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So basic security game.",
                    "label": 0
                },
                {
                    "sent": "Please get more complicated in different kinds of ways.",
                    "label": 0
                },
                {
                    "sent": "Most of the games that we talking bout have this sort of underlying dynamic, so we have two players, a defender and attacker.",
                    "label": 0
                },
                {
                    "sent": "And there's a set of targets the attacker is trying to attack some target within this set of targets, and the defender has some resources that they can allocate to try to defend this set of targets against attacks.",
                    "label": 0
                },
                {
                    "sent": "The pay offs are going to define a reward or penalty for each of the two players.",
                    "label": 0
                },
                {
                    "sent": "And we distinguish between the case of a successful or unsuccessful attack.",
                    "label": 0
                },
                {
                    "sent": "So if the attacker chooses to attack a target that's defended, their unsuccessful, and if the target is undefended, then we say that they're successful.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "One issue that often comes up is whether or not security games should always be modeled as zero.",
                    "label": 0
                },
                {
                    "sent": "Sum games and the answer, at least in the kinds of applications we worked on working on, is often no.",
                    "label": 0
                },
                {
                    "sent": "So it turns out that these.",
                    "label": 0
                },
                {
                    "sent": "There's a lot that goes into evaluating potential attacks on targets, including things like potential casualties, the economic costs of attacking a particular target, and the symbolic value of targets, and what we've learned from talking with domain experts is that.",
                    "label": 0
                },
                {
                    "sent": "So the defenders and the attackers may not weigh these different elements of the outcomes in the same way, right?",
                    "label": 0
                },
                {
                    "sent": "So the attackers may care more about, for example, the symbolic value, whereas the defenders care more about the loss of life or casualties.",
                    "label": 0
                },
                {
                    "sent": "So in a lot of our algorithms we make it weaker assumption.",
                    "label": 0
                },
                {
                    "sent": "Then the zero sum assumption, which is that the payos are sort of moving in the same direction, but not necessarily with the same magnitude.",
                    "label": 0
                },
                {
                    "sent": "So in particular.",
                    "label": 0
                },
                {
                    "sent": "For a particular target.",
                    "label": 0
                },
                {
                    "sent": "If that target is attacked, we say that.",
                    "label": 0
                },
                {
                    "sent": "The payoff has to be better for the defender if that target is defended as opposed to if it's undefended and vice versa for the attacker, so attackers prefer to attack undefended targets versus dependent targets.",
                    "label": 0
                },
                {
                    "sent": "An defenders prefer the opposite.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So let's look at an example of a very simple security game.",
                    "label": 0
                },
                {
                    "sent": "Here we have two players.",
                    "label": 0
                },
                {
                    "sent": "We have the police.",
                    "label": 0
                },
                {
                    "sent": "And an attacker and the police are going to make a decision here between deploying the resource.",
                    "label": 1
                },
                {
                    "sent": "They only have one resource in this example, and they're going to play that resource to either target one or Target 2.",
                    "label": 0
                },
                {
                    "sent": "While the attacker is making a decision to attack either target one or target too.",
                    "label": 1
                },
                {
                    "sent": "Those of you that are familiar with game theory will probably recognize this as a simple normal form game.",
                    "label": 0
                },
                {
                    "sent": "It's two players, two actions.",
                    "label": 0
                },
                {
                    "sent": "And we can fill in the pay offs into this game matrix.",
                    "label": 0
                },
                {
                    "sent": "So over here if if the defender chooses to defend target one and the attacker chooses to attack target one, the defender gets a higher pay off, so they get a path of 1 and the attacker gets loses and gets a path of negative one.",
                    "label": 0
                },
                {
                    "sent": "We fill in the past with the rest of the targets.",
                    "label": 0
                },
                {
                    "sent": "So in this example we have Target 2 seems to be a little bit more important because we have larger magnitude pay offs for that target.",
                    "label": 0
                },
                {
                    "sent": "But this is not a 0 sum game, so here we have a value of two for the defender and a value of only negative one for the attacker.",
                    "label": 1
                },
                {
                    "sent": "So now that we have a representation of this conflict between the defender in the attacker, we can apply our standard game theoretic tool set to try to analyze.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This game, so in particular we can look at things like best response.",
                    "label": 0
                },
                {
                    "sent": "So we can say if the defender chooses to defend target one, what is the attacker's best response?",
                    "label": 0
                },
                {
                    "sent": "So to do that, we just need to compare the two possible strategies for the attacker here, so the attacker can get either negative one by attacking target one or two by tacking tar.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Two so of course the best response is for the attacker to choose Target 2.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Similarly, we can do the same kind of analysis at the defenders, choosing to defend Target 2, and in that case the attacker prefers to attack Target 1.",
                    "label": 1
                },
                {
                    "sent": "Now is Montauk to lot about.",
                    "label": 0
                },
                {
                    "sent": "What we're really interested here is in.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Randomize strategies, so if we look at the class of mixed strategies or probability distributions over pure strategies for the defender.",
                    "label": 0
                },
                {
                    "sent": "And let's start with a very simple one.",
                    "label": 0
                },
                {
                    "sent": "So if the defender just flips the coin and says half of that, I'm going to target 1/2 of the time.",
                    "label": 0
                },
                {
                    "sent": "Go to Target 2 and we can look at what the outcomes are.",
                    "label": 1
                },
                {
                    "sent": "So if the attacker chose to attack Target 1/2 the time you get a half of 1 and half of the time you get a path of negative one.",
                    "label": 0
                },
                {
                    "sent": "That's an expected payoff of 0.",
                    "label": 0
                },
                {
                    "sent": "An if the attacker chooses to attack target 1/2 of the time, you get negative two half the time you get 2.",
                    "label": 0
                },
                {
                    "sent": "So again you have an expected path of zero and one of the things to notice is that it's better for the defender than either of the two peer strategy pay offs which were negative one and negative 2.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So if we extend these ideas of taking mixed strategies and best responses, we can arrive at the most famous solution concept in game theory, which is that a Nash equilibrium.",
                    "label": 0
                },
                {
                    "sent": "So a Nash equilibrium profile for this game is going to be a pair of mixed strategies for the attacker and the defender such that both players are playing a best response to the other player strategy.",
                    "label": 0
                },
                {
                    "sent": "So that solution has the property that neither player can improve their payoff by changing to a different strategy, given what the other player is doing.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "If we compute the Nash equilibrium for this game, we get a somewhat intuitive result.",
                    "label": 0
                },
                {
                    "sent": "Here the defender should should defend target 260% of the time in target 140% of the time, so they're more frequently patrolling that more important target.",
                    "label": 0
                },
                {
                    "sent": "And Meanwhile the attacker is choosing 67% of the time to attack the less valuable target target one and 33% of the time to attack Target 2, which is the more valuable target.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now, for security games we often use a variation of Nash equilibrium that allows us to model the surveillance that hackers can do before launching an attack.",
                    "label": 0
                },
                {
                    "sent": "So is Melinda mentioned in a lot of the real world domains, we know that attackers are very.",
                    "label": 0
                },
                {
                    "sent": "They spend a lot of time and a lot of effort trying to plan attacks, particularly against valuable targets such as LAX.",
                    "label": 0
                },
                {
                    "sent": "Or an international flight.",
                    "label": 0
                },
                {
                    "sent": "In the case of the air marshals.",
                    "label": 0
                },
                {
                    "sent": "So we want to capture that in our game model and the way that we do this is by using Stackelberg games.",
                    "label": 0
                },
                {
                    "sent": "So in the Stackelberg game model, the defender has to has to move first, they have to commit to a mix strategy particular security policy.",
                    "label": 0
                },
                {
                    "sent": "And then the attacker is able to observe that policy by, for example, gathering insider information, sending somebody through, sending somebody to the LAX airport for six months to try to figure out you know what is the distribution over where the checkpoints are placed in the airport.",
                    "label": 0
                },
                {
                    "sent": "That sort of thing.",
                    "label": 0
                },
                {
                    "sent": "So Defender chooses a mix strategy and the attacker gets to choose an exact optimal response to that strategy.",
                    "label": 0
                },
                {
                    "sent": "So for this kind of stockel board game, the solution concept is a strong Stackelberg equilibrium.",
                    "label": 0
                },
                {
                    "sent": "Which is an optimal strategy for the defender under the assumption that the attacker is going to choose an optimal response to that strategy.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So there's a paper actually before all this work on security games got started in 2006 by conference and home that laid out an algorithm for solving this for solving Stackelberg games in general.",
                    "label": 0
                },
                {
                    "sent": "I.",
                    "label": 0
                },
                {
                    "sent": "So it's pretty.",
                    "label": 0
                },
                {
                    "sent": "It's framed in terms of a mixed integer program here, and I'm not going to go through all the details of the notation, But basically this is so.",
                    "label": 0
                },
                {
                    "sent": "This entire linear program is finding the optimal value for the defender, assuming that an attacker chooses a particular response action.",
                    "label": 0
                },
                {
                    "sent": "So, given that our linear program says that we're maximizing the expected path for the defender.",
                    "label": 0
                },
                {
                    "sent": "This line gives a constraint that.",
                    "label": 0
                },
                {
                    "sent": "The action we've chosen for the attacker has to be optimal, so.",
                    "label": 0
                },
                {
                    "sent": "The payoff for that particular action is greater than or equal to the payoff for any other possible action the attacker could take an these last two constraints are just.",
                    "label": 0
                },
                {
                    "sent": "Clarifying the constraints on the defender has to choose a legal probability distribution.",
                    "label": 0
                },
                {
                    "sent": "Over their possible actions.",
                    "label": 0
                },
                {
                    "sent": "So if we solve.",
                    "label": 0
                },
                {
                    "sent": "One of these linear programs for every possible action.",
                    "label": 0
                },
                {
                    "sent": "Of the attacker.",
                    "label": 0
                },
                {
                    "sent": "And take the maximum over the values that are returned.",
                    "label": 0
                },
                {
                    "sent": "That gives us the optimal solution to the game.",
                    "label": 0
                },
                {
                    "sent": "So we're solving.",
                    "label": 0
                },
                {
                    "sent": "That's why this is called a multi linear programming formulation.",
                    "label": 0
                },
                {
                    "sent": "Because we're solving a number of different linear programs and then taking the maximum over.",
                    "label": 0
                },
                {
                    "sent": "The strategies for those.",
                    "label": 0
                },
                {
                    "sent": "So many of the algorithms that we'll see going forward have this sort of integer programming style approach under.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Item.",
                    "label": 0
                },
                {
                    "sent": "So the algorithms that we've been developing over the last five or six years to handle large, complex security games focus on a number of different research challenges.",
                    "label": 0
                },
                {
                    "sent": "The first set of research challenges are related to the problem of having very large, complex action spaces.",
                    "label": 0
                },
                {
                    "sent": "And these action spaces can be complicated, either because there's a very large number of defender actions.",
                    "label": 0
                },
                {
                    "sent": "In the case of the air marshals, we have many, many possible air marshals, and we have complex constraints about how these air marshals can be scheduled, so that leads to a very large possible action space for the defenders.",
                    "label": 0
                },
                {
                    "sent": "And in the case of Dubai example that will mention briefly we have a lot of possible strategies for the attackers because attack actions in that case are modeled as possible path through graph.",
                    "label": 0
                },
                {
                    "sent": "I'll talk more about the different challenges than certainty when we get to that part of the talk, but there's also a lot of different kinds of uncertainty that we can have in these games that also makes them very complex and challenging.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Solve.",
                    "label": 0
                },
                {
                    "sent": "So this is a slide that gives a subset of the algorithms that we've developed over the last six years an I ran out of room on the slide so I couldn't put all of the algorithms that we've developed, but you can see that there's a lot of different algorithms for different domains that scale well in different dimensions, whether they handle very large numbers of defender actions, very large numbers of attacker actions, different kinds of payoff structures, uncertainty over payoff structures.",
                    "label": 1
                },
                {
                    "sent": "And different kinds of scheduling constraints.",
                    "label": 0
                },
                {
                    "sent": "So the schedule constraints particularly relevant to things like the air Marshals domain and as mentioned, we've had a lot of graduate students put a lot of effort into coming up with nice acronyms for these games.",
                    "label": 0
                },
                {
                    "sent": "Are for these solution algorithms.",
                    "label": 0
                },
                {
                    "sent": "But to try to avoid some of the confusion of having to keep track of all these different names during the talk, we're actually going to refer to most of them by the applications.",
                    "label": 0
                },
                {
                    "sent": "For example, armor Iris 123 and four.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "The problem of scaling to complex action spaces became very clear when we first started looking at the federal air Marshals domain after.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We had already solved the develop the armor system for the LAX airport.",
                    "label": 0
                },
                {
                    "sent": "So the game matrices that were being solved for the LX Airport were on the order of a few 100 actions for each player.",
                    "label": 0
                },
                {
                    "sent": "And when we.",
                    "label": 0
                },
                {
                    "sent": "Took exactly the same approach and tried to formulate a game matrix for the air marshals problem we ended up with millions of possible strategies for the defenders and thousands of possible strategies for the attackers.",
                    "label": 0
                },
                {
                    "sent": "And in fact, example with only 100 flight flights, antenn air marshals and remember the real problem is 30,000 flights.",
                    "label": 0
                },
                {
                    "sent": "An 3000 air marshals.",
                    "label": 0
                },
                {
                    "sent": "I just generated 1.7 * 10 to 13 possible actions for the defender in the sort of naive representation.",
                    "label": 0
                },
                {
                    "sent": "So just applying the same algorithms have been used for armor, there was no hope of solving this.",
                    "label": 0
                },
                {
                    "sent": "We could solve up to about 20 flights, but then after that point we ran out of memory entirely.",
                    "label": 0
                },
                {
                    "sent": "So we've developed a couple of different approaches actually for handling games with such large and complex defender strategy spaces.",
                    "label": 0
                },
                {
                    "sent": "I need to go through each of these briefly, but both of them rely on not enumerating the entire space of possible strategies, so we have to reason either over a more compact representation of this space, or a restricted part of the strategy space.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the first idea.",
                    "label": 0
                },
                {
                    "sent": "Was to reason over what we call marginals instead of the full joint probabilities, so.",
                    "label": 0
                },
                {
                    "sent": "This example appear.",
                    "label": 0
                },
                {
                    "sent": "Gives us a problem with where we have 10 possible tours for air marshals and three air marshals, so the raw strategy space here would be possible.",
                    "label": 0
                },
                {
                    "sent": "Combinations of these tours so we send Air Marshall one flight Flight 2 or one Air Marshall 2IN Flight 2 or 2 three and so on.",
                    "label": 0
                },
                {
                    "sent": "So it turns out there's 120 possible combinations here and in the representation of the strategy space we would have to have a probability for each of these possible combinations of tours.",
                    "label": 0
                },
                {
                    "sent": "So, given that we could use a integer programming formulation similar to the one I showed you before, But the problem is that the number of variables is is exponential in the number of.",
                    "label": 0
                },
                {
                    "sent": "In the number of air marshals that you have.",
                    "label": 0
                },
                {
                    "sent": "So this integer program does not scale very well at all.",
                    "label": 0
                },
                {
                    "sent": "We looked at the actual payoff matrices that were generated by this process and we noticed.",
                    "label": 0
                },
                {
                    "sent": "There seems to be an awful lot of repetition in the payoff, so this strongly suggests that there is some sort of structure here that we can exploit in actually coming up with the.",
                    "label": 0
                },
                {
                    "sent": "A better, more scalable solution approach an we came up with the representation.",
                    "label": 0
                },
                {
                    "sent": "Which allows us to reason just over with all the marginal probabilities on the targets.",
                    "label": 0
                },
                {
                    "sent": "So that is the probability that there's going to be some Air Marshall on each of the possible flights.",
                    "label": 0
                },
                {
                    "sent": "That reduces this size of the strategy space dramatically, so in this case we have 10 variables instead of 120 variables that we need to represent the defender strategy space.",
                    "label": 0
                },
                {
                    "sent": "I.",
                    "label": 0
                },
                {
                    "sent": "Now one of the the complexities here is that we're actually not generating an explicit schedule for the defender to follow, but instead were saying you need to have some Air Marshall on each of these flights with this probability.",
                    "label": 0
                },
                {
                    "sent": "So afterwards we have to do a post processing step to find what the actual strategy is for the defenders, and it turns out that that's only possible if we have very simple tours.",
                    "label": 0
                },
                {
                    "sent": "So if we have tours of restricted size, in this case up to size 2.",
                    "label": 0
                },
                {
                    "sent": "So the other approach is I'm going to show you in a moment, works for arbitrarily large and arbitrarily complex scheduling constraints.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "But this approach of reasoning just over the marginals works for relatively simple scheduling constraints.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Given that approach, we can come up with another linear programming formulation, and so these are starting to get more and more complicated.",
                    "label": 0
                },
                {
                    "sent": "I'm not going to go into.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Details of that.",
                    "label": 0
                },
                {
                    "sent": "I do want to talk talk you through an algorithm we have for the simplest possible case because I think this actually gives some nice intuition for what these solutions actually look like.",
                    "label": 0
                },
                {
                    "sent": "This is a very fast polynomial time algorithm.",
                    "label": 0
                },
                {
                    "sent": "It works for a very restricted case where every resource or every air Marshall, for example that you have is exactly identical.",
                    "label": 0
                },
                {
                    "sent": "They can cover exactly 1 target.",
                    "label": 0
                },
                {
                    "sent": "Ann any any of your resources can cover any of the possible targets.",
                    "label": 0
                },
                {
                    "sent": "In addition, we have the payoff assumption that the payoff have to be moving in sort of the opposite direction, so they don't have to be exactly 07.",
                    "label": 0
                },
                {
                    "sent": "So this is an example where we have 4 air marshals or four flights and we're going to allocate one Air Marshall to cover these four flights.",
                    "label": 0
                },
                {
                    "sent": "The attackers paths are shown in this table over here, so if the flight is uncovered, the attacker gets a path of four for attacking the first Flight, 3 for attacking the 2nd two.",
                    "label": 0
                },
                {
                    "sent": "In one, we're going to keep things simple and say if any of these flights is covered, the attacker always gets a payoff of 0.",
                    "label": 0
                },
                {
                    "sent": "And just for your intuition, you can assume that the path for this or 0 sum, so the defender is getting exactly the opposite path that the attacker is getting.",
                    "label": 0
                },
                {
                    "sent": "So these bars here represent the attackers expected payoff for attacking each of the four targets.",
                    "label": 0
                },
                {
                    "sent": "Given this, this defender coverage strategy.",
                    "label": 0
                },
                {
                    "sent": "So right now we have all zero, so the defender is covering each of these targets with zero percent probability.",
                    "label": 0
                },
                {
                    "sent": "And the attacker is getting the exact uncovered paths that we have here.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I.",
                    "label": 0
                },
                {
                    "sent": "We can define a very useful notion called the attack set, which is going to be the set of targets that the attacker is willing to attack.",
                    "label": 0
                },
                {
                    "sent": "So the attacker is getting the maximum expected payoff for attacking some set of targets an right now there's exactly 1 target in that set, which is the target here that has the highest bar.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So our first observation is that it can never be optimal or never benefits the defender to add additional coverage to something that's outside of the attack set.",
                    "label": 0
                },
                {
                    "sent": "The attacker is always going to take something within that attack set, because it's the best response, right?",
                    "label": 1
                },
                {
                    "sent": "And remember our equilibrium solution concept says that the attacker has to choose the best response strategy.",
                    "label": 0
                },
                {
                    "sent": "So this tells us something immediately about where we have to assign the first bit of coverage probability here.",
                    "label": 0
                },
                {
                    "sent": "So we need to assign coverage to this target that has the highest set.",
                    "label": 0
                },
                {
                    "sent": "And we need to keep doing that until the expected payoff is equal to the next highest expected payoff.",
                    "label": 0
                },
                {
                    "sent": "For the attacker.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And simply by doing a little bit of algebra, we can compute exactly what the right coverage is necessary for those two to be equal is and.",
                    "label": 0
                },
                {
                    "sent": "So now we have two targets in our tax set.",
                    "label": 0
                },
                {
                    "sent": "We have two targets and the Packers win 22.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Our second observation is that.",
                    "label": 0
                },
                {
                    "sent": "It never benefits the defender to add coverage to just one of those targets in the attack set.",
                    "label": 0
                },
                {
                    "sent": "The reason is that as soon as you start adding coverage to one of the targets, it's no longer in the attack set because the attacker is worse off attacking that then the other targets in the attack set.",
                    "label": 0
                },
                {
                    "sent": "So what we really need is to is to sort of add coverage to these two targets in such a way that the attacker is expected payoff moves down by the exact same amount.",
                    "label": 0
                },
                {
                    "sent": "It sort of moves down in lockstep until it reaches this third target over here.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And again, doing a little bit of algebra with the payoff so we can, we can compute the coverage probabilities that are required for the pass through the attacker.",
                    "label": 0
                },
                {
                    "sent": "For these first 2 targets to equal the path to the third target.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now if we try to do that for the 4th target.",
                    "label": 0
                },
                {
                    "sent": "We come up with with the problem because now we need we need more coverage probability that we actually have.",
                    "label": 1
                },
                {
                    "sent": "We only have one Air Marshall, so we can't allocate that Air Marshall 75% of the time.",
                    "label": 0
                },
                {
                    "sent": "This target 66% of the time to this target etc.",
                    "label": 0
                },
                {
                    "sent": "So what that tells us is that.",
                    "label": 0
                },
                {
                    "sent": "In the optimal solution, the attacker is never going to be.",
                    "label": 0
                },
                {
                    "sent": "It's never going to be the best strategy for the attacker to take this.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Target.",
                    "label": 0
                },
                {
                    "sent": "If we go back one step though, we still have some additional coverage that we can assign and we want to assign it to these three targets in such a way that the we've assigned all of this probability in the optimal way.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And again, I'm not going to show you the equations, but there's just by doing a little bit of algebra we can come up with the right ratios to add that coverage probability, and so all those bars move down at the same rate.",
                    "label": 0
                },
                {
                    "sent": "And that gives us what is the optimal coverage strategy for the defender in this case?",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "As we've been pushing forward on developing the next generations of that system, we've had to develop approaches that were able to handle more complex scheduling constraints.",
                    "label": 0
                },
                {
                    "sent": "Then we could handle with the original approach, or just reasoning over the marginals.",
                    "label": 0
                },
                {
                    "sent": "So we've started to explore a different kind of solution called branch and price.",
                    "label": 0
                },
                {
                    "sent": "This is an approach that comes to us.",
                    "label": 0
                },
                {
                    "sent": "From the operations research community and its approach that's used to solve very very large integer programming problems.",
                    "label": 0
                },
                {
                    "sent": "It works by using a combination of branch and bound search over integer variables.",
                    "label": 0
                },
                {
                    "sent": "An column generation which I'll describe to you in a moment.",
                    "label": 0
                },
                {
                    "sent": "First, most of you are probably familiar with basic branch inbound solution methods.",
                    "label": 0
                },
                {
                    "sent": "This is a branch of boundary for our problem.",
                    "label": 0
                },
                {
                    "sent": "The orange nodes here represent problems where we have restricted where we've selected a particular target for the attacker to attack, so this is the attackers choosing to attack Target 1.",
                    "label": 0
                },
                {
                    "sent": "Packers choosing to attack Target 2 all the way up to N. And if we solve each of those nodes, that gives us a lower bound on the defenders optimal payoff.",
                    "label": 0
                },
                {
                    "sent": "The entire problem space.",
                    "label": 0
                },
                {
                    "sent": "The blue nodes up here represent nodes where the attacker so.",
                    "label": 0
                },
                {
                    "sent": "This blue note is where the attacker can choose any target at all.",
                    "label": 0
                },
                {
                    "sent": "This blue node is where the attacker could choose any target other than target one, etc.",
                    "label": 0
                },
                {
                    "sent": "So it turns out that we can compute upper bounds for these blue nodes using one of those two algorithms that I showed you before, so we can relax the scheduling constraints of the actual problem and we can solve it using that simplest version of the problem.",
                    "label": 0
                },
                {
                    "sent": "It runs very fast in polynomial time, and that this is a very fast way to compute upper bounds for these blue nodes.",
                    "label": 0
                },
                {
                    "sent": "For the.",
                    "label": 0
                },
                {
                    "sent": "Orange or red nodes?",
                    "label": 0
                },
                {
                    "sent": "I can't quite tell what color that is on this projector, but for the orange nodes we have to use this approach called column Jenner.",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And I'm going to give you a very, very brief overview of column generation.",
                    "label": 0
                },
                {
                    "sent": "The problem is that.",
                    "label": 0
                },
                {
                    "sent": "These orange nodes are actually very very large, so these orange nodes in the natural representation have that exponential strategy space for the defender.",
                    "label": 0
                },
                {
                    "sent": "The COM generation approach works a bit differently than the approach of reasoning for marginal zone that reasons over.",
                    "label": 0
                },
                {
                    "sent": "A subset or a small set of support for the strategy space.",
                    "label": 0
                },
                {
                    "sent": "So we start by defining a master problem, which is going to be solved for a restricted, very restricted set of the possible strategies for the defender.",
                    "label": 0
                },
                {
                    "sent": "Then we find the optimal strategies for that set of possible strategies.",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And then we solve what's called the slave problem.",
                    "label": 0
                },
                {
                    "sent": "So the slave problem is basically going to generate additional strategies to add to our master problem.",
                    "label": 1
                },
                {
                    "sent": "Une scheduled mental break.",
                    "label": 0
                },
                {
                    "sent": "Now we've had a moment to process everything that we've gone through so far, so I will.",
                    "label": 0
                },
                {
                    "sent": "So remember, so we're using a branch inbound approach over these.",
                    "label": 0
                },
                {
                    "sent": "But the integer variables in our formulation, which are specifying which targets are being attacked.",
                    "label": 0
                },
                {
                    "sent": "And I was talking about how we use the column generation approach to solve these very large linear programs in each of the lower bound nodes.",
                    "label": 0
                },
                {
                    "sent": "So we're starting with the master problem, which is solving the problem over restricted number of the possible joint strategies for the defender.",
                    "label": 0
                },
                {
                    "sent": "And once we've solved that for the restricted problem, we solve the slave problem and the slave problem basically answers to questions for us.",
                    "label": 0
                },
                {
                    "sent": "The first is, can we improve the defenders payoff in their stricted problem by adding some some additional strategy from the defender space into that restricted problem, and if so, which is the best one to add to that restricted problem?",
                    "label": 0
                },
                {
                    "sent": "So we came up with a minimum cost network flow representation which will answer both of those two questions using the paradigm of reducing or minimizing the reduced costs.",
                    "label": 1
                },
                {
                    "sent": "This is a standard technique in linear programming.",
                    "label": 0
                },
                {
                    "sent": "I given this we solve this network flow formulation that returns the next strategy to add to our master problem.",
                    "label": 0
                },
                {
                    "sent": "We solve that problem.",
                    "label": 0
                },
                {
                    "sent": "It gives us the next gratitude.",
                    "label": 0
                },
                {
                    "sent": "We do this iteratively until that first condition holds and we know that we can't improve the solution anymore by adding anymore of the defender strategies into the reduced the restricted problem.",
                    "label": 0
                },
                {
                    "sent": "Basically what this is exploiting is the fact that we can get optimal solutions that have a very small support in the space of the defender strategies.",
                    "label": 1
                },
                {
                    "sent": "So even though there may be millions or 10s of millions or trillions of strategies for defender, we can find an optimal strategy.",
                    "label": 0
                },
                {
                    "sent": "With support or positive probabilities for maybe 10 or 100 of those possible pure strategies.",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Again, we have some some runtime results here.",
                    "label": 0
                },
                {
                    "sent": "It turns out that the algorithm for the arbitrary scheduling case runs roughly as fast as the best algorithm we have for the that uses just the marginals and we can scale up quite well to very large numbers of targets.",
                    "label": 0
                },
                {
                    "sent": "Very complex schedules as well.",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so I want to shift gears now so those those were approaches for dealing with the dealing with the problem of having very large complex defender strategies.",
                    "label": 0
                },
                {
                    "sent": "Defender strategy spaces.",
                    "label": 0
                },
                {
                    "sent": "So I want to talk about modeling different kinds of uncertainty in these games.",
                    "label": 0
                },
                {
                    "sent": "And we're going to start by dealing with the case.",
                    "label": 0
                },
                {
                    "sent": "The payoff uncertainty, which leads us down the road of trying to solve instances of Bayesian Stackelberg games.",
                    "label": 0
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And what we found in these in working in these real world security domains is that there is a lot of different kinds of uncertainty that we have to account for.",
                    "label": 0
                },
                {
                    "sent": "We have uncertainty about the kinds of decision-making processes that the attackers are using.",
                    "label": 0
                },
                {
                    "sent": "We have uncertainty about with the way that the attackers are actually able to observe the defender strategy in the real world.",
                    "label": 0
                },
                {
                    "sent": "We have uncertainty about how the attackers are assessing the possible payoff.",
                    "label": 0
                },
                {
                    "sent": "How much do they value attacking one target versus another target?",
                    "label": 0
                },
                {
                    "sent": "We have uncertainty about what the capabilities of the attackers are.",
                    "label": 0
                },
                {
                    "sent": "What kinds of technologies do they have access to?",
                    "label": 0
                },
                {
                    "sent": "Where are they at?",
                    "label": 0
                },
                {
                    "sent": "Any particular time?",
                    "label": 0
                },
                {
                    "sent": "And we even have uncertainty about how well the defenders will execute.",
                    "label": 0
                },
                {
                    "sent": "The actions that we assigned for them.",
                    "label": 0
                },
                {
                    "sent": "So if we tell the police to go and set up a checkpoint on this particular Rd, but they get called off to do something more important and respond to threats somewhere else in the airport, they may not even execute the strategy exactly as it's been presented to them.",
                    "label": 0
                },
                {
                    "sent": "So all these are topics of ongoing research.",
                    "label": 0
                },
                {
                    "sent": "We're going to present just a few of them to you today.",
                    "label": 0
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So from the very first implementations of the armor system for ELEX, we've been concerned about the issue of not knowing exactly what the attackers pay offs are.",
                    "label": 0
                },
                {
                    "sent": "So for example.",
                    "label": 0
                },
                {
                    "sent": "One issue that came up when we were talking to the experts there was that there might be different kinds of attackers.",
                    "label": 0
                },
                {
                    "sent": "There might be some attackers who were very sophisticated, very highly capable terrorist organizations or other attackers who were local gangs, or maybe disgruntled employees at the airport, and that these attackers might have very different capabilities leading to different pay offs if they were to launch an attack.",
                    "label": 0
                },
                {
                    "sent": "So we can represent that as a Bayesian game where we have.",
                    "label": 0
                },
                {
                    "sent": "Instead of a single payoff matrix, we have here a situation with three different possible attacker types, so we have three different path matrices representing the payoff for those different types, and we also have a probability distribution over these possible attacker types.",
                    "label": 0
                },
                {
                    "sent": "The standard way of solving this using the existing algorithms would be to two.",
                    "label": 0
                },
                {
                    "sent": "We call Harsanyi transformation.",
                    "label": 0
                },
                {
                    "sent": "Basically we take these individual path matrices and we transform them into a larger payoff matrix in which the attackers action space is now an action for each of the possible types.",
                    "label": 0
                },
                {
                    "sent": "So this corresponds to attacker type one choosing action one Type 2, choosing action one Type 3, choosing action one, and we have an action in this game for every possible combination of actions by the attacker types.",
                    "label": 0
                },
                {
                    "sent": "If we were to apply the multiple LP's method to that we could solve this kind of game using this on your transformation.",
                    "label": 0
                },
                {
                    "sent": "But unfortunately we do know that these are NP hard problems, so that approach really does not scale.",
                    "label": 0
                }
            ]
        },
        "clip_55": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Terribly well.",
                    "label": 0
                },
                {
                    "sent": "Add.",
                    "label": 0
                },
                {
                    "sent": "In the original Armor application that developed an algorithm called Dobbs, which was a more efficient integer programming formulation of this that avoids the Harsanyi trans.",
                    "label": 0
                }
            ]
        },
        "clip_56": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Formation the approach of using the Harsanyi transformation an applying multiple peas is basically these two lines and the dog's algorithm that avoids her signing transformation.",
                    "label": 0
                },
                {
                    "sent": "Is these two lines?",
                    "label": 0
                },
                {
                    "sent": "Unfortunately, we have a log scale over here, so this is still even.",
                    "label": 0
                },
                {
                    "sent": "Those lines look linear, they're still scaling exponentially as we increase the number of types.",
                    "label": 0
                },
                {
                    "sent": "But this was at least sufficient for the LAX problem.",
                    "label": 0
                },
                {
                    "sent": "We had relatively small action spaces, and we were interested in a relatively limited set of potential attacker types.",
                    "label": 0
                },
                {
                    "sent": "As I started working on larger and larger versions of these games and became interested in modeling more and more different kinds of attacker types, we were motivated to do more work to try to scale up these solution algorithms for Bayesian games further.",
                    "label": 0
                }
            ]
        },
        "clip_57": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this tree here represents a Bayesian game, each level in the tree.",
                    "label": 0
                },
                {
                    "sent": "Is the action choice for a different kind of attacker type?",
                    "label": 0
                },
                {
                    "sent": "So this is attacker type one choose action, one attacker type, One chooses action two and then the second level.",
                    "label": 0
                },
                {
                    "sent": "Here is the action choice for attacker Type 2.",
                    "label": 0
                },
                {
                    "sent": "This is basically equivalent to this person new transformation and the problem here is that you have an exponential number of these nodes.",
                    "label": 0
                },
                {
                    "sent": "At the bottom of the tree.",
                    "label": 0
                },
                {
                    "sent": "And if we were to do that straightforward approach, just applying the multiple LP's method to this history, basically that means that we have to solve an exponential number of linear programs to actually get a solution.",
                    "label": 0
                },
                {
                    "sent": "But now that we have it in this tree form, we can return to our notion of using branch and bound search to try to improve the speed of these solution methods.",
                    "label": 0
                },
                {
                    "sent": "And if we're able to find some nice bounding rules or efficient search heuristics for operating this space of attacker types, we can potentially speed up the results of the algorithm by having by avoiding a lot of these computations at the at the leaf nodes.",
                    "label": 0
                }
            ]
        },
        "clip_58": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And the idea that we use.",
                    "label": 0
                },
                {
                    "sent": "For this is basically to solve restricted, more simplified versions of these games first, and to use the results of those in.",
                    "label": 0
                },
                {
                    "sent": "Be more general versions of the game.",
                    "label": 0
                },
                {
                    "sent": "So this is another tree.",
                    "label": 0
                },
                {
                    "sent": "Actually, each of these nodes.",
                    "label": 0
                },
                {
                    "sent": "Here is one of those trees that I showed you in the previous slide, so this node represents the full game.",
                    "label": 0
                },
                {
                    "sent": "Here we have a game with four possible attacker types.",
                    "label": 0
                },
                {
                    "sent": "This node is the game restricted to only attacker type one and hacker type 2.",
                    "label": 0
                },
                {
                    "sent": "This note is attacker type 3 attacker Type 4 and these bottom nodes here are attacker type 123 and four.",
                    "label": 0
                },
                {
                    "sent": "So the way that we solve this is we solve first these nodes with only a single attacker type.",
                    "label": 0
                },
                {
                    "sent": "So we assume that the defender knows exactly which of the four attacker types he's facing, and we find an optimal strategy for the defender against each of these types individually.",
                    "label": 0
                },
                {
                    "sent": "We then use the information from that to derive branching and bounding rules for solving these.",
                    "label": 0
                },
                {
                    "sent": "These nodes that are higher in the tree, so we take the solution for type one and Type 2 and we solve Now a larger game that has the attacker or defender facing two attackers of type one or type 2, and we solve this other game and then we propagate the information from those solutions up to the full game.",
                    "label": 0
                },
                {
                    "sent": "I also mentioned that we can actually speed up the solution to these individual nodes using the same sort of column generation approach that we used for scaling.",
                    "label": 0
                },
                {
                    "sent": "Two very large defender strategy spaces.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "Step three and four yes.",
                    "label": 0
                },
                {
                    "sent": "Will the company?",
                    "label": 0
                },
                {
                    "sent": "So the root node here is the node that has all possible combinations.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so solving each of these games is an approximation, but when we actually solve this node at the top, we get the exact solution.",
                    "label": 0
                },
                {
                    "sent": "OK, so we're using approximate solutions in a sense.",
                    "label": 0
                },
                {
                    "sent": "In essence, to guide the search for the exact solution.",
                    "label": 0
                },
                {
                    "sent": "In the root node.",
                    "label": 0
                }
            ]
        },
        "clip_59": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Just to show you the some of the computational results for how that works.",
                    "label": 0
                },
                {
                    "sent": "This is the original method, and this is actually the method believe that.",
                    "label": 0
                },
                {
                    "sent": "That's right, so this is the branch and bound that doesn't do that sort of breakdown and use the results of these simpler.",
                    "label": 0
                },
                {
                    "sent": "Simplified games, the green node here is this full hierarchical method where we solve the individual types 1st and propagate that information up the tree and you can see that up to six types, which is about the largest game that we could solve for the previous methods.",
                    "label": 0
                },
                {
                    "sent": "We're still doing quite well.",
                    "label": 0
                },
                {
                    "sent": "And in fact, using this approach we were able to get up to 50 different attacker types.",
                    "label": 0
                },
                {
                    "sent": "In under an hour and just to give you a sense of how large a game that really is, if we were to break that down into use, the multiple LP's approach that means we would need to solve 8.9 * 10 to the 34 different linear programs.",
                    "label": 0
                },
                {
                    "sent": "So by using the information from the simpler games we're able to prune out an awful lot of the computation from that full game.",
                    "label": 0
                }
            ]
        },
        "clip_60": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the kinds of algorithms I talked to you so far are good for modeling different kinds of distinct attacker types.",
                    "label": 0
                },
                {
                    "sent": "So now I want to give you a quick introduction to a different kind of game that we've looked at.",
                    "label": 0
                },
                {
                    "sent": "That's good for modeling a different kind of payoff uncertainty.",
                    "label": 0
                },
                {
                    "sent": "And the problem here is that in specifying each of these game models, we basically have to fill in the pay offs for each of these different possible combinations of actions.",
                    "label": 0
                },
                {
                    "sent": "So we're doing this based on.",
                    "label": 0
                },
                {
                    "sent": "Essentially, what the experts tell us they're using historical data intelligence information.",
                    "label": 0
                },
                {
                    "sent": "Lots of information of different kinds to try to find out, try to answer these questions about, well, how much would an attacker prefer to attack this target versus this target versus target?",
                    "label": 0
                },
                {
                    "sent": "How much more valuable is this flight than another flight?",
                    "label": 0
                },
                {
                    "sent": "And as we've made reference to before, there's a lot that goes into that, so they might be thinking about what is the likely number of casualties if we do this kind of attack on this particular target, what is the economic cost?",
                    "label": 0
                },
                {
                    "sent": "What is the?",
                    "label": 0
                },
                {
                    "sent": "The symbolic value.",
                    "label": 0
                },
                {
                    "sent": "How do we weight all of these things?",
                    "label": 0
                },
                {
                    "sent": "And the point here is that we don't actually have the exact numbers.",
                    "label": 0
                },
                {
                    "sent": "So there is information available to help us make these judgments, especially relative judgments, right?",
                    "label": 0
                },
                {
                    "sent": "So we can say, well, this flight is much larger than another flight and so forth, but it's very hard to pin these numbers down exactly.",
                    "label": 0
                },
                {
                    "sent": "So we've looked at is a different version of this game where we allow the payoff to be specified using distributions instead of point estimates for the payoff.",
                    "label": 0
                }
            ]
        },
        "clip_61": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here we have for each target in our in all the previous work that we showed you, we would have had a single payoff for a potential attack on the target when it was covered, and intentional attack potential attack on that target windows uncovered.",
                    "label": 0
                },
                {
                    "sent": "So now we've taken that we've replaced that with a distribution over possible pay offs for each of those cases, and we have two of these distributions for each day.",
                    "label": 0
                }
            ]
        },
        "clip_62": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Git.",
                    "label": 0
                },
                {
                    "sent": "So basically what this is is an infinite Bayesian soccer game.",
                    "label": 0
                },
                {
                    "sent": "So now we have an infinite number of possible attacker types and we have a distribution over the infinite space of possible attacker types defined by the distributions over these individual pay offs.",
                    "label": 0
                }
            ]
        },
        "clip_63": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "As we think about solving these infinite Bayesian Stackelberg games, first of all I should say that we're not able to solve them exactly, so we're talking about approximate methods for solving these these games and we can break it down into 2 steps.",
                    "label": 0
                },
                {
                    "sent": "So supposing we had a specific defender strategy that we're interested in evaluating a specific coverage strategy that places a certain amount of coverage on each of the possible targets.",
                    "label": 0
                }
            ]
        },
        "clip_64": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We can ask the question of what is the attacker strategy and what we really care about is what is the probability that the attackers are going to choose to attack each of the possible targets.",
                    "label": 0
                },
                {
                    "sent": "Given the defender strategy and these distributions over the possible playoffs.",
                    "label": 0
                }
            ]
        },
        "clip_65": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So that's question one.",
                    "label": 0
                },
                {
                    "sent": "And then, given that attacker response function.",
                    "label": 0
                },
                {
                    "sent": "We want to be able to search over the space of possible defender strategies to find the optimal strategy for the defender.",
                    "label": 0
                },
                {
                    "sent": "Given the attacker response.",
                    "label": 0
                }
            ]
        },
        "clip_66": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We've looked at a number of different ways to approximate each of these questions.",
                    "label": 0
                },
                {
                    "sent": "So first the attack vector.",
                    "label": 0
                },
                {
                    "sent": "Simplest approach is basically to sample.",
                    "label": 0
                },
                {
                    "sent": "Use Monte Carlo sampling to sample a number of distinct possible attacker types.",
                    "label": 0
                },
                {
                    "sent": "Option two is to do a whole bunch of math to drive very complicated equation, specifying exactly what the attacker probabilities are.",
                    "label": 0
                },
                {
                    "sent": "Unfortunately, don't have closed form solution, so we can only do numerical approximation on that.",
                    "label": 0
                },
                {
                    "sent": "To try to find to try to estimate exactly what the attacker response function is.",
                    "label": 0
                },
                {
                    "sent": "And then we've looked at a number of different ways to try to approximately optimize the defenders strategy.",
                    "label": 0
                },
                {
                    "sent": "Given this attacker computations.",
                    "label": 0
                }
            ]
        },
        "clip_67": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It turns out that in this case, doing all the fancy matthan coming up with the numerical approximations loses quite badly to the simple Monte Carlo approach.",
                    "label": 0
                },
                {
                    "sent": "So this is the.",
                    "label": 0
                },
                {
                    "sent": "Summation error versus runtime an.",
                    "label": 0
                },
                {
                    "sent": "The Monte Carlo sampling approach is giving us very, very accurate solutions much more quickly than the piecewise constant approximation method that we use.",
                    "label": 0
                },
                {
                    "sent": "So most of the remaining work focuses on using the Monte Carlo approximation for the attacker types.",
                    "label": 0
                }
            ]
        },
        "clip_68": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "As I said, we've looked at a number of different possible ways to approximate the defender strategy.",
                    "label": 0
                },
                {
                    "sent": "I will point out two baseline measures that we used to test against.",
                    "label": 0
                },
                {
                    "sent": "The first is just using a uniform random strategy.",
                    "label": 0
                },
                {
                    "sent": "And the second one is basically ignoring the uncertainty in the problem.",
                    "label": 0
                },
                {
                    "sent": "So if we solve the problem exactly using the mean of each path distribution, that is this baseline and I would argue that that's actually a very good approximation of what's being done when we force our end users to say exactly what the payoff is for a particular cell in these matrices, without using some sort of distributional assumption.",
                    "label": 0
                },
                {
                    "sent": "We can use a number of different methods.",
                    "label": 0
                },
                {
                    "sent": "Including.",
                    "label": 0
                },
                {
                    "sent": "Both the armor method and the HP HP GS method to try to do exact optimization given a set, a set of sampled attacker types.",
                    "label": 0
                },
                {
                    "sent": "And we can use a variety of different methods to do approximate optimization, including things like replicator dynamics and other methods.",
                    "label": 0
                }
            ]
        },
        "clip_69": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So I want to show you just very quickly the results.",
                    "label": 0
                },
                {
                    "sent": "From this we have on the Y axis.",
                    "label": 0
                },
                {
                    "sent": "Here the defenders expected payoff and here we're varying the amount of uncertainty that Defender has about the attackers pay offs.",
                    "label": 0
                },
                {
                    "sent": "And what I want to point out is that both of the baseline measures are down here, so using the mean of each payoff distribution as a point estimate is giving you roughly the same performance as just doing something completely random.",
                    "label": 0
                },
                {
                    "sent": "This line here is trying to do an exact optimization for a small set of attacker types.",
                    "label": 1
                },
                {
                    "sent": "And the top three lines here are doing some sort of approximate optimization with a much larger set of sampled attacker types, so we can see.",
                    "label": 0
                },
                {
                    "sent": "By doing by approximating a solution to this infinite Bayesian Stackelberg game, you're getting a much higher payoff than using either exact solution with a mean approximation of those distributions, or using a small number of sampled attacker types and exact.",
                    "label": 0
                }
            ]
        },
        "clip_70": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Station.",
                    "label": 0
                },
                {
                    "sent": "This slide actually shows that that tradeoff quite clearly.",
                    "label": 0
                },
                {
                    "sent": "So here we have increased, slowly increasing the number of sample attacker types, and you can see that the pay offs are improving dramatically as we start to increase the number of sample attacker types and are used to approximate the attacker response.",
                    "label": 0
                },
                {
                    "sent": "So the key here is that we need.",
                    "label": 0
                },
                {
                    "sent": "We need to get it to devote enough for computational resources to getting a good approximation of that attacker response, and it's worth trading off finding an exact optimization for the defender strategy.",
                    "label": 0
                },
                {
                    "sent": "To get a better approximation of the attacker's response.",
                    "label": 0
                }
            ]
        },
        "clip_71": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we think that these distributions are very useful modeling paradigm for.",
                    "label": 0
                },
                {
                    "sent": "Particularly, modeling uncertainty in that knowledge acquisition phase and some of the existing approaches of using point estimates or small numbers of possible attacker types generate really poor poor performance when we look at them in this context.",
                    "label": 0
                }
            ]
        },
        "clip_72": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So I'm going to turn it over to Melinda again and he's going to talk about human behavior and observation alternative.",
                    "label": 0
                }
            ]
        }
    }
}