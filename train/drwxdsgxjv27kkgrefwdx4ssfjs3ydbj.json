{
    "id": "drwxdsgxjv27kkgrefwdx4ssfjs3ydbj",
    "title": "Optimum Statistical Estimation with Strategic Data Sources",
    "info": {
        "author": [
            "Constantinos Daskalakis, Department of Electrical Engineering and Computer Science, Massachusetts Institute of Technology, MIT"
        ],
        "published": "Aug. 20, 2015",
        "recorded": "July 2015",
        "category": [
            "Top->Computer Science->Machine Learning->Active Learning",
            "Top->Computer Science->Machine Learning->Computational Learning Theory",
            "Top->Computer Science->Machine Learning->On-line Learning",
            "Top->Computer Science->Machine Learning->Reinforcement Learning",
            "Top->Computer Science->Machine Learning->Semi-supervised Learning"
        ]
    },
    "url": "http://videolectures.net/colt2015_daskalakis_data_sources/",
    "segmentation": [
        [
            "Alright, so this is joint work with Youngjae, and Chris is probably true so."
        ],
        [
            "So OK, so game theory in learning have been interacting for years.",
            "OK, starting from fictitious play and more recently we have seen some exciting interactions between the two fields.",
            "Team talk about them in the context of solution concepts and you know machine learning.",
            "So the our goal here is to sort of like explore the other direction about whether mechanism design and its tools can be used to help learning.",
            "And in particular, what we have in mind is we want to formulate the problem where you want to learn from crowdsourced examples, and we're going to have strategic agents who you query to get examples to use in your estimation.",
            "And these agents have cost for efforts, and their goal is to maximize.",
            "Oops, so to minimize effort minus payment OK.",
            "So the complication.",
            "So in our model so and in fact this is what we want to explore is that the learner will never actually get a ground truth, so he cannot process the examples that workers provided a posteriori to understand how well they did and reward or punish them respectively.",
            "And in fact he's not going to even learn how well his estimation performs OK, with respect to the truth.",
            "So the question is what can the learner do in this situation?",
            "So the takeaways from this is sort of like we're exploring this interaction, and I think there are exciting opportunities here so the takeaways are the question, the solution, and you know, exciting directions that you know come up.",
            "So let me be a bit concrete.",
            "In the last three minutes I have OK so."
        ],
        [
            "So our task is linear regression, so there is an unknown hyperplane we want to learn.",
            "So the learner.",
            "Us some estimator have had that requires examples and his goal is to minimize his mean square error.",
            "However, he has no examples but access to workers who can provide examples for him.",
            "Now it's worker is characterized by some function that Maps the effort he decides to commit to accuracy of his examples and given query by the learner.",
            "And depending on how much effort he decides to commit, he will produce an example that's accurate.",
            "With variance that depends on his effort level.",
            "Now his choice will be too.",
            "I think this is correct.",
            "Now he's going to choose effort to maximize his payment minus the effort where you know this function might depend on.",
            "You know both his query and his answer."
        ],
        [
            "Potentially, even if there are more workers, you know, but the other workers did.",
            "Now back to the learner.",
            "What the learner wants to do is he knows the effort to accuracy mapping for every worker he asked to choose workers what inputs to query them on and what payment functions to commit to, and his goal is to minimize some combination of his main scorer in payment and I don't want to be literal about the exact function.",
            "Let's let's fix this for this dog and the issues that sort of like what this will end up being depends on.",
            "The workers behavior, which depends on the payments functions to which the learner is going to commit to.",
            "So sort of like the setting becomes strategic, and that's the point of mechanism design here OK."
        ],
        [
            "So OK, so this is sort of like the summary of what I talked about.",
            "A lot of kind of like parameters here, but here they are so now.",
            "Sort of started this question.",
            "We have to kind of like first come up with the upper bound on what the learning could possibly hope to achieve, and basically we will consider a very sort of like.",
            "So I called this dream sort of like upper bound, which is suppose the letter could exactly control the effort committed by every worker and only paid them exactly for that effort.",
            "OK, this is an imaginary world, but if that was the case then the learner could achieve some objective value.",
            "OK notice here I'm being explicit by the fact that the learner optimizes respect to both the queries and the efforts committed by the workers to which which he cannot enforce.",
            "But you know, this is sort of like sort of like again.",
            "I can experiment.",
            "That's what lyrical possibly hope to achieve.",
            "So what we show is that, for example, if F is least squares regression, there exist payment functions that actually allow the learner to achieve exactly this objective value.",
            "OK, and that's not a phenomenal restricted only to list queries.",
            "We give bounds conditions that apply to other estimators.",
            "Other functions we allow regularization and so forth.",
            "And please come to the poster to see future directions.",
            "I think there are some exciting directions here."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Alright, so this is joint work with Youngjae, and Chris is probably true so.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So OK, so game theory in learning have been interacting for years.",
                    "label": 1
                },
                {
                    "sent": "OK, starting from fictitious play and more recently we have seen some exciting interactions between the two fields.",
                    "label": 0
                },
                {
                    "sent": "Team talk about them in the context of solution concepts and you know machine learning.",
                    "label": 1
                },
                {
                    "sent": "So the our goal here is to sort of like explore the other direction about whether mechanism design and its tools can be used to help learning.",
                    "label": 1
                },
                {
                    "sent": "And in particular, what we have in mind is we want to formulate the problem where you want to learn from crowdsourced examples, and we're going to have strategic agents who you query to get examples to use in your estimation.",
                    "label": 0
                },
                {
                    "sent": "And these agents have cost for efforts, and their goal is to maximize.",
                    "label": 0
                },
                {
                    "sent": "Oops, so to minimize effort minus payment OK.",
                    "label": 1
                },
                {
                    "sent": "So the complication.",
                    "label": 1
                },
                {
                    "sent": "So in our model so and in fact this is what we want to explore is that the learner will never actually get a ground truth, so he cannot process the examples that workers provided a posteriori to understand how well they did and reward or punish them respectively.",
                    "label": 1
                },
                {
                    "sent": "And in fact he's not going to even learn how well his estimation performs OK, with respect to the truth.",
                    "label": 0
                },
                {
                    "sent": "So the question is what can the learner do in this situation?",
                    "label": 0
                },
                {
                    "sent": "So the takeaways from this is sort of like we're exploring this interaction, and I think there are exciting opportunities here so the takeaways are the question, the solution, and you know, exciting directions that you know come up.",
                    "label": 0
                },
                {
                    "sent": "So let me be a bit concrete.",
                    "label": 0
                },
                {
                    "sent": "In the last three minutes I have OK so.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So our task is linear regression, so there is an unknown hyperplane we want to learn.",
                    "label": 1
                },
                {
                    "sent": "So the learner.",
                    "label": 1
                },
                {
                    "sent": "Us some estimator have had that requires examples and his goal is to minimize his mean square error.",
                    "label": 0
                },
                {
                    "sent": "However, he has no examples but access to workers who can provide examples for him.",
                    "label": 1
                },
                {
                    "sent": "Now it's worker is characterized by some function that Maps the effort he decides to commit to accuracy of his examples and given query by the learner.",
                    "label": 0
                },
                {
                    "sent": "And depending on how much effort he decides to commit, he will produce an example that's accurate.",
                    "label": 0
                },
                {
                    "sent": "With variance that depends on his effort level.",
                    "label": 0
                },
                {
                    "sent": "Now his choice will be too.",
                    "label": 0
                },
                {
                    "sent": "I think this is correct.",
                    "label": 0
                },
                {
                    "sent": "Now he's going to choose effort to maximize his payment minus the effort where you know this function might depend on.",
                    "label": 0
                },
                {
                    "sent": "You know both his query and his answer.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Potentially, even if there are more workers, you know, but the other workers did.",
                    "label": 0
                },
                {
                    "sent": "Now back to the learner.",
                    "label": 1
                },
                {
                    "sent": "What the learner wants to do is he knows the effort to accuracy mapping for every worker he asked to choose workers what inputs to query them on and what payment functions to commit to, and his goal is to minimize some combination of his main scorer in payment and I don't want to be literal about the exact function.",
                    "label": 1
                },
                {
                    "sent": "Let's let's fix this for this dog and the issues that sort of like what this will end up being depends on.",
                    "label": 0
                },
                {
                    "sent": "The workers behavior, which depends on the payments functions to which the learner is going to commit to.",
                    "label": 1
                },
                {
                    "sent": "So sort of like the setting becomes strategic, and that's the point of mechanism design here OK.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So OK, so this is sort of like the summary of what I talked about.",
                    "label": 0
                },
                {
                    "sent": "A lot of kind of like parameters here, but here they are so now.",
                    "label": 0
                },
                {
                    "sent": "Sort of started this question.",
                    "label": 0
                },
                {
                    "sent": "We have to kind of like first come up with the upper bound on what the learning could possibly hope to achieve, and basically we will consider a very sort of like.",
                    "label": 0
                },
                {
                    "sent": "So I called this dream sort of like upper bound, which is suppose the letter could exactly control the effort committed by every worker and only paid them exactly for that effort.",
                    "label": 0
                },
                {
                    "sent": "OK, this is an imaginary world, but if that was the case then the learner could achieve some objective value.",
                    "label": 0
                },
                {
                    "sent": "OK notice here I'm being explicit by the fact that the learner optimizes respect to both the queries and the efforts committed by the workers to which which he cannot enforce.",
                    "label": 0
                },
                {
                    "sent": "But you know, this is sort of like sort of like again.",
                    "label": 0
                },
                {
                    "sent": "I can experiment.",
                    "label": 0
                },
                {
                    "sent": "That's what lyrical possibly hope to achieve.",
                    "label": 0
                },
                {
                    "sent": "So what we show is that, for example, if F is least squares regression, there exist payment functions that actually allow the learner to achieve exactly this objective value.",
                    "label": 0
                },
                {
                    "sent": "OK, and that's not a phenomenal restricted only to list queries.",
                    "label": 0
                },
                {
                    "sent": "We give bounds conditions that apply to other estimators.",
                    "label": 0
                },
                {
                    "sent": "Other functions we allow regularization and so forth.",
                    "label": 0
                },
                {
                    "sent": "And please come to the poster to see future directions.",
                    "label": 0
                },
                {
                    "sent": "I think there are some exciting directions here.",
                    "label": 0
                }
            ]
        }
    }
}