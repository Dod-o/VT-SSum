{
    "id": "rrpgix7m7sht6ntsf7tn44j2ooquhce6",
    "title": "Crisp Boundary Detection Using Pointwise Mutual Information",
    "info": {
        "author": [
            "Phillip Isola, Department of Brain and Cognitive Sciences, Massachusetts Institute of Technology, MIT"
        ],
        "published": "Oct. 29, 2014",
        "recorded": "September 2014",
        "category": [
            "Top->Computer Science->Computer Vision"
        ]
    },
    "url": "http://videolectures.net/eccv2014_isola_mutual_information/",
    "segmentation": [
        [
            "I'm Phillip and I'm going to present work that's with Daniel Zoran, Dilip Krishnan, Ted Edelson at MIT.",
            "In our talk is called Chris Boundary detection using pointwise mutual information.",
            "So what we're going to do is take an image like this of Zurich and find all the boundaries between the objects in the image like so.",
            "OK, so this is an old."
        ],
        [
            "Problem in computer vision.",
            "A lot of people have worked on it and one of the popular ways of formalizing the problem is to say, given an input image like this one, which is from the Berkeley segmentation data set.",
            "Our goal is to find all the boundaries between the objects in a way that mimics were human would draw boundaries between objects in that image.",
            "So on the right we can see where a human subject has drawn boundaries between the different pieces of coral, and we want to replicate that ability.",
            "So let's look a little bit at the history of how people."
        ],
        [
            "Try to answer the question how do you find the boundary?",
            "One of the early methods is from Sevelen Feldman 1968 and the idea here was very simple.",
            "Just look for a change in luminance and this works well.",
            "It's nice and clean and simple, but it doesn't suppress highly contrasting textures that really should be grouped as part of the same object, so people moved on from this to more and more kind of complex feature descriptors which can detect pattern changes.",
            "One popular line of work was from Arbelaez at all GPB.",
            "And their idea was to find changes and not just luminance, but also color and texture, and then even more recently people have started moving onto machine learning, learning supervised rule that can match image patches to boundary map patches.",
            "So the trend here has been to move up to more and more complex pattern descriptors and more and more supervision that can really find a high parameter mapping between image patches and where people draw boundaries in an image.",
            "We're going fairly different direction and we have a very simple unsupervised method based on pointwise mutual information that can find it nice.",
            "Clean boundaries within this coral image, and the idea is that we're going to be measuring statistical dissociations between adjacent pixels in the image and where there's a statistical dissociation that will tend to be a boundary.",
            "So unlike the previous recent work, our method is unsupervised and it relies entirely on very simple low level features, so let's see how we do this."
        ],
        [
            "OK, consider this image of the zebras are key observation here is that pixels in this image or any other image like it that belong to the same object tend to have a higher degree of statistical Association than pixels that do not belong to the same object.",
            "The intuition is that in this image you can notice that the pattern block next to White seems to occur suspiciously often, and it be kind of weird to see that pattern.",
            "If those two colors did not belong to the same object.",
            "OK, but how can we actually quantify statistical Association an notice these types of suspicious coincidences?",
            "What we're going to do?"
        ],
        [
            "Is measure a very simple statistic pairwise color Co occurrences in the image.",
            "So we define distribution PA, B, which measures how often each color A occurs.",
            "Nearby or adjacent to each other color be within this exact image.",
            "So just like in the last talk, we're going to exploit the internal statistics of the images that we apply our algorithm to.",
            "And you can visualize this in 2D if I just show you a luminance slice of this space.",
            "So here I'm showing you how often every luminance value in this image occurs next to every other luminance value.",
            "And this distribution is dominated by the diagonal that just says that usually adjacent pixels have more or less the same luminance.",
            "This is the well known idea that images are mostly smooth, but there's some other interesting structure up in the corner here in the red circle you can see there's a little blip of probability which says Black will occur next to white now and then.",
            "That's the signature of the black and white stripes, and what we might want to say is that because we see black occurring next to white relatively frequently, which group black and white.",
            "But using joint probability to group pixels actually is not the best thing to do, and you can kind of understand this by looking at the region in the green circle.",
            "Here we have a pair of colors black occurring next to green, and that pair actually has higher joint probability then the pair black next to white.",
            "So what is going on here?",
            "Well, one reason why Black next screen has high probability is that there's just a lot more green pixels in the image then either black pixels or white pixels.",
            "So there's a higher random chance that green can appear next to anything in.",
            "This inflates the joint probability of green appearing next to any other color.",
            "To correct for this week."
        ],
        [
            "And divide by the base rates of how often each color appears in the image.",
            "And this gives us a different type of Association measure known as pointwise mutual information, which is just the joint probability of how often two colors black next to white occur in the image divided by the product of the marginals.",
            "And this is telling us how much more often those two colors Co occur in the image than they would if they were independent.",
            "So it's a measure of statistical dependence and what you can notice in the PMI function up at the top right is that now.",
            "The pattern block next to White has higher Association.",
            "We show this in the red circle.",
            "It has higher Association.",
            "The pattern black next to green, which is in the green green circle.",
            "So PMI has correctly identified the black should be grouped with white and black should not be grouped with green.",
            "OK, so we're going to do with this is use PMI as a pixel to pixel affinity metric measure for Infinity based grouping algorithm.",
            "That will reveal the boundaries in the image.",
            "But before we do that, I want to look a little bit more in detail at the PMI function."
        ],
        [
            "So we saw on that Zebra image that it seems to work out that PMI is able to group these pixels an intuitive fashion.",
            "But does this really hold up over other images so we can ask?",
            "Is PMI really informative about the location of object boundaries?",
            "We quantified this by on the Y axis, measuring the probability that two pixels AMB, which are nearby one another will occur on the same object segment as a function of the PMI between the pixel colors A&B.",
            "The function looks like this, So what I want you to observe is that down here when you have low PMI, it's relatively likely that there's a boundary that separates the two pixels A&B, which when."
        ],
        [
            "Have high PMI or pointwise mutual information.",
            "We can be almost certain that there is no boundary that separates those two pixels in the image.",
            "OK, so why does this work?",
            "Why can rule based on very simple color statistics be pretty good at deciding whether or not pixels belong to the same object?",
            "So one reason?"
        ],
        [
            "Is that this method is leveraging internal image statistics and we just saw an example of how powerful those can be.",
            "So here's another example well.",
            "Suppose that instead of measuring how often different colors Co occur in the single specific image, we instead try to learn a generic rule that would apply to all images.",
            "So we instead measure the color Co occurrences that exist in all the images in the world.",
            "In that case we have to have we have to average over statistics from these types of images too.",
            "So if we want to learn a generic rule that will apply to all the images, well the black should go with white.",
            "That black and white form an object is not a very good choice because most images are more like this one or the shrine where black next to white actually indicates that there are two separate objects.",
            "So it's not.",
            "It's the case that there is really no generic rule based on color statistics that can apply to all images, and therefore it helps to really adapt to the specific internal statistics of each individual image.",
            "So the grouping rules based on color for different images are different, and we can actually quantify how effective it is to adapt internal statistics by."
        ],
        [
            "Using the same analysis as before, this is the same function I just showed you where we have how predictive PMI is of whether or not MBR on the same object segment.",
            "This is measured based on internal image statistics, which is how we run our algorithm normally.",
            "But we can also measure PMI using the joint Co occurrence of colors from an external database.",
            "If we do so, we get a much worse classifier, so the slope is shallower and this just says that external image statistics are not well suited to modeling the specific color Co occurrences that are happening.",
            "In a given image so.",
            "Now we have a measure point West Mifflin formation, which we've seen is predictive of whether or not to pixels line the same boundary, and we've seen that it can be predicted because it's adapted to the special structure in each individual image supplied to how do we use?"
        ],
        [
            "But for actual boundary detection and segmentation, what we're going to do is."
        ],
        [
            "Just to use art, pointwise mutual information Measure 2 as an affinity measure for an affinity based clustering algorithm.",
            "So first we get the affinity between all pairs of pixels in the image using PMI.",
            "And this is our novel contribution.",
            "The next step, which is just apply affinity based clustering is we apply standard off the shelf techniques to do this.",
            "In particular we apply the spectral clustering based pipeline of arbelaez at all.",
            "So let me walk through house."
        ],
        [
            "It works on a single image.",
            "Given this image, the first thing we do is estimate the Co occurrence of features at adjacent locations in the image.",
            "We estimate the distribution PA, B.",
            "To do so, we sample adjacent pairs of pixels in the image indicated by the red and green dots, and we look at the features that occur at those colors at those locations.",
            "So here is the joint density over colors.",
            "We have a lot of samples of blue next to blue, Brown, next to Brown, and we fit the distribution around these samples using kernel density estimation.",
            "So note that I've been talking about colors, but we can also apply the same method to other types of features so A&B can take on another feature values and in our full boundary detection algorithm we use two types of features.",
            "We use both colors and we also use the color space we use is widened ellaby space and we also use the variance of color in a three by three window around each pixel.",
            "So two very simple color statistics and we're looking at the Co occurrence of these features at adjacent pixels in the image.",
            "This gives us our joint density PA, B."
        ],
        [
            "That is very simple to derive PMI, which is just a manipulation of the joint density and we use PMI point W. Mitchell information accurately measure."
        ],
        [
            "In an affinity based grouping algorithm, let's zoom in quickly on what the affinity structure looks like around some of the pixels in this image.",
            "So here we have in the center of the red box a bark pixel an unplugging the affinity that that bark pixel has with all of the adjacent pixels around it.",
            "Brighter colors mean stronger affinity, and what you can see is that the bark pixel has high affinity with other bark pixels and low affinity with the Sky behind it.",
            "So when we group based on affinity, we will be able to successfully find barcodes with Park in a separate from Sky."
        ],
        [
            "Let's look at the texture region down here and we can see that the center pixel in that texture has high affinity with all surrounding elements of the texture.",
            "And so when we group based on affinity, all of these pixels will end up grouped together because the statistics reveal that pattern as a regularity that should be part of the same object process.",
            "OK, the final step is we're just going to do the grouping based on affinity, so we make a affinity matrix which is just measuring the affinity between all nearby pairs of pixels in this image.",
            "So we make these types of Windows over the entire image, and then we just apply standard spectral clustering based."
        ],
        [
            "Mentation and boundary detection.",
            "And that reveals for us the boundaries between the different regions and we also get a segmentation.",
            "OK, so let's."
        ],
        [
            "Look at a few results from our method so he."
        ],
        [
            "There is 1 nice simple image with well color separated objects and indeed our method can identify that there are these clear different clusters of color and find clean boundaries between them.",
            "Here we have a slightly more complicated image where the objects are defined by textural processes, but this shows up again in the image statistics and when we cluster based on the pointwise mutual information, we can suppress these textures and find only the boundaries leftover between the textural regions.",
            "Here's an interesting case.",
            "Notice that the features on the faces of these children end up being grouped with the face.",
            "This is because those features actually have a strong degree of Association with the background color of the face.",
            "And now let's check if we did well on our zebra example.",
            "So are we able to group the white and black pixels into a coherent object?",
            "And the answer is yes, we are able to, but notice that there is an interesting failure between the two zebras.",
            "We were able to find the boundary between those two zebras and one reason for that is the two supers have more or less the same color statistics in order to find that boundary, we probably have to use higher order features like orientation features, because those two regions are not distinguished by their color statistics.",
            "OK, so that's something that we might want to work on in the future, so we also quantified this."
        ],
        [
            "Oh sorry, by the way, we can get segments using the same pipeline because this is all based on the spectral clustering method, which gets both boundaries and segments.",
            "OK, let's quantify."
        ],
        [
            "Our performance.",
            "And we do this on the standard Berkeley segmentation data set, so the task that people usually use here is a retrieval task with.",
            "The goal is try to retrieve all of the boundaries that humans label in the images.",
            "To perform well, you want to be up toward the top right, and our method ends up falling right along the kind of state of the art curve with a couple other methods.",
            "So we were able to match these state of the art results.",
            "But the key interesting thing is our mechanism unsupervised and uses very simple low level.",
            "Image statistics, which contrasts very much with most of the other recent approaches.",
            "OK."
        ],
        [
            "So because our method is unsupervised, it's not specially adapted to any particular kind of image, and indeed it can perform decently on a diverse range of stimuli.",
            "So I want to do a few examples so we can apply this to regular cell phone photos and find some nice boundaries art where the statistics are slightly different.",
            "But again, we're adapting to the specific internal statistics of each image.",
            "And we're also excited about applying this to other types of visual domains like satellite imagery, where this statistics might be slightly different, but still, this pointwise mutual information is able to successfully find groupings like in Manhattan here.",
            "1."
        ],
        [
            "Other type of application is we can apply this to videos.",
            "The only difference between this and the image based algorithm is we sample pixel pairs in space time as opposed to in space and then run everything through in the same fashion in space time and this allows us to find temporally smooth boundaries in a video."
        ],
        [
            "OK, so I want to summarize what we've done.",
            "We have seen that pointwise mutual information is a powerful affinity measure for grouping pixels in an image, and this has natural applications to both boundary detection and segmentation.",
            "This method is able to achieve high quality results despite being both unsupervised and relying entirely on simple internal image statistics."
        ],
        [
            "OK, so we have code available for this.",
            "You can see the MATLAB call there and the URL is right there so I hope you guys find this useful.",
            "Thank you.",
            "What happens if you have a picture of a zebra crossing the freeway?",
            "Will the dividing line of a freeway be detected or not?",
            "Yeah, so in that case I think probably not.",
            "So again there are.",
            "There are certain patterns that only will show up with higher order statistics.",
            "And you can see that we weren't able to separate one zebra from the next, and I think this will be a similar case with the dividing line will look just like more zebra pixels, so that's certainly something we would like to improve, and one possible way of improving it would be to work with some richer descriptors that go beyond just color, but can.",
            "Main Point is that you can get along way with just something as simple as color.",
            "Here, did you try to consider pixels which are further away, not just pairwise so?",
            "The distance between the samples actually varies from one to five pixels, so they do have a little bit of spatial distance.",
            "When I was saying adjacent, the real detail is nearby, but we didn't look at very long distances.",
            "We didn't look at Co occurrences over longer ranges.",
            "That will be something very interesting to explore.",
            "How this statistics change as a function of the distance between the pixels, but we haven't done that yet.",
            "OK, it's actually very small detail.",
            "I don't think it's gonna change the result at all, but is there any reason you didn't make it European isometric?",
            "I have notice that it's not perfectly symmetric, yeah?",
            "So.",
            "So.",
            "Or PMI.",
            "Is actually symmetric because it's just the joint distribution divided by the product of the marginals.",
            "So I think that it is in fact symmetric, but maybe we can talk afterward if if you.",
            "Had an insight beyond that.",
            "You can swap the rule of the of the two pixels and it will come out to be the same value.",
            "OK, but let me know if we can talk later if that's if there's a difference in your interpretation.",
            "I just have one more question.",
            "What's the runtime of your algorithm?",
            "Oh yeah, good question.",
            "So in order to achieve nice results that match the state of the art, it takes around 30 seconds per image.",
            "We can get higher resolution results in several minutes per image, but because the standard benchmarks actually don't care much about resolution, 30 seconds is sufficient to already get good results based on based on those criteria.",
            "And this is a MATLAB implementation.",
            "I think that it could be made a lot faster.",
            "The key bottlenecks are evaluating the affinity's because it's based on these big kernel densities and the spectral clustering.",
            "OK, let's thank the speaker again, thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I'm Phillip and I'm going to present work that's with Daniel Zoran, Dilip Krishnan, Ted Edelson at MIT.",
                    "label": 0
                },
                {
                    "sent": "In our talk is called Chris Boundary detection using pointwise mutual information.",
                    "label": 1
                },
                {
                    "sent": "So what we're going to do is take an image like this of Zurich and find all the boundaries between the objects in the image like so.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is an old.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Problem in computer vision.",
                    "label": 0
                },
                {
                    "sent": "A lot of people have worked on it and one of the popular ways of formalizing the problem is to say, given an input image like this one, which is from the Berkeley segmentation data set.",
                    "label": 0
                },
                {
                    "sent": "Our goal is to find all the boundaries between the objects in a way that mimics were human would draw boundaries between objects in that image.",
                    "label": 1
                },
                {
                    "sent": "So on the right we can see where a human subject has drawn boundaries between the different pieces of coral, and we want to replicate that ability.",
                    "label": 0
                },
                {
                    "sent": "So let's look a little bit at the history of how people.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Try to answer the question how do you find the boundary?",
                    "label": 1
                },
                {
                    "sent": "One of the early methods is from Sevelen Feldman 1968 and the idea here was very simple.",
                    "label": 0
                },
                {
                    "sent": "Just look for a change in luminance and this works well.",
                    "label": 1
                },
                {
                    "sent": "It's nice and clean and simple, but it doesn't suppress highly contrasting textures that really should be grouped as part of the same object, so people moved on from this to more and more kind of complex feature descriptors which can detect pattern changes.",
                    "label": 0
                },
                {
                    "sent": "One popular line of work was from Arbelaez at all GPB.",
                    "label": 0
                },
                {
                    "sent": "And their idea was to find changes and not just luminance, but also color and texture, and then even more recently people have started moving onto machine learning, learning supervised rule that can match image patches to boundary map patches.",
                    "label": 1
                },
                {
                    "sent": "So the trend here has been to move up to more and more complex pattern descriptors and more and more supervision that can really find a high parameter mapping between image patches and where people draw boundaries in an image.",
                    "label": 0
                },
                {
                    "sent": "We're going fairly different direction and we have a very simple unsupervised method based on pointwise mutual information that can find it nice.",
                    "label": 0
                },
                {
                    "sent": "Clean boundaries within this coral image, and the idea is that we're going to be measuring statistical dissociations between adjacent pixels in the image and where there's a statistical dissociation that will tend to be a boundary.",
                    "label": 0
                },
                {
                    "sent": "So unlike the previous recent work, our method is unsupervised and it relies entirely on very simple low level features, so let's see how we do this.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, consider this image of the zebras are key observation here is that pixels in this image or any other image like it that belong to the same object tend to have a higher degree of statistical Association than pixels that do not belong to the same object.",
                    "label": 1
                },
                {
                    "sent": "The intuition is that in this image you can notice that the pattern block next to White seems to occur suspiciously often, and it be kind of weird to see that pattern.",
                    "label": 0
                },
                {
                    "sent": "If those two colors did not belong to the same object.",
                    "label": 0
                },
                {
                    "sent": "OK, but how can we actually quantify statistical Association an notice these types of suspicious coincidences?",
                    "label": 0
                },
                {
                    "sent": "What we're going to do?",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Is measure a very simple statistic pairwise color Co occurrences in the image.",
                    "label": 1
                },
                {
                    "sent": "So we define distribution PA, B, which measures how often each color A occurs.",
                    "label": 1
                },
                {
                    "sent": "Nearby or adjacent to each other color be within this exact image.",
                    "label": 1
                },
                {
                    "sent": "So just like in the last talk, we're going to exploit the internal statistics of the images that we apply our algorithm to.",
                    "label": 0
                },
                {
                    "sent": "And you can visualize this in 2D if I just show you a luminance slice of this space.",
                    "label": 1
                },
                {
                    "sent": "So here I'm showing you how often every luminance value in this image occurs next to every other luminance value.",
                    "label": 0
                },
                {
                    "sent": "And this distribution is dominated by the diagonal that just says that usually adjacent pixels have more or less the same luminance.",
                    "label": 0
                },
                {
                    "sent": "This is the well known idea that images are mostly smooth, but there's some other interesting structure up in the corner here in the red circle you can see there's a little blip of probability which says Black will occur next to white now and then.",
                    "label": 0
                },
                {
                    "sent": "That's the signature of the black and white stripes, and what we might want to say is that because we see black occurring next to white relatively frequently, which group black and white.",
                    "label": 0
                },
                {
                    "sent": "But using joint probability to group pixels actually is not the best thing to do, and you can kind of understand this by looking at the region in the green circle.",
                    "label": 1
                },
                {
                    "sent": "Here we have a pair of colors black occurring next to green, and that pair actually has higher joint probability then the pair black next to white.",
                    "label": 0
                },
                {
                    "sent": "So what is going on here?",
                    "label": 0
                },
                {
                    "sent": "Well, one reason why Black next screen has high probability is that there's just a lot more green pixels in the image then either black pixels or white pixels.",
                    "label": 0
                },
                {
                    "sent": "So there's a higher random chance that green can appear next to anything in.",
                    "label": 0
                },
                {
                    "sent": "This inflates the joint probability of green appearing next to any other color.",
                    "label": 0
                },
                {
                    "sent": "To correct for this week.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And divide by the base rates of how often each color appears in the image.",
                    "label": 0
                },
                {
                    "sent": "And this gives us a different type of Association measure known as pointwise mutual information, which is just the joint probability of how often two colors black next to white occur in the image divided by the product of the marginals.",
                    "label": 1
                },
                {
                    "sent": "And this is telling us how much more often those two colors Co occur in the image than they would if they were independent.",
                    "label": 0
                },
                {
                    "sent": "So it's a measure of statistical dependence and what you can notice in the PMI function up at the top right is that now.",
                    "label": 0
                },
                {
                    "sent": "The pattern block next to White has higher Association.",
                    "label": 1
                },
                {
                    "sent": "We show this in the red circle.",
                    "label": 1
                },
                {
                    "sent": "It has higher Association.",
                    "label": 1
                },
                {
                    "sent": "The pattern black next to green, which is in the green green circle.",
                    "label": 0
                },
                {
                    "sent": "So PMI has correctly identified the black should be grouped with white and black should not be grouped with green.",
                    "label": 0
                },
                {
                    "sent": "OK, so we're going to do with this is use PMI as a pixel to pixel affinity metric measure for Infinity based grouping algorithm.",
                    "label": 0
                },
                {
                    "sent": "That will reveal the boundaries in the image.",
                    "label": 0
                },
                {
                    "sent": "But before we do that, I want to look a little bit more in detail at the PMI function.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we saw on that Zebra image that it seems to work out that PMI is able to group these pixels an intuitive fashion.",
                    "label": 0
                },
                {
                    "sent": "But does this really hold up over other images so we can ask?",
                    "label": 0
                },
                {
                    "sent": "Is PMI really informative about the location of object boundaries?",
                    "label": 1
                },
                {
                    "sent": "We quantified this by on the Y axis, measuring the probability that two pixels AMB, which are nearby one another will occur on the same object segment as a function of the PMI between the pixel colors A&B.",
                    "label": 0
                },
                {
                    "sent": "The function looks like this, So what I want you to observe is that down here when you have low PMI, it's relatively likely that there's a boundary that separates the two pixels A&B, which when.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Have high PMI or pointwise mutual information.",
                    "label": 1
                },
                {
                    "sent": "We can be almost certain that there is no boundary that separates those two pixels in the image.",
                    "label": 0
                },
                {
                    "sent": "OK, so why does this work?",
                    "label": 0
                },
                {
                    "sent": "Why can rule based on very simple color statistics be pretty good at deciding whether or not pixels belong to the same object?",
                    "label": 0
                },
                {
                    "sent": "So one reason?",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Is that this method is leveraging internal image statistics and we just saw an example of how powerful those can be.",
                    "label": 1
                },
                {
                    "sent": "So here's another example well.",
                    "label": 0
                },
                {
                    "sent": "Suppose that instead of measuring how often different colors Co occur in the single specific image, we instead try to learn a generic rule that would apply to all images.",
                    "label": 0
                },
                {
                    "sent": "So we instead measure the color Co occurrences that exist in all the images in the world.",
                    "label": 0
                },
                {
                    "sent": "In that case we have to have we have to average over statistics from these types of images too.",
                    "label": 0
                },
                {
                    "sent": "So if we want to learn a generic rule that will apply to all the images, well the black should go with white.",
                    "label": 0
                },
                {
                    "sent": "That black and white form an object is not a very good choice because most images are more like this one or the shrine where black next to white actually indicates that there are two separate objects.",
                    "label": 0
                },
                {
                    "sent": "So it's not.",
                    "label": 0
                },
                {
                    "sent": "It's the case that there is really no generic rule based on color statistics that can apply to all images, and therefore it helps to really adapt to the specific internal statistics of each individual image.",
                    "label": 0
                },
                {
                    "sent": "So the grouping rules based on color for different images are different, and we can actually quantify how effective it is to adapt internal statistics by.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Using the same analysis as before, this is the same function I just showed you where we have how predictive PMI is of whether or not MBR on the same object segment.",
                    "label": 0
                },
                {
                    "sent": "This is measured based on internal image statistics, which is how we run our algorithm normally.",
                    "label": 0
                },
                {
                    "sent": "But we can also measure PMI using the joint Co occurrence of colors from an external database.",
                    "label": 0
                },
                {
                    "sent": "If we do so, we get a much worse classifier, so the slope is shallower and this just says that external image statistics are not well suited to modeling the specific color Co occurrences that are happening.",
                    "label": 0
                },
                {
                    "sent": "In a given image so.",
                    "label": 0
                },
                {
                    "sent": "Now we have a measure point West Mifflin formation, which we've seen is predictive of whether or not to pixels line the same boundary, and we've seen that it can be predicted because it's adapted to the special structure in each individual image supplied to how do we use?",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But for actual boundary detection and segmentation, what we're going to do is.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Just to use art, pointwise mutual information Measure 2 as an affinity measure for an affinity based clustering algorithm.",
                    "label": 0
                },
                {
                    "sent": "So first we get the affinity between all pairs of pixels in the image using PMI.",
                    "label": 1
                },
                {
                    "sent": "And this is our novel contribution.",
                    "label": 0
                },
                {
                    "sent": "The next step, which is just apply affinity based clustering is we apply standard off the shelf techniques to do this.",
                    "label": 0
                },
                {
                    "sent": "In particular we apply the spectral clustering based pipeline of arbelaez at all.",
                    "label": 0
                },
                {
                    "sent": "So let me walk through house.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "It works on a single image.",
                    "label": 0
                },
                {
                    "sent": "Given this image, the first thing we do is estimate the Co occurrence of features at adjacent locations in the image.",
                    "label": 0
                },
                {
                    "sent": "We estimate the distribution PA, B.",
                    "label": 1
                },
                {
                    "sent": "To do so, we sample adjacent pairs of pixels in the image indicated by the red and green dots, and we look at the features that occur at those colors at those locations.",
                    "label": 0
                },
                {
                    "sent": "So here is the joint density over colors.",
                    "label": 0
                },
                {
                    "sent": "We have a lot of samples of blue next to blue, Brown, next to Brown, and we fit the distribution around these samples using kernel density estimation.",
                    "label": 0
                },
                {
                    "sent": "So note that I've been talking about colors, but we can also apply the same method to other types of features so A&B can take on another feature values and in our full boundary detection algorithm we use two types of features.",
                    "label": 0
                },
                {
                    "sent": "We use both colors and we also use the color space we use is widened ellaby space and we also use the variance of color in a three by three window around each pixel.",
                    "label": 0
                },
                {
                    "sent": "So two very simple color statistics and we're looking at the Co occurrence of these features at adjacent pixels in the image.",
                    "label": 0
                },
                {
                    "sent": "This gives us our joint density PA, B.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That is very simple to derive PMI, which is just a manipulation of the joint density and we use PMI point W. Mitchell information accurately measure.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In an affinity based grouping algorithm, let's zoom in quickly on what the affinity structure looks like around some of the pixels in this image.",
                    "label": 0
                },
                {
                    "sent": "So here we have in the center of the red box a bark pixel an unplugging the affinity that that bark pixel has with all of the adjacent pixels around it.",
                    "label": 0
                },
                {
                    "sent": "Brighter colors mean stronger affinity, and what you can see is that the bark pixel has high affinity with other bark pixels and low affinity with the Sky behind it.",
                    "label": 0
                },
                {
                    "sent": "So when we group based on affinity, we will be able to successfully find barcodes with Park in a separate from Sky.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Let's look at the texture region down here and we can see that the center pixel in that texture has high affinity with all surrounding elements of the texture.",
                    "label": 0
                },
                {
                    "sent": "And so when we group based on affinity, all of these pixels will end up grouped together because the statistics reveal that pattern as a regularity that should be part of the same object process.",
                    "label": 0
                },
                {
                    "sent": "OK, the final step is we're just going to do the grouping based on affinity, so we make a affinity matrix which is just measuring the affinity between all nearby pairs of pixels in this image.",
                    "label": 0
                },
                {
                    "sent": "So we make these types of Windows over the entire image, and then we just apply standard spectral clustering based.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Mentation and boundary detection.",
                    "label": 0
                },
                {
                    "sent": "And that reveals for us the boundaries between the different regions and we also get a segmentation.",
                    "label": 0
                },
                {
                    "sent": "OK, so let's.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Look at a few results from our method so he.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "There is 1 nice simple image with well color separated objects and indeed our method can identify that there are these clear different clusters of color and find clean boundaries between them.",
                    "label": 0
                },
                {
                    "sent": "Here we have a slightly more complicated image where the objects are defined by textural processes, but this shows up again in the image statistics and when we cluster based on the pointwise mutual information, we can suppress these textures and find only the boundaries leftover between the textural regions.",
                    "label": 0
                },
                {
                    "sent": "Here's an interesting case.",
                    "label": 0
                },
                {
                    "sent": "Notice that the features on the faces of these children end up being grouped with the face.",
                    "label": 0
                },
                {
                    "sent": "This is because those features actually have a strong degree of Association with the background color of the face.",
                    "label": 0
                },
                {
                    "sent": "And now let's check if we did well on our zebra example.",
                    "label": 0
                },
                {
                    "sent": "So are we able to group the white and black pixels into a coherent object?",
                    "label": 0
                },
                {
                    "sent": "And the answer is yes, we are able to, but notice that there is an interesting failure between the two zebras.",
                    "label": 0
                },
                {
                    "sent": "We were able to find the boundary between those two zebras and one reason for that is the two supers have more or less the same color statistics in order to find that boundary, we probably have to use higher order features like orientation features, because those two regions are not distinguished by their color statistics.",
                    "label": 0
                },
                {
                    "sent": "OK, so that's something that we might want to work on in the future, so we also quantified this.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Oh sorry, by the way, we can get segments using the same pipeline because this is all based on the spectral clustering method, which gets both boundaries and segments.",
                    "label": 0
                },
                {
                    "sent": "OK, let's quantify.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Our performance.",
                    "label": 0
                },
                {
                    "sent": "And we do this on the standard Berkeley segmentation data set, so the task that people usually use here is a retrieval task with.",
                    "label": 0
                },
                {
                    "sent": "The goal is try to retrieve all of the boundaries that humans label in the images.",
                    "label": 0
                },
                {
                    "sent": "To perform well, you want to be up toward the top right, and our method ends up falling right along the kind of state of the art curve with a couple other methods.",
                    "label": 0
                },
                {
                    "sent": "So we were able to match these state of the art results.",
                    "label": 0
                },
                {
                    "sent": "But the key interesting thing is our mechanism unsupervised and uses very simple low level.",
                    "label": 0
                },
                {
                    "sent": "Image statistics, which contrasts very much with most of the other recent approaches.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So because our method is unsupervised, it's not specially adapted to any particular kind of image, and indeed it can perform decently on a diverse range of stimuli.",
                    "label": 0
                },
                {
                    "sent": "So I want to do a few examples so we can apply this to regular cell phone photos and find some nice boundaries art where the statistics are slightly different.",
                    "label": 0
                },
                {
                    "sent": "But again, we're adapting to the specific internal statistics of each image.",
                    "label": 0
                },
                {
                    "sent": "And we're also excited about applying this to other types of visual domains like satellite imagery, where this statistics might be slightly different, but still, this pointwise mutual information is able to successfully find groupings like in Manhattan here.",
                    "label": 0
                },
                {
                    "sent": "1.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Other type of application is we can apply this to videos.",
                    "label": 0
                },
                {
                    "sent": "The only difference between this and the image based algorithm is we sample pixel pairs in space time as opposed to in space and then run everything through in the same fashion in space time and this allows us to find temporally smooth boundaries in a video.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so I want to summarize what we've done.",
                    "label": 0
                },
                {
                    "sent": "We have seen that pointwise mutual information is a powerful affinity measure for grouping pixels in an image, and this has natural applications to both boundary detection and segmentation.",
                    "label": 1
                },
                {
                    "sent": "This method is able to achieve high quality results despite being both unsupervised and relying entirely on simple internal image statistics.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so we have code available for this.",
                    "label": 0
                },
                {
                    "sent": "You can see the MATLAB call there and the URL is right there so I hope you guys find this useful.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                },
                {
                    "sent": "What happens if you have a picture of a zebra crossing the freeway?",
                    "label": 0
                },
                {
                    "sent": "Will the dividing line of a freeway be detected or not?",
                    "label": 0
                },
                {
                    "sent": "Yeah, so in that case I think probably not.",
                    "label": 0
                },
                {
                    "sent": "So again there are.",
                    "label": 0
                },
                {
                    "sent": "There are certain patterns that only will show up with higher order statistics.",
                    "label": 0
                },
                {
                    "sent": "And you can see that we weren't able to separate one zebra from the next, and I think this will be a similar case with the dividing line will look just like more zebra pixels, so that's certainly something we would like to improve, and one possible way of improving it would be to work with some richer descriptors that go beyond just color, but can.",
                    "label": 0
                },
                {
                    "sent": "Main Point is that you can get along way with just something as simple as color.",
                    "label": 0
                },
                {
                    "sent": "Here, did you try to consider pixels which are further away, not just pairwise so?",
                    "label": 0
                },
                {
                    "sent": "The distance between the samples actually varies from one to five pixels, so they do have a little bit of spatial distance.",
                    "label": 0
                },
                {
                    "sent": "When I was saying adjacent, the real detail is nearby, but we didn't look at very long distances.",
                    "label": 0
                },
                {
                    "sent": "We didn't look at Co occurrences over longer ranges.",
                    "label": 0
                },
                {
                    "sent": "That will be something very interesting to explore.",
                    "label": 0
                },
                {
                    "sent": "How this statistics change as a function of the distance between the pixels, but we haven't done that yet.",
                    "label": 0
                },
                {
                    "sent": "OK, it's actually very small detail.",
                    "label": 0
                },
                {
                    "sent": "I don't think it's gonna change the result at all, but is there any reason you didn't make it European isometric?",
                    "label": 0
                },
                {
                    "sent": "I have notice that it's not perfectly symmetric, yeah?",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Or PMI.",
                    "label": 0
                },
                {
                    "sent": "Is actually symmetric because it's just the joint distribution divided by the product of the marginals.",
                    "label": 0
                },
                {
                    "sent": "So I think that it is in fact symmetric, but maybe we can talk afterward if if you.",
                    "label": 0
                },
                {
                    "sent": "Had an insight beyond that.",
                    "label": 0
                },
                {
                    "sent": "You can swap the rule of the of the two pixels and it will come out to be the same value.",
                    "label": 0
                },
                {
                    "sent": "OK, but let me know if we can talk later if that's if there's a difference in your interpretation.",
                    "label": 0
                },
                {
                    "sent": "I just have one more question.",
                    "label": 0
                },
                {
                    "sent": "What's the runtime of your algorithm?",
                    "label": 0
                },
                {
                    "sent": "Oh yeah, good question.",
                    "label": 0
                },
                {
                    "sent": "So in order to achieve nice results that match the state of the art, it takes around 30 seconds per image.",
                    "label": 0
                },
                {
                    "sent": "We can get higher resolution results in several minutes per image, but because the standard benchmarks actually don't care much about resolution, 30 seconds is sufficient to already get good results based on based on those criteria.",
                    "label": 0
                },
                {
                    "sent": "And this is a MATLAB implementation.",
                    "label": 0
                },
                {
                    "sent": "I think that it could be made a lot faster.",
                    "label": 0
                },
                {
                    "sent": "The key bottlenecks are evaluating the affinity's because it's based on these big kernel densities and the spectral clustering.",
                    "label": 0
                },
                {
                    "sent": "OK, let's thank the speaker again, thank you.",
                    "label": 0
                }
            ]
        }
    }
}