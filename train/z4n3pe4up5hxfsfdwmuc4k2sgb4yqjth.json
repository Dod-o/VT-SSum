{
    "id": "z4n3pe4up5hxfsfdwmuc4k2sgb4yqjth",
    "title": "New Quasi-Newton Methods for Efficient Large-Scale Machine Learning",
    "info": {
        "author": [
            "S.V.N. Vishwanathan, National ICT Australia"
        ],
        "published": "Dec. 29, 2007",
        "recorded": "December 2007",
        "category": [
            "Top->Computer Science->Machine Learning"
        ]
    },
    "url": "http://videolectures.net/eml07_vishwanathan_nqm/",
    "segmentation": [
        [
            "Thank you very much.",
            "So my name is SVN Vishwanathan and this is joint work with a number of people, mainly next trade off my friend and colleague Simon Ginter postdoc Gene.",
            "You or my PhD student Peterson hunger postdoc in your control for colleague?"
        ],
        [
            "A lot of what I'm going to talk about today is about these four gentlemen in 1970.",
            "Within a span of one year, the four of them invented an algorithm which is now named in their honor called The BFG S algorithm.",
            "BF GS is basically the the black box algorithm that you want to use for unconstrained smooth, convex nonlinear optimization.",
            "So essentially if you call optimize in Matlab.",
            "By default it calls this algorithm that they invented and they amaze."
        ],
        [
            "Thing is that all four of them invented the algorithm independent of each other and published it in four different journals independent of each other, so.",
            "It's just a bit of trivia.",
            "Now, let's start and look at how the FDS actually works.",
            "It's conceptually it's a very, very simple algorithm, So what you do is at every time step you make a quadratic approximation to your function at your current rate 30.",
            "So you get the gradient and then you get the Hessian.",
            "And this is just the 2nd order Taylor approximation.",
            "And of course it's very expensive to compute the true Hessian.",
            "So what it does is it maintains an end by an estimate of the Hessian."
        ],
        [
            "And to find the next iterate, you do the most obvious thing which is you just go and minimize this quadratic function."
        ],
        [
            "If you, if you think about it for 30 seconds, it's very easy to convince yourself that the parimeter update essentially looks like this.",
            "So here BT is the inverse of the Hessian of the estimate of your Hessian, an typically notice that we're not taking a full step.",
            "So if you just minimize this blindly, you would've said either T to be one, but generally in VFS you'd also do align search, so you would find a direction and the direction being B times the gradient of FT, and then you do a line search.",
            "Along that direction, so you have a 1 dimensional convex function and you minimize that function along that line and you take a step."
        ],
        [
            "The question that probably is burning in your mind is how do you actually update this be matrix or this Hessian matrix.",
            "So in the night it kind of seems trivial in hindsight, but in the 1970s when they actually invented this algorithm, the big breakthrough was the fact that instead of maintaining the Hessian like all the other algorithms, who do an updating, the Hessian and inverting it at every step to find and iterate VFD S does something smart, it directly maintains the inverse of the Hessian.",
            "The way it maintains the Hessian is inverse of the Hessian is by saying it doesn't want to move too far away from the current iterate, and it maintains a condition.",
            "This condition is called the second condition.",
            "And estimated.",
            "So this is a constraint, so you minimize be subject to this constraint.",
            "So at every time step this is an invariant that's maintained, so the algorithm always maintained."
        ],
        [
            "The scenario where Whitey is nothing but the difference of the gradients and St is the difference in the parameters.",
            "The W is chosen.",
            "It's a weighted for business Norm, which you're minimizing, and EW is chosen.",
            "It's essentially black art."
        ],
        [
            "And to me, the most amazing thing is that all four of them essentially did the same black art independent of each other and the way the W is chosen is to ensure that the BT plus one your next iterate is essentially a projection of your current version of your current inverses in estimate plus a rank 1 update.",
            "So it's a rank 2 update.",
            "You can do it efficiently and you can you can employ all your numerical linear algebra tricks today."
        ],
        [
            "This efficiently then in 93 or 94 I believe Nocedal.",
            "His coworkers came up with a limited memory variant of it, so instead I said oh instead of maintaining this entire Hessian, which is NBN matrix, what if I only maintain K columns of it?",
            "So if I maintain a key rank approximation, how does it perform so essentially for the rest of this talk, I'll always talk about drugs, but keep in the back of your mind that whatever we do with BFG, S can also be done with limited memory variant."
        ],
        [
            "So before going ahead, I want to talk about the underlying or unstated assumptions that BSS makes, so the first unstated assumption is that the objective function is always strictly."
        ],
        [
            "Mix.",
            "Of course, we know that when we are looking at when you're where they're coming from, the deep belief net cloud, or if your follower of what you answer is well, you should keep away from convex loss functions and many of the things that we deal with a non convex."
        ],
        [
            "The other assumption is that the objective function is smooth, which means the gradients exist."
        ],
        [
            "Of course everybody knows that if you say for instance, do regularised risk minimization and use the hinge loss at the hinge points, your objective function is not smooth, it has."
        ],
        [
            "Subgradients the other assumption is that you have batch gradient, so which means that you can compute the gradient of your entire objective function and then you can."
        ],
        [
            "Step which of course is probably expensive when you're working with large datasets."
        ],
        [
            "And finally, there is an assumption, of course, or the way I presented it is that the parameter vector is always in finite dimensions.",
            "It's in our."
        ],
        [
            "Vector, but again, if you're working with kernel algorithms, you could have you could be working in a potentially infinite dimensional arcade."
        ],
        [
            "So the aim of this dog and pretty much the aim of a lot of people in the group that I work with, is essentially to try and systematically relax these assumptions and to go further and actually make VFD S applicable to many of these machine learning problems.",
            "So some of these assumptions really prevent you from applying the FTS, which is which is basically the state of the art solver to some of the problems or obvious problems in machine learning and hopefully by relaxing some of them will make it more applicable to machine learning.",
            "So this is the.",
            "This is the."
        ],
        [
            "Are all picture.",
            "So let's start by relaxing the strict convexity assumption.",
            "So here basically what I'll do is give you a quick overview of how we can relax strict convexity.",
            "A lot of this stuff of relaxing strict convexity.",
            "Convexity is not just our work, it's just part of folklore, but I just want to bring it out to people in this workshop because many of us are practitioners and we want to actually applied, and I think it's important to know these things.",
            "So the problem with strict convexity is that your Hessian has zero eigenvalues, and if you all of you know that if your matrix has zero eigenvalues, then.",
            "When you invert it, you can blow up."
        ],
        [
            "The estimate of your inverse, so we go back to the BFG is invariant and basically realized that the way be of GS maintains what's called the second equation, the HD plus one, which is the estimate of your Hessian at the new location Times St.",
            "The difference in your para meters is equal to the difference of your gradients."
        ],
        [
            "And what you do is you replace it with a trust region invariant, which is kind of pretty standard in optimization, but I just want to bring it up.",
            "So basically you maintain instead of maintaining the previous invariant you adero.",
            "Basically you shift the eigen spectrum by constant row is greater than 0."
        ],
        [
            "Then you maintain this invariant.",
            "What this changes is very little in the algorithm, except that you pick up arrow times SD term in your definition of YT, which is easy to see because you get H T + 1 * S T plus Rd times Estes, YT.",
            "So you just pick this up, but other than that the rest of the equation remains unchanged, so this."
        ],
        [
            "This is a beautiful thing.",
            "Now if you want to go one step further and say I want to be a few years but I want to work with non convex functions.",
            "The problem here is that your Hessian has negative eigenvalues and therefore your H inverse is not positive semidefinite.",
            "It's not even clear that."
        ],
        [
            "Exist and so on and so forth.",
            "You could do the trust region approach again and basically add a row and shift the whole spectrum app.",
            "But the problem with this is that you need to first of all you don't know what row to use because you have to shift everything up and you don't know abound on the largest negative eigenvalue and the other one is that it actually distorts curve."
        ],
        [
            "Which is kind of counterproductive.",
            "Another ad hoc solution could be that you go back to the B matrix update and you say, oh every time I'm using this S transpose YT in the update and if H is if the function is not convex then this quantity is negative answer.",
            "Therefore my updates get messed up.",
            "You can people try to just do this by adding the absolute value of the absolute value in the update and hoping and praying that everything works but."
        ],
        [
            "Sometimes it does, sometimes it doesn't, and finally the slightly more principled way to do this is that you maintain some kind of positive semidefinite approximations to the Hessian so you don't maintain the Hessian, but you maintain some kind of positive semidefinite approximations, and GT is some kind of a curvature measure.",
            "It's not the Hessian, but it's some kind of curvature measure.",
            "For instance, you could use a extended Gaussian approximation, or for instance the natural gradient approximation.",
            "Like you she was talking about in the morning.",
            "And again I want to.",
            "I want to point out that.",
            "You can have efficient implementations by using automatic differentiation."
        ],
        [
            "It's nothing to be worried about.",
            "Now let's go to the part where the exciting things that we're doing.",
            "So let's start with the with nonsmooth functions, and basically at the end of this, I'll show you how essentially, you can use LVS to train regular risk minimization with the hinge loss, which is non spoon, so that's that's where we're leading up to in this section.",
            "So what you do is the first thing you notice is that if your function is only sub differentiable, and then the problem is that you don't have a single gradient.",
            "You can have multiple gradients.",
            "A simple example is you take the hinge loss at the point the point many, many subgradients exist, so all of them are tangential to the function at that point and all of them are valid subgradients.",
            "So if you look at the set of all subgradients, it's called a sub differential and your problem is this sub differential is no longer a Singleton set, it has many."
        ],
        [
            "It's in this set.",
            "Actually, if you look at this sub differential, it satisfies a few good, bad and ugly."
        ],
        [
            "Probability says as I turn them.",
            "The first good properties at any location.",
            "If you look at this sub differential, it's a convex set.",
            "It's a very good property and you can use it."
        ],
        [
            "The bad thing is that if you pick an arbitrary subgradient, it's not a descent direction.",
            "So that's really bad news, because if you take a V, you're at the optimum.",
            "You get a pick.",
            "An arbitrary subgradient.",
            "Take a step in your out of optimum.",
            "Right, so not every subgradient is.",
            "Edison.",
            "Direction is kind of fun."
        ],
        [
            "Fortunate.",
            "And the ugly part is that you you can say that D is a different direction if and only if it lies in the normal cone to the entire convex set which defines the subdifferential.",
            "So this is kind of an very ugly condition, and it's not even clear how do you check if you give me if you give me a D, how do I characterize how do I find out all the subgradients and so on and so forth?",
            "So in general this seems like a pretty hopeless."
        ],
        [
            "Station.",
            "But it turns out that by slightly changing the model and by doing a few clever things, you can actually get around these problems.",
            "So the way we do that is let's start from the modeling assumption that albc makes.",
            "So every time it makes a quadratic model and then."
        ],
        [
            "It optimizes this model now of course the problem is that you have many models because you have subgradients and there are many many subgradients and so you can build many many different models among those models.",
            "Which ones to pick.",
            "Well, I say let's pick the one which is the tightest.",
            "So titles in terms of take the soup, overall subgradients.",
            "And let's pick this model.",
            "Of course, as you some of you who are alert would probably notice that immediately the model is no longer quadratic.",
            "It's only pseudo quadratic because it's essentially made up of piecewise linear parts with a quadratic part.",
            "So this is, this is something."
        ],
        [
            "To bear in mind, and as before I can go and minimize this model, I can minimize this function and try to find it."
        ],
        [
            "Indirection.",
            "Bystander tricking optimization, I can take my this linear part, just add an extra variable sign, and then add it to the constraint.",
            "So this is a standard trick in optimization.",
            "I can do this.",
            "I can take any anything in the objective function and make it a constraint by just adding one extra variable.",
            "But the key problem is this one.",
            "How do you find how do you characterize all the all the sub differentials in this set at a given point?"
        ],
        [
            "So let's let's say let's go and relax this problem right?",
            "So instead of enforcing it for all mu in this sub differential set, I don't force it only for a finite number of them.",
            "But if I pick an arbitrary arbitrary finite number of them, probably my estimates are not good.",
            "So I really need something which will ensure that I get a good decent direction, and that's what I'll show you.",
            "There's a way to pick these iterates."
        ],
        [
            "So just before that I just want to do a change of variables and write it out in some nicely familiar form.",
            "If you know about bundle methods, they should look very, very familiar to you is essentially nothing but a bundle method.",
            "It right.",
            "The only difference is that in bundle methods you take these subgradients at many different locations.",
            "Here you're always sampling, or you're taking the gradients subgradients at the same location of the function.",
            "So this is the key."
        ],
        [
            "They call that the Parimeter update before was that you did a 30 line search for ET and then this is how your direction look like.",
            "Now you can't directly do that because you don't."
        ],
        [
            "You don't have a gradient, but it turns out that you can do.",
            "Add find a decent direction by column generation or recently I was told by somebody from optimization that it's also called a constraint generation approach.",
            "So basically what you do is that you every time you come up with arbitrary decent direction, then you ask for give me the worst violating subgradient.",
            "Given that dissent direction, I must warn you that for an arbitrary convex nonsmooth function, this is not always possible, but for some of the some of the functions that we are interested in, for instance, mainly the hinge loss.",
            "This is always possible.",
            "I'll show you in a minute, but this is key and crucial.",
            "Then you go and say OK, let me find my next.",
            "Iterate by minimizing this function.",
            "But again, some of you might be wondering.",
            "This is kind of stupid because this is a QP an to find a different direction.",
            "You're solving.",
            "A QP doesn't make sense."
        ],
        [
            "Turns out that, well, you can.",
            "Actually, you don't need to solve QP.",
            "You can just find a decent direction by doing a line search.",
            "So it's like it's like a cheap man's version.",
            "It's like a poor man's version of solving the QP, and you can do a line search and you might be wondering, well, does this work?",
            "Is is theoretical."
        ],
        [
            "Blah blah blah.",
            "Actually it turns out that it is.",
            "It is actually well justified so you can.",
            "You can talk about rates of convergence and basically you can show that JK of D will actually converge to the true objective function.",
            "This is rates in the objective function value at order one or epsilon."
        ],
        [
            "So now that we have found a decent direction, let's concentrate on the next part, which is how do you do the line search, right?",
            "So again, as I said, you need to do the line search in order to find this step size.",
            "How much are you going to step?",
            "Generally if you look inside objc code align search is is called up to ensure water called.",
            "These are called equals conditions.",
            "There's another condition on top of this which is called a strong Wolf condition, but many of the line searches only fulfilled equals condition.",
            "So if you look at the vehicle.",
            "Conditions again, they have a gradient so I won't get too much into it, but essentially the two conditions ensure that a you don't take a very small step and B you at least decrease your objective function by certain values, so you don't want to just take, you know, stupid steps.",
            "This is how."
        ],
        [
            "The line searches obey.",
            "And it turns out that when you have subgradients again, you have to put an infant's soup and basically work with this.",
            "So this is kind of ugly, but again, for many of the loss functions that we want to work with, it's possib."
        ],
        [
            "So the the prototypical example that I want to use is essentially that of a hinge loss.",
            "Almost everybody here knows about the hinge loss.",
            "You have a square norm regularizer.",
            "You can add any regularizer, it doesn't matter.",
            "And the important thing is that you have a hinge and the hinge is not differentiable at the hinge points you have, you only have."
        ],
        [
            "Gradients turns out that you can do an exact line search.",
            "If I give you a direction of dissent, this becomes a quadratic function plus.",
            "Points at which piecewise linear parts are added, so there will be exactly points at which kinks will appear on the quadratic function, but essentially it's a quadratic function with kinks.",
            "Even better, you can actually exactly enumerate where the Kings will occur, and basically what you do is you first figure out at which locations the Kings are going to occur.",
            "You sort them, and then you just walk through them, and you can essentially find out you keep your function values going on.",
            "Going down, you keep on walking down the Kings and at the first point when your function value starts going up, you know that the optimum is between those two brackets and between those two brackets it's a.",
            "It's a convex, it's a QP, it's a quadratic.",
            "Which can be solved exactly, so you can actually do an exact line search."
        ],
        [
            "The other thing is that how do you find this interaction which is violating a given direction?",
            "It's again very easy because basically if you look at the gradient, the subgradient, they look like summation of some coefficients times XI.",
            "So essentially you just do XI times DK and if it is positive then you set the coefficients to be the highest value that they can take the highest positive value that they can take.",
            "And if the coefficients are negative, you said the coefficients to be the lowest value that these.",
            "Can take in this case it's zero, so you just kill them so."
        ],
        [
            "Can find the descent direction very easily, so just to get a picture of how this works here is, and here is a function that I'm trying to visualize, so this is a piece of paper folded into four but with A twist.",
            "The twist being there is a lot of curvature along this direction.",
            "It's twisted very highly here, but there's very little curvature along this direction, so on one along 1 axis it has 100 times more curvature than the other axis on."
        ],
        [
            "A simple problem.",
            "Let's try to run BF's and see what happens.",
            "Well, it essentially starts from, so this is looking up the value.",
            "So this is what is plotted here is you're looking from the top, so you start from here you take a step, you go to the other side.",
            "You oscillate a little bit, and then you figure out you never reach the optimum."
        ],
        [
            "You could try a slightly smarter version of this by saying, oh, I know I have hinges, so how about this that whenever I do a line search I push myself out of the hinges and keep away from the hinges.",
            "Turns out that again, you can actually converge, but it takes a long long time to converge."
        ],
        [
            "On the other hand.",
            "If you do an exact line search and find this different direction, you can converge into iterations.",
            "So basically what happens is you start from this point, you get a gradient direction you take in step and then you can do an exact line search so you land exactly on the hinge.",
            "So now you're on the hinge and Ann at the hinge point.",
            "You can get many different sub gradients, but essentially what happens?",
            "Is it because you're doing this column generation, you get the first subgradient, it's not a direction of dissent.",
            "Then you get a second subgradient.",
            "You take a convex combination of them and it always turns out that in two iterations you can find the direction of.",
            "So you find the direction of dissent again, you can do an exact line search so you slide along the hinge and you are at the solution 2 steps.",
            "You might be wondering, this is a type problem.",
            "How does it actually work in practice?",
            "Well."
        ],
        [
            "Let's see it.",
            "Here it is on writers.",
            "Large number of examples.",
            "Large number of dimensions and a very small regularizer, so I must point out that if you look at bundle methods they have really problems when the regularizer is very small, because the hinge is really dominate an almost all optimizers have problems in the regularizer is very small.",
            "This is common.",
            "So here I'm plotting the number of function evaluations it takes to reach reach to reduce the objective function value for different for different optimizers.",
            "And one thing to note is that be FGS also converges.",
            "Just plain BF's also converges on this really large on this really large problem.",
            "The problem is when BF GS works, it works beautifully, but when it fails it fails catastrophically because.",
            "There might be cases when you just land on the hinge.",
            "NBS completely fails to converge.",
            "On the other hand, what we do is basically it always converges.",
            "So here the black line is is bundled methods.",
            "So bundle methods also try to optimize the same problem, but the way they do it is philosophically different.",
            "They use these gradients to build a lower bound for the function and the optimized the lower bound at every step.",
            "So this is fundamentally different from the way LB FTS orbs is using the gradient information because it's using it to estimate curvature.",
            "And then taking a step again.",
            "Another noteworthy thing is that initially we make a lot of progress as compared to the bundle methods, but closer to the optimum we essentially the same as the rate of progress is similar to bundle methods.",
            "You might be wondering why this is and sort of these are really hot of the press results is just one or two days old and one of my conjectures is that initially it really helps you to make a quadratic ball approximation because you can slide and jump over many many hinges, but when you go close to the solution.",
            "Change is really, really matter.",
            "You must know where the hinges are and how to slide to the solution, so therefore it really makes sense to know and cut the hinges and then go to the solution like the bundle methods do while BF DS is still trying to make this quadratic approximation which might not be true or which may not be valid close to the hinge, so it takes a longer time to converge.",
            "This is a picture which I call the bank for the Buck picture which says how much CPU time you expand versus how do you decrease your objective function and again.",
            "We're pretty competitive initially and then later on, yeah.",
            "Training or test.",
            "So this is just the objective function value.",
            "No no, no error.",
            "This is just.",
            "I'm only an optimizer.",
            "Sorry yeah this on the training set so I'm an optimizer.",
            "I don't care about errors."
        ],
        [
            "Training and tests.",
            "And again, similar kind of results menu."
        ],
        [
            "I read the regularizer."
        ],
        [
            "And also on the KDD Cup with a few million 4 million examples.",
            "Again similar kind of resume."
        ],
        [
            "So."
        ],
        [
            "I won't get into them.",
            "Now, let's go.",
            "So now we all talked about batch we said oh what happens when it's not convex?",
            "And what happens when your function is not smooth?",
            "Let's do one more relaxation and let's try to work with online methods.",
            "So now at the end of this basically I'll try to show you how you can come up with how you can systematically fix buges to work in an online setting.",
            "An some of the results that we have for machine learning problems in this context.",
            "So now to make things on line, you might just again start with your parameter update and."
        ],
        [
            "Well, the simplest thing to do is you say, OK, I don't have the true gradient, but.",
            "I can get an instantaneous gradient again.",
            "One thing to note here is that I always write that this is a gradient, but a subgradient will suffice.",
            "So it's just to keep notation simple.",
            "Eyes you always say instantaneous gradient, but keep in mind that subgradient would suffice.",
            "I get an instant instantaneous gradient and many people have tried this in this at all.",
            "Yes, so that's yeah, yeah, yeah.",
            "So, actually Nonsmooth doesn't matter for online exactly because you keep bouncing stochastically around.",
            "So basically you get this.",
            "You get this instantaneous gradient and you might say, well, let me just use this instantaneous gradient, run the BS update and pray that everything works.",
            "People have tried this."
        ],
        [
            "Network.",
            "So first thing is, how do you do a line search?",
            "Thank you only have instantaneous gradient.",
            "You don't know how to do a line search, so typically."
        ],
        [
            "Instead of this step size which you used to find by line, search here to replace it with a gain schedule.",
            "Typically you can just do a simple game schedule, or you can be fancy and do some kind of gain adaptation.",
            "These are steps adaptation methods which can which can give you a good."
        ],
        [
            "Websites to take.",
            "Then let's dissect the Matrix update and see what happens.",
            "So clearly here YT you don't.",
            "You can no longer do this because you don't have full."
        ],
        [
            "Radiance.",
            "So your first attempt might be to say, oh, let me just take the sub gradient and gradient and sample it at XD and XD plus one.",
            "Again, if you try this, this doesn't work.",
            "This is a key crucial point and this took us a while to figure out, but this doesn't work, mainly because you're introducing a sampling noise, you're not getting the gradients at the same location.",
            "You're sampling the gradient at two different locations, both of which are coming to you by stochastic process.",
            "So you're introducing sampling noise into your process, so if you estimate your YT by doing this, it does not work."
        ],
        [
            "You have to.",
            "You have to essentially.",
            "Get your gradients.",
            "Your instantaneous gradients must be sampled at the same location, which also means that what you need to do is to store your data for one step.",
            "So you use your data at time T and your updates at time T + 1.",
            "So you need to store your data for one step.",
            "That is that surprise.",
            "You need to pay for this."
        ],
        [
            "Then the other problem that happens is that, let's say you're training with a CRF just as a Canonical example.",
            "Now you have lots and lots of features.",
            "Many, it's a very sparse feature vector, and on certain dimensions you'll never see any gradient until you've seen a large number of data points.",
            "So what happens is that blows up your H inverse estimate because basically your hedges rank deficient because you never see gradients along any any along many of these coordinates, and so to ensure that you don't overstep, you have to add a trust region parameter.",
            "This again, is in."
        ],
        [
            "Written in the online context.",
            "And so again, as I said before, if you add the rule you get this row times."
        ],
        [
            "Do you pick up this time and finally, if you look at the update formula?",
            "You need to do."
        ],
        [
            "You need to do one small change there, so since you're in an online setting, you had really really guard against a bad example.",
            "So if you get a really bad example which forces you to take a large step and to completely make your estimate going haywire, you had to guard against that.",
            "So essentially you guard against it by adding small constant.",
            "See here, which is less than one.",
            "But that also means you do.",
            "You pick up a 1 / C term.",
            "Here I put this in magenta and not in blue or red, because we really, really don't fully understand why this is needed.",
            "On some problems it just does not converge without this, and on some problems it does and the explanation that I gave you is the best kind of explanation that I have.",
            "So if you have some more intuition, please come and talk."
        ],
        [
            "I mean, I'd love to talk about it.",
            "So putting all these things together, you have the online beefs algorithm.",
            "So basically we have systematically taken VFD S. Looked at what happens when you do online, fixed each one of them.",
            "And here is here is our algorithm."
        ],
        [
            "Again, you must be wondering how does it perform well?",
            "Here are some performance curves, so basically this is plain elves on training conditional random fields.",
            "This is on the Kernel 2002, base NP, chunking tasks.",
            "Same setup as I see ML 2006 paper.",
            "The problem is really high dimensional, lots of sparse features.",
            "It is smooth because you're working with the log likelihood knows and it's convex, but it's asymptotically I'll condition in the sense that although you're taking the log some X.",
            "Basically the lock some X starts placing weights on only a small number of of labels, and so it almost starts behaving like a Max instead of being a softmax, and so it's asymptotically condition and here are results of SMD stepsize adaptation method.",
            "It is generally finicky, has a lot of things to tune this, and then these are two different versions of online LB FTS, one with the one over TDK and one where you use SMD.",
            "To update the step size and the SMB version seems to perform slightly better here and here.",
            "Just on the KDD Cup again, and you're doing SVM training in the primal, and again, it's not convex.",
            "Yep.",
            "Number.",
            "It's a number of updates, so the number of data points you see.",
            "And here again, this is a.",
            "This is a large data set.",
            "Again we showed you some experiments before with that and.",
            "And you can clearly see that online BFT is just with the one over TDK.",
            "Here seems to reduce the objective function quite well."
        ],
        [
            "He is it so.",
            "So here it was going up again because."
        ],
        [
            "Oh, actually.",
            "No, this is this is the true objective of the batch training, and then it's going up because you're stochastic, so.",
            "You're only seeing part of the data and you're only getting aggregating partial information.",
            "No, you don't know you haven't seen the full data set, so you don't know how to compute the objective.",
            "So you could compute with.",
            "Yeah, so this is.",
            "This is the instantaneous objective."
        ],
        [
            "Plugged in and here is a is a simple neural network task.",
            "If you're a deep believer, this is probably not deep enough, but.",
            "Here is a task where you have to predict the color of the carpet.",
            "The inputs are the coordinates of the points.",
            "There's a two layer input 10 layer thin layer, hidden output and then there are four nodes which gets switched on based on which color of the carpet and.",
            "This is smooth, but highly nonconvex and very ill conditioned problem.",
            "And here you can see that if you do, online VFS with SMD initially it seems too.",
            "It seems to reduce the loss quite a bit, but asymptotically, online VFS by just setting the by reducing the step size.",
            "Taking it in a way."
        ],
        [
            "Noriti fashion seems to be better.",
            "And finally, I won't spend a lot of time on this, but basically let us think about how we can lift this whole thing into our cages.",
            "And here I want to just quickly flash these equations.",
            "I'll tell you where the deepness is.",
            "The initial part is not very deep."
        ],
        [
            "Basically what happens is the BFG is updates, as you recall, have two two stages at one stage.",
            "How to compute the inverse and the other stage here to actually do the parimeter updates?"
        ],
        [
            "So the way."
        ],
        [
            "LB of DS does it is it reduces this into two loops.",
            "It maintains K vectors and every time it essentially inverts this K dimensional key rank matrix and then it updates its parameters.",
            "So the 1st loop is easy for inverting the matrix and the 2nd loop is essentially for finding that."
        ],
        [
            "And of this, and then you actually."
        ],
        [
            "Update your parameters then you."
        ],
        [
            "To estimate your YT, which is nothing but the difference of the gradients and so on and so forth.",
            "But the key."
        ],
        [
            "Mission is that.",
            "If you look at the LB FTS, you know.",
            "Pseudocode this is standard pseudocode from Nocedal and Wright.",
            "Basically the key observation is that you only using inner product and linear combinations and both of which we know can be lifted into another catches.",
            "So this is kind of E."
        ],
        [
            "Easy observation, and so if you want to lift it into an arcade as immediately you can say oh instead of instead of maintaining a buffer of lost key values of function values.",
            "Now instead of functions in another cages instead of maintaining vectors in R to the N. Answer You right out the dot product San.",
            "This is how it looks like, but there's a problem.",
            "The problem is that if you actually really need to compute these dot products explicitly in the Dark Ages, essentially you end up picking a kernel matrix.",
            "So what happens is that all the functions that you have are represented as linear combinations, so you're maintaining the dual dual para meters and then you have the kernel and then you have the dual parameter.",
            "So essentially these all these dot products would look something like Alpha S transpose.",
            "Could K times, Alpha, S and so on and so on.",
            "This kind of is very expensive, and if you're aggregating parameters as you're going online.",
            "Things get very."
        ],
        [
            "Nothing.",
            "To prevent that from happening, what you can do is that you can say OK, let me let me first do this whole thing in an online fashion, but then I do this in this online fashion.",
            "I said I can keep on aggregating terms and if I keep on aggregating terms, my dual coefficients will keep on growing unbounded and things."
        ],
        [
            "Then go completely haywire.",
            "Turns out that there are.",
            "Ways to do cheap updates of this dual parameters and you can do them exactly and maintain.",
            "You had to maintain some secondary parameters, but you maintain the secondary parameters and you can update them in a very cheap way in essentially linear time.",
            "So this is basically think of stochastic gradient descent in in the kernel space.",
            "But now instead of stochastic gradient descent you essentially doing online LVL."
        ],
        [
            "Here are some results on amnist with this so online SVM is essentially stochastic gradient descent in our cases.",
            "FMD is is our algorithm which uses SMD to do steps adaptation in stochastic online learning in in their cages and here is how our online kernel version of ALB performs.",
            "And here is a comparison with Pegasus which is essentially stochastic gradient descent.",
            "Again except with a different learning rates.",
            "So the online SVM uses a one over square root.",
            "The learning rate, while Pegasus uses 1 / T learning rate.",
            "I must admit that.",
            "We didn't really try very hard to optimize the parameters of the of the competing algorithms, and here is a particularly evil sequence.",
            "If you are doing online learning is that you get we took digits from Miss Ann.",
            "You order them so that you get 000001002 and so on.",
            "So initially you get a lot of zeros and then closer to the end you get 9999899.",
            "So you see a lot of lines, so the distribution is non stationary and changes with time.",
            "Most online algorithms will have trouble with this.",
            "Online SVM completely is not able to manage this FMD kind of gets along, but the online kernel LB FT is actually manage is to perform quite well on this."
        ],
        [
            "And finally, to conclude, I've showed you how to systematically relax some of the assumptions underlying assumptions of BFG S and hopefully make it more applicable to some of the machine learning problems that we have.",
            "I believe that these are only exciting early results.",
            "We are still.",
            "There's still a lot more to do.",
            "We're working towards it.",
            "We would love to have feedback, comments, people who want to jump in and help us and work with us.",
            "Please feel free to do so.",
            "There's a lot of things more to do and I want to leave you with a little open problem which is been bothering me for the last few days is in the case of the hinge loss in the binary hinge loss.",
            "Given a search direction, I can exactly find an do align search.",
            "I can do a line search and find the exact minimum an if I land on a hinge.",
            "I know exactly where I land.",
            "If I give you a direction of dissent in a structure estimation problem, can you do a line search for me?",
            "It is also a piecewise linear function.",
            "The only problem is that the number of pieces the piece linear pieces could be exponentially large, and I don't know how to do a line search with that function without evaluating the function or without spending too much time.",
            "So if you have any ideas on that, please come and talk to me.",
            "That's all I have to say.",
            "Thank you very much.",
            "And finally, I'd actually like to acknowledge Galion for some of the exciting discussions we had on on this sub.",
            "Gives some of the ideas that about subgraphs.",
            "Thanks.",
            "Yep yeah.",
            "I mean, LB of gears are behaviors in general, is pretty robust and some the problem does occur.",
            "If suppose you have zero eigenvalues or sometimes if you have those X transpose Y is negative.",
            "Then we see that it doesn't converge.",
            "I mean it might converge.",
            "Yeah, if it satisfies the Wolf conditions.",
            "Yeah, yeah.",
            "Well, maybe sexy to solve your problem.",
            "There's.",
            "I'd love to know more about them.",
            "In the online version of your outlook, do you need to solve a column generation problem on every single minute?",
            "No, not in the online version, because basically what happens is because you're stochastic.",
            "You sort of bounce around, so even if you land on a hinge, it's bad luck.",
            "Tough luck, but next time you just get out of it and get on with life, but in the batch you really, really have to do column generation.",
            "The gradient.",
            "Epsilon.",
            "Yes.",
            "It's it's the rates for the decent direction.",
            "Finding it is not the rates of the overall algorithm.",
            "This is only for the different direction finding and the rates are in terms of that objective function that I wrote out that pseudo quadratic objective function that I wrote out.",
            "You have rates for, how fast will that JK which was the approximation, the Cath step approximation converge to the true objective function.",
            "The true pseudo quadratic objective function, so those one over epsilon rates are.",
            "Rates in convergence in the in the objective function value not then not for the overall.",
            "No, not yet.",
            "I mean, I think the best we can do this is again pretty hot off the press.",
            "As I said, these results just came out yesterday or day before the plots that I showed you.",
            "I think.",
            "I mean, this is my belief that you can use the normal bgcse rates to prove that it will converge, but I don't think we can get rates.",
            "OK thanks."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Thank you very much.",
                    "label": 0
                },
                {
                    "sent": "So my name is SVN Vishwanathan and this is joint work with a number of people, mainly next trade off my friend and colleague Simon Ginter postdoc Gene.",
                    "label": 1
                },
                {
                    "sent": "You or my PhD student Peterson hunger postdoc in your control for colleague?",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "A lot of what I'm going to talk about today is about these four gentlemen in 1970.",
                    "label": 0
                },
                {
                    "sent": "Within a span of one year, the four of them invented an algorithm which is now named in their honor called The BFG S algorithm.",
                    "label": 0
                },
                {
                    "sent": "BF GS is basically the the black box algorithm that you want to use for unconstrained smooth, convex nonlinear optimization.",
                    "label": 0
                },
                {
                    "sent": "So essentially if you call optimize in Matlab.",
                    "label": 0
                },
                {
                    "sent": "By default it calls this algorithm that they invented and they amaze.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Thing is that all four of them invented the algorithm independent of each other and published it in four different journals independent of each other, so.",
                    "label": 0
                },
                {
                    "sent": "It's just a bit of trivia.",
                    "label": 0
                },
                {
                    "sent": "Now, let's start and look at how the FDS actually works.",
                    "label": 0
                },
                {
                    "sent": "It's conceptually it's a very, very simple algorithm, So what you do is at every time step you make a quadratic approximation to your function at your current rate 30.",
                    "label": 0
                },
                {
                    "sent": "So you get the gradient and then you get the Hessian.",
                    "label": 0
                },
                {
                    "sent": "And this is just the 2nd order Taylor approximation.",
                    "label": 0
                },
                {
                    "sent": "And of course it's very expensive to compute the true Hessian.",
                    "label": 0
                },
                {
                    "sent": "So what it does is it maintains an end by an estimate of the Hessian.",
                    "label": 1
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And to find the next iterate, you do the most obvious thing which is you just go and minimize this quadratic function.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "If you, if you think about it for 30 seconds, it's very easy to convince yourself that the parimeter update essentially looks like this.",
                    "label": 0
                },
                {
                    "sent": "So here BT is the inverse of the Hessian of the estimate of your Hessian, an typically notice that we're not taking a full step.",
                    "label": 1
                },
                {
                    "sent": "So if you just minimize this blindly, you would've said either T to be one, but generally in VFS you'd also do align search, so you would find a direction and the direction being B times the gradient of FT, and then you do a line search.",
                    "label": 0
                },
                {
                    "sent": "Along that direction, so you have a 1 dimensional convex function and you minimize that function along that line and you take a step.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The question that probably is burning in your mind is how do you actually update this be matrix or this Hessian matrix.",
                    "label": 0
                },
                {
                    "sent": "So in the night it kind of seems trivial in hindsight, but in the 1970s when they actually invented this algorithm, the big breakthrough was the fact that instead of maintaining the Hessian like all the other algorithms, who do an updating, the Hessian and inverting it at every step to find and iterate VFD S does something smart, it directly maintains the inverse of the Hessian.",
                    "label": 0
                },
                {
                    "sent": "The way it maintains the Hessian is inverse of the Hessian is by saying it doesn't want to move too far away from the current iterate, and it maintains a condition.",
                    "label": 0
                },
                {
                    "sent": "This condition is called the second condition.",
                    "label": 0
                },
                {
                    "sent": "And estimated.",
                    "label": 0
                },
                {
                    "sent": "So this is a constraint, so you minimize be subject to this constraint.",
                    "label": 0
                },
                {
                    "sent": "So at every time step this is an invariant that's maintained, so the algorithm always maintained.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The scenario where Whitey is nothing but the difference of the gradients and St is the difference in the parameters.",
                    "label": 1
                },
                {
                    "sent": "The W is chosen.",
                    "label": 0
                },
                {
                    "sent": "It's a weighted for business Norm, which you're minimizing, and EW is chosen.",
                    "label": 0
                },
                {
                    "sent": "It's essentially black art.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And to me, the most amazing thing is that all four of them essentially did the same black art independent of each other and the way the W is chosen is to ensure that the BT plus one your next iterate is essentially a projection of your current version of your current inverses in estimate plus a rank 1 update.",
                    "label": 0
                },
                {
                    "sent": "So it's a rank 2 update.",
                    "label": 0
                },
                {
                    "sent": "You can do it efficiently and you can you can employ all your numerical linear algebra tricks today.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This efficiently then in 93 or 94 I believe Nocedal.",
                    "label": 0
                },
                {
                    "sent": "His coworkers came up with a limited memory variant of it, so instead I said oh instead of maintaining this entire Hessian, which is NBN matrix, what if I only maintain K columns of it?",
                    "label": 0
                },
                {
                    "sent": "So if I maintain a key rank approximation, how does it perform so essentially for the rest of this talk, I'll always talk about drugs, but keep in the back of your mind that whatever we do with BFG, S can also be done with limited memory variant.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So before going ahead, I want to talk about the underlying or unstated assumptions that BSS makes, so the first unstated assumption is that the objective function is always strictly.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Mix.",
                    "label": 0
                },
                {
                    "sent": "Of course, we know that when we are looking at when you're where they're coming from, the deep belief net cloud, or if your follower of what you answer is well, you should keep away from convex loss functions and many of the things that we deal with a non convex.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The other assumption is that the objective function is smooth, which means the gradients exist.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Of course everybody knows that if you say for instance, do regularised risk minimization and use the hinge loss at the hinge points, your objective function is not smooth, it has.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Subgradients the other assumption is that you have batch gradient, so which means that you can compute the gradient of your entire objective function and then you can.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Step which of course is probably expensive when you're working with large datasets.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And finally, there is an assumption, of course, or the way I presented it is that the parameter vector is always in finite dimensions.",
                    "label": 0
                },
                {
                    "sent": "It's in our.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Vector, but again, if you're working with kernel algorithms, you could have you could be working in a potentially infinite dimensional arcade.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the aim of this dog and pretty much the aim of a lot of people in the group that I work with, is essentially to try and systematically relax these assumptions and to go further and actually make VFD S applicable to many of these machine learning problems.",
                    "label": 1
                },
                {
                    "sent": "So some of these assumptions really prevent you from applying the FTS, which is which is basically the state of the art solver to some of the problems or obvious problems in machine learning and hopefully by relaxing some of them will make it more applicable to machine learning.",
                    "label": 0
                },
                {
                    "sent": "So this is the.",
                    "label": 0
                },
                {
                    "sent": "This is the.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Are all picture.",
                    "label": 0
                },
                {
                    "sent": "So let's start by relaxing the strict convexity assumption.",
                    "label": 0
                },
                {
                    "sent": "So here basically what I'll do is give you a quick overview of how we can relax strict convexity.",
                    "label": 0
                },
                {
                    "sent": "A lot of this stuff of relaxing strict convexity.",
                    "label": 1
                },
                {
                    "sent": "Convexity is not just our work, it's just part of folklore, but I just want to bring it out to people in this workshop because many of us are practitioners and we want to actually applied, and I think it's important to know these things.",
                    "label": 0
                },
                {
                    "sent": "So the problem with strict convexity is that your Hessian has zero eigenvalues, and if you all of you know that if your matrix has zero eigenvalues, then.",
                    "label": 1
                },
                {
                    "sent": "When you invert it, you can blow up.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The estimate of your inverse, so we go back to the BFG is invariant and basically realized that the way be of GS maintains what's called the second equation, the HD plus one, which is the estimate of your Hessian at the new location Times St.",
                    "label": 0
                },
                {
                    "sent": "The difference in your para meters is equal to the difference of your gradients.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And what you do is you replace it with a trust region invariant, which is kind of pretty standard in optimization, but I just want to bring it up.",
                    "label": 0
                },
                {
                    "sent": "So basically you maintain instead of maintaining the previous invariant you adero.",
                    "label": 0
                },
                {
                    "sent": "Basically you shift the eigen spectrum by constant row is greater than 0.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Then you maintain this invariant.",
                    "label": 0
                },
                {
                    "sent": "What this changes is very little in the algorithm, except that you pick up arrow times SD term in your definition of YT, which is easy to see because you get H T + 1 * S T plus Rd times Estes, YT.",
                    "label": 0
                },
                {
                    "sent": "So you just pick this up, but other than that the rest of the equation remains unchanged, so this.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is a beautiful thing.",
                    "label": 0
                },
                {
                    "sent": "Now if you want to go one step further and say I want to be a few years but I want to work with non convex functions.",
                    "label": 0
                },
                {
                    "sent": "The problem here is that your Hessian has negative eigenvalues and therefore your H inverse is not positive semidefinite.",
                    "label": 0
                },
                {
                    "sent": "It's not even clear that.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Exist and so on and so forth.",
                    "label": 0
                },
                {
                    "sent": "You could do the trust region approach again and basically add a row and shift the whole spectrum app.",
                    "label": 0
                },
                {
                    "sent": "But the problem with this is that you need to first of all you don't know what row to use because you have to shift everything up and you don't know abound on the largest negative eigenvalue and the other one is that it actually distorts curve.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Which is kind of counterproductive.",
                    "label": 0
                },
                {
                    "sent": "Another ad hoc solution could be that you go back to the B matrix update and you say, oh every time I'm using this S transpose YT in the update and if H is if the function is not convex then this quantity is negative answer.",
                    "label": 0
                },
                {
                    "sent": "Therefore my updates get messed up.",
                    "label": 0
                },
                {
                    "sent": "You can people try to just do this by adding the absolute value of the absolute value in the update and hoping and praying that everything works but.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Sometimes it does, sometimes it doesn't, and finally the slightly more principled way to do this is that you maintain some kind of positive semidefinite approximations to the Hessian so you don't maintain the Hessian, but you maintain some kind of positive semidefinite approximations, and GT is some kind of a curvature measure.",
                    "label": 0
                },
                {
                    "sent": "It's not the Hessian, but it's some kind of curvature measure.",
                    "label": 1
                },
                {
                    "sent": "For instance, you could use a extended Gaussian approximation, or for instance the natural gradient approximation.",
                    "label": 1
                },
                {
                    "sent": "Like you she was talking about in the morning.",
                    "label": 0
                },
                {
                    "sent": "And again I want to.",
                    "label": 0
                },
                {
                    "sent": "I want to point out that.",
                    "label": 1
                },
                {
                    "sent": "You can have efficient implementations by using automatic differentiation.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "It's nothing to be worried about.",
                    "label": 0
                },
                {
                    "sent": "Now let's go to the part where the exciting things that we're doing.",
                    "label": 0
                },
                {
                    "sent": "So let's start with the with nonsmooth functions, and basically at the end of this, I'll show you how essentially, you can use LVS to train regular risk minimization with the hinge loss, which is non spoon, so that's that's where we're leading up to in this section.",
                    "label": 0
                },
                {
                    "sent": "So what you do is the first thing you notice is that if your function is only sub differentiable, and then the problem is that you don't have a single gradient.",
                    "label": 0
                },
                {
                    "sent": "You can have multiple gradients.",
                    "label": 0
                },
                {
                    "sent": "A simple example is you take the hinge loss at the point the point many, many subgradients exist, so all of them are tangential to the function at that point and all of them are valid subgradients.",
                    "label": 0
                },
                {
                    "sent": "So if you look at the set of all subgradients, it's called a sub differential and your problem is this sub differential is no longer a Singleton set, it has many.",
                    "label": 1
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It's in this set.",
                    "label": 0
                },
                {
                    "sent": "Actually, if you look at this sub differential, it satisfies a few good, bad and ugly.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Probability says as I turn them.",
                    "label": 0
                },
                {
                    "sent": "The first good properties at any location.",
                    "label": 0
                },
                {
                    "sent": "If you look at this sub differential, it's a convex set.",
                    "label": 0
                },
                {
                    "sent": "It's a very good property and you can use it.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The bad thing is that if you pick an arbitrary subgradient, it's not a descent direction.",
                    "label": 1
                },
                {
                    "sent": "So that's really bad news, because if you take a V, you're at the optimum.",
                    "label": 0
                },
                {
                    "sent": "You get a pick.",
                    "label": 0
                },
                {
                    "sent": "An arbitrary subgradient.",
                    "label": 0
                },
                {
                    "sent": "Take a step in your out of optimum.",
                    "label": 0
                },
                {
                    "sent": "Right, so not every subgradient is.",
                    "label": 1
                },
                {
                    "sent": "Edison.",
                    "label": 0
                },
                {
                    "sent": "Direction is kind of fun.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Fortunate.",
                    "label": 0
                },
                {
                    "sent": "And the ugly part is that you you can say that D is a different direction if and only if it lies in the normal cone to the entire convex set which defines the subdifferential.",
                    "label": 1
                },
                {
                    "sent": "So this is kind of an very ugly condition, and it's not even clear how do you check if you give me if you give me a D, how do I characterize how do I find out all the subgradients and so on and so forth?",
                    "label": 0
                },
                {
                    "sent": "So in general this seems like a pretty hopeless.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Station.",
                    "label": 0
                },
                {
                    "sent": "But it turns out that by slightly changing the model and by doing a few clever things, you can actually get around these problems.",
                    "label": 1
                },
                {
                    "sent": "So the way we do that is let's start from the modeling assumption that albc makes.",
                    "label": 1
                },
                {
                    "sent": "So every time it makes a quadratic model and then.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "It optimizes this model now of course the problem is that you have many models because you have subgradients and there are many many subgradients and so you can build many many different models among those models.",
                    "label": 0
                },
                {
                    "sent": "Which ones to pick.",
                    "label": 0
                },
                {
                    "sent": "Well, I say let's pick the one which is the tightest.",
                    "label": 0
                },
                {
                    "sent": "So titles in terms of take the soup, overall subgradients.",
                    "label": 0
                },
                {
                    "sent": "And let's pick this model.",
                    "label": 0
                },
                {
                    "sent": "Of course, as you some of you who are alert would probably notice that immediately the model is no longer quadratic.",
                    "label": 1
                },
                {
                    "sent": "It's only pseudo quadratic because it's essentially made up of piecewise linear parts with a quadratic part.",
                    "label": 1
                },
                {
                    "sent": "So this is, this is something.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To bear in mind, and as before I can go and minimize this model, I can minimize this function and try to find it.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Indirection.",
                    "label": 0
                },
                {
                    "sent": "Bystander tricking optimization, I can take my this linear part, just add an extra variable sign, and then add it to the constraint.",
                    "label": 0
                },
                {
                    "sent": "So this is a standard trick in optimization.",
                    "label": 0
                },
                {
                    "sent": "I can do this.",
                    "label": 0
                },
                {
                    "sent": "I can take any anything in the objective function and make it a constraint by just adding one extra variable.",
                    "label": 0
                },
                {
                    "sent": "But the key problem is this one.",
                    "label": 0
                },
                {
                    "sent": "How do you find how do you characterize all the all the sub differentials in this set at a given point?",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So let's let's say let's go and relax this problem right?",
                    "label": 0
                },
                {
                    "sent": "So instead of enforcing it for all mu in this sub differential set, I don't force it only for a finite number of them.",
                    "label": 0
                },
                {
                    "sent": "But if I pick an arbitrary arbitrary finite number of them, probably my estimates are not good.",
                    "label": 0
                },
                {
                    "sent": "So I really need something which will ensure that I get a good decent direction, and that's what I'll show you.",
                    "label": 0
                },
                {
                    "sent": "There's a way to pick these iterates.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So just before that I just want to do a change of variables and write it out in some nicely familiar form.",
                    "label": 0
                },
                {
                    "sent": "If you know about bundle methods, they should look very, very familiar to you is essentially nothing but a bundle method.",
                    "label": 0
                },
                {
                    "sent": "It right.",
                    "label": 0
                },
                {
                    "sent": "The only difference is that in bundle methods you take these subgradients at many different locations.",
                    "label": 0
                },
                {
                    "sent": "Here you're always sampling, or you're taking the gradients subgradients at the same location of the function.",
                    "label": 0
                },
                {
                    "sent": "So this is the key.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "They call that the Parimeter update before was that you did a 30 line search for ET and then this is how your direction look like.",
                    "label": 0
                },
                {
                    "sent": "Now you can't directly do that because you don't.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You don't have a gradient, but it turns out that you can do.",
                    "label": 0
                },
                {
                    "sent": "Add find a decent direction by column generation or recently I was told by somebody from optimization that it's also called a constraint generation approach.",
                    "label": 0
                },
                {
                    "sent": "So basically what you do is that you every time you come up with arbitrary decent direction, then you ask for give me the worst violating subgradient.",
                    "label": 0
                },
                {
                    "sent": "Given that dissent direction, I must warn you that for an arbitrary convex nonsmooth function, this is not always possible, but for some of the some of the functions that we are interested in, for instance, mainly the hinge loss.",
                    "label": 0
                },
                {
                    "sent": "This is always possible.",
                    "label": 0
                },
                {
                    "sent": "I'll show you in a minute, but this is key and crucial.",
                    "label": 0
                },
                {
                    "sent": "Then you go and say OK, let me find my next.",
                    "label": 0
                },
                {
                    "sent": "Iterate by minimizing this function.",
                    "label": 0
                },
                {
                    "sent": "But again, some of you might be wondering.",
                    "label": 0
                },
                {
                    "sent": "This is kind of stupid because this is a QP an to find a different direction.",
                    "label": 0
                },
                {
                    "sent": "You're solving.",
                    "label": 0
                },
                {
                    "sent": "A QP doesn't make sense.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Turns out that, well, you can.",
                    "label": 0
                },
                {
                    "sent": "Actually, you don't need to solve QP.",
                    "label": 0
                },
                {
                    "sent": "You can just find a decent direction by doing a line search.",
                    "label": 0
                },
                {
                    "sent": "So it's like it's like a cheap man's version.",
                    "label": 0
                },
                {
                    "sent": "It's like a poor man's version of solving the QP, and you can do a line search and you might be wondering, well, does this work?",
                    "label": 0
                },
                {
                    "sent": "Is is theoretical.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Blah blah blah.",
                    "label": 0
                },
                {
                    "sent": "Actually it turns out that it is.",
                    "label": 0
                },
                {
                    "sent": "It is actually well justified so you can.",
                    "label": 0
                },
                {
                    "sent": "You can talk about rates of convergence and basically you can show that JK of D will actually converge to the true objective function.",
                    "label": 1
                },
                {
                    "sent": "This is rates in the objective function value at order one or epsilon.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So now that we have found a decent direction, let's concentrate on the next part, which is how do you do the line search, right?",
                    "label": 0
                },
                {
                    "sent": "So again, as I said, you need to do the line search in order to find this step size.",
                    "label": 0
                },
                {
                    "sent": "How much are you going to step?",
                    "label": 0
                },
                {
                    "sent": "Generally if you look inside objc code align search is is called up to ensure water called.",
                    "label": 0
                },
                {
                    "sent": "These are called equals conditions.",
                    "label": 0
                },
                {
                    "sent": "There's another condition on top of this which is called a strong Wolf condition, but many of the line searches only fulfilled equals condition.",
                    "label": 0
                },
                {
                    "sent": "So if you look at the vehicle.",
                    "label": 0
                },
                {
                    "sent": "Conditions again, they have a gradient so I won't get too much into it, but essentially the two conditions ensure that a you don't take a very small step and B you at least decrease your objective function by certain values, so you don't want to just take, you know, stupid steps.",
                    "label": 0
                },
                {
                    "sent": "This is how.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The line searches obey.",
                    "label": 0
                },
                {
                    "sent": "And it turns out that when you have subgradients again, you have to put an infant's soup and basically work with this.",
                    "label": 0
                },
                {
                    "sent": "So this is kind of ugly, but again, for many of the loss functions that we want to work with, it's possib.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the the prototypical example that I want to use is essentially that of a hinge loss.",
                    "label": 1
                },
                {
                    "sent": "Almost everybody here knows about the hinge loss.",
                    "label": 1
                },
                {
                    "sent": "You have a square norm regularizer.",
                    "label": 1
                },
                {
                    "sent": "You can add any regularizer, it doesn't matter.",
                    "label": 0
                },
                {
                    "sent": "And the important thing is that you have a hinge and the hinge is not differentiable at the hinge points you have, you only have.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Gradients turns out that you can do an exact line search.",
                    "label": 1
                },
                {
                    "sent": "If I give you a direction of dissent, this becomes a quadratic function plus.",
                    "label": 0
                },
                {
                    "sent": "Points at which piecewise linear parts are added, so there will be exactly points at which kinks will appear on the quadratic function, but essentially it's a quadratic function with kinks.",
                    "label": 0
                },
                {
                    "sent": "Even better, you can actually exactly enumerate where the Kings will occur, and basically what you do is you first figure out at which locations the Kings are going to occur.",
                    "label": 0
                },
                {
                    "sent": "You sort them, and then you just walk through them, and you can essentially find out you keep your function values going on.",
                    "label": 0
                },
                {
                    "sent": "Going down, you keep on walking down the Kings and at the first point when your function value starts going up, you know that the optimum is between those two brackets and between those two brackets it's a.",
                    "label": 0
                },
                {
                    "sent": "It's a convex, it's a QP, it's a quadratic.",
                    "label": 1
                },
                {
                    "sent": "Which can be solved exactly, so you can actually do an exact line search.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The other thing is that how do you find this interaction which is violating a given direction?",
                    "label": 0
                },
                {
                    "sent": "It's again very easy because basically if you look at the gradient, the subgradient, they look like summation of some coefficients times XI.",
                    "label": 0
                },
                {
                    "sent": "So essentially you just do XI times DK and if it is positive then you set the coefficients to be the highest value that they can take the highest positive value that they can take.",
                    "label": 0
                },
                {
                    "sent": "And if the coefficients are negative, you said the coefficients to be the lowest value that these.",
                    "label": 0
                },
                {
                    "sent": "Can take in this case it's zero, so you just kill them so.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Can find the descent direction very easily, so just to get a picture of how this works here is, and here is a function that I'm trying to visualize, so this is a piece of paper folded into four but with A twist.",
                    "label": 0
                },
                {
                    "sent": "The twist being there is a lot of curvature along this direction.",
                    "label": 0
                },
                {
                    "sent": "It's twisted very highly here, but there's very little curvature along this direction, so on one along 1 axis it has 100 times more curvature than the other axis on.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "A simple problem.",
                    "label": 0
                },
                {
                    "sent": "Let's try to run BF's and see what happens.",
                    "label": 0
                },
                {
                    "sent": "Well, it essentially starts from, so this is looking up the value.",
                    "label": 0
                },
                {
                    "sent": "So this is what is plotted here is you're looking from the top, so you start from here you take a step, you go to the other side.",
                    "label": 0
                },
                {
                    "sent": "You oscillate a little bit, and then you figure out you never reach the optimum.",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You could try a slightly smarter version of this by saying, oh, I know I have hinges, so how about this that whenever I do a line search I push myself out of the hinges and keep away from the hinges.",
                    "label": 0
                },
                {
                    "sent": "Turns out that again, you can actually converge, but it takes a long long time to converge.",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "On the other hand.",
                    "label": 0
                },
                {
                    "sent": "If you do an exact line search and find this different direction, you can converge into iterations.",
                    "label": 1
                },
                {
                    "sent": "So basically what happens is you start from this point, you get a gradient direction you take in step and then you can do an exact line search so you land exactly on the hinge.",
                    "label": 0
                },
                {
                    "sent": "So now you're on the hinge and Ann at the hinge point.",
                    "label": 0
                },
                {
                    "sent": "You can get many different sub gradients, but essentially what happens?",
                    "label": 0
                },
                {
                    "sent": "Is it because you're doing this column generation, you get the first subgradient, it's not a direction of dissent.",
                    "label": 0
                },
                {
                    "sent": "Then you get a second subgradient.",
                    "label": 0
                },
                {
                    "sent": "You take a convex combination of them and it always turns out that in two iterations you can find the direction of.",
                    "label": 0
                },
                {
                    "sent": "So you find the direction of dissent again, you can do an exact line search so you slide along the hinge and you are at the solution 2 steps.",
                    "label": 0
                },
                {
                    "sent": "You might be wondering, this is a type problem.",
                    "label": 0
                },
                {
                    "sent": "How does it actually work in practice?",
                    "label": 0
                },
                {
                    "sent": "Well.",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Let's see it.",
                    "label": 0
                },
                {
                    "sent": "Here it is on writers.",
                    "label": 0
                },
                {
                    "sent": "Large number of examples.",
                    "label": 0
                },
                {
                    "sent": "Large number of dimensions and a very small regularizer, so I must point out that if you look at bundle methods they have really problems when the regularizer is very small, because the hinge is really dominate an almost all optimizers have problems in the regularizer is very small.",
                    "label": 0
                },
                {
                    "sent": "This is common.",
                    "label": 0
                },
                {
                    "sent": "So here I'm plotting the number of function evaluations it takes to reach reach to reduce the objective function value for different for different optimizers.",
                    "label": 0
                },
                {
                    "sent": "And one thing to note is that be FGS also converges.",
                    "label": 0
                },
                {
                    "sent": "Just plain BF's also converges on this really large on this really large problem.",
                    "label": 0
                },
                {
                    "sent": "The problem is when BF GS works, it works beautifully, but when it fails it fails catastrophically because.",
                    "label": 0
                },
                {
                    "sent": "There might be cases when you just land on the hinge.",
                    "label": 0
                },
                {
                    "sent": "NBS completely fails to converge.",
                    "label": 0
                },
                {
                    "sent": "On the other hand, what we do is basically it always converges.",
                    "label": 0
                },
                {
                    "sent": "So here the black line is is bundled methods.",
                    "label": 0
                },
                {
                    "sent": "So bundle methods also try to optimize the same problem, but the way they do it is philosophically different.",
                    "label": 0
                },
                {
                    "sent": "They use these gradients to build a lower bound for the function and the optimized the lower bound at every step.",
                    "label": 0
                },
                {
                    "sent": "So this is fundamentally different from the way LB FTS orbs is using the gradient information because it's using it to estimate curvature.",
                    "label": 0
                },
                {
                    "sent": "And then taking a step again.",
                    "label": 0
                },
                {
                    "sent": "Another noteworthy thing is that initially we make a lot of progress as compared to the bundle methods, but closer to the optimum we essentially the same as the rate of progress is similar to bundle methods.",
                    "label": 0
                },
                {
                    "sent": "You might be wondering why this is and sort of these are really hot of the press results is just one or two days old and one of my conjectures is that initially it really helps you to make a quadratic ball approximation because you can slide and jump over many many hinges, but when you go close to the solution.",
                    "label": 0
                },
                {
                    "sent": "Change is really, really matter.",
                    "label": 0
                },
                {
                    "sent": "You must know where the hinges are and how to slide to the solution, so therefore it really makes sense to know and cut the hinges and then go to the solution like the bundle methods do while BF DS is still trying to make this quadratic approximation which might not be true or which may not be valid close to the hinge, so it takes a longer time to converge.",
                    "label": 0
                },
                {
                    "sent": "This is a picture which I call the bank for the Buck picture which says how much CPU time you expand versus how do you decrease your objective function and again.",
                    "label": 0
                },
                {
                    "sent": "We're pretty competitive initially and then later on, yeah.",
                    "label": 0
                },
                {
                    "sent": "Training or test.",
                    "label": 0
                },
                {
                    "sent": "So this is just the objective function value.",
                    "label": 0
                },
                {
                    "sent": "No no, no error.",
                    "label": 0
                },
                {
                    "sent": "This is just.",
                    "label": 0
                },
                {
                    "sent": "I'm only an optimizer.",
                    "label": 0
                },
                {
                    "sent": "Sorry yeah this on the training set so I'm an optimizer.",
                    "label": 0
                },
                {
                    "sent": "I don't care about errors.",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Training and tests.",
                    "label": 0
                },
                {
                    "sent": "And again, similar kind of results menu.",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I read the regularizer.",
                    "label": 0
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And also on the KDD Cup with a few million 4 million examples.",
                    "label": 0
                },
                {
                    "sent": "Again similar kind of resume.",
                    "label": 0
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_55": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I won't get into them.",
                    "label": 0
                },
                {
                    "sent": "Now, let's go.",
                    "label": 0
                },
                {
                    "sent": "So now we all talked about batch we said oh what happens when it's not convex?",
                    "label": 0
                },
                {
                    "sent": "And what happens when your function is not smooth?",
                    "label": 0
                },
                {
                    "sent": "Let's do one more relaxation and let's try to work with online methods.",
                    "label": 0
                },
                {
                    "sent": "So now at the end of this basically I'll try to show you how you can come up with how you can systematically fix buges to work in an online setting.",
                    "label": 0
                },
                {
                    "sent": "An some of the results that we have for machine learning problems in this context.",
                    "label": 0
                },
                {
                    "sent": "So now to make things on line, you might just again start with your parameter update and.",
                    "label": 1
                }
            ]
        },
        "clip_56": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Well, the simplest thing to do is you say, OK, I don't have the true gradient, but.",
                    "label": 0
                },
                {
                    "sent": "I can get an instantaneous gradient again.",
                    "label": 0
                },
                {
                    "sent": "One thing to note here is that I always write that this is a gradient, but a subgradient will suffice.",
                    "label": 0
                },
                {
                    "sent": "So it's just to keep notation simple.",
                    "label": 0
                },
                {
                    "sent": "Eyes you always say instantaneous gradient, but keep in mind that subgradient would suffice.",
                    "label": 0
                },
                {
                    "sent": "I get an instant instantaneous gradient and many people have tried this in this at all.",
                    "label": 0
                },
                {
                    "sent": "Yes, so that's yeah, yeah, yeah.",
                    "label": 0
                },
                {
                    "sent": "So, actually Nonsmooth doesn't matter for online exactly because you keep bouncing stochastically around.",
                    "label": 0
                },
                {
                    "sent": "So basically you get this.",
                    "label": 0
                },
                {
                    "sent": "You get this instantaneous gradient and you might say, well, let me just use this instantaneous gradient, run the BS update and pray that everything works.",
                    "label": 0
                },
                {
                    "sent": "People have tried this.",
                    "label": 0
                }
            ]
        },
        "clip_57": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Network.",
                    "label": 0
                },
                {
                    "sent": "So first thing is, how do you do a line search?",
                    "label": 1
                },
                {
                    "sent": "Thank you only have instantaneous gradient.",
                    "label": 0
                },
                {
                    "sent": "You don't know how to do a line search, so typically.",
                    "label": 0
                }
            ]
        },
        "clip_58": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Instead of this step size which you used to find by line, search here to replace it with a gain schedule.",
                    "label": 1
                },
                {
                    "sent": "Typically you can just do a simple game schedule, or you can be fancy and do some kind of gain adaptation.",
                    "label": 0
                },
                {
                    "sent": "These are steps adaptation methods which can which can give you a good.",
                    "label": 0
                }
            ]
        },
        "clip_59": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Websites to take.",
                    "label": 0
                },
                {
                    "sent": "Then let's dissect the Matrix update and see what happens.",
                    "label": 0
                },
                {
                    "sent": "So clearly here YT you don't.",
                    "label": 0
                },
                {
                    "sent": "You can no longer do this because you don't have full.",
                    "label": 0
                }
            ]
        },
        "clip_60": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Radiance.",
                    "label": 0
                },
                {
                    "sent": "So your first attempt might be to say, oh, let me just take the sub gradient and gradient and sample it at XD and XD plus one.",
                    "label": 0
                },
                {
                    "sent": "Again, if you try this, this doesn't work.",
                    "label": 0
                },
                {
                    "sent": "This is a key crucial point and this took us a while to figure out, but this doesn't work, mainly because you're introducing a sampling noise, you're not getting the gradients at the same location.",
                    "label": 0
                },
                {
                    "sent": "You're sampling the gradient at two different locations, both of which are coming to you by stochastic process.",
                    "label": 0
                },
                {
                    "sent": "So you're introducing sampling noise into your process, so if you estimate your YT by doing this, it does not work.",
                    "label": 0
                }
            ]
        },
        "clip_61": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You have to.",
                    "label": 0
                },
                {
                    "sent": "You have to essentially.",
                    "label": 0
                },
                {
                    "sent": "Get your gradients.",
                    "label": 0
                },
                {
                    "sent": "Your instantaneous gradients must be sampled at the same location, which also means that what you need to do is to store your data for one step.",
                    "label": 0
                },
                {
                    "sent": "So you use your data at time T and your updates at time T + 1.",
                    "label": 0
                },
                {
                    "sent": "So you need to store your data for one step.",
                    "label": 0
                },
                {
                    "sent": "That is that surprise.",
                    "label": 0
                },
                {
                    "sent": "You need to pay for this.",
                    "label": 0
                }
            ]
        },
        "clip_62": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Then the other problem that happens is that, let's say you're training with a CRF just as a Canonical example.",
                    "label": 0
                },
                {
                    "sent": "Now you have lots and lots of features.",
                    "label": 0
                },
                {
                    "sent": "Many, it's a very sparse feature vector, and on certain dimensions you'll never see any gradient until you've seen a large number of data points.",
                    "label": 0
                },
                {
                    "sent": "So what happens is that blows up your H inverse estimate because basically your hedges rank deficient because you never see gradients along any any along many of these coordinates, and so to ensure that you don't overstep, you have to add a trust region parameter.",
                    "label": 0
                },
                {
                    "sent": "This again, is in.",
                    "label": 0
                }
            ]
        },
        "clip_63": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Written in the online context.",
                    "label": 0
                },
                {
                    "sent": "And so again, as I said before, if you add the rule you get this row times.",
                    "label": 0
                }
            ]
        },
        "clip_64": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Do you pick up this time and finally, if you look at the update formula?",
                    "label": 0
                },
                {
                    "sent": "You need to do.",
                    "label": 0
                }
            ]
        },
        "clip_65": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You need to do one small change there, so since you're in an online setting, you had really really guard against a bad example.",
                    "label": 0
                },
                {
                    "sent": "So if you get a really bad example which forces you to take a large step and to completely make your estimate going haywire, you had to guard against that.",
                    "label": 0
                },
                {
                    "sent": "So essentially you guard against it by adding small constant.",
                    "label": 0
                },
                {
                    "sent": "See here, which is less than one.",
                    "label": 0
                },
                {
                    "sent": "But that also means you do.",
                    "label": 0
                },
                {
                    "sent": "You pick up a 1 / C term.",
                    "label": 0
                },
                {
                    "sent": "Here I put this in magenta and not in blue or red, because we really, really don't fully understand why this is needed.",
                    "label": 0
                },
                {
                    "sent": "On some problems it just does not converge without this, and on some problems it does and the explanation that I gave you is the best kind of explanation that I have.",
                    "label": 0
                },
                {
                    "sent": "So if you have some more intuition, please come and talk.",
                    "label": 0
                }
            ]
        },
        "clip_66": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I mean, I'd love to talk about it.",
                    "label": 0
                },
                {
                    "sent": "So putting all these things together, you have the online beefs algorithm.",
                    "label": 0
                },
                {
                    "sent": "So basically we have systematically taken VFD S. Looked at what happens when you do online, fixed each one of them.",
                    "label": 0
                },
                {
                    "sent": "And here is here is our algorithm.",
                    "label": 0
                }
            ]
        },
        "clip_67": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Again, you must be wondering how does it perform well?",
                    "label": 0
                },
                {
                    "sent": "Here are some performance curves, so basically this is plain elves on training conditional random fields.",
                    "label": 0
                },
                {
                    "sent": "This is on the Kernel 2002, base NP, chunking tasks.",
                    "label": 0
                },
                {
                    "sent": "Same setup as I see ML 2006 paper.",
                    "label": 0
                },
                {
                    "sent": "The problem is really high dimensional, lots of sparse features.",
                    "label": 0
                },
                {
                    "sent": "It is smooth because you're working with the log likelihood knows and it's convex, but it's asymptotically I'll condition in the sense that although you're taking the log some X.",
                    "label": 0
                },
                {
                    "sent": "Basically the lock some X starts placing weights on only a small number of of labels, and so it almost starts behaving like a Max instead of being a softmax, and so it's asymptotically condition and here are results of SMD stepsize adaptation method.",
                    "label": 0
                },
                {
                    "sent": "It is generally finicky, has a lot of things to tune this, and then these are two different versions of online LB FTS, one with the one over TDK and one where you use SMD.",
                    "label": 0
                },
                {
                    "sent": "To update the step size and the SMB version seems to perform slightly better here and here.",
                    "label": 0
                },
                {
                    "sent": "Just on the KDD Cup again, and you're doing SVM training in the primal, and again, it's not convex.",
                    "label": 0
                },
                {
                    "sent": "Yep.",
                    "label": 0
                },
                {
                    "sent": "Number.",
                    "label": 0
                },
                {
                    "sent": "It's a number of updates, so the number of data points you see.",
                    "label": 0
                },
                {
                    "sent": "And here again, this is a.",
                    "label": 0
                },
                {
                    "sent": "This is a large data set.",
                    "label": 0
                },
                {
                    "sent": "Again we showed you some experiments before with that and.",
                    "label": 0
                },
                {
                    "sent": "And you can clearly see that online BFT is just with the one over TDK.",
                    "label": 0
                },
                {
                    "sent": "Here seems to reduce the objective function quite well.",
                    "label": 0
                }
            ]
        },
        "clip_68": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "He is it so.",
                    "label": 0
                },
                {
                    "sent": "So here it was going up again because.",
                    "label": 0
                }
            ]
        },
        "clip_69": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Oh, actually.",
                    "label": 0
                },
                {
                    "sent": "No, this is this is the true objective of the batch training, and then it's going up because you're stochastic, so.",
                    "label": 0
                },
                {
                    "sent": "You're only seeing part of the data and you're only getting aggregating partial information.",
                    "label": 0
                },
                {
                    "sent": "No, you don't know you haven't seen the full data set, so you don't know how to compute the objective.",
                    "label": 0
                },
                {
                    "sent": "So you could compute with.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so this is.",
                    "label": 0
                },
                {
                    "sent": "This is the instantaneous objective.",
                    "label": 0
                }
            ]
        },
        "clip_70": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Plugged in and here is a is a simple neural network task.",
                    "label": 0
                },
                {
                    "sent": "If you're a deep believer, this is probably not deep enough, but.",
                    "label": 0
                },
                {
                    "sent": "Here is a task where you have to predict the color of the carpet.",
                    "label": 1
                },
                {
                    "sent": "The inputs are the coordinates of the points.",
                    "label": 0
                },
                {
                    "sent": "There's a two layer input 10 layer thin layer, hidden output and then there are four nodes which gets switched on based on which color of the carpet and.",
                    "label": 0
                },
                {
                    "sent": "This is smooth, but highly nonconvex and very ill conditioned problem.",
                    "label": 1
                },
                {
                    "sent": "And here you can see that if you do, online VFS with SMD initially it seems too.",
                    "label": 0
                },
                {
                    "sent": "It seems to reduce the loss quite a bit, but asymptotically, online VFS by just setting the by reducing the step size.",
                    "label": 0
                },
                {
                    "sent": "Taking it in a way.",
                    "label": 0
                }
            ]
        },
        "clip_71": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Noriti fashion seems to be better.",
                    "label": 0
                },
                {
                    "sent": "And finally, I won't spend a lot of time on this, but basically let us think about how we can lift this whole thing into our cages.",
                    "label": 0
                },
                {
                    "sent": "And here I want to just quickly flash these equations.",
                    "label": 0
                },
                {
                    "sent": "I'll tell you where the deepness is.",
                    "label": 0
                },
                {
                    "sent": "The initial part is not very deep.",
                    "label": 0
                }
            ]
        },
        "clip_72": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Basically what happens is the BFG is updates, as you recall, have two two stages at one stage.",
                    "label": 0
                },
                {
                    "sent": "How to compute the inverse and the other stage here to actually do the parimeter updates?",
                    "label": 0
                }
            ]
        },
        "clip_73": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the way.",
                    "label": 0
                }
            ]
        },
        "clip_74": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "LB of DS does it is it reduces this into two loops.",
                    "label": 0
                },
                {
                    "sent": "It maintains K vectors and every time it essentially inverts this K dimensional key rank matrix and then it updates its parameters.",
                    "label": 0
                },
                {
                    "sent": "So the 1st loop is easy for inverting the matrix and the 2nd loop is essentially for finding that.",
                    "label": 0
                }
            ]
        },
        "clip_75": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And of this, and then you actually.",
                    "label": 0
                }
            ]
        },
        "clip_76": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Update your parameters then you.",
                    "label": 0
                }
            ]
        },
        "clip_77": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To estimate your YT, which is nothing but the difference of the gradients and so on and so forth.",
                    "label": 0
                },
                {
                    "sent": "But the key.",
                    "label": 0
                }
            ]
        },
        "clip_78": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Mission is that.",
                    "label": 0
                },
                {
                    "sent": "If you look at the LB FTS, you know.",
                    "label": 0
                },
                {
                    "sent": "Pseudocode this is standard pseudocode from Nocedal and Wright.",
                    "label": 0
                },
                {
                    "sent": "Basically the key observation is that you only using inner product and linear combinations and both of which we know can be lifted into another catches.",
                    "label": 1
                },
                {
                    "sent": "So this is kind of E.",
                    "label": 0
                }
            ]
        },
        "clip_79": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Easy observation, and so if you want to lift it into an arcade as immediately you can say oh instead of instead of maintaining a buffer of lost key values of function values.",
                    "label": 0
                },
                {
                    "sent": "Now instead of functions in another cages instead of maintaining vectors in R to the N. Answer You right out the dot product San.",
                    "label": 0
                },
                {
                    "sent": "This is how it looks like, but there's a problem.",
                    "label": 0
                },
                {
                    "sent": "The problem is that if you actually really need to compute these dot products explicitly in the Dark Ages, essentially you end up picking a kernel matrix.",
                    "label": 0
                },
                {
                    "sent": "So what happens is that all the functions that you have are represented as linear combinations, so you're maintaining the dual dual para meters and then you have the kernel and then you have the dual parameter.",
                    "label": 0
                },
                {
                    "sent": "So essentially these all these dot products would look something like Alpha S transpose.",
                    "label": 0
                },
                {
                    "sent": "Could K times, Alpha, S and so on and so on.",
                    "label": 0
                },
                {
                    "sent": "This kind of is very expensive, and if you're aggregating parameters as you're going online.",
                    "label": 0
                },
                {
                    "sent": "Things get very.",
                    "label": 0
                }
            ]
        },
        "clip_80": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Nothing.",
                    "label": 0
                },
                {
                    "sent": "To prevent that from happening, what you can do is that you can say OK, let me let me first do this whole thing in an online fashion, but then I do this in this online fashion.",
                    "label": 0
                },
                {
                    "sent": "I said I can keep on aggregating terms and if I keep on aggregating terms, my dual coefficients will keep on growing unbounded and things.",
                    "label": 0
                }
            ]
        },
        "clip_81": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Then go completely haywire.",
                    "label": 0
                },
                {
                    "sent": "Turns out that there are.",
                    "label": 0
                },
                {
                    "sent": "Ways to do cheap updates of this dual parameters and you can do them exactly and maintain.",
                    "label": 0
                },
                {
                    "sent": "You had to maintain some secondary parameters, but you maintain the secondary parameters and you can update them in a very cheap way in essentially linear time.",
                    "label": 0
                },
                {
                    "sent": "So this is basically think of stochastic gradient descent in in the kernel space.",
                    "label": 0
                },
                {
                    "sent": "But now instead of stochastic gradient descent you essentially doing online LVL.",
                    "label": 0
                }
            ]
        },
        "clip_82": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here are some results on amnist with this so online SVM is essentially stochastic gradient descent in our cases.",
                    "label": 0
                },
                {
                    "sent": "FMD is is our algorithm which uses SMD to do steps adaptation in stochastic online learning in in their cages and here is how our online kernel version of ALB performs.",
                    "label": 0
                },
                {
                    "sent": "And here is a comparison with Pegasus which is essentially stochastic gradient descent.",
                    "label": 0
                },
                {
                    "sent": "Again except with a different learning rates.",
                    "label": 0
                },
                {
                    "sent": "So the online SVM uses a one over square root.",
                    "label": 0
                },
                {
                    "sent": "The learning rate, while Pegasus uses 1 / T learning rate.",
                    "label": 0
                },
                {
                    "sent": "I must admit that.",
                    "label": 0
                },
                {
                    "sent": "We didn't really try very hard to optimize the parameters of the of the competing algorithms, and here is a particularly evil sequence.",
                    "label": 0
                },
                {
                    "sent": "If you are doing online learning is that you get we took digits from Miss Ann.",
                    "label": 0
                },
                {
                    "sent": "You order them so that you get 000001002 and so on.",
                    "label": 0
                },
                {
                    "sent": "So initially you get a lot of zeros and then closer to the end you get 9999899.",
                    "label": 0
                },
                {
                    "sent": "So you see a lot of lines, so the distribution is non stationary and changes with time.",
                    "label": 0
                },
                {
                    "sent": "Most online algorithms will have trouble with this.",
                    "label": 0
                },
                {
                    "sent": "Online SVM completely is not able to manage this FMD kind of gets along, but the online kernel LB FT is actually manage is to perform quite well on this.",
                    "label": 0
                }
            ]
        },
        "clip_83": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And finally, to conclude, I've showed you how to systematically relax some of the assumptions underlying assumptions of BFG S and hopefully make it more applicable to some of the machine learning problems that we have.",
                    "label": 0
                },
                {
                    "sent": "I believe that these are only exciting early results.",
                    "label": 1
                },
                {
                    "sent": "We are still.",
                    "label": 0
                },
                {
                    "sent": "There's still a lot more to do.",
                    "label": 0
                },
                {
                    "sent": "We're working towards it.",
                    "label": 0
                },
                {
                    "sent": "We would love to have feedback, comments, people who want to jump in and help us and work with us.",
                    "label": 0
                },
                {
                    "sent": "Please feel free to do so.",
                    "label": 0
                },
                {
                    "sent": "There's a lot of things more to do and I want to leave you with a little open problem which is been bothering me for the last few days is in the case of the hinge loss in the binary hinge loss.",
                    "label": 1
                },
                {
                    "sent": "Given a search direction, I can exactly find an do align search.",
                    "label": 0
                },
                {
                    "sent": "I can do a line search and find the exact minimum an if I land on a hinge.",
                    "label": 0
                },
                {
                    "sent": "I know exactly where I land.",
                    "label": 0
                },
                {
                    "sent": "If I give you a direction of dissent in a structure estimation problem, can you do a line search for me?",
                    "label": 0
                },
                {
                    "sent": "It is also a piecewise linear function.",
                    "label": 0
                },
                {
                    "sent": "The only problem is that the number of pieces the piece linear pieces could be exponentially large, and I don't know how to do a line search with that function without evaluating the function or without spending too much time.",
                    "label": 0
                },
                {
                    "sent": "So if you have any ideas on that, please come and talk to me.",
                    "label": 0
                },
                {
                    "sent": "That's all I have to say.",
                    "label": 0
                },
                {
                    "sent": "Thank you very much.",
                    "label": 0
                },
                {
                    "sent": "And finally, I'd actually like to acknowledge Galion for some of the exciting discussions we had on on this sub.",
                    "label": 0
                },
                {
                    "sent": "Gives some of the ideas that about subgraphs.",
                    "label": 0
                },
                {
                    "sent": "Thanks.",
                    "label": 0
                },
                {
                    "sent": "Yep yeah.",
                    "label": 0
                },
                {
                    "sent": "I mean, LB of gears are behaviors in general, is pretty robust and some the problem does occur.",
                    "label": 0
                },
                {
                    "sent": "If suppose you have zero eigenvalues or sometimes if you have those X transpose Y is negative.",
                    "label": 0
                },
                {
                    "sent": "Then we see that it doesn't converge.",
                    "label": 0
                },
                {
                    "sent": "I mean it might converge.",
                    "label": 0
                },
                {
                    "sent": "Yeah, if it satisfies the Wolf conditions.",
                    "label": 0
                },
                {
                    "sent": "Yeah, yeah.",
                    "label": 0
                },
                {
                    "sent": "Well, maybe sexy to solve your problem.",
                    "label": 0
                },
                {
                    "sent": "There's.",
                    "label": 0
                },
                {
                    "sent": "I'd love to know more about them.",
                    "label": 0
                },
                {
                    "sent": "In the online version of your outlook, do you need to solve a column generation problem on every single minute?",
                    "label": 0
                },
                {
                    "sent": "No, not in the online version, because basically what happens is because you're stochastic.",
                    "label": 0
                },
                {
                    "sent": "You sort of bounce around, so even if you land on a hinge, it's bad luck.",
                    "label": 0
                },
                {
                    "sent": "Tough luck, but next time you just get out of it and get on with life, but in the batch you really, really have to do column generation.",
                    "label": 0
                },
                {
                    "sent": "The gradient.",
                    "label": 0
                },
                {
                    "sent": "Epsilon.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "It's it's the rates for the decent direction.",
                    "label": 0
                },
                {
                    "sent": "Finding it is not the rates of the overall algorithm.",
                    "label": 0
                },
                {
                    "sent": "This is only for the different direction finding and the rates are in terms of that objective function that I wrote out that pseudo quadratic objective function that I wrote out.",
                    "label": 0
                },
                {
                    "sent": "You have rates for, how fast will that JK which was the approximation, the Cath step approximation converge to the true objective function.",
                    "label": 0
                },
                {
                    "sent": "The true pseudo quadratic objective function, so those one over epsilon rates are.",
                    "label": 0
                },
                {
                    "sent": "Rates in convergence in the in the objective function value not then not for the overall.",
                    "label": 0
                },
                {
                    "sent": "No, not yet.",
                    "label": 0
                },
                {
                    "sent": "I mean, I think the best we can do this is again pretty hot off the press.",
                    "label": 0
                },
                {
                    "sent": "As I said, these results just came out yesterday or day before the plots that I showed you.",
                    "label": 0
                },
                {
                    "sent": "I think.",
                    "label": 0
                },
                {
                    "sent": "I mean, this is my belief that you can use the normal bgcse rates to prove that it will converge, but I don't think we can get rates.",
                    "label": 0
                },
                {
                    "sent": "OK thanks.",
                    "label": 0
                }
            ]
        }
    }
}