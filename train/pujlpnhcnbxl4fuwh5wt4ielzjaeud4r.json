{
    "id": "pujlpnhcnbxl4fuwh5wt4ielzjaeud4r",
    "title": "Sequential Monte-Carlo Methods",
    "info": {
        "author": [
            "Arnaud Doucet, Department of Statistics, University of Oxford",
            "Nando de Freitas, Department of Computer Science, University of Oxford"
        ],
        "published": "Jan. 19, 2010",
        "recorded": "December 2009",
        "category": [
            "Top->Computer Science->Machine Learning->Monte Carlo Methods"
        ]
    },
    "url": "http://videolectures.net/nips09_doucet_freitas_smc/",
    "segmentation": [
        [
            "So the talk has two parts.",
            "The first part will be by Arner to set and I'll do an introduction before hand, so to kind of create a set up for people who haven't seen this before.",
            "I know we'll basically be talking about particle filtering for state space models, and he will discuss some algorithms that we need.",
            "A lot of us are very familiar with in this community, but then he will introduce some recent new developments that he's been working on with colleagues where he's looking at the issues of parameter learning, not just filtering and state estimation, but trying to go beyond to do tackle problems like smoothing.",
            "And learning.",
            "After that we this tutorials are kind of long, so we're going to have a short break.",
            "And then I will look into particle filtering.",
            "But I will consider other type of problems that we don't often deal with things like eigenvalue problems, protein folding problems, control problems and static distributions and so on.",
            "And also some very interesting ways of learning ABC.",
            "ABC's like this really cool.",
            "Bayesian technique where you can learn.",
            "If you can imagine it basically so only these."
        ],
        [
            "Four topics were covered basically at the end of the 20th century and most of what we're going to talk about will be new things."
        ],
        [
            "Many, many people in this community have worked in this problem and many communities to have attacked this problem.",
            "People in control, people in signal processing, people in statistics and physics, and so on, and they all give the method different names and slightly different methodologies and will try to bring to your attention some of these.",
            "In machine learning, the method became popular with Andrew Blake, and Michael is serving the Computer Vision application, you know, sort of.",
            "I'll show you some examples.",
            "Many people have contributed to the method in AI.",
            "I've left some here without mentioning just already Moon's face.",
            "He's done a lot of work with this too, and I'm sure I'm missing some of you in the audience.",
            "So what's particle filtering?",
            "So it's a technique for approximating distributions that evolve overtime that have some sort of dynamics.",
            "But it can also be useful static distributions as I'll talk about it at the end, but for now, let's consider dynamic distributions.",
            "The idea is we want to approximate distribution and the way we do it is we draw samples from this red distribution."
        ],
        [
            "And then if we just count how many samples fall in each bin, we get a histogram is approximation of this.",
            "And we can give weights to these different samples, which is what we call particles as well.",
            "And that allows us to get a good representation of this and here we kind of see how these particles propagate overtime.",
            "And if they're doing well.",
            "They get a bigger weight, so there's sort of a survival of the Fittest.",
            "Aspect to this, and here's another picture of the same thing where you showed that the how the distribution is evolving.",
            "Overtime.",
            "And you're able to, in this case, track a target that actually has two possible hypothesis of where it could be going, and so you have to maintain all your hypothesis in.",
            "So here is an example.",
            "Offer how you can use.",
            "Particles."
        ],
        [
            "Particles here just you're trying to estimate a probability distribution for the location of these players being tracked.",
            "And each of these blue boxes, like in this player is a particle.",
            "And then when you take the average is sort of get to mean you attract these things in video on the TV you don't project them to the world using some basic geometry and then you have sort of trajectory's you know what the person was doing.",
            "And it's."
        ],
        [
            "As in the game.",
            "And you can also play soccer and these videos I got from Dieter Fox is gas.",
            "Countless animations in his website definitely recommend you look at this.",
            "So here the particles represent the position of the ball and the position of the robot.",
            "The robot is learning what is trying to locate itself and locate the ball.",
            "A more impressive application, also teacher is a particle filter where the particles here represent an estimate of what the person is in the city of Seattle I believe, and then the particle filter also represents another state, which is where it believes the person is guided two.",
            "So it's a hierarchical setting with you know what the person goes.",
            "It helps you with the tracking and then there is a sort of particles following the person and this data was using to actually help people with."
        ],
        [
            "Some forms of dementia and so on.",
            "So 'cause you want to make sure that you can track them and you have an idea of what they're doing and Detective they've maybe caught the wrong bus and so that you can then intervene in a system you sort of don't intervene all the time because it can be very annoying.",
            "Answer You you need to get good estimates of what's going on.",
            "And the type of model that."
        ],
        [
            "Dieter has is a something that looks more or less like this where you have some observations or evolve overtime.",
            "There's some discrete states that represent the unknown location, and then there is a sort of meta variable that indicates what the plan is.",
            "Where, where is the person trying to reach at least type of factor representations have been used a lot with particle filtering.",
            "They used and also industrial setups in actual applications.",
            "One important thing is when you have structure in the graph you should exploit structure as much as possible.",
            "And you should do analytical computation as much as possible.",
            "Don't do Monte Carlo if you don't need to do it.",
            "It's really a last resort method.",
            "And indeed, when we exploit structure, these algorithms in terms of errors tend to do incredibly better.",
            "The methods that arnibal discuss also apply to setups in which the number of unknowns is changing overtime.",
            "Particle filters are very good for that, that we are able to estimate the so-called partition function, or normalization constant.",
            "So we can do model selection relatively easily compared to how it's done with traditional methods."
        ],
        [
            "I can see and see.",
            "Method is a really old one.",
            "It really goes back to.",
            "The 1st paper of Metropoles, an older man 1949.",
            "It's like a four page paper, but it has so much in it it's really worth reading every sentence few times.",
            "And of course they were interested in this kind of problems too.",
            "Blow up things and this is a picture of the ENIAC and the programmers of the time who this kind of has changed overtime.",
            "Phenomen actually needed someone to code these algorithms.",
            "He invented important sampling action, a small letter.",
            "He actually writes a note to someone and he says I believe when they're computer should be able to understand.",
            "These steps, and he puts like line numbers and so on in the program so.",
            "Soon later, he invented the.",
            "You know, the architecture for these things for the.",
            "How are computers?",
            "And many people have been involved with this, starting with Enrico Fermi for Neumann, Ola Metro police, who is actually Delaware around Metropolis.",
            "Who was the coder that they have young physicist that they got to come and Cody's machine and then became the famous metropolis in physics.",
            "Alot of them actually spend the rest of their lives campaigning for peace.",
            "And."
        ],
        [
            "Next well, talking to many people have worked on this method and there's been incredible amounts of work in different physics and in the world of phylogenetic trees in artificial intelligence.",
            "This really huge.",
            "The Russians were there too.",
            "They did some zaritsky and so on that did amazing things over the last 10 years.",
            "Aren't done a lot of work in this method and he will tell you next what he's been up to.",
            "So obviously I wasn't aware."
        ],
        [
            "The last slide.",
            "Date."
        ],
        [
            "So after the informal introduction of non do I'm going to talk more about the mathematical aspects of particle filters on goal for the equations.",
            "So I will give a few convergence results and I will explain the limitation also of the technique.",
            "OK, so I'm going to."
        ],
        [
            "Introduced like mathematically, the class of models were considering.",
            "So basically we're dealing with the class of a state space model, also known as hidden Markov model or partially observed dynamic model.",
            "So the way those models work is as follows.",
            "So first you have to earn observe Markov process XC.",
            "Which is defined basically by its initial density, new on a transition density F. So that defines basically the process.",
            "The later instead process you're interested in.",
            "Or you don't have access to XC."
        ],
        [
            "You only have access to related observation process, YK or?"
        ],
        [
            "Let you you assume is that the observation whites uik you collect our search that conditionally upon the process XC the observation ycr marginally distributed according to a density G OK.",
            "So what you want to do, mathematical E is essentially want to estimate the latent state process XK.",
            "Given the observation process, YK, or you want to.",
            "You might want to do this online or offline.",
            "OK, so I will first discuss the offline aspects, but by the end of the talk I will move basically to offline inference.",
            "So essentially I want to estimate X given Y, so formal, essentially a conceptual point of view.",
            "This is a trivial task, there's nothing complicated about that.",
            "OK, so assume you'll give."
        ],
        [
            "In a collection of observation Y2Y1Y N I'm using Matlab notation on, you want to infer the state X One X2, XN where basically inference rely on the posterior distribution P of X given Y, which is simply given by the joint distribution P of X, Y / P Y on what do I know where I know this distribution up to normalizing constant because P of XY by definition is P of X time.",
            "PY given X, it follows."
        ],
        [
            "From the markup assumption on the Macondo Dimarco has sunshine of XC, that deployer can be written as follow on.",
            "It follows from the assumption on the observation process that the conditional likelihood of Salvation given of Y given X is simply given by the product margin Loan City.",
            "OK, the marginal likelihood is obviously given by the expect.",
            "The integral of the joint distribution in respect to the latent process.",
            "So conceptually there's absolutely no problem on what I want to do already.",
            "What I'm interested in.",
            "It's first to come up with algorithm to compute the posterior distribution on the marginal likelihood sequentially with the time, and so I want to come up with sequential algorithm to estimate the sequence of his tail distribution.",
            "X1 and Y1, and on the marginal likelihood.",
            "Why one OK, as any increases.",
            "OK, so that's not difficult from a conceptual point of view, But the problem is."
        ],
        [
            "Actually, if you're dealing with nonlinear non Gaussian models, then there's no closed form expression.",
            "Basically, for this poster distribution on is no closed form expression for the marginal likelihood.",
            "They obviously a couple of very important exception important exception where you can do those calculations analytically, include the class of linear algorithm, state space model, in which case you can use the Kalman filter or the case where X takes value in a discrete in a finite state space, in which case you can do also order the calculation analytically.",
            "But as soon as you're going to have basically model which is nonlinear non Gaussian, you gonna need to come up with numerical approximation for this quantities.",
            "So the typical way the stone away to approximate those techniques consist basically of making functional type approximation.",
            "So for example you could say where this thing is, frogs for example is definitely not Goshen, but let's approximate it by Gaussian distribution.",
            "So this is for example the kind of assumption which are made by algorithm such that.",
            "Such as the unsalted carbon filter or the extended camel filter.",
            "We're not going to discuss this kind of this kind of basically of approximation.",
            "We're going to discuss, discuss a class of Monte Carlo methods, where essentially we do not make any functional approximation on the posterior distribution of interest on the method.",
            "We're going to basically discuss are in some sense, aseptically consistent.",
            "That is, if you increase your computational effort, they're going to converge throughout the true."
        ],
        [
            "Basically, distribution or the toolbar Gino like you.",
            "So the terms of technique we're using is Monte Carlo methods.",
            "So I'm just going to go very briefly for the very very basics or not the kilometers.",
            "So assume basically you're interested in approximating or high dimensional distribution, so the ignore case this is the posterior distribution of X given the observation Y multicare approximation, you're going to sample capital N particles random sample according to.",
            "The distribution of interest on your monitor color approximation is simply the empirical measure of the associated random sample.",
            "OK, so that the simple or the way you approx."
        ],
        [
            "Made basically I dimensional distribution using motor kilometers on.",
            "Why is it a clever way to do it, where it's a clever way to do it?",
            "Because essentially the sample can't."
        ],
        [
            "Don't write each self naturally in region of high priority mass.",
            "OK, so once we've got to assume you're able to come up with such a Monte Carlo approximation of the posterior, where is good, because in this case assume then you want to compute the expectation of a test function 5 respect to the true posterior, where to get an estimate of it you substitute to the true posterior.",
            "It's multicolor estimate on that give you basically multicolor estimate of the expectation.",
            "If you're interested also, not.",
            "Basically, in computing an expectation that you're interested in computing approximating a marginal distribution, say of the component XK, given all the observation where you can get directly or multicolor approximation of the margin, or the only thing you need to do is to keep the component XC in your empirical measure.",
            "So that's very nice if you're if you're able to come over essentially with the Monte Carlo approximation of the posterior distribution, you can do all calculation very nicely.",
            "It's very easy.",
            "OK, so that's that's good."
        ],
        [
            "The problem is you cannot.",
            "Sorry.",
            "The problem is that, well, I don't know how to sample from the side emotional distribution, so if I could do it would be great.",
            "The problem is I cannot do that OK exactly so OK, so I'm going to have basically to use something else where I'm not going to be able to come up with a very nice approximation.",
            "Multicolour approximation of the posterior distributions of interest, but I'm going to be able to come up with basically approximate Monte Carlo in some sense that are going to still give me.",
            "Basically, approximation of this form, so this is what I'm going to."
        ],
        [
            "Explain now.",
            "OK, so the way we're going to do because we essentially unable to sample directly from this really high dimensional probability distribution where we're going to use a kind of divide and conquer strategy.",
            "So what we're going to do is say to some pool approximately from this posterior distribution.",
            "I'm going to decompose this problem in the collection of much simpler subproblems.",
            "So first, what I'm going to do is at time one, I'm going to come, we come up with.",
            "Multi kilometers to approximate this low dimensional distribution, which is P of X1 given Y one.",
            "Once I obtain a Monte Carlo approximation of people say."
        ],
        [
            "Distribution at time one I'm going to move to time two.",
            "I'm going to basically come up with an approximation of the distribution P of X11X1 or X2 given Y1Y2 on to come up with multicolour approximation of these guy I'm going to reuse the multicolor approximation I had obtained a time one.",
            "So this is kind of building a collection of nested sequence of Monte Carlo approximation on the way I'm going to do that is essentially.",
            "By propagating a cloud of random samples forward according to two mechanisms, which are mechanism of important sampling mechanism of resampling and this is what I'm going to explain you now OK?",
            "So the way it works."
        ],
        [
            "Follow this very simple math.",
            "There's really nothing difficult about that.",
            "Usum you at time N minus one small N -- 1 only assume that that time N -- 1 you have Monte Carlo approximation of the target distribution of interest that tease you have capital N random sample approximately distributed according to the target distribution of interest, so that's what you're given at time N -- 1 on.",
            "Essentially given this multicolour approximation of the target distribution at time N -- 1.",
            "You want to obtain your naproxen."
        ],
        [
            "Target at time.",
            "To do where you're going to do that is quite simple.",
            "So at time of minus one, you've got this capital and particles are is going from one to capital N distributed according to personal distribution at time N -- 1 you extend each of these paths here.",
            "According your going to sample the new component accent~ according to the prior distribution of the dynamic model and the consideration.",
            "OK, this is what you're doing on you rebuild, you rename, you pass X1 until then.",
            "So these guys by construction they are distributed according to the posterior distribution of X1 till XN given the observation till 10 -- 1.",
            "So you build an approximation of the predictive distribution.",
            "So this is a multi color approximation of the of the predictive distribution.",
            "This is not what you're interested in or remember that what you're interested in is a time and you're interested in basically the posterior distribution at time N."
        ],
        [
            "OK, which is simply given forms to base formula by basically predicted that I'm in multiplied by the likelihood of the observation attachment.",
            "OK, so it's very simple.",
            "So now what you do well is going to be easy to approximate this posterior distribution where you're going to substitute too."
        ],
        [
            "This guy you're going to replace this guy, but it's Monte Carlo approximation, so you plug this empirical measure in this in the base form.",
            "That's very simple.",
            "And what do you obtain?",
            "Well, you up saying simply at, I'm in an airport simulation, a multicolor approximation of the target distribution.",
            "So there is simply we just sample forward, basically with extended each pass according to the prior distribution.",
            "We've already waited all the paths according to their likelihood.",
            "On that give me a new approximation of the target at time, so it's a collection.",
            "It's a weighted sum of Delta mass where each weight is proportional to the likelihood of the sample.",
            "OK.",
            "So that's it.",
            "This is an approximation of the target distribution at time N, but we're not very happy with this, because what we want a timer."
        ],
        [
            "Is to obtain Capitaland random sample approximately distributed according to the target distribution at time, and So what I'm going to do is very simple.",
            "Once I've got this approximation of the posterior distribution time and I'm gonna re some poor capital N times from this weighted on pure equal measure to obtain capital and sample approximately distributed according to the target distribution at time.",
            "OK here we go.",
            "This is the new basically multicolor approximation of the posterior distribution attachment.",
            "So this is the way you move from an empirical measure approximating the target distribution.",
            "At time N -- 1 to new empirical measure approximating the target."
        ],
        [
            "Solution at time.",
            "OK on these three samping mechanism it looks a bit a duck in a sense, because it seems like a computational trick on it might not have good convergence properties.",
            "Will see that actually this week."
        ],
        [
            "Something step decide of resampling from this weighted empirical measure is what makes particle filters well, and I'll discuss that later.",
            "So to summarize the basic particle filter so as to approximate the collection of posterior distribution P of X1 and given Y 1 N it proceed as follow.",
            "First time instance you sample capitaland particles according to the prior OK and then."
        ],
        [
            "Sorry, wait those particles according to the likelihood at time one, so that give you an approximation of Postal distribution at time one.",
            "Because you don't want to obtain weighted sample, you want some pool weighted evenly to have the same weight.",
            "Your example capital."
        ],
        [
            "In times from you put your approximation of the of the Purcell distribution to obtain a new approximation, which is a number equal measure.",
            "Add the following time index.",
            "Pulling time index when you at time N -- 1 you have capital N particles approximately distributed according to the personal distribution at time N -- 1 you sample extend each pass according to the prior of."
        ],
        [
            "Mark of process you re wait everybody to take into account.",
            "Basically the new observation that has come about time and that give you this particle approximation of the target distribution form which your example capital and time to obtain a new basically approximation, multicolour approximation of booster distribution.",
            "So this is a bootstrap filter on.",
            "This is essentially the key algorithm which was proposed in 1993 by Gordon Salomon Smith.",
            "OK so it's very simple.",
            "Sample resample algorithm.",
            "So what do you?"
        ],
        [
            "So at each time N you obtain a multicolor approximation of partial distribution.",
            "I haven't detailed it actually working, but you also obtain at each time you obtain an approximation of the marginal likelihood of interest, and this is a pure byproduct of the algorithm.",
            "You get it for basically so free lunch basically estimate guess you nothing.",
            "OK, this is an algorithm which is very easy to implement and we share the computational complexity linear in the number of particles."
        ],
        [
            "On the memory requirement in most."
        ],
        [
            "Basic version increases linearly with time because you need to store basically the component X1TX N on this capital and version of it."
        ],
        [
            "However, if you're only interested in approximating not the joint distribution of X1 to XN given the observation, but you only interested in computing the marginal distribution of the last component exam given Y 1 N, then in this case the mirror requirements do not increase with the time index on for all the tracking application.",
            "This is the object you're interested in.",
            "OK, so it's very simple algorithm.",
            "It's easy to parallelize as well on for most application.",
            "Actually more memory requirements also do not increase overtime, so that's basically particle filters on.",
            "It seemed that essentially by using this sampling resampling mechanism, we will shed what we wanted to.",
            "That is, we've come up with Monte Carlo mechanism to approximate those.",
            "This sequence of high dimensional distribution.",
            "Now what I'm going to show you what I like to emphasize is that actually.",
            "We've solved part of the problem, but we haven't solve all the problem actually.",
            "So let's have a look a graphical.",
            "Let's try to illustrate graphically what that person is.",
            "Basically, when you're using particle filter."
        ],
        [
            "So I'm going to consider a very simple example, so just look at basically at the bottom of the of the pictures.",
            "So assume you want basically the particle filter.",
            "So at time on you're going to support capital N particles according basically to the prior on those styles.",
            "Here corresponds to the location of the particle X1 till die.",
            "OK, so you've got capital N of them what you're doing.",
            "Is that those particle already waited?",
            "Basically according to the likelihood giy one given X one I OK there, we waited the once you've got you waited approximate you waited on particle measure your example capital N times from dissuaded empirical measure, some particles are going to die on.",
            "Some particles are going to have multiple of spring OK."
        ],
        [
            "So what happened is that time to wear.",
            "Obviously you've lost some components here, basically corresponding to the particle which have died at time one on some particle have had multiple offspring."
        ],
        [
            "And here basically each path correspond to one particle in the past space approximating the joint distribution P of X one X2.",
            "Given Y1Y2 you re weight each of these paths according to the likelihood that time of the observation Y 2.",
            "You were going to re sample from this.",
            "Waiting on particle measure.",
            "Some particles are going to die.",
            "Some cards pulled are going to."
        ],
        [
            "People are spraying.",
            "You got posted this way.",
            "OK, so you move for awhile, OK?"
        ],
        [
            "This is for example, in this case.",
            "In simple case the approximation you get of the posterior distribution joint posterior distribution of the 24 first component to join Purcell dissolution of the 24 first component given the 24th first observation.",
            "So what do you say over where you observe that each guy here corresponds to a path OK?",
            "We see that most."
        ],
        [
            "This particle share the same on testers.",
            "OK, they have all essentially is a kind of coalescence here that shouldn't be surprising because essentially what you're doing.",
            "Particle method, sequential Monte Carlo methods.",
            "You never look backwards, so you are timeworn.",
            "You simulate capital and particle X one I.",
            "But then you are trying to.",
            "You're going to write some point.",
            "You're going to lose some diversity.",
            "You're going to move forward or something.",
            "Again, you're losing diversity.",
            "So what's happening essentially, is that.",
            "If you fix basically a time instance K OK, you look at the SMC approximation of the marginal distribution of the K first components.",
            "Given the observation.",
            "Why won TYN?",
            "If you increase N the time index, if you pick N large enough then this marginal distribution is approximated by one single deltamas OK on that.",
            "That's basically.",
            "Simply due to the fact that you're using resampling or something or something again.",
            "OK, so that's a very important thing you have to keep in mind particle filter in some sense where they're going to be good at approximating marginal distribution like P of XN given Y1Y N. But if you basically you're interested in approximating joint distribution then it's not going to do the job well actually.",
            "So it is very important thing that people sometime sometime basically.",
            "So forget so let's see basically what this is a graphical registration of what we call the degeneracy problem, so I assume you have a linear algorithm state space model.",
            "Basically what I'm going to look at is I'm going to look at basically the exact calculation of this quantity, which can be done via the Kalman filter.",
            "This is the blue line.",
            "Oh, now I'm going to basically display the SMC estimate of the same quantity, which is based simply on the SMC approximation of the joint distribution.",
            "OK, So what we see is that.",
            "Four like ER was using 1000 particle.",
            "What you see is that basically in the 1st till time say 200 they simply approximation on the theoretical result, the exact quantity they match is perfect.",
            "OK, there's no approximation error.",
            "Essentially it's very very small.",
            "But what happens is as you increase the time index.",
            "OK, well you got this degeneracy of the particle approximation that kicks in essentially after awhile.",
            "Basically, it's going to diverge.",
            "OK, so the thing you have to keep in mind is that really, when you use particle methods, use them safely.",
            "Be careful because essentially they don't approximate joint distribution well.",
            "OK, so I'm going to formalize that in terms of convergence rates."
        ],
        [
            "So what can we say about those techniques?",
            "Well, we can see actually quite a lot, so I'm just going to start discussing very weak convergence wizard and I'm gonna move on to convergence result which are actually or particle interests.",
            "So assume that you're interested in computing the expectation of a function Phi N with respect to the Postal system."
        ],
        [
            "Vision on what you consider your going to consider the SMT estimate of it, which is simply the expectation of fire and with respect to the Empire equal measure generated by the particle filter algorithm OK.",
            "Under super weak assumption, which essentially as long as the likelihood is upper bounded, where you can show that essentially the approximation converge, two other two guy at the Monte Carlo right?",
            "OK, so there's no problem.",
            "You have NP convergence as a number of particles basically goes to Infinity.",
            "You do converge toward the right guy."
        ],
        [
            "Or you can also establish on the very weak assumption with some to limit time.",
            "OK, so that's that's that's awesome.",
            "Week results that tell us that summer is the number of particles increases.",
            "Things are going to converse with outdoor idea.",
            "Obviously the."
        ],
        [
            "Swayzer tar summer meaningless, OK and you should keep that in mind.",
            "They are meaningless because essentially obviously if you pick any function fire, where typically the constant here you are seeing on the variance here you obtain, they're going to increase with the time index and."
        ],
        [
            "OK, so to obtain estimates which basically with the surge that said of the this bond is uniformly bounded in time, you will need to increase the number of particles with the time index.",
            "That is normal.",
            "It follows from the fact that the approximation of the joint distribution degenerates overtime, so that's completely normal.",
            "Can we obtain results which in some scenarios are more informative than that?",
            "Yeah, thankfully, yes, so.",
            "Consider that you are in the running this kind of particle filter on.",
            "Consider that the true filter the exact filter puts their distribution PXNYN that you're trying to approximate is such that it has some kind of exponential stability.",
            "It satisfies some kind of exponential stability condition.",
            "So what does it mean?",
            "It means that assume you have that if you were initializing your system.",
            "Basically, at the location X1 or if you were initializing at a different initial condition X, one point on.",
            "If you were running the two.",
            "Basically you were computing the two posterior distribution.",
            "Which are subject to different initial condition.",
            "If this distance, this L1 norm was converging to zero exponentially with quickly as any crisis, then it means somehow that you're trying to approximate dynamic model, which kind of forgets.",
            "Basically it's fast, OK?",
            "If you have this kind of code."
        ],
        [
            "Mission.",
            "Well, you can show result which are much stronger theoretically, so consider for example that you're interested in just computing the expectation of a function which only depends on the last component XML.",
            "OK, in this case, if you have exponential ability assumption, then you get bombs which are essentially time independent.",
            "So it means in this case that essentially you are able to provide.",
            "In approximation and numerical approximation of the marginal PRX and given the N files of Salvation which basically doesn't generate overtime.",
            "OK, so the approximation error remains."
        ],
        [
            "Founded on this is this result is why people use particle filters.",
            "Is that in most scenario essentially when you only look at the marginal distribution, there's no accumulation of errors and that's why it makes the technique attractive.",
            "Also, what you can show in the sewers under the same condition is that."
        ],
        [
            "Basically, if you look at your estimate of the marginal likelihood where the variance obviously going to increase overtime, but it only increases linearly overtime, OK on that night because if you use a stoned out, basically important sampling type technique to approximate the marginal likelihood, then typically this variance would increase exponentially with the time index.",
            "So far mystery sampling you've moved to dial from the variance.",
            "Increasing exponentially with time to violence, increasing only linearly with the time index, which is one of the men basically benefit of using this kind of resampling algorithm.",
            "OK, so now these are the coil.",
            "Do kind of basic algorithm over the past few years there's been no.",
            "Actually a lot of techniques which have been proposed to improve.",
            "Basically the algorithm.",
            "I'm just going to detail some of them very briefly.",
            "OK, so in the stone down naive algorithm, what you're doing is that you're propagating the algorithm according to the dynamic of the model on your re, weighting them according to the like."
        ],
        [
            "Mood of this observation on this is some or something which is very naive because it's like shooting in the dark.",
            "Because imagine you have a likelihood which is very picky.",
            "That is, you have observation which also assume this is your likelihood.",
            "You have likely, which is quite picky.",
            "OK, on you, instead of using the observation essentially to guide."
        ],
        [
            "Your party cooling to region of I like you.",
            "You're doing just sampling naively according to the prior, so that's obviously something very nice.",
            "You can really improve those techniques easily by simply building mechanism where the particles are propagating forward using the information conveyed by the UPS."
        ],
        [
            "Station wagon"
        ],
        [
            "They are their values.",
            "Where to do that.",
            "Essentially the best way to do it is simply to sample your particle propagator particle for Walnut according to the prior back awning to this conditional distribution, which is simply proportional to the likelihood times the prior.",
            "So there's a lot of techniques which I've been discussed in the literature like this on when you cannot use basically this distribution."
        ],
        [
            "To propagate your particle forward where you can use approximation of it.",
            "So if you can come up with approximation of this distribution using, say, unsalted carbon filter or the extended common filter, in which case you need to re weight your particle in a different way, which correct for the bias introduced by this this proposal distribution.",
            "So the lot of techniques which have been done here, I'm not going to discuss it very, very in depth.",
            "One thing I'd like to mention because it will be used we used later on."
        ],
        [
            "Is that there is 1 standard way which has been proposed to increase diversity in the number of particles so remember and when you're doing this kind of sampling or something step afterwards sampling step you sample capital."
        ],
        [
            "In time from awaited empirical measure to obtain capital and new samples.",
            "And because you sample with replacement it means that after the resampling step you have actually quite a lot of particles which are similar one to each other.",
            "They might evolve in different fashion, but they are actually."
        ],
        [
            "Similar just after the resampling step.",
            "So one way you say it's not actually a very nice approximation to have particles which are exactly the same value.",
            "So if you want to somehow add diversity, jitter, the location in the particle on still keep consistent approximation of the posterior distribution.",
            "One thing you can do is simply move them, move each particle according to an artificial dynamic which preserve the invariant distribution.",
            "So one way to do that.",
            "For people over.",
            "For those of you are familiar with MCMC is very simple.",
            "Assume you have a particle here, a pass approximately distributed according to the posterior distribution of interest.",
            "What you're doing you're sampling your sampling a new particle X prime using a kernel transition kernel can, which is such that by construction it preserved.",
            "Look, put stereo as target distribution on the way to build this target this this.",
            "This transition kernel is obviously to use MCMC type mechanism so you can mix MCMC with SMC so as to add diversity in your clouds of particles.",
            "So it's very standard techniques which has been proven very useful."
        ],
        [
            "There's work to improve.",
            "Also the resampling step, which I won't detail but allows you to reduce the violence of your approximation.",
            "One thing I'd like to discuss because this is a problem that has been basically advice many times in the literature and for which there is no satisfactory answer, is the case where now instead of doing only state estimation, you have a dynamic model F&G like before.",
            "But now those this model FG, they depend on the hyperparameter Teeter on you like.",
            "To estimate this step."
        ],
        [
            "Tick parlamentar Teeter online.",
            "Given the data?",
            "OK, so you're going to swallow invasion approach onset applier PT to on this on this parameter.",
            "OK, so in this case the object on inference before it was the posterior the Eastern State given Y naughty to is also an unknown parameter.",
            "So what I'm interested in estimating is the joint distribution of Teeter X given one OK, which."
        ],
        [
            "Admits, obviously this simple decomposition on I use here this the substrate data indicates the conditioning by the argument data.",
            "OK, so I want to estimate this kind of posterior distribution OK. On clearly.",
            "This thing is nothing but a particulare case of what I've discussed before.",
            "OK, so consider now.",
            "Basically the pulse is dead and the Markov process again, which is composed of XN extended by a parameter tee time.",
            "OK, so I'm considering this Markov process on this is indeed a Markov process which needs a strange which I need.",
            "The following transition Kernel F Zen given that N -- 1 transition kernel.",
            "Well, there's a dental mass on Tieton because teachers are static power meter.",
            "It doesn't evolve OK. Times basically the transition kernel 4X.",
            "Um G. Basically, the likelihood were similarly conditional upon then where I can write his flow.",
            "So this simple rewriting tells you that because their end is a Markov process, then I can reuse old SMC methods so as to estimate this joint posterior OK, the problem?",
            "The problem you see is that this is actually a conceptual solution, but because essentially the Markov kernel on the extended state as very poor mixing properties.",
            "All the standardized MC method so as to approximate this distribution are going to have very very poor property on that should be intuitive because things that."
        ],
        [
            "Even if you knew the power meter teacher OK. Then we've seen before that the valiance of essentially the marginal likelihood increase basically linearly in the time index.",
            "OK, so this is even if we knew Tita now in a bit."
        ],
        [
            "In the context I'm interested in, I don't know Teeter on.",
            "I'm interested in estimating the joint distribution of PT to or negative, and why so?",
            "In particular, I'm interested in estimating the marginal distribution of T&Y."
        ],
        [
            "Which is proportional to marginal likelihood typed into.",
            "This is obviously a much more complex problem, because in this case data is not even fixed, so This is why.",
            "Essentially it's kind of it's kind of.",
            "Use less, it's impossible essentially to come up with SMC methods to approximate this type of posterior distribution which do which which are essentially numerically stable.",
            "Overtime, you're going to have each time you're going to use the same semester to approximate this time with distribution.",
            "The variance can only increase other overtime.",
            "You cannot have scheme which are numerically stable.",
            "OK, so one way to kind of mitigate the problem which has been proposed many times in the literature."
        ],
        [
            "Consists of saying OK T to the big problem with basically estimating this kind of posterior distribution.",
            "Italian X&Y is the fact that Tita is is a parameter which is static which has no dynamic, so this accumulation of error.",
            "So would it be possible to introduce a kind of artificial dynamic to mitigate the problem?",
            "Yeah you can do that using some kind of MCMC steps.",
            "OK, that's been proposed several time, but you should keep in mind.",
            "That anywhere, even if you're able to do this, all the schemes rely implicitly on the approximation of the marginal distribution P of X1 XN, given yyy and which is something that you cannot approximate very well with particle filters.",
            "So you have to keep in mind that this algorithm, although they are elegant, they're going to they're going to suffer numerically.",
            "There going to be some up and stable, so I'm going to give you an example of such algorithm.",
            "And then show you that numerically you have to be a little bit careful when you're using them.",
            "So assuming at time N -- 1 on you have an approximation."
        ],
        [
            "And of the joint distribution Teeter on the component X1 XN minus one, this is your approximation of certain and minus one.",
            "What you're doing at time N simple is very similar to what we've been doing before you sample the component accented according to the prior.",
            "OK, so we wait each of the sample to obtain a new approximation."
        ],
        [
            "Of the posterior distribution at time, and which is given simply simple, it's just waited on pericle measure each weight being proportional to the likelihood.",
            "What you doing once you're done, you always sample capital N times.",
            "Only the state valuable according to this measure.",
            "This weighted empirical measure OK. On your recreate."
        ],
        [
            "Capital NU values of the parameter in the parameter space by sampling Teeter according to Y on X.",
            "So in particular, if you're dealing with models in the exponential family, you don't need to store the whole path, but that only depends.",
            "This conditional distribution only depends on a set of fixed dimensional distributors, fixed dimensional statistics, so this is a very elegant algorithm.",
            "But keep in mind that this algorithm is not going to be a form, whereas the end the small time in days ago increase because implicitly it does rely."
        ],
        [
            "On the particle approximation of this joint distribution.",
            "So if you do that numerically, this is what you're going to observe, so I've considered a very simple linear algorithm state space model basically.",
            "This is basically the evolution.",
            "This is the estimate of the expectation of Tita given the observation as any increases.",
            "All in blue.",
            "This is the true value of the parameter I'm trying to estimate.",
            "So what you see is that at the beginning your particle approximation is kind of doing well.",
            "And certainly.",
            "Well, the problem is that N is going to increases your approximation of the joint distribution is going to detail your rate on things are going to get wrong on.",
            "This is quite difficult to diagnose, so you should be very careful when you're using this type of algorithm.",
            "So that's one thing that was a cautionary warning because this technique had been kind of heavily popularized over the past few years.",
            "OK, one thing I could do though, and I'm going to think this is the last topic I will address."
        ],
        [
            "One thing I could do is perhaps not be less ambitious on instead of, instead of trying to do online version parameter estimation, let's try to do things offline.",
            "OK, so I'm going to address the same problem now.",
            "You fix the number of Salvation.",
            "I'm not interested in a sequential scheme anymore.",
            "I'm going to say let's let's try to come up with offline algorithm to estimate the joint distribution of Teeter on the state given the observation.",
            "OK?",
            "So that's what I want to do.",
            "So what I know.",
            "Is I know that if you give me theater."
        ],
        [
            "SMC method can give me an estimate of the conditional distribution of X&Y given Theta on an estimate of the marginal likelihood for."
        ],
        [
            "You have data.",
            "OK, so this is what I simply gives me.",
            "OK, so is there a way to essentially use this kind of?",
            "Multi color approximation within an 80 or 80 vulgarism such as MCMC to do inference on both Teeter on the latent variable.",
            "OK, so this is what I'm going to show.",
            "I'm going to present an algorithm which essentially combine SMC estimate on MCMC algorithm to do inference of both on both the state on the parameter.",
            "Oh"
        ],
        [
            "So the way I'm going to use that, I'm going to come out in that he's using the Metro processing algorithm, so I'm going to have a brief recap of the Metro PCs store anything algorithm.",
            "So which will be testing algorithm is the most famous MCMC algorithm available?",
            "The wait, what it does is that it's an algorithm is an iterative algorithm to sample approximately from any target quality distribution of interest.",
            "So assume you're interested in obtaining approximate sample from a distribution Pi's Ed.",
            "OK, so the match will be lasting.",
            "Algorithm is going to generate a Markov chain according to the following mechanism.",
            "So you at iteration I -- 1.",
            "OK, what you're doing is you propose a candidate and you value that star according to proposal distribution, which can be parameterized by the previous basically sample.",
            "And essentially you accept this new proposal.",
            "According to this probability.",
            "OK, so this is this simple right here.",
            "OK, so that star is accepted with probability.",
            "Also while you stay well aware, so under very very weak assumption."
        ],
        [
            "So first you can easily show that if Zed is distributed according to part of that, then after one one basically application of this foundation kernel then that prime is also distributed according to pay off.",
            "Then on the very weak assumption.",
            "Basically, even if you don't start according your Markov chain according to Pi upset then there are essentially converged by that.",
            "OK so stoned are Metro police testing algorithm.",
            "I want to use this algorithm.",
            "In my context, so as to sample from the posterior distribution of Tita or next given, why OK?",
            "So if I want to use Metro police testing?"
        ],
        [
            "Erase 'em.",
            "In my context, it means that I need to define a proposal distribution OK, Q as it started and said.",
            "So what I propose to do in in my in my context is to propose new value.",
            "Extra test are you an excellent eater?",
            "According to the following mechanism 1st, I'm going to propose a new value of T test.",
            "According to shoot it to start it off.",
            "So that could be a random walking comment.",
            "And then when I have a new value of T test, a new value of T30 desktop, I'm going to propose basically new value for the latent state variable.",
            "According to the air condition, full conditional distribution, that is P of X."
        ],
        [
            "Given why Auntie Tester, so that's basically special instance of the Metro PCs Ting algorithm.",
            "On if I do that, what is very nice with this kind of acceptance?",
            "This kind of proposal distribution is that the Metro precessing acceptance probability simplified to this simple ratio.",
            "The ratio of the marginal likelihood of the data evaluated at E tester on Teeter on all the high dimensional random variable X have disappeared from the acceptance probability.",
            "So essentially, it's like equivalent to do.",
            "MCMC only on the space.",
            "The parameter space Teeter.",
            "This is why it's called some kind of marginal Metro possessing algorithm, because X Summer's disappeared.",
            "OK, so that's an algorithm I really like to implement this algorithm.",
            "The point is simple."
        ],
        [
            "Able to implement this algorithm because you don't know.",
            "Basically, the marginal likelihood for a given value of Peter your Noble to evaluate it on you cannot sample from the posterior distribution X."
        ],
        [
            "Given why on Twitter so you cannot implement this algorithm, you cannot sample from this guy.",
            "You cannot evaluate those terms.",
            "OK, so we're going to do it like use this simple idea is to say wherever.",
            "Basically I've got this guy appearing on this guy.",
            "I'm going to substitute to this this post to sell distribution on this marginal likelihood.",
            "They're there.",
            "SMC estimate their particle estimate OK.",
            "So we're going to.",
            "We're going to consider the following algorithm is very simple.",
            "When at time iteration I -- 1 ice on polar value of the test are according to."
        ],
        [
            "To cure their proposal, I'd like to some pull from the troposphere distribution of X, given Y on T test are, but I cannot do that.",
            "So instead I run SMC algorithm to estimate this posterior distribution and marginal likelihood.",
            "Oh nice so."
        ],
        [
            "People from this approximate posterior distribution OK.",
            "Uh, no.",
            "I'm going to accept the samples.",
            "According to the following."
        ],
        [
            "Mitchell, possessing the ratio, so it's very similar to the Metro police arresting ratio that was present given in the previous slides, except that wherever I had the true marginal likelihood not substituted, the SMC estimate.",
            "That's what I'm doing, so it's kind of very naive type of approximation.",
            "OK, so this is what I'm doing.",
            "OK, so this algorithm I mean it's been proposed as a new Ristic algorithm to sample from this posterior distribution in econometrics, actually.",
            "So people use this kind of algorithm as an artistic too."
        ],
        [
            "Approximate MCMC algorithm to sample from the posterior distribution.",
            "Well, it turned out that bit miraculously, whatever being the number of particles you're using."
        ],
        [
            "OK, to approximate the posterior distribution on the marginal likelihood.",
            "Actually, this algorithm admits exactly the right inbound distribution.",
            "There's no bias whatsoever, OK?",
            "Obviously, is no free lunch.",
            "Obviously, the higher than the higher number of particles, the better of the performance of the algorithm on.",
            "Typically you have that capital N scale."
        ],
        [
            "Roughly linearly within the time index.",
            "So that's quite useful.",
            "Algorithm is going to be particularly useful when you're dealing."
        ],
        [
            "If scenario where the state you're dealing with these nuts of very high dimensions so that particle filter are doing quite a good job but T to the power meter space, you're dealing with very high dimensional, and in particular this is an algorithm which also admits what is called sometime in statistic.",
            "The plug and play property, because this is an algorithm that essentially only requires you to be able to sample from the prior distribution.",
            "You don't even need to be able to write its expression analytically, so this kind of black box algorithm so.",
            "So it can be.",
            "It can be used like to do this kind of thing."
        ],
        [
            "And I'm just going to give you a simple application to stochastic kinetic model.",
            "OK, so that's used.",
            "This type of model is used to model like biochemical networks.",
            "I mean marjoram easier, so I think he can.",
            "He knows this.",
            "Our very, very well will be able to talk to you about about it better than me."
        ],
        [
            "So this is simple model we're going to consider this simple gem Markov process like.",
            "Pray Pray data model so you get like essentially there's a continuous time process on your interested.",
            "Essentially, you're observing one of the component.",
            "Basically in some noise on your intro."
        ],
        [
            "The latest mating, the kinetic component of this gem Markov process in some noise if you try to do in CMC so as to essentially estimate the parameter in the state you observation it's visible but using sonar MTMT is a bit of a pain because essentially because there's a kind of unknown number of basically jump into the market jump process, you obliged to use reversible jumps algorithm type algorithm.",
            "So it could be a bit painful to Kurt.",
            "It could be difficult basically to converge where.",
            "If you use this type of algorithm, commanding SMC on MCMC, the only thing already you require is being able to sample forward from this.",
            "This John Markoff process which is feasible thanks to what is called in the literature as the Gillepsie algorithm.",
            "And this is Friday."
        ],
        [
            "One example of inference.",
            "So this is here to pray the number of prey on the number of predator overtime.",
            "You only observe the process at some discrete time instance OK. And when you want to do inference about that is actually quite complicated, because don't forget that the latent causes a continuous state process.",
            "So you need to infer actually the really large number of latent, valuable.",
            "But it turns out it's not too complicated with this type of like particle MCMC type algorithm.",
            "So this is kind of example of inference we obtain with.",
            "This is simulated data true value on the posterior distribution associated to this guy.",
            "OK, I'm just not going to detail all the slide on smoothing.",
            "What I'd like to say is that for the time being in this part of the talk, I've discussed all the algorithm I've discussed essentially rely on the SMC approximation of the joint distribution on.",
            "I've told you that basically this type of approximation degrades overtime OK at the time index increase.",
            "There's a lot of methods available in the literature, some kind of smoothing algorithm which do not suffer.",
            "From this problem which can be used as an alternative to the kind of direct pass approximation."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the talk has two parts.",
                    "label": 0
                },
                {
                    "sent": "The first part will be by Arner to set and I'll do an introduction before hand, so to kind of create a set up for people who haven't seen this before.",
                    "label": 0
                },
                {
                    "sent": "I know we'll basically be talking about particle filtering for state space models, and he will discuss some algorithms that we need.",
                    "label": 0
                },
                {
                    "sent": "A lot of us are very familiar with in this community, but then he will introduce some recent new developments that he's been working on with colleagues where he's looking at the issues of parameter learning, not just filtering and state estimation, but trying to go beyond to do tackle problems like smoothing.",
                    "label": 0
                },
                {
                    "sent": "And learning.",
                    "label": 0
                },
                {
                    "sent": "After that we this tutorials are kind of long, so we're going to have a short break.",
                    "label": 0
                },
                {
                    "sent": "And then I will look into particle filtering.",
                    "label": 0
                },
                {
                    "sent": "But I will consider other type of problems that we don't often deal with things like eigenvalue problems, protein folding problems, control problems and static distributions and so on.",
                    "label": 0
                },
                {
                    "sent": "And also some very interesting ways of learning ABC.",
                    "label": 0
                },
                {
                    "sent": "ABC's like this really cool.",
                    "label": 0
                },
                {
                    "sent": "Bayesian technique where you can learn.",
                    "label": 0
                },
                {
                    "sent": "If you can imagine it basically so only these.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Four topics were covered basically at the end of the 20th century and most of what we're going to talk about will be new things.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Many, many people in this community have worked in this problem and many communities to have attacked this problem.",
                    "label": 0
                },
                {
                    "sent": "People in control, people in signal processing, people in statistics and physics, and so on, and they all give the method different names and slightly different methodologies and will try to bring to your attention some of these.",
                    "label": 0
                },
                {
                    "sent": "In machine learning, the method became popular with Andrew Blake, and Michael is serving the Computer Vision application, you know, sort of.",
                    "label": 0
                },
                {
                    "sent": "I'll show you some examples.",
                    "label": 0
                },
                {
                    "sent": "Many people have contributed to the method in AI.",
                    "label": 0
                },
                {
                    "sent": "I've left some here without mentioning just already Moon's face.",
                    "label": 0
                },
                {
                    "sent": "He's done a lot of work with this too, and I'm sure I'm missing some of you in the audience.",
                    "label": 0
                },
                {
                    "sent": "So what's particle filtering?",
                    "label": 0
                },
                {
                    "sent": "So it's a technique for approximating distributions that evolve overtime that have some sort of dynamics.",
                    "label": 0
                },
                {
                    "sent": "But it can also be useful static distributions as I'll talk about it at the end, but for now, let's consider dynamic distributions.",
                    "label": 0
                },
                {
                    "sent": "The idea is we want to approximate distribution and the way we do it is we draw samples from this red distribution.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then if we just count how many samples fall in each bin, we get a histogram is approximation of this.",
                    "label": 0
                },
                {
                    "sent": "And we can give weights to these different samples, which is what we call particles as well.",
                    "label": 0
                },
                {
                    "sent": "And that allows us to get a good representation of this and here we kind of see how these particles propagate overtime.",
                    "label": 0
                },
                {
                    "sent": "And if they're doing well.",
                    "label": 0
                },
                {
                    "sent": "They get a bigger weight, so there's sort of a survival of the Fittest.",
                    "label": 0
                },
                {
                    "sent": "Aspect to this, and here's another picture of the same thing where you showed that the how the distribution is evolving.",
                    "label": 0
                },
                {
                    "sent": "Overtime.",
                    "label": 0
                },
                {
                    "sent": "And you're able to, in this case, track a target that actually has two possible hypothesis of where it could be going, and so you have to maintain all your hypothesis in.",
                    "label": 0
                },
                {
                    "sent": "So here is an example.",
                    "label": 0
                },
                {
                    "sent": "Offer how you can use.",
                    "label": 0
                },
                {
                    "sent": "Particles.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Particles here just you're trying to estimate a probability distribution for the location of these players being tracked.",
                    "label": 0
                },
                {
                    "sent": "And each of these blue boxes, like in this player is a particle.",
                    "label": 0
                },
                {
                    "sent": "And then when you take the average is sort of get to mean you attract these things in video on the TV you don't project them to the world using some basic geometry and then you have sort of trajectory's you know what the person was doing.",
                    "label": 0
                },
                {
                    "sent": "And it's.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "As in the game.",
                    "label": 0
                },
                {
                    "sent": "And you can also play soccer and these videos I got from Dieter Fox is gas.",
                    "label": 0
                },
                {
                    "sent": "Countless animations in his website definitely recommend you look at this.",
                    "label": 0
                },
                {
                    "sent": "So here the particles represent the position of the ball and the position of the robot.",
                    "label": 0
                },
                {
                    "sent": "The robot is learning what is trying to locate itself and locate the ball.",
                    "label": 0
                },
                {
                    "sent": "A more impressive application, also teacher is a particle filter where the particles here represent an estimate of what the person is in the city of Seattle I believe, and then the particle filter also represents another state, which is where it believes the person is guided two.",
                    "label": 0
                },
                {
                    "sent": "So it's a hierarchical setting with you know what the person goes.",
                    "label": 0
                },
                {
                    "sent": "It helps you with the tracking and then there is a sort of particles following the person and this data was using to actually help people with.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Some forms of dementia and so on.",
                    "label": 0
                },
                {
                    "sent": "So 'cause you want to make sure that you can track them and you have an idea of what they're doing and Detective they've maybe caught the wrong bus and so that you can then intervene in a system you sort of don't intervene all the time because it can be very annoying.",
                    "label": 0
                },
                {
                    "sent": "Answer You you need to get good estimates of what's going on.",
                    "label": 0
                },
                {
                    "sent": "And the type of model that.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Dieter has is a something that looks more or less like this where you have some observations or evolve overtime.",
                    "label": 0
                },
                {
                    "sent": "There's some discrete states that represent the unknown location, and then there is a sort of meta variable that indicates what the plan is.",
                    "label": 0
                },
                {
                    "sent": "Where, where is the person trying to reach at least type of factor representations have been used a lot with particle filtering.",
                    "label": 0
                },
                {
                    "sent": "They used and also industrial setups in actual applications.",
                    "label": 0
                },
                {
                    "sent": "One important thing is when you have structure in the graph you should exploit structure as much as possible.",
                    "label": 0
                },
                {
                    "sent": "And you should do analytical computation as much as possible.",
                    "label": 0
                },
                {
                    "sent": "Don't do Monte Carlo if you don't need to do it.",
                    "label": 0
                },
                {
                    "sent": "It's really a last resort method.",
                    "label": 0
                },
                {
                    "sent": "And indeed, when we exploit structure, these algorithms in terms of errors tend to do incredibly better.",
                    "label": 0
                },
                {
                    "sent": "The methods that arnibal discuss also apply to setups in which the number of unknowns is changing overtime.",
                    "label": 0
                },
                {
                    "sent": "Particle filters are very good for that, that we are able to estimate the so-called partition function, or normalization constant.",
                    "label": 0
                },
                {
                    "sent": "So we can do model selection relatively easily compared to how it's done with traditional methods.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I can see and see.",
                    "label": 0
                },
                {
                    "sent": "Method is a really old one.",
                    "label": 0
                },
                {
                    "sent": "It really goes back to.",
                    "label": 0
                },
                {
                    "sent": "The 1st paper of Metropoles, an older man 1949.",
                    "label": 0
                },
                {
                    "sent": "It's like a four page paper, but it has so much in it it's really worth reading every sentence few times.",
                    "label": 0
                },
                {
                    "sent": "And of course they were interested in this kind of problems too.",
                    "label": 0
                },
                {
                    "sent": "Blow up things and this is a picture of the ENIAC and the programmers of the time who this kind of has changed overtime.",
                    "label": 0
                },
                {
                    "sent": "Phenomen actually needed someone to code these algorithms.",
                    "label": 0
                },
                {
                    "sent": "He invented important sampling action, a small letter.",
                    "label": 0
                },
                {
                    "sent": "He actually writes a note to someone and he says I believe when they're computer should be able to understand.",
                    "label": 0
                },
                {
                    "sent": "These steps, and he puts like line numbers and so on in the program so.",
                    "label": 0
                },
                {
                    "sent": "Soon later, he invented the.",
                    "label": 0
                },
                {
                    "sent": "You know, the architecture for these things for the.",
                    "label": 0
                },
                {
                    "sent": "How are computers?",
                    "label": 0
                },
                {
                    "sent": "And many people have been involved with this, starting with Enrico Fermi for Neumann, Ola Metro police, who is actually Delaware around Metropolis.",
                    "label": 0
                },
                {
                    "sent": "Who was the coder that they have young physicist that they got to come and Cody's machine and then became the famous metropolis in physics.",
                    "label": 0
                },
                {
                    "sent": "Alot of them actually spend the rest of their lives campaigning for peace.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Next well, talking to many people have worked on this method and there's been incredible amounts of work in different physics and in the world of phylogenetic trees in artificial intelligence.",
                    "label": 0
                },
                {
                    "sent": "This really huge.",
                    "label": 0
                },
                {
                    "sent": "The Russians were there too.",
                    "label": 0
                },
                {
                    "sent": "They did some zaritsky and so on that did amazing things over the last 10 years.",
                    "label": 0
                },
                {
                    "sent": "Aren't done a lot of work in this method and he will tell you next what he's been up to.",
                    "label": 0
                },
                {
                    "sent": "So obviously I wasn't aware.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The last slide.",
                    "label": 0
                },
                {
                    "sent": "Date.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So after the informal introduction of non do I'm going to talk more about the mathematical aspects of particle filters on goal for the equations.",
                    "label": 0
                },
                {
                    "sent": "So I will give a few convergence results and I will explain the limitation also of the technique.",
                    "label": 0
                },
                {
                    "sent": "OK, so I'm going to.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Introduced like mathematically, the class of models were considering.",
                    "label": 0
                },
                {
                    "sent": "So basically we're dealing with the class of a state space model, also known as hidden Markov model or partially observed dynamic model.",
                    "label": 0
                },
                {
                    "sent": "So the way those models work is as follows.",
                    "label": 0
                },
                {
                    "sent": "So first you have to earn observe Markov process XC.",
                    "label": 0
                },
                {
                    "sent": "Which is defined basically by its initial density, new on a transition density F. So that defines basically the process.",
                    "label": 0
                },
                {
                    "sent": "The later instead process you're interested in.",
                    "label": 0
                },
                {
                    "sent": "Or you don't have access to XC.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You only have access to related observation process, YK or?",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Let you you assume is that the observation whites uik you collect our search that conditionally upon the process XC the observation ycr marginally distributed according to a density G OK.",
                    "label": 0
                },
                {
                    "sent": "So what you want to do, mathematical E is essentially want to estimate the latent state process XK.",
                    "label": 0
                },
                {
                    "sent": "Given the observation process, YK, or you want to.",
                    "label": 0
                },
                {
                    "sent": "You might want to do this online or offline.",
                    "label": 0
                },
                {
                    "sent": "OK, so I will first discuss the offline aspects, but by the end of the talk I will move basically to offline inference.",
                    "label": 0
                },
                {
                    "sent": "So essentially I want to estimate X given Y, so formal, essentially a conceptual point of view.",
                    "label": 0
                },
                {
                    "sent": "This is a trivial task, there's nothing complicated about that.",
                    "label": 0
                },
                {
                    "sent": "OK, so assume you'll give.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In a collection of observation Y2Y1Y N I'm using Matlab notation on, you want to infer the state X One X2, XN where basically inference rely on the posterior distribution P of X given Y, which is simply given by the joint distribution P of X, Y / P Y on what do I know where I know this distribution up to normalizing constant because P of XY by definition is P of X time.",
                    "label": 0
                },
                {
                    "sent": "PY given X, it follows.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "From the markup assumption on the Macondo Dimarco has sunshine of XC, that deployer can be written as follow on.",
                    "label": 0
                },
                {
                    "sent": "It follows from the assumption on the observation process that the conditional likelihood of Salvation given of Y given X is simply given by the product margin Loan City.",
                    "label": 0
                },
                {
                    "sent": "OK, the marginal likelihood is obviously given by the expect.",
                    "label": 0
                },
                {
                    "sent": "The integral of the joint distribution in respect to the latent process.",
                    "label": 0
                },
                {
                    "sent": "So conceptually there's absolutely no problem on what I want to do already.",
                    "label": 0
                },
                {
                    "sent": "What I'm interested in.",
                    "label": 0
                },
                {
                    "sent": "It's first to come up with algorithm to compute the posterior distribution on the marginal likelihood sequentially with the time, and so I want to come up with sequential algorithm to estimate the sequence of his tail distribution.",
                    "label": 0
                },
                {
                    "sent": "X1 and Y1, and on the marginal likelihood.",
                    "label": 0
                },
                {
                    "sent": "Why one OK, as any increases.",
                    "label": 0
                },
                {
                    "sent": "OK, so that's not difficult from a conceptual point of view, But the problem is.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Actually, if you're dealing with nonlinear non Gaussian models, then there's no closed form expression.",
                    "label": 0
                },
                {
                    "sent": "Basically, for this poster distribution on is no closed form expression for the marginal likelihood.",
                    "label": 0
                },
                {
                    "sent": "They obviously a couple of very important exception important exception where you can do those calculations analytically, include the class of linear algorithm, state space model, in which case you can use the Kalman filter or the case where X takes value in a discrete in a finite state space, in which case you can do also order the calculation analytically.",
                    "label": 0
                },
                {
                    "sent": "But as soon as you're going to have basically model which is nonlinear non Gaussian, you gonna need to come up with numerical approximation for this quantities.",
                    "label": 0
                },
                {
                    "sent": "So the typical way the stone away to approximate those techniques consist basically of making functional type approximation.",
                    "label": 0
                },
                {
                    "sent": "So for example you could say where this thing is, frogs for example is definitely not Goshen, but let's approximate it by Gaussian distribution.",
                    "label": 0
                },
                {
                    "sent": "So this is for example the kind of assumption which are made by algorithm such that.",
                    "label": 0
                },
                {
                    "sent": "Such as the unsalted carbon filter or the extended camel filter.",
                    "label": 0
                },
                {
                    "sent": "We're not going to discuss this kind of this kind of basically of approximation.",
                    "label": 0
                },
                {
                    "sent": "We're going to discuss, discuss a class of Monte Carlo methods, where essentially we do not make any functional approximation on the posterior distribution of interest on the method.",
                    "label": 1
                },
                {
                    "sent": "We're going to basically discuss are in some sense, aseptically consistent.",
                    "label": 0
                },
                {
                    "sent": "That is, if you increase your computational effort, they're going to converge throughout the true.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Basically, distribution or the toolbar Gino like you.",
                    "label": 0
                },
                {
                    "sent": "So the terms of technique we're using is Monte Carlo methods.",
                    "label": 0
                },
                {
                    "sent": "So I'm just going to go very briefly for the very very basics or not the kilometers.",
                    "label": 0
                },
                {
                    "sent": "So assume basically you're interested in approximating or high dimensional distribution, so the ignore case this is the posterior distribution of X given the observation Y multicare approximation, you're going to sample capital N particles random sample according to.",
                    "label": 0
                },
                {
                    "sent": "The distribution of interest on your monitor color approximation is simply the empirical measure of the associated random sample.",
                    "label": 0
                },
                {
                    "sent": "OK, so that the simple or the way you approx.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Made basically I dimensional distribution using motor kilometers on.",
                    "label": 0
                },
                {
                    "sent": "Why is it a clever way to do it, where it's a clever way to do it?",
                    "label": 0
                },
                {
                    "sent": "Because essentially the sample can't.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Don't write each self naturally in region of high priority mass.",
                    "label": 0
                },
                {
                    "sent": "OK, so once we've got to assume you're able to come up with such a Monte Carlo approximation of the posterior, where is good, because in this case assume then you want to compute the expectation of a test function 5 respect to the true posterior, where to get an estimate of it you substitute to the true posterior.",
                    "label": 0
                },
                {
                    "sent": "It's multicolor estimate on that give you basically multicolor estimate of the expectation.",
                    "label": 0
                },
                {
                    "sent": "If you're interested also, not.",
                    "label": 0
                },
                {
                    "sent": "Basically, in computing an expectation that you're interested in computing approximating a marginal distribution, say of the component XK, given all the observation where you can get directly or multicolor approximation of the margin, or the only thing you need to do is to keep the component XC in your empirical measure.",
                    "label": 0
                },
                {
                    "sent": "So that's very nice if you're if you're able to come over essentially with the Monte Carlo approximation of the posterior distribution, you can do all calculation very nicely.",
                    "label": 0
                },
                {
                    "sent": "It's very easy.",
                    "label": 0
                },
                {
                    "sent": "OK, so that's that's good.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The problem is you cannot.",
                    "label": 0
                },
                {
                    "sent": "Sorry.",
                    "label": 0
                },
                {
                    "sent": "The problem is that, well, I don't know how to sample from the side emotional distribution, so if I could do it would be great.",
                    "label": 0
                },
                {
                    "sent": "The problem is I cannot do that OK exactly so OK, so I'm going to have basically to use something else where I'm not going to be able to come up with a very nice approximation.",
                    "label": 0
                },
                {
                    "sent": "Multicolour approximation of the posterior distributions of interest, but I'm going to be able to come up with basically approximate Monte Carlo in some sense that are going to still give me.",
                    "label": 0
                },
                {
                    "sent": "Basically, approximation of this form, so this is what I'm going to.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Explain now.",
                    "label": 0
                },
                {
                    "sent": "OK, so the way we're going to do because we essentially unable to sample directly from this really high dimensional probability distribution where we're going to use a kind of divide and conquer strategy.",
                    "label": 0
                },
                {
                    "sent": "So what we're going to do is say to some pool approximately from this posterior distribution.",
                    "label": 0
                },
                {
                    "sent": "I'm going to decompose this problem in the collection of much simpler subproblems.",
                    "label": 0
                },
                {
                    "sent": "So first, what I'm going to do is at time one, I'm going to come, we come up with.",
                    "label": 0
                },
                {
                    "sent": "Multi kilometers to approximate this low dimensional distribution, which is P of X1 given Y one.",
                    "label": 0
                },
                {
                    "sent": "Once I obtain a Monte Carlo approximation of people say.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Distribution at time one I'm going to move to time two.",
                    "label": 0
                },
                {
                    "sent": "I'm going to basically come up with an approximation of the distribution P of X11X1 or X2 given Y1Y2 on to come up with multicolour approximation of these guy I'm going to reuse the multicolor approximation I had obtained a time one.",
                    "label": 0
                },
                {
                    "sent": "So this is kind of building a collection of nested sequence of Monte Carlo approximation on the way I'm going to do that is essentially.",
                    "label": 1
                },
                {
                    "sent": "By propagating a cloud of random samples forward according to two mechanisms, which are mechanism of important sampling mechanism of resampling and this is what I'm going to explain you now OK?",
                    "label": 0
                },
                {
                    "sent": "So the way it works.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Follow this very simple math.",
                    "label": 0
                },
                {
                    "sent": "There's really nothing difficult about that.",
                    "label": 0
                },
                {
                    "sent": "Usum you at time N minus one small N -- 1 only assume that that time N -- 1 you have Monte Carlo approximation of the target distribution of interest that tease you have capital N random sample approximately distributed according to the target distribution of interest, so that's what you're given at time N -- 1 on.",
                    "label": 1
                },
                {
                    "sent": "Essentially given this multicolour approximation of the target distribution at time N -- 1.",
                    "label": 0
                },
                {
                    "sent": "You want to obtain your naproxen.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Target at time.",
                    "label": 0
                },
                {
                    "sent": "To do where you're going to do that is quite simple.",
                    "label": 0
                },
                {
                    "sent": "So at time of minus one, you've got this capital and particles are is going from one to capital N distributed according to personal distribution at time N -- 1 you extend each of these paths here.",
                    "label": 1
                },
                {
                    "sent": "According your going to sample the new component accent~ according to the prior distribution of the dynamic model and the consideration.",
                    "label": 0
                },
                {
                    "sent": "OK, this is what you're doing on you rebuild, you rename, you pass X1 until then.",
                    "label": 0
                },
                {
                    "sent": "So these guys by construction they are distributed according to the posterior distribution of X1 till XN given the observation till 10 -- 1.",
                    "label": 0
                },
                {
                    "sent": "So you build an approximation of the predictive distribution.",
                    "label": 0
                },
                {
                    "sent": "So this is a multi color approximation of the of the predictive distribution.",
                    "label": 0
                },
                {
                    "sent": "This is not what you're interested in or remember that what you're interested in is a time and you're interested in basically the posterior distribution at time N.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, which is simply given forms to base formula by basically predicted that I'm in multiplied by the likelihood of the observation attachment.",
                    "label": 0
                },
                {
                    "sent": "OK, so it's very simple.",
                    "label": 0
                },
                {
                    "sent": "So now what you do well is going to be easy to approximate this posterior distribution where you're going to substitute too.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This guy you're going to replace this guy, but it's Monte Carlo approximation, so you plug this empirical measure in this in the base form.",
                    "label": 0
                },
                {
                    "sent": "That's very simple.",
                    "label": 0
                },
                {
                    "sent": "And what do you obtain?",
                    "label": 0
                },
                {
                    "sent": "Well, you up saying simply at, I'm in an airport simulation, a multicolor approximation of the target distribution.",
                    "label": 0
                },
                {
                    "sent": "So there is simply we just sample forward, basically with extended each pass according to the prior distribution.",
                    "label": 0
                },
                {
                    "sent": "We've already waited all the paths according to their likelihood.",
                    "label": 0
                },
                {
                    "sent": "On that give me a new approximation of the target at time, so it's a collection.",
                    "label": 1
                },
                {
                    "sent": "It's a weighted sum of Delta mass where each weight is proportional to the likelihood of the sample.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So that's it.",
                    "label": 1
                },
                {
                    "sent": "This is an approximation of the target distribution at time N, but we're not very happy with this, because what we want a timer.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is to obtain Capitaland random sample approximately distributed according to the target distribution at time, and So what I'm going to do is very simple.",
                    "label": 0
                },
                {
                    "sent": "Once I've got this approximation of the posterior distribution time and I'm gonna re some poor capital N times from this weighted on pure equal measure to obtain capital and sample approximately distributed according to the target distribution at time.",
                    "label": 0
                },
                {
                    "sent": "OK here we go.",
                    "label": 0
                },
                {
                    "sent": "This is the new basically multicolor approximation of the posterior distribution attachment.",
                    "label": 0
                },
                {
                    "sent": "So this is the way you move from an empirical measure approximating the target distribution.",
                    "label": 0
                },
                {
                    "sent": "At time N -- 1 to new empirical measure approximating the target.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Solution at time.",
                    "label": 0
                },
                {
                    "sent": "OK on these three samping mechanism it looks a bit a duck in a sense, because it seems like a computational trick on it might not have good convergence properties.",
                    "label": 0
                },
                {
                    "sent": "Will see that actually this week.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Something step decide of resampling from this weighted empirical measure is what makes particle filters well, and I'll discuss that later.",
                    "label": 0
                },
                {
                    "sent": "So to summarize the basic particle filter so as to approximate the collection of posterior distribution P of X1 and given Y 1 N it proceed as follow.",
                    "label": 0
                },
                {
                    "sent": "First time instance you sample capitaland particles according to the prior OK and then.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Sorry, wait those particles according to the likelihood at time one, so that give you an approximation of Postal distribution at time one.",
                    "label": 0
                },
                {
                    "sent": "Because you don't want to obtain weighted sample, you want some pool weighted evenly to have the same weight.",
                    "label": 0
                },
                {
                    "sent": "Your example capital.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In times from you put your approximation of the of the Purcell distribution to obtain a new approximation, which is a number equal measure.",
                    "label": 0
                },
                {
                    "sent": "Add the following time index.",
                    "label": 0
                },
                {
                    "sent": "Pulling time index when you at time N -- 1 you have capital N particles approximately distributed according to the personal distribution at time N -- 1 you sample extend each pass according to the prior of.",
                    "label": 1
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Mark of process you re wait everybody to take into account.",
                    "label": 0
                },
                {
                    "sent": "Basically the new observation that has come about time and that give you this particle approximation of the target distribution form which your example capital and time to obtain a new basically approximation, multicolour approximation of booster distribution.",
                    "label": 0
                },
                {
                    "sent": "So this is a bootstrap filter on.",
                    "label": 0
                },
                {
                    "sent": "This is essentially the key algorithm which was proposed in 1993 by Gordon Salomon Smith.",
                    "label": 0
                },
                {
                    "sent": "OK so it's very simple.",
                    "label": 0
                },
                {
                    "sent": "Sample resample algorithm.",
                    "label": 0
                },
                {
                    "sent": "So what do you?",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So at each time N you obtain a multicolor approximation of partial distribution.",
                    "label": 0
                },
                {
                    "sent": "I haven't detailed it actually working, but you also obtain at each time you obtain an approximation of the marginal likelihood of interest, and this is a pure byproduct of the algorithm.",
                    "label": 0
                },
                {
                    "sent": "You get it for basically so free lunch basically estimate guess you nothing.",
                    "label": 0
                },
                {
                    "sent": "OK, this is an algorithm which is very easy to implement and we share the computational complexity linear in the number of particles.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "On the memory requirement in most.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Basic version increases linearly with time because you need to store basically the component X1TX N on this capital and version of it.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "However, if you're only interested in approximating not the joint distribution of X1 to XN given the observation, but you only interested in computing the marginal distribution of the last component exam given Y 1 N, then in this case the mirror requirements do not increase with the time index on for all the tracking application.",
                    "label": 0
                },
                {
                    "sent": "This is the object you're interested in.",
                    "label": 0
                },
                {
                    "sent": "OK, so it's very simple algorithm.",
                    "label": 0
                },
                {
                    "sent": "It's easy to parallelize as well on for most application.",
                    "label": 0
                },
                {
                    "sent": "Actually more memory requirements also do not increase overtime, so that's basically particle filters on.",
                    "label": 0
                },
                {
                    "sent": "It seemed that essentially by using this sampling resampling mechanism, we will shed what we wanted to.",
                    "label": 0
                },
                {
                    "sent": "That is, we've come up with Monte Carlo mechanism to approximate those.",
                    "label": 0
                },
                {
                    "sent": "This sequence of high dimensional distribution.",
                    "label": 0
                },
                {
                    "sent": "Now what I'm going to show you what I like to emphasize is that actually.",
                    "label": 0
                },
                {
                    "sent": "We've solved part of the problem, but we haven't solve all the problem actually.",
                    "label": 0
                },
                {
                    "sent": "So let's have a look a graphical.",
                    "label": 0
                },
                {
                    "sent": "Let's try to illustrate graphically what that person is.",
                    "label": 0
                },
                {
                    "sent": "Basically, when you're using particle filter.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So I'm going to consider a very simple example, so just look at basically at the bottom of the of the pictures.",
                    "label": 0
                },
                {
                    "sent": "So assume you want basically the particle filter.",
                    "label": 0
                },
                {
                    "sent": "So at time on you're going to support capital N particles according basically to the prior on those styles.",
                    "label": 0
                },
                {
                    "sent": "Here corresponds to the location of the particle X1 till die.",
                    "label": 0
                },
                {
                    "sent": "OK, so you've got capital N of them what you're doing.",
                    "label": 0
                },
                {
                    "sent": "Is that those particle already waited?",
                    "label": 0
                },
                {
                    "sent": "Basically according to the likelihood giy one given X one I OK there, we waited the once you've got you waited approximate you waited on particle measure your example capital N times from dissuaded empirical measure, some particles are going to die on.",
                    "label": 0
                },
                {
                    "sent": "Some particles are going to have multiple of spring OK.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So what happened is that time to wear.",
                    "label": 0
                },
                {
                    "sent": "Obviously you've lost some components here, basically corresponding to the particle which have died at time one on some particle have had multiple offspring.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And here basically each path correspond to one particle in the past space approximating the joint distribution P of X one X2.",
                    "label": 0
                },
                {
                    "sent": "Given Y1Y2 you re weight each of these paths according to the likelihood that time of the observation Y 2.",
                    "label": 0
                },
                {
                    "sent": "You were going to re sample from this.",
                    "label": 0
                },
                {
                    "sent": "Waiting on particle measure.",
                    "label": 0
                },
                {
                    "sent": "Some particles are going to die.",
                    "label": 0
                },
                {
                    "sent": "Some cards pulled are going to.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "People are spraying.",
                    "label": 0
                },
                {
                    "sent": "You got posted this way.",
                    "label": 0
                },
                {
                    "sent": "OK, so you move for awhile, OK?",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is for example, in this case.",
                    "label": 0
                },
                {
                    "sent": "In simple case the approximation you get of the posterior distribution joint posterior distribution of the 24 first component to join Purcell dissolution of the 24 first component given the 24th first observation.",
                    "label": 0
                },
                {
                    "sent": "So what do you say over where you observe that each guy here corresponds to a path OK?",
                    "label": 0
                },
                {
                    "sent": "We see that most.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This particle share the same on testers.",
                    "label": 0
                },
                {
                    "sent": "OK, they have all essentially is a kind of coalescence here that shouldn't be surprising because essentially what you're doing.",
                    "label": 0
                },
                {
                    "sent": "Particle method, sequential Monte Carlo methods.",
                    "label": 1
                },
                {
                    "sent": "You never look backwards, so you are timeworn.",
                    "label": 0
                },
                {
                    "sent": "You simulate capital and particle X one I.",
                    "label": 0
                },
                {
                    "sent": "But then you are trying to.",
                    "label": 0
                },
                {
                    "sent": "You're going to write some point.",
                    "label": 0
                },
                {
                    "sent": "You're going to lose some diversity.",
                    "label": 0
                },
                {
                    "sent": "You're going to move forward or something.",
                    "label": 0
                },
                {
                    "sent": "Again, you're losing diversity.",
                    "label": 0
                },
                {
                    "sent": "So what's happening essentially, is that.",
                    "label": 0
                },
                {
                    "sent": "If you fix basically a time instance K OK, you look at the SMC approximation of the marginal distribution of the K first components.",
                    "label": 0
                },
                {
                    "sent": "Given the observation.",
                    "label": 0
                },
                {
                    "sent": "Why won TYN?",
                    "label": 0
                },
                {
                    "sent": "If you increase N the time index, if you pick N large enough then this marginal distribution is approximated by one single deltamas OK on that.",
                    "label": 0
                },
                {
                    "sent": "That's basically.",
                    "label": 0
                },
                {
                    "sent": "Simply due to the fact that you're using resampling or something or something again.",
                    "label": 0
                },
                {
                    "sent": "OK, so that's a very important thing you have to keep in mind particle filter in some sense where they're going to be good at approximating marginal distribution like P of XN given Y1Y N. But if you basically you're interested in approximating joint distribution then it's not going to do the job well actually.",
                    "label": 0
                },
                {
                    "sent": "So it is very important thing that people sometime sometime basically.",
                    "label": 0
                },
                {
                    "sent": "So forget so let's see basically what this is a graphical registration of what we call the degeneracy problem, so I assume you have a linear algorithm state space model.",
                    "label": 0
                },
                {
                    "sent": "Basically what I'm going to look at is I'm going to look at basically the exact calculation of this quantity, which can be done via the Kalman filter.",
                    "label": 0
                },
                {
                    "sent": "This is the blue line.",
                    "label": 0
                },
                {
                    "sent": "Oh, now I'm going to basically display the SMC estimate of the same quantity, which is based simply on the SMC approximation of the joint distribution.",
                    "label": 0
                },
                {
                    "sent": "OK, So what we see is that.",
                    "label": 0
                },
                {
                    "sent": "Four like ER was using 1000 particle.",
                    "label": 0
                },
                {
                    "sent": "What you see is that basically in the 1st till time say 200 they simply approximation on the theoretical result, the exact quantity they match is perfect.",
                    "label": 0
                },
                {
                    "sent": "OK, there's no approximation error.",
                    "label": 0
                },
                {
                    "sent": "Essentially it's very very small.",
                    "label": 0
                },
                {
                    "sent": "But what happens is as you increase the time index.",
                    "label": 0
                },
                {
                    "sent": "OK, well you got this degeneracy of the particle approximation that kicks in essentially after awhile.",
                    "label": 0
                },
                {
                    "sent": "Basically, it's going to diverge.",
                    "label": 0
                },
                {
                    "sent": "OK, so the thing you have to keep in mind is that really, when you use particle methods, use them safely.",
                    "label": 0
                },
                {
                    "sent": "Be careful because essentially they don't approximate joint distribution well.",
                    "label": 0
                },
                {
                    "sent": "OK, so I'm going to formalize that in terms of convergence rates.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So what can we say about those techniques?",
                    "label": 0
                },
                {
                    "sent": "Well, we can see actually quite a lot, so I'm just going to start discussing very weak convergence wizard and I'm gonna move on to convergence result which are actually or particle interests.",
                    "label": 0
                },
                {
                    "sent": "So assume that you're interested in computing the expectation of a function Phi N with respect to the Postal system.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Vision on what you consider your going to consider the SMT estimate of it, which is simply the expectation of fire and with respect to the Empire equal measure generated by the particle filter algorithm OK.",
                    "label": 0
                },
                {
                    "sent": "Under super weak assumption, which essentially as long as the likelihood is upper bounded, where you can show that essentially the approximation converge, two other two guy at the Monte Carlo right?",
                    "label": 0
                },
                {
                    "sent": "OK, so there's no problem.",
                    "label": 0
                },
                {
                    "sent": "You have NP convergence as a number of particles basically goes to Infinity.",
                    "label": 0
                },
                {
                    "sent": "You do converge toward the right guy.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Or you can also establish on the very weak assumption with some to limit time.",
                    "label": 0
                },
                {
                    "sent": "OK, so that's that's that's awesome.",
                    "label": 0
                },
                {
                    "sent": "Week results that tell us that summer is the number of particles increases.",
                    "label": 0
                },
                {
                    "sent": "Things are going to converse with outdoor idea.",
                    "label": 0
                },
                {
                    "sent": "Obviously the.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Swayzer tar summer meaningless, OK and you should keep that in mind.",
                    "label": 0
                },
                {
                    "sent": "They are meaningless because essentially obviously if you pick any function fire, where typically the constant here you are seeing on the variance here you obtain, they're going to increase with the time index and.",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so to obtain estimates which basically with the surge that said of the this bond is uniformly bounded in time, you will need to increase the number of particles with the time index.",
                    "label": 0
                },
                {
                    "sent": "That is normal.",
                    "label": 0
                },
                {
                    "sent": "It follows from the fact that the approximation of the joint distribution degenerates overtime, so that's completely normal.",
                    "label": 0
                },
                {
                    "sent": "Can we obtain results which in some scenarios are more informative than that?",
                    "label": 0
                },
                {
                    "sent": "Yeah, thankfully, yes, so.",
                    "label": 0
                },
                {
                    "sent": "Consider that you are in the running this kind of particle filter on.",
                    "label": 0
                },
                {
                    "sent": "Consider that the true filter the exact filter puts their distribution PXNYN that you're trying to approximate is such that it has some kind of exponential stability.",
                    "label": 0
                },
                {
                    "sent": "It satisfies some kind of exponential stability condition.",
                    "label": 0
                },
                {
                    "sent": "So what does it mean?",
                    "label": 0
                },
                {
                    "sent": "It means that assume you have that if you were initializing your system.",
                    "label": 0
                },
                {
                    "sent": "Basically, at the location X1 or if you were initializing at a different initial condition X, one point on.",
                    "label": 0
                },
                {
                    "sent": "If you were running the two.",
                    "label": 0
                },
                {
                    "sent": "Basically you were computing the two posterior distribution.",
                    "label": 0
                },
                {
                    "sent": "Which are subject to different initial condition.",
                    "label": 0
                },
                {
                    "sent": "If this distance, this L1 norm was converging to zero exponentially with quickly as any crisis, then it means somehow that you're trying to approximate dynamic model, which kind of forgets.",
                    "label": 0
                },
                {
                    "sent": "Basically it's fast, OK?",
                    "label": 0
                },
                {
                    "sent": "If you have this kind of code.",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Mission.",
                    "label": 0
                },
                {
                    "sent": "Well, you can show result which are much stronger theoretically, so consider for example that you're interested in just computing the expectation of a function which only depends on the last component XML.",
                    "label": 0
                },
                {
                    "sent": "OK, in this case, if you have exponential ability assumption, then you get bombs which are essentially time independent.",
                    "label": 0
                },
                {
                    "sent": "So it means in this case that essentially you are able to provide.",
                    "label": 0
                },
                {
                    "sent": "In approximation and numerical approximation of the marginal PRX and given the N files of Salvation which basically doesn't generate overtime.",
                    "label": 0
                },
                {
                    "sent": "OK, so the approximation error remains.",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Founded on this is this result is why people use particle filters.",
                    "label": 0
                },
                {
                    "sent": "Is that in most scenario essentially when you only look at the marginal distribution, there's no accumulation of errors and that's why it makes the technique attractive.",
                    "label": 0
                },
                {
                    "sent": "Also, what you can show in the sewers under the same condition is that.",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Basically, if you look at your estimate of the marginal likelihood where the variance obviously going to increase overtime, but it only increases linearly overtime, OK on that night because if you use a stoned out, basically important sampling type technique to approximate the marginal likelihood, then typically this variance would increase exponentially with the time index.",
                    "label": 0
                },
                {
                    "sent": "So far mystery sampling you've moved to dial from the variance.",
                    "label": 0
                },
                {
                    "sent": "Increasing exponentially with time to violence, increasing only linearly with the time index, which is one of the men basically benefit of using this kind of resampling algorithm.",
                    "label": 0
                },
                {
                    "sent": "OK, so now these are the coil.",
                    "label": 0
                },
                {
                    "sent": "Do kind of basic algorithm over the past few years there's been no.",
                    "label": 0
                },
                {
                    "sent": "Actually a lot of techniques which have been proposed to improve.",
                    "label": 0
                },
                {
                    "sent": "Basically the algorithm.",
                    "label": 0
                },
                {
                    "sent": "I'm just going to detail some of them very briefly.",
                    "label": 0
                },
                {
                    "sent": "OK, so in the stone down naive algorithm, what you're doing is that you're propagating the algorithm according to the dynamic of the model on your re, weighting them according to the like.",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Mood of this observation on this is some or something which is very naive because it's like shooting in the dark.",
                    "label": 0
                },
                {
                    "sent": "Because imagine you have a likelihood which is very picky.",
                    "label": 0
                },
                {
                    "sent": "That is, you have observation which also assume this is your likelihood.",
                    "label": 0
                },
                {
                    "sent": "You have likely, which is quite picky.",
                    "label": 0
                },
                {
                    "sent": "OK, on you, instead of using the observation essentially to guide.",
                    "label": 0
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Your party cooling to region of I like you.",
                    "label": 0
                },
                {
                    "sent": "You're doing just sampling naively according to the prior, so that's obviously something very nice.",
                    "label": 0
                },
                {
                    "sent": "You can really improve those techniques easily by simply building mechanism where the particles are propagating forward using the information conveyed by the UPS.",
                    "label": 0
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Station wagon",
                    "label": 0
                }
            ]
        },
        "clip_55": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "They are their values.",
                    "label": 0
                },
                {
                    "sent": "Where to do that.",
                    "label": 0
                },
                {
                    "sent": "Essentially the best way to do it is simply to sample your particle propagator particle for Walnut according to the prior back awning to this conditional distribution, which is simply proportional to the likelihood times the prior.",
                    "label": 0
                },
                {
                    "sent": "So there's a lot of techniques which I've been discussed in the literature like this on when you cannot use basically this distribution.",
                    "label": 0
                }
            ]
        },
        "clip_56": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To propagate your particle forward where you can use approximation of it.",
                    "label": 0
                },
                {
                    "sent": "So if you can come up with approximation of this distribution using, say, unsalted carbon filter or the extended common filter, in which case you need to re weight your particle in a different way, which correct for the bias introduced by this this proposal distribution.",
                    "label": 0
                },
                {
                    "sent": "So the lot of techniques which have been done here, I'm not going to discuss it very, very in depth.",
                    "label": 0
                },
                {
                    "sent": "One thing I'd like to mention because it will be used we used later on.",
                    "label": 0
                }
            ]
        },
        "clip_57": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is that there is 1 standard way which has been proposed to increase diversity in the number of particles so remember and when you're doing this kind of sampling or something step afterwards sampling step you sample capital.",
                    "label": 0
                }
            ]
        },
        "clip_58": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In time from awaited empirical measure to obtain capital and new samples.",
                    "label": 0
                },
                {
                    "sent": "And because you sample with replacement it means that after the resampling step you have actually quite a lot of particles which are similar one to each other.",
                    "label": 1
                },
                {
                    "sent": "They might evolve in different fashion, but they are actually.",
                    "label": 0
                }
            ]
        },
        "clip_59": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Similar just after the resampling step.",
                    "label": 0
                },
                {
                    "sent": "So one way you say it's not actually a very nice approximation to have particles which are exactly the same value.",
                    "label": 0
                },
                {
                    "sent": "So if you want to somehow add diversity, jitter, the location in the particle on still keep consistent approximation of the posterior distribution.",
                    "label": 0
                },
                {
                    "sent": "One thing you can do is simply move them, move each particle according to an artificial dynamic which preserve the invariant distribution.",
                    "label": 0
                },
                {
                    "sent": "So one way to do that.",
                    "label": 0
                },
                {
                    "sent": "For people over.",
                    "label": 0
                },
                {
                    "sent": "For those of you are familiar with MCMC is very simple.",
                    "label": 0
                },
                {
                    "sent": "Assume you have a particle here, a pass approximately distributed according to the posterior distribution of interest.",
                    "label": 0
                },
                {
                    "sent": "What you're doing you're sampling your sampling a new particle X prime using a kernel transition kernel can, which is such that by construction it preserved.",
                    "label": 0
                },
                {
                    "sent": "Look, put stereo as target distribution on the way to build this target this this.",
                    "label": 0
                },
                {
                    "sent": "This transition kernel is obviously to use MCMC type mechanism so you can mix MCMC with SMC so as to add diversity in your clouds of particles.",
                    "label": 0
                },
                {
                    "sent": "So it's very standard techniques which has been proven very useful.",
                    "label": 0
                }
            ]
        },
        "clip_60": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "There's work to improve.",
                    "label": 0
                },
                {
                    "sent": "Also the resampling step, which I won't detail but allows you to reduce the violence of your approximation.",
                    "label": 0
                },
                {
                    "sent": "One thing I'd like to discuss because this is a problem that has been basically advice many times in the literature and for which there is no satisfactory answer, is the case where now instead of doing only state estimation, you have a dynamic model F&G like before.",
                    "label": 0
                },
                {
                    "sent": "But now those this model FG, they depend on the hyperparameter Teeter on you like.",
                    "label": 0
                },
                {
                    "sent": "To estimate this step.",
                    "label": 0
                }
            ]
        },
        "clip_61": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Tick parlamentar Teeter online.",
                    "label": 0
                },
                {
                    "sent": "Given the data?",
                    "label": 0
                },
                {
                    "sent": "OK, so you're going to swallow invasion approach onset applier PT to on this on this parameter.",
                    "label": 0
                },
                {
                    "sent": "OK, so in this case the object on inference before it was the posterior the Eastern State given Y naughty to is also an unknown parameter.",
                    "label": 0
                },
                {
                    "sent": "So what I'm interested in estimating is the joint distribution of Teeter X given one OK, which.",
                    "label": 0
                }
            ]
        },
        "clip_62": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Admits, obviously this simple decomposition on I use here this the substrate data indicates the conditioning by the argument data.",
                    "label": 0
                },
                {
                    "sent": "OK, so I want to estimate this kind of posterior distribution OK. On clearly.",
                    "label": 0
                },
                {
                    "sent": "This thing is nothing but a particulare case of what I've discussed before.",
                    "label": 0
                },
                {
                    "sent": "OK, so consider now.",
                    "label": 0
                },
                {
                    "sent": "Basically the pulse is dead and the Markov process again, which is composed of XN extended by a parameter tee time.",
                    "label": 0
                },
                {
                    "sent": "OK, so I'm considering this Markov process on this is indeed a Markov process which needs a strange which I need.",
                    "label": 0
                },
                {
                    "sent": "The following transition Kernel F Zen given that N -- 1 transition kernel.",
                    "label": 0
                },
                {
                    "sent": "Well, there's a dental mass on Tieton because teachers are static power meter.",
                    "label": 0
                },
                {
                    "sent": "It doesn't evolve OK. Times basically the transition kernel 4X.",
                    "label": 0
                },
                {
                    "sent": "Um G. Basically, the likelihood were similarly conditional upon then where I can write his flow.",
                    "label": 0
                },
                {
                    "sent": "So this simple rewriting tells you that because their end is a Markov process, then I can reuse old SMC methods so as to estimate this joint posterior OK, the problem?",
                    "label": 0
                },
                {
                    "sent": "The problem you see is that this is actually a conceptual solution, but because essentially the Markov kernel on the extended state as very poor mixing properties.",
                    "label": 0
                },
                {
                    "sent": "All the standardized MC method so as to approximate this distribution are going to have very very poor property on that should be intuitive because things that.",
                    "label": 0
                }
            ]
        },
        "clip_63": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Even if you knew the power meter teacher OK. Then we've seen before that the valiance of essentially the marginal likelihood increase basically linearly in the time index.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is even if we knew Tita now in a bit.",
                    "label": 0
                }
            ]
        },
        "clip_64": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In the context I'm interested in, I don't know Teeter on.",
                    "label": 0
                },
                {
                    "sent": "I'm interested in estimating the joint distribution of PT to or negative, and why so?",
                    "label": 0
                },
                {
                    "sent": "In particular, I'm interested in estimating the marginal distribution of T&Y.",
                    "label": 0
                }
            ]
        },
        "clip_65": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Which is proportional to marginal likelihood typed into.",
                    "label": 0
                },
                {
                    "sent": "This is obviously a much more complex problem, because in this case data is not even fixed, so This is why.",
                    "label": 0
                },
                {
                    "sent": "Essentially it's kind of it's kind of.",
                    "label": 0
                },
                {
                    "sent": "Use less, it's impossible essentially to come up with SMC methods to approximate this type of posterior distribution which do which which are essentially numerically stable.",
                    "label": 0
                },
                {
                    "sent": "Overtime, you're going to have each time you're going to use the same semester to approximate this time with distribution.",
                    "label": 0
                },
                {
                    "sent": "The variance can only increase other overtime.",
                    "label": 0
                },
                {
                    "sent": "You cannot have scheme which are numerically stable.",
                    "label": 0
                },
                {
                    "sent": "OK, so one way to kind of mitigate the problem which has been proposed many times in the literature.",
                    "label": 0
                }
            ]
        },
        "clip_66": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Consists of saying OK T to the big problem with basically estimating this kind of posterior distribution.",
                    "label": 0
                },
                {
                    "sent": "Italian X&Y is the fact that Tita is is a parameter which is static which has no dynamic, so this accumulation of error.",
                    "label": 0
                },
                {
                    "sent": "So would it be possible to introduce a kind of artificial dynamic to mitigate the problem?",
                    "label": 0
                },
                {
                    "sent": "Yeah you can do that using some kind of MCMC steps.",
                    "label": 0
                },
                {
                    "sent": "OK, that's been proposed several time, but you should keep in mind.",
                    "label": 0
                },
                {
                    "sent": "That anywhere, even if you're able to do this, all the schemes rely implicitly on the approximation of the marginal distribution P of X1 XN, given yyy and which is something that you cannot approximate very well with particle filters.",
                    "label": 0
                },
                {
                    "sent": "So you have to keep in mind that this algorithm, although they are elegant, they're going to they're going to suffer numerically.",
                    "label": 0
                },
                {
                    "sent": "There going to be some up and stable, so I'm going to give you an example of such algorithm.",
                    "label": 0
                },
                {
                    "sent": "And then show you that numerically you have to be a little bit careful when you're using them.",
                    "label": 0
                },
                {
                    "sent": "So assuming at time N -- 1 on you have an approximation.",
                    "label": 0
                }
            ]
        },
        "clip_67": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And of the joint distribution Teeter on the component X1 XN minus one, this is your approximation of certain and minus one.",
                    "label": 0
                },
                {
                    "sent": "What you're doing at time N simple is very similar to what we've been doing before you sample the component accented according to the prior.",
                    "label": 0
                },
                {
                    "sent": "OK, so we wait each of the sample to obtain a new approximation.",
                    "label": 0
                }
            ]
        },
        "clip_68": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Of the posterior distribution at time, and which is given simply simple, it's just waited on pericle measure each weight being proportional to the likelihood.",
                    "label": 0
                },
                {
                    "sent": "What you doing once you're done, you always sample capital N times.",
                    "label": 0
                },
                {
                    "sent": "Only the state valuable according to this measure.",
                    "label": 0
                },
                {
                    "sent": "This weighted empirical measure OK. On your recreate.",
                    "label": 0
                }
            ]
        },
        "clip_69": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Capital NU values of the parameter in the parameter space by sampling Teeter according to Y on X.",
                    "label": 0
                },
                {
                    "sent": "So in particular, if you're dealing with models in the exponential family, you don't need to store the whole path, but that only depends.",
                    "label": 0
                },
                {
                    "sent": "This conditional distribution only depends on a set of fixed dimensional distributors, fixed dimensional statistics, so this is a very elegant algorithm.",
                    "label": 0
                },
                {
                    "sent": "But keep in mind that this algorithm is not going to be a form, whereas the end the small time in days ago increase because implicitly it does rely.",
                    "label": 0
                }
            ]
        },
        "clip_70": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "On the particle approximation of this joint distribution.",
                    "label": 0
                },
                {
                    "sent": "So if you do that numerically, this is what you're going to observe, so I've considered a very simple linear algorithm state space model basically.",
                    "label": 0
                },
                {
                    "sent": "This is basically the evolution.",
                    "label": 0
                },
                {
                    "sent": "This is the estimate of the expectation of Tita given the observation as any increases.",
                    "label": 0
                },
                {
                    "sent": "All in blue.",
                    "label": 0
                },
                {
                    "sent": "This is the true value of the parameter I'm trying to estimate.",
                    "label": 0
                },
                {
                    "sent": "So what you see is that at the beginning your particle approximation is kind of doing well.",
                    "label": 0
                },
                {
                    "sent": "And certainly.",
                    "label": 0
                },
                {
                    "sent": "Well, the problem is that N is going to increases your approximation of the joint distribution is going to detail your rate on things are going to get wrong on.",
                    "label": 0
                },
                {
                    "sent": "This is quite difficult to diagnose, so you should be very careful when you're using this type of algorithm.",
                    "label": 0
                },
                {
                    "sent": "So that's one thing that was a cautionary warning because this technique had been kind of heavily popularized over the past few years.",
                    "label": 0
                },
                {
                    "sent": "OK, one thing I could do though, and I'm going to think this is the last topic I will address.",
                    "label": 0
                }
            ]
        },
        "clip_71": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "One thing I could do is perhaps not be less ambitious on instead of, instead of trying to do online version parameter estimation, let's try to do things offline.",
                    "label": 0
                },
                {
                    "sent": "OK, so I'm going to address the same problem now.",
                    "label": 0
                },
                {
                    "sent": "You fix the number of Salvation.",
                    "label": 0
                },
                {
                    "sent": "I'm not interested in a sequential scheme anymore.",
                    "label": 0
                },
                {
                    "sent": "I'm going to say let's let's try to come up with offline algorithm to estimate the joint distribution of Teeter on the state given the observation.",
                    "label": 0
                },
                {
                    "sent": "OK?",
                    "label": 0
                },
                {
                    "sent": "So that's what I want to do.",
                    "label": 0
                },
                {
                    "sent": "So what I know.",
                    "label": 0
                },
                {
                    "sent": "Is I know that if you give me theater.",
                    "label": 0
                }
            ]
        },
        "clip_72": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "SMC method can give me an estimate of the conditional distribution of X&Y given Theta on an estimate of the marginal likelihood for.",
                    "label": 0
                }
            ]
        },
        "clip_73": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You have data.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is what I simply gives me.",
                    "label": 0
                },
                {
                    "sent": "OK, so is there a way to essentially use this kind of?",
                    "label": 0
                },
                {
                    "sent": "Multi color approximation within an 80 or 80 vulgarism such as MCMC to do inference on both Teeter on the latent variable.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is what I'm going to show.",
                    "label": 0
                },
                {
                    "sent": "I'm going to present an algorithm which essentially combine SMC estimate on MCMC algorithm to do inference of both on both the state on the parameter.",
                    "label": 0
                },
                {
                    "sent": "Oh",
                    "label": 0
                }
            ]
        },
        "clip_74": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the way I'm going to use that, I'm going to come out in that he's using the Metro processing algorithm, so I'm going to have a brief recap of the Metro PCs store anything algorithm.",
                    "label": 0
                },
                {
                    "sent": "So which will be testing algorithm is the most famous MCMC algorithm available?",
                    "label": 0
                },
                {
                    "sent": "The wait, what it does is that it's an algorithm is an iterative algorithm to sample approximately from any target quality distribution of interest.",
                    "label": 0
                },
                {
                    "sent": "So assume you're interested in obtaining approximate sample from a distribution Pi's Ed.",
                    "label": 0
                },
                {
                    "sent": "OK, so the match will be lasting.",
                    "label": 0
                },
                {
                    "sent": "Algorithm is going to generate a Markov chain according to the following mechanism.",
                    "label": 0
                },
                {
                    "sent": "So you at iteration I -- 1.",
                    "label": 0
                },
                {
                    "sent": "OK, what you're doing is you propose a candidate and you value that star according to proposal distribution, which can be parameterized by the previous basically sample.",
                    "label": 0
                },
                {
                    "sent": "And essentially you accept this new proposal.",
                    "label": 0
                },
                {
                    "sent": "According to this probability.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is this simple right here.",
                    "label": 0
                },
                {
                    "sent": "OK, so that star is accepted with probability.",
                    "label": 0
                },
                {
                    "sent": "Also while you stay well aware, so under very very weak assumption.",
                    "label": 0
                }
            ]
        },
        "clip_75": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So first you can easily show that if Zed is distributed according to part of that, then after one one basically application of this foundation kernel then that prime is also distributed according to pay off.",
                    "label": 0
                },
                {
                    "sent": "Then on the very weak assumption.",
                    "label": 0
                },
                {
                    "sent": "Basically, even if you don't start according your Markov chain according to Pi upset then there are essentially converged by that.",
                    "label": 1
                },
                {
                    "sent": "OK so stoned are Metro police testing algorithm.",
                    "label": 0
                },
                {
                    "sent": "I want to use this algorithm.",
                    "label": 0
                },
                {
                    "sent": "In my context, so as to sample from the posterior distribution of Tita or next given, why OK?",
                    "label": 1
                },
                {
                    "sent": "So if I want to use Metro police testing?",
                    "label": 0
                }
            ]
        },
        "clip_76": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Erase 'em.",
                    "label": 0
                },
                {
                    "sent": "In my context, it means that I need to define a proposal distribution OK, Q as it started and said.",
                    "label": 0
                },
                {
                    "sent": "So what I propose to do in in my in my context is to propose new value.",
                    "label": 0
                },
                {
                    "sent": "Extra test are you an excellent eater?",
                    "label": 0
                },
                {
                    "sent": "According to the following mechanism 1st, I'm going to propose a new value of T test.",
                    "label": 1
                },
                {
                    "sent": "According to shoot it to start it off.",
                    "label": 0
                },
                {
                    "sent": "So that could be a random walking comment.",
                    "label": 0
                },
                {
                    "sent": "And then when I have a new value of T test, a new value of T30 desktop, I'm going to propose basically new value for the latent state variable.",
                    "label": 0
                },
                {
                    "sent": "According to the air condition, full conditional distribution, that is P of X.",
                    "label": 0
                }
            ]
        },
        "clip_77": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Given why Auntie Tester, so that's basically special instance of the Metro PCs Ting algorithm.",
                    "label": 0
                },
                {
                    "sent": "On if I do that, what is very nice with this kind of acceptance?",
                    "label": 0
                },
                {
                    "sent": "This kind of proposal distribution is that the Metro precessing acceptance probability simplified to this simple ratio.",
                    "label": 0
                },
                {
                    "sent": "The ratio of the marginal likelihood of the data evaluated at E tester on Teeter on all the high dimensional random variable X have disappeared from the acceptance probability.",
                    "label": 0
                },
                {
                    "sent": "So essentially, it's like equivalent to do.",
                    "label": 0
                },
                {
                    "sent": "MCMC only on the space.",
                    "label": 0
                },
                {
                    "sent": "The parameter space Teeter.",
                    "label": 0
                },
                {
                    "sent": "This is why it's called some kind of marginal Metro possessing algorithm, because X Summer's disappeared.",
                    "label": 0
                },
                {
                    "sent": "OK, so that's an algorithm I really like to implement this algorithm.",
                    "label": 0
                },
                {
                    "sent": "The point is simple.",
                    "label": 0
                }
            ]
        },
        "clip_78": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Able to implement this algorithm because you don't know.",
                    "label": 0
                },
                {
                    "sent": "Basically, the marginal likelihood for a given value of Peter your Noble to evaluate it on you cannot sample from the posterior distribution X.",
                    "label": 0
                }
            ]
        },
        "clip_79": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Given why on Twitter so you cannot implement this algorithm, you cannot sample from this guy.",
                    "label": 1
                },
                {
                    "sent": "You cannot evaluate those terms.",
                    "label": 0
                },
                {
                    "sent": "OK, so we're going to do it like use this simple idea is to say wherever.",
                    "label": 0
                },
                {
                    "sent": "Basically I've got this guy appearing on this guy.",
                    "label": 0
                },
                {
                    "sent": "I'm going to substitute to this this post to sell distribution on this marginal likelihood.",
                    "label": 0
                },
                {
                    "sent": "They're there.",
                    "label": 0
                },
                {
                    "sent": "SMC estimate their particle estimate OK.",
                    "label": 0
                },
                {
                    "sent": "So we're going to.",
                    "label": 1
                },
                {
                    "sent": "We're going to consider the following algorithm is very simple.",
                    "label": 0
                },
                {
                    "sent": "When at time iteration I -- 1 ice on polar value of the test are according to.",
                    "label": 0
                }
            ]
        },
        "clip_80": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To cure their proposal, I'd like to some pull from the troposphere distribution of X, given Y on T test are, but I cannot do that.",
                    "label": 0
                },
                {
                    "sent": "So instead I run SMC algorithm to estimate this posterior distribution and marginal likelihood.",
                    "label": 0
                },
                {
                    "sent": "Oh nice so.",
                    "label": 0
                }
            ]
        },
        "clip_81": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "People from this approximate posterior distribution OK.",
                    "label": 0
                },
                {
                    "sent": "Uh, no.",
                    "label": 0
                },
                {
                    "sent": "I'm going to accept the samples.",
                    "label": 0
                },
                {
                    "sent": "According to the following.",
                    "label": 0
                }
            ]
        },
        "clip_82": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Mitchell, possessing the ratio, so it's very similar to the Metro police arresting ratio that was present given in the previous slides, except that wherever I had the true marginal likelihood not substituted, the SMC estimate.",
                    "label": 0
                },
                {
                    "sent": "That's what I'm doing, so it's kind of very naive type of approximation.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is what I'm doing.",
                    "label": 0
                },
                {
                    "sent": "OK, so this algorithm I mean it's been proposed as a new Ristic algorithm to sample from this posterior distribution in econometrics, actually.",
                    "label": 0
                },
                {
                    "sent": "So people use this kind of algorithm as an artistic too.",
                    "label": 0
                }
            ]
        },
        "clip_83": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Approximate MCMC algorithm to sample from the posterior distribution.",
                    "label": 0
                },
                {
                    "sent": "Well, it turned out that bit miraculously, whatever being the number of particles you're using.",
                    "label": 0
                }
            ]
        },
        "clip_84": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, to approximate the posterior distribution on the marginal likelihood.",
                    "label": 0
                },
                {
                    "sent": "Actually, this algorithm admits exactly the right inbound distribution.",
                    "label": 1
                },
                {
                    "sent": "There's no bias whatsoever, OK?",
                    "label": 0
                },
                {
                    "sent": "Obviously, is no free lunch.",
                    "label": 1
                },
                {
                    "sent": "Obviously, the higher than the higher number of particles, the better of the performance of the algorithm on.",
                    "label": 0
                },
                {
                    "sent": "Typically you have that capital N scale.",
                    "label": 0
                }
            ]
        },
        "clip_85": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Roughly linearly within the time index.",
                    "label": 0
                },
                {
                    "sent": "So that's quite useful.",
                    "label": 0
                },
                {
                    "sent": "Algorithm is going to be particularly useful when you're dealing.",
                    "label": 0
                }
            ]
        },
        "clip_86": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "If scenario where the state you're dealing with these nuts of very high dimensions so that particle filter are doing quite a good job but T to the power meter space, you're dealing with very high dimensional, and in particular this is an algorithm which also admits what is called sometime in statistic.",
                    "label": 0
                },
                {
                    "sent": "The plug and play property, because this is an algorithm that essentially only requires you to be able to sample from the prior distribution.",
                    "label": 0
                },
                {
                    "sent": "You don't even need to be able to write its expression analytically, so this kind of black box algorithm so.",
                    "label": 0
                },
                {
                    "sent": "So it can be.",
                    "label": 0
                },
                {
                    "sent": "It can be used like to do this kind of thing.",
                    "label": 0
                }
            ]
        },
        "clip_87": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And I'm just going to give you a simple application to stochastic kinetic model.",
                    "label": 0
                },
                {
                    "sent": "OK, so that's used.",
                    "label": 0
                },
                {
                    "sent": "This type of model is used to model like biochemical networks.",
                    "label": 0
                },
                {
                    "sent": "I mean marjoram easier, so I think he can.",
                    "label": 0
                },
                {
                    "sent": "He knows this.",
                    "label": 0
                },
                {
                    "sent": "Our very, very well will be able to talk to you about about it better than me.",
                    "label": 0
                }
            ]
        },
        "clip_88": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is simple model we're going to consider this simple gem Markov process like.",
                    "label": 0
                },
                {
                    "sent": "Pray Pray data model so you get like essentially there's a continuous time process on your interested.",
                    "label": 0
                },
                {
                    "sent": "Essentially, you're observing one of the component.",
                    "label": 0
                },
                {
                    "sent": "Basically in some noise on your intro.",
                    "label": 0
                }
            ]
        },
        "clip_89": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The latest mating, the kinetic component of this gem Markov process in some noise if you try to do in CMC so as to essentially estimate the parameter in the state you observation it's visible but using sonar MTMT is a bit of a pain because essentially because there's a kind of unknown number of basically jump into the market jump process, you obliged to use reversible jumps algorithm type algorithm.",
                    "label": 0
                },
                {
                    "sent": "So it could be a bit painful to Kurt.",
                    "label": 0
                },
                {
                    "sent": "It could be difficult basically to converge where.",
                    "label": 0
                },
                {
                    "sent": "If you use this type of algorithm, commanding SMC on MCMC, the only thing already you require is being able to sample forward from this.",
                    "label": 0
                },
                {
                    "sent": "This John Markoff process which is feasible thanks to what is called in the literature as the Gillepsie algorithm.",
                    "label": 0
                },
                {
                    "sent": "And this is Friday.",
                    "label": 0
                }
            ]
        },
        "clip_90": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "One example of inference.",
                    "label": 0
                },
                {
                    "sent": "So this is here to pray the number of prey on the number of predator overtime.",
                    "label": 0
                },
                {
                    "sent": "You only observe the process at some discrete time instance OK. And when you want to do inference about that is actually quite complicated, because don't forget that the latent causes a continuous state process.",
                    "label": 0
                },
                {
                    "sent": "So you need to infer actually the really large number of latent, valuable.",
                    "label": 0
                },
                {
                    "sent": "But it turns out it's not too complicated with this type of like particle MCMC type algorithm.",
                    "label": 0
                },
                {
                    "sent": "So this is kind of example of inference we obtain with.",
                    "label": 0
                },
                {
                    "sent": "This is simulated data true value on the posterior distribution associated to this guy.",
                    "label": 0
                },
                {
                    "sent": "OK, I'm just not going to detail all the slide on smoothing.",
                    "label": 0
                },
                {
                    "sent": "What I'd like to say is that for the time being in this part of the talk, I've discussed all the algorithm I've discussed essentially rely on the SMC approximation of the joint distribution on.",
                    "label": 0
                },
                {
                    "sent": "I've told you that basically this type of approximation degrades overtime OK at the time index increase.",
                    "label": 0
                },
                {
                    "sent": "There's a lot of methods available in the literature, some kind of smoothing algorithm which do not suffer.",
                    "label": 0
                },
                {
                    "sent": "From this problem which can be used as an alternative to the kind of direct pass approximation.",
                    "label": 0
                }
            ]
        }
    }
}