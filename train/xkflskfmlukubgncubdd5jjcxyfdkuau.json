{
    "id": "xkflskfmlukubgncubdd5jjcxyfdkuau",
    "title": "From activity to language: learning to recognise the meaning of motion",
    "info": {
        "author": [
            "Richard Bowden, Department of Electronic Engineering, University of Surrey"
        ],
        "published": "Aug. 24, 2011",
        "recorded": "June 2011",
        "category": [
            "Top->Computer Science->Computer Vision"
        ]
    },
    "url": "http://videolectures.net/gesturerecognition2011_bowden_activity/",
    "segmentation": [
        [
            "I apologize now 'cause I have a North and English accent and I talk very fast at the best of times, so I apologized to the interpreters now.",
            "I'll try and pace it."
        ],
        [
            "But then I also made the fundamental mistake when I wrote the abstract of including too much, so was actually until I came to put the slides together.",
            "I thought, Oh my God, Oh my God, how am I gonna fit all this into half an hour?",
            "So I'm going to race through a rate of knots and I'm going to talk about a couple of things.",
            "First, a little bit about activity recognition.",
            "And then I'll move on to sign language recognition.",
            "And then Lastly facial feature tracking.",
            "Kind of in the domain of lip reading, but motivated largely for the non manual features that go with the sign language."
        ],
        [
            "Ignition so first."
        ],
        [
            "All activity now.",
            "We spent a long time working with sign.",
            "And I think the activity recognition was all of a sudden it was becoming quite a popular topic.",
            "We spent ages sort of like trying to these large lexicons of signs hundreds, or you know, nowadays in thousands of signs and then there were all these other people doing 12 activities.",
            "So we thought, well can't be that hard going from down to 12.",
            "So we thought we'd have ago.",
            "But this.",
            "This kind of introduced some new learning algorithms to US ones that we kind of well, let's say, stole from the data mining community.",
            "But the way that we do not abate recognition was was largely to do with trying not to make assumptions.",
            "So object recognition has gone leaps and bounds, and the key thing behind that's driven object recognition was the idea of feature detectors, feature detectors that were invariant too.",
            "Define deformation scale invariant.",
            "All these sorts of things, so it's quite natural that when people have started working on activity or action that you know, let's take special temporal extensions of these things.",
            "And our argument was, well, if your engineering your features to be sparse to make the problem tractable to be invariant to this, be invariant about you, not necessarily engineering, to be good at what you want them to be, which is discriminating between classes.",
            "And so we dropped down to the simplest features we could, which were corners, corners, not 3D corners, But corners actually in spatial corners, but also corners in XT and YT.",
            "And what you end up then it is even for a very low resolution video.",
            "Millions and millions of these things firing well.",
            "What we want to try and do is to try and extract the little spatial temporal configurations are corners that are important for the thing that we want to recognize, and so the way we did this was we use data mining and we use the a priori algorithm so.",
            "We weren't the first to introduce into the vision community.",
            "I must admit I kind of I was quite inspired by till quacks poster ICCV God knows when it was.",
            "But the idea is that we use this algorithm, which is kind of commonly known as the shopping basket algorithm.",
            "To try and find efficiently statistically Co occurring things.",
            "So for every single corner we've detected and literally there are millions of them.",
            "What we do is we encode the other corners that fire locally to it.",
            "So here's a corner.",
            "And then in a very small spatial region around it, we encode all the other corners, their position, relative position, orientation, their scale at the firing up, and we produce a massive database of these things.",
            "And then we pump it through this.",
            "A priori algorithm.",
            "And we ask it to find those things that are statistically Co occurring and we bastardize the algorithm slightly so that we use in a discriminatory fashion.",
            "We say find us things that Co occur here but aren't in the negative data.",
            "And then what we do is we repeat that process.",
            "So what comes out of that?",
            "That data mining is a tiny subset of those configurations that are actually relevant and then for each one of those configurations we then encode the configurations relative to each other.",
            "And I mean it literally takes longer to load.",
            "Be in for."
        ],
        [
            "Listen to memory than it does to go through because the apriori algorithm uses some very efficient tree pruning strategies to try and find these statistically relevant things.",
            "So just as kind of an overview, this is, you know these are corners down the lowest level we encode these, we pump it through this algorithm and what the algorithm says is, well, there's this little configuration here made out of these corners.",
            "This one over here this one over here that I think are relevant for this class on a discriminatory against other classes.",
            "And then we repeat the process at a slightly larger scale.",
            "And then it says, right?",
            "Well, I found another configuration that's build out of these configurations.",
            "So down at this level you've got millions of millions of corners.",
            "But at this level you've effectively got some class that the thing that you want to recognize.",
            "And the important thing is that each point this stage is throwing away, you know here you throw away 99% of those millions of corners 'cause they're completely."
        ],
        [
            "Worthless now if you do this, what you get is very good performance, right?",
            "So and you know these are.",
            "KTH is kind of maxed out now so it's fairly hard not to get sort of like in the 90s, but it does."
        ],
        [
            "Be well on most of the popular datasets and this is on the Hollywood data and it you know it's nice 'cause you can actually interpret what's going on.",
            "So obviously these are corners.",
            "It's fairly poor performance, and as our groupings of these corners get more complex than the recognition accuracy goes up and here is a video of shake hands.",
            "These are corners firing.",
            "These are stage two.",
            "These are stage three, so this is actually whether the recognition is happening and you can sort of see that there's only a subset of the features.",
            "The original features that actually fire anymore, and the interesting thing is that these things far along the arm, right?",
            "So it's kind of it's localized in space and time.",
            "The one thing in that video that was kind of had some commonality.",
            "And don't forget you're not looking at a corner anymore, you're looking at a representation of some sort of configuration of corners in space and time.",
            "The interesting thing is it also picks up features on the head.",
            "And I have no, you know, sort of.",
            "Like evidenced about this up.",
            "But I would argue that's kind of to do with.",
            "I mean, you look at these videos quite a lot of them they're taking from Hollywood movies.",
            "I mean, sort of the data is in the room.",
            "And and it's phenomenally difficult data.",
            "I mean, in some of those cases, you can't even see their hands.",
            "So I mean, I'll be glad, say, because this is pure data driven approach.",
            "It's trying to pick up anything it possibly can to recognize the action.",
            "So it's also picking up on the fact that, well, as a slight head nod when when they, when they show."
        ],
        [
            "Accounts now what we've done is we've taken this one stage further, and so we're looking at now, iteratively grouping images and video.",
            "So the idea is that rather than taking a hard data set, these are this this class?",
            "These are that class what we want to do is allow the user to actually manipulate the data directly and say I think these have something in common.",
            "Put them in the same category and so we've done this by combining 2 two different data mining approaches.",
            "The min hash algorithm and an the a priori algorithm.",
            "The min hash allows us to.",
            "Like very very very large descriptors, you know, sort of like bag of words, approaches.",
            "And and very efficiently compute metric distance spaces on this, and then we allow we project we can protect that data.",
            "We would allow the user to say I think these should be the same class.",
            "I think these shouldn't be the same class and then the Priory goes through."
        ],
        [
            "Who and tries to find the rules that these examples have in common?",
            "So just to illustrate here, we've got 2 examples from the YouTube data set of swimming, and these are very, you know, appearance wise.",
            "They've got not got a great deal in common and in terms of the visualization space, they're both very separate.",
            "What we've done is the user is taken to the examples, push them together.",
            "We've run it through this learning algorithm and it finds some rules and what it actually does.",
            "Is it really weight?",
            "The the histogram representation, so it can actually be based on whatever you want, and in this paper we had a paper accepted for ICC V. We demonstrated in images and videos using various difference or representations.",
            "And it's very sad because for the 1200 videos for YouTube, it's 35 seconds per iteration and with about I think about 28 videos.",
            "We can get the same sort of clustering performance.",
            "Well, yeah, same clustering results out of it as if you'd used all the ground truth label data there.",
            "So and arguably I mean 'cause.",
            "What happens when you're visually doing this?",
            "You will pick the outliers, you will pick the most challenging cases.",
            "So you as an interactive part of the learning algorithm.",
            "I'll be in."
        ],
        [
            "Selective about the best constraints to add it."
        ],
        [
            "So now I'm going to move on a bit about sign language.",
            "We've already heard quite a bit about it, so I'm not going to dwell on.",
            "It's got various parts, the the motion and the handshake finger spelling, which is just a very small part of it.",
            "Non manual features which is a partner in terms of visual recognition.",
            "We often neglect and then this thing here, which we really haven't got a handle on.",
            "Yeah I would say which is the complex linguistic constructs and I think this is one of the things that's really missing to allow us to do proper continuous recognition.",
            "But speaking very personally, one of the problems I've always had.",
            "We sign language recognition is the sheer lack of available data back or framework 5 or whatever it was when I started working with Andrew Jessamine on sign language recognition.",
            "Very, you know when it was muggins here, who was the only person that actually understood some sign and it was muggins here.",
            "I'd sit down and label all the data.",
            "It very quickly brought home to me that we were going to have to look at new ways to tackle this.",
            "And a couple years ago we tried the same algorithms I've just shown you in.",
            "The domain of the activity that a priori algorithm we tried to use that to see if we could automatically learn from subtitles.",
            "So here we got a bit of video footage.",
            "There's a signer here, and So what we've got is subtitle."
        ],
        [
            "That are also being translated so the idea is can we use the subtitles of some form weak supervision in order to learn the signs that are there?",
            "If we could do that, fantastic, I don't need to label data anymore.",
            "Who are, hey, we're off.",
            "The trouble is, it's actually not that easy, of course, and what we've got here is you've got the sign glass and then we've got the subtitles underneath and we color coded where there is some correlation between the two, so you can sort of see that occasionally there is a word that occurs in the subtitles and the corresponding sign also occurs.",
            "But we don't know whether it's before, whether it's after, whether it's there at all.",
            "And of course, because of the nature of sign language design, even though it says that's I might be there, it's in a different can't."
        ],
        [
            "Actually, it may actually be completely different in that context, But what we did is we take the tracking.",
            "We can cluster those features and then we can use this a priori algorithm again to try and go through and find the things that happened in the visual domain that statistically important because we don't know what the time window is.",
            "We start with a very large time window and then what we try and do is hone in on the places where we think there is something in common and we also do something which we called.",
            "Introducing contextual negatives and that gave us a real performance increase because if you know that you've got 2 signs in the subtitles, 2 words that are next to each other, then you can artificially dope your negative training data by trying to find where you know examples of exactly what you think is going to contaminate your present positive data.",
            "So that does help and these are signs that are automatically being pulled out.",
            "The signs for army in obese and there's no user intervention at all."
        ],
        [
            "But of course I mean.",
            "Sign languages is far more complex than just a simple bit of motion of the hand.",
            "So while this approach does work, you know it's it's not particularly scalable approach, but we do have a new project starting in October with the system and everything 'em 'cause I mean we had a friendly competition so we both had papers doing almost the same thing in that CPR 09, but we've got a four year project now to try and take this further.",
            "We're going to be looking @ language, but we want to look at more general broadcast footage.",
            "So the idea is that the system will automatically learn.",
            "Kind of metadata annotation and then magically it will just be able to sort of like annotate incoming data for us.",
            "Of course it will be as easy as that's in four years time.",
            "The whole problem will be solved what we've been working on the moment though is this project Vector sign which Christian's already talked a bit about this morning.",
            "And this is a large EU project and one of the advantages for me for this project was the massive amount of data that it said it would capture.",
            "So it was to generate four parallel corpora across.",
            "Four different domains, and then of course somebody else is doing all the annotation, which was fantastic as well.",
            "Annotation using the hammer, SIS and the objective of the project is to produce kind of Web 2.0 tools, so one of the demonstrators which worries the hell out of us is the concept of a sign wiki right?",
            "And so by hook or by crook by the end of the project we will have a system where you can sign in front of it and an avatar will give you will.",
            "Repeat that sign in back and then the user will be able to go in and edit that that that information.",
            "It'll be fine without, you know we were only in the fight."
        ],
        [
            "The announcer.",
            "So with so I'm not going to dwell on this 'cause I got no time left and all really Christians talks about how many assist, but how much?",
            "This is quite well is this phonetic representation of language."
        ],
        [
            "I won't talk about.",
            "I mean, this is actually not the sign for Rich in BSL.",
            "It's designed for wealthy, but it is my sign name because Rich is my name.",
            "But the nice thing about it is, is the generalization right?",
            "So Christians already explain this.",
            "This is a left to right mirror.",
            "This the handshake with the modification.",
            "This is where it's happening in the body.",
            "This is palm orientation.",
            "This is the motion downwards, but the idea is that it doesn't matter if I do it slow.",
            "I do it fast, I do it in a large science based doing the small sign space.",
            "The symbol should be fairly consistent, so as with speech, the argument for recognizing phonetic level is there.",
            "It should generalize better across people.",
            "The other advantage, of course, is that sign data is difficult to acquire.",
            "We got terabytes and terabytes of it were drowning in it.",
            "It's difficult to annotate, and you've got precious few examples of, for instance, assign.",
            "But because the phonemes, the phonetic sort of components.",
            "Can exist in multiple signs, although you may have only have a handful of examples of the sign itself, you've got lots of examples."
        ],
        [
            "Down at the phonetic level, so we're encoding at the moment just a subset of these hypnosis features.",
            "Location mode."
        ],
        [
            "In Hampshire, handshake Handshape learned using while the best results we get from using visual Gist features, which are effectively Gabor filters computed over different different scales.",
            "And then these are put through an RDF random decision forest classifier and you get actually in terms of sine, fairly poor performance because that's, but that's because there's huge amounts of variation if you take some handshape classifier.",
            "Then the actual visual appearance of it through all the motion is actually quite varied."
        ],
        [
            "In something like finger spelling where the hand poses far more constrained than recognition, recognition becomes much easier.",
            "So here we've got.",
            "This is a connect camera.",
            "This is recognizing the Gabor features actually in the depth domain.",
            "And the the ranked classification results are shown like this.",
            "So if this thing was.",
            "Was working 100% accurately.",
            "Then the the the correct letter would always be on the right hand side, but we rank them to give the user so that when classification fails you can choose or the next best.",
            "Yeah, well."
        ],
        [
            "It's not.",
            "So we struck these features from our sign.",
            "And So what you can see down here is this little ticker tape and that's a load of classifiers, basically firing and then what we want to do is learn the patterns of these classifiers."
        ],
        [
            "So the architecture looks something like this.",
            "We got some dictionary videos, we've got some extracted features.",
            "There's a training procedure and then we got this big classifier bank.",
            "And now what happens at runtime is we extract the same features we run through the classifier bank.",
            "We're trying to find the sign that we that we want and then we display the results.",
            "Now in terms of classified bank here we don't use HMMS.",
            "Largely because here because of the training requirements, you need quite a few you know in order to force the architecture that hmm onto the data, you need lots of examples.",
            "Here what we've got this kind of very discreet sort of symbols coming in then theory generalized quite well over the data.",
            "And so here what we have in the simplest form of this load of Markov chains that are recognizing the temporal ordering of these sequences."
        ],
        [
            "Yep, and performance wise it works quite well, but I mean I should.",
            "You gotta be careful here because arguably this is this is optimizing the hell out of our test data.",
            "This is 984 isolate signs.",
            "Single user, 5 repetitions for use for training.",
            "1 user validation is cross validated and we could sort of like argue.",
            "We get very good results, but again you know this is single sign.",
            "It's isolated sign so.",
            "But what you should take from this is that the effect of using these different things in isolation in combination for instance, that handshake classification.",
            "Is fairly poor 3.4%, but actually when you combine it with other things it can give you quite a good bolster in performance.",
            "Down here what we're looking at, although it using Markov chains, we can do if you were using HMMS then typically use left right transitional models with skips in the architecture we can enforce these skips onto the Markov chains and we get a similar performance."
        ],
        [
            "Chris, so in terms of a live demo 'cause at the end of the project we want this sign wiki.",
            "We've replaced the front end with a connect 'cause that solves after problems of tracking, but largely architecture means the same.",
            "And then because we're recognizing the signs and we have the hammer SIS, we also have an animation system."
        ],
        [
            "This annacis we can animate the output so it is the system in operation.",
            "This is Helen.",
            "She's going to.",
            "She's going to do some GSL, sign that bridge in GSL.",
            "Bridge.",
            "Now I just know.",
            "OK, well I can get away with it then.",
            "Nobody else knows GSL do they right?",
            "I can make it up as I go along then.",
            "So, but what you should say is that in that case I think it got it.",
            "Got it ranked as the first one, the second one, it guessed it is bend, which kind of goes like that.",
            "So that's you know it's not 100 miles away.",
            "She's now done the sign band.",
            "And again, it's been recognized as the first, I think on the next example, it fails across all four.",
            "It doesn't recognize anything in each of the Avatar says I do not know, but I haven't got time to let that play."
        ],
        [
            "So that's the connect.",
            "Now I know, I know I'm going to go really quick, so we want to move to 3D and we knew the Connect was coming online so that when we when we actually captured all this corpus data we made them do it with 3D cameras.",
            "We made them do it with Bumblebee so that we would be ready for the connect.",
            "Unfortunately that turned into a massive headache."
        ],
        [
            "The bumblebee is nowhere near gave is the same advantage?",
            "Well the same performances would get out the connect and so instead what we've been doing is trying to reconstruct the 3D.",
            "So I've got time to go through this.",
            "This has been accepted for ICC CV so."
        ],
        [
            "Probably be a post you can come along and grill as that, but this is affectively well.",
            "It's a scene flow algorithm, but it's a very efficient one, much more efficient than kind of other ones in the literature, largely based on particle filter.",
            "This is where this is computing scene flow."
        ],
        [
            "From Connect data where we can also use it with some additional color constraints for the multi view.",
            "So this is a cost us which we've already seen in some of the earlier talks and these are the particles in three space and what we get out of this is very nice trajectory's now.",
            "So we've got a lot of clusters pumping away back at home.",
            "Basically computing 3D trajectory's for all of the data that we've got and everything we're doing is to."
        ],
        [
            "Brian gets everything into the same domain because we want to be using the connect for the front end because it's the only way we're going to get this signed wiki to be robust and unusable.",
            "But of course all our data we want to be in a kind of similar domain."
        ],
        [
            "I'm going to talk about this data here.",
            "Some preliminary results.",
            "Using doing user independent recognition.",
            "So this is a very small lexicon of 20 signs, but I mean this has Athens and April in which are two very similar motions.",
            "It's only the handshape classifier that differs.",
            "We can already were assigned to get good generalization across individuals, so this is trained on four subjects tested on one unseen subjects and.",
            "Well, not good here where it's getting good is over here with sequential patterns which I'm not gonna have time to talk about, but that will be fine because the RA that's done the work I could not get slides out because he hasn't published it yet.",
            "He really didn't want me to talk about it, so I've got.",
            "I've got time to talk about facial feature tracking."
        ],
        [
            "One minute."
        ],
        [
            "So facial features tracking.",
            "Right, the last part equation and it's something that we're also looking at looking at in this final year.",
            "The project and what we'd already previously done is weed weed.",
            "Built this linear predictor tracker, so the idea of the linear predictor."
        ],
        [
            "Tracker is so the naive approach if you want to track a facial feature point is to take a texture right so I'll just.",
            "I want this corner.",
            "I'll take the local texture are using LK tracker and it falls flat on its face.",
            "As soon as you try and do anything complicated with it, why?",
            "Well, you know for a corner of the mouth corner VI that's fine, but actually if you want to start tracking points inside the lip using the local texture around that point, particularly bad idea.",
            "As soon as you open your mouth the local texture changes.",
            "So instead what we did is we use this idea linear prediction linear predictor.",
            "Is just a simple predictor that basically predicts the motion of a point based on some pixel intensity changes.",
            "So I want to track this point here.",
            "I've got some support pixels around it and I can artificially offset that measure.",
            "The difference in the pic set, pixel intensity changes and then have a simple linear regressor that says when I see this pixel intensity change, I move like this, right?",
            "Dead simple and rubbish."
        ],
        [
            "At its job."
        ],
        [
            "If you put some of these things together in a flock then they start to become a bit more robust because the idea is that some of them will fail.",
            "Some of them work and the majority vote will actually give you quite a good tracker.",
            "And then what we do is we put the."
        ],
        [
            "Little learning framework selection framework and so here we want to track this point on the upper lip.",
            "And each one of these is a separate linear predictor that we want to build together into a flock, and we're going to do is we're going to choose the best ones and the selection criteria now can choose.",
            "Well, the first thing is, it won't choose anything inside the mouth because of the fact that texture changes.",
            "Here we did coupled X&Y and the interesting thing is, if you want to track a point on the lower inside of the lower lip, that in terms of the X translation it chooses support from the upper lip, which so I want to track this, but it's using stuff.",
            "From from the wrong part of face.",
            "But this is a very good structure to stop this point.",
            "Sliding backwards and forwards.",
            "But of course, if I want to localize it in why, then I'm going to choose points from the rigid part of the face down here."
        ],
        [
            "The chin you do this, you get very good facial feature tracking right?",
            "And the important thing here is there is no facial model here.",
            "There's no prior on the shape of the face.",
            "Each one of these points is affectively independent.",
            "Point tracker.",
            "We've connected them together with the line just for visualization purposes there is there is a gating function in there, so anything that looks wildly like a face not like a face gets kind of dragged back.",
            "But there is no sort of explicit PCA on the shape features.",
            "Well, partly true.",
            "And we've already used this."
        ],
        [
            "Triam got time to talk about this.",
            "You're going to kill."
        ],
        [
            "Right?"
        ],
        [
            "OK, so sequential patterns last thing."
        ],
        [
            "Which he doesn't want me to talk about."
        ],
        [
            "So I won't talk."
        ],
        [
            "But the idea here, this is what's already given as the good performance replacing those simple Markov chains.",
            "I know, I know.",
            "This idea of what we've done is we've taken some of the ideas that I have right in the beginning for a priori in the machine learning which are tree pruning strategies, and we've applied them to more classical machine learning approaches, and we've not published this work yet, but all the results are phenominal, right?",
            "So already it's outperforming the stuff in the sign."
        ],
        [
            "Maine."
        ],
        [
            "And we can do some quite complex."
        ],
        [
            "Things.",
            "Let me show you this video.",
            "And.",
            "This is using the same learning approach to recognize special temporal sequences on the lips.",
            "Which we call word spotting so it's been trained to recognize some number sequences as they appear on the lips.",
            "So there's no speech.",
            "Recognition is purely the just the motion there.",
            "So this I mean this final part of the project."
        ],
        [
            "It's now for us is to try and bring all these things together, but in terms of conclusions.",
            "Interpreting the motion is common across all these examples, and it was a bit eclectic.",
            "Sign is far more complex than motion.",
            "I think.",
            "A priori, we're using to death, I mean, but it really is sort of like it's great.",
            "You know, I remember five years ago boosting, you know the entire cluster was happy and hammered for, you know, for the best part of the week, in order to build some classifier and the these kind of variants on some of the some of the data mining techniques that literally is it takes longer to load the data into memory than it does for us to do the learning process.",
            "And it kind of breaks everything down because I mean it really is sort of like hardcore.",
            "You know from the bottom of machine learning, but I think it needs you need to be a bit careful down here that we're not actually optimizing over our datasets, which is also, so hopefully I'm preaching to converted.",
            "I think we're getting dangerously close now to sort of like going all out.",
            "You know you don't get paper published in less your state of the art and some of these datasets.",
            "Things like KTH.",
            "I mean, we really are just.",
            "How well do these approaches generalize when we're sort of like claiming that we got 95% on these very simple datasets?",
            "So I think it's a community we need to be quite careful that we're not sort of just optimizing overall training data, but.",
            "Test data, but certainly as more and more data in the context of sign comes online.",
            "We can do more more with it I would say right, sorry overtime not my work, I'm just the guy you sort of like pushes people in the right direction.",
            "These are the real stars of the shape."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I apologize now 'cause I have a North and English accent and I talk very fast at the best of times, so I apologized to the interpreters now.",
                    "label": 0
                },
                {
                    "sent": "I'll try and pace it.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "But then I also made the fundamental mistake when I wrote the abstract of including too much, so was actually until I came to put the slides together.",
                    "label": 0
                },
                {
                    "sent": "I thought, Oh my God, Oh my God, how am I gonna fit all this into half an hour?",
                    "label": 0
                },
                {
                    "sent": "So I'm going to race through a rate of knots and I'm going to talk about a couple of things.",
                    "label": 0
                },
                {
                    "sent": "First, a little bit about activity recognition.",
                    "label": 1
                },
                {
                    "sent": "And then I'll move on to sign language recognition.",
                    "label": 0
                },
                {
                    "sent": "And then Lastly facial feature tracking.",
                    "label": 1
                },
                {
                    "sent": "Kind of in the domain of lip reading, but motivated largely for the non manual features that go with the sign language.",
                    "label": 1
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Ignition so first.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "All activity now.",
                    "label": 0
                },
                {
                    "sent": "We spent a long time working with sign.",
                    "label": 0
                },
                {
                    "sent": "And I think the activity recognition was all of a sudden it was becoming quite a popular topic.",
                    "label": 0
                },
                {
                    "sent": "We spent ages sort of like trying to these large lexicons of signs hundreds, or you know, nowadays in thousands of signs and then there were all these other people doing 12 activities.",
                    "label": 0
                },
                {
                    "sent": "So we thought, well can't be that hard going from down to 12.",
                    "label": 0
                },
                {
                    "sent": "So we thought we'd have ago.",
                    "label": 0
                },
                {
                    "sent": "But this.",
                    "label": 0
                },
                {
                    "sent": "This kind of introduced some new learning algorithms to US ones that we kind of well, let's say, stole from the data mining community.",
                    "label": 0
                },
                {
                    "sent": "But the way that we do not abate recognition was was largely to do with trying not to make assumptions.",
                    "label": 0
                },
                {
                    "sent": "So object recognition has gone leaps and bounds, and the key thing behind that's driven object recognition was the idea of feature detectors, feature detectors that were invariant too.",
                    "label": 0
                },
                {
                    "sent": "Define deformation scale invariant.",
                    "label": 0
                },
                {
                    "sent": "All these sorts of things, so it's quite natural that when people have started working on activity or action that you know, let's take special temporal extensions of these things.",
                    "label": 0
                },
                {
                    "sent": "And our argument was, well, if your engineering your features to be sparse to make the problem tractable to be invariant to this, be invariant about you, not necessarily engineering, to be good at what you want them to be, which is discriminating between classes.",
                    "label": 0
                },
                {
                    "sent": "And so we dropped down to the simplest features we could, which were corners, corners, not 3D corners, But corners actually in spatial corners, but also corners in XT and YT.",
                    "label": 0
                },
                {
                    "sent": "And what you end up then it is even for a very low resolution video.",
                    "label": 0
                },
                {
                    "sent": "Millions and millions of these things firing well.",
                    "label": 0
                },
                {
                    "sent": "What we want to try and do is to try and extract the little spatial temporal configurations are corners that are important for the thing that we want to recognize, and so the way we did this was we use data mining and we use the a priori algorithm so.",
                    "label": 0
                },
                {
                    "sent": "We weren't the first to introduce into the vision community.",
                    "label": 0
                },
                {
                    "sent": "I must admit I kind of I was quite inspired by till quacks poster ICCV God knows when it was.",
                    "label": 0
                },
                {
                    "sent": "But the idea is that we use this algorithm, which is kind of commonly known as the shopping basket algorithm.",
                    "label": 0
                },
                {
                    "sent": "To try and find efficiently statistically Co occurring things.",
                    "label": 0
                },
                {
                    "sent": "So for every single corner we've detected and literally there are millions of them.",
                    "label": 0
                },
                {
                    "sent": "What we do is we encode the other corners that fire locally to it.",
                    "label": 0
                },
                {
                    "sent": "So here's a corner.",
                    "label": 0
                },
                {
                    "sent": "And then in a very small spatial region around it, we encode all the other corners, their position, relative position, orientation, their scale at the firing up, and we produce a massive database of these things.",
                    "label": 0
                },
                {
                    "sent": "And then we pump it through this.",
                    "label": 0
                },
                {
                    "sent": "A priori algorithm.",
                    "label": 0
                },
                {
                    "sent": "And we ask it to find those things that are statistically Co occurring and we bastardize the algorithm slightly so that we use in a discriminatory fashion.",
                    "label": 0
                },
                {
                    "sent": "We say find us things that Co occur here but aren't in the negative data.",
                    "label": 0
                },
                {
                    "sent": "And then what we do is we repeat that process.",
                    "label": 0
                },
                {
                    "sent": "So what comes out of that?",
                    "label": 0
                },
                {
                    "sent": "That data mining is a tiny subset of those configurations that are actually relevant and then for each one of those configurations we then encode the configurations relative to each other.",
                    "label": 0
                },
                {
                    "sent": "And I mean it literally takes longer to load.",
                    "label": 0
                },
                {
                    "sent": "Be in for.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Listen to memory than it does to go through because the apriori algorithm uses some very efficient tree pruning strategies to try and find these statistically relevant things.",
                    "label": 0
                },
                {
                    "sent": "So just as kind of an overview, this is, you know these are corners down the lowest level we encode these, we pump it through this algorithm and what the algorithm says is, well, there's this little configuration here made out of these corners.",
                    "label": 0
                },
                {
                    "sent": "This one over here this one over here that I think are relevant for this class on a discriminatory against other classes.",
                    "label": 0
                },
                {
                    "sent": "And then we repeat the process at a slightly larger scale.",
                    "label": 0
                },
                {
                    "sent": "And then it says, right?",
                    "label": 0
                },
                {
                    "sent": "Well, I found another configuration that's build out of these configurations.",
                    "label": 0
                },
                {
                    "sent": "So down at this level you've got millions of millions of corners.",
                    "label": 0
                },
                {
                    "sent": "But at this level you've effectively got some class that the thing that you want to recognize.",
                    "label": 0
                },
                {
                    "sent": "And the important thing is that each point this stage is throwing away, you know here you throw away 99% of those millions of corners 'cause they're completely.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Worthless now if you do this, what you get is very good performance, right?",
                    "label": 0
                },
                {
                    "sent": "So and you know these are.",
                    "label": 0
                },
                {
                    "sent": "KTH is kind of maxed out now so it's fairly hard not to get sort of like in the 90s, but it does.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Be well on most of the popular datasets and this is on the Hollywood data and it you know it's nice 'cause you can actually interpret what's going on.",
                    "label": 0
                },
                {
                    "sent": "So obviously these are corners.",
                    "label": 0
                },
                {
                    "sent": "It's fairly poor performance, and as our groupings of these corners get more complex than the recognition accuracy goes up and here is a video of shake hands.",
                    "label": 0
                },
                {
                    "sent": "These are corners firing.",
                    "label": 0
                },
                {
                    "sent": "These are stage two.",
                    "label": 0
                },
                {
                    "sent": "These are stage three, so this is actually whether the recognition is happening and you can sort of see that there's only a subset of the features.",
                    "label": 0
                },
                {
                    "sent": "The original features that actually fire anymore, and the interesting thing is that these things far along the arm, right?",
                    "label": 0
                },
                {
                    "sent": "So it's kind of it's localized in space and time.",
                    "label": 0
                },
                {
                    "sent": "The one thing in that video that was kind of had some commonality.",
                    "label": 0
                },
                {
                    "sent": "And don't forget you're not looking at a corner anymore, you're looking at a representation of some sort of configuration of corners in space and time.",
                    "label": 0
                },
                {
                    "sent": "The interesting thing is it also picks up features on the head.",
                    "label": 0
                },
                {
                    "sent": "And I have no, you know, sort of.",
                    "label": 0
                },
                {
                    "sent": "Like evidenced about this up.",
                    "label": 0
                },
                {
                    "sent": "But I would argue that's kind of to do with.",
                    "label": 0
                },
                {
                    "sent": "I mean, you look at these videos quite a lot of them they're taking from Hollywood movies.",
                    "label": 0
                },
                {
                    "sent": "I mean, sort of the data is in the room.",
                    "label": 0
                },
                {
                    "sent": "And and it's phenomenally difficult data.",
                    "label": 0
                },
                {
                    "sent": "I mean, in some of those cases, you can't even see their hands.",
                    "label": 0
                },
                {
                    "sent": "So I mean, I'll be glad, say, because this is pure data driven approach.",
                    "label": 0
                },
                {
                    "sent": "It's trying to pick up anything it possibly can to recognize the action.",
                    "label": 0
                },
                {
                    "sent": "So it's also picking up on the fact that, well, as a slight head nod when when they, when they show.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Accounts now what we've done is we've taken this one stage further, and so we're looking at now, iteratively grouping images and video.",
                    "label": 0
                },
                {
                    "sent": "So the idea is that rather than taking a hard data set, these are this this class?",
                    "label": 0
                },
                {
                    "sent": "These are that class what we want to do is allow the user to actually manipulate the data directly and say I think these have something in common.",
                    "label": 0
                },
                {
                    "sent": "Put them in the same category and so we've done this by combining 2 two different data mining approaches.",
                    "label": 0
                },
                {
                    "sent": "The min hash algorithm and an the a priori algorithm.",
                    "label": 1
                },
                {
                    "sent": "The min hash allows us to.",
                    "label": 0
                },
                {
                    "sent": "Like very very very large descriptors, you know, sort of like bag of words, approaches.",
                    "label": 0
                },
                {
                    "sent": "And and very efficiently compute metric distance spaces on this, and then we allow we project we can protect that data.",
                    "label": 0
                },
                {
                    "sent": "We would allow the user to say I think these should be the same class.",
                    "label": 1
                },
                {
                    "sent": "I think these shouldn't be the same class and then the Priory goes through.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Who and tries to find the rules that these examples have in common?",
                    "label": 0
                },
                {
                    "sent": "So just to illustrate here, we've got 2 examples from the YouTube data set of swimming, and these are very, you know, appearance wise.",
                    "label": 0
                },
                {
                    "sent": "They've got not got a great deal in common and in terms of the visualization space, they're both very separate.",
                    "label": 0
                },
                {
                    "sent": "What we've done is the user is taken to the examples, push them together.",
                    "label": 0
                },
                {
                    "sent": "We've run it through this learning algorithm and it finds some rules and what it actually does.",
                    "label": 0
                },
                {
                    "sent": "Is it really weight?",
                    "label": 0
                },
                {
                    "sent": "The the histogram representation, so it can actually be based on whatever you want, and in this paper we had a paper accepted for ICC V. We demonstrated in images and videos using various difference or representations.",
                    "label": 0
                },
                {
                    "sent": "And it's very sad because for the 1200 videos for YouTube, it's 35 seconds per iteration and with about I think about 28 videos.",
                    "label": 1
                },
                {
                    "sent": "We can get the same sort of clustering performance.",
                    "label": 0
                },
                {
                    "sent": "Well, yeah, same clustering results out of it as if you'd used all the ground truth label data there.",
                    "label": 0
                },
                {
                    "sent": "So and arguably I mean 'cause.",
                    "label": 0
                },
                {
                    "sent": "What happens when you're visually doing this?",
                    "label": 0
                },
                {
                    "sent": "You will pick the outliers, you will pick the most challenging cases.",
                    "label": 0
                },
                {
                    "sent": "So you as an interactive part of the learning algorithm.",
                    "label": 0
                },
                {
                    "sent": "I'll be in.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Selective about the best constraints to add it.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So now I'm going to move on a bit about sign language.",
                    "label": 0
                },
                {
                    "sent": "We've already heard quite a bit about it, so I'm not going to dwell on.",
                    "label": 0
                },
                {
                    "sent": "It's got various parts, the the motion and the handshake finger spelling, which is just a very small part of it.",
                    "label": 0
                },
                {
                    "sent": "Non manual features which is a partner in terms of visual recognition.",
                    "label": 0
                },
                {
                    "sent": "We often neglect and then this thing here, which we really haven't got a handle on.",
                    "label": 0
                },
                {
                    "sent": "Yeah I would say which is the complex linguistic constructs and I think this is one of the things that's really missing to allow us to do proper continuous recognition.",
                    "label": 0
                },
                {
                    "sent": "But speaking very personally, one of the problems I've always had.",
                    "label": 0
                },
                {
                    "sent": "We sign language recognition is the sheer lack of available data back or framework 5 or whatever it was when I started working with Andrew Jessamine on sign language recognition.",
                    "label": 0
                },
                {
                    "sent": "Very, you know when it was muggins here, who was the only person that actually understood some sign and it was muggins here.",
                    "label": 0
                },
                {
                    "sent": "I'd sit down and label all the data.",
                    "label": 0
                },
                {
                    "sent": "It very quickly brought home to me that we were going to have to look at new ways to tackle this.",
                    "label": 0
                },
                {
                    "sent": "And a couple years ago we tried the same algorithms I've just shown you in.",
                    "label": 0
                },
                {
                    "sent": "The domain of the activity that a priori algorithm we tried to use that to see if we could automatically learn from subtitles.",
                    "label": 0
                },
                {
                    "sent": "So here we got a bit of video footage.",
                    "label": 0
                },
                {
                    "sent": "There's a signer here, and So what we've got is subtitle.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "That are also being translated so the idea is can we use the subtitles of some form weak supervision in order to learn the signs that are there?",
                    "label": 1
                },
                {
                    "sent": "If we could do that, fantastic, I don't need to label data anymore.",
                    "label": 0
                },
                {
                    "sent": "Who are, hey, we're off.",
                    "label": 0
                },
                {
                    "sent": "The trouble is, it's actually not that easy, of course, and what we've got here is you've got the sign glass and then we've got the subtitles underneath and we color coded where there is some correlation between the two, so you can sort of see that occasionally there is a word that occurs in the subtitles and the corresponding sign also occurs.",
                    "label": 0
                },
                {
                    "sent": "But we don't know whether it's before, whether it's after, whether it's there at all.",
                    "label": 0
                },
                {
                    "sent": "And of course, because of the nature of sign language design, even though it says that's I might be there, it's in a different can't.",
                    "label": 1
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Actually, it may actually be completely different in that context, But what we did is we take the tracking.",
                    "label": 0
                },
                {
                    "sent": "We can cluster those features and then we can use this a priori algorithm again to try and go through and find the things that happened in the visual domain that statistically important because we don't know what the time window is.",
                    "label": 0
                },
                {
                    "sent": "We start with a very large time window and then what we try and do is hone in on the places where we think there is something in common and we also do something which we called.",
                    "label": 0
                },
                {
                    "sent": "Introducing contextual negatives and that gave us a real performance increase because if you know that you've got 2 signs in the subtitles, 2 words that are next to each other, then you can artificially dope your negative training data by trying to find where you know examples of exactly what you think is going to contaminate your present positive data.",
                    "label": 0
                },
                {
                    "sent": "So that does help and these are signs that are automatically being pulled out.",
                    "label": 0
                },
                {
                    "sent": "The signs for army in obese and there's no user intervention at all.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "But of course I mean.",
                    "label": 0
                },
                {
                    "sent": "Sign languages is far more complex than just a simple bit of motion of the hand.",
                    "label": 1
                },
                {
                    "sent": "So while this approach does work, you know it's it's not particularly scalable approach, but we do have a new project starting in October with the system and everything 'em 'cause I mean we had a friendly competition so we both had papers doing almost the same thing in that CPR 09, but we've got a four year project now to try and take this further.",
                    "label": 0
                },
                {
                    "sent": "We're going to be looking @ language, but we want to look at more general broadcast footage.",
                    "label": 0
                },
                {
                    "sent": "So the idea is that the system will automatically learn.",
                    "label": 0
                },
                {
                    "sent": "Kind of metadata annotation and then magically it will just be able to sort of like annotate incoming data for us.",
                    "label": 0
                },
                {
                    "sent": "Of course it will be as easy as that's in four years time.",
                    "label": 0
                },
                {
                    "sent": "The whole problem will be solved what we've been working on the moment though is this project Vector sign which Christian's already talked a bit about this morning.",
                    "label": 1
                },
                {
                    "sent": "And this is a large EU project and one of the advantages for me for this project was the massive amount of data that it said it would capture.",
                    "label": 0
                },
                {
                    "sent": "So it was to generate four parallel corpora across.",
                    "label": 1
                },
                {
                    "sent": "Four different domains, and then of course somebody else is doing all the annotation, which was fantastic as well.",
                    "label": 0
                },
                {
                    "sent": "Annotation using the hammer, SIS and the objective of the project is to produce kind of Web 2.0 tools, so one of the demonstrators which worries the hell out of us is the concept of a sign wiki right?",
                    "label": 1
                },
                {
                    "sent": "And so by hook or by crook by the end of the project we will have a system where you can sign in front of it and an avatar will give you will.",
                    "label": 0
                },
                {
                    "sent": "Repeat that sign in back and then the user will be able to go in and edit that that that information.",
                    "label": 0
                },
                {
                    "sent": "It'll be fine without, you know we were only in the fight.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The announcer.",
                    "label": 0
                },
                {
                    "sent": "So with so I'm not going to dwell on this 'cause I got no time left and all really Christians talks about how many assist, but how much?",
                    "label": 0
                },
                {
                    "sent": "This is quite well is this phonetic representation of language.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I won't talk about.",
                    "label": 0
                },
                {
                    "sent": "I mean, this is actually not the sign for Rich in BSL.",
                    "label": 0
                },
                {
                    "sent": "It's designed for wealthy, but it is my sign name because Rich is my name.",
                    "label": 0
                },
                {
                    "sent": "But the nice thing about it is, is the generalization right?",
                    "label": 0
                },
                {
                    "sent": "So Christians already explain this.",
                    "label": 0
                },
                {
                    "sent": "This is a left to right mirror.",
                    "label": 1
                },
                {
                    "sent": "This the handshake with the modification.",
                    "label": 0
                },
                {
                    "sent": "This is where it's happening in the body.",
                    "label": 0
                },
                {
                    "sent": "This is palm orientation.",
                    "label": 0
                },
                {
                    "sent": "This is the motion downwards, but the idea is that it doesn't matter if I do it slow.",
                    "label": 0
                },
                {
                    "sent": "I do it fast, I do it in a large science based doing the small sign space.",
                    "label": 0
                },
                {
                    "sent": "The symbol should be fairly consistent, so as with speech, the argument for recognizing phonetic level is there.",
                    "label": 0
                },
                {
                    "sent": "It should generalize better across people.",
                    "label": 0
                },
                {
                    "sent": "The other advantage, of course, is that sign data is difficult to acquire.",
                    "label": 0
                },
                {
                    "sent": "We got terabytes and terabytes of it were drowning in it.",
                    "label": 0
                },
                {
                    "sent": "It's difficult to annotate, and you've got precious few examples of, for instance, assign.",
                    "label": 0
                },
                {
                    "sent": "But because the phonemes, the phonetic sort of components.",
                    "label": 0
                },
                {
                    "sent": "Can exist in multiple signs, although you may have only have a handful of examples of the sign itself, you've got lots of examples.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Down at the phonetic level, so we're encoding at the moment just a subset of these hypnosis features.",
                    "label": 0
                },
                {
                    "sent": "Location mode.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In Hampshire, handshake Handshape learned using while the best results we get from using visual Gist features, which are effectively Gabor filters computed over different different scales.",
                    "label": 0
                },
                {
                    "sent": "And then these are put through an RDF random decision forest classifier and you get actually in terms of sine, fairly poor performance because that's, but that's because there's huge amounts of variation if you take some handshape classifier.",
                    "label": 0
                },
                {
                    "sent": "Then the actual visual appearance of it through all the motion is actually quite varied.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In something like finger spelling where the hand poses far more constrained than recognition, recognition becomes much easier.",
                    "label": 0
                },
                {
                    "sent": "So here we've got.",
                    "label": 0
                },
                {
                    "sent": "This is a connect camera.",
                    "label": 0
                },
                {
                    "sent": "This is recognizing the Gabor features actually in the depth domain.",
                    "label": 0
                },
                {
                    "sent": "And the the ranked classification results are shown like this.",
                    "label": 0
                },
                {
                    "sent": "So if this thing was.",
                    "label": 0
                },
                {
                    "sent": "Was working 100% accurately.",
                    "label": 0
                },
                {
                    "sent": "Then the the the correct letter would always be on the right hand side, but we rank them to give the user so that when classification fails you can choose or the next best.",
                    "label": 0
                },
                {
                    "sent": "Yeah, well.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It's not.",
                    "label": 0
                },
                {
                    "sent": "So we struck these features from our sign.",
                    "label": 0
                },
                {
                    "sent": "And So what you can see down here is this little ticker tape and that's a load of classifiers, basically firing and then what we want to do is learn the patterns of these classifiers.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the architecture looks something like this.",
                    "label": 0
                },
                {
                    "sent": "We got some dictionary videos, we've got some extracted features.",
                    "label": 0
                },
                {
                    "sent": "There's a training procedure and then we got this big classifier bank.",
                    "label": 0
                },
                {
                    "sent": "And now what happens at runtime is we extract the same features we run through the classifier bank.",
                    "label": 0
                },
                {
                    "sent": "We're trying to find the sign that we that we want and then we display the results.",
                    "label": 0
                },
                {
                    "sent": "Now in terms of classified bank here we don't use HMMS.",
                    "label": 0
                },
                {
                    "sent": "Largely because here because of the training requirements, you need quite a few you know in order to force the architecture that hmm onto the data, you need lots of examples.",
                    "label": 0
                },
                {
                    "sent": "Here what we've got this kind of very discreet sort of symbols coming in then theory generalized quite well over the data.",
                    "label": 0
                },
                {
                    "sent": "And so here what we have in the simplest form of this load of Markov chains that are recognizing the temporal ordering of these sequences.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Yep, and performance wise it works quite well, but I mean I should.",
                    "label": 0
                },
                {
                    "sent": "You gotta be careful here because arguably this is this is optimizing the hell out of our test data.",
                    "label": 0
                },
                {
                    "sent": "This is 984 isolate signs.",
                    "label": 0
                },
                {
                    "sent": "Single user, 5 repetitions for use for training.",
                    "label": 0
                },
                {
                    "sent": "1 user validation is cross validated and we could sort of like argue.",
                    "label": 0
                },
                {
                    "sent": "We get very good results, but again you know this is single sign.",
                    "label": 0
                },
                {
                    "sent": "It's isolated sign so.",
                    "label": 0
                },
                {
                    "sent": "But what you should take from this is that the effect of using these different things in isolation in combination for instance, that handshake classification.",
                    "label": 0
                },
                {
                    "sent": "Is fairly poor 3.4%, but actually when you combine it with other things it can give you quite a good bolster in performance.",
                    "label": 0
                },
                {
                    "sent": "Down here what we're looking at, although it using Markov chains, we can do if you were using HMMS then typically use left right transitional models with skips in the architecture we can enforce these skips onto the Markov chains and we get a similar performance.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Chris, so in terms of a live demo 'cause at the end of the project we want this sign wiki.",
                    "label": 1
                },
                {
                    "sent": "We've replaced the front end with a connect 'cause that solves after problems of tracking, but largely architecture means the same.",
                    "label": 0
                },
                {
                    "sent": "And then because we're recognizing the signs and we have the hammer SIS, we also have an animation system.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This annacis we can animate the output so it is the system in operation.",
                    "label": 0
                },
                {
                    "sent": "This is Helen.",
                    "label": 0
                },
                {
                    "sent": "She's going to.",
                    "label": 0
                },
                {
                    "sent": "She's going to do some GSL, sign that bridge in GSL.",
                    "label": 0
                },
                {
                    "sent": "Bridge.",
                    "label": 0
                },
                {
                    "sent": "Now I just know.",
                    "label": 0
                },
                {
                    "sent": "OK, well I can get away with it then.",
                    "label": 0
                },
                {
                    "sent": "Nobody else knows GSL do they right?",
                    "label": 0
                },
                {
                    "sent": "I can make it up as I go along then.",
                    "label": 0
                },
                {
                    "sent": "So, but what you should say is that in that case I think it got it.",
                    "label": 0
                },
                {
                    "sent": "Got it ranked as the first one, the second one, it guessed it is bend, which kind of goes like that.",
                    "label": 0
                },
                {
                    "sent": "So that's you know it's not 100 miles away.",
                    "label": 0
                },
                {
                    "sent": "She's now done the sign band.",
                    "label": 0
                },
                {
                    "sent": "And again, it's been recognized as the first, I think on the next example, it fails across all four.",
                    "label": 0
                },
                {
                    "sent": "It doesn't recognize anything in each of the Avatar says I do not know, but I haven't got time to let that play.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So that's the connect.",
                    "label": 0
                },
                {
                    "sent": "Now I know, I know I'm going to go really quick, so we want to move to 3D and we knew the Connect was coming online so that when we when we actually captured all this corpus data we made them do it with 3D cameras.",
                    "label": 0
                },
                {
                    "sent": "We made them do it with Bumblebee so that we would be ready for the connect.",
                    "label": 0
                },
                {
                    "sent": "Unfortunately that turned into a massive headache.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The bumblebee is nowhere near gave is the same advantage?",
                    "label": 0
                },
                {
                    "sent": "Well the same performances would get out the connect and so instead what we've been doing is trying to reconstruct the 3D.",
                    "label": 0
                },
                {
                    "sent": "So I've got time to go through this.",
                    "label": 0
                },
                {
                    "sent": "This has been accepted for ICC CV so.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Probably be a post you can come along and grill as that, but this is affectively well.",
                    "label": 0
                },
                {
                    "sent": "It's a scene flow algorithm, but it's a very efficient one, much more efficient than kind of other ones in the literature, largely based on particle filter.",
                    "label": 0
                },
                {
                    "sent": "This is where this is computing scene flow.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "From Connect data where we can also use it with some additional color constraints for the multi view.",
                    "label": 0
                },
                {
                    "sent": "So this is a cost us which we've already seen in some of the earlier talks and these are the particles in three space and what we get out of this is very nice trajectory's now.",
                    "label": 0
                },
                {
                    "sent": "So we've got a lot of clusters pumping away back at home.",
                    "label": 0
                },
                {
                    "sent": "Basically computing 3D trajectory's for all of the data that we've got and everything we're doing is to.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Brian gets everything into the same domain because we want to be using the connect for the front end because it's the only way we're going to get this signed wiki to be robust and unusable.",
                    "label": 0
                },
                {
                    "sent": "But of course all our data we want to be in a kind of similar domain.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I'm going to talk about this data here.",
                    "label": 0
                },
                {
                    "sent": "Some preliminary results.",
                    "label": 0
                },
                {
                    "sent": "Using doing user independent recognition.",
                    "label": 0
                },
                {
                    "sent": "So this is a very small lexicon of 20 signs, but I mean this has Athens and April in which are two very similar motions.",
                    "label": 0
                },
                {
                    "sent": "It's only the handshape classifier that differs.",
                    "label": 0
                },
                {
                    "sent": "We can already were assigned to get good generalization across individuals, so this is trained on four subjects tested on one unseen subjects and.",
                    "label": 0
                },
                {
                    "sent": "Well, not good here where it's getting good is over here with sequential patterns which I'm not gonna have time to talk about, but that will be fine because the RA that's done the work I could not get slides out because he hasn't published it yet.",
                    "label": 0
                },
                {
                    "sent": "He really didn't want me to talk about it, so I've got.",
                    "label": 0
                },
                {
                    "sent": "I've got time to talk about facial feature tracking.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "One minute.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So facial features tracking.",
                    "label": 0
                },
                {
                    "sent": "Right, the last part equation and it's something that we're also looking at looking at in this final year.",
                    "label": 0
                },
                {
                    "sent": "The project and what we'd already previously done is weed weed.",
                    "label": 0
                },
                {
                    "sent": "Built this linear predictor tracker, so the idea of the linear predictor.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Tracker is so the naive approach if you want to track a facial feature point is to take a texture right so I'll just.",
                    "label": 0
                },
                {
                    "sent": "I want this corner.",
                    "label": 0
                },
                {
                    "sent": "I'll take the local texture are using LK tracker and it falls flat on its face.",
                    "label": 0
                },
                {
                    "sent": "As soon as you try and do anything complicated with it, why?",
                    "label": 0
                },
                {
                    "sent": "Well, you know for a corner of the mouth corner VI that's fine, but actually if you want to start tracking points inside the lip using the local texture around that point, particularly bad idea.",
                    "label": 0
                },
                {
                    "sent": "As soon as you open your mouth the local texture changes.",
                    "label": 0
                },
                {
                    "sent": "So instead what we did is we use this idea linear prediction linear predictor.",
                    "label": 0
                },
                {
                    "sent": "Is just a simple predictor that basically predicts the motion of a point based on some pixel intensity changes.",
                    "label": 1
                },
                {
                    "sent": "So I want to track this point here.",
                    "label": 0
                },
                {
                    "sent": "I've got some support pixels around it and I can artificially offset that measure.",
                    "label": 1
                },
                {
                    "sent": "The difference in the pic set, pixel intensity changes and then have a simple linear regressor that says when I see this pixel intensity change, I move like this, right?",
                    "label": 0
                },
                {
                    "sent": "Dead simple and rubbish.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "At its job.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "If you put some of these things together in a flock then they start to become a bit more robust because the idea is that some of them will fail.",
                    "label": 0
                },
                {
                    "sent": "Some of them work and the majority vote will actually give you quite a good tracker.",
                    "label": 0
                },
                {
                    "sent": "And then what we do is we put the.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Little learning framework selection framework and so here we want to track this point on the upper lip.",
                    "label": 0
                },
                {
                    "sent": "And each one of these is a separate linear predictor that we want to build together into a flock, and we're going to do is we're going to choose the best ones and the selection criteria now can choose.",
                    "label": 0
                },
                {
                    "sent": "Well, the first thing is, it won't choose anything inside the mouth because of the fact that texture changes.",
                    "label": 0
                },
                {
                    "sent": "Here we did coupled X&Y and the interesting thing is, if you want to track a point on the lower inside of the lower lip, that in terms of the X translation it chooses support from the upper lip, which so I want to track this, but it's using stuff.",
                    "label": 0
                },
                {
                    "sent": "From from the wrong part of face.",
                    "label": 0
                },
                {
                    "sent": "But this is a very good structure to stop this point.",
                    "label": 0
                },
                {
                    "sent": "Sliding backwards and forwards.",
                    "label": 0
                },
                {
                    "sent": "But of course, if I want to localize it in why, then I'm going to choose points from the rigid part of the face down here.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The chin you do this, you get very good facial feature tracking right?",
                    "label": 1
                },
                {
                    "sent": "And the important thing here is there is no facial model here.",
                    "label": 0
                },
                {
                    "sent": "There's no prior on the shape of the face.",
                    "label": 0
                },
                {
                    "sent": "Each one of these points is affectively independent.",
                    "label": 0
                },
                {
                    "sent": "Point tracker.",
                    "label": 0
                },
                {
                    "sent": "We've connected them together with the line just for visualization purposes there is there is a gating function in there, so anything that looks wildly like a face not like a face gets kind of dragged back.",
                    "label": 0
                },
                {
                    "sent": "But there is no sort of explicit PCA on the shape features.",
                    "label": 0
                },
                {
                    "sent": "Well, partly true.",
                    "label": 0
                },
                {
                    "sent": "And we've already used this.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Triam got time to talk about this.",
                    "label": 0
                },
                {
                    "sent": "You're going to kill.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Right?",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so sequential patterns last thing.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Which he doesn't want me to talk about.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So I won't talk.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But the idea here, this is what's already given as the good performance replacing those simple Markov chains.",
                    "label": 0
                },
                {
                    "sent": "I know, I know.",
                    "label": 0
                },
                {
                    "sent": "This idea of what we've done is we've taken some of the ideas that I have right in the beginning for a priori in the machine learning which are tree pruning strategies, and we've applied them to more classical machine learning approaches, and we've not published this work yet, but all the results are phenominal, right?",
                    "label": 0
                },
                {
                    "sent": "So already it's outperforming the stuff in the sign.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Maine.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we can do some quite complex.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_46": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Things.",
                    "label": 0
                },
                {
                    "sent": "Let me show you this video.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "This is using the same learning approach to recognize special temporal sequences on the lips.",
                    "label": 0
                },
                {
                    "sent": "Which we call word spotting so it's been trained to recognize some number sequences as they appear on the lips.",
                    "label": 0
                },
                {
                    "sent": "So there's no speech.",
                    "label": 0
                },
                {
                    "sent": "Recognition is purely the just the motion there.",
                    "label": 0
                },
                {
                    "sent": "So this I mean this final part of the project.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It's now for us is to try and bring all these things together, but in terms of conclusions.",
                    "label": 0
                },
                {
                    "sent": "Interpreting the motion is common across all these examples, and it was a bit eclectic.",
                    "label": 0
                },
                {
                    "sent": "Sign is far more complex than motion.",
                    "label": 0
                },
                {
                    "sent": "I think.",
                    "label": 0
                },
                {
                    "sent": "A priori, we're using to death, I mean, but it really is sort of like it's great.",
                    "label": 0
                },
                {
                    "sent": "You know, I remember five years ago boosting, you know the entire cluster was happy and hammered for, you know, for the best part of the week, in order to build some classifier and the these kind of variants on some of the some of the data mining techniques that literally is it takes longer to load the data into memory than it does for us to do the learning process.",
                    "label": 0
                },
                {
                    "sent": "And it kind of breaks everything down because I mean it really is sort of like hardcore.",
                    "label": 0
                },
                {
                    "sent": "You know from the bottom of machine learning, but I think it needs you need to be a bit careful down here that we're not actually optimizing over our datasets, which is also, so hopefully I'm preaching to converted.",
                    "label": 0
                },
                {
                    "sent": "I think we're getting dangerously close now to sort of like going all out.",
                    "label": 0
                },
                {
                    "sent": "You know you don't get paper published in less your state of the art and some of these datasets.",
                    "label": 0
                },
                {
                    "sent": "Things like KTH.",
                    "label": 0
                },
                {
                    "sent": "I mean, we really are just.",
                    "label": 0
                },
                {
                    "sent": "How well do these approaches generalize when we're sort of like claiming that we got 95% on these very simple datasets?",
                    "label": 0
                },
                {
                    "sent": "So I think it's a community we need to be quite careful that we're not sort of just optimizing overall training data, but.",
                    "label": 0
                },
                {
                    "sent": "Test data, but certainly as more and more data in the context of sign comes online.",
                    "label": 0
                },
                {
                    "sent": "We can do more more with it I would say right, sorry overtime not my work, I'm just the guy you sort of like pushes people in the right direction.",
                    "label": 0
                },
                {
                    "sent": "These are the real stars of the shape.",
                    "label": 0
                }
            ]
        }
    }
}