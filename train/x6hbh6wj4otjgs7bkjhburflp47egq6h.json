{
    "id": "x6hbh6wj4otjgs7bkjhburflp47egq6h",
    "title": "Formal Theory of Fun & Creativity",
    "info": {
        "author": [
            "Jurgen Schmidhuber, IDSIA"
        ],
        "published": "Dec. 13, 2010",
        "recorded": "September 2010",
        "category": [
            "Top->Computer Science->Machine Learning"
        ]
    },
    "url": "http://videolectures.net/ecmlpkdd2010_schmidhuber_ftf/",
    "segmentation": [
        [
            "Three prisoners were sentence to death.",
            "One of them friends, one of them.",
            "German, one of them Spanish.",
            "What is your last wish?",
            "They ask the French guy, he says.",
            "A bottle of exquisite a French wine was last wish.",
            "They asked the German guy, he says.",
            "I want to give a speech.",
            "What is your last wish?",
            "They ask the Spanish guy, he says.",
            "I want to get shot before the German starts this speech.",
            "Unfortunately for you guys, it is too late now because I'm in the middle of my little speech already.",
            "And it's about the formal theory of fun and creativity.",
            "This is my name.",
            "This is to help Michelle pronounce my name.",
            "And ask you."
        ],
        [
            "He mentioned I'm spending most of my time at the Swiss AI lab.",
            "It's yeah, but I also."
        ],
        [
            "Of a research group at the Tech University Munich focusing on robot learning.",
            "See it's here.",
            "By the way, is affiliated with the University of Lugano and Subsea."
        ],
        [
            "Traditional reinforcement learning.",
            "Is about Asians that interact with the world and then there is a reward function which you are supposed to optimize and the wild is unknown and everything is clear because usually it goes like this.",
            "There's a robot and it bumps against an obstacle and then it feels pain which is just a negative number or it reaches a goal which is given by the external teacher.",
            "And it gets a positive reward and the sum of these negative and positive rewards should be as high as possible.",
            "So the reinforcement learning algorithm is trying to maximize the future expected reward at that time.",
            "So that is just traditional standard reinforcement learning and found many, many methods for that.",
            "But with humans there's this additional thing, apparently.",
            "You also get reward for.",
            "Listening to music.",
            "Why?",
            "That's what does that have with what does that have to do with problem solving?",
            "Or going to the museum or going to a place like this?",
            "Which in many ways is a statically pleasing.",
            "But what does it mean to be pleasing?",
            "What kind of internal reward is that that you get there?",
            "And can we make that formal?",
            "And is there may be a reason for that external reward?",
            "And can we implement that stuff on robots set such that they become better robots?",
            "That's what I'm going to talk about and the basic idea is extremely simple.",
            "I believe that and I want to convince you that this intrinsic reward is the thing that is driving all these fundamental human activities such as sinzan.",
            "Art and comedy and whatever and and the only thing that is important.",
            "The thing that is defining the intrinsic reward is the creation or discovery of novel patterns.",
            "Novel patterns.",
            "Now this is sounds just like an informal stuff.",
            "So to make this formal we have to add."
        ],
        [
            "So two questions.",
            "The first question is, what exactly is a pattern and?",
            "When is it novel as opposed to already known?"
        ],
        [
            "And computer science has the answer.",
            "It knows what is a pattern, any set of raw data has a pattern.",
            "If you can describe it by a computer program that is significantly shorter than the raw data itself.",
            "Then it's compressible.",
            "Any symmetry, any regularity, can be expressed in this way?",
            "So anything that is regular has a program that is shorter than the original data itself, so we know where the pattern is.",
            "For example, here we have a piece of broccoli which is fractal, which means that.",
            "The program that computes the outline of the broccoli can also be reused again to compute all these little details.",
            "Offer broccoli because it's self similar and so a very short piece of code computes the entire broccoli.",
            "So that is one of a million examples of regular patterns.",
            "But there are many, many patterns which are already known and which are uninteresting and not rewarding because you already know them.",
            "What is a novel pattern and how can I measure how novel it is and how rewarding it is?",
            "To deal with it.",
            "And the answer is the compression algorithm that you are using as you are encoding.",
            "Parts of the input stream.",
            "Is not.",
            "Constant, it's not the same compression algorithm.",
            "All the time, but it improves through learning, so there's a learning algorithm which is working on it, and in this way it becomes a better compressor, better encoder of the data, and then for any data you can just compare how many bits did I need to encode this data before learning.",
            "And how many bits do I need afterwards?",
            "If there is a normal regularity, then afterwards I needed fewer bits.",
            "Which means I made compression progress or learning progress, and that's the crucial thing.",
            "He is 3 bits that you just saved.",
            "That is your intrinsic keyboard.",
            "That is your learning progress.",
            "And that's why you want to maximize as an actor who is selecting the data which you are trying to compress or to explain to analyze.",
            "And that's it.",
            "That's what my talk is about, and it's extremely simple.",
            "The principle is extremely simple."
        ],
        [
            "And the the only devil is occasionally is somewhere in the detail.",
            "Let me explain how that explains physics.",
            "As a physicist, you are motivated to create experiments that lead to data.",
            "That follow a previously unknown law, not a known law which you already can easily compress.",
            "But some pattern where you still have to work on what exactly is the pattern.",
            "And once you find the pattern you will suddenly can greatly compress the history, for example 10.",
            "Apples are falling to the ground, and they're all falling in the same way.",
            "And if you don't know the law of gravity but suddenly discover it, then you can use this very short code that.",
            "That embodies the law of gravity to greatly compress the video of the 10 falling apples, because the same orange blob is always going down the same way, there are many details that you cannot explain by this by this simpler, However, you can still greatly compress because there is at least something in the video that is really regular and explainable by a short law in music.",
            "It's just the same thing as a composer.",
            "You are motivated to create.",
            "Newer sound streams that don't sound like the already known run of the mill rock and roll songs, but weather is a new harmony, something that is unusual but still regular so it's nonrandom, non arbitrary.",
            "It's regular, but in a way that was known before.",
            "So music is all about finding novel patterns.",
            "As an artist, you are trying to create these novel novel patterns.",
            "As an observer.",
            "You're listening to them, and you know once you listen to a certain song 100 times in a row.",
            "It's not interesting anymore, but your actor, the action selector, which says, for example, select the next song from the same composer, maybe is trying to maximize the future expected reward by taking the stuff that he learned so far.",
            "For example this composer.",
            "Is writing pleasing songs and add something to the knowledge that you already have from this way, so adding novel patterns to your repertoire.",
            "And as you are building this repertoire, you also building the action repertoire which you need to construct these."
        ],
        [
            "Patterns.",
            "The same in the visual arts.",
            "Visual arts is about novel patterns, just like music and like science.",
            "Barcelona is full of novel patterns for tourists, at least those who already know them every day.",
            "They are less interested in them than the tourists who.",
            "Always stand there in front of the saga Amelia and crowd the place because there are lots of regular things going on there and they are interesting.",
            "There's interesting Ness.",
            "We want intrinsic reward internal reward for seeing these patterns that are novel.",
            "As long as you haven't assimilated."
        ],
        [
            "I'm yet to build a creative system.",
            "We therefore need only two learning modules.",
            "We need.",
            "First of all, the compressor said takes the incoming data stream and compresses it, but then there's a learning algorithm on top of it such that overtime, as the history is growing, it gets more and more training examples which it can use to become a better compressor such that the raw data is like that.",
            "The compressed version of it is like that.",
            "And then maybe overnight, the learning algorithm is running and then the new compressed version of the data is like that and that you will save 3 bits and that's the exciting thing.",
            "That's the progress you will never in general achieve a situation where you where you go all the way down to the Kolmogorov McConnell graph complexity of the data history, which is essentially the length of the shortest program that computes the entire data.",
            "And there's no way of finding that in practical applications.",
            "However, you have a limited.",
            "In many ways, limited compression algorithm and that limited algorithm is sometimes making a little bit of progress there, and that's the rewarding thing for the other guy.",
            "The other guy who is trying to.",
            "Create the experiments.",
            "The actions that lead to these data such that you get more data that has a property that you still can find some new regularity in it.",
            "So this in terms of wired.",
            "Is."
        ],
        [
            "Easy to define and let's just do it here.",
            "We takes a quantity B here.",
            "As the number of bits or as being proportional to the number of bits that we need to encode the incoming data sequence X, for example.",
            "By the current limited compression algorithm that the observer all has.",
            "At a certain point, T in his life, the observer changes overtime and he is getting smarter all the time.",
            "But at a certain point, has a particular compression method, and that's what he's using to compress and it needs and important is also here.",
            "The Observer is living in an online situation, which means that he has to quickly compress the data as it's coming in.",
            "You can compress the data by for example, predicting it.",
            "Whatever you can predict.",
            "You can compress because you don't have to store it extra if you can predict it and only the things you cannot predict.",
            "That's what you have to store extra to store the entire story.",
            "So.",
            "At every time step.",
            "But in every minute there are only so many instructions that you're limited compression.",
            "Mechanism your brain can execute to do this and and that's the constraint that we have here.",
            "Otherwise, we're just doing standard minimum description length.",
            "Which means we are trying to find a model of the data which consumes a few bits as possible.",
            "So it's very standard what we're doing here we're counting bits, except that we are applying this to possibly the entire history.",
            "A lifelong history which grows all the time.",
            "And and then we have this learning algorithm, which makes it a better compressor which makes all of his compressor better overtime.",
            "A better predictor, better compressor and.",
            "To measure the programs, we just compare the number of bits the B at time T. To the number of bits we need to encode the same data at time T -- 1, and that is the instantaneous intrinsic reward that you get there for the actor, which then is motivated to create new situations, new situations.",
            "New situations which again.",
            "Allow the.",
            "Predictor to improve?",
            "And learn a new role anti about the world.",
            "Now the basic idea is go back 20 years.",
            "And since then, I think I've got about 20 papers on this and it became more formal overtime and totally formal.",
            "It wasn't in 2006, but.",
            "The basic ideas were there 20 years ago.",
            "Let me just.",
            "Write down the theory of creativity in a nutshell.",
            "Using continuous time form."
        ],
        [
            "Nation you have the reward to fund.",
            "At time T, which is the external reward that he gets if you are living in environment and three times a day, you get extremely wide because you're eating something which tastes good or whatever.",
            "That's your external wide standard.",
            "But then there's the intrinsic reward, and in terms of what is where you get as you're looking at the history at the entire history.",
            "Off your life so far.",
            "Some of the things that happened there suddenly become a little clearer.",
            "In other words, become a little bit better explainable or compressible.",
            "And that's where you're making progress.",
            "And sometimes maybe even during sleep you make this progress and you suddenly need fewer bits to encode the same thing than before.",
            "And the first derivative of this compressibility, the first derivative of B of the number of bits you need to encode the data.",
            "With respect to time, that is what you are after.",
            "So the change in the compressibility, the change in the compressibility.",
            "And so the other thing is just against Dan and a certain sense.",
            "Maximize the future expected reward using any of your favorite methods for doing that.",
            "Now this talk is about the objective.",
            "It's not so much about the methods that you use to do this.",
            "To achieve this reward maximization, it's just about the.",
            "The goals that you should build into your creative systems such that they are driven to become artificial."
        ],
        [
            "Scientists and artists.",
            "This once all theory let me give you an example.",
            "The concrete application.",
            "Here we see a low complexity artwork, artwork that I made for you and like all artists has a pattern.",
            "But what's different to most types of traditional art is that you are really forced to show that there is an extremely short computer program that computes it, and in fact there is an extremely short computer program that computes it and and to make you see that this is really true, I'm super imposing a graphical explanation."
        ],
        [
            "And of what's going on here?",
            "So you see, each of the lines in the image is actually.",
            "On one of these circles, it's a segment of one of these circles and its end point and its starting point is also defined by some two other circles which.",
            "Which define the endpoints and which are also.",
            "In principle, easy to encode.",
            "Because I cannot use any arbitrary circle.",
            "Instead, they only very very few legal circles, which I may use, and I'm going to show you."
        ],
        [
            "They come from so he is now a sketch office thing and the blue circles are the only ones that I need to encode this drawing.",
            "So all I need to encode are these Blues blue circles there."
        ],
        [
            "And they are actually just part of this fractal image which was generated."
        ],
        [
            "Let me rotate it for you, which was generated by recursive fractal application of a simple fractal algorithm.",
            "Let me remove the smallest."
        ],
        [
            "Doctor said you better see what's going on now.",
            "Let me remove the circles."
        ],
        [
            "Twice as big and then we've got that, and so finally let me."
        ],
        [
            "Remove everything but the largest circles which define the original pattern.",
            "So let me let me move you backwards so that whenever there is a circle that intersects another circle of a given size, then you can have another circle of half the size."
        ],
        [
            "At the same position with the same center, that's where you get 10, and so you."
        ],
        [
            "Adding more and more cyclists there are few."
        ],
        [
            "Large circles and."
        ],
        [
            "On many smaller circles.",
            "And is the goal now?",
            "At some point the goal of the low complexity artist is to look at this thing and somehow figure out how can you use these lines here too?",
            "And how can you remove most of these lines and just keep a few that correspond to some patterns that make sense that is related to what observers already know about human shapes and so on.",
            "And that is what happened here.",
            "And it takes a long long time because almost nothing looks reasonable.",
            "But then if you work and do 1000 trial."
        ],
        [
            "Else then and get a little bit computer and support them.",
            "Then you can finally come up with with this."
        ],
        [
            "And it's it's."
        ],
        [
            "From this, because your computer scientists is clear that you can encode this drawing here with just a few bits of information with a very short."
        ],
        [
            "Program."
        ],
        [
            "There."
        ],
        [
            "Of course many, many other."
        ],
        [
            "Regular patterns."
        ],
        [
            "You don't have to."
        ],
        [
            "You use these circles here.",
            "For example, most of my slides are also regular because they are constructed by recursive applications of the harmonic proportion, the Golden ratio which some artist claims is preferable over other ratios.",
            "You know, before I came here I thought this is going to be just another easy MLP KDD conference and there won't be much of an audience.",
            "But you are actually a large audience by my standards.",
            "The other day I gave a talk and there was just a single person in the audience.",
            "A young lady I said, young lady, it's very embarrassing, but apparently here today I'm going to give this talk just to you.",
            "And she said, OK, but please hurry, I gotta clean up here."
        ],
        [
            "So what is that about jokes?",
            "How does the authors have to do?",
            "What does this have to do with jokes and humor?",
            "And the answer again is very simple.",
            "Every talk has a little punch line and the punchline is designed to be unexpected to those who don't already know.",
            "The joke.",
            "If you only know the jokes and it is totally boring.",
            "But if you don't know the jokes and there's some, you need extra bits to predict the thing.",
            "So you predict something, but it's not where you predict it, and so you need extra bits to store the stuff that you can't couldn't predict well.",
            "However, all the jobs are designed to.",
            "To have a regularity that relates the punchline back to the previous story in a way that human learning algorithms.",
            "Easily pick out and so immediately the learning algorithm kicks in and recognizes that punchline is related to the rest of the story in a way that allows you to save bits, because all you need to insert there is a pointer to a previous part of the story such that you can again get rid of these extra bits that you didn't know that you didn't expect, and another save bits.",
            "That's the fun that you have.",
            "The number of bits that you are saving.",
            "The first derivative of the compressibility, that is your intrinsic reward.",
            "That's what you are trying to maximize and the action is easy action selector.",
            "The action selector.",
            "Just as the usual thing that all reinforcement learning algorithms do, namely try to.",
            "Generate more data which also has the property that it's fun and so for example, one possible action could be just stay seated and wait.",
            "Weather this comedian has another interesting things to say.",
            "So learning from previous experience to predict which other things in the future might be.",
            "Adding something to your repertoire of novel patterns, which then soon are not novel anymore."
        ],
        [
            "Here we are in Spain and and recently I had the great honor and pleasure to.",
            "To give a scientific talk, very much like this one to the King of Spain himself.",
            "At least he said that he is the King of Spain.",
            "In fact, what he said was if you are a scientist, then I'm the King of Spain.",
            "If you want to build an artificial scientist or an artist.",
            "We have two questions.",
            "What kind of compression algorithm or prediction algorithm do we use and what kind of learning algorithm for this method and the other one is?",
            "What kind of reinforcement learning articles and we used to maximize the intrinsic keyboard signals that we are getting as the other guy is improving, so the rewards maximizer has to be smart enough to deal with the situation where the intrinsic keywords coming from the other system and influenced by the limitations of the learning algorithm of the other system vanish.",
            "Overtime they vanished because obviously as the compressor or predictor is learning about what's going on in the world there.",
            "It is not improving anymore and so where there used to be some intrinsic reward, there is no intrinsic worth no more after some time.",
            "So the reinforcement learner has some some serious tasks."
        ],
        [
            "Boom and the first.",
            "Methods that we use for that were very simple and an all of you probably have some experience with ours in 1991 twenty years ago as a prediction machine we just used.",
            "Neural networks as you as you home.",
            "As you often use them, how many people in this audience use neural networks occasionally?",
            "Hands up.",
            "So maybe 20% or is it actually more like 55?",
            "There's another guy, so it's about 25%.",
            "20 years ago we had this little prediction machine, which as you know, is a compressor.",
            "Every neural networks that predicts the future is also compressor, because whatever you don't predict well, you have to store extra, so it's not good and compressing whatever you predict while you don't have to store extra, so you are compressing the data and what you cannot predict.",
            "Well there you need extra storage space.",
            "Just orange and then see the actor.",
            "Was just a standard Q learning algorithm plus on your network function approximator, and there was an environment you know 20 years ago people always had these little maze environments and there the agents could run around.",
            "And get sometimes extremely bored, but then some parts of this environment were more easily predictable than others and so see him.",
            "Prediction machine like to improve more in certain areas and less in others, which means that there was more intrinsic reward in certain areas.",
            "Whether you wish there was more compression progress or more learning progress and so the system like to go there and then we had examples where sometimes actually helps to speed up external reward because you are, you know, more about the world and sometimes this helps to speed up external reward as well.",
            "20 years ago we did that and and I'm kind of happy that today.",
            "But only recently this has picked up steam and lots of people are starting to get interested in this and build their own little versions of Aquarius."
        ],
        [
            "Seems like this now neural networks can be replaced.",
            "Of course by support vector machines and all kinds of things, but they are under estimated and they're really good.",
            "What happened just a couple of months ago is that we used plain standard plain old backup networks to break the MNIST wild record.",
            "The handwritten digit recognition wild record is anybody in the audience who knows this evidenced data set.",
            "Which that OK. Quite a few of which has a long history of broken record since 1998, when younger can't defined it.",
            "And and you look at these.",
            "These records.",
            "And in the very beginning there were multilayer perceptrons, but then it was always support vector machines or certain special cases of convolutional networks or then combinations of classifiers and support vector machines combined with something and more recently deep networks.",
            "For example by Hinton and Bengio and others who pre train and unsupervised fashion.",
            "These deep networks with which have many layers and then you.",
            "Texas system and and we train it in a supervised fashion to merkwan on the data.",
            "And all of this.",
            "Is not really necessary.",
            "It turns out here are the guys who really did the work that's done.",
            "Cheer is on and William I am.",
            "And down there this is Luke, Gamma, Della my my office neighbor who is mostly working on swarm intelligence and artificial ends and who has papers with thousands and thousands of citations.",
            "Original papers, not even surveys or textbooks which usually get get more citations anyway.",
            "And this new record of oh point 35% on the MNIST data set was achieved without any any fancy tricks or classifier combinations or something.",
            "It was just plain backdrop.",
            "However, it was a deep network.",
            "With seven layers or something and.",
            "It was implemented on graphics cards which are 50 times faster than."
        ],
        [
            "Traditional.",
            "Then CPU is.",
            "And this is a lot related, and one of the reasons why I'm telling you that is because Timothy Budd Pogio gave yesterday this talk about deep hierarchical networks.",
            "But there the individual layers were pre wired or at least very much previous signed which is totally fine because they have the goal is very different.",
            "The goal is to be as close as you can get to the neuroscience models and here we don't really care for.",
            "Imitating neuroscience models, however, of course in the deep layers we also see complex feature detectors in the lower level lower layers we see standard on center, office around and and bar detectors and stuff like that.",
            "So automatically you get.",
            "Of course he is feature detector hierarchies in these networks.",
            "In this particular case there are 12 million weights and and five days on a graphics card unit you can.",
            "Achieve as much as in 200 days on CPU.",
            "And I love these numbers a billion times.",
            "A million wait updates to go through the training set.",
            "And one thing is important, the original training set is way too small for this.",
            "It's only 50,000 digits, so you have to have a method first proposed by the MoD, and we use that to create many many additional training examples out of these original, only 50,000 training digits.",
            "But the important thing is no unsupervised learning, which has become very fashionable recently, is necessary to achieve this best result so far.",
            "One of the reviewers called this a wake up call to the machine learning community."
        ],
        [
            "Now, here's another interesting example of a neural network application feedforward neural network application.",
            "Here we see Alexander Glide faster.",
            "Who is the head of my robot lab in Switzerland?",
            "But in a former life he wants the team leader of the team that won the RoboCop 1 Championship and the Fast League.",
            "And the only League where humans with a joystick cannot win against the best teams.",
            "And each of these little robots are you see, there has a little neural network model on board for each of its Motors.",
            "It can.",
            "It learns to predict what happens if I do this or that.",
            "And then it uses a trick which possibly me.",
            "But maybe somebody else proposed 20 years ago, 20 years ago was a productive time for me.",
            "But you can plan ahead so you plan ahead with by unfolding these predictions in time and do a couple of plan ahead stair steps and then you can still optimize the action sequences using gradient descent or something similar to achieve a desired goal.",
            "Like for example go quickly to the ball, but then breaking times.",
            "Actually don't bump it away or run into an opponent or something like that.",
            "So little things like that you can plan little sub calls like that and it really worked for Alex."
        ],
        [
            "Who is also the first guy who had the same principle to build resilient machines?",
            "Resilient robots?",
            "I'm inserting this slide because on the first day we had to talk about hot lips and and he talked about us.",
            "Some system of 2007 I think.",
            "Where where you had also a model author system which was essentially 3D model.",
            "And then there were 16 different topologies in the search space essentially and you could choose one of them and.",
            "The robot discovered whenever it was harmed that it could not.",
            "That the model predicts something that is different from what happens in reality, and from that you can deduce that something is wrong with your actuators.",
            "One of your actuators is.",
            "Is out of order, and then you can reuse the new model and alternative model to again heal yourself and plan again.",
            "And Alexander was the first who did something like that.",
            "Not using 3D models, but these these newer models where you have.",
            "Is that I think I have a laser pointer here.",
            "Where you where you have a standard driving pattern that is like a clean test drive pattern, But then if you damaged one of these four Motors that you have in the robot then this doesn't work anymore and the model certainly is confronted with weird behavior like that which doesn't match its predictions anymore.",
            "But it can use that then to switch to another model, learn another model and use them that to again optimize the action sequences and get again good behavior."
        ],
        [
            "This was all about feedforward networks, but of course what we're trying to do as we are building creative systems, we are dealing with histories of actions and.",
            "Inputs which get long and longer and something that happens at this point in time may be very much dependent on what happened at this point.",
            "And on this point.",
            "So feedforward networks will not being good at compressing data histories like that.",
            "You have to take something else and one thing you can do and one thing we like to use is recurrent neural networks.",
            "How many people in this room ever used the recurrent neural network for anything?",
            "Love you love you.",
            "And these recurrent neural networks are general computers and the weight matrix of these networks.",
            "Other programs.",
            "And sometimes you hear people making a difference between the functionality of of some system and the parameters of the system, but it's.",
            "Just the same thing and become networks just like the bits in this laptop.",
            "Here are all parts of the functionality and of the para meters in a certain sense, all the weights are in a recurrent network, which is a general computer which can compute anything.",
            "This laptop can compute.",
            "Because this laptop essentially is a recurrent network with a particular activation function for the recurrent units.",
            "There you don't have really this difference between functionality and para meters and what you can do with these recurrent networks is that you can.",
            "Use them as predictors of time series, for example, of histories of actions and.",
            "And send your inputs and you can.",
            "You can.",
            "Compute the difference between what the network is predicting and what really happens, and this is where you want to minimize of course, and then you can compute gradient in algorithm space in program space, essentially because there's a way of changing the weights in the system such that you minimize that you that you find.",
            "That you compute the faster relative of the wish that you have, namely minimize this error with respect to the problem that is running on the recurrent network, which is just as its weight matrix.",
            "So this is very nice.",
            "You have a space of programs and in that space you find an algorithm you find a gradient which leads to a better program.",
            "Now, in the 1990s, the neural networks of this type, the Recon networks they were considered by some exciting and very general, but.",
            "In practical applications, they just didn't scale up well, and it was all toy problems, but this situation has totally changed now has totally changed now and."
        ],
        [
            "Here's just one recent example that is, by the way, that's Alex Graves, who used to be my PhD student, and now a postdoc in Munich.",
            "And he is now beating every other algorithm in connected handwriting recognition.",
            "Connected handwriting recognition is much more difficult than single digit recognition, which we had before a couple of slides ago because there's no teacher who tells you where does.",
            "This individual letter start here and where does it end?",
            "All you have, if you're lucky, you have a set of training sequences and a teacher told you what kind of.",
            "Letter labels this corresponds to, but even the teacher doesn't know is rather letter here is that part of letters that just an accident is, that is that the beginning of some letter or the end of it of another letter, and so on.",
            "But what you can do is what you can do.",
            "Things such as maximize the probability of the probabilities of.",
            "Label sequences which are in this case, for example he oh blank BE blank billing blank TO blank HER and you want to match that somehow to this real valued input stream that you get here and you can maximize the probability of this label sequence given this real valued input stream.",
            "Go over all the training sequences in the set and it turns out that if you do that right, if you use the right type of networks, you must use long short-term memory recurrent networks which don't have all the problems that the original weekend networks have.",
            "In particular, they can deal with really long time lags between irrelevant events, while the traditional recurrent networks cannot do this, and this is enough to now win all the handwriting competitions.",
            "Alex for example, also achieved the best results in.",
            "In an Arabic handwriting recognition contest.",
            "Although he doesn't speak a word of Arabic.",
            "Now you can use these.",
            "These compression machines are these recurrent networks as prediction machines and therefore compression machines.",
            "And.",
            "And it's very natural for such a network.",
            "Then to develop various sets of neurons that always get active when a certain type of sequence spatial temporal sequences active is present, and then store their memory for awhile.",
            "Because if you want to predict the next thing given the previous things, the best thing you can do is encode the stuff that frequently occurs again and again by just a few things.",
            "A few neurons that somehow correspond to a prototype.",
            "A prototype of this object, which is an object, is just something that frequently comes up and so.",
            "Symbols or.",
            "Clearly defined groups of neurons or little compact things that stand for.",
            "Apps that stand for complex input sequences and compactly encode them are just a natural byproduct of compression of this type.",
            "Any weaker network like that there is trying to predict data sequences is compressing all the time and the way it's compressing is use the same units again and again for different but similar input sequences.",
            "So the best thing to do to deal with environments like ours is just invent a couple of prototypes that are.",
            "That reflect what's often reoccuring and then on top of it.",
            "Just add the extra stuff that you need to describe the special instances and that's the way you can save a lot of."
        ],
        [
            "And I never understood this difference between sub symbolic and symbolic, because obviously you get stuff that is very much like symbolic computation, just as a byproduct of these.",
            "Of these training algorithms for recurrent networks, and of course as you are.",
            "Interacting with the world as an agent, that is.",
            "Experiencing all kinds of events, but some of them are related to the sun, goes up every single day and you have to eat three times a day.",
            "And all these things.",
            "There is one thing, of course that is there.",
            "Whenever the agent interacts with the one that's the agent itself, so it's the most natural thing to have a couple of neurons that somehow represent this prototype off the agent itself.",
            "So that would be something like a self symbol, and people are often discussing consciousness and all these things and writing books about it, and it seems to me this is just a very simple byproduct of compression.",
            "It's just efficient to have a couple of neurons dedicated for modeling the things that frequently appear, including."
        ],
        [
            "Yourself, we can take one of these.",
            "We can't neural networks that are modeling probability distributions over our future possible events and learn them, and we can then for each new observation measure how much does.",
            "Um, the knowledge about the world improve.",
            "And all we have to do is to.",
            "Take the probability distribution over the possible new events before and after the new observation.",
            "And there was some learning progress.",
            "Now in 1995 we didn't use these sophisticated recogne networks.",
            "We just had a simple probability estimator based on on counting stuff and counting events and.",
            "And then the the reinforcement learner again was just a standard traditional Markovian assumption based reinforcement learning algorithm.",
            "And all it did was measure the relative entropy between the prize and the posteriors.",
            "In other words, the probability distributions before and after learning before and after learning.",
            "And you can translate that into a number of safe bits.",
            "And the right way of doing that is used.",
            "The callback library diversions and compute the difference between probability distribution before and afterwards, and then you get an intrinsic you want signal, which is then what you want to maximize the expected value of which you want to maximize for the future.",
            "And then ten years later, people are starting to use that in vision to model I movements of humans better than previous models.",
            "Why do you look here and not there?",
            "Because it's more interesting here than there.",
            "Why is it more interesting here than there?",
            "Because here there is something that you don't know yet.",
            "So I'm learning progress that we can achieve well over there.",
            "You know everything already, so that's why you're directing your attention here and not there."
        ],
        [
            "My favorite system.",
            "Maybe my favorite system?",
            "Favorite implementation of the basic principles.",
            "Was from 2002.",
            "And and there actually in.",
            "Bossy compression machine and the.",
            "The actor are collapsed into one thing, but we still have two competing systems.",
            "I call them the left brain and the right brain, but they are not very biological because actually the left brain and the right brain.",
            "I just probabilistic.",
            "Computers and they have a probabilistic universal programming language.",
            "Looks a little bit like generic programming, but it's really different, so you get programs that you can compute based by drawing them that you can generate by drawing them from probability distributions with loops and recursion and everything, and each of these programs is both describing an action sequence and the predicted outcome of the action sequence.",
            "So it's essentially an experiment, plus the prediction about the outcome of the experiment.",
            "And now the left brain says let's do this algorithmic experiment, which is just a. Protocole code, a program.",
            "And I bet that at the end of this program, cell number 15 will have the value of five.",
            "Any computable prediction is modeled can be modeled this way, and the other guy the right prinses.",
            "Let me look at your code.",
            "OK, we can do this, but I predict there will be a different outcome.",
            "And if they disagree, they can bet against each other, and one of them will be right.",
            "And one of them will get this intrinsic reward by just running the experiment.",
            "So once they agree to disagree, they run the experiment.",
            "It's a fixed protocol, and then the outcome is like this, which means that one of them will have will be the winner and one of them will be the surprise loser.",
            "One of them was a better model of what's going on there then the other guy.",
            "And and then the loser has to pay the winner and the intrinsic reward.",
            "Is moving from essentially one guy from the left left brain to the right brain?",
            "And the sum of the intrinsic rewards is always 0, because what the one guy is losing, the other one is gaining.",
            "And each of them is maximally motivated to come up with a new experiment.",
            "That creates data.",
            "And internal states that there's an internal storage where you can compute stuff, including transformations of inputs that we get from the environment.",
            "So each of these guys is motivated to come up with an experiment that the other one finds attractive enough to agree, but once he differs on the outcome.",
            "Prediction and the prediction of the outcome.",
            "So those experiments were both think.",
            "Will lead to the same result.",
            "They are not interesting to any of them because nobody can win their only those where the two programs have different predictions.",
            "You have this.",
            "Incentive to execute the experiment, which cost something every time stepped on something.",
            "So that's how they they increase a repertoire of probabilistic programs, and they're building on the previously learned repertoire and.",
            "I think that lots of things that one can improve with this particular system is in particular you can improve the particular reinforcement learning algorithms that we had back then.",
            "Today there are better ones, but the basic gist of it, I think, is still very relevant and some of you who saw the talk of hot lips and actually will feel reminded of what he did in 2007.",
            "But you also had genetic programming essentially plus a regularizer which enforced shortcodes as opposed to long codes.",
            "And then I think during his talk he said.",
            "The crucial thing was that you had different models for certain parts of the space and then you.",
            "Focused on those where there were different opinions of these models, as opposed to looking at the other parts of the state space where there was no different opinion, so that's very similar in spirit."
        ],
        [
            "That was 2002 and what we are currently doing is we are using just a 3D simulation off the off the I cub robot.",
            "The icon Robot is a baby like robot which has a face like that and there's a stereo camera on top and then we have a 3D simulation of the icon and using the stagger camera you can improve this 3D simulation which you can use as a predictor by just incorporating the stuff that the camera sees here using some vision algorithm.",
            "So should you suddenly get little objects in the environment of this icon and and by adding these objects here, say, simulation becomes more complex, which means you need more bits to describe the simulation.",
            "However, it also becomes more powerful as a predictor, it becomes, it gets more predictive power because suddenly you can, for example, predict that if you move your hands like that, your eyes like that.",
            "Then you will see that there's a little object that is now in there in the simulation, and now again you can use the same principle you look at the number of bits you need to describe the history so far, which is essentially the number of bits you need for all the polygons in the simulation, plus the extra bits you need to encode the deviations off the entire strip.",
            "You would try to learn new motor skills just like a little baby.",
            "We have a little robot baby here, which overtime focuses on, focuses its attention on those pads.",
            "After Wildweb can make learning programs which in the beginning will be very stupid, simple things so it will be a very limited scientist doing just doing very simple experiments as opposed to.",
            "More complex experiments that lead to insights like the general theory of relativity.",
            "However, the principle I think is already, that's all there is the same thing that led to the general theory of relativity.",
            "And the fun that you have in motor in learning motor skills.",
            "That is just um."
        ],
        [
            "Well, yeah, I mean why should anybody?",
            "Why should anybody learn juggling?",
            "It's useless, isn't it?",
            "However, it's fun because it's regular and you'll get a lot of reward just by creating this new regular sequence which is rewarding because it leads to a new type of regular pattern for your compressor, for your prediction machine such that you can certainly save alot of bits because it's it's knew your pattern recognizer which first needs a lot of bits and then shrinks it down.",
            "And that's how you will get.",
            "Progress and we have now this European program project, which is called intrinsically motivated.",
            "Cumulatively learning robots don't ask me who invented the acronym, I'm clever for that, but that's what the name of the project is, and I hope I can keep you updated on the progress of that, so I don't have time to talk about the low complexity you want maximizes themselves.",
            "I don't have time to show you low complexity, we can networks programmed by Universal for year transformation based languages.",
            "I don't even have shine time to show you movies here.",
            "Instead I should instead I should just focus on the take home message to take home messages.",
            "That fun intrinsic you want is the change of the number of bits you need to encode data, novel patterns, and you measure that by looking at how many bits you need before and after learning, and you take the time into account, the time into account that you automatically take into account by having a limited compression machine which is only so good at discovering certain patterns and is not good at discovering other patterns.",
            "Even if there are additional patterns.",
            "And from the rest of it is standard because you still have the standard external reward that you have in addition to the intrinsic reward, and you you have some evolutionary algorithm or reinforcement learning algorithm or other program search techniques for maximizing the future expected reward.",
            "And I believe this applying explains all the essential things that are defining our behavior like attention.",
            "Why do we look here?",
            "I'm not there.",
            "Science in general, which is just a very focused type of attention on various various selective experiments where you can then formally nail down what's happening and you can formally nailed down your compression programs, but also art and music as we were as we talked about."
        ],
        [
            "I wish to thank the organizers for doing a great job and.",
            "And also for the check which I'm going to invest into the education of my kids.",
            "I wish to thank my mom and my dad without whom all of this would not even happy impossible.",
            "And I wish to thank my kids without whom all of this wouldn't even be necessary.",
            "And I wish to thank you, my lovely audience for your patience.",
            "Do we have time for questions or not?",
            "Window question.",
            "I think everything is clear anyway.",
            "I had two reasons for asking a question.",
            "One was to make them run all the way up.",
            "The most serious one is if I if I look at what you say what is fun, it seems to be that if in the end it is something with very low complexity, it's very good.",
            "But then there is another theory of beauty by Pieter Adriaans, who says, Nah, it should not be very compressible.",
            "It should of course not be incompressible.",
            "It should be somewhere half way."
        ],
        [
            "How do you?",
            "Thank you very much for this question.",
            "Does this work here?",
            "Do you still hear me?",
            "That's a very nice question, I think because it relates to the old work of the aesthetic information theorists who in the 1960s and 50s started to look at which patterns are interesting or aesthetically pleasing.",
            "As I called it, and they always pointed out that the low complexity is that's the very simple stuff is not very exciting, not very aesthetically pleasing, just like the extremely complex stuff like randomness and random white noise is not.",
            "Interesting.",
            "And they had the so called wind curve and what you're saying is a special case.",
            "I think of this the one curve which looks like this.",
            "So here you plot the the interesting Ness via static of reward.",
            "And here you plot plot the information content of the object and then you get something like that.",
            "It has a maximum somewhere in between and then lots of people wrote about this but nobody knew what formally defines this maximum and all of this I don't need because what is missing in this I think is.",
            "The essential thing the essential thing which is the first derivative of the number of bits that you are a simulating as you are looking at this piece of art because the compressibility of the of the piece of add or off the object is irrelevant for the interestingness of the objects.",
            "The only thing that counts is the first derivative relative to your own subjective compression method as you.",
            "As the number of bits are shrinking that you need to encode the object, that's where your internal reward comes from, and that's why some objects are interesting to some observer but not to others observers.",
            "So any theory of aesthetic.",
            "Judgment and pleasure has to take into account this objective observer and what's pleasing to one is not pleasing to the other, But the reason is clear.",
            "From this theory.",
            "It is because you have different compressors and different different prior knowledge.",
            "In these different observers and it's a dynamic thing because what used to be interesting ones.",
            "Becomes boring overtime and this is all contained in this new theory as opposed to the old information theorists.",
            "Also let me add something.",
            "There is a theory of humor which also is always based on unexpectedness, so you why is something funny?",
            "Well because it's unexpected and that usually stops.",
            "And what's missing that is that you measure.",
            "The progress that you achieve through learning through a learning algorithm which takes the unexpected thing and make something which is rather uncompressible because it's so unexpected and then quickly sees hey it's much more compressible than I thought and there you save the bits.",
            "So the first derivative of the number of bits you need to encode.",
            "That's the crucial thing.",
            "It's not the compressibility itself, it's the dynamic process that leads to less bits before and after learning.",
            "Long after the derivatives gone to zero, yeah.",
            "But how many times is it 100 times or only five times?",
            "Because I have my my appeared is roughly like 567 times I hear new song which I really like and 1st I think hey there's something interesting and then I want to hear it again and then usually at the third time or something, my my interest peaks, because then I'm starting to figure out what kind of new chords which I didn't know in this form are being used.",
            "And then it goes down again after 100 times.",
            "I can't hear no more.",
            "However, I'm motivated to get another song from the same artist, for example.",
            "Which leads them to new patterns which are related to the old ones, because all these artists they have similar styles but still have something new.",
            "Then why after seeing 1000 reproductions of Mona Lisa, would I still go to louver to see the original thing?",
            "Why do they go and see the Mona Lisa?",
            "Although you can simply look it up on search engines and everything.",
            "Because of course if you go there, you really get a different pattern.",
            "What you get is this exciting situation where there's a crowd of 100 people and they're all trying to get a glimpse and you.",
            "So it's really a novel pattern that you get there going to the Louvre itself is really different in terms of sensory experience and also action sequences that you have to execute to get the sequence of sensory experiences.",
            "Then just typing into Google, Mona Lisa and looking at the images.",
            "That's the reason why I'm doing it.",
            "Is it possible to damage this mechanism because?",
            "That's probably something like cultural arrogance, but I'm under the impression that a lot of people are seeking out actively stuff that is.",
            "Of very low difference to what they know already and it doesn't really matter what it is, whether it's hard or movies or just food that basically they want to stick to the stuff they already know, not get too far from.",
            "So, is it possible that with food I think one has to be careful because it's so much related to externally while you have to get food three times a day and then you don't want to?",
            "Never eat food that makes you feel unwell so you better keep the probability.",
            "Low by rally eating stuff that you don't know you know.",
            "You have replied by citing Mona Lisa.",
            "I would like to cite Mozart.",
            "There is something that sermons call or form.",
            "And this is some piece of music Mozart has made.",
            "Many of the sort which you would and you are enjoying listening to again and again.",
            "Although in a certain sense it is really boring.",
            "Can you elaborate a bit on that?",
            "Yeah.",
            "So I guess again the difference is.",
            "If you listen to any artwork in any piece of music, there are two things you can do, at least two things.",
            "There's so many things you can do, but one is take exactly the same recording and listen to it again and again, and again and very few people I know do that more than 10 times in a row.",
            "However, listening to the same piece of music interpreted by different artists, that is something very unusual because every artist has his own interpretation and creates little additional patterns on top of the of the basic pattern of the basic melody and the basic arrangement, etc.",
            "There is so much freedom in interpretation that many of these interpretations are just very attractive.",
            "Just because of these differences to the other interpretations of the other artists.",
            "And it's also a very different from singing yourself this thing, because there you get really again a different sensory perception based on your own voice.",
            "Maybe you never sang those were warm this year one.",
            "I don't even know where the English word for that.",
            "Again and again while you are starting to do this while you're learning to sing it, you get a lot of progress because this particular pattern, which is coming out of your own mouth and is similar to those that you heard only by qualified Singer so far, is a new pattern and you can work on improving it and you can make it better and so you are motivated to to do that for awhile.",
            "So what about transition between intrinsic and extrinsic rewards when some intrinsic reward becomes external and some external reward becomes internal?",
            "This is a pretty common occurrence in physiological and evolutionary processes.",
            "When anticipation of a word later on.",
            "Actually causes the hormonal spike earlier in earlier and that's how they explained, for example, gambling addictions.",
            "So this transition and feedback between external and internal and changes from one through the other than partially could explain this comfort we find in familiar.",
            "Yeah, So what you are describing is, I think, just the effect that you have in any reinforcement learning algorithm.",
            "Weather is delayed reward.",
            "So at some point you have reward and then this reward is transformed by even Q.",
            "Learning is doing that, but many other more sophisticated.",
            "Possibly doing algorithms are doing the same thing so that you get the credit assignment.",
            "Two things that happened earlier which are causally related to this we want, and so you just get the standard way of propagating these predicted rewards back into time.",
            "Search that you get all kinds of associations with things that you did earlier which are then causative, or at least to a certain extent predicted for the future reward.",
            "So there's no problem at all with this.",
            "This is just a standard.",
            "Product off the reinforcement of a standard reinforcement learning algorithm that you are using to optimize the the action sequence leading to the reward.",
            "And then it becomes necessity just like food.",
            "Yeah, so food is food is so in the language now I'm using here.",
            "Maybe it's not the same as some people in your science.",
            "I found out I have to be so careful when I'm talking to neuro scientist because they're using Safari reinforcement for a different thing.",
            "They say even if my predictor improves here and this means that some of the weights get stronger, they say the waves get reinforced.",
            "This confuses hell out of me because the predictor is just a method is just as justice.",
            "A traditional learning algorithm which just improves it using gradient descent or something like that.",
            "While the reinforcement business that is for the reward maximizer.",
            "So I'm now always trying to actually off, and I'm trying to avoid the word reinforcement.",
            "Just say there are the.",
            "The the adaptation mechanisms in the prediction machine, which often is called habituation, habitation in neuroscience, and then there's the reward maximizing business for the guy who is selecting the actions.",
            "So instead of using stuff like using words like reinforcement I'm using now.",
            "Reward maximization and.",
            "I'm using habituation for what's happening in the prediction machine, and suddenly then I can start talking to neuro scientists and neuropsychologists.",
            "So we have a terminology problem, but.",
            "It's all just terminology I found.",
            "Thank you for a fascinating talk.",
            "I was wondering whether you could link the 1 / F noise or pink noise and Bierhoff Thierry with with your theory about the one everybody.",
            "So back off is one of these guys who found it.",
            "This information theoretic view of pleasure.",
            "And I think in 1931 he was pretty much the first he had.",
            "This you looked at objects and try to come up with the complexity measure of pictures of objects based on simple primitives etc.",
            "And then lots of people built on that and then, especially in the 60s there were people like do we mention them here?",
            "Yeah, more less.",
            "Moles are more than friends and then bends Anne Frank and knock.",
            "And frankly these were all in Germany.",
            "Whether you have the full field called information aesthetics.",
            "And all trying to build on each other and I think what was missing in all of these approaches.",
            "I'm still talking to people like nothing was.",
            "The missing thing was this concept of dynamic changed relative to the given observer, who is using a learning algorithm to improve the number of bits you need to encode the data and this first derivative of the compressibility that wasn't really there and that makes all the difference.",
            "That's it, and that's so I'm not talking about the compressibility itself.",
            "There are lots of patterns that are compressible.",
            "I'm talking about the change of the compressibility, and this is what you have to.",
            "Take into account and ephemera it goes away quickly because once you have it, you have learned on this thing.",
            "You need a new thing which becomes interesting because the old thing has become boring, so that's so different."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Three prisoners were sentence to death.",
                    "label": 0
                },
                {
                    "sent": "One of them friends, one of them.",
                    "label": 0
                },
                {
                    "sent": "German, one of them Spanish.",
                    "label": 0
                },
                {
                    "sent": "What is your last wish?",
                    "label": 0
                },
                {
                    "sent": "They ask the French guy, he says.",
                    "label": 0
                },
                {
                    "sent": "A bottle of exquisite a French wine was last wish.",
                    "label": 0
                },
                {
                    "sent": "They asked the German guy, he says.",
                    "label": 0
                },
                {
                    "sent": "I want to give a speech.",
                    "label": 0
                },
                {
                    "sent": "What is your last wish?",
                    "label": 0
                },
                {
                    "sent": "They ask the Spanish guy, he says.",
                    "label": 0
                },
                {
                    "sent": "I want to get shot before the German starts this speech.",
                    "label": 0
                },
                {
                    "sent": "Unfortunately for you guys, it is too late now because I'm in the middle of my little speech already.",
                    "label": 0
                },
                {
                    "sent": "And it's about the formal theory of fun and creativity.",
                    "label": 1
                },
                {
                    "sent": "This is my name.",
                    "label": 0
                },
                {
                    "sent": "This is to help Michelle pronounce my name.",
                    "label": 0
                },
                {
                    "sent": "And ask you.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "He mentioned I'm spending most of my time at the Swiss AI lab.",
                    "label": 0
                },
                {
                    "sent": "It's yeah, but I also.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Of a research group at the Tech University Munich focusing on robot learning.",
                    "label": 0
                },
                {
                    "sent": "See it's here.",
                    "label": 0
                },
                {
                    "sent": "By the way, is affiliated with the University of Lugano and Subsea.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Traditional reinforcement learning.",
                    "label": 0
                },
                {
                    "sent": "Is about Asians that interact with the world and then there is a reward function which you are supposed to optimize and the wild is unknown and everything is clear because usually it goes like this.",
                    "label": 0
                },
                {
                    "sent": "There's a robot and it bumps against an obstacle and then it feels pain which is just a negative number or it reaches a goal which is given by the external teacher.",
                    "label": 0
                },
                {
                    "sent": "And it gets a positive reward and the sum of these negative and positive rewards should be as high as possible.",
                    "label": 0
                },
                {
                    "sent": "So the reinforcement learning algorithm is trying to maximize the future expected reward at that time.",
                    "label": 0
                },
                {
                    "sent": "So that is just traditional standard reinforcement learning and found many, many methods for that.",
                    "label": 1
                },
                {
                    "sent": "But with humans there's this additional thing, apparently.",
                    "label": 0
                },
                {
                    "sent": "You also get reward for.",
                    "label": 0
                },
                {
                    "sent": "Listening to music.",
                    "label": 0
                },
                {
                    "sent": "Why?",
                    "label": 0
                },
                {
                    "sent": "That's what does that have with what does that have to do with problem solving?",
                    "label": 0
                },
                {
                    "sent": "Or going to the museum or going to a place like this?",
                    "label": 0
                },
                {
                    "sent": "Which in many ways is a statically pleasing.",
                    "label": 0
                },
                {
                    "sent": "But what does it mean to be pleasing?",
                    "label": 0
                },
                {
                    "sent": "What kind of internal reward is that that you get there?",
                    "label": 0
                },
                {
                    "sent": "And can we make that formal?",
                    "label": 0
                },
                {
                    "sent": "And is there may be a reason for that external reward?",
                    "label": 1
                },
                {
                    "sent": "And can we implement that stuff on robots set such that they become better robots?",
                    "label": 0
                },
                {
                    "sent": "That's what I'm going to talk about and the basic idea is extremely simple.",
                    "label": 0
                },
                {
                    "sent": "I believe that and I want to convince you that this intrinsic reward is the thing that is driving all these fundamental human activities such as sinzan.",
                    "label": 1
                },
                {
                    "sent": "Art and comedy and whatever and and the only thing that is important.",
                    "label": 0
                },
                {
                    "sent": "The thing that is defining the intrinsic reward is the creation or discovery of novel patterns.",
                    "label": 0
                },
                {
                    "sent": "Novel patterns.",
                    "label": 0
                },
                {
                    "sent": "Now this is sounds just like an informal stuff.",
                    "label": 0
                },
                {
                    "sent": "So to make this formal we have to add.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So two questions.",
                    "label": 0
                },
                {
                    "sent": "The first question is, what exactly is a pattern and?",
                    "label": 1
                },
                {
                    "sent": "When is it novel as opposed to already known?",
                    "label": 1
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And computer science has the answer.",
                    "label": 0
                },
                {
                    "sent": "It knows what is a pattern, any set of raw data has a pattern.",
                    "label": 0
                },
                {
                    "sent": "If you can describe it by a computer program that is significantly shorter than the raw data itself.",
                    "label": 0
                },
                {
                    "sent": "Then it's compressible.",
                    "label": 0
                },
                {
                    "sent": "Any symmetry, any regularity, can be expressed in this way?",
                    "label": 0
                },
                {
                    "sent": "So anything that is regular has a program that is shorter than the original data itself, so we know where the pattern is.",
                    "label": 0
                },
                {
                    "sent": "For example, here we have a piece of broccoli which is fractal, which means that.",
                    "label": 0
                },
                {
                    "sent": "The program that computes the outline of the broccoli can also be reused again to compute all these little details.",
                    "label": 0
                },
                {
                    "sent": "Offer broccoli because it's self similar and so a very short piece of code computes the entire broccoli.",
                    "label": 0
                },
                {
                    "sent": "So that is one of a million examples of regular patterns.",
                    "label": 0
                },
                {
                    "sent": "But there are many, many patterns which are already known and which are uninteresting and not rewarding because you already know them.",
                    "label": 0
                },
                {
                    "sent": "What is a novel pattern and how can I measure how novel it is and how rewarding it is?",
                    "label": 0
                },
                {
                    "sent": "To deal with it.",
                    "label": 0
                },
                {
                    "sent": "And the answer is the compression algorithm that you are using as you are encoding.",
                    "label": 0
                },
                {
                    "sent": "Parts of the input stream.",
                    "label": 0
                },
                {
                    "sent": "Is not.",
                    "label": 0
                },
                {
                    "sent": "Constant, it's not the same compression algorithm.",
                    "label": 0
                },
                {
                    "sent": "All the time, but it improves through learning, so there's a learning algorithm which is working on it, and in this way it becomes a better compressor, better encoder of the data, and then for any data you can just compare how many bits did I need to encode this data before learning.",
                    "label": 0
                },
                {
                    "sent": "And how many bits do I need afterwards?",
                    "label": 0
                },
                {
                    "sent": "If there is a normal regularity, then afterwards I needed fewer bits.",
                    "label": 0
                },
                {
                    "sent": "Which means I made compression progress or learning progress, and that's the crucial thing.",
                    "label": 0
                },
                {
                    "sent": "He is 3 bits that you just saved.",
                    "label": 0
                },
                {
                    "sent": "That is your intrinsic keyboard.",
                    "label": 0
                },
                {
                    "sent": "That is your learning progress.",
                    "label": 0
                },
                {
                    "sent": "And that's why you want to maximize as an actor who is selecting the data which you are trying to compress or to explain to analyze.",
                    "label": 0
                },
                {
                    "sent": "And that's it.",
                    "label": 0
                },
                {
                    "sent": "That's what my talk is about, and it's extremely simple.",
                    "label": 0
                },
                {
                    "sent": "The principle is extremely simple.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And the the only devil is occasionally is somewhere in the detail.",
                    "label": 0
                },
                {
                    "sent": "Let me explain how that explains physics.",
                    "label": 0
                },
                {
                    "sent": "As a physicist, you are motivated to create experiments that lead to data.",
                    "label": 0
                },
                {
                    "sent": "That follow a previously unknown law, not a known law which you already can easily compress.",
                    "label": 1
                },
                {
                    "sent": "But some pattern where you still have to work on what exactly is the pattern.",
                    "label": 0
                },
                {
                    "sent": "And once you find the pattern you will suddenly can greatly compress the history, for example 10.",
                    "label": 0
                },
                {
                    "sent": "Apples are falling to the ground, and they're all falling in the same way.",
                    "label": 0
                },
                {
                    "sent": "And if you don't know the law of gravity but suddenly discover it, then you can use this very short code that.",
                    "label": 0
                },
                {
                    "sent": "That embodies the law of gravity to greatly compress the video of the 10 falling apples, because the same orange blob is always going down the same way, there are many details that you cannot explain by this by this simpler, However, you can still greatly compress because there is at least something in the video that is really regular and explainable by a short law in music.",
                    "label": 0
                },
                {
                    "sent": "It's just the same thing as a composer.",
                    "label": 0
                },
                {
                    "sent": "You are motivated to create.",
                    "label": 0
                },
                {
                    "sent": "Newer sound streams that don't sound like the already known run of the mill rock and roll songs, but weather is a new harmony, something that is unusual but still regular so it's nonrandom, non arbitrary.",
                    "label": 0
                },
                {
                    "sent": "It's regular, but in a way that was known before.",
                    "label": 1
                },
                {
                    "sent": "So music is all about finding novel patterns.",
                    "label": 0
                },
                {
                    "sent": "As an artist, you are trying to create these novel novel patterns.",
                    "label": 0
                },
                {
                    "sent": "As an observer.",
                    "label": 0
                },
                {
                    "sent": "You're listening to them, and you know once you listen to a certain song 100 times in a row.",
                    "label": 0
                },
                {
                    "sent": "It's not interesting anymore, but your actor, the action selector, which says, for example, select the next song from the same composer, maybe is trying to maximize the future expected reward by taking the stuff that he learned so far.",
                    "label": 0
                },
                {
                    "sent": "For example this composer.",
                    "label": 0
                },
                {
                    "sent": "Is writing pleasing songs and add something to the knowledge that you already have from this way, so adding novel patterns to your repertoire.",
                    "label": 0
                },
                {
                    "sent": "And as you are building this repertoire, you also building the action repertoire which you need to construct these.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Patterns.",
                    "label": 0
                },
                {
                    "sent": "The same in the visual arts.",
                    "label": 0
                },
                {
                    "sent": "Visual arts is about novel patterns, just like music and like science.",
                    "label": 1
                },
                {
                    "sent": "Barcelona is full of novel patterns for tourists, at least those who already know them every day.",
                    "label": 0
                },
                {
                    "sent": "They are less interested in them than the tourists who.",
                    "label": 0
                },
                {
                    "sent": "Always stand there in front of the saga Amelia and crowd the place because there are lots of regular things going on there and they are interesting.",
                    "label": 0
                },
                {
                    "sent": "There's interesting Ness.",
                    "label": 0
                },
                {
                    "sent": "We want intrinsic reward internal reward for seeing these patterns that are novel.",
                    "label": 0
                },
                {
                    "sent": "As long as you haven't assimilated.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I'm yet to build a creative system.",
                    "label": 0
                },
                {
                    "sent": "We therefore need only two learning modules.",
                    "label": 1
                },
                {
                    "sent": "We need.",
                    "label": 0
                },
                {
                    "sent": "First of all, the compressor said takes the incoming data stream and compresses it, but then there's a learning algorithm on top of it such that overtime, as the history is growing, it gets more and more training examples which it can use to become a better compressor such that the raw data is like that.",
                    "label": 0
                },
                {
                    "sent": "The compressed version of it is like that.",
                    "label": 1
                },
                {
                    "sent": "And then maybe overnight, the learning algorithm is running and then the new compressed version of the data is like that and that you will save 3 bits and that's the exciting thing.",
                    "label": 0
                },
                {
                    "sent": "That's the progress you will never in general achieve a situation where you where you go all the way down to the Kolmogorov McConnell graph complexity of the data history, which is essentially the length of the shortest program that computes the entire data.",
                    "label": 0
                },
                {
                    "sent": "And there's no way of finding that in practical applications.",
                    "label": 0
                },
                {
                    "sent": "However, you have a limited.",
                    "label": 0
                },
                {
                    "sent": "In many ways, limited compression algorithm and that limited algorithm is sometimes making a little bit of progress there, and that's the rewarding thing for the other guy.",
                    "label": 0
                },
                {
                    "sent": "The other guy who is trying to.",
                    "label": 0
                },
                {
                    "sent": "Create the experiments.",
                    "label": 0
                },
                {
                    "sent": "The actions that lead to these data such that you get more data that has a property that you still can find some new regularity in it.",
                    "label": 0
                },
                {
                    "sent": "So this in terms of wired.",
                    "label": 0
                },
                {
                    "sent": "Is.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Easy to define and let's just do it here.",
                    "label": 0
                },
                {
                    "sent": "We takes a quantity B here.",
                    "label": 0
                },
                {
                    "sent": "As the number of bits or as being proportional to the number of bits that we need to encode the incoming data sequence X, for example.",
                    "label": 0
                },
                {
                    "sent": "By the current limited compression algorithm that the observer all has.",
                    "label": 0
                },
                {
                    "sent": "At a certain point, T in his life, the observer changes overtime and he is getting smarter all the time.",
                    "label": 0
                },
                {
                    "sent": "But at a certain point, has a particular compression method, and that's what he's using to compress and it needs and important is also here.",
                    "label": 0
                },
                {
                    "sent": "The Observer is living in an online situation, which means that he has to quickly compress the data as it's coming in.",
                    "label": 0
                },
                {
                    "sent": "You can compress the data by for example, predicting it.",
                    "label": 0
                },
                {
                    "sent": "Whatever you can predict.",
                    "label": 0
                },
                {
                    "sent": "You can compress because you don't have to store it extra if you can predict it and only the things you cannot predict.",
                    "label": 0
                },
                {
                    "sent": "That's what you have to store extra to store the entire story.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "At every time step.",
                    "label": 0
                },
                {
                    "sent": "But in every minute there are only so many instructions that you're limited compression.",
                    "label": 0
                },
                {
                    "sent": "Mechanism your brain can execute to do this and and that's the constraint that we have here.",
                    "label": 0
                },
                {
                    "sent": "Otherwise, we're just doing standard minimum description length.",
                    "label": 0
                },
                {
                    "sent": "Which means we are trying to find a model of the data which consumes a few bits as possible.",
                    "label": 0
                },
                {
                    "sent": "So it's very standard what we're doing here we're counting bits, except that we are applying this to possibly the entire history.",
                    "label": 0
                },
                {
                    "sent": "A lifelong history which grows all the time.",
                    "label": 0
                },
                {
                    "sent": "And and then we have this learning algorithm, which makes it a better compressor which makes all of his compressor better overtime.",
                    "label": 0
                },
                {
                    "sent": "A better predictor, better compressor and.",
                    "label": 0
                },
                {
                    "sent": "To measure the programs, we just compare the number of bits the B at time T. To the number of bits we need to encode the same data at time T -- 1, and that is the instantaneous intrinsic reward that you get there for the actor, which then is motivated to create new situations, new situations.",
                    "label": 0
                },
                {
                    "sent": "New situations which again.",
                    "label": 0
                },
                {
                    "sent": "Allow the.",
                    "label": 0
                },
                {
                    "sent": "Predictor to improve?",
                    "label": 0
                },
                {
                    "sent": "And learn a new role anti about the world.",
                    "label": 0
                },
                {
                    "sent": "Now the basic idea is go back 20 years.",
                    "label": 0
                },
                {
                    "sent": "And since then, I think I've got about 20 papers on this and it became more formal overtime and totally formal.",
                    "label": 0
                },
                {
                    "sent": "It wasn't in 2006, but.",
                    "label": 0
                },
                {
                    "sent": "The basic ideas were there 20 years ago.",
                    "label": 0
                },
                {
                    "sent": "Let me just.",
                    "label": 0
                },
                {
                    "sent": "Write down the theory of creativity in a nutshell.",
                    "label": 0
                },
                {
                    "sent": "Using continuous time form.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Nation you have the reward to fund.",
                    "label": 0
                },
                {
                    "sent": "At time T, which is the external reward that he gets if you are living in environment and three times a day, you get extremely wide because you're eating something which tastes good or whatever.",
                    "label": 1
                },
                {
                    "sent": "That's your external wide standard.",
                    "label": 0
                },
                {
                    "sent": "But then there's the intrinsic reward, and in terms of what is where you get as you're looking at the history at the entire history.",
                    "label": 0
                },
                {
                    "sent": "Off your life so far.",
                    "label": 0
                },
                {
                    "sent": "Some of the things that happened there suddenly become a little clearer.",
                    "label": 0
                },
                {
                    "sent": "In other words, become a little bit better explainable or compressible.",
                    "label": 0
                },
                {
                    "sent": "And that's where you're making progress.",
                    "label": 0
                },
                {
                    "sent": "And sometimes maybe even during sleep you make this progress and you suddenly need fewer bits to encode the same thing than before.",
                    "label": 0
                },
                {
                    "sent": "And the first derivative of this compressibility, the first derivative of B of the number of bits you need to encode the data.",
                    "label": 0
                },
                {
                    "sent": "With respect to time, that is what you are after.",
                    "label": 0
                },
                {
                    "sent": "So the change in the compressibility, the change in the compressibility.",
                    "label": 0
                },
                {
                    "sent": "And so the other thing is just against Dan and a certain sense.",
                    "label": 0
                },
                {
                    "sent": "Maximize the future expected reward using any of your favorite methods for doing that.",
                    "label": 0
                },
                {
                    "sent": "Now this talk is about the objective.",
                    "label": 0
                },
                {
                    "sent": "It's not so much about the methods that you use to do this.",
                    "label": 0
                },
                {
                    "sent": "To achieve this reward maximization, it's just about the.",
                    "label": 0
                },
                {
                    "sent": "The goals that you should build into your creative systems such that they are driven to become artificial.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Scientists and artists.",
                    "label": 0
                },
                {
                    "sent": "This once all theory let me give you an example.",
                    "label": 0
                },
                {
                    "sent": "The concrete application.",
                    "label": 0
                },
                {
                    "sent": "Here we see a low complexity artwork, artwork that I made for you and like all artists has a pattern.",
                    "label": 1
                },
                {
                    "sent": "But what's different to most types of traditional art is that you are really forced to show that there is an extremely short computer program that computes it, and in fact there is an extremely short computer program that computes it and and to make you see that this is really true, I'm super imposing a graphical explanation.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And of what's going on here?",
                    "label": 0
                },
                {
                    "sent": "So you see, each of the lines in the image is actually.",
                    "label": 0
                },
                {
                    "sent": "On one of these circles, it's a segment of one of these circles and its end point and its starting point is also defined by some two other circles which.",
                    "label": 0
                },
                {
                    "sent": "Which define the endpoints and which are also.",
                    "label": 0
                },
                {
                    "sent": "In principle, easy to encode.",
                    "label": 0
                },
                {
                    "sent": "Because I cannot use any arbitrary circle.",
                    "label": 0
                },
                {
                    "sent": "Instead, they only very very few legal circles, which I may use, and I'm going to show you.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "They come from so he is now a sketch office thing and the blue circles are the only ones that I need to encode this drawing.",
                    "label": 0
                },
                {
                    "sent": "So all I need to encode are these Blues blue circles there.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And they are actually just part of this fractal image which was generated.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Let me rotate it for you, which was generated by recursive fractal application of a simple fractal algorithm.",
                    "label": 0
                },
                {
                    "sent": "Let me remove the smallest.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Doctor said you better see what's going on now.",
                    "label": 0
                },
                {
                    "sent": "Let me remove the circles.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Twice as big and then we've got that, and so finally let me.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Remove everything but the largest circles which define the original pattern.",
                    "label": 0
                },
                {
                    "sent": "So let me let me move you backwards so that whenever there is a circle that intersects another circle of a given size, then you can have another circle of half the size.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "At the same position with the same center, that's where you get 10, and so you.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Adding more and more cyclists there are few.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Large circles and.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "On many smaller circles.",
                    "label": 0
                },
                {
                    "sent": "And is the goal now?",
                    "label": 0
                },
                {
                    "sent": "At some point the goal of the low complexity artist is to look at this thing and somehow figure out how can you use these lines here too?",
                    "label": 0
                },
                {
                    "sent": "And how can you remove most of these lines and just keep a few that correspond to some patterns that make sense that is related to what observers already know about human shapes and so on.",
                    "label": 0
                },
                {
                    "sent": "And that is what happened here.",
                    "label": 0
                },
                {
                    "sent": "And it takes a long long time because almost nothing looks reasonable.",
                    "label": 0
                },
                {
                    "sent": "But then if you work and do 1000 trial.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Else then and get a little bit computer and support them.",
                    "label": 0
                },
                {
                    "sent": "Then you can finally come up with with this.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And it's it's.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "From this, because your computer scientists is clear that you can encode this drawing here with just a few bits of information with a very short.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Program.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "There.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Of course many, many other.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Regular patterns.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You don't have to.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "You use these circles here.",
                    "label": 0
                },
                {
                    "sent": "For example, most of my slides are also regular because they are constructed by recursive applications of the harmonic proportion, the Golden ratio which some artist claims is preferable over other ratios.",
                    "label": 1
                },
                {
                    "sent": "You know, before I came here I thought this is going to be just another easy MLP KDD conference and there won't be much of an audience.",
                    "label": 0
                },
                {
                    "sent": "But you are actually a large audience by my standards.",
                    "label": 0
                },
                {
                    "sent": "The other day I gave a talk and there was just a single person in the audience.",
                    "label": 0
                },
                {
                    "sent": "A young lady I said, young lady, it's very embarrassing, but apparently here today I'm going to give this talk just to you.",
                    "label": 0
                },
                {
                    "sent": "And she said, OK, but please hurry, I gotta clean up here.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So what is that about jokes?",
                    "label": 0
                },
                {
                    "sent": "How does the authors have to do?",
                    "label": 0
                },
                {
                    "sent": "What does this have to do with jokes and humor?",
                    "label": 0
                },
                {
                    "sent": "And the answer again is very simple.",
                    "label": 0
                },
                {
                    "sent": "Every talk has a little punch line and the punchline is designed to be unexpected to those who don't already know.",
                    "label": 0
                },
                {
                    "sent": "The joke.",
                    "label": 0
                },
                {
                    "sent": "If you only know the jokes and it is totally boring.",
                    "label": 0
                },
                {
                    "sent": "But if you don't know the jokes and there's some, you need extra bits to predict the thing.",
                    "label": 0
                },
                {
                    "sent": "So you predict something, but it's not where you predict it, and so you need extra bits to store the stuff that you can't couldn't predict well.",
                    "label": 0
                },
                {
                    "sent": "However, all the jobs are designed to.",
                    "label": 0
                },
                {
                    "sent": "To have a regularity that relates the punchline back to the previous story in a way that human learning algorithms.",
                    "label": 0
                },
                {
                    "sent": "Easily pick out and so immediately the learning algorithm kicks in and recognizes that punchline is related to the rest of the story in a way that allows you to save bits, because all you need to insert there is a pointer to a previous part of the story such that you can again get rid of these extra bits that you didn't know that you didn't expect, and another save bits.",
                    "label": 0
                },
                {
                    "sent": "That's the fun that you have.",
                    "label": 0
                },
                {
                    "sent": "The number of bits that you are saving.",
                    "label": 0
                },
                {
                    "sent": "The first derivative of the compressibility, that is your intrinsic reward.",
                    "label": 0
                },
                {
                    "sent": "That's what you are trying to maximize and the action is easy action selector.",
                    "label": 0
                },
                {
                    "sent": "The action selector.",
                    "label": 0
                },
                {
                    "sent": "Just as the usual thing that all reinforcement learning algorithms do, namely try to.",
                    "label": 0
                },
                {
                    "sent": "Generate more data which also has the property that it's fun and so for example, one possible action could be just stay seated and wait.",
                    "label": 0
                },
                {
                    "sent": "Weather this comedian has another interesting things to say.",
                    "label": 0
                },
                {
                    "sent": "So learning from previous experience to predict which other things in the future might be.",
                    "label": 0
                },
                {
                    "sent": "Adding something to your repertoire of novel patterns, which then soon are not novel anymore.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Here we are in Spain and and recently I had the great honor and pleasure to.",
                    "label": 0
                },
                {
                    "sent": "To give a scientific talk, very much like this one to the King of Spain himself.",
                    "label": 0
                },
                {
                    "sent": "At least he said that he is the King of Spain.",
                    "label": 0
                },
                {
                    "sent": "In fact, what he said was if you are a scientist, then I'm the King of Spain.",
                    "label": 0
                },
                {
                    "sent": "If you want to build an artificial scientist or an artist.",
                    "label": 0
                },
                {
                    "sent": "We have two questions.",
                    "label": 0
                },
                {
                    "sent": "What kind of compression algorithm or prediction algorithm do we use and what kind of learning algorithm for this method and the other one is?",
                    "label": 0
                },
                {
                    "sent": "What kind of reinforcement learning articles and we used to maximize the intrinsic keyboard signals that we are getting as the other guy is improving, so the rewards maximizer has to be smart enough to deal with the situation where the intrinsic keywords coming from the other system and influenced by the limitations of the learning algorithm of the other system vanish.",
                    "label": 0
                },
                {
                    "sent": "Overtime they vanished because obviously as the compressor or predictor is learning about what's going on in the world there.",
                    "label": 0
                },
                {
                    "sent": "It is not improving anymore and so where there used to be some intrinsic reward, there is no intrinsic worth no more after some time.",
                    "label": 0
                },
                {
                    "sent": "So the reinforcement learner has some some serious tasks.",
                    "label": 1
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Boom and the first.",
                    "label": 0
                },
                {
                    "sent": "Methods that we use for that were very simple and an all of you probably have some experience with ours in 1991 twenty years ago as a prediction machine we just used.",
                    "label": 0
                },
                {
                    "sent": "Neural networks as you as you home.",
                    "label": 0
                },
                {
                    "sent": "As you often use them, how many people in this audience use neural networks occasionally?",
                    "label": 0
                },
                {
                    "sent": "Hands up.",
                    "label": 0
                },
                {
                    "sent": "So maybe 20% or is it actually more like 55?",
                    "label": 0
                },
                {
                    "sent": "There's another guy, so it's about 25%.",
                    "label": 0
                },
                {
                    "sent": "20 years ago we had this little prediction machine, which as you know, is a compressor.",
                    "label": 0
                },
                {
                    "sent": "Every neural networks that predicts the future is also compressor, because whatever you don't predict well, you have to store extra, so it's not good and compressing whatever you predict while you don't have to store extra, so you are compressing the data and what you cannot predict.",
                    "label": 0
                },
                {
                    "sent": "Well there you need extra storage space.",
                    "label": 0
                },
                {
                    "sent": "Just orange and then see the actor.",
                    "label": 0
                },
                {
                    "sent": "Was just a standard Q learning algorithm plus on your network function approximator, and there was an environment you know 20 years ago people always had these little maze environments and there the agents could run around.",
                    "label": 0
                },
                {
                    "sent": "And get sometimes extremely bored, but then some parts of this environment were more easily predictable than others and so see him.",
                    "label": 0
                },
                {
                    "sent": "Prediction machine like to improve more in certain areas and less in others, which means that there was more intrinsic reward in certain areas.",
                    "label": 0
                },
                {
                    "sent": "Whether you wish there was more compression progress or more learning progress and so the system like to go there and then we had examples where sometimes actually helps to speed up external reward because you are, you know, more about the world and sometimes this helps to speed up external reward as well.",
                    "label": 0
                },
                {
                    "sent": "20 years ago we did that and and I'm kind of happy that today.",
                    "label": 0
                },
                {
                    "sent": "But only recently this has picked up steam and lots of people are starting to get interested in this and build their own little versions of Aquarius.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Seems like this now neural networks can be replaced.",
                    "label": 0
                },
                {
                    "sent": "Of course by support vector machines and all kinds of things, but they are under estimated and they're really good.",
                    "label": 0
                },
                {
                    "sent": "What happened just a couple of months ago is that we used plain standard plain old backup networks to break the MNIST wild record.",
                    "label": 0
                },
                {
                    "sent": "The handwritten digit recognition wild record is anybody in the audience who knows this evidenced data set.",
                    "label": 1
                },
                {
                    "sent": "Which that OK. Quite a few of which has a long history of broken record since 1998, when younger can't defined it.",
                    "label": 0
                },
                {
                    "sent": "And and you look at these.",
                    "label": 0
                },
                {
                    "sent": "These records.",
                    "label": 0
                },
                {
                    "sent": "And in the very beginning there were multilayer perceptrons, but then it was always support vector machines or certain special cases of convolutional networks or then combinations of classifiers and support vector machines combined with something and more recently deep networks.",
                    "label": 0
                },
                {
                    "sent": "For example by Hinton and Bengio and others who pre train and unsupervised fashion.",
                    "label": 0
                },
                {
                    "sent": "These deep networks with which have many layers and then you.",
                    "label": 0
                },
                {
                    "sent": "Texas system and and we train it in a supervised fashion to merkwan on the data.",
                    "label": 0
                },
                {
                    "sent": "And all of this.",
                    "label": 0
                },
                {
                    "sent": "Is not really necessary.",
                    "label": 0
                },
                {
                    "sent": "It turns out here are the guys who really did the work that's done.",
                    "label": 0
                },
                {
                    "sent": "Cheer is on and William I am.",
                    "label": 0
                },
                {
                    "sent": "And down there this is Luke, Gamma, Della my my office neighbor who is mostly working on swarm intelligence and artificial ends and who has papers with thousands and thousands of citations.",
                    "label": 0
                },
                {
                    "sent": "Original papers, not even surveys or textbooks which usually get get more citations anyway.",
                    "label": 0
                },
                {
                    "sent": "And this new record of oh point 35% on the MNIST data set was achieved without any any fancy tricks or classifier combinations or something.",
                    "label": 0
                },
                {
                    "sent": "It was just plain backdrop.",
                    "label": 0
                },
                {
                    "sent": "However, it was a deep network.",
                    "label": 0
                },
                {
                    "sent": "With seven layers or something and.",
                    "label": 0
                },
                {
                    "sent": "It was implemented on graphics cards which are 50 times faster than.",
                    "label": 1
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Traditional.",
                    "label": 0
                },
                {
                    "sent": "Then CPU is.",
                    "label": 0
                },
                {
                    "sent": "And this is a lot related, and one of the reasons why I'm telling you that is because Timothy Budd Pogio gave yesterday this talk about deep hierarchical networks.",
                    "label": 0
                },
                {
                    "sent": "But there the individual layers were pre wired or at least very much previous signed which is totally fine because they have the goal is very different.",
                    "label": 0
                },
                {
                    "sent": "The goal is to be as close as you can get to the neuroscience models and here we don't really care for.",
                    "label": 0
                },
                {
                    "sent": "Imitating neuroscience models, however, of course in the deep layers we also see complex feature detectors in the lower level lower layers we see standard on center, office around and and bar detectors and stuff like that.",
                    "label": 0
                },
                {
                    "sent": "So automatically you get.",
                    "label": 0
                },
                {
                    "sent": "Of course he is feature detector hierarchies in these networks.",
                    "label": 0
                },
                {
                    "sent": "In this particular case there are 12 million weights and and five days on a graphics card unit you can.",
                    "label": 0
                },
                {
                    "sent": "Achieve as much as in 200 days on CPU.",
                    "label": 1
                },
                {
                    "sent": "And I love these numbers a billion times.",
                    "label": 0
                },
                {
                    "sent": "A million wait updates to go through the training set.",
                    "label": 0
                },
                {
                    "sent": "And one thing is important, the original training set is way too small for this.",
                    "label": 0
                },
                {
                    "sent": "It's only 50,000 digits, so you have to have a method first proposed by the MoD, and we use that to create many many additional training examples out of these original, only 50,000 training digits.",
                    "label": 0
                },
                {
                    "sent": "But the important thing is no unsupervised learning, which has become very fashionable recently, is necessary to achieve this best result so far.",
                    "label": 0
                },
                {
                    "sent": "One of the reviewers called this a wake up call to the machine learning community.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now, here's another interesting example of a neural network application feedforward neural network application.",
                    "label": 0
                },
                {
                    "sent": "Here we see Alexander Glide faster.",
                    "label": 0
                },
                {
                    "sent": "Who is the head of my robot lab in Switzerland?",
                    "label": 0
                },
                {
                    "sent": "But in a former life he wants the team leader of the team that won the RoboCop 1 Championship and the Fast League.",
                    "label": 1
                },
                {
                    "sent": "And the only League where humans with a joystick cannot win against the best teams.",
                    "label": 0
                },
                {
                    "sent": "And each of these little robots are you see, there has a little neural network model on board for each of its Motors.",
                    "label": 0
                },
                {
                    "sent": "It can.",
                    "label": 0
                },
                {
                    "sent": "It learns to predict what happens if I do this or that.",
                    "label": 0
                },
                {
                    "sent": "And then it uses a trick which possibly me.",
                    "label": 0
                },
                {
                    "sent": "But maybe somebody else proposed 20 years ago, 20 years ago was a productive time for me.",
                    "label": 0
                },
                {
                    "sent": "But you can plan ahead so you plan ahead with by unfolding these predictions in time and do a couple of plan ahead stair steps and then you can still optimize the action sequences using gradient descent or something similar to achieve a desired goal.",
                    "label": 0
                },
                {
                    "sent": "Like for example go quickly to the ball, but then breaking times.",
                    "label": 0
                },
                {
                    "sent": "Actually don't bump it away or run into an opponent or something like that.",
                    "label": 0
                },
                {
                    "sent": "So little things like that you can plan little sub calls like that and it really worked for Alex.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Who is also the first guy who had the same principle to build resilient machines?",
                    "label": 0
                },
                {
                    "sent": "Resilient robots?",
                    "label": 0
                },
                {
                    "sent": "I'm inserting this slide because on the first day we had to talk about hot lips and and he talked about us.",
                    "label": 0
                },
                {
                    "sent": "Some system of 2007 I think.",
                    "label": 0
                },
                {
                    "sent": "Where where you had also a model author system which was essentially 3D model.",
                    "label": 0
                },
                {
                    "sent": "And then there were 16 different topologies in the search space essentially and you could choose one of them and.",
                    "label": 0
                },
                {
                    "sent": "The robot discovered whenever it was harmed that it could not.",
                    "label": 0
                },
                {
                    "sent": "That the model predicts something that is different from what happens in reality, and from that you can deduce that something is wrong with your actuators.",
                    "label": 0
                },
                {
                    "sent": "One of your actuators is.",
                    "label": 0
                },
                {
                    "sent": "Is out of order, and then you can reuse the new model and alternative model to again heal yourself and plan again.",
                    "label": 0
                },
                {
                    "sent": "And Alexander was the first who did something like that.",
                    "label": 0
                },
                {
                    "sent": "Not using 3D models, but these these newer models where you have.",
                    "label": 0
                },
                {
                    "sent": "Is that I think I have a laser pointer here.",
                    "label": 0
                },
                {
                    "sent": "Where you where you have a standard driving pattern that is like a clean test drive pattern, But then if you damaged one of these four Motors that you have in the robot then this doesn't work anymore and the model certainly is confronted with weird behavior like that which doesn't match its predictions anymore.",
                    "label": 0
                },
                {
                    "sent": "But it can use that then to switch to another model, learn another model and use them that to again optimize the action sequences and get again good behavior.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This was all about feedforward networks, but of course what we're trying to do as we are building creative systems, we are dealing with histories of actions and.",
                    "label": 0
                },
                {
                    "sent": "Inputs which get long and longer and something that happens at this point in time may be very much dependent on what happened at this point.",
                    "label": 0
                },
                {
                    "sent": "And on this point.",
                    "label": 0
                },
                {
                    "sent": "So feedforward networks will not being good at compressing data histories like that.",
                    "label": 0
                },
                {
                    "sent": "You have to take something else and one thing you can do and one thing we like to use is recurrent neural networks.",
                    "label": 0
                },
                {
                    "sent": "How many people in this room ever used the recurrent neural network for anything?",
                    "label": 0
                },
                {
                    "sent": "Love you love you.",
                    "label": 0
                },
                {
                    "sent": "And these recurrent neural networks are general computers and the weight matrix of these networks.",
                    "label": 0
                },
                {
                    "sent": "Other programs.",
                    "label": 0
                },
                {
                    "sent": "And sometimes you hear people making a difference between the functionality of of some system and the parameters of the system, but it's.",
                    "label": 0
                },
                {
                    "sent": "Just the same thing and become networks just like the bits in this laptop.",
                    "label": 0
                },
                {
                    "sent": "Here are all parts of the functionality and of the para meters in a certain sense, all the weights are in a recurrent network, which is a general computer which can compute anything.",
                    "label": 0
                },
                {
                    "sent": "This laptop can compute.",
                    "label": 0
                },
                {
                    "sent": "Because this laptop essentially is a recurrent network with a particular activation function for the recurrent units.",
                    "label": 0
                },
                {
                    "sent": "There you don't have really this difference between functionality and para meters and what you can do with these recurrent networks is that you can.",
                    "label": 0
                },
                {
                    "sent": "Use them as predictors of time series, for example, of histories of actions and.",
                    "label": 0
                },
                {
                    "sent": "And send your inputs and you can.",
                    "label": 0
                },
                {
                    "sent": "You can.",
                    "label": 0
                },
                {
                    "sent": "Compute the difference between what the network is predicting and what really happens, and this is where you want to minimize of course, and then you can compute gradient in algorithm space in program space, essentially because there's a way of changing the weights in the system such that you minimize that you that you find.",
                    "label": 0
                },
                {
                    "sent": "That you compute the faster relative of the wish that you have, namely minimize this error with respect to the problem that is running on the recurrent network, which is just as its weight matrix.",
                    "label": 0
                },
                {
                    "sent": "So this is very nice.",
                    "label": 0
                },
                {
                    "sent": "You have a space of programs and in that space you find an algorithm you find a gradient which leads to a better program.",
                    "label": 0
                },
                {
                    "sent": "Now, in the 1990s, the neural networks of this type, the Recon networks they were considered by some exciting and very general, but.",
                    "label": 0
                },
                {
                    "sent": "In practical applications, they just didn't scale up well, and it was all toy problems, but this situation has totally changed now has totally changed now and.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Here's just one recent example that is, by the way, that's Alex Graves, who used to be my PhD student, and now a postdoc in Munich.",
                    "label": 0
                },
                {
                    "sent": "And he is now beating every other algorithm in connected handwriting recognition.",
                    "label": 0
                },
                {
                    "sent": "Connected handwriting recognition is much more difficult than single digit recognition, which we had before a couple of slides ago because there's no teacher who tells you where does.",
                    "label": 1
                },
                {
                    "sent": "This individual letter start here and where does it end?",
                    "label": 0
                },
                {
                    "sent": "All you have, if you're lucky, you have a set of training sequences and a teacher told you what kind of.",
                    "label": 0
                },
                {
                    "sent": "Letter labels this corresponds to, but even the teacher doesn't know is rather letter here is that part of letters that just an accident is, that is that the beginning of some letter or the end of it of another letter, and so on.",
                    "label": 0
                },
                {
                    "sent": "But what you can do is what you can do.",
                    "label": 0
                },
                {
                    "sent": "Things such as maximize the probability of the probabilities of.",
                    "label": 1
                },
                {
                    "sent": "Label sequences which are in this case, for example he oh blank BE blank billing blank TO blank HER and you want to match that somehow to this real valued input stream that you get here and you can maximize the probability of this label sequence given this real valued input stream.",
                    "label": 0
                },
                {
                    "sent": "Go over all the training sequences in the set and it turns out that if you do that right, if you use the right type of networks, you must use long short-term memory recurrent networks which don't have all the problems that the original weekend networks have.",
                    "label": 0
                },
                {
                    "sent": "In particular, they can deal with really long time lags between irrelevant events, while the traditional recurrent networks cannot do this, and this is enough to now win all the handwriting competitions.",
                    "label": 0
                },
                {
                    "sent": "Alex for example, also achieved the best results in.",
                    "label": 0
                },
                {
                    "sent": "In an Arabic handwriting recognition contest.",
                    "label": 0
                },
                {
                    "sent": "Although he doesn't speak a word of Arabic.",
                    "label": 0
                },
                {
                    "sent": "Now you can use these.",
                    "label": 0
                },
                {
                    "sent": "These compression machines are these recurrent networks as prediction machines and therefore compression machines.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "And it's very natural for such a network.",
                    "label": 0
                },
                {
                    "sent": "Then to develop various sets of neurons that always get active when a certain type of sequence spatial temporal sequences active is present, and then store their memory for awhile.",
                    "label": 0
                },
                {
                    "sent": "Because if you want to predict the next thing given the previous things, the best thing you can do is encode the stuff that frequently occurs again and again by just a few things.",
                    "label": 0
                },
                {
                    "sent": "A few neurons that somehow correspond to a prototype.",
                    "label": 0
                },
                {
                    "sent": "A prototype of this object, which is an object, is just something that frequently comes up and so.",
                    "label": 0
                },
                {
                    "sent": "Symbols or.",
                    "label": 0
                },
                {
                    "sent": "Clearly defined groups of neurons or little compact things that stand for.",
                    "label": 0
                },
                {
                    "sent": "Apps that stand for complex input sequences and compactly encode them are just a natural byproduct of compression of this type.",
                    "label": 0
                },
                {
                    "sent": "Any weaker network like that there is trying to predict data sequences is compressing all the time and the way it's compressing is use the same units again and again for different but similar input sequences.",
                    "label": 0
                },
                {
                    "sent": "So the best thing to do to deal with environments like ours is just invent a couple of prototypes that are.",
                    "label": 0
                },
                {
                    "sent": "That reflect what's often reoccuring and then on top of it.",
                    "label": 0
                },
                {
                    "sent": "Just add the extra stuff that you need to describe the special instances and that's the way you can save a lot of.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And I never understood this difference between sub symbolic and symbolic, because obviously you get stuff that is very much like symbolic computation, just as a byproduct of these.",
                    "label": 0
                },
                {
                    "sent": "Of these training algorithms for recurrent networks, and of course as you are.",
                    "label": 0
                },
                {
                    "sent": "Interacting with the world as an agent, that is.",
                    "label": 0
                },
                {
                    "sent": "Experiencing all kinds of events, but some of them are related to the sun, goes up every single day and you have to eat three times a day.",
                    "label": 0
                },
                {
                    "sent": "And all these things.",
                    "label": 0
                },
                {
                    "sent": "There is one thing, of course that is there.",
                    "label": 1
                },
                {
                    "sent": "Whenever the agent interacts with the one that's the agent itself, so it's the most natural thing to have a couple of neurons that somehow represent this prototype off the agent itself.",
                    "label": 1
                },
                {
                    "sent": "So that would be something like a self symbol, and people are often discussing consciousness and all these things and writing books about it, and it seems to me this is just a very simple byproduct of compression.",
                    "label": 0
                },
                {
                    "sent": "It's just efficient to have a couple of neurons dedicated for modeling the things that frequently appear, including.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Yourself, we can take one of these.",
                    "label": 0
                },
                {
                    "sent": "We can't neural networks that are modeling probability distributions over our future possible events and learn them, and we can then for each new observation measure how much does.",
                    "label": 0
                },
                {
                    "sent": "Um, the knowledge about the world improve.",
                    "label": 0
                },
                {
                    "sent": "And all we have to do is to.",
                    "label": 0
                },
                {
                    "sent": "Take the probability distribution over the possible new events before and after the new observation.",
                    "label": 0
                },
                {
                    "sent": "And there was some learning progress.",
                    "label": 0
                },
                {
                    "sent": "Now in 1995 we didn't use these sophisticated recogne networks.",
                    "label": 0
                },
                {
                    "sent": "We just had a simple probability estimator based on on counting stuff and counting events and.",
                    "label": 1
                },
                {
                    "sent": "And then the the reinforcement learner again was just a standard traditional Markovian assumption based reinforcement learning algorithm.",
                    "label": 0
                },
                {
                    "sent": "And all it did was measure the relative entropy between the prize and the posteriors.",
                    "label": 1
                },
                {
                    "sent": "In other words, the probability distributions before and after learning before and after learning.",
                    "label": 0
                },
                {
                    "sent": "And you can translate that into a number of safe bits.",
                    "label": 0
                },
                {
                    "sent": "And the right way of doing that is used.",
                    "label": 0
                },
                {
                    "sent": "The callback library diversions and compute the difference between probability distribution before and afterwards, and then you get an intrinsic you want signal, which is then what you want to maximize the expected value of which you want to maximize for the future.",
                    "label": 0
                },
                {
                    "sent": "And then ten years later, people are starting to use that in vision to model I movements of humans better than previous models.",
                    "label": 0
                },
                {
                    "sent": "Why do you look here and not there?",
                    "label": 0
                },
                {
                    "sent": "Because it's more interesting here than there.",
                    "label": 0
                },
                {
                    "sent": "Why is it more interesting here than there?",
                    "label": 0
                },
                {
                    "sent": "Because here there is something that you don't know yet.",
                    "label": 0
                },
                {
                    "sent": "So I'm learning progress that we can achieve well over there.",
                    "label": 0
                },
                {
                    "sent": "You know everything already, so that's why you're directing your attention here and not there.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "My favorite system.",
                    "label": 0
                },
                {
                    "sent": "Maybe my favorite system?",
                    "label": 0
                },
                {
                    "sent": "Favorite implementation of the basic principles.",
                    "label": 0
                },
                {
                    "sent": "Was from 2002.",
                    "label": 0
                },
                {
                    "sent": "And and there actually in.",
                    "label": 0
                },
                {
                    "sent": "Bossy compression machine and the.",
                    "label": 0
                },
                {
                    "sent": "The actor are collapsed into one thing, but we still have two competing systems.",
                    "label": 0
                },
                {
                    "sent": "I call them the left brain and the right brain, but they are not very biological because actually the left brain and the right brain.",
                    "label": 1
                },
                {
                    "sent": "I just probabilistic.",
                    "label": 0
                },
                {
                    "sent": "Computers and they have a probabilistic universal programming language.",
                    "label": 0
                },
                {
                    "sent": "Looks a little bit like generic programming, but it's really different, so you get programs that you can compute based by drawing them that you can generate by drawing them from probability distributions with loops and recursion and everything, and each of these programs is both describing an action sequence and the predicted outcome of the action sequence.",
                    "label": 1
                },
                {
                    "sent": "So it's essentially an experiment, plus the prediction about the outcome of the experiment.",
                    "label": 0
                },
                {
                    "sent": "And now the left brain says let's do this algorithmic experiment, which is just a. Protocole code, a program.",
                    "label": 0
                },
                {
                    "sent": "And I bet that at the end of this program, cell number 15 will have the value of five.",
                    "label": 1
                },
                {
                    "sent": "Any computable prediction is modeled can be modeled this way, and the other guy the right prinses.",
                    "label": 0
                },
                {
                    "sent": "Let me look at your code.",
                    "label": 0
                },
                {
                    "sent": "OK, we can do this, but I predict there will be a different outcome.",
                    "label": 0
                },
                {
                    "sent": "And if they disagree, they can bet against each other, and one of them will be right.",
                    "label": 0
                },
                {
                    "sent": "And one of them will get this intrinsic reward by just running the experiment.",
                    "label": 0
                },
                {
                    "sent": "So once they agree to disagree, they run the experiment.",
                    "label": 0
                },
                {
                    "sent": "It's a fixed protocol, and then the outcome is like this, which means that one of them will have will be the winner and one of them will be the surprise loser.",
                    "label": 0
                },
                {
                    "sent": "One of them was a better model of what's going on there then the other guy.",
                    "label": 0
                },
                {
                    "sent": "And and then the loser has to pay the winner and the intrinsic reward.",
                    "label": 0
                },
                {
                    "sent": "Is moving from essentially one guy from the left left brain to the right brain?",
                    "label": 0
                },
                {
                    "sent": "And the sum of the intrinsic rewards is always 0, because what the one guy is losing, the other one is gaining.",
                    "label": 0
                },
                {
                    "sent": "And each of them is maximally motivated to come up with a new experiment.",
                    "label": 0
                },
                {
                    "sent": "That creates data.",
                    "label": 0
                },
                {
                    "sent": "And internal states that there's an internal storage where you can compute stuff, including transformations of inputs that we get from the environment.",
                    "label": 0
                },
                {
                    "sent": "So each of these guys is motivated to come up with an experiment that the other one finds attractive enough to agree, but once he differs on the outcome.",
                    "label": 0
                },
                {
                    "sent": "Prediction and the prediction of the outcome.",
                    "label": 0
                },
                {
                    "sent": "So those experiments were both think.",
                    "label": 0
                },
                {
                    "sent": "Will lead to the same result.",
                    "label": 0
                },
                {
                    "sent": "They are not interesting to any of them because nobody can win their only those where the two programs have different predictions.",
                    "label": 0
                },
                {
                    "sent": "You have this.",
                    "label": 0
                },
                {
                    "sent": "Incentive to execute the experiment, which cost something every time stepped on something.",
                    "label": 0
                },
                {
                    "sent": "So that's how they they increase a repertoire of probabilistic programs, and they're building on the previously learned repertoire and.",
                    "label": 0
                },
                {
                    "sent": "I think that lots of things that one can improve with this particular system is in particular you can improve the particular reinforcement learning algorithms that we had back then.",
                    "label": 0
                },
                {
                    "sent": "Today there are better ones, but the basic gist of it, I think, is still very relevant and some of you who saw the talk of hot lips and actually will feel reminded of what he did in 2007.",
                    "label": 0
                },
                {
                    "sent": "But you also had genetic programming essentially plus a regularizer which enforced shortcodes as opposed to long codes.",
                    "label": 0
                },
                {
                    "sent": "And then I think during his talk he said.",
                    "label": 0
                },
                {
                    "sent": "The crucial thing was that you had different models for certain parts of the space and then you.",
                    "label": 0
                },
                {
                    "sent": "Focused on those where there were different opinions of these models, as opposed to looking at the other parts of the state space where there was no different opinion, so that's very similar in spirit.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "That was 2002 and what we are currently doing is we are using just a 3D simulation off the off the I cub robot.",
                    "label": 0
                },
                {
                    "sent": "The icon Robot is a baby like robot which has a face like that and there's a stereo camera on top and then we have a 3D simulation of the icon and using the stagger camera you can improve this 3D simulation which you can use as a predictor by just incorporating the stuff that the camera sees here using some vision algorithm.",
                    "label": 0
                },
                {
                    "sent": "So should you suddenly get little objects in the environment of this icon and and by adding these objects here, say, simulation becomes more complex, which means you need more bits to describe the simulation.",
                    "label": 0
                },
                {
                    "sent": "However, it also becomes more powerful as a predictor, it becomes, it gets more predictive power because suddenly you can, for example, predict that if you move your hands like that, your eyes like that.",
                    "label": 0
                },
                {
                    "sent": "Then you will see that there's a little object that is now in there in the simulation, and now again you can use the same principle you look at the number of bits you need to describe the history so far, which is essentially the number of bits you need for all the polygons in the simulation, plus the extra bits you need to encode the deviations off the entire strip.",
                    "label": 0
                },
                {
                    "sent": "You would try to learn new motor skills just like a little baby.",
                    "label": 0
                },
                {
                    "sent": "We have a little robot baby here, which overtime focuses on, focuses its attention on those pads.",
                    "label": 0
                },
                {
                    "sent": "After Wildweb can make learning programs which in the beginning will be very stupid, simple things so it will be a very limited scientist doing just doing very simple experiments as opposed to.",
                    "label": 0
                },
                {
                    "sent": "More complex experiments that lead to insights like the general theory of relativity.",
                    "label": 0
                },
                {
                    "sent": "However, the principle I think is already, that's all there is the same thing that led to the general theory of relativity.",
                    "label": 0
                },
                {
                    "sent": "And the fun that you have in motor in learning motor skills.",
                    "label": 1
                },
                {
                    "sent": "That is just um.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Well, yeah, I mean why should anybody?",
                    "label": 0
                },
                {
                    "sent": "Why should anybody learn juggling?",
                    "label": 0
                },
                {
                    "sent": "It's useless, isn't it?",
                    "label": 0
                },
                {
                    "sent": "However, it's fun because it's regular and you'll get a lot of reward just by creating this new regular sequence which is rewarding because it leads to a new type of regular pattern for your compressor, for your prediction machine such that you can certainly save alot of bits because it's it's knew your pattern recognizer which first needs a lot of bits and then shrinks it down.",
                    "label": 0
                },
                {
                    "sent": "And that's how you will get.",
                    "label": 0
                },
                {
                    "sent": "Progress and we have now this European program project, which is called intrinsically motivated.",
                    "label": 1
                },
                {
                    "sent": "Cumulatively learning robots don't ask me who invented the acronym, I'm clever for that, but that's what the name of the project is, and I hope I can keep you updated on the progress of that, so I don't have time to talk about the low complexity you want maximizes themselves.",
                    "label": 0
                },
                {
                    "sent": "I don't have time to show you low complexity, we can networks programmed by Universal for year transformation based languages.",
                    "label": 0
                },
                {
                    "sent": "I don't even have shine time to show you movies here.",
                    "label": 0
                },
                {
                    "sent": "Instead I should instead I should just focus on the take home message to take home messages.",
                    "label": 0
                },
                {
                    "sent": "That fun intrinsic you want is the change of the number of bits you need to encode data, novel patterns, and you measure that by looking at how many bits you need before and after learning, and you take the time into account, the time into account that you automatically take into account by having a limited compression machine which is only so good at discovering certain patterns and is not good at discovering other patterns.",
                    "label": 0
                },
                {
                    "sent": "Even if there are additional patterns.",
                    "label": 0
                },
                {
                    "sent": "And from the rest of it is standard because you still have the standard external reward that you have in addition to the intrinsic reward, and you you have some evolutionary algorithm or reinforcement learning algorithm or other program search techniques for maximizing the future expected reward.",
                    "label": 0
                },
                {
                    "sent": "And I believe this applying explains all the essential things that are defining our behavior like attention.",
                    "label": 0
                },
                {
                    "sent": "Why do we look here?",
                    "label": 0
                },
                {
                    "sent": "I'm not there.",
                    "label": 0
                },
                {
                    "sent": "Science in general, which is just a very focused type of attention on various various selective experiments where you can then formally nail down what's happening and you can formally nailed down your compression programs, but also art and music as we were as we talked about.",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I wish to thank the organizers for doing a great job and.",
                    "label": 0
                },
                {
                    "sent": "And also for the check which I'm going to invest into the education of my kids.",
                    "label": 0
                },
                {
                    "sent": "I wish to thank my mom and my dad without whom all of this would not even happy impossible.",
                    "label": 0
                },
                {
                    "sent": "And I wish to thank my kids without whom all of this wouldn't even be necessary.",
                    "label": 0
                },
                {
                    "sent": "And I wish to thank you, my lovely audience for your patience.",
                    "label": 0
                },
                {
                    "sent": "Do we have time for questions or not?",
                    "label": 0
                },
                {
                    "sent": "Window question.",
                    "label": 0
                },
                {
                    "sent": "I think everything is clear anyway.",
                    "label": 0
                },
                {
                    "sent": "I had two reasons for asking a question.",
                    "label": 0
                },
                {
                    "sent": "One was to make them run all the way up.",
                    "label": 0
                },
                {
                    "sent": "The most serious one is if I if I look at what you say what is fun, it seems to be that if in the end it is something with very low complexity, it's very good.",
                    "label": 0
                },
                {
                    "sent": "But then there is another theory of beauty by Pieter Adriaans, who says, Nah, it should not be very compressible.",
                    "label": 0
                },
                {
                    "sent": "It should of course not be incompressible.",
                    "label": 0
                },
                {
                    "sent": "It should be somewhere half way.",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "How do you?",
                    "label": 0
                },
                {
                    "sent": "Thank you very much for this question.",
                    "label": 0
                },
                {
                    "sent": "Does this work here?",
                    "label": 0
                },
                {
                    "sent": "Do you still hear me?",
                    "label": 0
                },
                {
                    "sent": "That's a very nice question, I think because it relates to the old work of the aesthetic information theorists who in the 1960s and 50s started to look at which patterns are interesting or aesthetically pleasing.",
                    "label": 0
                },
                {
                    "sent": "As I called it, and they always pointed out that the low complexity is that's the very simple stuff is not very exciting, not very aesthetically pleasing, just like the extremely complex stuff like randomness and random white noise is not.",
                    "label": 0
                },
                {
                    "sent": "Interesting.",
                    "label": 0
                },
                {
                    "sent": "And they had the so called wind curve and what you're saying is a special case.",
                    "label": 0
                },
                {
                    "sent": "I think of this the one curve which looks like this.",
                    "label": 0
                },
                {
                    "sent": "So here you plot the the interesting Ness via static of reward.",
                    "label": 0
                },
                {
                    "sent": "And here you plot plot the information content of the object and then you get something like that.",
                    "label": 0
                },
                {
                    "sent": "It has a maximum somewhere in between and then lots of people wrote about this but nobody knew what formally defines this maximum and all of this I don't need because what is missing in this I think is.",
                    "label": 0
                },
                {
                    "sent": "The essential thing the essential thing which is the first derivative of the number of bits that you are a simulating as you are looking at this piece of art because the compressibility of the of the piece of add or off the object is irrelevant for the interestingness of the objects.",
                    "label": 0
                },
                {
                    "sent": "The only thing that counts is the first derivative relative to your own subjective compression method as you.",
                    "label": 0
                },
                {
                    "sent": "As the number of bits are shrinking that you need to encode the object, that's where your internal reward comes from, and that's why some objects are interesting to some observer but not to others observers.",
                    "label": 0
                },
                {
                    "sent": "So any theory of aesthetic.",
                    "label": 0
                },
                {
                    "sent": "Judgment and pleasure has to take into account this objective observer and what's pleasing to one is not pleasing to the other, But the reason is clear.",
                    "label": 0
                },
                {
                    "sent": "From this theory.",
                    "label": 0
                },
                {
                    "sent": "It is because you have different compressors and different different prior knowledge.",
                    "label": 0
                },
                {
                    "sent": "In these different observers and it's a dynamic thing because what used to be interesting ones.",
                    "label": 0
                },
                {
                    "sent": "Becomes boring overtime and this is all contained in this new theory as opposed to the old information theorists.",
                    "label": 0
                },
                {
                    "sent": "Also let me add something.",
                    "label": 0
                },
                {
                    "sent": "There is a theory of humor which also is always based on unexpectedness, so you why is something funny?",
                    "label": 0
                },
                {
                    "sent": "Well because it's unexpected and that usually stops.",
                    "label": 0
                },
                {
                    "sent": "And what's missing that is that you measure.",
                    "label": 0
                },
                {
                    "sent": "The progress that you achieve through learning through a learning algorithm which takes the unexpected thing and make something which is rather uncompressible because it's so unexpected and then quickly sees hey it's much more compressible than I thought and there you save the bits.",
                    "label": 0
                },
                {
                    "sent": "So the first derivative of the number of bits you need to encode.",
                    "label": 0
                },
                {
                    "sent": "That's the crucial thing.",
                    "label": 0
                },
                {
                    "sent": "It's not the compressibility itself, it's the dynamic process that leads to less bits before and after learning.",
                    "label": 0
                },
                {
                    "sent": "Long after the derivatives gone to zero, yeah.",
                    "label": 0
                },
                {
                    "sent": "But how many times is it 100 times or only five times?",
                    "label": 0
                },
                {
                    "sent": "Because I have my my appeared is roughly like 567 times I hear new song which I really like and 1st I think hey there's something interesting and then I want to hear it again and then usually at the third time or something, my my interest peaks, because then I'm starting to figure out what kind of new chords which I didn't know in this form are being used.",
                    "label": 0
                },
                {
                    "sent": "And then it goes down again after 100 times.",
                    "label": 0
                },
                {
                    "sent": "I can't hear no more.",
                    "label": 0
                },
                {
                    "sent": "However, I'm motivated to get another song from the same artist, for example.",
                    "label": 0
                },
                {
                    "sent": "Which leads them to new patterns which are related to the old ones, because all these artists they have similar styles but still have something new.",
                    "label": 0
                },
                {
                    "sent": "Then why after seeing 1000 reproductions of Mona Lisa, would I still go to louver to see the original thing?",
                    "label": 0
                },
                {
                    "sent": "Why do they go and see the Mona Lisa?",
                    "label": 0
                },
                {
                    "sent": "Although you can simply look it up on search engines and everything.",
                    "label": 0
                },
                {
                    "sent": "Because of course if you go there, you really get a different pattern.",
                    "label": 0
                },
                {
                    "sent": "What you get is this exciting situation where there's a crowd of 100 people and they're all trying to get a glimpse and you.",
                    "label": 0
                },
                {
                    "sent": "So it's really a novel pattern that you get there going to the Louvre itself is really different in terms of sensory experience and also action sequences that you have to execute to get the sequence of sensory experiences.",
                    "label": 0
                },
                {
                    "sent": "Then just typing into Google, Mona Lisa and looking at the images.",
                    "label": 0
                },
                {
                    "sent": "That's the reason why I'm doing it.",
                    "label": 0
                },
                {
                    "sent": "Is it possible to damage this mechanism because?",
                    "label": 0
                },
                {
                    "sent": "That's probably something like cultural arrogance, but I'm under the impression that a lot of people are seeking out actively stuff that is.",
                    "label": 0
                },
                {
                    "sent": "Of very low difference to what they know already and it doesn't really matter what it is, whether it's hard or movies or just food that basically they want to stick to the stuff they already know, not get too far from.",
                    "label": 0
                },
                {
                    "sent": "So, is it possible that with food I think one has to be careful because it's so much related to externally while you have to get food three times a day and then you don't want to?",
                    "label": 0
                },
                {
                    "sent": "Never eat food that makes you feel unwell so you better keep the probability.",
                    "label": 0
                },
                {
                    "sent": "Low by rally eating stuff that you don't know you know.",
                    "label": 0
                },
                {
                    "sent": "You have replied by citing Mona Lisa.",
                    "label": 0
                },
                {
                    "sent": "I would like to cite Mozart.",
                    "label": 0
                },
                {
                    "sent": "There is something that sermons call or form.",
                    "label": 0
                },
                {
                    "sent": "And this is some piece of music Mozart has made.",
                    "label": 0
                },
                {
                    "sent": "Many of the sort which you would and you are enjoying listening to again and again.",
                    "label": 0
                },
                {
                    "sent": "Although in a certain sense it is really boring.",
                    "label": 0
                },
                {
                    "sent": "Can you elaborate a bit on that?",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "So I guess again the difference is.",
                    "label": 0
                },
                {
                    "sent": "If you listen to any artwork in any piece of music, there are two things you can do, at least two things.",
                    "label": 0
                },
                {
                    "sent": "There's so many things you can do, but one is take exactly the same recording and listen to it again and again, and again and very few people I know do that more than 10 times in a row.",
                    "label": 0
                },
                {
                    "sent": "However, listening to the same piece of music interpreted by different artists, that is something very unusual because every artist has his own interpretation and creates little additional patterns on top of the of the basic pattern of the basic melody and the basic arrangement, etc.",
                    "label": 0
                },
                {
                    "sent": "There is so much freedom in interpretation that many of these interpretations are just very attractive.",
                    "label": 0
                },
                {
                    "sent": "Just because of these differences to the other interpretations of the other artists.",
                    "label": 0
                },
                {
                    "sent": "And it's also a very different from singing yourself this thing, because there you get really again a different sensory perception based on your own voice.",
                    "label": 0
                },
                {
                    "sent": "Maybe you never sang those were warm this year one.",
                    "label": 0
                },
                {
                    "sent": "I don't even know where the English word for that.",
                    "label": 0
                },
                {
                    "sent": "Again and again while you are starting to do this while you're learning to sing it, you get a lot of progress because this particular pattern, which is coming out of your own mouth and is similar to those that you heard only by qualified Singer so far, is a new pattern and you can work on improving it and you can make it better and so you are motivated to to do that for awhile.",
                    "label": 0
                },
                {
                    "sent": "So what about transition between intrinsic and extrinsic rewards when some intrinsic reward becomes external and some external reward becomes internal?",
                    "label": 0
                },
                {
                    "sent": "This is a pretty common occurrence in physiological and evolutionary processes.",
                    "label": 0
                },
                {
                    "sent": "When anticipation of a word later on.",
                    "label": 0
                },
                {
                    "sent": "Actually causes the hormonal spike earlier in earlier and that's how they explained, for example, gambling addictions.",
                    "label": 0
                },
                {
                    "sent": "So this transition and feedback between external and internal and changes from one through the other than partially could explain this comfort we find in familiar.",
                    "label": 0
                },
                {
                    "sent": "Yeah, So what you are describing is, I think, just the effect that you have in any reinforcement learning algorithm.",
                    "label": 0
                },
                {
                    "sent": "Weather is delayed reward.",
                    "label": 0
                },
                {
                    "sent": "So at some point you have reward and then this reward is transformed by even Q.",
                    "label": 0
                },
                {
                    "sent": "Learning is doing that, but many other more sophisticated.",
                    "label": 0
                },
                {
                    "sent": "Possibly doing algorithms are doing the same thing so that you get the credit assignment.",
                    "label": 0
                },
                {
                    "sent": "Two things that happened earlier which are causally related to this we want, and so you just get the standard way of propagating these predicted rewards back into time.",
                    "label": 0
                },
                {
                    "sent": "Search that you get all kinds of associations with things that you did earlier which are then causative, or at least to a certain extent predicted for the future reward.",
                    "label": 0
                },
                {
                    "sent": "So there's no problem at all with this.",
                    "label": 0
                },
                {
                    "sent": "This is just a standard.",
                    "label": 0
                },
                {
                    "sent": "Product off the reinforcement of a standard reinforcement learning algorithm that you are using to optimize the the action sequence leading to the reward.",
                    "label": 0
                },
                {
                    "sent": "And then it becomes necessity just like food.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so food is food is so in the language now I'm using here.",
                    "label": 0
                },
                {
                    "sent": "Maybe it's not the same as some people in your science.",
                    "label": 0
                },
                {
                    "sent": "I found out I have to be so careful when I'm talking to neuro scientist because they're using Safari reinforcement for a different thing.",
                    "label": 0
                },
                {
                    "sent": "They say even if my predictor improves here and this means that some of the weights get stronger, they say the waves get reinforced.",
                    "label": 0
                },
                {
                    "sent": "This confuses hell out of me because the predictor is just a method is just as justice.",
                    "label": 0
                },
                {
                    "sent": "A traditional learning algorithm which just improves it using gradient descent or something like that.",
                    "label": 0
                },
                {
                    "sent": "While the reinforcement business that is for the reward maximizer.",
                    "label": 0
                },
                {
                    "sent": "So I'm now always trying to actually off, and I'm trying to avoid the word reinforcement.",
                    "label": 0
                },
                {
                    "sent": "Just say there are the.",
                    "label": 0
                },
                {
                    "sent": "The the adaptation mechanisms in the prediction machine, which often is called habituation, habitation in neuroscience, and then there's the reward maximizing business for the guy who is selecting the actions.",
                    "label": 0
                },
                {
                    "sent": "So instead of using stuff like using words like reinforcement I'm using now.",
                    "label": 0
                },
                {
                    "sent": "Reward maximization and.",
                    "label": 0
                },
                {
                    "sent": "I'm using habituation for what's happening in the prediction machine, and suddenly then I can start talking to neuro scientists and neuropsychologists.",
                    "label": 0
                },
                {
                    "sent": "So we have a terminology problem, but.",
                    "label": 0
                },
                {
                    "sent": "It's all just terminology I found.",
                    "label": 0
                },
                {
                    "sent": "Thank you for a fascinating talk.",
                    "label": 0
                },
                {
                    "sent": "I was wondering whether you could link the 1 / F noise or pink noise and Bierhoff Thierry with with your theory about the one everybody.",
                    "label": 0
                },
                {
                    "sent": "So back off is one of these guys who found it.",
                    "label": 0
                },
                {
                    "sent": "This information theoretic view of pleasure.",
                    "label": 0
                },
                {
                    "sent": "And I think in 1931 he was pretty much the first he had.",
                    "label": 0
                },
                {
                    "sent": "This you looked at objects and try to come up with the complexity measure of pictures of objects based on simple primitives etc.",
                    "label": 0
                },
                {
                    "sent": "And then lots of people built on that and then, especially in the 60s there were people like do we mention them here?",
                    "label": 0
                },
                {
                    "sent": "Yeah, more less.",
                    "label": 0
                },
                {
                    "sent": "Moles are more than friends and then bends Anne Frank and knock.",
                    "label": 0
                },
                {
                    "sent": "And frankly these were all in Germany.",
                    "label": 0
                },
                {
                    "sent": "Whether you have the full field called information aesthetics.",
                    "label": 0
                },
                {
                    "sent": "And all trying to build on each other and I think what was missing in all of these approaches.",
                    "label": 0
                },
                {
                    "sent": "I'm still talking to people like nothing was.",
                    "label": 0
                },
                {
                    "sent": "The missing thing was this concept of dynamic changed relative to the given observer, who is using a learning algorithm to improve the number of bits you need to encode the data and this first derivative of the compressibility that wasn't really there and that makes all the difference.",
                    "label": 0
                },
                {
                    "sent": "That's it, and that's so I'm not talking about the compressibility itself.",
                    "label": 0
                },
                {
                    "sent": "There are lots of patterns that are compressible.",
                    "label": 0
                },
                {
                    "sent": "I'm talking about the change of the compressibility, and this is what you have to.",
                    "label": 0
                },
                {
                    "sent": "Take into account and ephemera it goes away quickly because once you have it, you have learned on this thing.",
                    "label": 0
                },
                {
                    "sent": "You need a new thing which becomes interesting because the old thing has become boring, so that's so different.",
                    "label": 0
                }
            ]
        }
    }
}