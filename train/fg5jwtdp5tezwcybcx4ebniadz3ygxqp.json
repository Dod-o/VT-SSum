{
    "id": "fg5jwtdp5tezwcybcx4ebniadz3ygxqp",
    "title": "Automatic expansion of DBpedia exploiting Wikipedia cross-language information",
    "info": {
        "introducer": [
            "Harald Sack, Hasso-Plattner-Institute, University of Potsdam"
        ],
        "author": [
            "Alessio Palmero Aprosio, Bruno Kessler Foundation"
        ],
        "published": "July 8, 2013",
        "recorded": "May 2013",
        "category": [
            "Top->Computer Science->Semantic Web",
            "Top->Computer Science->Big Data"
        ]
    },
    "url": "http://videolectures.net/eswc2013_palmero_aprosio_expansion/",
    "segmentation": [
        [
            "So we come to the last speaker of the session.",
            "It's Alicia Palmero approach.",
            "Go from fundacion.",
            "Bruno Kessler in Trento and he's giving a talk about automatic expansion of DB Pedia.",
            "Exploiting Wikipedia cross language information.",
            "Please welcome, alessio.",
            "Thank you.",
            "I am Elizabeth Brazil.",
            "I am a PhD students from Milan and train to from from the center Kessler.",
            "This is a joint work with Cloud Juliana and Alberta Lavalley from FBC.",
            "Sorry."
        ],
        [
            "And then the demand of structured data collected from the web is growing in the last years and several knowledge basis has been realized, released to fit this need.",
            "Mainly they are taken from the extracted from Wikipedia.",
            "Wikipedia is perfect choice for this for this task because it's free, is continuously updated.",
            "And it represents what people need to know.",
            "It's an encyclopedia, so it's very big and free."
        ],
        [
            "We will concentrate only on DB pedia DP.",
            "There is the first project of this kind.",
            "I need the hub of the Lincoln Data Link data Cloud.",
            "Sorry, and then you pay.",
            "There is also releasing a lot of languages 16.",
            "And then it it has a someone teologi with 359 classes and 1775.",
            "Properties in this work we concentrate only on classes and we try to extend this.",
            "This resource."
        ],
        [
            "ADB Pedia works using Infoboxes info boxes are.",
            "Sort of box summarizing the most important information in Wikipedia pages and this info boxes are mapped to the corresponding class in the pedia.",
            "Clearly some info boxes are most frequent.",
            "For example, an actor info box, maybe three months more frequent than Cyclist Inbox, so most frequent infoboxes arm up first.",
            "In"
        ],
        [
            "Matt there is also an extraction framework released by the PDF community that the Maps this.",
            "This page is to the corresponding class, so if the info box is mapped to the class, the pages added to this class.",
            "Obviously, also properties are mapped about this not concern our work."
        ],
        [
            "In the very same issues in DB Pedia, the first issue is that is it concerned multilinguality Wikipedia is releasing 16 languages as we said.",
            "But the mappings are done for each language separately.",
            "So if someone wants to create a new community pedia and you chapter depending on language not covered, the job must be done from scratch.",
            "Actually, the pedia offered the cross language links in their source, but these are not used for the corresponding language chapter.",
            "And also this multi language.",
            "The way how we multi language is managed in DB pedia is may cause the December geniti between between the classes and between the coverage for example."
        ],
        [
            "The the 10 most frequent templates in English, Italian, French cover has a very different coverage over there than Encyclopedia pedia.",
            "For example, the French one.",
            "Cover only the 14% of pages, so you need more mappings to cover the same of the Italian one."
        ],
        [
            "The second problem we encounter in the Pedia is that sometimes the infoboxes are.",
            "Are too generic, so for example in this page Clint Eastwood has an infobox person, but he's an actor and we want the system to classify as an actor.",
            "But for example in English there is no info box for actors or there is one, but it's not widely used in the pages, but for example there is 1 called Chinese language singer and actor, so the crowd philosophy used to build Wikipedia.",
            "Have these issues in this area reflects the paideia too."
        ],
        [
            "Example, Clint Eastwood is classified as person in the Italian in English, the Bay Area and this actor in the French and Spanish, the Pedia or even Barack Obama has three different classification.",
            "But it has four.",
            "If you extend to other languages.",
            "I."
        ],
        [
            "Other trivial problem is that sometimes the.",
            "Wikipedia pages has not anything box, so we want to classify these two D pedia."
        ],
        [
            "Actually classify it as a thing so you can find that page in DB pedia.",
            "But it's classified as a trivial thing.",
            "So."
        ],
        [
            "Our goals is to extend the population of DB Pedia to make a fine grained categorisation when needed and to use multilinguality to do that so we can extend to other languages without a big effort.",
            "How are you?"
        ],
        [
            "This is that we can infer the most appropriate class of the Wikipedia page or the Wikipedia entity by using other other characteristics of the page.",
            "Then only the infobox now info boxes where you can see the Barrack Obama photo.",
            "But we can use the text summary, the OR categories, or other features."
        ],
        [
            "Our system.",
            "It won't be a supervised automatic approach, so we use the already present Wikipedia pages for training the Wikipedia pages to be classified, and we want to classify them using a supervised approach.",
            "The."
        ],
        [
            "First issue is that sometimes some classes are not covered in India.",
            "For example, actors in Italian and English are have only a few representative because as we said, there is no info box for actors in English and nor there is in Italian.",
            "In for example there is in French and Spanish.",
            "So these two languages are well covered and if we don't have any training data for actors in Italian.",
            "We cannot collect classified Italian actors clearly, so."
        ],
        [
            "We use the cross language links.",
            "We build an entity matrix and so from now on we only reason about entities.",
            "So the week the Barrack Obama page in Italian or in English or in French is the same entity Barack Obama.",
            "And we need the two unify the classification DB pedia.",
            "In fact, as we said."
        ],
        [
            "Some pages are differently classified in DB pedia.",
            "This is true for a very famous pages, for example, less famous vision is not a Max like that, but sometimes it happens that he has a lot of different classification."
        ],
        [
            "In order to see if we want to use one of them, for example, our rule for do this is to have to take the deepest one, having the half of the of the evaluation.",
            "Clearly, as we talk about.",
            "An ontology.",
            "So if there are inheritance between classes, a officeholder automatically gives a point to a vote to person.",
            "So in this case, the President gives about to politician, and so on."
        ],
        [
            "A so we unified this classification with politician and we note that in some."
        ],
        [
            "In some languages we can have a better classification, so we can go deeply in the interval entology.",
            "And so with this trick."
        ],
        [
            "We can populate some classes before this.",
            "Tasker has not populated, for example, actors in Italian.",
            "English now has a lot of representatives, so we can train our model."
        ],
        [
            "To do that, we use the strategy of kernel methods.",
            "So we first to embed the the data input data in a feature space, and then we search for a linear algorithm to discover nonlinear patterns and that are the first graph.",
            "In the input space and we get a kernel function we."
        ],
        [
            "He extracts as we said.",
            "Yeah, a lot of features from the pages, for example, use sections with categories, so we use templates as a pager is actually using but not for supervised machine learning technique.",
            "We use the bag of words or vertical tax and we also use the semantic analysis text.",
            "So we have 5 kernels for each language."
        ],
        [
            "The first four kernels are bugs Colonel, so are linear.",
            "Travel curlers and the semantic kernels usually run transformation to cut the vector space to 100 dimensions.",
            "He discussed in the paper.",
            "If you want to."
        ],
        [
            "Go deep and then we we compute the composite kernel and we obtain the final kernel.",
            "A to use with our machine learning approach."
        ],
        [
            "You know what experiments we want to populate the whole DB pedia ontology that is made by 359 classes.",
            "We try to use two different machine learning approaches.",
            "The key and the SVM.",
            "And we use a six different language for training English, Italian, Spanish, Portuguese, French and German.",
            "You know it's."
        ],
        [
            "It means KNN obtains better results and then we use K equals to 10 because it's one of the best results we annotate in 500 pages for as a gold standard to test our system, and in this 500 pages and in the results I'll show later we only consider page is not in the PDF.",
            "So even if we use for training only a subset of DB pedia.",
            "For example for KNN.",
            "We in our experience, we only consider pages not in DP.",
            "I."
        ],
        [
            "Our classification is clearly hierarchical because we use the depatie ontology we want to tune precision and recall on on the frequency of guest class KNN gives.",
            "For example, in our example, K is 10, so 10 energies 10 guess the class.",
            "And we use three different strategies to tune precision, every color to boost the precision and recall are we.",
            "Can we see it later?"
        ],
        [
            "So we use our hierarchical classifier.",
            "This is an example of the.",
            "It's a subset of the ontology and this is.",
            "I guess it's a key and end results, so our system gives 10 different different classes and we want to also.",
            "They parent classes are automatically narrated.",
            "So for example, when our system gets musical artists we also devote to artist, person, agent and obvious thing.",
            "But we don't consider thing as is trivial.",
            "So in this case we have nine votes for Agent 9, four person, one for work, 747 for musical artists.",
            "Now we starting from this we can tune precision and recall using our three different strategies."
        ],
        [
            "We set the threshold zed to tune precision.",
            "Recall an whenever our system gives us certain classification.",
            "We compare with that and so we can have our guest final results.",
            "We have three strategies to select the class."
        ],
        [
            "The first is the bottom up strategy.",
            "For example, we set that to 8."
        ],
        [
            "We are using the example above.",
            "We have this results.",
            "So we start from the deepest from the deepest class."
        ],
        [
            "And we show that 7 is not eight is lesser than 8.",
            "So we go."
        ],
        [
            "APTA and 70 anything update."
        ],
        [
            "So in this case we have 9 is greater than 8, so we keep this as our classification.",
            "So in this case we with that equals weight.",
            "We classify this person."
        ],
        [
            "In the top down approach we."
        ],
        [
            "Again, we fix that.",
            "Wait we."
        ],
        [
            "I only classify with the top level with a top level classifier and we classify for example in this situation we have 10 votes for agent and zero for the other classes."
        ],
        [
            "A 10 is OK is a greater than 8, so we can go deeper with some new classifiers.",
            "So we have a classifier in this.",
            "In this strategy we have a classifier for each for each class."
        ],
        [
            "For example, this can be the output again."
        ],
        [
            "We use purse."
        ],
        [
            "Then"
        ],
        [
            "Artist then we."
        ],
        [
            "Because 70."
        ],
        [
            "Is a lesser than 8.",
            "So we give artists as a result.",
            "The 3rd way."
        ],
        [
            "I'm using some big classifier on the most frequent classes that is personal workplace and there is a shun.",
            "These four classes cover around 90% of pages, DB Pedia and so."
        ],
        [
            "We again use it said equals 2."
        ],
        [
            "We classify with the bottom up system, but we stop."
        ],
        [
            "On the on one of the classes, the most frequent classes, and then we use our new classifier trained only for this class."
        ],
        [
            "So we can obtain these results and again."
        ],
        [
            "We start from the bottom and."
        ],
        [
            "We conclude."
        ],
        [
            "That this is an artist.",
            "And now we proceed with the evaluation as."
        ],
        [
            "We we are using an ontology in the tree taxonomy and we want that if our system for example."
        ],
        [
            "Yes, that Michael Jackson is athlete.",
            "OK, this is wrong clearly, but it's better than if our system gets it.",
            "Him as a food or as a place so."
        ],
        [
            "We want you with the the information, in this case a.",
            "Clearly Michael Jackson is a musical artist, so we have."
        ],
        [
            "False positive for athlete because he is wrong."
        ],
        [
            "I have two false negative for musical artist."
        ],
        [
            "And two 2 positive for agent in person.",
            "So he almost right almost wrong.",
            "Using this evaluation we."
        ],
        [
            "We had these results the first quarter, right?",
            "The line is our system, trained with only templates.",
            "This means that this is.",
            "The maximum recall DPI can reach with a by annotating them place.",
            "He is an estimation is not is not the real value, but we can see that the recall is quite low.",
            "And then D Pedia cannot cover more than 50% pages in all of the remaining pages with respect to the actual DB pedia, because a lot of people have not infoboxes with bottom up system.",
            "We reach the green line or this graph is a recall on the X and precision on the Y line in with the top down we boost the recall.",
            "As we can see from the black line and with blue line we can boost precision.",
            "The blue line is a hybrid approach using the four.",
            "The four most frequent.",
            "Classifiers with the four most frequent classes.",
            "The final resource resources released."
        ],
        [
            "Scholarpedia you can find it on the website, repeater.org.",
            "It contains a 20,000,000 stripe.",
            "Also, we extract them with this firm precision recall.",
            "Threshold with the 8, nine and 10 so This is why there are twenty millions.",
            "There are in fact they are not tripod.",
            "There quadruples because the 4th element of the RDF is the precision.",
            "We map the new 1.7 million new entities so.",
            "Ignoring ignoring the old thing classification in DP, there we extended by 1.7 million entities and there is also the sparkling point you can query if you want more more information.",
            "If you want more trifles.",
            "The."
        ],
        [
            "Is a schema DB that covers only 2.2 million entities in these 6 languages and we extend it by 1.7 and we also re annotated the the DPD entities so.",
            "We can we try to go deep in the classification."
        ],
        [
            "Same conclusion, we extended the pedia in six languages.",
            "We define the general methodology that can be used in every languages also, if there are no mappings in the pedia.",
            "And we released the source, we are actually working on properties.",
            "If you go to the website you can see some results in this sense and we are extending the resource in 31 languages."
        ],
        [
            "Thank you for your attention.",
            "Yeah, nice work.",
            "One question for the.",
            "The other categories you only used DVD classes correct?",
            "OK so the and you only used the classes that you've shown in the graph fragment in their archaic.",
            "Now we use the Hula DP ontology the whole division.",
            "This is only for example purposes and they have you notice you know different position recall in classes that have few instances or respect to the because you mentioned mainly order before you mentioned in the examples are.",
            "No, not largely.",
            "Bigger than the by far bigger than the others.",
            "And OK, we did some testing the 1st when we start our experiments.",
            "Only if there are less examples in one class.",
            "Our system maybe have mistakes, but usually our system in this case is try to guess the apparent class.",
            "Maybe.",
            "For example, if there are less example for badminton players, our system gets athlete or person or abstain because our system can also obtain.",
            "So for some classes our system is simply abstain and This is why the recall is not very high genus and in certain cases.",
            "Anyway, yeah results are worth when when the class is less populated.",
            "According to your approach, is Clint Eastwood an actor or director about Clint Eastwood?",
            "Is A is an actor because he is already classified in the PD as an actor in some languages so.",
            "OK, this is this is a good question because sometimes in Indy Pedia you can have multiple class classification but not in a single language.",
            "The pedia, as each template is mapped only to one class.",
            "So if you mix some languages you can have multiple classification.",
            "This is true but we want to simulate the PDF so we don't care about multiple classification in this work.",
            "It said to do it Saturday.",
            "Sorry Valentina, first.",
            "Actually related to this.",
            "With about coverage, I mean you have a intrinsic limit given by the limitation of the coverage of the ontology, the coverage of the domain.",
            "I mean because they depend on teologi.",
            "Is limited based on the fact that is, you know map today infobox.",
            "So do you plan in anyway?",
            "Yeah, this is a good point and This is why our our system recall is not very high to gain a because you compared to T Palo I have a bias in there.",
            "Yes, yes, this is an issue, but for example sometimes lists of pages are classified as pages because there is not in 3.8 version of the pedia class for lists.",
            "In this case our system simply abstain.",
            "Usually, if if it cannot.",
            "Compared with that, calculated the kernel with other with other pages, our system simply abstains.",
            "Over there, yeah.",
            "Jean is from the FBI.",
            "I've actually 2 questions.",
            "One is how does your approach relate to Vicki data?",
            "OK, when we started this worker in August, we even didn't know that Wiki data was was rising.",
            "Wiki data is manually annotated, I think so.",
            "In this sense, our work is not related with wiki data.",
            "We use training data from from DB pedia.",
            "We are going deeply into wiki data and we are using it for the GNU GNU experiment we're doing.",
            "But this work is not related with the wiki data I ask because it would be valuable feedback for them to actually diploid or do the initial data set and the second question is so you actually talk a lot about this.",
            "What I would call the most intuitive type of a thing.",
            "Right, and this is heavily related to my research, so what's associated with a thing.",
            "So do you have any like ground truth for that?",
            "Or is it just manually annotated and you said, OK?",
            "Clint Eastwood is an actor is a politician.",
            "I didn't understand the question.",
            "So you mean that in the classification of things or the root level?",
            "Now I didn't understand.",
            "Could you repeat please?",
            "So this is you have this use this notion of the most intuitive typo.",
            "I would call it or describe it like this.",
            "Like is Clint Eastwood, is he now an actor or is he a politician, right?",
            "Do you have any data set like a ground truth or gold standard for this?",
            "OK, in our gold standard we now in there during the annotation we were three annotators, different translators, and we consider the most.",
            "Come on.",
            "Class so for example, if listed for design is an actor in IS director of the politician.",
            "We consider it as an actor.",
            "Or maybe there is disagreement between us.",
            "Agreement is not 100% clearly.",
            "So.",
            "One question I have is when you when you did the evaluation you decided to annotate yourself.",
            "And I want to know what is the motivation for this versus using.",
            "A classical, let's say, holdout set that you that you don't use for training.",
            "So why did you?",
            "Why did you annotate yourself?",
            "Because we want to test on pages that are not present in DB pedia.",
            "So.",
            "Well, maybe I don't, but for evaluating your approach you could have as well tested on pages that are available in DB pedia by pretending that you don't.",
            "Have the annotation by holding it out right now.",
            "OK. OK so I can cross validation sort of cross validation.",
            "Yeah, we tried cross validation and it was very very good results.",
            "Clearly because the training set is biased on this as we use also template to train our system and the pager uses templates.",
            "We tried this but we had 97 percent 98% of precision.",
            "We want to test it on.",
            "On pages that I have not infobox we don't extend the Villa and we also want to give a system that can be used on different languages.",
            "So language for which we don't have any training in that language.",
            "So This is why we annotated this pages.",
            "OK, more questions.",
            "So then, let's thank the speaker and any other speaker of the session again."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we come to the last speaker of the session.",
                    "label": 0
                },
                {
                    "sent": "It's Alicia Palmero approach.",
                    "label": 0
                },
                {
                    "sent": "Go from fundacion.",
                    "label": 0
                },
                {
                    "sent": "Bruno Kessler in Trento and he's giving a talk about automatic expansion of DB Pedia.",
                    "label": 1
                },
                {
                    "sent": "Exploiting Wikipedia cross language information.",
                    "label": 0
                },
                {
                    "sent": "Please welcome, alessio.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                },
                {
                    "sent": "I am Elizabeth Brazil.",
                    "label": 0
                },
                {
                    "sent": "I am a PhD students from Milan and train to from from the center Kessler.",
                    "label": 0
                },
                {
                    "sent": "This is a joint work with Cloud Juliana and Alberta Lavalley from FBC.",
                    "label": 0
                },
                {
                    "sent": "Sorry.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then the demand of structured data collected from the web is growing in the last years and several knowledge basis has been realized, released to fit this need.",
                    "label": 0
                },
                {
                    "sent": "Mainly they are taken from the extracted from Wikipedia.",
                    "label": 0
                },
                {
                    "sent": "Wikipedia is perfect choice for this for this task because it's free, is continuously updated.",
                    "label": 0
                },
                {
                    "sent": "And it represents what people need to know.",
                    "label": 0
                },
                {
                    "sent": "It's an encyclopedia, so it's very big and free.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We will concentrate only on DB pedia DP.",
                    "label": 0
                },
                {
                    "sent": "There is the first project of this kind.",
                    "label": 0
                },
                {
                    "sent": "I need the hub of the Lincoln Data Link data Cloud.",
                    "label": 1
                },
                {
                    "sent": "Sorry, and then you pay.",
                    "label": 0
                },
                {
                    "sent": "There is also releasing a lot of languages 16.",
                    "label": 0
                },
                {
                    "sent": "And then it it has a someone teologi with 359 classes and 1775.",
                    "label": 0
                },
                {
                    "sent": "Properties in this work we concentrate only on classes and we try to extend this.",
                    "label": 0
                },
                {
                    "sent": "This resource.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "ADB Pedia works using Infoboxes info boxes are.",
                    "label": 0
                },
                {
                    "sent": "Sort of box summarizing the most important information in Wikipedia pages and this info boxes are mapped to the corresponding class in the pedia.",
                    "label": 1
                },
                {
                    "sent": "Clearly some info boxes are most frequent.",
                    "label": 0
                },
                {
                    "sent": "For example, an actor info box, maybe three months more frequent than Cyclist Inbox, so most frequent infoboxes arm up first.",
                    "label": 1
                },
                {
                    "sent": "In",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Matt there is also an extraction framework released by the PDF community that the Maps this.",
                    "label": 0
                },
                {
                    "sent": "This page is to the corresponding class, so if the info box is mapped to the class, the pages added to this class.",
                    "label": 0
                },
                {
                    "sent": "Obviously, also properties are mapped about this not concern our work.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In the very same issues in DB Pedia, the first issue is that is it concerned multilinguality Wikipedia is releasing 16 languages as we said.",
                    "label": 0
                },
                {
                    "sent": "But the mappings are done for each language separately.",
                    "label": 1
                },
                {
                    "sent": "So if someone wants to create a new community pedia and you chapter depending on language not covered, the job must be done from scratch.",
                    "label": 0
                },
                {
                    "sent": "Actually, the pedia offered the cross language links in their source, but these are not used for the corresponding language chapter.",
                    "label": 0
                },
                {
                    "sent": "And also this multi language.",
                    "label": 0
                },
                {
                    "sent": "The way how we multi language is managed in DB pedia is may cause the December geniti between between the classes and between the coverage for example.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The the 10 most frequent templates in English, Italian, French cover has a very different coverage over there than Encyclopedia pedia.",
                    "label": 1
                },
                {
                    "sent": "For example, the French one.",
                    "label": 0
                },
                {
                    "sent": "Cover only the 14% of pages, so you need more mappings to cover the same of the Italian one.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The second problem we encounter in the Pedia is that sometimes the infoboxes are.",
                    "label": 0
                },
                {
                    "sent": "Are too generic, so for example in this page Clint Eastwood has an infobox person, but he's an actor and we want the system to classify as an actor.",
                    "label": 1
                },
                {
                    "sent": "But for example in English there is no info box for actors or there is one, but it's not widely used in the pages, but for example there is 1 called Chinese language singer and actor, so the crowd philosophy used to build Wikipedia.",
                    "label": 0
                },
                {
                    "sent": "Have these issues in this area reflects the paideia too.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Example, Clint Eastwood is classified as person in the Italian in English, the Bay Area and this actor in the French and Spanish, the Pedia or even Barack Obama has three different classification.",
                    "label": 1
                },
                {
                    "sent": "But it has four.",
                    "label": 0
                },
                {
                    "sent": "If you extend to other languages.",
                    "label": 0
                },
                {
                    "sent": "I.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Other trivial problem is that sometimes the.",
                    "label": 0
                },
                {
                    "sent": "Wikipedia pages has not anything box, so we want to classify these two D pedia.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Actually classify it as a thing so you can find that page in DB pedia.",
                    "label": 0
                },
                {
                    "sent": "But it's classified as a trivial thing.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Our goals is to extend the population of DB Pedia to make a fine grained categorisation when needed and to use multilinguality to do that so we can extend to other languages without a big effort.",
                    "label": 0
                },
                {
                    "sent": "How are you?",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This is that we can infer the most appropriate class of the Wikipedia page or the Wikipedia entity by using other other characteristics of the page.",
                    "label": 1
                },
                {
                    "sent": "Then only the infobox now info boxes where you can see the Barrack Obama photo.",
                    "label": 0
                },
                {
                    "sent": "But we can use the text summary, the OR categories, or other features.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Our system.",
                    "label": 0
                },
                {
                    "sent": "It won't be a supervised automatic approach, so we use the already present Wikipedia pages for training the Wikipedia pages to be classified, and we want to classify them using a supervised approach.",
                    "label": 1
                },
                {
                    "sent": "The.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "First issue is that sometimes some classes are not covered in India.",
                    "label": 0
                },
                {
                    "sent": "For example, actors in Italian and English are have only a few representative because as we said, there is no info box for actors in English and nor there is in Italian.",
                    "label": 0
                },
                {
                    "sent": "In for example there is in French and Spanish.",
                    "label": 0
                },
                {
                    "sent": "So these two languages are well covered and if we don't have any training data for actors in Italian.",
                    "label": 1
                },
                {
                    "sent": "We cannot collect classified Italian actors clearly, so.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We use the cross language links.",
                    "label": 0
                },
                {
                    "sent": "We build an entity matrix and so from now on we only reason about entities.",
                    "label": 0
                },
                {
                    "sent": "So the week the Barrack Obama page in Italian or in English or in French is the same entity Barack Obama.",
                    "label": 0
                },
                {
                    "sent": "And we need the two unify the classification DB pedia.",
                    "label": 0
                },
                {
                    "sent": "In fact, as we said.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Some pages are differently classified in DB pedia.",
                    "label": 0
                },
                {
                    "sent": "This is true for a very famous pages, for example, less famous vision is not a Max like that, but sometimes it happens that he has a lot of different classification.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In order to see if we want to use one of them, for example, our rule for do this is to have to take the deepest one, having the half of the of the evaluation.",
                    "label": 0
                },
                {
                    "sent": "Clearly, as we talk about.",
                    "label": 0
                },
                {
                    "sent": "An ontology.",
                    "label": 0
                },
                {
                    "sent": "So if there are inheritance between classes, a officeholder automatically gives a point to a vote to person.",
                    "label": 0
                },
                {
                    "sent": "So in this case, the President gives about to politician, and so on.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "A so we unified this classification with politician and we note that in some.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In some languages we can have a better classification, so we can go deeply in the interval entology.",
                    "label": 0
                },
                {
                    "sent": "And so with this trick.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We can populate some classes before this.",
                    "label": 0
                },
                {
                    "sent": "Tasker has not populated, for example, actors in Italian.",
                    "label": 0
                },
                {
                    "sent": "English now has a lot of representatives, so we can train our model.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "To do that, we use the strategy of kernel methods.",
                    "label": 1
                },
                {
                    "sent": "So we first to embed the the data input data in a feature space, and then we search for a linear algorithm to discover nonlinear patterns and that are the first graph.",
                    "label": 1
                },
                {
                    "sent": "In the input space and we get a kernel function we.",
                    "label": 1
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "He extracts as we said.",
                    "label": 0
                },
                {
                    "sent": "Yeah, a lot of features from the pages, for example, use sections with categories, so we use templates as a pager is actually using but not for supervised machine learning technique.",
                    "label": 0
                },
                {
                    "sent": "We use the bag of words or vertical tax and we also use the semantic analysis text.",
                    "label": 1
                },
                {
                    "sent": "So we have 5 kernels for each language.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The first four kernels are bugs Colonel, so are linear.",
                    "label": 0
                },
                {
                    "sent": "Travel curlers and the semantic kernels usually run transformation to cut the vector space to 100 dimensions.",
                    "label": 0
                },
                {
                    "sent": "He discussed in the paper.",
                    "label": 0
                },
                {
                    "sent": "If you want to.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Go deep and then we we compute the composite kernel and we obtain the final kernel.",
                    "label": 0
                },
                {
                    "sent": "A to use with our machine learning approach.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "You know what experiments we want to populate the whole DB pedia ontology that is made by 359 classes.",
                    "label": 1
                },
                {
                    "sent": "We try to use two different machine learning approaches.",
                    "label": 0
                },
                {
                    "sent": "The key and the SVM.",
                    "label": 0
                },
                {
                    "sent": "And we use a six different language for training English, Italian, Spanish, Portuguese, French and German.",
                    "label": 1
                },
                {
                    "sent": "You know it's.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "It means KNN obtains better results and then we use K equals to 10 because it's one of the best results we annotate in 500 pages for as a gold standard to test our system, and in this 500 pages and in the results I'll show later we only consider page is not in the PDF.",
                    "label": 0
                },
                {
                    "sent": "So even if we use for training only a subset of DB pedia.",
                    "label": 0
                },
                {
                    "sent": "For example for KNN.",
                    "label": 0
                },
                {
                    "sent": "We in our experience, we only consider pages not in DP.",
                    "label": 1
                },
                {
                    "sent": "I.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Our classification is clearly hierarchical because we use the depatie ontology we want to tune precision and recall on on the frequency of guest class KNN gives.",
                    "label": 0
                },
                {
                    "sent": "For example, in our example, K is 10, so 10 energies 10 guess the class.",
                    "label": 0
                },
                {
                    "sent": "And we use three different strategies to tune precision, every color to boost the precision and recall are we.",
                    "label": 1
                },
                {
                    "sent": "Can we see it later?",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we use our hierarchical classifier.",
                    "label": 1
                },
                {
                    "sent": "This is an example of the.",
                    "label": 0
                },
                {
                    "sent": "It's a subset of the ontology and this is.",
                    "label": 0
                },
                {
                    "sent": "I guess it's a key and end results, so our system gives 10 different different classes and we want to also.",
                    "label": 0
                },
                {
                    "sent": "They parent classes are automatically narrated.",
                    "label": 0
                },
                {
                    "sent": "So for example, when our system gets musical artists we also devote to artist, person, agent and obvious thing.",
                    "label": 0
                },
                {
                    "sent": "But we don't consider thing as is trivial.",
                    "label": 1
                },
                {
                    "sent": "So in this case we have nine votes for Agent 9, four person, one for work, 747 for musical artists.",
                    "label": 0
                },
                {
                    "sent": "Now we starting from this we can tune precision and recall using our three different strategies.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We set the threshold zed to tune precision.",
                    "label": 1
                },
                {
                    "sent": "Recall an whenever our system gives us certain classification.",
                    "label": 1
                },
                {
                    "sent": "We compare with that and so we can have our guest final results.",
                    "label": 0
                },
                {
                    "sent": "We have three strategies to select the class.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The first is the bottom up strategy.",
                    "label": 0
                },
                {
                    "sent": "For example, we set that to 8.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We are using the example above.",
                    "label": 0
                },
                {
                    "sent": "We have this results.",
                    "label": 0
                },
                {
                    "sent": "So we start from the deepest from the deepest class.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we show that 7 is not eight is lesser than 8.",
                    "label": 0
                },
                {
                    "sent": "So we go.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "APTA and 70 anything update.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So in this case we have 9 is greater than 8, so we keep this as our classification.",
                    "label": 0
                },
                {
                    "sent": "So in this case we with that equals weight.",
                    "label": 0
                },
                {
                    "sent": "We classify this person.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In the top down approach we.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Again, we fix that.",
                    "label": 0
                },
                {
                    "sent": "Wait we.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I only classify with the top level with a top level classifier and we classify for example in this situation we have 10 votes for agent and zero for the other classes.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "A 10 is OK is a greater than 8, so we can go deeper with some new classifiers.",
                    "label": 0
                },
                {
                    "sent": "So we have a classifier in this.",
                    "label": 0
                },
                {
                    "sent": "In this strategy we have a classifier for each for each class.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For example, this can be the output again.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We use purse.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Then",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Artist then we.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Because 70.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is a lesser than 8.",
                    "label": 0
                },
                {
                    "sent": "So we give artists as a result.",
                    "label": 0
                },
                {
                    "sent": "The 3rd way.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I'm using some big classifier on the most frequent classes that is personal workplace and there is a shun.",
                    "label": 0
                },
                {
                    "sent": "These four classes cover around 90% of pages, DB Pedia and so.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We again use it said equals 2.",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We classify with the bottom up system, but we stop.",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "On the on one of the classes, the most frequent classes, and then we use our new classifier trained only for this class.",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_51": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we can obtain these results and again.",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We start from the bottom and.",
                    "label": 0
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We conclude.",
                    "label": 0
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That this is an artist.",
                    "label": 0
                },
                {
                    "sent": "And now we proceed with the evaluation as.",
                    "label": 0
                }
            ]
        },
        "clip_55": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We we are using an ontology in the tree taxonomy and we want that if our system for example.",
                    "label": 0
                }
            ]
        },
        "clip_56": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Yes, that Michael Jackson is athlete.",
                    "label": 1
                },
                {
                    "sent": "OK, this is wrong clearly, but it's better than if our system gets it.",
                    "label": 0
                },
                {
                    "sent": "Him as a food or as a place so.",
                    "label": 0
                }
            ]
        },
        "clip_57": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We want you with the the information, in this case a.",
                    "label": 0
                },
                {
                    "sent": "Clearly Michael Jackson is a musical artist, so we have.",
                    "label": 0
                }
            ]
        },
        "clip_58": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "False positive for athlete because he is wrong.",
                    "label": 0
                }
            ]
        },
        "clip_59": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I have two false negative for musical artist.",
                    "label": 0
                }
            ]
        },
        "clip_60": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And two 2 positive for agent in person.",
                    "label": 0
                },
                {
                    "sent": "So he almost right almost wrong.",
                    "label": 0
                },
                {
                    "sent": "Using this evaluation we.",
                    "label": 0
                }
            ]
        },
        "clip_61": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We had these results the first quarter, right?",
                    "label": 0
                },
                {
                    "sent": "The line is our system, trained with only templates.",
                    "label": 0
                },
                {
                    "sent": "This means that this is.",
                    "label": 0
                },
                {
                    "sent": "The maximum recall DPI can reach with a by annotating them place.",
                    "label": 0
                },
                {
                    "sent": "He is an estimation is not is not the real value, but we can see that the recall is quite low.",
                    "label": 0
                },
                {
                    "sent": "And then D Pedia cannot cover more than 50% pages in all of the remaining pages with respect to the actual DB pedia, because a lot of people have not infoboxes with bottom up system.",
                    "label": 0
                },
                {
                    "sent": "We reach the green line or this graph is a recall on the X and precision on the Y line in with the top down we boost the recall.",
                    "label": 0
                },
                {
                    "sent": "As we can see from the black line and with blue line we can boost precision.",
                    "label": 0
                },
                {
                    "sent": "The blue line is a hybrid approach using the four.",
                    "label": 0
                },
                {
                    "sent": "The four most frequent.",
                    "label": 0
                },
                {
                    "sent": "Classifiers with the four most frequent classes.",
                    "label": 0
                },
                {
                    "sent": "The final resource resources released.",
                    "label": 0
                }
            ]
        },
        "clip_62": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Scholarpedia you can find it on the website, repeater.org.",
                    "label": 0
                },
                {
                    "sent": "It contains a 20,000,000 stripe.",
                    "label": 0
                },
                {
                    "sent": "Also, we extract them with this firm precision recall.",
                    "label": 0
                },
                {
                    "sent": "Threshold with the 8, nine and 10 so This is why there are twenty millions.",
                    "label": 0
                },
                {
                    "sent": "There are in fact they are not tripod.",
                    "label": 0
                },
                {
                    "sent": "There quadruples because the 4th element of the RDF is the precision.",
                    "label": 0
                },
                {
                    "sent": "We map the new 1.7 million new entities so.",
                    "label": 0
                },
                {
                    "sent": "Ignoring ignoring the old thing classification in DP, there we extended by 1.7 million entities and there is also the sparkling point you can query if you want more more information.",
                    "label": 0
                },
                {
                    "sent": "If you want more trifles.",
                    "label": 0
                },
                {
                    "sent": "The.",
                    "label": 0
                }
            ]
        },
        "clip_63": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is a schema DB that covers only 2.2 million entities in these 6 languages and we extend it by 1.7 and we also re annotated the the DPD entities so.",
                    "label": 0
                },
                {
                    "sent": "We can we try to go deep in the classification.",
                    "label": 0
                }
            ]
        },
        "clip_64": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Same conclusion, we extended the pedia in six languages.",
                    "label": 0
                },
                {
                    "sent": "We define the general methodology that can be used in every languages also, if there are no mappings in the pedia.",
                    "label": 0
                },
                {
                    "sent": "And we released the source, we are actually working on properties.",
                    "label": 0
                },
                {
                    "sent": "If you go to the website you can see some results in this sense and we are extending the resource in 31 languages.",
                    "label": 0
                }
            ]
        },
        "clip_65": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Thank you for your attention.",
                    "label": 0
                },
                {
                    "sent": "Yeah, nice work.",
                    "label": 0
                },
                {
                    "sent": "One question for the.",
                    "label": 0
                },
                {
                    "sent": "The other categories you only used DVD classes correct?",
                    "label": 0
                },
                {
                    "sent": "OK so the and you only used the classes that you've shown in the graph fragment in their archaic.",
                    "label": 0
                },
                {
                    "sent": "Now we use the Hula DP ontology the whole division.",
                    "label": 0
                },
                {
                    "sent": "This is only for example purposes and they have you notice you know different position recall in classes that have few instances or respect to the because you mentioned mainly order before you mentioned in the examples are.",
                    "label": 0
                },
                {
                    "sent": "No, not largely.",
                    "label": 0
                },
                {
                    "sent": "Bigger than the by far bigger than the others.",
                    "label": 0
                },
                {
                    "sent": "And OK, we did some testing the 1st when we start our experiments.",
                    "label": 0
                },
                {
                    "sent": "Only if there are less examples in one class.",
                    "label": 0
                },
                {
                    "sent": "Our system maybe have mistakes, but usually our system in this case is try to guess the apparent class.",
                    "label": 0
                },
                {
                    "sent": "Maybe.",
                    "label": 0
                },
                {
                    "sent": "For example, if there are less example for badminton players, our system gets athlete or person or abstain because our system can also obtain.",
                    "label": 0
                },
                {
                    "sent": "So for some classes our system is simply abstain and This is why the recall is not very high genus and in certain cases.",
                    "label": 0
                },
                {
                    "sent": "Anyway, yeah results are worth when when the class is less populated.",
                    "label": 0
                },
                {
                    "sent": "According to your approach, is Clint Eastwood an actor or director about Clint Eastwood?",
                    "label": 0
                },
                {
                    "sent": "Is A is an actor because he is already classified in the PD as an actor in some languages so.",
                    "label": 0
                },
                {
                    "sent": "OK, this is this is a good question because sometimes in Indy Pedia you can have multiple class classification but not in a single language.",
                    "label": 0
                },
                {
                    "sent": "The pedia, as each template is mapped only to one class.",
                    "label": 0
                },
                {
                    "sent": "So if you mix some languages you can have multiple classification.",
                    "label": 0
                },
                {
                    "sent": "This is true but we want to simulate the PDF so we don't care about multiple classification in this work.",
                    "label": 0
                },
                {
                    "sent": "It said to do it Saturday.",
                    "label": 0
                },
                {
                    "sent": "Sorry Valentina, first.",
                    "label": 0
                },
                {
                    "sent": "Actually related to this.",
                    "label": 0
                },
                {
                    "sent": "With about coverage, I mean you have a intrinsic limit given by the limitation of the coverage of the ontology, the coverage of the domain.",
                    "label": 0
                },
                {
                    "sent": "I mean because they depend on teologi.",
                    "label": 0
                },
                {
                    "sent": "Is limited based on the fact that is, you know map today infobox.",
                    "label": 0
                },
                {
                    "sent": "So do you plan in anyway?",
                    "label": 0
                },
                {
                    "sent": "Yeah, this is a good point and This is why our our system recall is not very high to gain a because you compared to T Palo I have a bias in there.",
                    "label": 0
                },
                {
                    "sent": "Yes, yes, this is an issue, but for example sometimes lists of pages are classified as pages because there is not in 3.8 version of the pedia class for lists.",
                    "label": 0
                },
                {
                    "sent": "In this case our system simply abstain.",
                    "label": 0
                },
                {
                    "sent": "Usually, if if it cannot.",
                    "label": 0
                },
                {
                    "sent": "Compared with that, calculated the kernel with other with other pages, our system simply abstains.",
                    "label": 0
                },
                {
                    "sent": "Over there, yeah.",
                    "label": 0
                },
                {
                    "sent": "Jean is from the FBI.",
                    "label": 0
                },
                {
                    "sent": "I've actually 2 questions.",
                    "label": 0
                },
                {
                    "sent": "One is how does your approach relate to Vicki data?",
                    "label": 0
                },
                {
                    "sent": "OK, when we started this worker in August, we even didn't know that Wiki data was was rising.",
                    "label": 0
                },
                {
                    "sent": "Wiki data is manually annotated, I think so.",
                    "label": 0
                },
                {
                    "sent": "In this sense, our work is not related with wiki data.",
                    "label": 0
                },
                {
                    "sent": "We use training data from from DB pedia.",
                    "label": 0
                },
                {
                    "sent": "We are going deeply into wiki data and we are using it for the GNU GNU experiment we're doing.",
                    "label": 0
                },
                {
                    "sent": "But this work is not related with the wiki data I ask because it would be valuable feedback for them to actually diploid or do the initial data set and the second question is so you actually talk a lot about this.",
                    "label": 0
                },
                {
                    "sent": "What I would call the most intuitive type of a thing.",
                    "label": 0
                },
                {
                    "sent": "Right, and this is heavily related to my research, so what's associated with a thing.",
                    "label": 0
                },
                {
                    "sent": "So do you have any like ground truth for that?",
                    "label": 0
                },
                {
                    "sent": "Or is it just manually annotated and you said, OK?",
                    "label": 0
                },
                {
                    "sent": "Clint Eastwood is an actor is a politician.",
                    "label": 0
                },
                {
                    "sent": "I didn't understand the question.",
                    "label": 0
                },
                {
                    "sent": "So you mean that in the classification of things or the root level?",
                    "label": 0
                },
                {
                    "sent": "Now I didn't understand.",
                    "label": 0
                },
                {
                    "sent": "Could you repeat please?",
                    "label": 0
                },
                {
                    "sent": "So this is you have this use this notion of the most intuitive typo.",
                    "label": 0
                },
                {
                    "sent": "I would call it or describe it like this.",
                    "label": 0
                },
                {
                    "sent": "Like is Clint Eastwood, is he now an actor or is he a politician, right?",
                    "label": 0
                },
                {
                    "sent": "Do you have any data set like a ground truth or gold standard for this?",
                    "label": 0
                },
                {
                    "sent": "OK, in our gold standard we now in there during the annotation we were three annotators, different translators, and we consider the most.",
                    "label": 0
                },
                {
                    "sent": "Come on.",
                    "label": 0
                },
                {
                    "sent": "Class so for example, if listed for design is an actor in IS director of the politician.",
                    "label": 0
                },
                {
                    "sent": "We consider it as an actor.",
                    "label": 0
                },
                {
                    "sent": "Or maybe there is disagreement between us.",
                    "label": 0
                },
                {
                    "sent": "Agreement is not 100% clearly.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "One question I have is when you when you did the evaluation you decided to annotate yourself.",
                    "label": 0
                },
                {
                    "sent": "And I want to know what is the motivation for this versus using.",
                    "label": 0
                },
                {
                    "sent": "A classical, let's say, holdout set that you that you don't use for training.",
                    "label": 0
                },
                {
                    "sent": "So why did you?",
                    "label": 0
                },
                {
                    "sent": "Why did you annotate yourself?",
                    "label": 0
                },
                {
                    "sent": "Because we want to test on pages that are not present in DB pedia.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Well, maybe I don't, but for evaluating your approach you could have as well tested on pages that are available in DB pedia by pretending that you don't.",
                    "label": 0
                },
                {
                    "sent": "Have the annotation by holding it out right now.",
                    "label": 0
                },
                {
                    "sent": "OK. OK so I can cross validation sort of cross validation.",
                    "label": 0
                },
                {
                    "sent": "Yeah, we tried cross validation and it was very very good results.",
                    "label": 0
                },
                {
                    "sent": "Clearly because the training set is biased on this as we use also template to train our system and the pager uses templates.",
                    "label": 0
                },
                {
                    "sent": "We tried this but we had 97 percent 98% of precision.",
                    "label": 0
                },
                {
                    "sent": "We want to test it on.",
                    "label": 0
                },
                {
                    "sent": "On pages that I have not infobox we don't extend the Villa and we also want to give a system that can be used on different languages.",
                    "label": 0
                },
                {
                    "sent": "So language for which we don't have any training in that language.",
                    "label": 0
                },
                {
                    "sent": "So This is why we annotated this pages.",
                    "label": 0
                },
                {
                    "sent": "OK, more questions.",
                    "label": 0
                },
                {
                    "sent": "So then, let's thank the speaker and any other speaker of the session again.",
                    "label": 0
                }
            ]
        }
    }
}