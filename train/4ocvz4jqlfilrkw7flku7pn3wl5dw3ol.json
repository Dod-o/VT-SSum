{
    "id": "4ocvz4jqlfilrkw7flku7pn3wl5dw3ol",
    "title": "Graph Characterization via Backtrackless paths",
    "info": {
        "author": [
            "Richard Wilson, Department of Computer Science, University of York"
        ],
        "published": "Oct. 17, 2011",
        "recorded": "September 2011",
        "category": [
            "Top->Mathematics->Graph Theory"
        ]
    },
    "url": "http://videolectures.net/simbad2011_wilson_backtrackless/",
    "segmentation": [
        [
            "OK, so this is work that I've been doing with for can as is and Edwin."
        ],
        [
            "My cock.",
            "So like the other speakers in this session, I have the compulsory slide on how important graph representations are.",
            "I don't want to really go from repeat what the other speakers have said.",
            "I just had like to add a couple of observations though to what they have said.",
            "So most of the early representations based on graphs were derived from computer vision problems, so feature extraction and then create some kind of geometric representation of the image via Delaunay triangulation or similar type of idea.",
            "The data that we use now is kind of moving away from that and that kind of image based representation is quite a long way removed from the original data.",
            "There's quite a big gap between a graph and the original representation in the image.",
            "Lot of the more recent days are coming from things like bioinformatics in camera informatics, the graph structure is much more inherent in the data, so things like protein, protein interaction networks, representations of molecular structure, the graph representation is very close and really inherent in the data.",
            "Itself, so I think these kind of graph techniques are going to become more and more important as we see more and more of this type of data collected.",
            "OK, so as a kind of counterpoint to the two talks we've seen so far, I'd like to talk a little bit about graph embedding so when we're doing embedding instead of trying to build a structural model of the object, what we're trying to do is find an embedding, either explicit or implicit, of the grass into some kind of feature space.",
            "So we want to represent the graphs as a feature space, or viral Kern or something like that.",
            "So there's two main approaches to solving this problem, so the first I've called this structure approach and that's where we have a explicit structural representation of objects which we then compared to each other.",
            "So we do something like graph matching, compute the edit distance, or have some kind of graph kernel where we explicitly compare the structural parts of the graph with each other to get some kind of similarity or kernel.",
            "If we have a kernel.",
            "Of course we can directly use the kernel in something like a kernel machine to do pattern recognition with.",
            "Otherwise we might want to use some kind of similarity embedding.",
            "In order to create a feature space representing the difference between the objects.",
            "So that relies directly on a structural comparison of the two objects.",
            "The other type of approach is what I call a feature approach, and that's where we try and characterize the graphs individually rather than in comparison with each other.",
            "So we want some kind of features which represented individual graph and then by comparing those features directly in the feature space with each other, we can get some kind of characterization of what the distribution of a set of graphs looks like.",
            "So in the second case, which we don't have, this direct structural comparison, what's going to be important too is the efficiency of calculating those features and their expressive power, so they have to, in some sense reflect the structural characteristics of the graph, and in particular we want to see that the distance in the feature space in some way represents a structural characteristic like the edit distance between the graphs.",
            "So what this talk is really about is is efficient methods for characterizing graphs that don't involve having to do an exhaustive structural search on the graphs."
        ],
        [
            "OK, so I'd like to begin with just by reviewing a little bit some recent developments in graph kernels, so garden in 2003 looked at the idea of creating a random walk kernel.",
            "The idea with random Walk kernel as you look at the power generated by somebody walking at random across a graph.",
            "So you take a sequence of steps, random steps each time, look at the type of cars that are generated, and then if you compare those two paths that you drank from 2 graphs, then you can get a structural characterization of how similar those.",
            "Two graphs are to each other.",
            "So in this kernel formulation we have this matrix AK here, which basically counts the number of walks of vertical length K and this matrix is defined on the product graph.",
            "So I talk a little bit more detail about the product graph later on, But this is a graph formed by merging the two graphs together in such a way that if both walks exist in both graphs, you get and you walk in the product graph.",
            "So this this graph kernel is quite useful, but there are a couple of problems with actually computing it.",
            "So firstly we have this infinite sum over the length of the walks.",
            "So we want to sum up all the walks from length zero to Infinity, which obviously we can't do in practice.",
            "So what we do is we introduce this epsilon parameter and silent parameter down, waits long walks in the graph, so excellent gets smaller as K gets larger and we can truncate the series at some point in order to actually compute the kernel.",
            "The second problem is this product graph can often be quite large, which makes it quite expensive to compute this graph walk kernel.",
            "One important feature of this graph, what kernel I've highlighted here, and that's the problem of tottering.",
            "So if you take a random walk, then sometimes you at the step that you take in your random walk you back to where you originally came from, so we can get walks like I've illustrated here, where we take a step from one Note 2 and X, then back the same way, and then back again, and then we carry on walking.",
            "And this is an example of what we call Tostring.",
            "So we get many of these types of walks that go backwards and forwards, and clearly these don't add anything to the structural information that we gain about the graph because we're just repeating a bit of structure that we've already seen in the graph.",
            "So it doesn't add anything useful, but we still have all these walks there.",
            "So this kind of tostring actually reduces the expressive power of the kernel because we get these these large number of walks that total like this and it reduces the master structural difference between two different graphs."
        ],
        [
            "So as an alternative to try and reduce this problem of tottering.",
            "Path based kernels are introduced, so we define a path to be a sequence of edges such that none of the edges repeat in the path.",
            "So we take a sequence of steps across the graph in the path we get is not allowed to have any repeated edges in it, so by doing that we actually prevent this.",
            "Tottering 'cause we're not allowed to repeat an edge step along an edge of the graph.",
            "So this all past kernel was introduced in 2005, so it's a similar kind of idea, except now we're summing over all the possible paths in the two graphs and then we have a kernel which computes the similarity between those two those two paths.",
            "So the old pass kernel is a true Colonel in the sense it's going to be positive semidefinite Ann, and we can use it as a kernel, but in general it's NP hard to compute all the parts from a particular graph and therefore again we have a problem with actually computing this thing.",
            "So as an alternative, something that's practically computable is easy to use, the shortest path between two vertices of the graph or the K shortest paths, and we can compute that in polynomial time."
        ],
        [
            "So find alternative to random walk based kernels without aerocycle Colonel.",
            "So again, this reduces, tottering or remove tottering from the kernel by looking at cycles within the graph.",
            "So we define a cycle.",
            "Basically to be a path that starts and ends at the same vertex of the graph.",
            "So if we have cycles like this in the graph, we can compute very similar idea, very similar types of kernels by comparing with each of these cycles together.",
            "In the two graphs that we're interested in, so Gardner introduced this in 2000 and four introduced a kernel based on these cycles and also bridges.",
            "So bridges are short connections which connect to these cycles in the graph, and that helps deal with problems in the grass where you have certain sections which don't include any cycles.",
            "And again I'll touch on that point later on when I talk about some of our work.",
            "In general, is still NP complete.",
            "To compute all these cycles, but there are some special graphs where you can actually compute the cycles in polynomial time, depending on the exact structural nature of the graph.",
            "So for certain types of graphs this is a more efficient way of computing the kernel."
        ],
        [
            "OK, so also briefly just like to touch on the idea of graph characterization and very briefly review some of the ideas, alot of which we've tried to develop at York.",
            "So rather than comparing and enumerating all these paths rather than doing a similarity comparison between two graphs, the idea with characterization is to characterize each graph individually and compare the numbers.",
            "The features that we get out of the graphs with each other.",
            "So this graph characterization.",
            "It should measure these structural properties that were interested in.",
            "In a way which is independent from how we label the graph.",
            "So it doesn't matter what order we consider the vertices in, we have to avoid this.",
            "This labeling problem with the graph and if we can do that, we get what we call a graph feature.",
            "So there are several of these graph features which have been developed.",
            "The spectral features.",
            "These essentially use things like the eigenvalues or the eigenvectors of the adjacency matrix or Laplacian of the graph, and these can be used to characterize the graph.",
            "However, there's not a direct structural link between the eigenvalues of the adjacency matrix or the Laplacian, and the characterization of the graph that also algebraic based characterizations.",
            "Things like the coefficients of the characteristic polynomial.",
            "Of adjacency or Laplacian matrices.",
            "And of course some standard topological type characterizations.",
            "So very simple things like the average degree of the graph, the degree distribution, the number of edges, cycle graph diameter, and so on.",
            "These are all numbers that can be used to characterize the graph so that we can compare them with each other.",
            "And then of course, once we have these features, we can compare the features and hopefully get a similarity which in some way.",
            "Simulates the idea of edit distance between the graph."
        ],
        [
            "So one of the earliest attempts to try and provide a characterization of a graph was by the heat kernel, so the heat kernel is very closely related to the idea of random walk on a graph, so this is in some way a characterization which is the analogue of the random walk kernel.",
            "So the heat kernel is the one of the fundamental solutions of the heat equation defined on a graph.",
            "So here the Laplacian operator L is the Laplacian.",
            "In this case the.",
            "Vertex basal passing at the graph, it's an operator which we can use to define a heat equation, and if we find the fundamental solution of heat equation then we find what we call the heat kernel, which is H of T. So this is a matrix which represents the graph and has this parameter T which is time and we can vary the time to get different representations of the graph.",
            "So this is related to the idea of a random walk in the sense that is the limit of a lazy random walk, a certain type of lazy random walk on the graph as the probability of transition to nodes goes to zero and the number of steps goes to Infinity.",
            "So there's a direct relationship between these two things.",
            "So the kernel of course can't be used as a graph characterization on its own, because it still depends on the way in which we label the vertices of the graph.",
            "It's a matrix representation of the graph.",
            "What we can do is look at things like the heat kernel trace.",
            "So if we take the trace of the heat kernel, that doesn't depend on the way we label the vertices of the graph, and we can use it as a characterization, and in fact it's quite a rich characterization because we can vary this time parameter took out a whole set of different characterizations at different times of the graph, and that essentially represents the way in which he.",
            "Will flow across the graph.",
            "So if we start with heat at a certain vertex of the graph and then we look at way that that heat spreads across the graph with time, we get these characterizations based on the trace of the heat kernel.",
            "And in fact, there's a nice representation of this so we can show that it's quite straightforwardly represents related to the eigenvalues of the Laplacian of the graph."
        ],
        [
            "OK, so the heat kernel is is closely related to the idea of doing random walks on graphs, and in fact you can find an explicit formula for that and you can show that the heat kernel could be represented in terms of formula, which is the sum over the path between two vertices on the graph.",
            "So PK is the number of paths of length K which joined the vertices U&V on the graph, and in fact we can find out this path length distribution directly from the eigenvalues of the Laplacian.",
            "So these two things are closely connected to each other and more interesting connection is to the something called the Rosenbergs Eater function.",
            "So we can also show that we can define this Rosenberg Zetor function and fashion I've written up there and this is very closely connected to moments of this heat kernel trace, so we look at the moments of the heat kernel trace.",
            "They depend on the values of this Rosenberg Zetor function.",
            "So this connection to a Zetor function actually motivated this to start looking at."
        ],
        [
            "Other types of data function that we can define on grass, and in particular something called the O'Hara Zetor function.",
            "So this was introduced in 1992 by Bass and then do out further by Catonian.",
            "Sedan are in 2000.",
            "The idea of the Hi Rosita function is basically that analog or the Riemann Zeta function, which involves prime numbers.",
            "So the first thing we have to define for the high resita function is this concept of a prime cycle on a graph.",
            "So I talked a little bit about cycle kernels earlier on, so this is a slightly more restricted idea of water cycle is so prime cycle is a cycle which has no backtracking in it.",
            "And is not a multiple of another cycle defined on the graph.",
            "So on the left hand side here I've got an example of a primary cycle, so straightforwardly go round apart in the graph and return to where we began.",
            "So the one in the middle is not a prime cycle because it has a backtracking step in it where we repeat an edge immediately in our path and the final example on the right again is not a prime cycle because we've gone twice around the same cycle, and therefore it doesn't fit the definition of a prime cycle.",
            "So we're interested in these prime cycles which are defined on the left here."
        ],
        [
            "So as with some of the other kernels I talked about, these prime cycles eliminate some of the weaknesses.",
            "The random walk kernel, because they don't allow tostring, so we don't get these backtracking steps that cause problems in characterizing the structure of the graph.",
            "So the question we're trying to answer is, can we efficiently characterize graphs using prime cycles?",
            "This is work we recently published in TNN along with pen Rang, so the idea is to start from the harazi to function which I've defined here.",
            "So the higher resita function is basically a product, so it's a function of that which has a parameter you and it's a product over all the prime cycles in the graph of this function of you.",
            "So you hear is raised to the power of the length of the prime cycle you're considering.",
            "So it's the number of steps in that prime cycle.",
            "So this is how Rosita function depends purely on the prime cycle links in the graph and therefore it's a graph characterization.",
            "So it doesn't depend on no vertex labeling.",
            "The graph can purely characterize the graph based on these prime cycles, and since these prime cycles don't have backtracking in, it avoids the tottering problem.",
            "But if we want to evaluate this, of course we have to find all these prime cycles, which is a problem."
        ],
        [
            "Fortunately, development of the RAC to function, it was shown.",
            "In fact there are polynomial expressions for this.",
            "Is how Rosita function which depend on matrix representations of the graph.",
            "So we have three representations here.",
            "So at the top is the representation I gave you on the previous slide of the holiday to function as a polynomial representation on the second line, which depends on adjacency matrix A and the node degree matrix Q of the graph and then finally at the bottom there's another representation polynomial representation which depends on the.",
            "Power on from the previous operator, the graph.",
            "So this second line involves the adjacency matrix of the graph, so it has those have the same number of entries as the size of the graph.",
            "This parent Frobenius operator is actually a larger graph, so essentially defined as follows.",
            "It's the adjacency matrix of the oriented line graph of the original graph.",
            "So what we have to do in order to compute this operator is essentially start off with our original graph here on the left.",
            "And then for each edge in the original graph.",
            "So this is an undirected graph, we divide that edge into two directed edges going in either direction will then create the group the jewel of this graph in the middle here by turning each edge of that middle graph into a vertex of the new graph, and then two vertices will be connected if there are two edges in the middle graph which join head to tail.",
            "So if we go through a vertex to another edge, then we make a connection in our rented line graph.",
            "The one exception to that is.",
            "Edges which go along one way and then back in the same direction between two vertices.",
            "These are denoted by these dotted lines here, so they're not connected in the oriented line graph."
        ],
        [
            "OK, so this allows us to compute the matrix T, so T is the adjacency matrix with that oriented line graph and once we have that to hand, we can compute this determinant and we expand it in terms of polynomial.",
            "In this parameter U and once we've done that then we can use these coefficients C nought up to CM in order to characterize the graph in a way that is basically computed from the prime cycles without actually having to compute what the prime cycles at the graph are.",
            "So this is quite a nice way to characterize the graph.",
            "Unfortunately, the naive implementation of this is quite expensive, so because we have to go to this oriented line graph, then the number of nodes in this oriented line graph will be equals number of edges in the original graph and the number of possible edges will be the square of that.",
            "So T can be ordered into the 4th, where N is the number of vertices in the original graph and the running time of such a method would be of the order end to the 12, which is quite expensive.",
            "However, that problem can be overcome.",
            "We showed how to do that in recent K paper using Bell polynomials, so they provide an efficient way to actually compute this.",
            "This ahara Zetor function."
        ],
        [
            "Representation.",
            "OK, so just a quick summary of Bihar's.",
            "Each function is very powerful tool for representing graphs and we've shown that it's very useful for embedding graphs using these kind of harazi function characterizations.",
            "These coefficients that we get.",
            "It's linked directly to topological quantities because it's computed by these prime cycles, so the length of the prime cycle is really the turbins.",
            "The values of these coefficients.",
            "It's what we called an edge based representation because we transfer from the original graph to this oriented line graph, which is based on connections between the edges rather than the vertices of the original graph.",
            "And in that sense, it's got some very interesting connections to other works we did on quantum walks, so we showed that considering our quantum walk on a graph can actually lift Co spectrality of certain types of graphs which are difficult to tell apart and the idea of a quantum walk has very close analogies with this idea of an oriented line graph and the characterization of that.",
            "Also it has connections to the other types of characterizations I talked about, so there's a correct connection to the spectral polynomials that we published in Palm in 2005, and there's a natural extension to things like hyper graph.",
            "So it's a very flexible tool for characterizing graphs."
        ],
        [
            "OK, so a couple of observations so removing this backtracking step, this tottering that you get from random walks, provide you this Richard description of the graphs and by using prime cycles in the Rosita function we can avoid backtracking.",
            "And it turns out that because of the specific way which we define these cycles, you can find an efficient way of evaluating this whole Rosita function.",
            "So in that sense is a very powerful tool.",
            "Unfortunately it has limited applicability to certain types of graph.",
            "So the reason for that is that basically given here.",
            "So if we have a tree for example, then there are no cycles in the tree and therefore we can't use any horror see to function to characterize it because we simply get nothing, we have no prime cycles.",
            "OK, so we might not want to use it to evaluate trees, but of course if we have a graph that has any kind of tree like component to it, so any leaves any vertices with degree one, then we can't characterize that part of the graph because they don't participate in any of these prime cycles in the graph, and so it has a week.",
            "Some parts of the graph it can't characterize properly."
        ],
        [
            "So that led us to go back and look at the idea of random walks again and see if we could define a way of computing the back track list random walk on a graph.",
            "So a random walk is essentially a sequence of length K, or vertices of the graph.",
            "So we step through these these vertices at random U1U2 up to UK plus one such that each of those pair of vertices corresponds to an edge in the graph.",
            "So we always walk down an edge of the graph.",
            "In a back track list walk, we add the additional condition that the edge that we traverse next cannot be the same as the edge we've just reversed, so we're not allowed to take this step backwards.",
            "So essentially we can think of this work is being a sequence of oriented edges in the graph.",
            "So instead of stepping across vertices along edges, we can think about stepping along edges of the graph such that the next edge is not the same as the previous one that we traversed.",
            "So in fact that's exactly what we encoded in this idea of the oriented line graph.",
            "So we converted the edges to vertices of this oriented line graph.",
            "We remove these edges.",
            "These dotted lines here, which corresponds to the backtracking step.",
            "So if we take a walk on this oriented line graph.",
            "Then automatically will get a back track list random walk, so that's the essential idea behind these backtrack list walks.",
            "We generate this oriented line graph and then if we walk across that, it prevents backtracking."
        ],
        [
            "So just a quick word about labeling unlabeled graphs.",
            "So a lot of the data we use, it is.",
            "If it's unlabeled variety on the left, so each of the vertex of the graph is the same as any other vertex in the sense we don't have any information about 1 being different from another.",
            "There are other types of data, so this example on the right is the other type of data that we use in experimental studies later.",
            "This is a labeled graph, so each of those vertices is labeled by an Atom type.",
            "So if we compare walks on the right hand side, we only want to allow walks where their label types of the same in each of these two walks.",
            "So while we can use a characterization on the left hand side on the right hand side where we have these labeled walks, we actually need to compare the walks with each other so we can only really use a kernel representation for the walks on the right."
        ],
        [
            "OK, so this is the definition of the back track list.",
            "Random walk kernel.",
            "So we formed this oriented line graph of the product graph.",
            "So this is where I define the product graph.",
            "The product graph has a vertex set which consists of pair of vertices, one from each of the two graphs that we want to compare with each other and it has an edge set consisting of the pair of vertices from the product graph where these verses will be joined to each other if the edge exists in both the first graph and the second graph between these two verses.",
            "So where the education both graphs?",
            "Then we connect up the edge in the product graph.",
            "OK, so this is the product graph and we're going to generate this product graph from this oriented line graph, which prevents backtracking steps when we consider a random walks.",
            "So the idea is to transform its graph into the oriented line graph and then form the product graph and compute the random walk kernel as described at the top there and then by eliminating these reverse edges in the oriented line graph.",
            "Then we prevent the backtracking step."
        ],
        [
            "So, as I mentioned before, complexity rapidly becomes a problem if you take this kind of approach.",
            "So Vertex set of the product graph will be N squared and the edge set of the products graph will be 10 to the 4th.",
            "And then if we try and compute this random walk kernel on this, essentially it will take me to the 12 steps which is very expensive way of doing it.",
            "So it turns out that she's more efficient way of computing these back track list random walks directly on the original graphs rather than actually having to transform the oriented line graph.",
            "So this is given by the recursion at the bottom here for the Matrix A.",
            "So for walks of length one, so a so AK is defined as the number of walks of length K which join two of the vertices in our graph.",
            "So if I if K is equal to 1, this is obviously just given by the adjacency matrix.",
            "There's one walk between any pair of us is joined by an edge.",
            "If K is 2, then it's a ^2 -- Q + I.",
            "So again Q.",
            "Here is the degree matrix of the graph.",
            "If K is greater than two, then we can use a recursion to efficiently compute the number of walks.",
            "So it tells us a K is a K -- 1 * A -- 8 K minus 2 * Q, so this is very inefficient way of computing these number of back track list walks in the graph without actually having to compute the oriented line graph, and therefore it's a much more efficient way of doing it because we're only using N versus rather than squared vertices."
        ],
        [
            "OK, so just do a brief word about kernels and characterizations so we can use this matrix both in the sense of using a kernel and in using a characterization so the kernel is basically exactly what I've described so far.",
            "So we have the number of walks we have this epsilon parameter which truncates the series at a finite level finite length of walk, and from that we can compute the kernel of the comparison between two graphs.",
            "We can also provide a characterization of the graph using the back track list random walk, essentially just by counting the total number of walks of length K over all pairs of us is in the graph.",
            "So if we take this characterization and sum it up over all pairs inj, then we count the total number of back track list walks in the graph."
        ],
        [
            "OK, so finally just some experiments.",
            "So firstly with synthetic graphs.",
            "So what we're trying to do here is firstly show the most important thing and that is that these characterizations, via random walks, actually reflect in some way the edit distance between the graphs.",
            "So on the left here we've got along the bottom, the edit distance between pairs of graphs and up the side we have the feature distance, i.e.",
            "The distance between our characterization from random walks.",
            "So on the left is the random walk.",
            "And on the right is the back track list random walk and pleasingly can see there's quite a strong correlation between the graph edit distance between these graphs and the feature distance, so it's a good analogue of the edit distance through these feature computations.",
            "So both these walks into produce, reproduce the edit distance well."
        ],
        [
            "How we look more closely we can see that the correspondence between edit distance and feature distance is not exact.",
            "There are some random variation in there.",
            "If we look more closely at the random variation, we can see that this random variation is smallest for the back track list random wall, so it seems to give a more stable representation of edit distance than the other types of representation."
        ],
        [
            "So we also looked at a couple of real world datasets so the coil data set has already been mentioned before.",
            "We also have this mutagenesis data set which is based on chemical compounds, so straightforward graph representation and in the mutagenesis data set we have the possibility of using labels as well.",
            "Because we have these Atom labels on the vertices and the task there is to try and predict whether compound will generate mutations or not."
        ],
        [
            "OK, so these are results we obtained so.",
            "On all of these different types of data, so the coil data, mutagenesis, data, both unlabeled and labeled, that our feature vector and our kernel from backtrack list random walks, outperforms the other alternatives.",
            "So the random walk kernel, the ahara coefficients in even the shortest path Colonel, so the results look very effective and they seem to give an improvement over these other types of representation."
        ],
        [
            "The other important thing with these kernels, of course is the running time of them.",
            "So the idea of opposing the back track list random walk in this way was to try and prevent provide an efficient characterization efficient in time characterization of the graphs so the random walk is all render the 6th, and the experiments took nine or just under 10 seconds.",
            "The back track list walk using our proposed method was slightly slower than 12 seconds, but if we do the back track list walk.",
            "Using the naive method with the oriented line graph, then it takes over 300 seconds, so it gives us an efficient characterization which is more effective than the other ways."
        ],
        [
            "So just quick conclusions.",
            "Backtrack list walks seem to be more robust to noise when compared to random walks.",
            "We can provide these efficient ways of computing back track list random walks through these matrix recursions and they seem to give us a better characterization of graph structures than random walk.",
            "Shortest path walk.",
            "Sandy.",
            "How rosita function?",
            "K and thank you very much."
        ],
        [
            "Adam, I was wondering with the backtrack this random walk animal.",
            "Could you envision particular classes of graphs or whether one would outperform created the other hand and vice versa in terms of comparison between random and back track list?",
            "OK, let's say when it comes to being actual transportation forms.",
            "Whether there's certainly there's a clear difference between types of graphs which performed well with the whole Rosita function and the random walk type kernels.",
            "Because of this problem of having cycles are not in the graph.",
            "So if you have something like Adele on a graph which is composed purely in terms of cycles, triangles in the graph, then the whole Rosita function can be very effective on those and is effective.",
            "Is the other method when you have other things like shape skeletons that Luca talked about.",
            "Of course there trees and so they are busy to function is useless.",
            "But most graphs of course are somewhere in between those two, so the random walk has the advantage of being to explore the tree like parts of the graph rather than just the cycle parts of the graph.",
            "In terms of the difference between backtrack lists, random walks and the traditional random walks, the central difference is this problem of tottering in the graph.",
            "So where you have a lot of these past that torture, and then a small structural difference at the end, you'd expect the back track list random walk to outperform the normal random walk.",
            "But in terms of actually fighting a set of examples where these examples will perform well and these examples won't perform well, I think that's quite a difficult problem.",
            "Or is it a very interesting problem, but one that we have not looked in?",
            "Detail at.",
            "So while reading the Horseshoe, Defunction overlooks the three nights structure.",
            "So what is it actually they measured?",
            "You know anything about this graph problems?",
            "The tree as a backbone is sort of measuring the most dominant statistically dependency structure, and it's also efficiently computable if you think of belief propagation algorithms running on such a substructure, you can also approximate with mixtures of trees efficient probability distribution and more complex graphs, and so it's a little weird senses that characterization by the system function, they are complementary.",
            "Or is it actual measurement range?",
            "I think to a certain extent that that was the type of problem that's addressed in this idea of cycle and bridge kernels, which I talked briefly about the start of my talk.",
            "So the idea there was to characterize part of the graphs which have these cycle structures in it by something like Bihar azita function.",
            "Although their version was purely based on cycles, but then have these bridges which are structural connections which are non cycle like the tree tree, like parts of the graph which connect these cycle parts.",
            "So I think it might be a very profitable direction to look in whether you can actually identify the parts of graphs that can be characterized by Harris Teeter function type characterizations, and then the other parts which aren't characterized in the same way that you could look at walk like kernels for.",
            "So are there any indications that this is basically measure within the convex part of grass?",
            "You know where they barely have his loopy structure, which actually could give rise to to non convergence of belief propagation type of methods?",
            "Our Zeta function yeah.",
            "It overlooks the tree path in the 3 pounds easy.",
            "I think that's an interesting idea in the coefficients that we obtained from the arsita function are related specifically to the number of certain types of cycles.",
            "So the number of triangles, the number of squares, and in fact if you look at the low order coefficients, they're very directly related to the number of triangles or the number of cycles.",
            "For the first few, if you look at some of the higher order coefficients, they rapidly become much more complicated, and so it's hard to extract specific information about cycle structure from those, but I think that's an interesting idea that maybe you can characterize.",
            "Certain types of graphs that are difficult for loopy belief propagation, for example by looking at the Yarra characterization of those parts.",
            "OK, I think we have to leave this thing which is less than the three just to speak with her."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so this is work that I've been doing with for can as is and Edwin.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "My cock.",
                    "label": 0
                },
                {
                    "sent": "So like the other speakers in this session, I have the compulsory slide on how important graph representations are.",
                    "label": 0
                },
                {
                    "sent": "I don't want to really go from repeat what the other speakers have said.",
                    "label": 0
                },
                {
                    "sent": "I just had like to add a couple of observations though to what they have said.",
                    "label": 0
                },
                {
                    "sent": "So most of the early representations based on graphs were derived from computer vision problems, so feature extraction and then create some kind of geometric representation of the image via Delaunay triangulation or similar type of idea.",
                    "label": 0
                },
                {
                    "sent": "The data that we use now is kind of moving away from that and that kind of image based representation is quite a long way removed from the original data.",
                    "label": 0
                },
                {
                    "sent": "There's quite a big gap between a graph and the original representation in the image.",
                    "label": 0
                },
                {
                    "sent": "Lot of the more recent days are coming from things like bioinformatics in camera informatics, the graph structure is much more inherent in the data, so things like protein, protein interaction networks, representations of molecular structure, the graph representation is very close and really inherent in the data.",
                    "label": 0
                },
                {
                    "sent": "Itself, so I think these kind of graph techniques are going to become more and more important as we see more and more of this type of data collected.",
                    "label": 0
                },
                {
                    "sent": "OK, so as a kind of counterpoint to the two talks we've seen so far, I'd like to talk a little bit about graph embedding so when we're doing embedding instead of trying to build a structural model of the object, what we're trying to do is find an embedding, either explicit or implicit, of the grass into some kind of feature space.",
                    "label": 0
                },
                {
                    "sent": "So we want to represent the graphs as a feature space, or viral Kern or something like that.",
                    "label": 0
                },
                {
                    "sent": "So there's two main approaches to solving this problem, so the first I've called this structure approach and that's where we have a explicit structural representation of objects which we then compared to each other.",
                    "label": 0
                },
                {
                    "sent": "So we do something like graph matching, compute the edit distance, or have some kind of graph kernel where we explicitly compare the structural parts of the graph with each other to get some kind of similarity or kernel.",
                    "label": 1
                },
                {
                    "sent": "If we have a kernel.",
                    "label": 0
                },
                {
                    "sent": "Of course we can directly use the kernel in something like a kernel machine to do pattern recognition with.",
                    "label": 0
                },
                {
                    "sent": "Otherwise we might want to use some kind of similarity embedding.",
                    "label": 0
                },
                {
                    "sent": "In order to create a feature space representing the difference between the objects.",
                    "label": 0
                },
                {
                    "sent": "So that relies directly on a structural comparison of the two objects.",
                    "label": 0
                },
                {
                    "sent": "The other type of approach is what I call a feature approach, and that's where we try and characterize the graphs individually rather than in comparison with each other.",
                    "label": 0
                },
                {
                    "sent": "So we want some kind of features which represented individual graph and then by comparing those features directly in the feature space with each other, we can get some kind of characterization of what the distribution of a set of graphs looks like.",
                    "label": 0
                },
                {
                    "sent": "So in the second case, which we don't have, this direct structural comparison, what's going to be important too is the efficiency of calculating those features and their expressive power, so they have to, in some sense reflect the structural characteristics of the graph, and in particular we want to see that the distance in the feature space in some way represents a structural characteristic like the edit distance between the graphs.",
                    "label": 0
                },
                {
                    "sent": "So what this talk is really about is is efficient methods for characterizing graphs that don't involve having to do an exhaustive structural search on the graphs.",
                    "label": 1
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so I'd like to begin with just by reviewing a little bit some recent developments in graph kernels, so garden in 2003 looked at the idea of creating a random walk kernel.",
                    "label": 1
                },
                {
                    "sent": "The idea with random Walk kernel as you look at the power generated by somebody walking at random across a graph.",
                    "label": 0
                },
                {
                    "sent": "So you take a sequence of steps, random steps each time, look at the type of cars that are generated, and then if you compare those two paths that you drank from 2 graphs, then you can get a structural characterization of how similar those.",
                    "label": 1
                },
                {
                    "sent": "Two graphs are to each other.",
                    "label": 0
                },
                {
                    "sent": "So in this kernel formulation we have this matrix AK here, which basically counts the number of walks of vertical length K and this matrix is defined on the product graph.",
                    "label": 0
                },
                {
                    "sent": "So I talk a little bit more detail about the product graph later on, But this is a graph formed by merging the two graphs together in such a way that if both walks exist in both graphs, you get and you walk in the product graph.",
                    "label": 0
                },
                {
                    "sent": "So this this graph kernel is quite useful, but there are a couple of problems with actually computing it.",
                    "label": 0
                },
                {
                    "sent": "So firstly we have this infinite sum over the length of the walks.",
                    "label": 0
                },
                {
                    "sent": "So we want to sum up all the walks from length zero to Infinity, which obviously we can't do in practice.",
                    "label": 0
                },
                {
                    "sent": "So what we do is we introduce this epsilon parameter and silent parameter down, waits long walks in the graph, so excellent gets smaller as K gets larger and we can truncate the series at some point in order to actually compute the kernel.",
                    "label": 0
                },
                {
                    "sent": "The second problem is this product graph can often be quite large, which makes it quite expensive to compute this graph walk kernel.",
                    "label": 0
                },
                {
                    "sent": "One important feature of this graph, what kernel I've highlighted here, and that's the problem of tottering.",
                    "label": 1
                },
                {
                    "sent": "So if you take a random walk, then sometimes you at the step that you take in your random walk you back to where you originally came from, so we can get walks like I've illustrated here, where we take a step from one Note 2 and X, then back the same way, and then back again, and then we carry on walking.",
                    "label": 0
                },
                {
                    "sent": "And this is an example of what we call Tostring.",
                    "label": 0
                },
                {
                    "sent": "So we get many of these types of walks that go backwards and forwards, and clearly these don't add anything to the structural information that we gain about the graph because we're just repeating a bit of structure that we've already seen in the graph.",
                    "label": 0
                },
                {
                    "sent": "So it doesn't add anything useful, but we still have all these walks there.",
                    "label": 0
                },
                {
                    "sent": "So this kind of tostring actually reduces the expressive power of the kernel because we get these these large number of walks that total like this and it reduces the master structural difference between two different graphs.",
                    "label": 1
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So as an alternative to try and reduce this problem of tottering.",
                    "label": 0
                },
                {
                    "sent": "Path based kernels are introduced, so we define a path to be a sequence of edges such that none of the edges repeat in the path.",
                    "label": 1
                },
                {
                    "sent": "So we take a sequence of steps across the graph in the path we get is not allowed to have any repeated edges in it, so by doing that we actually prevent this.",
                    "label": 0
                },
                {
                    "sent": "Tottering 'cause we're not allowed to repeat an edge step along an edge of the graph.",
                    "label": 0
                },
                {
                    "sent": "So this all past kernel was introduced in 2005, so it's a similar kind of idea, except now we're summing over all the possible paths in the two graphs and then we have a kernel which computes the similarity between those two those two paths.",
                    "label": 1
                },
                {
                    "sent": "So the old pass kernel is a true Colonel in the sense it's going to be positive semidefinite Ann, and we can use it as a kernel, but in general it's NP hard to compute all the parts from a particular graph and therefore again we have a problem with actually computing this thing.",
                    "label": 0
                },
                {
                    "sent": "So as an alternative, something that's practically computable is easy to use, the shortest path between two vertices of the graph or the K shortest paths, and we can compute that in polynomial time.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So find alternative to random walk based kernels without aerocycle Colonel.",
                    "label": 0
                },
                {
                    "sent": "So again, this reduces, tottering or remove tottering from the kernel by looking at cycles within the graph.",
                    "label": 0
                },
                {
                    "sent": "So we define a cycle.",
                    "label": 0
                },
                {
                    "sent": "Basically to be a path that starts and ends at the same vertex of the graph.",
                    "label": 1
                },
                {
                    "sent": "So if we have cycles like this in the graph, we can compute very similar idea, very similar types of kernels by comparing with each of these cycles together.",
                    "label": 1
                },
                {
                    "sent": "In the two graphs that we're interested in, so Gardner introduced this in 2000 and four introduced a kernel based on these cycles and also bridges.",
                    "label": 0
                },
                {
                    "sent": "So bridges are short connections which connect to these cycles in the graph, and that helps deal with problems in the grass where you have certain sections which don't include any cycles.",
                    "label": 0
                },
                {
                    "sent": "And again I'll touch on that point later on when I talk about some of our work.",
                    "label": 0
                },
                {
                    "sent": "In general, is still NP complete.",
                    "label": 0
                },
                {
                    "sent": "To compute all these cycles, but there are some special graphs where you can actually compute the cycles in polynomial time, depending on the exact structural nature of the graph.",
                    "label": 0
                },
                {
                    "sent": "So for certain types of graphs this is a more efficient way of computing the kernel.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so also briefly just like to touch on the idea of graph characterization and very briefly review some of the ideas, alot of which we've tried to develop at York.",
                    "label": 0
                },
                {
                    "sent": "So rather than comparing and enumerating all these paths rather than doing a similarity comparison between two graphs, the idea with characterization is to characterize each graph individually and compare the numbers.",
                    "label": 0
                },
                {
                    "sent": "The features that we get out of the graphs with each other.",
                    "label": 0
                },
                {
                    "sent": "So this graph characterization.",
                    "label": 0
                },
                {
                    "sent": "It should measure these structural properties that were interested in.",
                    "label": 0
                },
                {
                    "sent": "In a way which is independent from how we label the graph.",
                    "label": 0
                },
                {
                    "sent": "So it doesn't matter what order we consider the vertices in, we have to avoid this.",
                    "label": 0
                },
                {
                    "sent": "This labeling problem with the graph and if we can do that, we get what we call a graph feature.",
                    "label": 0
                },
                {
                    "sent": "So there are several of these graph features which have been developed.",
                    "label": 0
                },
                {
                    "sent": "The spectral features.",
                    "label": 0
                },
                {
                    "sent": "These essentially use things like the eigenvalues or the eigenvectors of the adjacency matrix or Laplacian of the graph, and these can be used to characterize the graph.",
                    "label": 1
                },
                {
                    "sent": "However, there's not a direct structural link between the eigenvalues of the adjacency matrix or the Laplacian, and the characterization of the graph that also algebraic based characterizations.",
                    "label": 0
                },
                {
                    "sent": "Things like the coefficients of the characteristic polynomial.",
                    "label": 1
                },
                {
                    "sent": "Of adjacency or Laplacian matrices.",
                    "label": 0
                },
                {
                    "sent": "And of course some standard topological type characterizations.",
                    "label": 0
                },
                {
                    "sent": "So very simple things like the average degree of the graph, the degree distribution, the number of edges, cycle graph diameter, and so on.",
                    "label": 0
                },
                {
                    "sent": "These are all numbers that can be used to characterize the graph so that we can compare them with each other.",
                    "label": 0
                },
                {
                    "sent": "And then of course, once we have these features, we can compare the features and hopefully get a similarity which in some way.",
                    "label": 0
                },
                {
                    "sent": "Simulates the idea of edit distance between the graph.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So one of the earliest attempts to try and provide a characterization of a graph was by the heat kernel, so the heat kernel is very closely related to the idea of random walk on a graph, so this is in some way a characterization which is the analogue of the random walk kernel.",
                    "label": 1
                },
                {
                    "sent": "So the heat kernel is the one of the fundamental solutions of the heat equation defined on a graph.",
                    "label": 0
                },
                {
                    "sent": "So here the Laplacian operator L is the Laplacian.",
                    "label": 0
                },
                {
                    "sent": "In this case the.",
                    "label": 0
                },
                {
                    "sent": "Vertex basal passing at the graph, it's an operator which we can use to define a heat equation, and if we find the fundamental solution of heat equation then we find what we call the heat kernel, which is H of T. So this is a matrix which represents the graph and has this parameter T which is time and we can vary the time to get different representations of the graph.",
                    "label": 0
                },
                {
                    "sent": "So this is related to the idea of a random walk in the sense that is the limit of a lazy random walk, a certain type of lazy random walk on the graph as the probability of transition to nodes goes to zero and the number of steps goes to Infinity.",
                    "label": 0
                },
                {
                    "sent": "So there's a direct relationship between these two things.",
                    "label": 1
                },
                {
                    "sent": "So the kernel of course can't be used as a graph characterization on its own, because it still depends on the way in which we label the vertices of the graph.",
                    "label": 1
                },
                {
                    "sent": "It's a matrix representation of the graph.",
                    "label": 0
                },
                {
                    "sent": "What we can do is look at things like the heat kernel trace.",
                    "label": 0
                },
                {
                    "sent": "So if we take the trace of the heat kernel, that doesn't depend on the way we label the vertices of the graph, and we can use it as a characterization, and in fact it's quite a rich characterization because we can vary this time parameter took out a whole set of different characterizations at different times of the graph, and that essentially represents the way in which he.",
                    "label": 0
                },
                {
                    "sent": "Will flow across the graph.",
                    "label": 0
                },
                {
                    "sent": "So if we start with heat at a certain vertex of the graph and then we look at way that that heat spreads across the graph with time, we get these characterizations based on the trace of the heat kernel.",
                    "label": 0
                },
                {
                    "sent": "And in fact, there's a nice representation of this so we can show that it's quite straightforwardly represents related to the eigenvalues of the Laplacian of the graph.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so the heat kernel is is closely related to the idea of doing random walks on graphs, and in fact you can find an explicit formula for that and you can show that the heat kernel could be represented in terms of formula, which is the sum over the path between two vertices on the graph.",
                    "label": 0
                },
                {
                    "sent": "So PK is the number of paths of length K which joined the vertices U&V on the graph, and in fact we can find out this path length distribution directly from the eigenvalues of the Laplacian.",
                    "label": 0
                },
                {
                    "sent": "So these two things are closely connected to each other and more interesting connection is to the something called the Rosenbergs Eater function.",
                    "label": 0
                },
                {
                    "sent": "So we can also show that we can define this Rosenberg Zetor function and fashion I've written up there and this is very closely connected to moments of this heat kernel trace, so we look at the moments of the heat kernel trace.",
                    "label": 1
                },
                {
                    "sent": "They depend on the values of this Rosenberg Zetor function.",
                    "label": 0
                },
                {
                    "sent": "So this connection to a Zetor function actually motivated this to start looking at.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Other types of data function that we can define on grass, and in particular something called the O'Hara Zetor function.",
                    "label": 0
                },
                {
                    "sent": "So this was introduced in 1992 by Bass and then do out further by Catonian.",
                    "label": 0
                },
                {
                    "sent": "Sedan are in 2000.",
                    "label": 0
                },
                {
                    "sent": "The idea of the Hi Rosita function is basically that analog or the Riemann Zeta function, which involves prime numbers.",
                    "label": 0
                },
                {
                    "sent": "So the first thing we have to define for the high resita function is this concept of a prime cycle on a graph.",
                    "label": 0
                },
                {
                    "sent": "So I talked a little bit about cycle kernels earlier on, so this is a slightly more restricted idea of water cycle is so prime cycle is a cycle which has no backtracking in it.",
                    "label": 0
                },
                {
                    "sent": "And is not a multiple of another cycle defined on the graph.",
                    "label": 1
                },
                {
                    "sent": "So on the left hand side here I've got an example of a primary cycle, so straightforwardly go round apart in the graph and return to where we began.",
                    "label": 0
                },
                {
                    "sent": "So the one in the middle is not a prime cycle because it has a backtracking step in it where we repeat an edge immediately in our path and the final example on the right again is not a prime cycle because we've gone twice around the same cycle, and therefore it doesn't fit the definition of a prime cycle.",
                    "label": 0
                },
                {
                    "sent": "So we're interested in these prime cycles which are defined on the left here.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So as with some of the other kernels I talked about, these prime cycles eliminate some of the weaknesses.",
                    "label": 1
                },
                {
                    "sent": "The random walk kernel, because they don't allow tostring, so we don't get these backtracking steps that cause problems in characterizing the structure of the graph.",
                    "label": 0
                },
                {
                    "sent": "So the question we're trying to answer is, can we efficiently characterize graphs using prime cycles?",
                    "label": 1
                },
                {
                    "sent": "This is work we recently published in TNN along with pen Rang, so the idea is to start from the harazi to function which I've defined here.",
                    "label": 0
                },
                {
                    "sent": "So the higher resita function is basically a product, so it's a function of that which has a parameter you and it's a product over all the prime cycles in the graph of this function of you.",
                    "label": 0
                },
                {
                    "sent": "So you hear is raised to the power of the length of the prime cycle you're considering.",
                    "label": 1
                },
                {
                    "sent": "So it's the number of steps in that prime cycle.",
                    "label": 0
                },
                {
                    "sent": "So this is how Rosita function depends purely on the prime cycle links in the graph and therefore it's a graph characterization.",
                    "label": 0
                },
                {
                    "sent": "So it doesn't depend on no vertex labeling.",
                    "label": 1
                },
                {
                    "sent": "The graph can purely characterize the graph based on these prime cycles, and since these prime cycles don't have backtracking in, it avoids the tottering problem.",
                    "label": 0
                },
                {
                    "sent": "But if we want to evaluate this, of course we have to find all these prime cycles, which is a problem.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Fortunately, development of the RAC to function, it was shown.",
                    "label": 0
                },
                {
                    "sent": "In fact there are polynomial expressions for this.",
                    "label": 1
                },
                {
                    "sent": "Is how Rosita function which depend on matrix representations of the graph.",
                    "label": 0
                },
                {
                    "sent": "So we have three representations here.",
                    "label": 0
                },
                {
                    "sent": "So at the top is the representation I gave you on the previous slide of the holiday to function as a polynomial representation on the second line, which depends on adjacency matrix A and the node degree matrix Q of the graph and then finally at the bottom there's another representation polynomial representation which depends on the.",
                    "label": 0
                },
                {
                    "sent": "Power on from the previous operator, the graph.",
                    "label": 0
                },
                {
                    "sent": "So this second line involves the adjacency matrix of the graph, so it has those have the same number of entries as the size of the graph.",
                    "label": 0
                },
                {
                    "sent": "This parent Frobenius operator is actually a larger graph, so essentially defined as follows.",
                    "label": 0
                },
                {
                    "sent": "It's the adjacency matrix of the oriented line graph of the original graph.",
                    "label": 1
                },
                {
                    "sent": "So what we have to do in order to compute this operator is essentially start off with our original graph here on the left.",
                    "label": 0
                },
                {
                    "sent": "And then for each edge in the original graph.",
                    "label": 0
                },
                {
                    "sent": "So this is an undirected graph, we divide that edge into two directed edges going in either direction will then create the group the jewel of this graph in the middle here by turning each edge of that middle graph into a vertex of the new graph, and then two vertices will be connected if there are two edges in the middle graph which join head to tail.",
                    "label": 0
                },
                {
                    "sent": "So if we go through a vertex to another edge, then we make a connection in our rented line graph.",
                    "label": 0
                },
                {
                    "sent": "The one exception to that is.",
                    "label": 0
                },
                {
                    "sent": "Edges which go along one way and then back in the same direction between two vertices.",
                    "label": 0
                },
                {
                    "sent": "These are denoted by these dotted lines here, so they're not connected in the oriented line graph.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so this allows us to compute the matrix T, so T is the adjacency matrix with that oriented line graph and once we have that to hand, we can compute this determinant and we expand it in terms of polynomial.",
                    "label": 0
                },
                {
                    "sent": "In this parameter U and once we've done that then we can use these coefficients C nought up to CM in order to characterize the graph in a way that is basically computed from the prime cycles without actually having to compute what the prime cycles at the graph are.",
                    "label": 0
                },
                {
                    "sent": "So this is quite a nice way to characterize the graph.",
                    "label": 1
                },
                {
                    "sent": "Unfortunately, the naive implementation of this is quite expensive, so because we have to go to this oriented line graph, then the number of nodes in this oriented line graph will be equals number of edges in the original graph and the number of possible edges will be the square of that.",
                    "label": 0
                },
                {
                    "sent": "So T can be ordered into the 4th, where N is the number of vertices in the original graph and the running time of such a method would be of the order end to the 12, which is quite expensive.",
                    "label": 1
                },
                {
                    "sent": "However, that problem can be overcome.",
                    "label": 0
                },
                {
                    "sent": "We showed how to do that in recent K paper using Bell polynomials, so they provide an efficient way to actually compute this.",
                    "label": 1
                },
                {
                    "sent": "This ahara Zetor function.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Representation.",
                    "label": 0
                },
                {
                    "sent": "OK, so just a quick summary of Bihar's.",
                    "label": 0
                },
                {
                    "sent": "Each function is very powerful tool for representing graphs and we've shown that it's very useful for embedding graphs using these kind of harazi function characterizations.",
                    "label": 1
                },
                {
                    "sent": "These coefficients that we get.",
                    "label": 1
                },
                {
                    "sent": "It's linked directly to topological quantities because it's computed by these prime cycles, so the length of the prime cycle is really the turbins.",
                    "label": 0
                },
                {
                    "sent": "The values of these coefficients.",
                    "label": 1
                },
                {
                    "sent": "It's what we called an edge based representation because we transfer from the original graph to this oriented line graph, which is based on connections between the edges rather than the vertices of the original graph.",
                    "label": 0
                },
                {
                    "sent": "And in that sense, it's got some very interesting connections to other works we did on quantum walks, so we showed that considering our quantum walk on a graph can actually lift Co spectrality of certain types of graphs which are difficult to tell apart and the idea of a quantum walk has very close analogies with this idea of an oriented line graph and the characterization of that.",
                    "label": 0
                },
                {
                    "sent": "Also it has connections to the other types of characterizations I talked about, so there's a correct connection to the spectral polynomials that we published in Palm in 2005, and there's a natural extension to things like hyper graph.",
                    "label": 0
                },
                {
                    "sent": "So it's a very flexible tool for characterizing graphs.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so a couple of observations so removing this backtracking step, this tottering that you get from random walks, provide you this Richard description of the graphs and by using prime cycles in the Rosita function we can avoid backtracking.",
                    "label": 0
                },
                {
                    "sent": "And it turns out that because of the specific way which we define these cycles, you can find an efficient way of evaluating this whole Rosita function.",
                    "label": 0
                },
                {
                    "sent": "So in that sense is a very powerful tool.",
                    "label": 0
                },
                {
                    "sent": "Unfortunately it has limited applicability to certain types of graph.",
                    "label": 1
                },
                {
                    "sent": "So the reason for that is that basically given here.",
                    "label": 0
                },
                {
                    "sent": "So if we have a tree for example, then there are no cycles in the tree and therefore we can't use any horror see to function to characterize it because we simply get nothing, we have no prime cycles.",
                    "label": 0
                },
                {
                    "sent": "OK, so we might not want to use it to evaluate trees, but of course if we have a graph that has any kind of tree like component to it, so any leaves any vertices with degree one, then we can't characterize that part of the graph because they don't participate in any of these prime cycles in the graph, and so it has a week.",
                    "label": 1
                },
                {
                    "sent": "Some parts of the graph it can't characterize properly.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So that led us to go back and look at the idea of random walks again and see if we could define a way of computing the back track list random walk on a graph.",
                    "label": 0
                },
                {
                    "sent": "So a random walk is essentially a sequence of length K, or vertices of the graph.",
                    "label": 1
                },
                {
                    "sent": "So we step through these these vertices at random U1U2 up to UK plus one such that each of those pair of vertices corresponds to an edge in the graph.",
                    "label": 0
                },
                {
                    "sent": "So we always walk down an edge of the graph.",
                    "label": 0
                },
                {
                    "sent": "In a back track list walk, we add the additional condition that the edge that we traverse next cannot be the same as the edge we've just reversed, so we're not allowed to take this step backwards.",
                    "label": 1
                },
                {
                    "sent": "So essentially we can think of this work is being a sequence of oriented edges in the graph.",
                    "label": 0
                },
                {
                    "sent": "So instead of stepping across vertices along edges, we can think about stepping along edges of the graph such that the next edge is not the same as the previous one that we traversed.",
                    "label": 0
                },
                {
                    "sent": "So in fact that's exactly what we encoded in this idea of the oriented line graph.",
                    "label": 0
                },
                {
                    "sent": "So we converted the edges to vertices of this oriented line graph.",
                    "label": 0
                },
                {
                    "sent": "We remove these edges.",
                    "label": 0
                },
                {
                    "sent": "These dotted lines here, which corresponds to the backtracking step.",
                    "label": 0
                },
                {
                    "sent": "So if we take a walk on this oriented line graph.",
                    "label": 0
                },
                {
                    "sent": "Then automatically will get a back track list random walk, so that's the essential idea behind these backtrack list walks.",
                    "label": 0
                },
                {
                    "sent": "We generate this oriented line graph and then if we walk across that, it prevents backtracking.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So just a quick word about labeling unlabeled graphs.",
                    "label": 0
                },
                {
                    "sent": "So a lot of the data we use, it is.",
                    "label": 0
                },
                {
                    "sent": "If it's unlabeled variety on the left, so each of the vertex of the graph is the same as any other vertex in the sense we don't have any information about 1 being different from another.",
                    "label": 0
                },
                {
                    "sent": "There are other types of data, so this example on the right is the other type of data that we use in experimental studies later.",
                    "label": 0
                },
                {
                    "sent": "This is a labeled graph, so each of those vertices is labeled by an Atom type.",
                    "label": 0
                },
                {
                    "sent": "So if we compare walks on the right hand side, we only want to allow walks where their label types of the same in each of these two walks.",
                    "label": 0
                },
                {
                    "sent": "So while we can use a characterization on the left hand side on the right hand side where we have these labeled walks, we actually need to compare the walks with each other so we can only really use a kernel representation for the walks on the right.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so this is the definition of the back track list.",
                    "label": 0
                },
                {
                    "sent": "Random walk kernel.",
                    "label": 0
                },
                {
                    "sent": "So we formed this oriented line graph of the product graph.",
                    "label": 0
                },
                {
                    "sent": "So this is where I define the product graph.",
                    "label": 1
                },
                {
                    "sent": "The product graph has a vertex set which consists of pair of vertices, one from each of the two graphs that we want to compare with each other and it has an edge set consisting of the pair of vertices from the product graph where these verses will be joined to each other if the edge exists in both the first graph and the second graph between these two verses.",
                    "label": 0
                },
                {
                    "sent": "So where the education both graphs?",
                    "label": 0
                },
                {
                    "sent": "Then we connect up the edge in the product graph.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is the product graph and we're going to generate this product graph from this oriented line graph, which prevents backtracking steps when we consider a random walks.",
                    "label": 0
                },
                {
                    "sent": "So the idea is to transform its graph into the oriented line graph and then form the product graph and compute the random walk kernel as described at the top there and then by eliminating these reverse edges in the oriented line graph.",
                    "label": 1
                },
                {
                    "sent": "Then we prevent the backtracking step.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So, as I mentioned before, complexity rapidly becomes a problem if you take this kind of approach.",
                    "label": 1
                },
                {
                    "sent": "So Vertex set of the product graph will be N squared and the edge set of the products graph will be 10 to the 4th.",
                    "label": 0
                },
                {
                    "sent": "And then if we try and compute this random walk kernel on this, essentially it will take me to the 12 steps which is very expensive way of doing it.",
                    "label": 0
                },
                {
                    "sent": "So it turns out that she's more efficient way of computing these back track list random walks directly on the original graphs rather than actually having to transform the oriented line graph.",
                    "label": 0
                },
                {
                    "sent": "So this is given by the recursion at the bottom here for the Matrix A.",
                    "label": 1
                },
                {
                    "sent": "So for walks of length one, so a so AK is defined as the number of walks of length K which join two of the vertices in our graph.",
                    "label": 1
                },
                {
                    "sent": "So if I if K is equal to 1, this is obviously just given by the adjacency matrix.",
                    "label": 1
                },
                {
                    "sent": "There's one walk between any pair of us is joined by an edge.",
                    "label": 0
                },
                {
                    "sent": "If K is 2, then it's a ^2 -- Q + I.",
                    "label": 0
                },
                {
                    "sent": "So again Q.",
                    "label": 0
                },
                {
                    "sent": "Here is the degree matrix of the graph.",
                    "label": 1
                },
                {
                    "sent": "If K is greater than two, then we can use a recursion to efficiently compute the number of walks.",
                    "label": 0
                },
                {
                    "sent": "So it tells us a K is a K -- 1 * A -- 8 K minus 2 * Q, so this is very inefficient way of computing these number of back track list walks in the graph without actually having to compute the oriented line graph, and therefore it's a much more efficient way of doing it because we're only using N versus rather than squared vertices.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so just do a brief word about kernels and characterizations so we can use this matrix both in the sense of using a kernel and in using a characterization so the kernel is basically exactly what I've described so far.",
                    "label": 1
                },
                {
                    "sent": "So we have the number of walks we have this epsilon parameter which truncates the series at a finite level finite length of walk, and from that we can compute the kernel of the comparison between two graphs.",
                    "label": 0
                },
                {
                    "sent": "We can also provide a characterization of the graph using the back track list random walk, essentially just by counting the total number of walks of length K over all pairs of us is in the graph.",
                    "label": 1
                },
                {
                    "sent": "So if we take this characterization and sum it up over all pairs inj, then we count the total number of back track list walks in the graph.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so finally just some experiments.",
                    "label": 0
                },
                {
                    "sent": "So firstly with synthetic graphs.",
                    "label": 1
                },
                {
                    "sent": "So what we're trying to do here is firstly show the most important thing and that is that these characterizations, via random walks, actually reflect in some way the edit distance between the graphs.",
                    "label": 0
                },
                {
                    "sent": "So on the left here we've got along the bottom, the edit distance between pairs of graphs and up the side we have the feature distance, i.e.",
                    "label": 0
                },
                {
                    "sent": "The distance between our characterization from random walks.",
                    "label": 0
                },
                {
                    "sent": "So on the left is the random walk.",
                    "label": 0
                },
                {
                    "sent": "And on the right is the back track list random walk and pleasingly can see there's quite a strong correlation between the graph edit distance between these graphs and the feature distance, so it's a good analogue of the edit distance through these feature computations.",
                    "label": 1
                },
                {
                    "sent": "So both these walks into produce, reproduce the edit distance well.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "How we look more closely we can see that the correspondence between edit distance and feature distance is not exact.",
                    "label": 0
                },
                {
                    "sent": "There are some random variation in there.",
                    "label": 0
                },
                {
                    "sent": "If we look more closely at the random variation, we can see that this random variation is smallest for the back track list random wall, so it seems to give a more stable representation of edit distance than the other types of representation.",
                    "label": 1
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we also looked at a couple of real world datasets so the coil data set has already been mentioned before.",
                    "label": 1
                },
                {
                    "sent": "We also have this mutagenesis data set which is based on chemical compounds, so straightforward graph representation and in the mutagenesis data set we have the possibility of using labels as well.",
                    "label": 0
                },
                {
                    "sent": "Because we have these Atom labels on the vertices and the task there is to try and predict whether compound will generate mutations or not.",
                    "label": 1
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so these are results we obtained so.",
                    "label": 0
                },
                {
                    "sent": "On all of these different types of data, so the coil data, mutagenesis, data, both unlabeled and labeled, that our feature vector and our kernel from backtrack list random walks, outperforms the other alternatives.",
                    "label": 0
                },
                {
                    "sent": "So the random walk kernel, the ahara coefficients in even the shortest path Colonel, so the results look very effective and they seem to give an improvement over these other types of representation.",
                    "label": 1
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The other important thing with these kernels, of course is the running time of them.",
                    "label": 1
                },
                {
                    "sent": "So the idea of opposing the back track list random walk in this way was to try and prevent provide an efficient characterization efficient in time characterization of the graphs so the random walk is all render the 6th, and the experiments took nine or just under 10 seconds.",
                    "label": 1
                },
                {
                    "sent": "The back track list walk using our proposed method was slightly slower than 12 seconds, but if we do the back track list walk.",
                    "label": 0
                },
                {
                    "sent": "Using the naive method with the oriented line graph, then it takes over 300 seconds, so it gives us an efficient characterization which is more effective than the other ways.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So just quick conclusions.",
                    "label": 0
                },
                {
                    "sent": "Backtrack list walks seem to be more robust to noise when compared to random walks.",
                    "label": 1
                },
                {
                    "sent": "We can provide these efficient ways of computing back track list random walks through these matrix recursions and they seem to give us a better characterization of graph structures than random walk.",
                    "label": 0
                },
                {
                    "sent": "Shortest path walk.",
                    "label": 0
                },
                {
                    "sent": "Sandy.",
                    "label": 0
                },
                {
                    "sent": "How rosita function?",
                    "label": 0
                },
                {
                    "sent": "K and thank you very much.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Adam, I was wondering with the backtrack this random walk animal.",
                    "label": 0
                },
                {
                    "sent": "Could you envision particular classes of graphs or whether one would outperform created the other hand and vice versa in terms of comparison between random and back track list?",
                    "label": 0
                },
                {
                    "sent": "OK, let's say when it comes to being actual transportation forms.",
                    "label": 0
                },
                {
                    "sent": "Whether there's certainly there's a clear difference between types of graphs which performed well with the whole Rosita function and the random walk type kernels.",
                    "label": 0
                },
                {
                    "sent": "Because of this problem of having cycles are not in the graph.",
                    "label": 0
                },
                {
                    "sent": "So if you have something like Adele on a graph which is composed purely in terms of cycles, triangles in the graph, then the whole Rosita function can be very effective on those and is effective.",
                    "label": 0
                },
                {
                    "sent": "Is the other method when you have other things like shape skeletons that Luca talked about.",
                    "label": 0
                },
                {
                    "sent": "Of course there trees and so they are busy to function is useless.",
                    "label": 0
                },
                {
                    "sent": "But most graphs of course are somewhere in between those two, so the random walk has the advantage of being to explore the tree like parts of the graph rather than just the cycle parts of the graph.",
                    "label": 0
                },
                {
                    "sent": "In terms of the difference between backtrack lists, random walks and the traditional random walks, the central difference is this problem of tottering in the graph.",
                    "label": 0
                },
                {
                    "sent": "So where you have a lot of these past that torture, and then a small structural difference at the end, you'd expect the back track list random walk to outperform the normal random walk.",
                    "label": 0
                },
                {
                    "sent": "But in terms of actually fighting a set of examples where these examples will perform well and these examples won't perform well, I think that's quite a difficult problem.",
                    "label": 0
                },
                {
                    "sent": "Or is it a very interesting problem, but one that we have not looked in?",
                    "label": 0
                },
                {
                    "sent": "Detail at.",
                    "label": 0
                },
                {
                    "sent": "So while reading the Horseshoe, Defunction overlooks the three nights structure.",
                    "label": 0
                },
                {
                    "sent": "So what is it actually they measured?",
                    "label": 0
                },
                {
                    "sent": "You know anything about this graph problems?",
                    "label": 0
                },
                {
                    "sent": "The tree as a backbone is sort of measuring the most dominant statistically dependency structure, and it's also efficiently computable if you think of belief propagation algorithms running on such a substructure, you can also approximate with mixtures of trees efficient probability distribution and more complex graphs, and so it's a little weird senses that characterization by the system function, they are complementary.",
                    "label": 0
                },
                {
                    "sent": "Or is it actual measurement range?",
                    "label": 0
                },
                {
                    "sent": "I think to a certain extent that that was the type of problem that's addressed in this idea of cycle and bridge kernels, which I talked briefly about the start of my talk.",
                    "label": 0
                },
                {
                    "sent": "So the idea there was to characterize part of the graphs which have these cycle structures in it by something like Bihar azita function.",
                    "label": 0
                },
                {
                    "sent": "Although their version was purely based on cycles, but then have these bridges which are structural connections which are non cycle like the tree tree, like parts of the graph which connect these cycle parts.",
                    "label": 0
                },
                {
                    "sent": "So I think it might be a very profitable direction to look in whether you can actually identify the parts of graphs that can be characterized by Harris Teeter function type characterizations, and then the other parts which aren't characterized in the same way that you could look at walk like kernels for.",
                    "label": 0
                },
                {
                    "sent": "So are there any indications that this is basically measure within the convex part of grass?",
                    "label": 0
                },
                {
                    "sent": "You know where they barely have his loopy structure, which actually could give rise to to non convergence of belief propagation type of methods?",
                    "label": 0
                },
                {
                    "sent": "Our Zeta function yeah.",
                    "label": 0
                },
                {
                    "sent": "It overlooks the tree path in the 3 pounds easy.",
                    "label": 0
                },
                {
                    "sent": "I think that's an interesting idea in the coefficients that we obtained from the arsita function are related specifically to the number of certain types of cycles.",
                    "label": 0
                },
                {
                    "sent": "So the number of triangles, the number of squares, and in fact if you look at the low order coefficients, they're very directly related to the number of triangles or the number of cycles.",
                    "label": 0
                },
                {
                    "sent": "For the first few, if you look at some of the higher order coefficients, they rapidly become much more complicated, and so it's hard to extract specific information about cycle structure from those, but I think that's an interesting idea that maybe you can characterize.",
                    "label": 0
                },
                {
                    "sent": "Certain types of graphs that are difficult for loopy belief propagation, for example by looking at the Yarra characterization of those parts.",
                    "label": 0
                },
                {
                    "sent": "OK, I think we have to leave this thing which is less than the three just to speak with her.",
                    "label": 0
                }
            ]
        }
    }
}