{
    "id": "pbnaihvdark53me6wrzqppsa3nqisgid",
    "title": "Probabilistic Models for Data Combination in Recommender Systems",
    "info": {
        "author": [
            "Sinead Williamson, University of Texas at Austin"
        ],
        "published": "Dec. 20, 2008",
        "recorded": "December 2008",
        "category": [
            "Top->Computer Science->Machine Learning"
        ]
    },
    "url": "http://videolectures.net/lms08_williamson_pmdc/",
    "segmentation": [
        [
            "So sooner wilsonians Uber money back there for ballistic models with data combination in recommender systems.",
            "Thanks very much, OK?",
            "I'm sure everyone here is familiar with the record."
        ],
        [
            "Station problem where we have some set of users and some set of items and I've always predict which items are given.",
            "User will like.",
            "Now we've got several sorts of data which can help us in this problem.",
            "So most importantly, we've got ratings data, which is some indication of how much a user will use his like other items.",
            "We might also have information which is specific about the items, so if our items and movies we might have cost lists or genre information or reviews, or if our items, their electronic goods, we might have technical specifications for example.",
            "We might also have information about our users, so we could have demographic information such as their age or where they live, or information from social network data."
        ],
        [
            "So there are two main approaches to the recommendation problem, collaborative filtering and content based filtering.",
            "So collaborative filtering the idea is to use the information about which items users of light before to make predictions of what items they were like in future.",
            "Oh this method in general works really, really well.",
            "Um?",
            "Those of you who follow the Netflix prize, no, it doesn't work quite $1,000,000 well yet, but it's really closely collaborative.",
            "Filtering generally works very well because it captures in general both the features of an item, so whether a movie it will recommend horror movies, people you like, horror movies, but also differentiate between a good horror movie in a bad horror movie?",
            "However, it does have problems and the main problems are what do we do?",
            "We've got a new movie which we haven't, which was rated before or what do we do?",
            "Have a new user comes along?",
            "He hasn't made any movies yet.",
            "What do you recommend in that case?",
            "Now.",
            "In one sense, these are edge problems, but they're quite important problems because if your business is recommending movies, you really want to recommend the new movies to people.",
            "And if you've got a website that recommends things to people you want to make sure that new people stay with your system rather than realize oh, the ratings are the recommendations of rubbish on move on someone elses recommended system.",
            "So this is quite a problem with collaborative methods.",
            "On the other hand, we have content based methods and content based filtering.",
            "We look at what items are users like and recommend items that are similar to the ones that that users liked in some measure of similarity based on the content of the items.",
            "And this has the advantage that we can extend to new items very easily, doesn't match of non rated movie provided we've got data about what actors are in it or what genre it is or.",
            "The reviews on IMDb or whatever.",
            "And in general, content based filtering's really good at capturing genre and type information.",
            "But their less good.",
            "At.",
            "Way back will get less good at.",
            "I didn't find the quality of an item so telling between that good horror movie in the bad horror movie.",
            "So it seems that these two approaches have complementary advantages and problems, so we were looking for a method to combine these two approaches to recommendation."
        ],
        [
            "Now, matrix factorization is quite commonly used approach in recommender systems, especially in collaborative filtering.",
            "And the basic idea here is we you are.",
            "Ratings data as a incomplete matrix containing the ratings given by the users to the M Movies and we try to factorize this matrix is the product of 2 lower rank matrices here A&B, where a is you by K&B is K by M. And we use some.",
            "Pushing forward too.",
            "Drive the ratings from this product for the two matrices."
        ],
        [
            "So we extend that we can extend this idea to factor multiple matrices at the same time.",
            "So here I've demonstrated how we can factorize a partially observed ratings matrix R and a fully observed contents matrix S. In here R is vector product of NBS is product, these factorized as the product of B&C and the latent matrix B is constrained to be common to both matrices.",
            "Now here I've shown it for just two matrices.",
            "But if we had in addition to our content matrix S, IF we also had some demographic information, we could add another matrix to the left of this diagram constrain matters.",
            "I guess going backwards for me would be easy by a matrix where a is common between the.",
            "Make the user matrix and the ratings matrix are."
        ],
        [
            "So.",
            "Um?",
            "We can take this model and use as our form for the matrix factorization.",
            "We can use a linear Gaussian case is pretty much the simplest.",
            "Approach we can take with this model where we have the ratings matrix are the entries of.",
            "This are Gaussian distributed with mean given by the product of the A&B matrix and some variance.",
            "The squared and similarly the S matrix is given by Gaussian distributed with mean C * B.",
            "In order to form Bayesian inference in this, we put priors on the.",
            "Latent matrices AB&C and we choose these priors to be 0 mean Gaussian.",
            "We can use variational Bayes to perform inference in this model.",
            "This works out very nicely.",
            "We simply use.",
            "We introduce a variational distribution Q of a BNC.",
            "We use Jensen inequality to lower bound to log likelihood on the marginal likelihood.",
            "We then introduce our one main approximation, which is, we assume that our variational distribution can be factorized into the product of the individual distributions on a BMC.",
            "If we do this, we see that the variational distributions are also Gaussian, and we can derive the updates for the means and variances of these variational distributions on a B&C we hold.",
            "Two constant and update A, then B, then C in turn until we've got convergence."
        ],
        [
            "And this is exactly what we did on the movielens data set.",
            "So here the movie on stage set is a data set of around 1000 users and around 1000 half movies.",
            "Where we've got 100,000 ratings in total, that's what we use our partially reserve ratings matrix.",
            "Obviously without content data included with the Movielens data set, there is a. AA.",
            "At binary genre set of genre information where each movie is associated with zero or more of a set of genres.",
            "We learned this model using the variational approach I just described and compare.",
            "We also used the equivalent variational approach just using the ratings data and we used the.",
            "J rank algorithm are Priscilla Cone Hoffman, which is a kernel method for jointly learning the content in the collaborative data.",
            "To learn the ordinal classifications for this, and we also used a set of naive Bayes classifiers.",
            "One classifier for each user, where we train this classifier using the content data and got it to predict the ratings.",
            "Um?",
            "So in our first experiment, we randomly held out third of the test data and.",
            "Predicted the held out data and calculated the RSC on this held up data and we found that our model outperformed the other three models which.",
            "Was.",
            "A nice finding, but this kind of wasn't the problem that motivated us to look at this problem in the first place.",
            "So if you recall.",
            "One things that.",
            "Made us interested in combining content and collaborative data.",
            "Was the fact that collaborative filtering alone generally works poorly.",
            "When we've got a new movie or a new item.",
            "So we wanted to have a way of finding out well.",
            "How is our method perform on a new movie?",
            "So to do this we took the movie on his data and simulated the effect of a new movie.",
            "And it's only just really being released and hardly has any ratings yet.",
            "So out of our data set we chose 200 movies around at random out of the set of all movies that had over 200 ratings.",
            "And we removed almost all at the ratings for these movies, leaving behind between North and 10 ratings.",
            "For these two 100 movies, so this was to make a movie that only a handful of people have yet reviewed.",
            "We then predicted the remaining held out data using the four methods as before, and here we found a more significant improvement in the joint metrics factorization method where we were including the content and the.",
            "Pirated data rather than just the collaborative data and compared with the other two methods that can be for combining content in collaborative data.",
            "So.",
            "This is very nice."
        ],
        [
            "However, we've made a big assumption, which is that our data is nice and friendly and Gaussian.",
            "Which is always nice and convenient, but it's not always appropriate.",
            "Probably a reasonable model for the rating station movie Lens.",
            "But there are many situations where it's less appropriate.",
            "So for example, if you have rather than ratings, you have some sort of implicit preference given by the number of times a user listening to online radio has listened to a certain artist or a certain song.",
            "You might think that's more likely to be plus on distributed than Gaussian distributed, and similarly, if you don't have ratings data, you just have information about whether a user is bought or not a certain item.",
            "If you have a new distribution would be more appropriate.",
            "So.",
            "We've started off with the Bayesian exponential family PCA model, which was presented by Muhammad's whole earlier in the main conference.",
            "To allow inference in the general exponential factor, general exponential family case of learning multiple matrices.",
            "So Bayesian exponential family PCA.",
            "Is a. Xbox One PCA method where the matrix R is represents the natural parameters of the exponential family.",
            "We've chosen to use to represent our data.",
            "So."
        ],
        [
            "This is shown here.",
            "The are on my blue.",
            "Matrix hasn't shown up here, but imagine there's an R on that blue circle if you will.",
            "So here we have the R matrix is.",
            "Drawn from the exponential family.",
            "Parameterized by a linear combination of the vectors B and the vectors A, where B is drawn from the family conjugate to the exponential family, and a is scale set of.",
            "Scaling vectors, which are drawn from a Gaussian distribution and.",
            "On our Gaussian distribution we put a Gaussian prior on the mean and a inverse gamma prior prior on the variance.",
            "So.",
            "This is Beijing next match family PCA."
        ],
        [
            "We can extend this to multiple matrices.",
            "By holding the well, we can send this to multiple matrices in one of two ways, either in the way that I've described here, where we have two are two matrices or partial reserve rating data and are fully observed content data being from the same exponential family where we hold the conjugate distribution common in between the two.",
            "Macy's and we have separate Gaussian scaling factors for the two matrices.",
            "Or if we believe we have different exponential families, we could obviously switch the order had the Gaussian distribution common and have a separate exponential.",
            "This has separate conjugate.",
            "Family distribution for each matrix.",
            "Now the log joint probability in this model is continuous, which means we can perform efficient inference using hybrid Monte Carlo.",
            "We currently carrying out results in this.",
            "Our results are very flimsy so our data set for this data is for this model is playcount data from the movie from the.",
            "Music recommendation system.",
            "Last FM.",
            "Last FM.",
            "For those who aren't familiar with it, makes counts of what artists, what music you play on your computer.",
            "And it.",
            "You can use the data to get a count data of how many times given users listen to a certain artist and this we used as our content data or sorry, our collaborative data for the content data also on the last FM site, users can assign tags to certain artists like rock and jazz and terrible music and indie and whatever.",
            "So we used.",
            "The Joint Exponential family representation.",
            "To learn the two pots on distributed matrices in this book in this problem, so our results are still preliminary, but we've found our results so far suggests that there's if we.",
            "Mimic the GNU artist case, in this case, where we remove most of the data for new artists and system, we achieve a significant improvement in the long predicted probability.",
            "In recommending these new artists.",
            "Um?",
            "The IF we take the data at random unfortunately.",
            "There is less clear an advantage over the single matrix factorization, but it certainly seems to be a definite improvement in the case of GNU artists in the system.",
            "So."
        ],
        [
            "To conclude, collaborative filtering often forms poorly in the case of new items or new users.",
            "And using joint factorization of multiple matrices using common latent matrices, we can combine the content and ratings data in a reasonable manner, which by doing so we can improve performance, particularly in the case of a new item.",
            "We've described inference using both the Gaussian case using Variational Bayes and general exponential family case using hybrid Monte Carlo and well.",
            "The experiments have shown here have only used the case of two matrices.",
            "Our model can easily be extended to include further information.",
            "For example, we're currently looking at including demographic and social network data.",
            "Thank you any questions.",
            "What's the score?",
            "My dear.",
            "Offhand, I'm not sure.",
            "But certainly I mean the the single matrix factorization is effective as a variational Bayesian.",
            "Version of the probabilistic matrix factorization method which.",
            "Was presented last year NIPS and this year it I CML, which achieved very good results.",
            "So generally the idea of.",
            "Basic factor probabilistic matrix factorization for movie prediction performs well so but I don't know exactly how well predicting random does.",
            "I know it's the normal thing when you're looking at these rating systems to to look at auto Masters.",
            "The error across the whole set of your test data.",
            "But there was a couple of papers that Rex is this year where they make this.",
            "We obvious point, which is that the important recommendations to get right at the strongly positive recommendations astronomy positive rating.",
            "So there's a notion that if The thing is being correct in predicting A3 on a scale of 1 to 5, but that's not.",
            "Important because you're not going to action that you're not going to recommend that to the user and instead was really important.",
            "So that's really important is when you're predicting force implies that you're right.",
            "Now you're missing.",
            "The real force applies in the days there, so it would be worth.",
            "Maybe looking at that as an alternative loss function based on that you're entirely right.",
            "And like almost everyone working this, I've been entirely influenced by the fact that Netflix users are messy, but it's definitely a good point that this is maybe not the right way to look at it.",
            "Whether it's a good idea."
        ],
        [
            "To predict whether someone really hate a movie or in qualitative movie, that's not so in or be indifferent to a movie.",
            "So yeah, that's a very good point, but we've only looked at Arma 3 on that."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So sooner wilsonians Uber money back there for ballistic models with data combination in recommender systems.",
                    "label": 1
                },
                {
                    "sent": "Thanks very much, OK?",
                    "label": 0
                },
                {
                    "sent": "I'm sure everyone here is familiar with the record.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Station problem where we have some set of users and some set of items and I've always predict which items are given.",
                    "label": 1
                },
                {
                    "sent": "User will like.",
                    "label": 0
                },
                {
                    "sent": "Now we've got several sorts of data which can help us in this problem.",
                    "label": 1
                },
                {
                    "sent": "So most importantly, we've got ratings data, which is some indication of how much a user will use his like other items.",
                    "label": 0
                },
                {
                    "sent": "We might also have information which is specific about the items, so if our items and movies we might have cost lists or genre information or reviews, or if our items, their electronic goods, we might have technical specifications for example.",
                    "label": 1
                },
                {
                    "sent": "We might also have information about our users, so we could have demographic information such as their age or where they live, or information from social network data.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So there are two main approaches to the recommendation problem, collaborative filtering and content based filtering.",
                    "label": 0
                },
                {
                    "sent": "So collaborative filtering the idea is to use the information about which items users of light before to make predictions of what items they were like in future.",
                    "label": 1
                },
                {
                    "sent": "Oh this method in general works really, really well.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Those of you who follow the Netflix prize, no, it doesn't work quite $1,000,000 well yet, but it's really closely collaborative.",
                    "label": 1
                },
                {
                    "sent": "Filtering generally works very well because it captures in general both the features of an item, so whether a movie it will recommend horror movies, people you like, horror movies, but also differentiate between a good horror movie in a bad horror movie?",
                    "label": 1
                },
                {
                    "sent": "However, it does have problems and the main problems are what do we do?",
                    "label": 0
                },
                {
                    "sent": "We've got a new movie which we haven't, which was rated before or what do we do?",
                    "label": 0
                },
                {
                    "sent": "Have a new user comes along?",
                    "label": 0
                },
                {
                    "sent": "He hasn't made any movies yet.",
                    "label": 0
                },
                {
                    "sent": "What do you recommend in that case?",
                    "label": 0
                },
                {
                    "sent": "Now.",
                    "label": 1
                },
                {
                    "sent": "In one sense, these are edge problems, but they're quite important problems because if your business is recommending movies, you really want to recommend the new movies to people.",
                    "label": 0
                },
                {
                    "sent": "And if you've got a website that recommends things to people you want to make sure that new people stay with your system rather than realize oh, the ratings are the recommendations of rubbish on move on someone elses recommended system.",
                    "label": 0
                },
                {
                    "sent": "So this is quite a problem with collaborative methods.",
                    "label": 0
                },
                {
                    "sent": "On the other hand, we have content based methods and content based filtering.",
                    "label": 0
                },
                {
                    "sent": "We look at what items are users like and recommend items that are similar to the ones that that users liked in some measure of similarity based on the content of the items.",
                    "label": 1
                },
                {
                    "sent": "And this has the advantage that we can extend to new items very easily, doesn't match of non rated movie provided we've got data about what actors are in it or what genre it is or.",
                    "label": 0
                },
                {
                    "sent": "The reviews on IMDb or whatever.",
                    "label": 0
                },
                {
                    "sent": "And in general, content based filtering's really good at capturing genre and type information.",
                    "label": 0
                },
                {
                    "sent": "But their less good.",
                    "label": 0
                },
                {
                    "sent": "At.",
                    "label": 0
                },
                {
                    "sent": "Way back will get less good at.",
                    "label": 0
                },
                {
                    "sent": "I didn't find the quality of an item so telling between that good horror movie in the bad horror movie.",
                    "label": 0
                },
                {
                    "sent": "So it seems that these two approaches have complementary advantages and problems, so we were looking for a method to combine these two approaches to recommendation.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now, matrix factorization is quite commonly used approach in recommender systems, especially in collaborative filtering.",
                    "label": 1
                },
                {
                    "sent": "And the basic idea here is we you are.",
                    "label": 0
                },
                {
                    "sent": "Ratings data as a incomplete matrix containing the ratings given by the users to the M Movies and we try to factorize this matrix is the product of 2 lower rank matrices here A&B, where a is you by K&B is K by M. And we use some.",
                    "label": 1
                },
                {
                    "sent": "Pushing forward too.",
                    "label": 0
                },
                {
                    "sent": "Drive the ratings from this product for the two matrices.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we extend that we can extend this idea to factor multiple matrices at the same time.",
                    "label": 1
                },
                {
                    "sent": "So here I've demonstrated how we can factorize a partially observed ratings matrix R and a fully observed contents matrix S. In here R is vector product of NBS is product, these factorized as the product of B&C and the latent matrix B is constrained to be common to both matrices.",
                    "label": 0
                },
                {
                    "sent": "Now here I've shown it for just two matrices.",
                    "label": 0
                },
                {
                    "sent": "But if we had in addition to our content matrix S, IF we also had some demographic information, we could add another matrix to the left of this diagram constrain matters.",
                    "label": 0
                },
                {
                    "sent": "I guess going backwards for me would be easy by a matrix where a is common between the.",
                    "label": 0
                },
                {
                    "sent": "Make the user matrix and the ratings matrix are.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "We can take this model and use as our form for the matrix factorization.",
                    "label": 0
                },
                {
                    "sent": "We can use a linear Gaussian case is pretty much the simplest.",
                    "label": 0
                },
                {
                    "sent": "Approach we can take with this model where we have the ratings matrix are the entries of.",
                    "label": 0
                },
                {
                    "sent": "This are Gaussian distributed with mean given by the product of the A&B matrix and some variance.",
                    "label": 0
                },
                {
                    "sent": "The squared and similarly the S matrix is given by Gaussian distributed with mean C * B.",
                    "label": 0
                },
                {
                    "sent": "In order to form Bayesian inference in this, we put priors on the.",
                    "label": 0
                },
                {
                    "sent": "Latent matrices AB&C and we choose these priors to be 0 mean Gaussian.",
                    "label": 0
                },
                {
                    "sent": "We can use variational Bayes to perform inference in this model.",
                    "label": 0
                },
                {
                    "sent": "This works out very nicely.",
                    "label": 0
                },
                {
                    "sent": "We simply use.",
                    "label": 0
                },
                {
                    "sent": "We introduce a variational distribution Q of a BNC.",
                    "label": 0
                },
                {
                    "sent": "We use Jensen inequality to lower bound to log likelihood on the marginal likelihood.",
                    "label": 0
                },
                {
                    "sent": "We then introduce our one main approximation, which is, we assume that our variational distribution can be factorized into the product of the individual distributions on a BMC.",
                    "label": 0
                },
                {
                    "sent": "If we do this, we see that the variational distributions are also Gaussian, and we can derive the updates for the means and variances of these variational distributions on a B&C we hold.",
                    "label": 0
                },
                {
                    "sent": "Two constant and update A, then B, then C in turn until we've got convergence.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And this is exactly what we did on the movielens data set.",
                    "label": 0
                },
                {
                    "sent": "So here the movie on stage set is a data set of around 1000 users and around 1000 half movies.",
                    "label": 0
                },
                {
                    "sent": "Where we've got 100,000 ratings in total, that's what we use our partially reserve ratings matrix.",
                    "label": 0
                },
                {
                    "sent": "Obviously without content data included with the Movielens data set, there is a. AA.",
                    "label": 0
                },
                {
                    "sent": "At binary genre set of genre information where each movie is associated with zero or more of a set of genres.",
                    "label": 0
                },
                {
                    "sent": "We learned this model using the variational approach I just described and compare.",
                    "label": 0
                },
                {
                    "sent": "We also used the equivalent variational approach just using the ratings data and we used the.",
                    "label": 0
                },
                {
                    "sent": "J rank algorithm are Priscilla Cone Hoffman, which is a kernel method for jointly learning the content in the collaborative data.",
                    "label": 0
                },
                {
                    "sent": "To learn the ordinal classifications for this, and we also used a set of naive Bayes classifiers.",
                    "label": 1
                },
                {
                    "sent": "One classifier for each user, where we train this classifier using the content data and got it to predict the ratings.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "So in our first experiment, we randomly held out third of the test data and.",
                    "label": 0
                },
                {
                    "sent": "Predicted the held out data and calculated the RSC on this held up data and we found that our model outperformed the other three models which.",
                    "label": 0
                },
                {
                    "sent": "Was.",
                    "label": 0
                },
                {
                    "sent": "A nice finding, but this kind of wasn't the problem that motivated us to look at this problem in the first place.",
                    "label": 0
                },
                {
                    "sent": "So if you recall.",
                    "label": 0
                },
                {
                    "sent": "One things that.",
                    "label": 0
                },
                {
                    "sent": "Made us interested in combining content and collaborative data.",
                    "label": 0
                },
                {
                    "sent": "Was the fact that collaborative filtering alone generally works poorly.",
                    "label": 0
                },
                {
                    "sent": "When we've got a new movie or a new item.",
                    "label": 0
                },
                {
                    "sent": "So we wanted to have a way of finding out well.",
                    "label": 0
                },
                {
                    "sent": "How is our method perform on a new movie?",
                    "label": 0
                },
                {
                    "sent": "So to do this we took the movie on his data and simulated the effect of a new movie.",
                    "label": 0
                },
                {
                    "sent": "And it's only just really being released and hardly has any ratings yet.",
                    "label": 0
                },
                {
                    "sent": "So out of our data set we chose 200 movies around at random out of the set of all movies that had over 200 ratings.",
                    "label": 1
                },
                {
                    "sent": "And we removed almost all at the ratings for these movies, leaving behind between North and 10 ratings.",
                    "label": 1
                },
                {
                    "sent": "For these two 100 movies, so this was to make a movie that only a handful of people have yet reviewed.",
                    "label": 0
                },
                {
                    "sent": "We then predicted the remaining held out data using the four methods as before, and here we found a more significant improvement in the joint metrics factorization method where we were including the content and the.",
                    "label": 0
                },
                {
                    "sent": "Pirated data rather than just the collaborative data and compared with the other two methods that can be for combining content in collaborative data.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "This is very nice.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "However, we've made a big assumption, which is that our data is nice and friendly and Gaussian.",
                    "label": 0
                },
                {
                    "sent": "Which is always nice and convenient, but it's not always appropriate.",
                    "label": 0
                },
                {
                    "sent": "Probably a reasonable model for the rating station movie Lens.",
                    "label": 0
                },
                {
                    "sent": "But there are many situations where it's less appropriate.",
                    "label": 0
                },
                {
                    "sent": "So for example, if you have rather than ratings, you have some sort of implicit preference given by the number of times a user listening to online radio has listened to a certain artist or a certain song.",
                    "label": 0
                },
                {
                    "sent": "You might think that's more likely to be plus on distributed than Gaussian distributed, and similarly, if you don't have ratings data, you just have information about whether a user is bought or not a certain item.",
                    "label": 0
                },
                {
                    "sent": "If you have a new distribution would be more appropriate.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "We've started off with the Bayesian exponential family PCA model, which was presented by Muhammad's whole earlier in the main conference.",
                    "label": 0
                },
                {
                    "sent": "To allow inference in the general exponential factor, general exponential family case of learning multiple matrices.",
                    "label": 1
                },
                {
                    "sent": "So Bayesian exponential family PCA.",
                    "label": 1
                },
                {
                    "sent": "Is a. Xbox One PCA method where the matrix R is represents the natural parameters of the exponential family.",
                    "label": 0
                },
                {
                    "sent": "We've chosen to use to represent our data.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is shown here.",
                    "label": 0
                },
                {
                    "sent": "The are on my blue.",
                    "label": 0
                },
                {
                    "sent": "Matrix hasn't shown up here, but imagine there's an R on that blue circle if you will.",
                    "label": 0
                },
                {
                    "sent": "So here we have the R matrix is.",
                    "label": 0
                },
                {
                    "sent": "Drawn from the exponential family.",
                    "label": 0
                },
                {
                    "sent": "Parameterized by a linear combination of the vectors B and the vectors A, where B is drawn from the family conjugate to the exponential family, and a is scale set of.",
                    "label": 0
                },
                {
                    "sent": "Scaling vectors, which are drawn from a Gaussian distribution and.",
                    "label": 0
                },
                {
                    "sent": "On our Gaussian distribution we put a Gaussian prior on the mean and a inverse gamma prior prior on the variance.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "This is Beijing next match family PCA.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We can extend this to multiple matrices.",
                    "label": 0
                },
                {
                    "sent": "By holding the well, we can send this to multiple matrices in one of two ways, either in the way that I've described here, where we have two are two matrices or partial reserve rating data and are fully observed content data being from the same exponential family where we hold the conjugate distribution common in between the two.",
                    "label": 0
                },
                {
                    "sent": "Macy's and we have separate Gaussian scaling factors for the two matrices.",
                    "label": 0
                },
                {
                    "sent": "Or if we believe we have different exponential families, we could obviously switch the order had the Gaussian distribution common and have a separate exponential.",
                    "label": 0
                },
                {
                    "sent": "This has separate conjugate.",
                    "label": 0
                },
                {
                    "sent": "Family distribution for each matrix.",
                    "label": 0
                },
                {
                    "sent": "Now the log joint probability in this model is continuous, which means we can perform efficient inference using hybrid Monte Carlo.",
                    "label": 1
                },
                {
                    "sent": "We currently carrying out results in this.",
                    "label": 0
                },
                {
                    "sent": "Our results are very flimsy so our data set for this data is for this model is playcount data from the movie from the.",
                    "label": 0
                },
                {
                    "sent": "Music recommendation system.",
                    "label": 0
                },
                {
                    "sent": "Last FM.",
                    "label": 0
                },
                {
                    "sent": "Last FM.",
                    "label": 0
                },
                {
                    "sent": "For those who aren't familiar with it, makes counts of what artists, what music you play on your computer.",
                    "label": 0
                },
                {
                    "sent": "And it.",
                    "label": 0
                },
                {
                    "sent": "You can use the data to get a count data of how many times given users listen to a certain artist and this we used as our content data or sorry, our collaborative data for the content data also on the last FM site, users can assign tags to certain artists like rock and jazz and terrible music and indie and whatever.",
                    "label": 0
                },
                {
                    "sent": "So we used.",
                    "label": 0
                },
                {
                    "sent": "The Joint Exponential family representation.",
                    "label": 0
                },
                {
                    "sent": "To learn the two pots on distributed matrices in this book in this problem, so our results are still preliminary, but we've found our results so far suggests that there's if we.",
                    "label": 0
                },
                {
                    "sent": "Mimic the GNU artist case, in this case, where we remove most of the data for new artists and system, we achieve a significant improvement in the long predicted probability.",
                    "label": 0
                },
                {
                    "sent": "In recommending these new artists.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "The IF we take the data at random unfortunately.",
                    "label": 0
                },
                {
                    "sent": "There is less clear an advantage over the single matrix factorization, but it certainly seems to be a definite improvement in the case of GNU artists in the system.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "To conclude, collaborative filtering often forms poorly in the case of new items or new users.",
                    "label": 1
                },
                {
                    "sent": "And using joint factorization of multiple matrices using common latent matrices, we can combine the content and ratings data in a reasonable manner, which by doing so we can improve performance, particularly in the case of a new item.",
                    "label": 1
                },
                {
                    "sent": "We've described inference using both the Gaussian case using Variational Bayes and general exponential family case using hybrid Monte Carlo and well.",
                    "label": 0
                },
                {
                    "sent": "The experiments have shown here have only used the case of two matrices.",
                    "label": 1
                },
                {
                    "sent": "Our model can easily be extended to include further information.",
                    "label": 0
                },
                {
                    "sent": "For example, we're currently looking at including demographic and social network data.",
                    "label": 0
                },
                {
                    "sent": "Thank you any questions.",
                    "label": 0
                },
                {
                    "sent": "What's the score?",
                    "label": 0
                },
                {
                    "sent": "My dear.",
                    "label": 0
                },
                {
                    "sent": "Offhand, I'm not sure.",
                    "label": 0
                },
                {
                    "sent": "But certainly I mean the the single matrix factorization is effective as a variational Bayesian.",
                    "label": 0
                },
                {
                    "sent": "Version of the probabilistic matrix factorization method which.",
                    "label": 0
                },
                {
                    "sent": "Was presented last year NIPS and this year it I CML, which achieved very good results.",
                    "label": 0
                },
                {
                    "sent": "So generally the idea of.",
                    "label": 0
                },
                {
                    "sent": "Basic factor probabilistic matrix factorization for movie prediction performs well so but I don't know exactly how well predicting random does.",
                    "label": 0
                },
                {
                    "sent": "I know it's the normal thing when you're looking at these rating systems to to look at auto Masters.",
                    "label": 0
                },
                {
                    "sent": "The error across the whole set of your test data.",
                    "label": 0
                },
                {
                    "sent": "But there was a couple of papers that Rex is this year where they make this.",
                    "label": 0
                },
                {
                    "sent": "We obvious point, which is that the important recommendations to get right at the strongly positive recommendations astronomy positive rating.",
                    "label": 0
                },
                {
                    "sent": "So there's a notion that if The thing is being correct in predicting A3 on a scale of 1 to 5, but that's not.",
                    "label": 0
                },
                {
                    "sent": "Important because you're not going to action that you're not going to recommend that to the user and instead was really important.",
                    "label": 0
                },
                {
                    "sent": "So that's really important is when you're predicting force implies that you're right.",
                    "label": 0
                },
                {
                    "sent": "Now you're missing.",
                    "label": 0
                },
                {
                    "sent": "The real force applies in the days there, so it would be worth.",
                    "label": 0
                },
                {
                    "sent": "Maybe looking at that as an alternative loss function based on that you're entirely right.",
                    "label": 0
                },
                {
                    "sent": "And like almost everyone working this, I've been entirely influenced by the fact that Netflix users are messy, but it's definitely a good point that this is maybe not the right way to look at it.",
                    "label": 0
                },
                {
                    "sent": "Whether it's a good idea.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To predict whether someone really hate a movie or in qualitative movie, that's not so in or be indifferent to a movie.",
                    "label": 0
                },
                {
                    "sent": "So yeah, that's a very good point, but we've only looked at Arma 3 on that.",
                    "label": 0
                }
            ]
        }
    }
}