{
    "id": "o2da2wbrmbfhstd6yryekbxgnv4paggh",
    "title": "Automatic Annotation of Images using Ensembles of Trees for Hierarchical Multi-label Classification",
    "info": {
        "author": [
            "Ivica Dimitrovski, Department of Knowledge Technologies, Jo\u017eef Stefan Institute"
        ],
        "published": "March 26, 2010",
        "recorded": "March 2010",
        "category": [
            "Top->Computer Science->Computer Vision",
            "Top->Computer Science->Image Analysis",
            "Top->Computer Science->Machine Learning->Pattern Recognition",
            "Top->Computer Science->Machine Learning->Preprocessing"
        ]
    },
    "url": "http://videolectures.net/solomon_dimitrovski_aai/",
    "segmentation": [
        [
            "OK, I guess.",
            "It is my pleasure to introduce Ivica Dimitrovski.",
            "The Faculty of Information Technologies and electrical Engineering in Scopia Macedonia, and he spending this academic year and the Department of Knowledge Technologies, and they are just if an international post Graduate School.",
            "He is working with us.",
            "He already started in the last couple of years and is continuing the collaboration on annotation of images by using machine learning techniques and today he will focus on.",
            "Medical images, mostly so without Much Ado.",
            "Thank you.",
            "The title of today's presentation is automatic annotation of images using ensembles of trees for hierarchical multi label classification."
        ],
        [
            "This is the outline of the presentation.",
            "I will start with defining the.",
            "I will start with defining the problem that we are trying to solve.",
            "Then I will tell something about content based image retrieval.",
            "The basic idea in content based image retrieval systems and there are limitations later.",
            "I will talk more did I will tell.",
            "More details about the system for automatic image annotation that we have implemented and the main accent of this talk will be hierarchical.",
            "Annotation of medical images.",
            "More precisely, X Ray images.",
            "End of the presentation.",
            "I will go in details about the experimental evaluation and the experimental results, and I will conclude.",
            "The presentation with some basic ideas for further development of the system for automatic image."
        ],
        [
            "Annotation.",
            "Nowadays we have billions of digital images stored on a personal computer, sending commercial databases and people do not spend time labeling, organizing core annotating this image collection more interesting.",
            "Digital digital imaging in medicine is in constant growth due to the increasing availability of imaging equipment in hospitals such as X Ray computed tomography or magnetic resonance.",
            "For example, of average size, the radiology Department produce several terabytes of data annually.",
            "Manual annotation or an organization of these images is very expensive and time consuming, consuming almost impractical.",
            "This prompts for efficient systems for image annotation, storage, retrieval, and mining to tackle the problem of image retrieval.",
            "Content based image retrieval, an automatic image annotation."
        ],
        [
            "Are proposed.",
            "Now now I will go in or go with some details about content."
        ],
        [
            "Base image retrieval it is almost impossible to find a picture by keywords or text.",
            "Blah blah blah.",
            "This is impossible in the in the scenario when the metadata metadata or the text annotation are absent or not.",
            "So sheated with the images.",
            "The aim of the content based image retrieval system is searching and finding similar multimedia items based on their content rather than relying on the meta data and text annotations.",
            "The images can be represented by numerical features extracted directly from the image pixels.",
            "These features are stored in the database as a signature together with the images with the images are.",
            "And are used to measure the similarity between the images in the retrieval process.",
            "But the but content based image retrieval system, there are efficient limited by the application by the application domain.",
            "The content based image retrieval research area is very wide, wide and include image processing, feature extraction, indexing for rapid and fast.",
            "Search through the images pattern, recognition, machine learning and so on.",
            "Usually in the content based image retrieval system we can search by providing example image or example images.",
            "Rough sketch of the image that we want to find or regions or segments of the of the images."
        ],
        [
            "The most important step in content based image retrieval is efficient image representation.",
            "Goal of the image representation step is to move from a 2 dimensional image to a vector of numbers.",
            "The representation should preserve enough information of the image content and.",
            "At the same time, not to be sensitive, sensitive to object Placement artifacts, an image on image quality.",
            "So this is the most crucial and most important step in any content based image."
        ],
        [
            "Evil system.",
            "Most commonly used content based image retrieval features are color features and texture features.",
            "There are some examples here on the slide.",
            "I will not go in details about these features.",
            "The color features on the texture features are usually global, so called global feature.",
            "They take into account the pixels, the pixels, the pixel values for the entire for the entire image.",
            "The shape features are also very used in content based image retrieval, they are.",
            "By I would say mid level representation of the image content and there are several shape features already.",
            "The."
        ],
        [
            "Galloped the impact said 7 standard.",
            "This standard that defines several descriptor for audiovisual content there.",
            "These are the descriptors that are included in the Impact 7 standard.",
            "I will note not go in details here also, but they are divided mainly in three groups.",
            "The first descriptors are color descriptors.",
            "II descriptors are texture descriptors, edge histogram, texture browsing, homogeneous texture and last two region shape descriptors and contour shape descriptor represent the shape of the object present in the.",
            "Images.",
            "In recent research, local features in variant to image and transformation are most commonly used for content based image retrieval.",
            "There are some examples of local features.",
            "The scale invariant feature transform or speed up robust feature.",
            "This is basically the same idea as in as in the SIFT features, but it's optimized for online retrieval or gradient location and orientation histogram we can go.",
            "Besides this low level feature image representation, the images can be represented with so-called mid level features with which include image segmentation to detect relevant objects in the image and define relationships between this object in the between the object present in the image.",
            "This technique, this features are.",
            "Very difficult to extract and to obtain becausw the image segmentation process is also very, very difficult and unsolved issue, especially for general images."
        ],
        [
            "Now I will go in details about the limitation of content based image retrieval.",
            "The human understanding of the image content leads to semantic concepts and reasoning.",
            "It is very hard to represent represent this semantic meaning of the image using low level image features like color, texture and shape.",
            "The features, the visual features, the low level visual features can't reflect the high level semantic similarity between images.",
            "For example, the two images can have equal color distribution distribution but very different semantic semantic meaning.",
            "Um?",
            "But I don't know we can have red Apple and Red Bull.",
            "The pictures are if we compare the pictures by taking account the color.",
            "They are very similar, but the object present in the image are very semantically different.",
            "We have a Apple and bowl.",
            "There are several techniques that try to overcome this semantic gap.",
            "One of the technique is relevance feedback with relevance with feedback.",
            "A user can label a few images as a new example for the retrieval engine if it is not satisfied with that retrieval results.",
            "Actually, the this new images will refine the original query and will enable the relevance feedback process to overcome the.",
            "Yep, between high level image semantics and low level image features, we obtain how the relevance feedback goes.",
            "We obtain some initial results from the query engine, then we select the positive negative samples and then we.",
            "Initiate a requery and actually we guide the system through the retrieval process.",
            "This is not fully automatic, it is basically semi semi automatic retrieval.",
            "Also we can introduce the certain feature schemes or template that can represent semantic semantic semantic meanings for example.",
            "We can we can define template with.",
            "I don't know green and blue color and this this template will represent.",
            "I don't know, maybe a landscape and we can scan the entire image looking for this kind of this kind of a templates in the image, but the relevance feedback on the custom feature share schemes do not really help to solve and to overcome to overcome the semantic gap in the content based image retrieval they just narrowing.",
            "Down, but in order to overcome the semantic gap and the limitation of content based image retrieval, we have to use machine learning techniques to model visual features and the semantic concepts present in the image.",
            "So our goal in this research is to develop a system for automatic image."
        ],
        [
            "Sure annotation.",
            "Now I will go.",
            "I will present the system for automatic image annotation."
        ],
        [
            "That we have developed.",
            "First I will.",
            "I will present you the basic idea with automatic image annotation with a simple animation based on the predefined set of annotated already annotated images.",
            "We can build a model and later on if we put some UN annotated images to this model, the system will be able to automatically annotate the images an assigned.",
            "Unassigned labels different classes."
        ],
        [
            "This is the overall architecture of the implemented system.",
            "The most important layer's parts in these systems are the feature extraction part and part under classification part.",
            "As input, the system accepts training images which have to be pre annotated and later on it accept, accept test images and test.",
            "The system will automatically label the test images.",
            "Based on the annotation that it will find in the train set of images in the feature extraction part, we have implemented 26 different types of visual descriptors.",
            "For now, we have several different color spaces and we have several different sampling strategies for generating the local descriptors.",
            "The descriptors of the image content can be used to learn a classifier to annotate the images with the visual concept and the classifier outputs the probabilities with which an image is annotated with the given visual with a given visual concept in the classification part, we're using predictive clustering trees for hierarchical multi label classification."
        ],
        [
            "Becausw the experimental results that I will present here are for Medical X Ray images.",
            "I will go in details only about the feature extraction techniques concerning and that can be applied.",
            "So to that that can be applied to describe 3 images.",
            "There are four different feature extraction techniques.",
            "The first is simplest, one row pixel representation, local binary patterns, each histogram descriptor and the scale invariant feature transform."
        ],
        [
            "Histogram.",
            "The.",
            "The role pixel representation is actually used as a base baseline.",
            "The this is the most simple image representation.",
            "We scale the image to a common size, usually 32 by 32 pixels, and we represent the image by feature vector that contains the image pixel values.",
            "We obtain vector with a fixed length."
        ],
        [
            "For each image of the database.",
            "The main idea besides besides the local binary pattern of the descriptor, is to assign binary code to describe the local texture pattern in a circular region.",
            "Thresholding this is achieved by thresholding each neighborhood on the circle by the grave value of its center.",
            "There is a simple example.",
            "Of the process of generating of this this feature we have center pixel with value 45 and some on 8 neighborhood pixels and I will show you how we have generated a lot."
        ],
        [
            "Binary pattern histogram.",
            "The threshold here is 4."
        ],
        [
            "85 75 -- 45 is."
        ],
        [
            "Bigger than 0, so we put one at the position of 75."
        ],
        [
            "If we take the second pixel."
        ],
        [
            "99 -- 45."
        ],
        [
            "So bigger than zero we put one at this position."
        ],
        [
            "29 minus"
        ],
        [
            "45 is less."
        ],
        [
            "Then zero we put zero at this."
        ],
        [
            "Position and we repeat this step for each neighborhood pixel and based on this one."
        ],
        [
            "On some zeros we obtain a binary code.",
            "This binary code will replace the middle pixel in the operator we can define different local binary patterns.",
            "If we take different radius and different number of points.",
            "Here we have we have radius one and eight points.",
            "But we can take radius one and we can define operator with.",
            "Radius on an take into account just four points or maybe radius two and take much more points from the neighborhood."
        ],
        [
            "When the image is rotated, the pixel values with will correspondingly move around the perimeter of the of the circle.",
            "This show on these two operator or local binary patterns.",
            "In order, in order to remove the effect of rotation, we defined rotation invariant local binary pattern in the rotation invariant local binary pattern pattern.",
            "These two patterns will have equal value.",
            "In the basic local binary pattern, these two patterns will have."
        ],
        [
            "Different values.",
            "For example, here is a.",
            "On this slide, 36 unique rotation invariant binary patterns in local binary pattern operator with radius one."
        ],
        [
            "Eight points.",
            "Furthermore, we can define uniform patterns and non non uniform patterns.",
            "The uniform patterns have at most two transition from zero to 1.",
            "They're usually majority over 90% of the entire patterns in the image and they are they serve as a template for micro structures such as bright spot.",
            "Flat Ari or dark spot.",
            "This is the this template and edges of varying positive and negative curvatures from 127 you can see there is only one at most two transition from zero to 1.",
            "One here and one here.",
            "The non uniform patterns have more than two transition from zero 22021."
        ],
        [
            "In our research we divide the image in 16 subregions, 16 sub images and for each sub image we extract uniform local binary pattern with radius one and we take into account eight points around that pixel.",
            "We concatenate the histograms for the individual subregions and we obtained one histogram for the entire."
        ],
        [
            "Image.",
            "The third descriptor that we used is the edge histogram descriptor.",
            "This is quite simple.",
            "Also quite simple descriptor it.",
            "Takes into account sharp changes of rumination intensity.",
            "It contains information about the shapes of the object present in the image.",
            "This is how we calculate calculate this descriptor.",
            "We subdivide the image again in 16 sub images and edges in the sub pages are categorized into five types.",
            "These are the five types of edges in each subimage vertical horizontal, 45 degrees, 135 degrees and non directional edges.",
            "We count this type of edges in each image and for every sub image we obtain.",
            "A histogram with five bins and we concatenate these histograms in one histogram global histogram for the entire."
        ],
        [
            "Image contact.",
            "In our research we have also.",
            "We also used local features.",
            "The local features are have.",
            "To generate the local features, we have to go through several steps.",
            "First we have to the text to detect the key points.",
            "Around which the local features the local descriptor will be generated.",
            "Then we have.",
            "We have to define the descriptor, what to represent around that local point.",
            "Usually when we speak about local features.",
            "We are using the bag of visual words approach to transform the local features in fixed length feature vectors because most of the machine learning algorithms work with fixed feature fixed vectors and not set of vectors cause by this procedure we can obtain many local features and they will represent not one vector but set of vectors.",
            "But with this approach we transformed local features with a fixed vector and we obtain a histogram.",
            "Actually, a histogram of this local."
        ],
        [
            "Features.",
            "The first step is the sampling strategies for local features.",
            "These are the key points around which the local feature features will be defined.",
            "We can choose from several strategies.",
            "The simplest one is random sampling.",
            "Just take random random points random pixels in the image undefined, undefined local descriptors around this image, or we can.",
            "Only or weaken the uniform uniformly sampled entire image space and around each point defined local descriptor.",
            "Or we can go with some interest point detector, Harris, Laplacian, Laplacian of Gaussian.",
            "This interest point interest point detectors usually detects points in the image where intensity changes exist along multiple multiple.",
            "Direction you see the keypoints are around the ages of the object that is present on the image.",
            "Or we can go with the segmentation based patches to segment the image and then to define the local features in this."
        ],
        [
            "You know segment.",
            "As I mentioned before, we used in our research, we use the scale invariant feature transform.",
            "These are the four.",
            "Stages to define the scale invariant feature transform.",
            "The first stage is scale space.",
            "Extreme detection.",
            "We search in this stage, research over the entire scale space using difference of Gaussian to identify points of potential interest in the second stage we of the location of scale or feature candidate point is determined.",
            "Key points are selected.",
            "Cording to some stability measures in the third stage stage, one or more orientation are assigned to each keypoint based on local image gradients, and in the final stage descriptor is generated for each keypoint from local image gradient.",
            "At the scale that we that we have found in the stage #2 the keypoint localization.",
            "In our research regarding .1 we used random sampling due to the local contrast of the extra images.",
            "It would be very difficult to apply any interest point detector, so we choose to use random sampling.",
            "Can choose random points for each images and we also I didn't mention this.",
            "The local feature descriptor is invariant to changes in illumination image noise, rotation scaling.",
            "Minor changes in viewing direction.",
            "In our research we have we.",
            "Difficult to detect key points in an automated fashion.",
            "Because of the low contrast of the radiographs, we don't have clear I don't know edges of the objects in the image.",
            "The radiographs usually have very low contrast.",
            "Guidelines on when to you know there are no no.",
            "There are many researchers, researchers that state that the random sampling and the uniform then sampling is superior to the keypoint detection, actually.",
            "With the interest point detection, I don't know.",
            "In some image we can detect 15 points in some even image we can detect.",
            "I don't know 1000 points, but with the random sampling and uniform grid sampling we can go with equal number of points in each each image.",
            "And that's why we are using.",
            "Random sampling.",
            "VUV in our research will we also discard the rotation invariants and.",
            "Scaling.",
            "Becausw the rotation invariants is not relevant for our classification task, as the various structures in the radio graphs are likely to appear always.",
            "In the same orientation, and the scale is not likely to change too much between images in the same class and that's why we eliminate the rotation and scaling invariant of this descriptors.",
            "We didn't compute the orientation of the key points, and we extracted the scale invariant feature.",
            "The feature transform descriptors only at the first octave."
        ],
        [
            "As I mentioned before, the outcome of this of the previous operations, the sampling strategy, is the generating of local descriptor.",
            "Will gender will be huge number of key points typically typically for the X Ray images we can obtain from 50 to.",
            "I don't know thousand Image 1000 points per image.",
            "This is huge amount amount of data.",
            "Answer Because of the limitation of the machine learning algorithms that I mentioned before, it is very difficult to use the set of.",
            "Of a set of vectors.",
            "That's why with the bag of visual words approach, we are transforming this local features into a histogram representation.",
            "We begin by extraction, extracting local features of the entire image set.",
            "Later on we select.",
            "I don't know random subset of the extracted local features.",
            "We don't take into account all the features while building the visual word dictionary, we apply vector quantization, usually cumins clustering to this initial subset of local features and.",
            "We obtain.",
            "Masters in which clusters the local features that are visually similar, are grouped and in the final stage we calculate the distribution of the local features among these clusters.",
            "Becausw we have four clusters here.",
            "The historic data resulting histogram will have four bins.",
            "Well, in the last stage we actually count the number of local features in the first cluster for each image.",
            "The number of features in the first cluster, second cluster through cluster and four clusters, and these are the numbers."
        ],
        [
            "Because these methods discard all information about the spatial layout of the features, they have limited descriptive ability to overcome this issue.",
            "We use spatial pyramid representation.",
            "This is actually an extension of the bag of visual words approach.",
            "We represent the.",
            "We generate actually the histograms at several level of special special resolution."
        ],
        [
            "For the entire image, we subdivide the image in four regions and we calculate the distribution of local features in each."
        ],
        [
            "Csap image we can go one level more.",
            "We can subdivide the image in four by four blocks and calculate local local histogram for each image."
        ],
        [
            "This is the setup that we used in our research.",
            "We applied Cummings clustering with 5500 clusters.",
            "The Visual Dictionary was with 500 code words and we use special pyramids of two by two and one by three.",
            "There is an example of spatial pyramid two by two.",
            "We we obtain histogram for each part on one by three we have.",
            "Local Sift histogram 4.",
            "The three parts in the one by three.",
            "So special."
        ],
        [
            "Dermitt representation.",
            "Now I will tell you more about the classification part of the developed system to contract the classifiers, we use predictive clustering trees in the predictive clustering.",
            "Framework at three viewers, a hierarchy of clusters.",
            "The top node corresponds to one cluster containing called data, which is recursively partitioned into smaller cluster while moving down the tree.",
            "Predictive clustering trees are constructed with a standard top down induction of decision trees and the heuristic for selecting the tests is the reduction in variance caused by partioning the instances maximine, maximizing the.",
            "The variance reduction, maximize cluster homogenity and improves predictive performance with appropriate variance and prototype functions.",
            "Predictive clustering trees can handle different types of data, multiple targets or time series.",
            "On the slides on this slide, there is a simple example of predictive clustering tree that can distinguish between squares, circles and triangles."
        ],
        [
            "In the hierarchical Multi label classification, an example can be labeled with multiple labels that are organized in a hierarchy to apply the predictive clustering trees to the task of hierarchical multi label classification.",
            "The example levels are represented as vectors with with Boolean components.",
            "There is a example for this kind of representation.",
            "The components in the vector correspond to the labels in the hierarchy.",
            "Traverse Tinda depth first manner.",
            "The ITE component of the vector is 1 if the example belongs to the corresponding class and 0 otherwise.",
            "This is actually a visualization of a very small part of the Irma coding scheme that we used in our research.",
            "Irma stands for image retrieval in medical application.",
            "And here is a example.",
            "If the image is annotated with high energy inspiration LINQ the vector, the Boolean vector will be defined.",
            "In this way, Becausw because we have annotation high energy, the position 1234 in the the components will have values one because of the inspiration annotation the components eight, 9:10 and 11:00 will have also value one and because of the language annotation the 13 and 14 will also have.",
            "This component will also have one.",
            "Value one and the rest of the component components in the Boolean vector will be 0 because we don't have the other annotation for this for this image."
        ],
        [
            "In the hierarchical Multi label classification, the variance of a set of examples is defined at the Asda very squared distance between each example and the mean level of the entire set.",
            "The higher levels of the car here more more important and an error at the upper level costs more than an an error on the lower levels.",
            "And considering this we used.",
            "Waited, waited Euclidean distance."
        ],
        [
            "In order to improve the predictive performance, we used ensemble classifier.",
            "Sample Classifier is a set of base classifiers and new example is classified classified by combining the prediction of the member classifiers.",
            "The prediction can be combined by taking the average for regression task or majority vote for classification task or even more complex combination.",
            "We consider two example learning techniques that have preliminary been used in the context of Decision tree.",
            "Begging can random forest.",
            "The baking algorithms work by modification of the data and random forest algorithm works by modification of the data and modify."
        ],
        [
            "Kacian of the algorithm.",
            "There is a presentation.",
            "There is a simple sketch of the.",
            "Of how this ansambl techniques usually work, but begging construct the different classifiers by making bootstrap replicates of the training set and using each of these replicates to construct one classifier.",
            "These are the bootstrap replicates.",
            "Each bootstrap sample is obtained by randomly sampling training instances with replacement from the original training set until a number of instances obtained equal to the size of the training set.",
            "A random forest is also ensemble of trees.",
            "Obtain both by Bootstrap sampling count by randomly changing the feature set during the learning stage, and we combine the.",
            "Output the prediction of the individual and classifiers to obtain the final the final vote."
        ],
        [
            "W as a the implemented the implementation of the base classifiers, the predicted clusters clustering trees was taken from the class."
        ],
        [
            "Our system.",
            "Now we'll go in more details about the hierarchical annotation of May."
        ],
        [
            "Week of images for the hierarchical annotation of medical images we have used as I mentioned before, the Irma coding scheme.",
            "The Irma code is mono, hierarchical multi, actual coding coding scheme for representing for describing medical images, the EMA coding scheme consists of four access.",
            "These four access are marked with one of these symbols 029 and a 2.",
            "Deals at the Four Access our technical which represent the image modality, directional, which represent the body orientation, anatomical the body region that is being examined and biological the biological system that is being examined.",
            "This allows a short, ambiguous notation of this form.",
            "You can see the.",
            "Technical access have.",
            "Yes, 4 digits.",
            "The directional 3 done atomic Columbia logical also tree.",
            "The code is strictly strictly hierarchical.",
            "There is a example for the biological code.",
            "Biological coding 5 denotes Europe iotic system 5 one will denote robotic system.",
            "Kidney 512 will denote Europe.",
            "Iotic system, kidney renal.",
            "Pelvis these these annotations are for for this image.",
            "And this is also only the biological axis of the entire."
        ],
        [
            "Colt.",
            "The performance of the system was evaluated using the Heerema database.",
            "This data database consists of scanned XX images.",
            "The database have few characteristics.",
            "It is extremely unbalanced as you can see from this.",
            "Image some classes are with over 1000 samples and some classes with just just a few samples less than 10 samples per class.",
            "The images are also are also very noisy with irregular brightness and contrast.",
            "You can see all of these images are from one class, but they have different contrast.",
            "An irregular brightness.",
            "Some classes also have has great variability within the class.",
            "For example, this class is of the left hip joint in a certain direction, the direction is different, but you can see it yes, very irregular.",
            "The images in this in this class.",
            "Yes, irregular orientation.",
            "Some artifacts such as artificial limbs and X-ray borders.",
            "Here that these artifacts are stronger than the actual content present on the image."
        ],
        [
            "On the other hand, different classes have may have high similarity.",
            "Every row of images on this slide represent different class.",
            "You you can note the.",
            "The different classes among the technical axis and directional axis, the differences X Ray beam, the direction and the patient is breathing out or in during the during the examination.",
            "The difference, as I mentioned the differences with is within the technical axis and the directional axis if you.",
            "Observe the images.",
            "It is challenge even for a human to distinguish between these categories.",
            "If you are not.",
            "I don't know, train physician Becausw.",
            "These images are very visually."
        ],
        [
            "Similar.",
            "We modified the here here of the Irma coat in order to increase the interclass variability and the on the other side decrease the intraclass variability.",
            "As you can see from this picture, we take the code of the first position for the biological biological.",
            "Access an edit in front of the codes for the directional and anatomical axis.",
            "The inclusion of the biological code in the first level of the hierarchy help us to initially filter the images resulting in visually more different images in the first level of the hierarchy."
        ],
        [
            "Now now we will present the experimental evaluation and what was the?"
        ],
        [
            "Goals of the of this research.",
            "We have several experimental hypothesis in the first hip hypothesis we want to see do ensembles of P cities have competitive predictive performance that's using can sample of PCs leave the predictive performance of a single piece it in the domain of image annotation.",
            "Which sample method performs better, either begging to random forests and we also tested how samples of predicting clustering trees.",
            "Compared to the performance of support vector machines, if we treat the problem as a flat classification and don't don't take into account here here of the code.",
            "We also want to know which feature extraction technique is most suitable for medical X Ray images and do combination of feature extraction techniques improved predictive performance.",
            "In this scenario, we concatenate the descriptor descriptors in a single feature vector and train a classifier on the joint."
        ],
        [
            "Feature vector.",
            "To test this hypothesis, we took the image Class 2009 challenge.",
            "Medical image Medical annotation challenge.",
            "The images in this challenge are from the Irma database and they are divided in two different labeling sets.",
            "They are classified according to two 2 labeling different labeling sets.",
            "The first label set set contains 1 Congress and 16 Irma codes and the second label set contains 196.",
            "You're my you're my quotes.",
            "The image Clef 2009 competition was actually a summary from the previous years and that's why we have the image Clef 2017 image Clef 2008 labeling sets in the in this 2009."
        ],
        [
            "Fish.",
            "Asset valuation metrics we.",
            "We use two precision recall recall curves and the image Cliff here.",
            "He called evaluation measure.",
            "As a performance measure in the first evaluation metrics metric we use the area under the average precision.",
            "Recall, precision, recall curve and the image Cliff.",
            "Hierarchical evaluation measures take into account the depth and the branching factor and also allows the classifier not to predict the complete code, but only just just the part of the code.",
            "For example, we can predict.",
            "Only the first 2 digits of the biologic of the anatomical code and then say I don't know for the for the rest of the sub codes in the.",
            "And it's an anatomical axis.",
            "Or if we put.",
            "Asterix here these are.",
            "This Asterix will.",
            "The note we will then they know that we don't know the codes behind the asterisks."
        ],
        [
            "We trained predictive clustering trees for hierarchical multi label classification.",
            "We also train examples ensemble of predicting clustering trees for hierarchical multi label classification, random forest with feature subset size, 10% of the number of descriptive descriptive attributes of the individual descriptors.",
            "We also train ensambles begging and the number of classifiers in the sample.",
            "Was set to 100 unpruned trees.",
            "We used we also SVM.",
            "Untreated the problem as a flat classification problem to solve the partial binary classification problems we apply the one one against all approach each of the FVS was trained with the Gaussian."
        ],
        [
            "Colonel.",
            "Now will present the results.",
            "First we compare the performance of predictive clustering trees and examples of predictive clustering trees using the area under the average curve.",
            "Ensemble methods outperform the single predicted clustering trees as we expected.",
            "Here we have the significance factor.",
            "Random forest outperforms begging.",
            "The random forest method is around 10 points faster than begging.",
            "And the worst performance of all our algorithms on the image Clef 2008.",
            "That data set compared to the image Clef 2007 datasets becausw the here here the hierarchy in this data.",
            "In this data set is much bigger.",
            "We have 195 nodes in the 2008 DOT data set and only 140 nodes in the here here for the image Clef 2007."
        ],
        [
            "Dataset.",
            "Now let us compare the predicted performance of the individual feature extraction algorithms.",
            "Local binary patterns, pattern and scale invariant feature transform histogram are most capable of capturing the hierarchical structure of the X Ray images.",
            "Then she stuck in the script or feature perform slightly worse.",
            "We compare to this two.",
            "And the simplest descriptor obtained from the row pixel representation has worse performance as we expected.",
            "Inclusion of more than one type of feature in the classification process helps to further improve the predictive performance if we concatenate local binary pattern H histogram descriptor and scale invariant feature feature transform transform, we will obtain the highest highest score for the image Clef 2007 data set and if we concatenate local binary patterns and scale invariant feature transform, we will obtain the best.",
            "Value for the image Clef 2008 data set.",
            "You have any idea whether these differences in performance is significant, yeah?",
            "We have the.",
            "The significant factors calculated here.",
            "So these are when you compare the metal, yeah?",
            "What test do you use?",
            "Wilcox said, yeah.",
            "If you go to the next slide.",
            "Oh yeah, for the feature extraction techniques we don't have the.",
            "We didn't check check.",
            "Yes.",
            "For example, I would say intuitively, OK, LBP and LBP plus see if there should be some difference there.",
            "But when you when you look between LBP plus shift versus LBP plus C plus EHD, which is a bit better, but maybe the difference to LP plus shift is not really significant.",
            "Will check that."
        ],
        [
            "From the precision recall curves, we can also note that I predicted performance of the local binary pattern operator and SIFT histogram.",
            "If you.",
            "Oh, they they have quite similar."
        ],
        [
            "Formance we also compare tower approach with a flat classification approach using support vector machines.",
            "By the image Clef error measure, random forest of predictive clustering trees are superior.",
            "Today SVM's SVM approach for all feature extraction algorithms and their combination.",
            "On which proves our point that exploit exploiting the structure of the karahi codes help in improving the predictive performance.",
            "Furthermore, the value of 160 six 65.23 for the image Clef 2008 data set is the best error score reported so far for this problem in the literature and the error score.",
            "Of 65.89 is just one point worse than the best error Score Score report reported so far for the image Clef 2007."
        ],
        [
            "Dataset.",
            "That's about all now I will."
        ],
        [
            "Conclude the presentation.",
            "I've presented a general approach to hierarchical image annotation and visual concept detection.",
            "We achieved excellent predictive performance compared to the other approaches.",
            "For medical images and for general images also, I will say something about this later.",
            "The system is easily extendable with new feature extraction methods, algorithms and it can be easily applied to other domains.",
            "Type of images and other classification schemes.",
            "The system this approach was already applied for the image Clef competition part of the International Conference on Pattern.",
            "Recognition about about annotation of general images and we achieved achieved quite good performance here.",
            "Actually we ranked second among the participation groups in the International Conference on Pattern Recognition.",
            "Which proves our point that this is very general approach for hierarchical annotation of images.",
            "That's so cute.",
            "Precious.",
            "I have quite a few.",
            "So.",
            "One of the issues at the very beginning of the talk you were arguing that OK, people don't like annotating their personal photos.",
            "And I agree with that.",
            "I'm the lazy one.",
            "I remember my personal photos.",
            "However, if we're talking about medical images, you know those are taken in an institutional setup.",
            "You have medical doctors that actually have to perform a diagnosis based on the on the image, so they actually obligated to provide.",
            "Someone rotation of the of the image.",
            "This earily nicely.",
            "Here are Hickory structures in this case, but typically they would have to say something.",
            "Yes, yes, that's true, but considering the fact that there is a very huge amount of data that is produced in the.",
            "Medical Department's I think that first they can go with this process of automatic annotation and then to correct some problems.",
            "Thought that it would be useful to have the automated annotation, but I view this is this would be primarily an additional tool and not to be using.",
            "Yes, yeah.",
            "The the other the other issue.",
            "If anybody else has any questions, we were just jumping, but then I can, otherwise I will go on and I will ask you one more question.",
            "So the the other the other issue is some more powerful than you know logical issue.",
            "You talk about descriptors.",
            "Need the singular use of the word descriptor would mean one column in the in the table and you use it more in the sense.",
            "OK, this is a set of columns in the table which have been possibly derived using one algorithm.",
            "So for example the edge.",
            "Is actually a set of columns that he actually distribution of ages.",
            "Is this standard terminology to use the singular?",
            "Yes, which is standard and terminology.",
            "The entire vector, yeah?",
            "For somebody who's been in machine learning for too long and then when you say you expect a single single goal.",
            "OK.",
            "The.",
            "Next question I have is on the comparison tool to SVM so.",
            "The ensembles you use are ensembles or.",
            "Please book article of a multi level.",
            "Yes no the SVM so you use for flat flat classification.",
            "Work on actually SVM's for construction prediction that are able to take into account some sort of structure of India.",
            "You can either have flat SBM's and then on top of that.",
            "I don't know.",
            "He was a Bayesian them yeah told to take into account here or here.",
            "Gene function, or you can actually directly predict the structure, yes, But the best approach is so far until our work.",
            "Was done with the SVM.",
            "Some treating the problem as a flat classification problem.",
            "That's why we compared with that approach, actually.",
            "It may simply be just like this approach was not tried before for the hierarchical classification of images.",
            "It can well be that the hierarchical SVM have not been tried.",
            "Yeah, question is kept even tried it no no no no no, only SVM for flat classification not.",
            "Listing to try SVM spoke hierarchical classification and compare them both to the cities for hierarchical classification on one hand and then to flat SVM Sunday on the other hand.",
            "Can be interested.",
            "Phone.",
            "In that case, I think it's a again.",
            "Thank you again."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, I guess.",
                    "label": 0
                },
                {
                    "sent": "It is my pleasure to introduce Ivica Dimitrovski.",
                    "label": 0
                },
                {
                    "sent": "The Faculty of Information Technologies and electrical Engineering in Scopia Macedonia, and he spending this academic year and the Department of Knowledge Technologies, and they are just if an international post Graduate School.",
                    "label": 0
                },
                {
                    "sent": "He is working with us.",
                    "label": 0
                },
                {
                    "sent": "He already started in the last couple of years and is continuing the collaboration on annotation of images by using machine learning techniques and today he will focus on.",
                    "label": 0
                },
                {
                    "sent": "Medical images, mostly so without Much Ado.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                },
                {
                    "sent": "The title of today's presentation is automatic annotation of images using ensembles of trees for hierarchical multi label classification.",
                    "label": 1
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This is the outline of the presentation.",
                    "label": 0
                },
                {
                    "sent": "I will start with defining the.",
                    "label": 0
                },
                {
                    "sent": "I will start with defining the problem that we are trying to solve.",
                    "label": 0
                },
                {
                    "sent": "Then I will tell something about content based image retrieval.",
                    "label": 1
                },
                {
                    "sent": "The basic idea in content based image retrieval systems and there are limitations later.",
                    "label": 0
                },
                {
                    "sent": "I will talk more did I will tell.",
                    "label": 0
                },
                {
                    "sent": "More details about the system for automatic image annotation that we have implemented and the main accent of this talk will be hierarchical.",
                    "label": 1
                },
                {
                    "sent": "Annotation of medical images.",
                    "label": 0
                },
                {
                    "sent": "More precisely, X Ray images.",
                    "label": 0
                },
                {
                    "sent": "End of the presentation.",
                    "label": 0
                },
                {
                    "sent": "I will go in details about the experimental evaluation and the experimental results, and I will conclude.",
                    "label": 0
                },
                {
                    "sent": "The presentation with some basic ideas for further development of the system for automatic image.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Annotation.",
                    "label": 0
                },
                {
                    "sent": "Nowadays we have billions of digital images stored on a personal computer, sending commercial databases and people do not spend time labeling, organizing core annotating this image collection more interesting.",
                    "label": 0
                },
                {
                    "sent": "Digital digital imaging in medicine is in constant growth due to the increasing availability of imaging equipment in hospitals such as X Ray computed tomography or magnetic resonance.",
                    "label": 0
                },
                {
                    "sent": "For example, of average size, the radiology Department produce several terabytes of data annually.",
                    "label": 0
                },
                {
                    "sent": "Manual annotation or an organization of these images is very expensive and time consuming, consuming almost impractical.",
                    "label": 1
                },
                {
                    "sent": "This prompts for efficient systems for image annotation, storage, retrieval, and mining to tackle the problem of image retrieval.",
                    "label": 1
                },
                {
                    "sent": "Content based image retrieval, an automatic image annotation.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Are proposed.",
                    "label": 0
                },
                {
                    "sent": "Now now I will go in or go with some details about content.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Base image retrieval it is almost impossible to find a picture by keywords or text.",
                    "label": 1
                },
                {
                    "sent": "Blah blah blah.",
                    "label": 0
                },
                {
                    "sent": "This is impossible in the in the scenario when the metadata metadata or the text annotation are absent or not.",
                    "label": 0
                },
                {
                    "sent": "So sheated with the images.",
                    "label": 0
                },
                {
                    "sent": "The aim of the content based image retrieval system is searching and finding similar multimedia items based on their content rather than relying on the meta data and text annotations.",
                    "label": 0
                },
                {
                    "sent": "The images can be represented by numerical features extracted directly from the image pixels.",
                    "label": 0
                },
                {
                    "sent": "These features are stored in the database as a signature together with the images with the images are.",
                    "label": 0
                },
                {
                    "sent": "And are used to measure the similarity between the images in the retrieval process.",
                    "label": 1
                },
                {
                    "sent": "But the but content based image retrieval system, there are efficient limited by the application by the application domain.",
                    "label": 0
                },
                {
                    "sent": "The content based image retrieval research area is very wide, wide and include image processing, feature extraction, indexing for rapid and fast.",
                    "label": 0
                },
                {
                    "sent": "Search through the images pattern, recognition, machine learning and so on.",
                    "label": 0
                },
                {
                    "sent": "Usually in the content based image retrieval system we can search by providing example image or example images.",
                    "label": 0
                },
                {
                    "sent": "Rough sketch of the image that we want to find or regions or segments of the of the images.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The most important step in content based image retrieval is efficient image representation.",
                    "label": 0
                },
                {
                    "sent": "Goal of the image representation step is to move from a 2 dimensional image to a vector of numbers.",
                    "label": 1
                },
                {
                    "sent": "The representation should preserve enough information of the image content and.",
                    "label": 1
                },
                {
                    "sent": "At the same time, not to be sensitive, sensitive to object Placement artifacts, an image on image quality.",
                    "label": 0
                },
                {
                    "sent": "So this is the most crucial and most important step in any content based image.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Evil system.",
                    "label": 0
                },
                {
                    "sent": "Most commonly used content based image retrieval features are color features and texture features.",
                    "label": 1
                },
                {
                    "sent": "There are some examples here on the slide.",
                    "label": 0
                },
                {
                    "sent": "I will not go in details about these features.",
                    "label": 0
                },
                {
                    "sent": "The color features on the texture features are usually global, so called global feature.",
                    "label": 0
                },
                {
                    "sent": "They take into account the pixels, the pixels, the pixel values for the entire for the entire image.",
                    "label": 0
                },
                {
                    "sent": "The shape features are also very used in content based image retrieval, they are.",
                    "label": 0
                },
                {
                    "sent": "By I would say mid level representation of the image content and there are several shape features already.",
                    "label": 0
                },
                {
                    "sent": "The.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Galloped the impact said 7 standard.",
                    "label": 0
                },
                {
                    "sent": "This standard that defines several descriptor for audiovisual content there.",
                    "label": 1
                },
                {
                    "sent": "These are the descriptors that are included in the Impact 7 standard.",
                    "label": 0
                },
                {
                    "sent": "I will note not go in details here also, but they are divided mainly in three groups.",
                    "label": 0
                },
                {
                    "sent": "The first descriptors are color descriptors.",
                    "label": 0
                },
                {
                    "sent": "II descriptors are texture descriptors, edge histogram, texture browsing, homogeneous texture and last two region shape descriptors and contour shape descriptor represent the shape of the object present in the.",
                    "label": 1
                },
                {
                    "sent": "Images.",
                    "label": 1
                },
                {
                    "sent": "In recent research, local features in variant to image and transformation are most commonly used for content based image retrieval.",
                    "label": 0
                },
                {
                    "sent": "There are some examples of local features.",
                    "label": 1
                },
                {
                    "sent": "The scale invariant feature transform or speed up robust feature.",
                    "label": 1
                },
                {
                    "sent": "This is basically the same idea as in as in the SIFT features, but it's optimized for online retrieval or gradient location and orientation histogram we can go.",
                    "label": 0
                },
                {
                    "sent": "Besides this low level feature image representation, the images can be represented with so-called mid level features with which include image segmentation to detect relevant objects in the image and define relationships between this object in the between the object present in the image.",
                    "label": 0
                },
                {
                    "sent": "This technique, this features are.",
                    "label": 0
                },
                {
                    "sent": "Very difficult to extract and to obtain becausw the image segmentation process is also very, very difficult and unsolved issue, especially for general images.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now I will go in details about the limitation of content based image retrieval.",
                    "label": 0
                },
                {
                    "sent": "The human understanding of the image content leads to semantic concepts and reasoning.",
                    "label": 0
                },
                {
                    "sent": "It is very hard to represent represent this semantic meaning of the image using low level image features like color, texture and shape.",
                    "label": 0
                },
                {
                    "sent": "The features, the visual features, the low level visual features can't reflect the high level semantic similarity between images.",
                    "label": 1
                },
                {
                    "sent": "For example, the two images can have equal color distribution distribution but very different semantic semantic meaning.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "But I don't know we can have red Apple and Red Bull.",
                    "label": 0
                },
                {
                    "sent": "The pictures are if we compare the pictures by taking account the color.",
                    "label": 0
                },
                {
                    "sent": "They are very similar, but the object present in the image are very semantically different.",
                    "label": 0
                },
                {
                    "sent": "We have a Apple and bowl.",
                    "label": 0
                },
                {
                    "sent": "There are several techniques that try to overcome this semantic gap.",
                    "label": 0
                },
                {
                    "sent": "One of the technique is relevance feedback with relevance with feedback.",
                    "label": 0
                },
                {
                    "sent": "A user can label a few images as a new example for the retrieval engine if it is not satisfied with that retrieval results.",
                    "label": 0
                },
                {
                    "sent": "Actually, the this new images will refine the original query and will enable the relevance feedback process to overcome the.",
                    "label": 0
                },
                {
                    "sent": "Yep, between high level image semantics and low level image features, we obtain how the relevance feedback goes.",
                    "label": 0
                },
                {
                    "sent": "We obtain some initial results from the query engine, then we select the positive negative samples and then we.",
                    "label": 0
                },
                {
                    "sent": "Initiate a requery and actually we guide the system through the retrieval process.",
                    "label": 0
                },
                {
                    "sent": "This is not fully automatic, it is basically semi semi automatic retrieval.",
                    "label": 0
                },
                {
                    "sent": "Also we can introduce the certain feature schemes or template that can represent semantic semantic semantic meanings for example.",
                    "label": 0
                },
                {
                    "sent": "We can we can define template with.",
                    "label": 0
                },
                {
                    "sent": "I don't know green and blue color and this this template will represent.",
                    "label": 0
                },
                {
                    "sent": "I don't know, maybe a landscape and we can scan the entire image looking for this kind of this kind of a templates in the image, but the relevance feedback on the custom feature share schemes do not really help to solve and to overcome to overcome the semantic gap in the content based image retrieval they just narrowing.",
                    "label": 1
                },
                {
                    "sent": "Down, but in order to overcome the semantic gap and the limitation of content based image retrieval, we have to use machine learning techniques to model visual features and the semantic concepts present in the image.",
                    "label": 1
                },
                {
                    "sent": "So our goal in this research is to develop a system for automatic image.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Sure annotation.",
                    "label": 0
                },
                {
                    "sent": "Now I will go.",
                    "label": 0
                },
                {
                    "sent": "I will present the system for automatic image annotation.",
                    "label": 1
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "That we have developed.",
                    "label": 0
                },
                {
                    "sent": "First I will.",
                    "label": 0
                },
                {
                    "sent": "I will present you the basic idea with automatic image annotation with a simple animation based on the predefined set of annotated already annotated images.",
                    "label": 1
                },
                {
                    "sent": "We can build a model and later on if we put some UN annotated images to this model, the system will be able to automatically annotate the images an assigned.",
                    "label": 0
                },
                {
                    "sent": "Unassigned labels different classes.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This is the overall architecture of the implemented system.",
                    "label": 0
                },
                {
                    "sent": "The most important layer's parts in these systems are the feature extraction part and part under classification part.",
                    "label": 0
                },
                {
                    "sent": "As input, the system accepts training images which have to be pre annotated and later on it accept, accept test images and test.",
                    "label": 0
                },
                {
                    "sent": "The system will automatically label the test images.",
                    "label": 0
                },
                {
                    "sent": "Based on the annotation that it will find in the train set of images in the feature extraction part, we have implemented 26 different types of visual descriptors.",
                    "label": 1
                },
                {
                    "sent": "For now, we have several different color spaces and we have several different sampling strategies for generating the local descriptors.",
                    "label": 0
                },
                {
                    "sent": "The descriptors of the image content can be used to learn a classifier to annotate the images with the visual concept and the classifier outputs the probabilities with which an image is annotated with the given visual with a given visual concept in the classification part, we're using predictive clustering trees for hierarchical multi label classification.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Becausw the experimental results that I will present here are for Medical X Ray images.",
                    "label": 0
                },
                {
                    "sent": "I will go in details only about the feature extraction techniques concerning and that can be applied.",
                    "label": 0
                },
                {
                    "sent": "So to that that can be applied to describe 3 images.",
                    "label": 0
                },
                {
                    "sent": "There are four different feature extraction techniques.",
                    "label": 1
                },
                {
                    "sent": "The first is simplest, one row pixel representation, local binary patterns, each histogram descriptor and the scale invariant feature transform.",
                    "label": 1
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Histogram.",
                    "label": 0
                },
                {
                    "sent": "The.",
                    "label": 0
                },
                {
                    "sent": "The role pixel representation is actually used as a base baseline.",
                    "label": 0
                },
                {
                    "sent": "The this is the most simple image representation.",
                    "label": 0
                },
                {
                    "sent": "We scale the image to a common size, usually 32 by 32 pixels, and we represent the image by feature vector that contains the image pixel values.",
                    "label": 1
                },
                {
                    "sent": "We obtain vector with a fixed length.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "For each image of the database.",
                    "label": 0
                },
                {
                    "sent": "The main idea besides besides the local binary pattern of the descriptor, is to assign binary code to describe the local texture pattern in a circular region.",
                    "label": 1
                },
                {
                    "sent": "Thresholding this is achieved by thresholding each neighborhood on the circle by the grave value of its center.",
                    "label": 0
                },
                {
                    "sent": "There is a simple example.",
                    "label": 0
                },
                {
                    "sent": "Of the process of generating of this this feature we have center pixel with value 45 and some on 8 neighborhood pixels and I will show you how we have generated a lot.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Binary pattern histogram.",
                    "label": 0
                },
                {
                    "sent": "The threshold here is 4.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "85 75 -- 45 is.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Bigger than 0, so we put one at the position of 75.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "If we take the second pixel.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "99 -- 45.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So bigger than zero we put one at this position.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "29 minus",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "45 is less.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Then zero we put zero at this.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Position and we repeat this step for each neighborhood pixel and based on this one.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "On some zeros we obtain a binary code.",
                    "label": 1
                },
                {
                    "sent": "This binary code will replace the middle pixel in the operator we can define different local binary patterns.",
                    "label": 1
                },
                {
                    "sent": "If we take different radius and different number of points.",
                    "label": 1
                },
                {
                    "sent": "Here we have we have radius one and eight points.",
                    "label": 0
                },
                {
                    "sent": "But we can take radius one and we can define operator with.",
                    "label": 0
                },
                {
                    "sent": "Radius on an take into account just four points or maybe radius two and take much more points from the neighborhood.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "When the image is rotated, the pixel values with will correspondingly move around the perimeter of the of the circle.",
                    "label": 1
                },
                {
                    "sent": "This show on these two operator or local binary patterns.",
                    "label": 1
                },
                {
                    "sent": "In order, in order to remove the effect of rotation, we defined rotation invariant local binary pattern in the rotation invariant local binary pattern pattern.",
                    "label": 0
                },
                {
                    "sent": "These two patterns will have equal value.",
                    "label": 0
                },
                {
                    "sent": "In the basic local binary pattern, these two patterns will have.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Different values.",
                    "label": 0
                },
                {
                    "sent": "For example, here is a.",
                    "label": 0
                },
                {
                    "sent": "On this slide, 36 unique rotation invariant binary patterns in local binary pattern operator with radius one.",
                    "label": 1
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Eight points.",
                    "label": 0
                },
                {
                    "sent": "Furthermore, we can define uniform patterns and non non uniform patterns.",
                    "label": 0
                },
                {
                    "sent": "The uniform patterns have at most two transition from zero to 1.",
                    "label": 0
                },
                {
                    "sent": "They're usually majority over 90% of the entire patterns in the image and they are they serve as a template for micro structures such as bright spot.",
                    "label": 0
                },
                {
                    "sent": "Flat Ari or dark spot.",
                    "label": 1
                },
                {
                    "sent": "This is the this template and edges of varying positive and negative curvatures from 127 you can see there is only one at most two transition from zero to 1.",
                    "label": 1
                },
                {
                    "sent": "One here and one here.",
                    "label": 1
                },
                {
                    "sent": "The non uniform patterns have more than two transition from zero 22021.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In our research we divide the image in 16 subregions, 16 sub images and for each sub image we extract uniform local binary pattern with radius one and we take into account eight points around that pixel.",
                    "label": 0
                },
                {
                    "sent": "We concatenate the histograms for the individual subregions and we obtained one histogram for the entire.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Image.",
                    "label": 0
                },
                {
                    "sent": "The third descriptor that we used is the edge histogram descriptor.",
                    "label": 0
                },
                {
                    "sent": "This is quite simple.",
                    "label": 0
                },
                {
                    "sent": "Also quite simple descriptor it.",
                    "label": 0
                },
                {
                    "sent": "Takes into account sharp changes of rumination intensity.",
                    "label": 0
                },
                {
                    "sent": "It contains information about the shapes of the object present in the image.",
                    "label": 1
                },
                {
                    "sent": "This is how we calculate calculate this descriptor.",
                    "label": 0
                },
                {
                    "sent": "We subdivide the image again in 16 sub images and edges in the sub pages are categorized into five types.",
                    "label": 0
                },
                {
                    "sent": "These are the five types of edges in each subimage vertical horizontal, 45 degrees, 135 degrees and non directional edges.",
                    "label": 0
                },
                {
                    "sent": "We count this type of edges in each image and for every sub image we obtain.",
                    "label": 0
                },
                {
                    "sent": "A histogram with five bins and we concatenate these histograms in one histogram global histogram for the entire.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Image contact.",
                    "label": 0
                },
                {
                    "sent": "In our research we have also.",
                    "label": 0
                },
                {
                    "sent": "We also used local features.",
                    "label": 0
                },
                {
                    "sent": "The local features are have.",
                    "label": 0
                },
                {
                    "sent": "To generate the local features, we have to go through several steps.",
                    "label": 0
                },
                {
                    "sent": "First we have to the text to detect the key points.",
                    "label": 0
                },
                {
                    "sent": "Around which the local features the local descriptor will be generated.",
                    "label": 0
                },
                {
                    "sent": "Then we have.",
                    "label": 0
                },
                {
                    "sent": "We have to define the descriptor, what to represent around that local point.",
                    "label": 0
                },
                {
                    "sent": "Usually when we speak about local features.",
                    "label": 0
                },
                {
                    "sent": "We are using the bag of visual words approach to transform the local features in fixed length feature vectors because most of the machine learning algorithms work with fixed feature fixed vectors and not set of vectors cause by this procedure we can obtain many local features and they will represent not one vector but set of vectors.",
                    "label": 1
                },
                {
                    "sent": "But with this approach we transformed local features with a fixed vector and we obtain a histogram.",
                    "label": 1
                },
                {
                    "sent": "Actually, a histogram of this local.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Features.",
                    "label": 0
                },
                {
                    "sent": "The first step is the sampling strategies for local features.",
                    "label": 1
                },
                {
                    "sent": "These are the key points around which the local feature features will be defined.",
                    "label": 0
                },
                {
                    "sent": "We can choose from several strategies.",
                    "label": 0
                },
                {
                    "sent": "The simplest one is random sampling.",
                    "label": 0
                },
                {
                    "sent": "Just take random random points random pixels in the image undefined, undefined local descriptors around this image, or we can.",
                    "label": 0
                },
                {
                    "sent": "Only or weaken the uniform uniformly sampled entire image space and around each point defined local descriptor.",
                    "label": 0
                },
                {
                    "sent": "Or we can go with some interest point detector, Harris, Laplacian, Laplacian of Gaussian.",
                    "label": 0
                },
                {
                    "sent": "This interest point interest point detectors usually detects points in the image where intensity changes exist along multiple multiple.",
                    "label": 0
                },
                {
                    "sent": "Direction you see the keypoints are around the ages of the object that is present on the image.",
                    "label": 0
                },
                {
                    "sent": "Or we can go with the segmentation based patches to segment the image and then to define the local features in this.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "You know segment.",
                    "label": 0
                },
                {
                    "sent": "As I mentioned before, we used in our research, we use the scale invariant feature transform.",
                    "label": 0
                },
                {
                    "sent": "These are the four.",
                    "label": 0
                },
                {
                    "sent": "Stages to define the scale invariant feature transform.",
                    "label": 0
                },
                {
                    "sent": "The first stage is scale space.",
                    "label": 0
                },
                {
                    "sent": "Extreme detection.",
                    "label": 0
                },
                {
                    "sent": "We search in this stage, research over the entire scale space using difference of Gaussian to identify points of potential interest in the second stage we of the location of scale or feature candidate point is determined.",
                    "label": 0
                },
                {
                    "sent": "Key points are selected.",
                    "label": 0
                },
                {
                    "sent": "Cording to some stability measures in the third stage stage, one or more orientation are assigned to each keypoint based on local image gradients, and in the final stage descriptor is generated for each keypoint from local image gradient.",
                    "label": 0
                },
                {
                    "sent": "At the scale that we that we have found in the stage #2 the keypoint localization.",
                    "label": 0
                },
                {
                    "sent": "In our research regarding .1 we used random sampling due to the local contrast of the extra images.",
                    "label": 0
                },
                {
                    "sent": "It would be very difficult to apply any interest point detector, so we choose to use random sampling.",
                    "label": 0
                },
                {
                    "sent": "Can choose random points for each images and we also I didn't mention this.",
                    "label": 0
                },
                {
                    "sent": "The local feature descriptor is invariant to changes in illumination image noise, rotation scaling.",
                    "label": 1
                },
                {
                    "sent": "Minor changes in viewing direction.",
                    "label": 0
                },
                {
                    "sent": "In our research we have we.",
                    "label": 0
                },
                {
                    "sent": "Difficult to detect key points in an automated fashion.",
                    "label": 0
                },
                {
                    "sent": "Because of the low contrast of the radiographs, we don't have clear I don't know edges of the objects in the image.",
                    "label": 0
                },
                {
                    "sent": "The radiographs usually have very low contrast.",
                    "label": 0
                },
                {
                    "sent": "Guidelines on when to you know there are no no.",
                    "label": 0
                },
                {
                    "sent": "There are many researchers, researchers that state that the random sampling and the uniform then sampling is superior to the keypoint detection, actually.",
                    "label": 0
                },
                {
                    "sent": "With the interest point detection, I don't know.",
                    "label": 0
                },
                {
                    "sent": "In some image we can detect 15 points in some even image we can detect.",
                    "label": 0
                },
                {
                    "sent": "I don't know 1000 points, but with the random sampling and uniform grid sampling we can go with equal number of points in each each image.",
                    "label": 0
                },
                {
                    "sent": "And that's why we are using.",
                    "label": 0
                },
                {
                    "sent": "Random sampling.",
                    "label": 0
                },
                {
                    "sent": "VUV in our research will we also discard the rotation invariants and.",
                    "label": 0
                },
                {
                    "sent": "Scaling.",
                    "label": 0
                },
                {
                    "sent": "Becausw the rotation invariants is not relevant for our classification task, as the various structures in the radio graphs are likely to appear always.",
                    "label": 0
                },
                {
                    "sent": "In the same orientation, and the scale is not likely to change too much between images in the same class and that's why we eliminate the rotation and scaling invariant of this descriptors.",
                    "label": 1
                },
                {
                    "sent": "We didn't compute the orientation of the key points, and we extracted the scale invariant feature.",
                    "label": 0
                },
                {
                    "sent": "The feature transform descriptors only at the first octave.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "As I mentioned before, the outcome of this of the previous operations, the sampling strategy, is the generating of local descriptor.",
                    "label": 0
                },
                {
                    "sent": "Will gender will be huge number of key points typically typically for the X Ray images we can obtain from 50 to.",
                    "label": 0
                },
                {
                    "sent": "I don't know thousand Image 1000 points per image.",
                    "label": 0
                },
                {
                    "sent": "This is huge amount amount of data.",
                    "label": 0
                },
                {
                    "sent": "Answer Because of the limitation of the machine learning algorithms that I mentioned before, it is very difficult to use the set of.",
                    "label": 0
                },
                {
                    "sent": "Of a set of vectors.",
                    "label": 0
                },
                {
                    "sent": "That's why with the bag of visual words approach, we are transforming this local features into a histogram representation.",
                    "label": 1
                },
                {
                    "sent": "We begin by extraction, extracting local features of the entire image set.",
                    "label": 0
                },
                {
                    "sent": "Later on we select.",
                    "label": 0
                },
                {
                    "sent": "I don't know random subset of the extracted local features.",
                    "label": 0
                },
                {
                    "sent": "We don't take into account all the features while building the visual word dictionary, we apply vector quantization, usually cumins clustering to this initial subset of local features and.",
                    "label": 1
                },
                {
                    "sent": "We obtain.",
                    "label": 0
                },
                {
                    "sent": "Masters in which clusters the local features that are visually similar, are grouped and in the final stage we calculate the distribution of the local features among these clusters.",
                    "label": 0
                },
                {
                    "sent": "Becausw we have four clusters here.",
                    "label": 0
                },
                {
                    "sent": "The historic data resulting histogram will have four bins.",
                    "label": 0
                },
                {
                    "sent": "Well, in the last stage we actually count the number of local features in the first cluster for each image.",
                    "label": 0
                },
                {
                    "sent": "The number of features in the first cluster, second cluster through cluster and four clusters, and these are the numbers.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Because these methods discard all information about the spatial layout of the features, they have limited descriptive ability to overcome this issue.",
                    "label": 0
                },
                {
                    "sent": "We use spatial pyramid representation.",
                    "label": 1
                },
                {
                    "sent": "This is actually an extension of the bag of visual words approach.",
                    "label": 1
                },
                {
                    "sent": "We represent the.",
                    "label": 0
                },
                {
                    "sent": "We generate actually the histograms at several level of special special resolution.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For the entire image, we subdivide the image in four regions and we calculate the distribution of local features in each.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Csap image we can go one level more.",
                    "label": 0
                },
                {
                    "sent": "We can subdivide the image in four by four blocks and calculate local local histogram for each image.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This is the setup that we used in our research.",
                    "label": 0
                },
                {
                    "sent": "We applied Cummings clustering with 5500 clusters.",
                    "label": 0
                },
                {
                    "sent": "The Visual Dictionary was with 500 code words and we use special pyramids of two by two and one by three.",
                    "label": 1
                },
                {
                    "sent": "There is an example of spatial pyramid two by two.",
                    "label": 0
                },
                {
                    "sent": "We we obtain histogram for each part on one by three we have.",
                    "label": 0
                },
                {
                    "sent": "Local Sift histogram 4.",
                    "label": 0
                },
                {
                    "sent": "The three parts in the one by three.",
                    "label": 0
                },
                {
                    "sent": "So special.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Dermitt representation.",
                    "label": 0
                },
                {
                    "sent": "Now I will tell you more about the classification part of the developed system to contract the classifiers, we use predictive clustering trees in the predictive clustering.",
                    "label": 0
                },
                {
                    "sent": "Framework at three viewers, a hierarchy of clusters.",
                    "label": 1
                },
                {
                    "sent": "The top node corresponds to one cluster containing called data, which is recursively partitioned into smaller cluster while moving down the tree.",
                    "label": 0
                },
                {
                    "sent": "Predictive clustering trees are constructed with a standard top down induction of decision trees and the heuristic for selecting the tests is the reduction in variance caused by partioning the instances maximine, maximizing the.",
                    "label": 0
                },
                {
                    "sent": "The variance reduction, maximize cluster homogenity and improves predictive performance with appropriate variance and prototype functions.",
                    "label": 0
                },
                {
                    "sent": "Predictive clustering trees can handle different types of data, multiple targets or time series.",
                    "label": 1
                },
                {
                    "sent": "On the slides on this slide, there is a simple example of predictive clustering tree that can distinguish between squares, circles and triangles.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In the hierarchical Multi label classification, an example can be labeled with multiple labels that are organized in a hierarchy to apply the predictive clustering trees to the task of hierarchical multi label classification.",
                    "label": 1
                },
                {
                    "sent": "The example levels are represented as vectors with with Boolean components.",
                    "label": 0
                },
                {
                    "sent": "There is a example for this kind of representation.",
                    "label": 0
                },
                {
                    "sent": "The components in the vector correspond to the labels in the hierarchy.",
                    "label": 0
                },
                {
                    "sent": "Traverse Tinda depth first manner.",
                    "label": 0
                },
                {
                    "sent": "The ITE component of the vector is 1 if the example belongs to the corresponding class and 0 otherwise.",
                    "label": 0
                },
                {
                    "sent": "This is actually a visualization of a very small part of the Irma coding scheme that we used in our research.",
                    "label": 0
                },
                {
                    "sent": "Irma stands for image retrieval in medical application.",
                    "label": 0
                },
                {
                    "sent": "And here is a example.",
                    "label": 0
                },
                {
                    "sent": "If the image is annotated with high energy inspiration LINQ the vector, the Boolean vector will be defined.",
                    "label": 0
                },
                {
                    "sent": "In this way, Becausw because we have annotation high energy, the position 1234 in the the components will have values one because of the inspiration annotation the components eight, 9:10 and 11:00 will have also value one and because of the language annotation the 13 and 14 will also have.",
                    "label": 0
                },
                {
                    "sent": "This component will also have one.",
                    "label": 0
                },
                {
                    "sent": "Value one and the rest of the component components in the Boolean vector will be 0 because we don't have the other annotation for this for this image.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In the hierarchical Multi label classification, the variance of a set of examples is defined at the Asda very squared distance between each example and the mean level of the entire set.",
                    "label": 1
                },
                {
                    "sent": "The higher levels of the car here more more important and an error at the upper level costs more than an an error on the lower levels.",
                    "label": 1
                },
                {
                    "sent": "And considering this we used.",
                    "label": 0
                },
                {
                    "sent": "Waited, waited Euclidean distance.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In order to improve the predictive performance, we used ensemble classifier.",
                    "label": 0
                },
                {
                    "sent": "Sample Classifier is a set of base classifiers and new example is classified classified by combining the prediction of the member classifiers.",
                    "label": 1
                },
                {
                    "sent": "The prediction can be combined by taking the average for regression task or majority vote for classification task or even more complex combination.",
                    "label": 0
                },
                {
                    "sent": "We consider two example learning techniques that have preliminary been used in the context of Decision tree.",
                    "label": 0
                },
                {
                    "sent": "Begging can random forest.",
                    "label": 0
                },
                {
                    "sent": "The baking algorithms work by modification of the data and random forest algorithm works by modification of the data and modify.",
                    "label": 1
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Kacian of the algorithm.",
                    "label": 0
                },
                {
                    "sent": "There is a presentation.",
                    "label": 0
                },
                {
                    "sent": "There is a simple sketch of the.",
                    "label": 0
                },
                {
                    "sent": "Of how this ansambl techniques usually work, but begging construct the different classifiers by making bootstrap replicates of the training set and using each of these replicates to construct one classifier.",
                    "label": 0
                },
                {
                    "sent": "These are the bootstrap replicates.",
                    "label": 0
                },
                {
                    "sent": "Each bootstrap sample is obtained by randomly sampling training instances with replacement from the original training set until a number of instances obtained equal to the size of the training set.",
                    "label": 0
                },
                {
                    "sent": "A random forest is also ensemble of trees.",
                    "label": 0
                },
                {
                    "sent": "Obtain both by Bootstrap sampling count by randomly changing the feature set during the learning stage, and we combine the.",
                    "label": 0
                },
                {
                    "sent": "Output the prediction of the individual and classifiers to obtain the final the final vote.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "W as a the implemented the implementation of the base classifiers, the predicted clusters clustering trees was taken from the class.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Our system.",
                    "label": 0
                },
                {
                    "sent": "Now we'll go in more details about the hierarchical annotation of May.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Week of images for the hierarchical annotation of medical images we have used as I mentioned before, the Irma coding scheme.",
                    "label": 0
                },
                {
                    "sent": "The Irma code is mono, hierarchical multi, actual coding coding scheme for representing for describing medical images, the EMA coding scheme consists of four access.",
                    "label": 0
                },
                {
                    "sent": "These four access are marked with one of these symbols 029 and a 2.",
                    "label": 0
                },
                {
                    "sent": "Deals at the Four Access our technical which represent the image modality, directional, which represent the body orientation, anatomical the body region that is being examined and biological the biological system that is being examined.",
                    "label": 1
                },
                {
                    "sent": "This allows a short, ambiguous notation of this form.",
                    "label": 0
                },
                {
                    "sent": "You can see the.",
                    "label": 0
                },
                {
                    "sent": "Technical access have.",
                    "label": 0
                },
                {
                    "sent": "Yes, 4 digits.",
                    "label": 0
                },
                {
                    "sent": "The directional 3 done atomic Columbia logical also tree.",
                    "label": 0
                },
                {
                    "sent": "The code is strictly strictly hierarchical.",
                    "label": 1
                },
                {
                    "sent": "There is a example for the biological code.",
                    "label": 1
                },
                {
                    "sent": "Biological coding 5 denotes Europe iotic system 5 one will denote robotic system.",
                    "label": 0
                },
                {
                    "sent": "Kidney 512 will denote Europe.",
                    "label": 0
                },
                {
                    "sent": "Iotic system, kidney renal.",
                    "label": 0
                },
                {
                    "sent": "Pelvis these these annotations are for for this image.",
                    "label": 0
                },
                {
                    "sent": "And this is also only the biological axis of the entire.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Colt.",
                    "label": 0
                },
                {
                    "sent": "The performance of the system was evaluated using the Heerema database.",
                    "label": 0
                },
                {
                    "sent": "This data database consists of scanned XX images.",
                    "label": 0
                },
                {
                    "sent": "The database have few characteristics.",
                    "label": 0
                },
                {
                    "sent": "It is extremely unbalanced as you can see from this.",
                    "label": 0
                },
                {
                    "sent": "Image some classes are with over 1000 samples and some classes with just just a few samples less than 10 samples per class.",
                    "label": 0
                },
                {
                    "sent": "The images are also are also very noisy with irregular brightness and contrast.",
                    "label": 1
                },
                {
                    "sent": "You can see all of these images are from one class, but they have different contrast.",
                    "label": 0
                },
                {
                    "sent": "An irregular brightness.",
                    "label": 0
                },
                {
                    "sent": "Some classes also have has great variability within the class.",
                    "label": 0
                },
                {
                    "sent": "For example, this class is of the left hip joint in a certain direction, the direction is different, but you can see it yes, very irregular.",
                    "label": 0
                },
                {
                    "sent": "The images in this in this class.",
                    "label": 0
                },
                {
                    "sent": "Yes, irregular orientation.",
                    "label": 0
                },
                {
                    "sent": "Some artifacts such as artificial limbs and X-ray borders.",
                    "label": 0
                },
                {
                    "sent": "Here that these artifacts are stronger than the actual content present on the image.",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "On the other hand, different classes have may have high similarity.",
                    "label": 0
                },
                {
                    "sent": "Every row of images on this slide represent different class.",
                    "label": 0
                },
                {
                    "sent": "You you can note the.",
                    "label": 0
                },
                {
                    "sent": "The different classes among the technical axis and directional axis, the differences X Ray beam, the direction and the patient is breathing out or in during the during the examination.",
                    "label": 0
                },
                {
                    "sent": "The difference, as I mentioned the differences with is within the technical axis and the directional axis if you.",
                    "label": 0
                },
                {
                    "sent": "Observe the images.",
                    "label": 0
                },
                {
                    "sent": "It is challenge even for a human to distinguish between these categories.",
                    "label": 0
                },
                {
                    "sent": "If you are not.",
                    "label": 0
                },
                {
                    "sent": "I don't know, train physician Becausw.",
                    "label": 0
                },
                {
                    "sent": "These images are very visually.",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Similar.",
                    "label": 0
                },
                {
                    "sent": "We modified the here here of the Irma coat in order to increase the interclass variability and the on the other side decrease the intraclass variability.",
                    "label": 1
                },
                {
                    "sent": "As you can see from this picture, we take the code of the first position for the biological biological.",
                    "label": 0
                },
                {
                    "sent": "Access an edit in front of the codes for the directional and anatomical axis.",
                    "label": 0
                },
                {
                    "sent": "The inclusion of the biological code in the first level of the hierarchy help us to initially filter the images resulting in visually more different images in the first level of the hierarchy.",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now now we will present the experimental evaluation and what was the?",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Goals of the of this research.",
                    "label": 0
                },
                {
                    "sent": "We have several experimental hypothesis in the first hip hypothesis we want to see do ensembles of P cities have competitive predictive performance that's using can sample of PCs leave the predictive performance of a single piece it in the domain of image annotation.",
                    "label": 0
                },
                {
                    "sent": "Which sample method performs better, either begging to random forests and we also tested how samples of predicting clustering trees.",
                    "label": 0
                },
                {
                    "sent": "Compared to the performance of support vector machines, if we treat the problem as a flat classification and don't don't take into account here here of the code.",
                    "label": 0
                },
                {
                    "sent": "We also want to know which feature extraction technique is most suitable for medical X Ray images and do combination of feature extraction techniques improved predictive performance.",
                    "label": 1
                },
                {
                    "sent": "In this scenario, we concatenate the descriptor descriptors in a single feature vector and train a classifier on the joint.",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Feature vector.",
                    "label": 0
                },
                {
                    "sent": "To test this hypothesis, we took the image Class 2009 challenge.",
                    "label": 0
                },
                {
                    "sent": "Medical image Medical annotation challenge.",
                    "label": 1
                },
                {
                    "sent": "The images in this challenge are from the Irma database and they are divided in two different labeling sets.",
                    "label": 0
                },
                {
                    "sent": "They are classified according to two 2 labeling different labeling sets.",
                    "label": 1
                },
                {
                    "sent": "The first label set set contains 1 Congress and 16 Irma codes and the second label set contains 196.",
                    "label": 0
                },
                {
                    "sent": "You're my you're my quotes.",
                    "label": 0
                },
                {
                    "sent": "The image Clef 2009 competition was actually a summary from the previous years and that's why we have the image Clef 2017 image Clef 2008 labeling sets in the in this 2009.",
                    "label": 0
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Fish.",
                    "label": 0
                },
                {
                    "sent": "Asset valuation metrics we.",
                    "label": 0
                },
                {
                    "sent": "We use two precision recall recall curves and the image Cliff here.",
                    "label": 0
                },
                {
                    "sent": "He called evaluation measure.",
                    "label": 0
                },
                {
                    "sent": "As a performance measure in the first evaluation metrics metric we use the area under the average precision.",
                    "label": 0
                },
                {
                    "sent": "Recall, precision, recall curve and the image Cliff.",
                    "label": 0
                },
                {
                    "sent": "Hierarchical evaluation measures take into account the depth and the branching factor and also allows the classifier not to predict the complete code, but only just just the part of the code.",
                    "label": 1
                },
                {
                    "sent": "For example, we can predict.",
                    "label": 0
                },
                {
                    "sent": "Only the first 2 digits of the biologic of the anatomical code and then say I don't know for the for the rest of the sub codes in the.",
                    "label": 0
                },
                {
                    "sent": "And it's an anatomical axis.",
                    "label": 0
                },
                {
                    "sent": "Or if we put.",
                    "label": 0
                },
                {
                    "sent": "Asterix here these are.",
                    "label": 0
                },
                {
                    "sent": "This Asterix will.",
                    "label": 0
                },
                {
                    "sent": "The note we will then they know that we don't know the codes behind the asterisks.",
                    "label": 0
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We trained predictive clustering trees for hierarchical multi label classification.",
                    "label": 0
                },
                {
                    "sent": "We also train examples ensemble of predicting clustering trees for hierarchical multi label classification, random forest with feature subset size, 10% of the number of descriptive descriptive attributes of the individual descriptors.",
                    "label": 1
                },
                {
                    "sent": "We also train ensambles begging and the number of classifiers in the sample.",
                    "label": 1
                },
                {
                    "sent": "Was set to 100 unpruned trees.",
                    "label": 0
                },
                {
                    "sent": "We used we also SVM.",
                    "label": 0
                },
                {
                    "sent": "Untreated the problem as a flat classification problem to solve the partial binary classification problems we apply the one one against all approach each of the FVS was trained with the Gaussian.",
                    "label": 0
                }
            ]
        },
        "clip_55": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Colonel.",
                    "label": 0
                },
                {
                    "sent": "Now will present the results.",
                    "label": 0
                },
                {
                    "sent": "First we compare the performance of predictive clustering trees and examples of predictive clustering trees using the area under the average curve.",
                    "label": 0
                },
                {
                    "sent": "Ensemble methods outperform the single predicted clustering trees as we expected.",
                    "label": 1
                },
                {
                    "sent": "Here we have the significance factor.",
                    "label": 0
                },
                {
                    "sent": "Random forest outperforms begging.",
                    "label": 0
                },
                {
                    "sent": "The random forest method is around 10 points faster than begging.",
                    "label": 1
                },
                {
                    "sent": "And the worst performance of all our algorithms on the image Clef 2008.",
                    "label": 0
                },
                {
                    "sent": "That data set compared to the image Clef 2007 datasets becausw the here here the hierarchy in this data.",
                    "label": 0
                },
                {
                    "sent": "In this data set is much bigger.",
                    "label": 0
                },
                {
                    "sent": "We have 195 nodes in the 2008 DOT data set and only 140 nodes in the here here for the image Clef 2007.",
                    "label": 0
                }
            ]
        },
        "clip_56": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Dataset.",
                    "label": 0
                },
                {
                    "sent": "Now let us compare the predicted performance of the individual feature extraction algorithms.",
                    "label": 1
                },
                {
                    "sent": "Local binary patterns, pattern and scale invariant feature transform histogram are most capable of capturing the hierarchical structure of the X Ray images.",
                    "label": 1
                },
                {
                    "sent": "Then she stuck in the script or feature perform slightly worse.",
                    "label": 0
                },
                {
                    "sent": "We compare to this two.",
                    "label": 1
                },
                {
                    "sent": "And the simplest descriptor obtained from the row pixel representation has worse performance as we expected.",
                    "label": 0
                },
                {
                    "sent": "Inclusion of more than one type of feature in the classification process helps to further improve the predictive performance if we concatenate local binary pattern H histogram descriptor and scale invariant feature feature transform transform, we will obtain the highest highest score for the image Clef 2007 data set and if we concatenate local binary patterns and scale invariant feature transform, we will obtain the best.",
                    "label": 1
                },
                {
                    "sent": "Value for the image Clef 2008 data set.",
                    "label": 0
                },
                {
                    "sent": "You have any idea whether these differences in performance is significant, yeah?",
                    "label": 0
                },
                {
                    "sent": "We have the.",
                    "label": 0
                },
                {
                    "sent": "The significant factors calculated here.",
                    "label": 0
                },
                {
                    "sent": "So these are when you compare the metal, yeah?",
                    "label": 0
                },
                {
                    "sent": "What test do you use?",
                    "label": 0
                },
                {
                    "sent": "Wilcox said, yeah.",
                    "label": 0
                },
                {
                    "sent": "If you go to the next slide.",
                    "label": 0
                },
                {
                    "sent": "Oh yeah, for the feature extraction techniques we don't have the.",
                    "label": 0
                },
                {
                    "sent": "We didn't check check.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "For example, I would say intuitively, OK, LBP and LBP plus see if there should be some difference there.",
                    "label": 0
                },
                {
                    "sent": "But when you when you look between LBP plus shift versus LBP plus C plus EHD, which is a bit better, but maybe the difference to LP plus shift is not really significant.",
                    "label": 0
                },
                {
                    "sent": "Will check that.",
                    "label": 0
                }
            ]
        },
        "clip_57": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "From the precision recall curves, we can also note that I predicted performance of the local binary pattern operator and SIFT histogram.",
                    "label": 0
                },
                {
                    "sent": "If you.",
                    "label": 0
                },
                {
                    "sent": "Oh, they they have quite similar.",
                    "label": 0
                }
            ]
        },
        "clip_58": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Formance we also compare tower approach with a flat classification approach using support vector machines.",
                    "label": 0
                },
                {
                    "sent": "By the image Clef error measure, random forest of predictive clustering trees are superior.",
                    "label": 0
                },
                {
                    "sent": "Today SVM's SVM approach for all feature extraction algorithms and their combination.",
                    "label": 1
                },
                {
                    "sent": "On which proves our point that exploit exploiting the structure of the karahi codes help in improving the predictive performance.",
                    "label": 1
                },
                {
                    "sent": "Furthermore, the value of 160 six 65.23 for the image Clef 2008 data set is the best error score reported so far for this problem in the literature and the error score.",
                    "label": 0
                },
                {
                    "sent": "Of 65.89 is just one point worse than the best error Score Score report reported so far for the image Clef 2007.",
                    "label": 0
                }
            ]
        },
        "clip_59": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Dataset.",
                    "label": 0
                },
                {
                    "sent": "That's about all now I will.",
                    "label": 0
                }
            ]
        },
        "clip_60": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Conclude the presentation.",
                    "label": 0
                },
                {
                    "sent": "I've presented a general approach to hierarchical image annotation and visual concept detection.",
                    "label": 1
                },
                {
                    "sent": "We achieved excellent predictive performance compared to the other approaches.",
                    "label": 0
                },
                {
                    "sent": "For medical images and for general images also, I will say something about this later.",
                    "label": 1
                },
                {
                    "sent": "The system is easily extendable with new feature extraction methods, algorithms and it can be easily applied to other domains.",
                    "label": 0
                },
                {
                    "sent": "Type of images and other classification schemes.",
                    "label": 0
                },
                {
                    "sent": "The system this approach was already applied for the image Clef competition part of the International Conference on Pattern.",
                    "label": 0
                },
                {
                    "sent": "Recognition about about annotation of general images and we achieved achieved quite good performance here.",
                    "label": 0
                },
                {
                    "sent": "Actually we ranked second among the participation groups in the International Conference on Pattern Recognition.",
                    "label": 0
                },
                {
                    "sent": "Which proves our point that this is very general approach for hierarchical annotation of images.",
                    "label": 0
                },
                {
                    "sent": "That's so cute.",
                    "label": 0
                },
                {
                    "sent": "Precious.",
                    "label": 0
                },
                {
                    "sent": "I have quite a few.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "One of the issues at the very beginning of the talk you were arguing that OK, people don't like annotating their personal photos.",
                    "label": 0
                },
                {
                    "sent": "And I agree with that.",
                    "label": 0
                },
                {
                    "sent": "I'm the lazy one.",
                    "label": 0
                },
                {
                    "sent": "I remember my personal photos.",
                    "label": 0
                },
                {
                    "sent": "However, if we're talking about medical images, you know those are taken in an institutional setup.",
                    "label": 0
                },
                {
                    "sent": "You have medical doctors that actually have to perform a diagnosis based on the on the image, so they actually obligated to provide.",
                    "label": 0
                },
                {
                    "sent": "Someone rotation of the of the image.",
                    "label": 0
                },
                {
                    "sent": "This earily nicely.",
                    "label": 0
                },
                {
                    "sent": "Here are Hickory structures in this case, but typically they would have to say something.",
                    "label": 0
                },
                {
                    "sent": "Yes, yes, that's true, but considering the fact that there is a very huge amount of data that is produced in the.",
                    "label": 0
                },
                {
                    "sent": "Medical Department's I think that first they can go with this process of automatic annotation and then to correct some problems.",
                    "label": 0
                },
                {
                    "sent": "Thought that it would be useful to have the automated annotation, but I view this is this would be primarily an additional tool and not to be using.",
                    "label": 0
                },
                {
                    "sent": "Yes, yeah.",
                    "label": 0
                },
                {
                    "sent": "The the other the other issue.",
                    "label": 0
                },
                {
                    "sent": "If anybody else has any questions, we were just jumping, but then I can, otherwise I will go on and I will ask you one more question.",
                    "label": 0
                },
                {
                    "sent": "So the the other the other issue is some more powerful than you know logical issue.",
                    "label": 0
                },
                {
                    "sent": "You talk about descriptors.",
                    "label": 0
                },
                {
                    "sent": "Need the singular use of the word descriptor would mean one column in the in the table and you use it more in the sense.",
                    "label": 0
                },
                {
                    "sent": "OK, this is a set of columns in the table which have been possibly derived using one algorithm.",
                    "label": 0
                },
                {
                    "sent": "So for example the edge.",
                    "label": 0
                },
                {
                    "sent": "Is actually a set of columns that he actually distribution of ages.",
                    "label": 0
                },
                {
                    "sent": "Is this standard terminology to use the singular?",
                    "label": 0
                },
                {
                    "sent": "Yes, which is standard and terminology.",
                    "label": 0
                },
                {
                    "sent": "The entire vector, yeah?",
                    "label": 0
                },
                {
                    "sent": "For somebody who's been in machine learning for too long and then when you say you expect a single single goal.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "The.",
                    "label": 0
                },
                {
                    "sent": "Next question I have is on the comparison tool to SVM so.",
                    "label": 0
                },
                {
                    "sent": "The ensembles you use are ensembles or.",
                    "label": 0
                },
                {
                    "sent": "Please book article of a multi level.",
                    "label": 0
                },
                {
                    "sent": "Yes no the SVM so you use for flat flat classification.",
                    "label": 0
                },
                {
                    "sent": "Work on actually SVM's for construction prediction that are able to take into account some sort of structure of India.",
                    "label": 0
                },
                {
                    "sent": "You can either have flat SBM's and then on top of that.",
                    "label": 0
                },
                {
                    "sent": "I don't know.",
                    "label": 0
                },
                {
                    "sent": "He was a Bayesian them yeah told to take into account here or here.",
                    "label": 0
                },
                {
                    "sent": "Gene function, or you can actually directly predict the structure, yes, But the best approach is so far until our work.",
                    "label": 0
                },
                {
                    "sent": "Was done with the SVM.",
                    "label": 0
                },
                {
                    "sent": "Some treating the problem as a flat classification problem.",
                    "label": 0
                },
                {
                    "sent": "That's why we compared with that approach, actually.",
                    "label": 0
                },
                {
                    "sent": "It may simply be just like this approach was not tried before for the hierarchical classification of images.",
                    "label": 0
                },
                {
                    "sent": "It can well be that the hierarchical SVM have not been tried.",
                    "label": 0
                },
                {
                    "sent": "Yeah, question is kept even tried it no no no no no, only SVM for flat classification not.",
                    "label": 0
                },
                {
                    "sent": "Listing to try SVM spoke hierarchical classification and compare them both to the cities for hierarchical classification on one hand and then to flat SVM Sunday on the other hand.",
                    "label": 0
                },
                {
                    "sent": "Can be interested.",
                    "label": 0
                },
                {
                    "sent": "Phone.",
                    "label": 0
                },
                {
                    "sent": "In that case, I think it's a again.",
                    "label": 0
                },
                {
                    "sent": "Thank you again.",
                    "label": 0
                }
            ]
        }
    }
}