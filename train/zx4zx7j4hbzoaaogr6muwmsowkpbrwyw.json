{
    "id": "zx4zx7j4hbzoaaogr6muwmsowkpbrwyw",
    "title": "Learning to combine foveal glimpses with a third-order Boltzmann machine",
    "info": {
        "author": [
            "Hugo Larochelle, Google, Inc."
        ],
        "published": "Jan. 12, 2011",
        "recorded": "December 2010",
        "category": [
            "Top->Computer Science->Computer Vision"
        ]
    },
    "url": "http://videolectures.net/nips2010_larochelle_lcf/",
    "segmentation": [
        [
            "Hi everyone, so I'm Hugo.",
            "This is joint work with Geoffrey Hinton, University of Toronto.",
            "Alright."
        ],
        [
            "So this is work about solving vision problems and so for like most vision systems will interested in looking at a particular characteristics of human vision and the two characteristics we're going to look at is the first is that human vision is uses an intelligent fixation point strategy.",
            "That is, we use ISA cards in order to determine the sort of visually salient regions of an image, and the sequence of fixation positions are actually influenced by the task that we have to solve.",
            "Also, when we get information in an image or in the field of view, we actually use a retina and so, which essentially means that we get high resolution in formation near the fixation position, and then lower resolution information as you go away from that position.",
            "So taken together, these two characteristics mean that we can actually ignore part of the part of the image part of the image.",
            "That's not useful for the task one to solve, and in particular, if you're interested in building rich generative models of images that can be interesting because it means that you can.",
            "Only be a good chance of model of these salient regions as opposed to the whole image that can be appealing."
        ],
        [
            "Anne.",
            "However, if you look at most of vision systems and you try to describe them within these two parameters, there you can actually say that there are sort of based on the uniform resolution retina, and they actually fixate everywhere in the image, and they do that by taking the whole image in sort of a holistic manner, or actually extracting the same set of features everywhere in the image at each position.",
            "So in this talk I'm going to talk about our attempt at including these two aspects in a fixation point strategy in the retina into a vision system and.",
            "We did that with the post."
        ],
        [
            "Machine.",
            "Alright, so in this setting we actually cannot use the whole image.",
            "That's the constraint we impose.",
            "We can only query it, so we give a position, I, J and then at that position there's this thing we call a retinal transformation, which is going to give us a glimpse at that position and so effectively what it's doing is that it's taking in some region we called the fovea around the fixation center.",
            "It just copies the Pixel at the output, and it also computes local averages in hexagonal regions of increasing side with eccentricity.",
            "And so you have on your right few examples of glimpses taken from an image of a 2 an.",
            "So what we need is a system that's actually able to take these glimpses and the associated positions and combine them to make a good prediction about here.",
            "The class of the image, and we also need a component that's actually going to tell us where to look in an image."
        ],
        [
            "Alright, so there are these two components which I call recognition components an intentional component, so I'll first focus on the 1st component.",
            "So for now, we'll assume somebody's telling us where to actually look in the image."
        ],
        [
            "Alright, so for that we're going to use a variant on the restricted Boltzmann machine or DBM, so I'll first describe the basic model.",
            "So in GBM is bipartite Marco Random Field where we model the distribution of observations with a layer of binary hidden units.",
            "And here in observation is an input image and a label Y.",
            "And so to do that, we essentially parameterized the interactions between the hidden units with the matrix W, and we also paralyzed the.",
            "So that's the interactions between the image and the hidden units, and the interactions between the hidden units and the labels.",
            "Parent tries my matrix you.",
            "And then to get a actual distribution over these things, you just take the exponential of the negative energy and normalized.",
            "Now the normalization constant.",
            "Then we normally cannot compute it exactly, but the army as other interesting characteristics which are going to be useful here."
        ],
        [
            "So one of them is that inference is easy.",
            "That is, if you give it an observation, the conditional distribution of the hidden units is actually factorial, so they're all in conditionally independent, and the same thing is true given the value of the hidden layer.",
            "All the observation elements are actually independent, so that."
        ],
        [
            "We can do Gibbs sampling really efficiently and given some observation, we can use the vector of probabilities of the hidden units being equal to 1 as a sort of more abstract representation of our observation."
        ],
        [
            "Another interesting characteristics is that classification is easy and tractable.",
            "If you give it some observation, some input image, we can compute the full posterior of probability of the label given the image that is marginalizing over the hidden units.",
            "And so you have the formula here.",
            "The exact formula is not really important.",
            "The main thing to remember is that that computation can be done efficiently in exam."
        ],
        [
            "Alright, so now in this setting we want to adapt the PBM by changing the full image with cleanses that are taken from Big K number."
        ],
        [
            "Stations here we have."
        ],
        [
            "Three fixations and the way we do that is that we connect these glimpses that glistens RDX variables.",
            "The X factors we connect them to the hidden layer by a matrix which actually depends on the fixation position.",
            "So X1 the clips.",
            "The first glimpse is connected with by Matrix W I1J1.",
            "To the hidden units, and so you can think of this.",
            "The naive implementation of this will have a separate set of parameters.",
            "Separate matrix for each possible fixation position in the image.",
            "Now."
        ],
        [
            "So we call this RBM multi fixation.",
            "GBM is actually part of the larger family of 3rd order Boltzmann machine because yeah effectively have interactions between hidden units, input units and the position units on which, so that position inj on which we condition."
        ],
        [
            "Alright, so now I've told you that you know the nave implementation.",
            "We actually have a separate matrix for each position, but that's too many parameters, so we introduce a weight factorization.",
            "So W like case for The Cave fixation is going to be decomposed into three matrices.",
            "The first one on your right is the filter matrix, which is the position independent.",
            "Then there's the gaining matrix, which is a diagonal matrix where the vector on the diagonal is actually independent is dependent on the position.",
            "And then we have another pooling matrix and so the idea here is that the matrix in the middle is effectively going to select some of the rows of the F matrix.",
            "Some of the features or filters that are going to be used to combine information to the hidden layer."
        ],
        [
            "So.",
            "So now we only have to learn a vector for each position as opposed to."
        ],
        [
            "Matrix and then to understand this with factorization we can just look at what happens if we multiply by glimpse.",
            "So if you have the first glimpse position I1J1, then first we multiply."
        ],
        [
            "The filters so we get filter outputs."
        ],
        [
            "And we multiply by this diagonal matrix with.",
            "Effectively corresponds to doing and elementwise multiplication between that said, vector and the filter outputs.",
            "So perhaps it would be zeroing out some of the filter outputs, just ignoring them."
        ],
        [
            "And then multiply by the pooling matrix."
        ],
        [
            "And if we look at what happens if we multiply, are safe for the second glimpse, the only thing that changes is that set factor.",
            "So we effectively put emphasis on different filters in that filter matrix."
        ],
        [
            "Alright."
        ],
        [
            "Now we've defined a model.",
            "How do we train it?",
            "There are different things we could do.",
            "First thing could be discriminative training.",
            "So the cost here to minimize would be the negative log probability of the label given the input.",
            "So we're focusing on predicting the label given our glimpses.",
            "The input.",
            "We could do generative learning that is also learned statistical structure within the input.",
            "But actually works.",
            "Best is to take a linear combination between those two objectives and control with this hyperparameter Alpha how much we want to do generative learning.",
            "So effectively this part of the cost.",
            "The generative cost sort of acts as a data dependent regularizer.",
            "And then we also looked at a hybrid.",
            "Sorry sequential version of the hybrid, where instead of waiting after having gotten all of the K fixations to make an update of the PBM, we actually make an update every time we add a new fixation.",
            "So every time a new fixation is mainly try to predict why.",
            "The label an with some weight.",
            "We also try to model the distribution of the next glimpse given the previous glimpses and the position of the new columns.",
            "So I don't have really much time to describe how to get gradients for these different costs, but essentially it's based on contrastive divergent San details, aren't they?"
        ],
        [
            "Alright, so I've talked about the recognition component Now what about the attentional component?",
            "How do we decide?"
        ],
        [
            "To look in an image so the way we so the problem is that given the K -- 1 previous fixations, we need to determine what's the position of The Cave fixation.",
            "And so to do that the way."
        ],
        [
            "We decided to tackle this problem.",
            "First we define what we call a summary vector S case.",
            "So this summary vector is sort of a feature vector of what we know about the image from these K -- 1 previous fixations, and so in that vector you could put different things.",
            "We decided to put a binary histogram representation of the positions of the previous fixations, as well as the hidden representation of the RBM condition on these K -- 1 previous fixations.",
            "OK, so an estimate of the probability of each of the hidden unit in the PBM.",
            "For these K -- 1 previous fixations, kind of makes sense.",
            "That's the PBM is sort of learning a representation of its input, so to use that seems sensible."
        ],
        [
            "Now, after that we actually define a coarse grid on the image, so this will be a grid of possible fixation position."
        ],
        [
            "And then we will learn is scoring function over that grid so that scoring function its goal is to determine make a prediction of how useful it would be to fix it up at a particular position in the image.",
            "Given this summary vector S and the actual position you're considering.",
            "So to model the scoring function, we just use a linear transformation.",
            "So multiplied the vector S by a weight vector and we have a separate weight vector for each position under grim.",
            "So effectively again in the.",
            "Prediction of the score outputs over the whole grid is just a matrix vector multiplication.",
            "Alright."
        ],
        [
            "So now we need to define what it means to be useful to fixate somewhere.",
            "And you could think of different objectives for that.",
            "The one that we considered which worked well is that we looked at the log probability of the true label given the K -- 1 previous fixations and the new fixation that we're making at the considered position.",
            "And."
        ],
        [
            "So in other words, the scoring function is going to try to predict what's going to happen to the lock probability under the RBM of the true label.",
            "If we fix it at this considered position, and in order to train the scoring function, what we can do is simply take the fixation dollar generating during training, the PBM, and also train the controller such that it's good at predicting this slog probability.",
            "Now test time we can just sequentially take the most useful fixation positions.",
            "But then a training time in order to explore different fixation strategies, we actually sample from the scoring function.",
            "So we just take the softmax over the scoring function outputs over the grid, and we normalize by over the remaining possible fixation positions."
        ],
        [
            "So let's put this all together into a sort of cartoonish illustration of the."
        ],
        [
            "So first."
        ],
        [
            "Compute S and then from that we get a distribution for where to fixate.",
            "So here we have a 55 by 5 grid of possible fixation positions."
        ],
        [
            "Then we sample from that distribution."
        ],
        [
            "And introduce the glimpse at that position in the original image and connect it to the hidden layer."
        ],
        [
            "Then we update the controller so that it's good at predicting the lug likely probability of the correct label after introducing disclaims."
        ],
        [
            "And then we update."
        ],
        [
            "Rs vector get a new distribution for where to."
        ],
        [
            "Fixate sample fixation position an inch."
        ],
        [
            "Deuce, the glimpse at that position."
        ],
        [
            "And once again we look at what happened.",
            "How did the lug probability of the correct label change and actually update the scoring scoring output for that position so that it's now better at predicting that by just a gradient step essentially?",
            "And we continue."
        ],
        [
            "Like that for all possible."
        ],
        [
            "Fixations."
        ],
        [
            "So all the."
        ],
        [
            "I mean, all the fixations we want to allow in the model so."
        ],
        [
            "That's three.",
            "And."
        ],
        [
            "Then at the end, we actually update the parameters of the of the multi fixation RPM, so that's if were and then you choose the objective.",
            "It could be discriminative, generative or hybrid.",
            "And if we had used the sequential version of the hybrid objective, we would actually update the PBM every time a new fixed."
        ],
        [
            "It would be made."
        ],
        [
            "Alright.",
            "Now before I talk about the experiments, just want to mention the few related work.",
            "There's more than that, but these two are particularly relevant now.",
            "The first one, which seems only fair to mention, is work by all paid in 15 years ago, where they use the neural net to accumulate fixations.",
            "Dollar sample from a fixed side, and see map so saliency map.",
            "Computer over the whole image is actually not learned.",
            "It was determined by hand and then this year Canon control actually have this pretty interesting model where they actually learn the saliency map.",
            "Which is used to sample independently fixation positions on the image, and those are combined by nonparametric nearest neighbor recognition model.",
            "And so they actually have.",
            "I really encourage people to check that paper out.",
            "They actually have really good performance on challenging problems.",
            "So in this particular work, the main difference is that we actually propose a way of jointly training a recognition component and attentional component.",
            "And also we explicitly avoid looking everywhere in the image which is not actually true if you compute the saliency map over the whole high resolution image, that effectively corresponds to looking everywhere in the image.",
            "OK, so that's the main difference."
        ],
        [
            "Alright, so experiments.",
            "I've had three different experiments.",
            "The first one we focus our evaluation on the multi fixation DBM.",
            "Then we actually focused evaluation on the controller and then on the whole system."
        ],
        [
            "So the first experiments quickly we have to classify images of digits into 10 different classes, and here there's no controller.",
            "We always feed the same for fixations of the same for positions for all images, and then we compared with pre trained neural net and SVM.",
            "Both are being trained on the whole images, but of course not the multi fixation PBM.",
            "It uses the fixation positions and as you can see you do.",
            "It does a pretty good job.",
            "So that part of this system seems to be working sometimes a bit better than the.",
            "The methods on the whole image sometimes have been worse, but that part of this system seems to be doing fine."
        ],
        [
            "Then we designed the synthetic problem.",
            "Where I've been having the correct fixation policy is really important to solve it, and so in this problem we have a binary image, so binary pixels and it's a binary classification problem.",
            "We have to distinguish between two classes and it actually corresponds to identifying whether there is a horizontal or vertical bar somewhere near the border of the image.",
            "Also, there's this symbol at the center of the image.",
            "That sort of points towards the region where the bar is.",
            "So the way to solve this problem is to first look at the center an after looking at the center based on the symbol that's there, determine where you should look next, where is the bar, look there and then have the multi fixation are being determined.",
            "The orientation of the bar.",
            "And."
        ],
        [
            "So the main result is that if you actually train the RBM using the hybrid objective and it's actually able to solve this problem perfectly, which is great.",
            "However, if you use the descriptive objective for training the multi fixation GBM, so just change the actual cost for updating the PBM within that system.",
            "It actually fails and the main reason for this, we think, is that the symbol in the middle actually conveys no discriminative information.",
            "All that it says is where the bar is, but it doesn't tell you what the orientation of the bars.",
            "So that means that the PBM doesn't learn a meaningful representation of that symbol.",
            "And then because of that, since the controller actually uses that representation to make predictions for where to look, Next's actually not able to determine what's the right fixation position."
        ],
        [
            "And then final experiment.",
            "So we are classifying images of faces 9696 pixels so classified into seven different classes, or facial expressions which you see here.",
            "So we compare the system with six fixations.",
            "With an SVM that's actually trained on the whole image, and so here the controller also learns where to fix it in the image.",
            "And so as you can see, after six fixations actually does better, and for this particular problem we also only use the fovea for the retinal transformation.",
            "In order to be able to say something objective about how many high resolution pixels from the image is actually used by the system, every time you do a new fixation and do."
        ],
        [
            "Yes, we are able to say that after three fixation, it actually has seen at most 60% of the image.",
            "And yet it actually performs as well as an SVM trained on the whole image.",
            "So so that's good."
        ],
        [
            "And then finally we can actually look at what kind of fixations are sort of policy or fixation sequences are learned by the controller an we observe something that makes sense.",
            "It first looks at the mouth, which is quite informative with respect to what the class of the images and then often looks at the eyes, after which also informative.",
            "So that's good.",
            "Alright."
        ],
        [
            "Sorry to sum up, we've investigating the model for gently learning a recognition attentional component, and we've done that with the 3rd order Boltzmann machine, and there's still quite a lot of things to do with that kind of particular approach.",
            "Would like to look at what's the impact of a retinal transformation, for instance on the performance, the size of the fovea, the size of the periphery, and also, could we improve the controller algorithm, for instance by looking at the reinforcement learning literature.",
            "So for those who've been at.",
            "Tutorial on embedded cognition.",
            "We've seen some examples of people thinking about how to do that, and that could be probably incorporated into a system like this, and also how to do multi task learning.",
            "Imagine you have multiple tasks to solve for a given image, then how to learn a single controller that's able to solve all of these tasks well."
        ],
        [
            "And that's it.",
            "Thank you.",
            "OK, any questions?",
            "Alright, I'll quickly as one, so I was wondering that a lot of these eye fixation models in literature tend to use bottom up saliency cues, and I wondered where they thought about incorporating those into a model tool or they somehow redundant, right?",
            "So I guess that we really wanted to look at a particular approach where the constraint is really, you don't actually look everywhere, but I guess you could do saliency within the retinal transformation, so that's definitely possible.",
            "I think some people have actually done this, but where?",
            "They've used like useful features from the vision literature and here really interested in actually learning everything, but that's definitely doable, yes?",
            "OK, what if another questions thank the speaker again."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Hi everyone, so I'm Hugo.",
                    "label": 0
                },
                {
                    "sent": "This is joint work with Geoffrey Hinton, University of Toronto.",
                    "label": 1
                },
                {
                    "sent": "Alright.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this is work about solving vision problems and so for like most vision systems will interested in looking at a particular characteristics of human vision and the two characteristics we're going to look at is the first is that human vision is uses an intelligent fixation point strategy.",
                    "label": 1
                },
                {
                    "sent": "That is, we use ISA cards in order to determine the sort of visually salient regions of an image, and the sequence of fixation positions are actually influenced by the task that we have to solve.",
                    "label": 0
                },
                {
                    "sent": "Also, when we get information in an image or in the field of view, we actually use a retina and so, which essentially means that we get high resolution in formation near the fixation position, and then lower resolution information as you go away from that position.",
                    "label": 0
                },
                {
                    "sent": "So taken together, these two characteristics mean that we can actually ignore part of the part of the image part of the image.",
                    "label": 0
                },
                {
                    "sent": "That's not useful for the task one to solve, and in particular, if you're interested in building rich generative models of images that can be interesting because it means that you can.",
                    "label": 0
                },
                {
                    "sent": "Only be a good chance of model of these salient regions as opposed to the whole image that can be appealing.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "However, if you look at most of vision systems and you try to describe them within these two parameters, there you can actually say that there are sort of based on the uniform resolution retina, and they actually fixate everywhere in the image, and they do that by taking the whole image in sort of a holistic manner, or actually extracting the same set of features everywhere in the image at each position.",
                    "label": 1
                },
                {
                    "sent": "So in this talk I'm going to talk about our attempt at including these two aspects in a fixation point strategy in the retina into a vision system and.",
                    "label": 0
                },
                {
                    "sent": "We did that with the post.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Machine.",
                    "label": 0
                },
                {
                    "sent": "Alright, so in this setting we actually cannot use the whole image.",
                    "label": 0
                },
                {
                    "sent": "That's the constraint we impose.",
                    "label": 0
                },
                {
                    "sent": "We can only query it, so we give a position, I, J and then at that position there's this thing we call a retinal transformation, which is going to give us a glimpse at that position and so effectively what it's doing is that it's taking in some region we called the fovea around the fixation center.",
                    "label": 0
                },
                {
                    "sent": "It just copies the Pixel at the output, and it also computes local averages in hexagonal regions of increasing side with eccentricity.",
                    "label": 0
                },
                {
                    "sent": "And so you have on your right few examples of glimpses taken from an image of a 2 an.",
                    "label": 0
                },
                {
                    "sent": "So what we need is a system that's actually able to take these glimpses and the associated positions and combine them to make a good prediction about here.",
                    "label": 0
                },
                {
                    "sent": "The class of the image, and we also need a component that's actually going to tell us where to look in an image.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Alright, so there are these two components which I call recognition components an intentional component, so I'll first focus on the 1st component.",
                    "label": 0
                },
                {
                    "sent": "So for now, we'll assume somebody's telling us where to actually look in the image.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Alright, so for that we're going to use a variant on the restricted Boltzmann machine or DBM, so I'll first describe the basic model.",
                    "label": 1
                },
                {
                    "sent": "So in GBM is bipartite Marco Random Field where we model the distribution of observations with a layer of binary hidden units.",
                    "label": 0
                },
                {
                    "sent": "And here in observation is an input image and a label Y.",
                    "label": 0
                },
                {
                    "sent": "And so to do that, we essentially parameterized the interactions between the hidden units with the matrix W, and we also paralyzed the.",
                    "label": 0
                },
                {
                    "sent": "So that's the interactions between the image and the hidden units, and the interactions between the hidden units and the labels.",
                    "label": 0
                },
                {
                    "sent": "Parent tries my matrix you.",
                    "label": 0
                },
                {
                    "sent": "And then to get a actual distribution over these things, you just take the exponential of the negative energy and normalized.",
                    "label": 0
                },
                {
                    "sent": "Now the normalization constant.",
                    "label": 0
                },
                {
                    "sent": "Then we normally cannot compute it exactly, but the army as other interesting characteristics which are going to be useful here.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So one of them is that inference is easy.",
                    "label": 0
                },
                {
                    "sent": "That is, if you give it an observation, the conditional distribution of the hidden units is actually factorial, so they're all in conditionally independent, and the same thing is true given the value of the hidden layer.",
                    "label": 0
                },
                {
                    "sent": "All the observation elements are actually independent, so that.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We can do Gibbs sampling really efficiently and given some observation, we can use the vector of probabilities of the hidden units being equal to 1 as a sort of more abstract representation of our observation.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Another interesting characteristics is that classification is easy and tractable.",
                    "label": 1
                },
                {
                    "sent": "If you give it some observation, some input image, we can compute the full posterior of probability of the label given the image that is marginalizing over the hidden units.",
                    "label": 0
                },
                {
                    "sent": "And so you have the formula here.",
                    "label": 0
                },
                {
                    "sent": "The exact formula is not really important.",
                    "label": 0
                },
                {
                    "sent": "The main thing to remember is that that computation can be done efficiently in exam.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Alright, so now in this setting we want to adapt the PBM by changing the full image with cleanses that are taken from Big K number.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Stations here we have.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Three fixations and the way we do that is that we connect these glimpses that glistens RDX variables.",
                    "label": 0
                },
                {
                    "sent": "The X factors we connect them to the hidden layer by a matrix which actually depends on the fixation position.",
                    "label": 0
                },
                {
                    "sent": "So X1 the clips.",
                    "label": 0
                },
                {
                    "sent": "The first glimpse is connected with by Matrix W I1J1.",
                    "label": 0
                },
                {
                    "sent": "To the hidden units, and so you can think of this.",
                    "label": 0
                },
                {
                    "sent": "The naive implementation of this will have a separate set of parameters.",
                    "label": 0
                },
                {
                    "sent": "Separate matrix for each possible fixation position in the image.",
                    "label": 0
                },
                {
                    "sent": "Now.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we call this RBM multi fixation.",
                    "label": 0
                },
                {
                    "sent": "GBM is actually part of the larger family of 3rd order Boltzmann machine because yeah effectively have interactions between hidden units, input units and the position units on which, so that position inj on which we condition.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Alright, so now I've told you that you know the nave implementation.",
                    "label": 0
                },
                {
                    "sent": "We actually have a separate matrix for each position, but that's too many parameters, so we introduce a weight factorization.",
                    "label": 0
                },
                {
                    "sent": "So W like case for The Cave fixation is going to be decomposed into three matrices.",
                    "label": 0
                },
                {
                    "sent": "The first one on your right is the filter matrix, which is the position independent.",
                    "label": 0
                },
                {
                    "sent": "Then there's the gaining matrix, which is a diagonal matrix where the vector on the diagonal is actually independent is dependent on the position.",
                    "label": 0
                },
                {
                    "sent": "And then we have another pooling matrix and so the idea here is that the matrix in the middle is effectively going to select some of the rows of the F matrix.",
                    "label": 0
                },
                {
                    "sent": "Some of the features or filters that are going to be used to combine information to the hidden layer.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "So now we only have to learn a vector for each position as opposed to.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Matrix and then to understand this with factorization we can just look at what happens if we multiply by glimpse.",
                    "label": 0
                },
                {
                    "sent": "So if you have the first glimpse position I1J1, then first we multiply.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The filters so we get filter outputs.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we multiply by this diagonal matrix with.",
                    "label": 0
                },
                {
                    "sent": "Effectively corresponds to doing and elementwise multiplication between that said, vector and the filter outputs.",
                    "label": 0
                },
                {
                    "sent": "So perhaps it would be zeroing out some of the filter outputs, just ignoring them.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then multiply by the pooling matrix.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And if we look at what happens if we multiply, are safe for the second glimpse, the only thing that changes is that set factor.",
                    "label": 0
                },
                {
                    "sent": "So we effectively put emphasis on different filters in that filter matrix.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Alright.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now we've defined a model.",
                    "label": 0
                },
                {
                    "sent": "How do we train it?",
                    "label": 0
                },
                {
                    "sent": "There are different things we could do.",
                    "label": 0
                },
                {
                    "sent": "First thing could be discriminative training.",
                    "label": 0
                },
                {
                    "sent": "So the cost here to minimize would be the negative log probability of the label given the input.",
                    "label": 0
                },
                {
                    "sent": "So we're focusing on predicting the label given our glimpses.",
                    "label": 0
                },
                {
                    "sent": "The input.",
                    "label": 0
                },
                {
                    "sent": "We could do generative learning that is also learned statistical structure within the input.",
                    "label": 0
                },
                {
                    "sent": "But actually works.",
                    "label": 0
                },
                {
                    "sent": "Best is to take a linear combination between those two objectives and control with this hyperparameter Alpha how much we want to do generative learning.",
                    "label": 0
                },
                {
                    "sent": "So effectively this part of the cost.",
                    "label": 0
                },
                {
                    "sent": "The generative cost sort of acts as a data dependent regularizer.",
                    "label": 0
                },
                {
                    "sent": "And then we also looked at a hybrid.",
                    "label": 0
                },
                {
                    "sent": "Sorry sequential version of the hybrid, where instead of waiting after having gotten all of the K fixations to make an update of the PBM, we actually make an update every time we add a new fixation.",
                    "label": 0
                },
                {
                    "sent": "So every time a new fixation is mainly try to predict why.",
                    "label": 0
                },
                {
                    "sent": "The label an with some weight.",
                    "label": 0
                },
                {
                    "sent": "We also try to model the distribution of the next glimpse given the previous glimpses and the position of the new columns.",
                    "label": 0
                },
                {
                    "sent": "So I don't have really much time to describe how to get gradients for these different costs, but essentially it's based on contrastive divergent San details, aren't they?",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Alright, so I've talked about the recognition component Now what about the attentional component?",
                    "label": 0
                },
                {
                    "sent": "How do we decide?",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To look in an image so the way we so the problem is that given the K -- 1 previous fixations, we need to determine what's the position of The Cave fixation.",
                    "label": 0
                },
                {
                    "sent": "And so to do that the way.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We decided to tackle this problem.",
                    "label": 0
                },
                {
                    "sent": "First we define what we call a summary vector S case.",
                    "label": 0
                },
                {
                    "sent": "So this summary vector is sort of a feature vector of what we know about the image from these K -- 1 previous fixations, and so in that vector you could put different things.",
                    "label": 1
                },
                {
                    "sent": "We decided to put a binary histogram representation of the positions of the previous fixations, as well as the hidden representation of the RBM condition on these K -- 1 previous fixations.",
                    "label": 0
                },
                {
                    "sent": "OK, so an estimate of the probability of each of the hidden unit in the PBM.",
                    "label": 0
                },
                {
                    "sent": "For these K -- 1 previous fixations, kind of makes sense.",
                    "label": 0
                },
                {
                    "sent": "That's the PBM is sort of learning a representation of its input, so to use that seems sensible.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now, after that we actually define a coarse grid on the image, so this will be a grid of possible fixation position.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And then we will learn is scoring function over that grid so that scoring function its goal is to determine make a prediction of how useful it would be to fix it up at a particular position in the image.",
                    "label": 0
                },
                {
                    "sent": "Given this summary vector S and the actual position you're considering.",
                    "label": 1
                },
                {
                    "sent": "So to model the scoring function, we just use a linear transformation.",
                    "label": 0
                },
                {
                    "sent": "So multiplied the vector S by a weight vector and we have a separate weight vector for each position under grim.",
                    "label": 0
                },
                {
                    "sent": "So effectively again in the.",
                    "label": 0
                },
                {
                    "sent": "Prediction of the score outputs over the whole grid is just a matrix vector multiplication.",
                    "label": 0
                },
                {
                    "sent": "Alright.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So now we need to define what it means to be useful to fixate somewhere.",
                    "label": 0
                },
                {
                    "sent": "And you could think of different objectives for that.",
                    "label": 0
                },
                {
                    "sent": "The one that we considered which worked well is that we looked at the log probability of the true label given the K -- 1 previous fixations and the new fixation that we're making at the considered position.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So in other words, the scoring function is going to try to predict what's going to happen to the lock probability under the RBM of the true label.",
                    "label": 0
                },
                {
                    "sent": "If we fix it at this considered position, and in order to train the scoring function, what we can do is simply take the fixation dollar generating during training, the PBM, and also train the controller such that it's good at predicting this slog probability.",
                    "label": 1
                },
                {
                    "sent": "Now test time we can just sequentially take the most useful fixation positions.",
                    "label": 0
                },
                {
                    "sent": "But then a training time in order to explore different fixation strategies, we actually sample from the scoring function.",
                    "label": 0
                },
                {
                    "sent": "So we just take the softmax over the scoring function outputs over the grid, and we normalize by over the remaining possible fixation positions.",
                    "label": 1
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So let's put this all together into a sort of cartoonish illustration of the.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So first.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Compute S and then from that we get a distribution for where to fixate.",
                    "label": 0
                },
                {
                    "sent": "So here we have a 55 by 5 grid of possible fixation positions.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Then we sample from that distribution.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And introduce the glimpse at that position in the original image and connect it to the hidden layer.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Then we update the controller so that it's good at predicting the lug likely probability of the correct label after introducing disclaims.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then we update.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Rs vector get a new distribution for where to.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Fixate sample fixation position an inch.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Deuce, the glimpse at that position.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And once again we look at what happened.",
                    "label": 0
                },
                {
                    "sent": "How did the lug probability of the correct label change and actually update the scoring scoring output for that position so that it's now better at predicting that by just a gradient step essentially?",
                    "label": 0
                },
                {
                    "sent": "And we continue.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Like that for all possible.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Fixations.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So all the.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I mean, all the fixations we want to allow in the model so.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That's three.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Then at the end, we actually update the parameters of the of the multi fixation RPM, so that's if were and then you choose the objective.",
                    "label": 0
                },
                {
                    "sent": "It could be discriminative, generative or hybrid.",
                    "label": 0
                },
                {
                    "sent": "And if we had used the sequential version of the hybrid objective, we would actually update the PBM every time a new fixed.",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It would be made.",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_50": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Alright.",
                    "label": 0
                },
                {
                    "sent": "Now before I talk about the experiments, just want to mention the few related work.",
                    "label": 0
                },
                {
                    "sent": "There's more than that, but these two are particularly relevant now.",
                    "label": 0
                },
                {
                    "sent": "The first one, which seems only fair to mention, is work by all paid in 15 years ago, where they use the neural net to accumulate fixations.",
                    "label": 0
                },
                {
                    "sent": "Dollar sample from a fixed side, and see map so saliency map.",
                    "label": 1
                },
                {
                    "sent": "Computer over the whole image is actually not learned.",
                    "label": 0
                },
                {
                    "sent": "It was determined by hand and then this year Canon control actually have this pretty interesting model where they actually learn the saliency map.",
                    "label": 0
                },
                {
                    "sent": "Which is used to sample independently fixation positions on the image, and those are combined by nonparametric nearest neighbor recognition model.",
                    "label": 1
                },
                {
                    "sent": "And so they actually have.",
                    "label": 0
                },
                {
                    "sent": "I really encourage people to check that paper out.",
                    "label": 0
                },
                {
                    "sent": "They actually have really good performance on challenging problems.",
                    "label": 1
                },
                {
                    "sent": "So in this particular work, the main difference is that we actually propose a way of jointly training a recognition component and attentional component.",
                    "label": 0
                },
                {
                    "sent": "And also we explicitly avoid looking everywhere in the image which is not actually true if you compute the saliency map over the whole high resolution image, that effectively corresponds to looking everywhere in the image.",
                    "label": 1
                },
                {
                    "sent": "OK, so that's the main difference.",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Alright, so experiments.",
                    "label": 0
                },
                {
                    "sent": "I've had three different experiments.",
                    "label": 0
                },
                {
                    "sent": "The first one we focus our evaluation on the multi fixation DBM.",
                    "label": 0
                },
                {
                    "sent": "Then we actually focused evaluation on the controller and then on the whole system.",
                    "label": 1
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the first experiments quickly we have to classify images of digits into 10 different classes, and here there's no controller.",
                    "label": 0
                },
                {
                    "sent": "We always feed the same for fixations of the same for positions for all images, and then we compared with pre trained neural net and SVM.",
                    "label": 0
                },
                {
                    "sent": "Both are being trained on the whole images, but of course not the multi fixation PBM.",
                    "label": 0
                },
                {
                    "sent": "It uses the fixation positions and as you can see you do.",
                    "label": 0
                },
                {
                    "sent": "It does a pretty good job.",
                    "label": 0
                },
                {
                    "sent": "So that part of this system seems to be working sometimes a bit better than the.",
                    "label": 0
                },
                {
                    "sent": "The methods on the whole image sometimes have been worse, but that part of this system seems to be doing fine.",
                    "label": 0
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Then we designed the synthetic problem.",
                    "label": 0
                },
                {
                    "sent": "Where I've been having the correct fixation policy is really important to solve it, and so in this problem we have a binary image, so binary pixels and it's a binary classification problem.",
                    "label": 0
                },
                {
                    "sent": "We have to distinguish between two classes and it actually corresponds to identifying whether there is a horizontal or vertical bar somewhere near the border of the image.",
                    "label": 1
                },
                {
                    "sent": "Also, there's this symbol at the center of the image.",
                    "label": 0
                },
                {
                    "sent": "That sort of points towards the region where the bar is.",
                    "label": 1
                },
                {
                    "sent": "So the way to solve this problem is to first look at the center an after looking at the center based on the symbol that's there, determine where you should look next, where is the bar, look there and then have the multi fixation are being determined.",
                    "label": 0
                },
                {
                    "sent": "The orientation of the bar.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the main result is that if you actually train the RBM using the hybrid objective and it's actually able to solve this problem perfectly, which is great.",
                    "label": 1
                },
                {
                    "sent": "However, if you use the descriptive objective for training the multi fixation GBM, so just change the actual cost for updating the PBM within that system.",
                    "label": 0
                },
                {
                    "sent": "It actually fails and the main reason for this, we think, is that the symbol in the middle actually conveys no discriminative information.",
                    "label": 0
                },
                {
                    "sent": "All that it says is where the bar is, but it doesn't tell you what the orientation of the bars.",
                    "label": 1
                },
                {
                    "sent": "So that means that the PBM doesn't learn a meaningful representation of that symbol.",
                    "label": 0
                },
                {
                    "sent": "And then because of that, since the controller actually uses that representation to make predictions for where to look, Next's actually not able to determine what's the right fixation position.",
                    "label": 0
                }
            ]
        },
        "clip_55": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then final experiment.",
                    "label": 0
                },
                {
                    "sent": "So we are classifying images of faces 9696 pixels so classified into seven different classes, or facial expressions which you see here.",
                    "label": 0
                },
                {
                    "sent": "So we compare the system with six fixations.",
                    "label": 0
                },
                {
                    "sent": "With an SVM that's actually trained on the whole image, and so here the controller also learns where to fix it in the image.",
                    "label": 0
                },
                {
                    "sent": "And so as you can see, after six fixations actually does better, and for this particular problem we also only use the fovea for the retinal transformation.",
                    "label": 0
                },
                {
                    "sent": "In order to be able to say something objective about how many high resolution pixels from the image is actually used by the system, every time you do a new fixation and do.",
                    "label": 0
                }
            ]
        },
        "clip_56": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Yes, we are able to say that after three fixation, it actually has seen at most 60% of the image.",
                    "label": 1
                },
                {
                    "sent": "And yet it actually performs as well as an SVM trained on the whole image.",
                    "label": 0
                },
                {
                    "sent": "So so that's good.",
                    "label": 0
                }
            ]
        },
        "clip_57": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then finally we can actually look at what kind of fixations are sort of policy or fixation sequences are learned by the controller an we observe something that makes sense.",
                    "label": 0
                },
                {
                    "sent": "It first looks at the mouth, which is quite informative with respect to what the class of the images and then often looks at the eyes, after which also informative.",
                    "label": 0
                },
                {
                    "sent": "So that's good.",
                    "label": 0
                },
                {
                    "sent": "Alright.",
                    "label": 0
                }
            ]
        },
        "clip_58": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Sorry to sum up, we've investigating the model for gently learning a recognition attentional component, and we've done that with the 3rd order Boltzmann machine, and there's still quite a lot of things to do with that kind of particular approach.",
                    "label": 1
                },
                {
                    "sent": "Would like to look at what's the impact of a retinal transformation, for instance on the performance, the size of the fovea, the size of the periphery, and also, could we improve the controller algorithm, for instance by looking at the reinforcement learning literature.",
                    "label": 0
                },
                {
                    "sent": "So for those who've been at.",
                    "label": 0
                },
                {
                    "sent": "Tutorial on embedded cognition.",
                    "label": 0
                },
                {
                    "sent": "We've seen some examples of people thinking about how to do that, and that could be probably incorporated into a system like this, and also how to do multi task learning.",
                    "label": 0
                },
                {
                    "sent": "Imagine you have multiple tasks to solve for a given image, then how to learn a single controller that's able to solve all of these tasks well.",
                    "label": 0
                }
            ]
        },
        "clip_59": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And that's it.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                },
                {
                    "sent": "OK, any questions?",
                    "label": 0
                },
                {
                    "sent": "Alright, I'll quickly as one, so I was wondering that a lot of these eye fixation models in literature tend to use bottom up saliency cues, and I wondered where they thought about incorporating those into a model tool or they somehow redundant, right?",
                    "label": 0
                },
                {
                    "sent": "So I guess that we really wanted to look at a particular approach where the constraint is really, you don't actually look everywhere, but I guess you could do saliency within the retinal transformation, so that's definitely possible.",
                    "label": 0
                },
                {
                    "sent": "I think some people have actually done this, but where?",
                    "label": 0
                },
                {
                    "sent": "They've used like useful features from the vision literature and here really interested in actually learning everything, but that's definitely doable, yes?",
                    "label": 0
                },
                {
                    "sent": "OK, what if another questions thank the speaker again.",
                    "label": 0
                }
            ]
        }
    }
}