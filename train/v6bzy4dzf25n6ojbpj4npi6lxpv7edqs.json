{
    "id": "v6bzy4dzf25n6ojbpj4npi6lxpv7edqs",
    "title": "Where machine vision needs help from machine learning",
    "info": {
        "author": [
            "William T. Freeman, Department of Electrical Engineering and Computer Science, Massachusetts Institute of Technology, MIT"
        ],
        "published": "Aug. 2, 2011",
        "recorded": "July 2011",
        "category": [
            "Top->Computer Science->Machine Learning"
        ]
    },
    "url": "http://videolectures.net/colt2011_freeman_help/",
    "segmentation": [
        [
            "I'm, uh, an emissary from another community here.",
            "I work in."
        ],
        [
            "Computer vision and.",
            "The kind of thing is we're stuck with some of these hard problems, and God would be cool if we could get the people that called.",
            "Really, you know, there are a lot of smart people there.",
            "Get them excited about our problems too, so that's that's the goal here.",
            "So I want to start out by telling you how I got interested in computer vision.",
            "And talk about kind of the state of the art in computer vision now.",
            "What sort of applications there are?",
            "What we can do and then start talking about open issues and places where we're stuck.",
            "So it starts out."
        ],
        [
            "Kind of as a travel log, here's.",
            "I live for a year in China with my wife.",
            "Before I start having kids and to have experience in another country and there I am at the computer center of the tire and typing at Ashley and see if you can spot me."
        ],
        [
            "I'm right there.",
            "And so during."
        ],
        [
            "Time, you know we would drive the family car to the foreigners cafeteria.",
            "This was before."
        ],
        [
            "Really opened up and they were really good to me.",
            "This is my office.",
            "In you know, I was anyway I was just a someone with a Masters degree from Polaroid.",
            "They set me up in this nice office so anyway."
        ],
        [
            "While I was there I read this great book that got me totally excited about computer vision.",
            "An MIT press has recently reissued it an It's called Vision by David Marr.",
            "So."
        ],
        [
            "So David Marr said the goal of vision is to tell what is where by looking and so examples of the sorts of things you want to do with vision is to estimate the shapes and properties of things that like material characteristics, recognize objects, find and recognize people.",
            "Find Rd lanes and cars help a robot walk and inspect for manufacturing.",
            "And so within."
        ],
        [
            "As you know, space of possible things are a number of very kind of concrete goals you might set, so you might want to weigh the camera around some object and get out of 3D model of it.",
            "That would be a useful thing you want to have a video camera looking at an actor or dancer moving around and pull out the three depots overtime of that person moving.",
            "Detect and recognize faces.",
            "Recognize objects, track people or objects.",
            "This is useful for surveillance, for safety, for all sorts of things, and also at a kind of lower level you might want to enhance images.",
            "So how well can we do it these things?",
            "Well, one piece of evidence that we're actually doing pretty wealthy."
        ],
        [
            "Things is there a whole lot of companies that are sprung up over the years and also more recently which have made computer vision applications.",
            "So I just wanted some of them just to give a.",
            "Pick."
        ],
        [
            "We have kind of where we are, so the leader in.",
            "Sort of manufacturing kind of old style computer vision, sort of controlled environment.",
            "Manufacturing is Cognex, so they do a lot of inspection for semiconductors.",
            "I think that every diaper disposable diaper manufactured is inspected with computer vision.",
            "And so that's useful and ubiquitous.",
            "It's not really a research problem in the sense that it's so so well controlled that that it's solved in any way."
        ],
        [
            "Is.",
            "Here's an application that's you just can't argue with how useful it is.",
            "There's a company that puts cameras under swimming pools and looks for people who have drowned.",
            "And."
        ],
        [
            "They've installed them in a lot of pools.",
            "Anne."
        ],
        [
            "And they save lives with them.",
            "So that's somewhat controlled but not completely control a lot of lighting conditions and so forth, but stationary camera.",
            "So that's great application of computer vision."
        ],
        [
            "Here's one an Israeli company started by unknown Joshua, which is up and coming.",
            "I think these products are in Mercedes-Benz cars now and.",
            "They it's a little camera that sits behind the rearview mirror and looks out of the world, and it tells you when you're shifting lanes when you shouldn't be, and things like that, and it's expected that more and more overtime, more and more controls will be handed over to this camera systems.",
            "Right now, it's just a warning system, but it could also do, I think in some cases it is breaking if you're about to collide with something it breaks for you.",
            "So again, that's a certain application.",
            "It will save a lot of lives."
        ],
        [
            "Here's the progression of other applications.",
            "This is a research project from my lab in the late 1990s.",
            "Computer vision for computer games.",
            "There's a little camera.",
            "There's person playing game.",
            "This is in a trade show.",
            "Note the controlled conditions.",
            "There's a black screen behind the person that was late 1990s then are."
        ],
        [
            "2003 Sony came out with the Eyetoy, which was in peoples living rooms, although you still had to be careful with the lighting conditions.",
            "So they sold 10,000,000 / 8 years."
        ],
        [
            "Good and then Microsoft.",
            "Just recently came out with the Connect product and that just went haywire.",
            "As far as people accepting it, it holds the Guinness Book of World Records for being the fastest selling consumer electronics device.",
            "They sold 8 million in the first 60 days and they've sold 10,000,000 up to March 9th.",
            "And this, by the way, is a great success story for research in general for industrial research, because within Microsoft it's viewed as this great success of the research labs who kind of stepped in.",
            "Relatively at the last minute and applied a lot of sort of straightforward really machine learning methods to get this thing to work as reliably as it does.",
            "It's an active sensing system, so they project out infrared light at the world to help them recover these depth Maps that are used in these games."
        ],
        [
            "We also use computer vision for face recognition and for for detecting frontal faces.",
            "We can do pretty much as well or better than humans do, but when you get unknown lighting conditions and get people moving their heads, then it the performance falls off quite a bit."
        ],
        [
            "Of course Google is in everything and they're also in computer vision as well.",
            "And of course you have search that can look for things that look similar to what you're looking for."
        ],
        [
            "And also there's this wonderful new product, relatively new called Google Goggles that.",
            "Lets you take a PDA or a cell phone and take a photo of something and then goes and looks up.",
            "What it is and tells you something about it, and these are the sorts of things that it works well for.",
            "Basically kind of richly textured things which aren't too.",
            "Movable, which kind of fairly rigid can do well at those, and we'll see why these are basically feature based, and we're doing pretty well with features, and I'll talk about that in a little bit."
        ],
        [
            "So there's a nice summary of what the state of computer vision industry is on David Lowe's web page and you can just read out some of the headlines, automotive assistance, digital photography."
        ],
        [
            "Be tracking.",
            "Games and gesture recognition."
        ],
        [
            "General purpose."
        ],
        [
            "This industrial automation people tracking object recognition also say in terms of where the field is excited about the field is kind of maniacally focused on the object recognition problem.",
            "I think a little too much I think, but that's where there's a whole lot of effort in trying to.",
            "We can recognize a few categories pretty well.",
            "We want to get that up to somewhere recognized thousands of objects, or it's not that people can recognize like 30,000 different objects.",
            "Well, we're nowhere near that."
        ],
        [
            "Old performance.",
            "Traffic and Rd management web applications 3D."
        ],
        [
            "Only so, so with all that industrial interest and work you know what?",
            "How are we on what, the status report and where we are with with those particular tasks that I mentioned before, can you wave around the camera and get a 3D model out?",
            "Well, almost certainly you can use the so called active lighting user Connect or some other system and get a 3D model out.",
            "Doing it was simply a camera you can almost do that.",
            "Or many times it can do it, but have some holes or problems in it.",
            "Capture opposing an actor dancing.",
            "Well if you use multiple cameras, we can nail that problem and people signed it to their computer vision glasses with just a single camera.",
            "It's much harder, and we're not quite there yet, but we're getting close.",
            "Detect and recognize faces.",
            "If it's a frontal view, yes.",
            "If it's not funnel as much harder.",
            "Recognize object.",
            "Again, there's a lot of people working on it, and a lot of progress, but it's still.",
            "It's a tough problem and we have a long way to go.",
            "Track people and objects well if it's over a short period of time, yes, over a long period of time, meaning more than just a second or two, it's hard to do it reliably.",
            "And enhance images.",
            "Well, we can enlarge images and make up details for those enlargements.",
            "If we zoom just by a factor of four in each dimension.",
            "But we go larger than that, then we start breaking down."
        ],
        [
            "So that's kind of where things are.",
            "So what I want to do now is kind of a little bit more detail talk about how these problems are really machine learning problems and talk about where some of the places are.",
            "They were stuck."
        ],
        [
            "So high level vision."
        ],
        [
            "Um?",
            "So why?",
            "Why is this hard?",
            "Why can't we just solve this?"
        ],
        [
            "Problems well, the thing that really makes it hard is variability.",
            "So here I'm going to show you a lot of pictures of one person."
        ],
        [
            "And just look at how different these pictures are of that one person.",
            "Of course, this is celebrity.",
            "We all know him, but these are all Paul McCartney pictures.",
            "Over different times under different lighting conditions.",
            "Normalized so they're all facing forward and same size, but you can see how much that image changes overtime.",
            "That's just one object, one not even.",
            "You know it's a sub category of an object if you start."
        ],
        [
            "Branching out to different instances in different types of within one category, you can get huge visual variability, so all these things are chairs or things you can sit on and yet you can see that they.",
            "Look very different visually, so we want to get a classifier which will look at any one of those and say, oh, that's a chair.",
            "So that's a hard problem."
        ],
        [
            "So that's really in my mind, the top level thing that makes vision difficult.",
            "Or do you want to become invariant?",
            "Two different viewpoints, different illumination conditions, invariant to occlusions, different scales to deformations to clutter?",
            "Those are the things that really make it difficult.",
            "So.",
            "One approach to get around these problems is to find so-called features.",
            "A little regions of the image and some representation of that image.",
            "Which is invariant as much as possible to all these little changes.",
            "They're going to happen to it, and now you can't expect the whole image to be invariant to these things, but maybe you can come up with some representation which will make this small region descriptive yet invariant, and that's actually where we've recently made progress.",
            "So to talk about that."
        ],
        [
            "So I'm going to go back in time first, so let's take a little time machine and see what things were like like in the mid 80s, OK, in computer vision.",
            "So bad."
        ],
        [
            "Then everybody looked like this.",
            "OK, nice geometrical things connected by lines bounded by points."
        ],
        [
            "And so those are the kind of features that people used.",
            "Back then.",
            "Points, lines, conics, sometimes fitted curve."
        ],
        [
            "And we could do pretty well with kind of computer generated images of things that look kind of like this sort of blocksworld.",
            "We could handle it pretty well.",
            "And so."
        ],
        [
            "Here's a picture from a research paper around 1986, so this is like the.",
            "You know the good output of a paper at the top conference in 1986 and so.",
            "Well, if you'll pardon the image quality from back then digitized from a paper proceedings, here's a model they're looking for.",
            "Here's the input image.",
            "Find this in that model.",
            "So first of all, it's all 2D's that makes it much easier, and it's all geometrical shapes that also makes it easier and hear the spectacular result of this paper at the top conference in 1986 was OK. We found the two different instances of that thing.",
            "That shape within that clutter.",
            "OK, now let's go."
        ],
        [
            "Forward to six years later, still at the top conference.",
            "Well, we were looking at it from a slightly different viewpoint.",
            "Now it's got slightly more lighting variation, but still things that are kind of mostly flat sitting on table geometric anile look.",
            "We found them again, you know, so progress was slow."
        ],
        [
            "But now let's go back with The Time Machine back to the present.",
            "Well nowadays we handle images like this and.",
            "And we you know, real world images of how these companies we have things looking out from cars.",
            "How is it that we?",
            "Have made that progress from what we could do in the."
        ],
        [
            "80s and 90s.",
            "Well so.",
            "This is all my view of things.",
            "I think they're kind of four reasons.",
            "Arguably, this progress, the first one are these modern features, and these are getting little descriptions of local image areas that are primarily robust against many of those changes that we're going to be worried about, and I want to tell you about the ones that had the one that is had by far the most impact, but other things I should mention have been discriminative classifiers.",
            "Again, these are not things that we borrowed from your community.",
            "I think from the NIPS type community discriminative classifiers such as boosting support vector machines had a huge impact in computer vision.",
            "Bayesian methods, graphical models, nonparametric Bayes have also had a big impact.",
            "And of course another thing that I think is really brought about.",
            "A lot of this change is just computers advancing and having very large databases.",
            "So you should note, by the way, that these four things that have really caused these improvements in my area.",
            "Only one of them is really vision specific and the others are things that we borrowed from other communities or just as a result of computers getting faster.",
            "But this would be encouraging for you to jump in and help us."
        ],
        [
            "More.",
            "But let me talk about the SIFT features that have really had a big impact.",
            "In the vision field so."
        ],
        [
            "This is.",
            "The paper that had the huge impact.",
            "It's not the only kind of feature there is, but it just is by far the most influential is by David Lowe at UBC.",
            "And this paper that he published in Journal Form in 04."
        ],
        [
            "Received 9000 citations and it was like single handedly responsible for having the impact factor of that Journal be as high as it is and they were.",
            "They were worried that when when the.",
            "Time that they track the impact factor for an individual paper passed over this paper, they're going to fall in their impact factor because this one paper has been so."
        ],
        [
            "Influential, So what does the paper do?",
            "So the game is again you want to find some local description of a local region which will be as much as possible robust against all these changes that happen to things in the world.",
            "And so the story is, if you can find that magical descriptor, then you would take an object you want to recognize and apply this featured detector and descriptor all over the image and get a little set of features.",
            "These are the rich textural features that are.",
            "That are present on this object, and then you would go with some image that you want to recognize that object in you go apply your feature detector and descriptor all over this image.",
            "And go compare it against your dictionary database saying all the features that you have in which database object that feature corresponds to.",
            "So then in this case you would look and say oh here's that feature outlook.",
            "I've seen that feature before.",
            "That's from this database objects and so here's a candidate pose.",
            "An object that might be in this image and you find other features and they all confirm that same object and pose and say hi detected this object at this pose in this image is kind of.",
            "The way things work now, how are we going to describe those local image regions?",
            "Well, again, we want it to be robust against all these lights."
        ],
        [
            "Changes and stuff.",
            "So the first thing let's not use pixels, let's use.",
            "Image gradients, image image, directional derivatives.",
            "So why is that going to be helpful?",
            "Well, here's a picture of my hand under two different lighting conditions, and the pixel based image.",
            "You can see it's quite different from one lighting condition to another, but if you instead represent it as image gradient orientations.",
            "And normalize it to local contrast.",
            "You can see it's actually much more similar to each other than in the original pixel based representation.",
            "So that's step one.",
            "Let's let's work with image gradients.",
            "To get some."
        ],
        [
            "Independence and then Step 2 is we want to.",
            "We don't really care whether some contour goes exactly here or some slight difference away from it.",
            "And again, if we use the pixel representation and then you try to subtract the two and compare, you're going to be very sensitive to everything lining up just perfectly.",
            "So we want to be insensitive to that.",
            "So let's first take the image, find the image gradients.",
            "Then let's do some spatial pooling so that we don't have to worry about exactly."
        ],
        [
            "Everything landed, so let's look not at the histograms themselves, but rather.",
            "Sorry, not at the gradients themselves, but rather at histogram of the gradients.",
            "Cooling over some spatial region, so that's going to be our representation of that local image region will take the gradients.",
            "Pull them over space an but we don't forget entirely where things happened over space will make little regions of pooling and stack them together in a configuration.",
            "This is 2 by two in practice which you used as a four by four region of these little local pooled accumulation regions where we calculate the histogram of the gradients history orientations.",
            "And that's pretty much it.",
            "Then we take all those things and stack them up into big vector.",
            "And that's a turns out 128 dimensional representation of the image stuff in each little region.",
            "Then there's other steps about where you find those specific regions that you.",
            "Refinable way.",
            "That will and then set up a coordinate system that's invariant to the local orientation, invariant to scale.",
            "And if you follow all those steps then you get this so called sift feature for scale invariant feature transform which takes these features, put them into 120 mention vector which is by and large robust against orientation scale, exact positioning, an lighting and these things are the sliced bread of computer vision.",
            "It's kind of annoying actually how many papers.",
            "Use this just as the initial first step, but anyway."
        ],
        [
            "Very successful.",
            "And why are they successful?",
            "'cause they work pretty well.",
            "So here's a couple of slides showing how they work pretty well.",
            "Here we're going to add different amounts of image noise on the bottom 0246, eight, 10%.",
            "Pixel noise and then look at how well this feature will match against the data set of features.",
            "Finding it's it's match within that data set.",
            "It's fairly robust against noise, so what's nice about it is a relatively high dimensional feature 120 dimensional so it can be you can push it around a little bit and you'll still find its nearest proper nearest neighbor."
        ],
        [
            "You can change the viewpoint of the image, so this is modeled by an afine change, and if we change the viewpoint angle by on the bottom scale 0 ten 2040, thirty 4050 degrees and again the correct matching falls off somewhat, but not dramatically.",
            "As you make these changes in viewpoint, so that's."
        ],
        [
            "So good and then how distinctive are they?",
            "Well, you can take this 120th national feature and then just add lots more features to the data set that you're trying to look for the best match within.",
            "And even as you add many, many more sort of distractors if you will for finding the nearest neighbour match it will still do a very good job of finding their stable match again because it's a fairly relatively high dimensional thing.",
            "120 mentioned that you're looking for so there the number of other distracting key points in the database can be 1010 thousand or 100,000 and performance drops very little."
        ],
        [
            "And so the result is you can get results like these, so this is from this 2004 paper.",
            "Here's a here's your little.",
            "Toy data set of objects you're looking for.",
            "Again, you go and find the search features in there and then.",
            "Here's the image you want to find those in.",
            "So now you take your SIFT feature detector and look for all the places where you find those features and then look to see when did I see this thing anywhere.",
            "There rather did I see the features that were found here anywhere else in this image.",
            "Anna how you did and you can localize where those objects are even if they are included so you don't.",
            "The features are localized so you don't find all of them, you just have to find some."
        ],
        [
            "And here's another example, and again, this kind of shows where it works really well when you have richly textured things, it just nails it.",
            "Harder with things that don't have the same kind of richness of the orientation distribution, but here's some totem poles.",
            "And you can find the those in some other photo quite easily.",
            "So what can you do with this?"
        ],
        [
            "Sort of thing.",
            "Well, again, there pervasive.",
            "So you can use them in."
        ],
        [
            "Computational photography, so here you're making a mosaic taking many different shots of this region and then matching one picture with another.",
            "By matching those sift features."
        ],
        [
            "And it turns out these things are useful for all sorts of computer vision and image processing applications, so here's a partial list of where they used image alignment, 3D reconstruction, motion tracking, indexing, database retrieval mode, robot navigation, and then it's also used in places where they wouldn't think of work well.",
            "So when I first saw these that OK, these are good, for instance recognition for really for magazine cover detection.",
            "If you have a magazine cover and you want to find that somewhere else you look, you match those exact textured regions.",
            "And the other thing.",
            "But to my surprise, and other people surprise."
        ],
        [
            "They're also really good for category object category recognition.",
            "In other words, you have a database of chairs.",
            "Go find a new chair that you've never seen before in your database.",
            "Not an exact match.",
            "It still does a good job to 1st represent these things.",
            "These features, and of course you want to maybe vector quantized them as little space around them, But then match up those features that works really quite well for object category recognition."
        ],
        [
            "So here's an example of that.",
            "You might want to take an image and.",
            "Detect those, detect those points where you're going to describe the local image region.",
            "These are called key points for finding your features.",
            "Then describe the local.",
            "Image region with the SIFT feature at those points and then typically these are vector quantized into a little vocabulary of maybe 2000 or so."
        ],
        [
            "You would call them visual words.",
            "This is your visual vocabulary.",
            "And.",
            "And."
        ],
        [
            "You can use these to categorize, so here's the image.",
            "Find the features and then you say OK, how many times did each of my two or three each of my different of the 3000 vocabulary elements that I have for all images, how many times each?",
            "Did each image occur?",
            "Sorry.",
            "Did each feature vector word occur?",
            "Let me get back to where I was.",
            "So then you can make a almost like a with a text document.",
            "You make a word frequency occurrence that describes this image and then puzzlingly enough.",
            "This is actually quite good at.",
            "At detecting what kind of objects are in this image, just looking at the frequency, how many times did each different feature word class occur?",
            "So my point is."
        ],
        [
            "Now this starts to look like a learning problem.",
            "We have M possible.",
            "And feature words that were found in some test region and then end possible matching features from some each of each different K possible training classes.",
            "Which of those training classes most likely to have a curd in that image and?",
            "So this is this type of approaches is among the leaders in object recognition approaches currently."
        ],
        [
            "So.",
            "These features have been very useful.",
            "We've also adopted many machine learning methods.",
            "What else do we want?",
            "You know?",
            "What do we need to help make progress?"
        ],
        [
            "So I actually went around to the last several computer vision conferences and asked my colleagues this question.",
            "It would be sort of my lunchtime conversation with them.",
            "I say so suppose.",
            "You were talking with a good group of machine learning theorists.",
            "You know what would you ask them for?",
            "So here's a.",
            "Picture representing my community.",
            "This was at a particular workshop."
        ],
        [
            "And so I would ask them.",
            "How do you think computer science can best help computer vision?"
        ],
        [
            "So the most common response for what they wanted was.",
            "Any guesses, by the way?",
            "The most common."
        ],
        [
            "Once was fast.",
            "Approximate nearest neighbor search in high dimensions.",
            "Now you may be thinking, but look we gave them that already.",
            "You know, gave them locality sensitive hashing.",
            "You know they've already got this, but no."
        ],
        [
            "It's not good enough.",
            "So here's some quotes from people what they said OK. Let's see nearest neighbor search, but taking into account our particular type of data, you know these are images are not just random vectors and also what maybe have them tell us what questions we should be asking about our data in order to do nearest neighbor search.",
            "Well, how can we explore parallelism?",
            "Why doesn't LSH work as advertised for our datasets?",
            "Let's see.",
            "Right, so let me."
        ],
        [
            "Show some of this, so there's a nice paper also actually by Co.",
            "Authored by David Lowe on fast approximate nearest neighbors for.",
            "Um?"
        ],
        [
            "Algorithms and how to configure these rolling, so here's a plot showing.",
            "See for the number of.",
            "If you want to key nearest neighbors and have some fraction of those indeed be within the K nearest neighbors, set, here's the fraction of the nearest neighbors that are correctly retrieved.",
            "The nearest fraction of the nearest neighbors that you retrieve that are correct.",
            "Going from 50 sixty 7900.",
            "And then here is the speedup over linear search plotted this way.",
            "So the best curve would be high here.",
            "And how does LSH perform well?",
            "It's way down here for our particular datasets, and so the point of this paper was introducing these other way to automatically tune these other two algorithms.",
            "K means tryan random KD trees which do much better than other methods.",
            "Again for finding nearest neighbors of image patches or of local descriptors of image patches.",
            "So.",
            "We need."
        ],
        [
            "Help here and also oftentimes in our nearest neighbor searches, there's extra structure that we'd like to be able to exploit or have an algorithm take advantage of.",
            "So for example.",
            "Here's a panda and then overlaid.",
            "There are all these little features that are detected and each one has a little word that's associated with it.",
            "To saying what image, what's the image?",
            "Appearances in this local region that spanned A and here's panda be that you want to match it to.",
            "It doesn't have all the same features detected.",
            "It has some of the same ones detected and there's different scales involved an so you want to do an optimal partial matching of the features found in here to the features found there.",
            "And so here's a.",
            "An attempt at that are optimal partial matching of the features, and you've got scale variations and distance variations.",
            "So how can we quickly find the most probable object categories from these sets of partial matches of features?",
            "How do we, in a principled way, handle these features?",
            "Variations that are inevitably?"
        ],
        [
            "Going to show up.",
            "Another nearest nearest neighbor search problem.",
            "With kind of the structure of images, is so called nonlocal means denoising, so this is.",
            "This is actually the world's best denoising algorithm right now.",
            "Or tide with the best and it's this crazy simple Al."
        ],
        [
            "Rhythm here it is.",
            "It's easy, it's so easy.",
            "You can explain it with the picture.",
            "The idea is that there aren't that many different image patches in the world, or even in any single image, an if you.",
            "So in any given image, if you take any Patch, you'll be able to find.",
            "Within that image, other matches of that Patch which are pretty much the same Patch, just with some noise added to it.",
            "So this is sort of a sparsity assumption about image data.",
            "And so one way to denoise an image is to go grab each Patch, look for its nearest neighbors within that image and average them together.",
            "Say that well, these are just versions of the exact same Patch and the only differences between these are caused by noise.",
            "So I'll just average them together and take the average value as my new denoise value for the center pixel, and do that for all the pixels of your image and you get the world's best in terms of signal noise ratio denoising algorithm.",
            "But so this brings up the question, how do you quickly and efficiently find those?",
            "Nearest neighbor matches key nearest neighbor matches within the image and you've got the again.",
            "This extra structure that you've got.",
            "It's an image is not just random sets of data."
        ],
        [
            "So here's one.",
            "Here's one algorithm which actually works well to take that into account, and so this is.",
            "Perhaps not where we need help, but it's an example of the sort of algorithm that we need.",
            "Apply in other situations.",
            "This is called Patch match.",
            "It was.",
            "It's a randomized."
        ],
        [
            "Algorithm.",
            "So here's the story you take here."
        ],
        [
            "Pixel user Patch.",
            "Step one is you throw down your Patch marker at random different positions within the image.",
            "These are candidate matches for it."
        ],
        [
            "And then Step 2 is you look at the previous pixel, which by now you from the previous iteration of the algorithm you found the best matches for that thing and you."
        ],
        [
            "Say OK, what?",
            "So the previous pixel to the left had these best nearest neighbor Patch patches for matching, so I'm going to."
        ],
        [
            "Look at what's just one to the right of those patches.",
            "That's like a Reese."
        ],
        [
            "More good guess for what might be a good match to where you are and so now.",
            "You got this set of candidate patches.",
            "You've got the ones that matched that were just to the right of the ones that matched your pixel to the left from the previous time, and you've got these ones from throwing down your.",
            "Candidate position that it's just random locations.",
            "Let's take this set of candidates and now exhaustively look and see how close each one of them is to the current Patch and pick."
        ],
        [
            "The best ones there and use that as my set of K nearest neighbors to match this particular Patch and then move on.",
            "So you introduce a little bit of randomness in the search by by throwing down the marker at random positions in the image."
        ],
        [
            "And OK, this is a kind of crazy algorithm, kind of simple, not that hard to come up with.",
            "You can come up with other things like this for us, but this one, for example, works spectacularly well, and it's in the latest version of Photoshop, so I want to show you show it to you working.",
            "Um?",
            "Let's see, let's go to photo shop.",
            "OK, here's a picture of my daughter.",
            "You can say I want to take away.",
            "That white plate.",
            "OK, so I'm going to hit the delete key.",
            "On the computer and it asked me OK, when I fill in what you're deleting, do you want me to fill it in with a content where a content aware fill?",
            "And I'll say yes.",
            "And there it does it, so it it did this past match algorithm to fill in that stuff.",
            "But look for things that would fit in well from other parts.",
            "But you can do bigger things here.",
            "Let's take this the whole thing away.",
            "Let's delete that content aware sure.",
            "And so there is hard to see.",
            "Where was let's do something harder just to finish up.",
            "I think this so I'm not sure if this will fail or work, but let's go try this thing at a boundary.",
            "Delete that.",
            "And as you know, that's a pretty good guess.",
            "So anyway, that's that's one of the benefits of randomized algorithms in computer vision applications.",
            "Let's go back to the show."
        ],
        [
            "And so, by the way, this this is another example of research working well.",
            "the Adobe group that the Adobe Research Group introduced this to the into the product and they just it led to the first billion dollars sales of Photoshop than they had in a year before.",
            "I mean, for the first year after this was introduced, they had the sales dramatically increased and they thought it was marketing, particularly thought that was caused by this feature.",
            "I mean, there's in the blogs and all the reviews just raved over that feature.",
            "New feature for Adobe Photo shop.",
            "Um?",
            "OK, let me go back."
        ],
        [
            "OK so anyway, just to recap, we need help with nearest neighbor search in high dimensions for images and it will have application in texture synthesis and super resolution image filling in object recognition scene recognition."
        ],
        [
            "All sorts of applications and what else did people ask for?",
            "In general, people ask for help scaling things up that.",
            "Many computer vision algorithms really boil down to solving some integer program or some linear program, or some quadratic program, or some semidefinite programs, and with large amounts of high dimensional data, and the standard solvers typically don't work under the conditions that we're asking them to work, and we need help in exploiting the sparsity or the structure of the problem, or developing online versions.",
            "You know with maybe thousands of other categories.",
            "These are some of the things that people ask for."
        ],
        [
            "So that summarizes this slide."
        ],
        [
            "So those are kind of high level things, although I guess the Patch matches low level as well.",
            "Let's talk about some other low level problems so I'm distinguishing high level from low level.",
            "I think high level vision as image in words out like descriptions of it low level vision as image in image out, maybe an enhanced image."
        ],
        [
            "One thing we really need help with is having statistical priors on images.",
            "How are prices can be useful?",
            "Well, so here's an image.",
            "Here's a noisy version of that image.",
            "We want to denoise it.",
            "You have to have make prior assumptions about what the images look like in order to do anything with a noisy image.",
            "Suppose you didn't know anything about images.",
            "How do you know that that isn't a perfectly good image and you should just stop right there?",
            "Because there you got it?",
            "You know you've got to make some assumptions about images to move away from this one.",
            "Well, it turns out it really matters what assumptions you make as far as how well you can denoise, for example, or many things as well.",
            "So if you just make a Gaussian assumption about images you and make some assumption about with the spectral falloff is you'll get a an optimal reconstruction of this noisy image.",
            "That might look something like this.",
            "Which would be optimally supersense under some assumptions about the spectrum of the image, but it doesn't literally look like an image.",
            "If you instead use.",
            "More sophisticated Gaussian scale mixture model.",
            "In a wave representation, you can get a denoising result that looks like this.",
            "It's still obviously has flaws, but it's much better."
        ],
        [
            "Another problem that image priors are essential to is removing blur from images.",
            "So if you imagine you shake your camera, so here's kind of a picture of the shows.",
            "Both the output and the problem.",
            "Here's a picture of someone in the mirror.",
            "She shook the camera when she took the picture and you get a blurred picture of her."
        ],
        [
            "We've developed an algorithm which uses Bayesian methods to infer the and prior assumption about images to make a best guess at what the sharp image was before it was blurred."
        ],
        [
            "So he was showing."
        ],
        [
            "With the algorithms, here's original, here's kind."
        ],
        [
            "Naive sharpening is not just simply sharpening that you need to do.",
            "You need to also basically estimate how was blurred and remove that.",
            "Um?"
        ],
        [
            "So here's for this problem.",
            "Here's the the model for how we get the data blurry.",
            "Image results from some latent sharp image convolved with this blur kernel.",
            "So here's a picture of how I'm going to blur kernels.",
            "It's a photograph of what a point of light would have looked like if you move the camera in the same way as you're photographing this point of light, so that's how one pixel was blurred, and we assume that the whole.",
            "Every point in the image is blurred in the same way, so then you are instructed to convolve this with that to get this thing.",
            "What's really cool about this problem is there's just delightfulee under detur."
        ],
        [
            "And again, so here's your data.",
            "There are many possible solutions which fit this data."
        ],
        [
            "Number one.",
            "How do you know this was blurred at all?",
            "It could be that's what was out there.",
            "That was the image, and that's the blur kernel, you know, just the Delta function, no blur.",
            "How do you know that's not there?",
            "You haven't seen this thing before."
        ],
        [
            "If you're pathological, you can also come up with crazy combinations of image and blur kernel, which will get you what you."
        ],
        [
            "Saw and then of course, this is what you're really looking for.",
            "This kind of sharp image and implausible kernel, and so to distinguish between these choices, especially this one, is.",
            "This is really hard to beat because it gets the noise exactly correctly.",
            "You know everything is just the likelihood is very high on this one."
        ],
        [
            "So how do we favor this one well?"
        ],
        [
            "It turns out that you all are really quite good at looking at images you've never seen before and telling us whether it's blurred or not.",
            "Let's just."
        ],
        [
            "Some just to show me that you can do it blurred or not blurred."
        ],
        [
            "OK this one."
        ],
        [
            "Blurred, but this one blurred.",
            "Yes, right?",
            "So you could imagine it's kind of high level process that you know about people in swing sets are supposed to look like, but you'd really like to have a low level process that looks at it and tells you whether this is valid image data or whether it's."
        ],
        [
            "Unblurred in some way.",
            "So it turns out one.",
            "I mean we're not done with this problem, but we need a little bit of progress on it.",
            "Some of the progress is just looking at image gradients again, is just really useful.",
            "Here's a simple statistical model for images saying that if you look at the difference between adjacent pixels, it should have this shape.",
            "So here is zero difference.",
            "Here's an scale zero 255 here is going minus 50 -- 100 + 50 + 100 and the vertical axis is log frequency of occurrence of that difference between adjacent pixels.",
            "In this image.",
            "So what does it tell you?",
            "Right away?",
            "We're not dealing with Gaussians, right?",
            "Because the log frequency of occurrence for Gaussian noise, it would be an inverted parabola, but it's just really spiky thing, so it's much sparse."
        ],
        [
            "Within Gaussians, and then if you blur the image and look at those gradients, distribution of differences, you get a different curve an.",
            "So that's what we use for our for the work that I showed you the results up here.",
            "That's what we worked uses are."
        ],
        [
            "Which prior we we actually did this particular image, we fit a parametrically this.",
            "Histogram of adjacent."
        ],
        [
            "So differences and then put it into a."
        ],
        [
            "Bayesian framework, so we had a reconstruction constraint that our latent image convolved with our estimated blur kernel, had to give us our data."
        ],
        [
            "We had a prior on the latent image that the gradient distributions had to look like that."
        ],
        [
            "And we had a little prior on the Blur kernel that had to be sparse and positive."
        ],
        [
            "And put it on a Bayesian framework.",
            "It turns out.",
            "We couldn't use Nmap solution to this.",
            "And we thought a lot about the reasons for why that we've written papers on this, but variational Bayes worked much better, and I think that's because there are many local Maxima in this problem and you want to.",
            "It's over 200 constrained to just use Nmap approach an but marginalizing.",
            "Basically.",
            "Marginalizing over all possible the images was very good for estimating the unknown blur kernel."
        ],
        [
            "And then once you have the blue kernel, would freeze that an estimate the latent image.",
            "So here's an example image.",
            "This was taken into museum.",
            "We couldn't use flash, and it's blurred."
        ],
        [
            "Here's are the results of this variational Bayesian method I just sketched to you, and here's the D blurred image.",
            "And here's the estimated blur kernel Ann, just to show you that it's."
        ],
        [
            "Hard problem, here's the output of matlab's decons blind.",
            "Nothing gets Matlab, but it's there."
        ],
        [
            "Problem, and here's a close up of our output and the original bird image in Matlab, secom blind.",
            "So.",
            "This paper generated a lot of interest in the computer vision and graphics community on on revisiting this so called blind deconvolution problem and we've made it."
        ],
        [
            "Progress, but there's still images that we can't at all handle.",
            "Basically, we can, if the blur is pretty much uniform over the whole image, well, we have enough data.",
            "We can kind of solve that, but if different things are moving different ways, we just can't deal with that well now, and so there's a lot of room for."
        ],
        [
            "A good statistical characterization of images that could be used in noise removal and super resolution and filling in and texture synthesis.",
            "Lots of things."
        ],
        [
            "Um?",
            "Let's see.",
            "Now that's a repair metric type prior, but we could also use.",
            "There's a lot of benefits to non parametric synthesis in nonparametric techniques in texture synthesis, and you could use these as priors as well.",
            "Turns out, the world's best texture synthesis algorithm is basically something that.",
            "Looks at a local image region, looks in a source texture for where have I seen that same local neighborhood before?",
            "Looks at the corresponding pixel that you're trying to synthesize in those previous regions and.",
            "Select one to put there that's.",
            "One of the."
        ],
        [
            "Simplest and best texture synthesis methods is basically a non parametric image prior and works great and what we would like is for ways to make this more controllable.",
            "Maybe let me just first show."
        ],
        [
            "The outputs of this texture synthesis method.",
            "Here's the input texture, and here's more of that same stuff and."
        ],
        [
            "It just works great to use these very simple non parametric."
        ],
        [
            "Methods.",
            "I would call it the corrupt professors algorithm 'cause it basically says plagiarize as much as you possibly can from the image and try to cover up your tracks.",
            "And anyway, that works really well for this texture synthesis."
        ],
        [
            "But we want to use it for other things, for again, for image priors.",
            "For these other problems, and so I guess another problem is how to construct and manage nonparametric signal prior as well.",
            "And you could use these in many different places, and here are some references for papers that address this problem."
        ],
        [
            "So then still on the subject of image priors and image prior, that's very often used as a marker and a field.",
            "This is quite a bit in computer vision and image processing applications, so we have a graphical model.",
            "These might represent pixels.",
            "These might represent patches neighboring each other, and.",
            "Our image is too big to have to make to make this thing be attractable prior over and something that large is an image we want to modular eyes it so will say, well, we say we know what this compatibility function is between neighboring patches or between neighboring pixels and we just use that same function over and over again.",
            "And then we say what the maybe the likelihood term is between some observation and some underlying label or pixel value.",
            "We're trying to estimate and again we keep that same one and use it in spatially invariant pattern.",
            "So then this is our prior over the entire image, if you.",
            "Give some data in for your wise.",
            "You want to try to estimate some underlying label or some underlying modified pixel and Marco Random Field will tell you analytically what that relationship is.",
            "We can use these things and saw we typically want to then solve for the optimal labeling or set of pixels act."
        ],
        [
            "So what are some approximate methods we have to solve this?",
            "It's an NP hard problem.",
            "Well, you can use loopy belief propagation and get.",
            "You know an approximate answer for for any desired.",
            "Compatibility function between neighboring patches or pixels.",
            "Or you can use graph cuts, but then you have this restriction of things being submodular for.",
            "In order to use the min cut Max flow algorithms and get guarantees on perfor."
        ],
        [
            "And so one thing we like is efficient algorithms for minimizing non submodular functions which give at the same time bounds on the quality of the solution.",
            "Because we don't have that now.",
            "Another thing I proposed, Marco Brandon Fields that we would like help with."
        ],
        [
            "Is people have recently pointed out?",
            "That if you use more than just these pairwise compatibility between neighboring labels but use maybe trios or higher order click compatibility's, you get much better results in the image processing.",
            "So here's an example showing the better results that they're trying to labeling of this image.",
            "And they have different features they use and then try to optimize the label.",
            "Makes makes any given segmentation most likely, and if you use pairwise potentials you get this labeling of tree, grass, building and Sky.",
            "But if you use higher order clique potentials and others higher than just second order, then you get a much richer labeling really showing the benefit of these higher order cliques in the market and fields, and these are the things that we can't."
        ],
        [
            "Work with as well.",
            "So again, we'd like to find better ways to solve these markers.",
            "Random fields with these higher order cliques and give us performance bounds.",
            "Let's see, another thing was asked for.",
            "Is.",
            "That we often work with one of two different kinds of constraints in the market, brownfields, structural constraints, like say planarity or treewidth.",
            "And also you might call them language constraints like submodularity or convexity and it be useful to have something that combines the two."
        ],
        [
            "Here's an example of a constraint if you're.",
            "Oftentimes, in image editing applications you want to put some box around something and have the algorithm automatically figure out what what you really mean when you put that box around it.",
            "And so what's the constraint that gives a good hint for that?",
            "Well, you didn't waste area when you put your box around the box is going to be every side is going to be close to some pixels of the thing you want pulled out within that region, so this is a.",
            "A constraint on the as you call it a bounding box prior on this segmentation that you want to pull out something which has a certain consistent set of characteristics in here and you have this added constraint that that thing you're going to pull out has to be close to the bounding box edge for every one of the sides.",
            "So that's an additional constraint that will help you in your image editing application, so here it doesn't meet that constraint, and you've missed the head of the baby, and here it does meet that constraint when you use that hint that actually constraint you can pull out the head."
        ],
        [
            "So these topological constraints are useful for mark random fields."
        ],
        [
            "OK, so.",
            "So then, summarizing this little section, we need help with inference in marker and fields.",
            "How to handle higher order quick potentials, high dimensional safe aerials and these various constraints.",
            "OK, so then.",
            "Let me."
        ],
        [
            "Pop up with some miscellaneous problems that people ask me for."
        ],
        [
            "One is compressed sensing, so compressed everyones wildbach compressed sensing.",
            "Does it apply to images?",
            "I'm not sure it does."
        ],
        [
            "This current sparsity assumptions are actually unrealistic for natural images, and is there perhaps a relaxed set of sparsity assumptions where these assumptions of compressed sensing could be?",
            "Where these relaxed set of assumptions could apply, and then it could be useful for sensing images."
        ],
        [
            "So there could be potential photographic applications for a relaxed set of sparsely assumptions, which would actually be met by by natural images as opposed to these sort of unrealistic ones which."
        ],
        [
            "Natural images don't meet.",
            "One thing is I talked with an issue and he said he's like our successful businessman in our field and he said, well, you know, Bill, what really matters more than anything else are datasets just having huge data set.",
            "That's what wins in computer vision.",
            "And so he ranked what matters for our field as one datasets 2 features matter to an three is algorithms.",
            "You know, once you have a good feature in your data set, it almost doesn't matter what you use anyway.",
            "We.",
            "So let's look at number one.",
            "We still need help handling our large noisy datasets, so we always assume that our training and test distributions are the same, but they're often not.",
            "So how can we, under what circumstances can you break the assumption that the two distributions are the same?",
            "What is the effect on algorithms when the IID assumption which we so often make doesn't hold and then because we have these huge datasets, you know lots and lots of images.",
            "Online learning is really important, so online algorithms are critical."
        ],
        [
            "For us"
        ],
        [
            "Let's see Cheyenne."
        ],
        [
            "John had a really funny one."
        ],
        [
            "Which is he wanted to develop something called blind vision which is multi party techniques for vision algorithms.",
            "So you've got person A who has just this super hot face recognition algorithm that he doesn't want to let out at all.",
            "It doesn't want anyone to know about it and then person B who wants to have some great face recognition algorithm applied to.",
            "This data set but doesn't want to let out any of these images 'cause they're sensitive.",
            "So can these two people.",
            "These two players somehow and let?",
            "Alice is algorithm be run on Bobs images without either of them knowing anything about the other parties sensitive information.",
            "So you could think of that as blind vision is set of protocols that would let somehow information about the faces be passed through the face detector, but yet no party know anything about the face detector or about the sensitive images."
        ],
        [
            "Something I want is."
        ],
        [
            "Is.",
            "In signal processing, it's just totally clear how to deal with continuous and discrete representations.",
            "We have this sort of the Shannon sampling theorem if you want to do something, tells you precisely how many samples you should take.",
            "And how to interpolate between them to get the exact same result you would have gotten if you played it into continuous domain.",
            "We don't have that same thing with sort of these probabilistic belief propagation type algorithms.",
            "How many layers should we discretize?",
            "The possible set of candidate depths in a stereo image?",
            "How many discrete levels should we use and how should we interpret between them to get to get the same result in a way that's independent of our digitization of scale of depth?",
            "So I haven't yet seen a nice clean prescription for how to handle that discretization and how to go back and forth between continuous and discrete domains.",
            "Um?"
        ],
        [
            "So.",
            "I'd like a theory for how to optimally quantize manipulate probabilities over continuous domain."
        ],
        [
            "Let me skip some of these."
        ],
        [
            "Another person, Devil wanted an easy way to evaluate a function over power set of all possible segmentations.",
            "It turns out if someone gives you a segmentation of the image everything is easy.",
            "You can just interpret things really simply.",
            "And if someone on the other hand, let's interpret things for you, it's easy to find the segmentation, but it's just often hard to do both and so you like some way that would evaluate all over all possible segmentation."
        ],
        [
            "And that you pick out the best thing.",
            "Um?"
        ],
        [
            "And my friend."
        ],
        [
            "Efros said he wants some language that will help you understand, helping not confuse a having something.",
            "Having a 10% similarity to a dog versus a 10% probability that it's a dog.",
            "We often confound those two things in our language, and he wanted to kind of richer description of probabilistic relationships too.",
            "To not confound having weak relationship with something or having an uncertain relationship about something."
        ],
        [
            "And then just to summarize, actually, really, we want is another breakthrough.",
            "You know, we've just eaten up support vector machines, boosting, belief propagation, graph cuts.",
            "We just embrace them and use them all over the place, and we're kind of ready for the next big thing."
        ],
        [
            "And then finally, David Lowery, the person who invented features, I asked him what he thought we needed."
        ],
        [
            "He said, well, you know, we could use better features.",
            "That an artist can like draw the end of an elephants trunk and you know immediately what it is you know.",
            "Such a rich description of just something that you can do.",
            "So that's an elephants trunk.",
            "We don't.",
            "But none of our features capture that.",
            "That richness."
        ],
        [
            "Let's see.",
            "So I have a manuscript that kind of describes some of this and all the references.",
            "Many of the references to talk about or in that manuscript is on my web page.",
            "And also, I guess this talk will be available on the web."
        ],
        [
            "So if you are interested and want to join us, please do let me tell you a little bit about the computer vision, academic culture, computer vision got burned lots of times by people.",
            "Promising results that take you from point A to point B and it turns out that you never really needed to go to point A and couldn't do anything.",
            "Once you got to point B and so really we're interested in end to end systems, and it's your papers.",
            "If they don't have it, offer end to end.",
            "Solutions are often rejected, so it's hard to publish many if only papers, and you need to sort of end.",
            "An empirical evaluation is often what it takes to get a paper into these selective conferences.",
            "There's a certain overhead and coming up to speed with all the filters and representations that you want to work with.",
            "The competitive conferences of 20 to 25% acceptance rate.",
            "And if you don't publish in these conferences, people don't really aren't really aware of what you're doing, so you have to publish these conferences.",
            "These are the competitive ones where you want to publish.",
            "So the point of all this is, it's really best if you actually collaborate with someone.",
            "But we know that you can help us and we're looking for help in our doors are open.",
            "Let me just close with."
        ],
        [
            "A mildly entertaining application of nearest neighbor finding."
        ],
        [
            "In high dimensions, and that's something that came out of our lab.",
            "We call near infinite images.",
            "So here we start with this video.",
            "Now it turns out this video was all made up.",
            "We just started from a single image an used Flickr Ann made it look as if we had a much bigger image.",
            "I had a video that was."
        ],
        [
            "Around some scenes, so you start from the collection of like 6 million images from Flickr."
        ],
        [
            "And to get this to work without jumping from one situation to a crazy one that didn't fit with it, we first applied a preprocessing to those images from Flickr to put them into different themes.",
            "So we had several 100,000 images in a Skyline theme or in landscapes theme or in a street theme, and to put them into themes we used trained in SVM based classifier from a set of labeled training examples.",
            "OK, once they're in a theme we want to."
        ],
        [
            "Find a representation to match images in or match parts of images in an.",
            "We use something very similar to the SIFT feature representation, but a different one.",
            "It's called just an.",
            "It's basically looks at the different orientations and different spatial scales in different regions of the image.",
            "Again pooling over local spatial regions.",
            "We also looked at a very low resolution, pixelated version of the image."
        ],
        [
            "And."
        ],
        [
            "So here's what you want to do.",
            "If you have an input image and you say OK, I want to pan my camera to the right and make up."
        ],
        [
            "What would be there so, which is to say you take the right hand part of your image, put it off in the left and say I'm looking for an image in my database which has this on the left side and I don't care what's in the right side.",
            "And so that would let you basically pan around and put in the appropriate images."
        ],
        [
            "And so here's what we found in our database, which in this representation I just told you about was the best match to this left side of the image.",
            "Now we're going to work to make it fit in without."
        ],
        [
            "Too much of visual artifacts, so we take those two images, wiggle around over each other to find the best."
        ],
        [
            "Matching translation then we do dynamic programming to find the best cut between these two that would cut across the fewest image gradients too."
        ],
        [
            "We are the fewest cut artifacts and we use it basically integrate up from the observed gradients to come up with a so-called plus on representation, but it's.",
            "This computer graphics technique designed to hide cuts between images.",
            "And here's our synthesized new image starting from here, and we've made up all this extra stuff which fits.",
            "You know, without too many visual artifacts for."
        ],
        [
            "I would go there and you can do the same thing with that was for translation.",
            "You can do the same thing for rotation, so if we want to rotate from here then we're looking for an."
        ],
        [
            "Image which looks like that on his left side."
        ],
        [
            "And we don't care what's on there."
        ],
        [
            "I hate you."
        ],
        [
            "Do the same trick and find out something here so you can."
        ],
        [
            "These synthetic panoramas that didn't really exist anywhere but there from your Flickr data set."
        ],
        [
            "And so let me just close with some of these videos.",
            "So here's.",
            "Let's see, right?",
            "You can start from famous scenes and see where you get too.",
            "So here's starting from the Hollywood image."
        ],
        [
            "And we also made an image taxi, so you can start from one image.",
            "They take start from one image.",
            "Take me to another image on some path.",
            "So here's we're going to end up with the desired well known image.",
            "Enter image taxi.",
            "Takes us back to there.",
            "Anne."
        ],
        [
            "And you can if you want to know what's off to the right of the Windows XP screensaver.",
            "You can find that out.",
            "Um?",
            "And so again, this is all.",
            "The result of fast nearest neighbor search through his large data set of images.",
            "OK, so thank you very much."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I'm, uh, an emissary from another community here.",
                    "label": 0
                },
                {
                    "sent": "I work in.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Computer vision and.",
                    "label": 0
                },
                {
                    "sent": "The kind of thing is we're stuck with some of these hard problems, and God would be cool if we could get the people that called.",
                    "label": 0
                },
                {
                    "sent": "Really, you know, there are a lot of smart people there.",
                    "label": 0
                },
                {
                    "sent": "Get them excited about our problems too, so that's that's the goal here.",
                    "label": 0
                },
                {
                    "sent": "So I want to start out by telling you how I got interested in computer vision.",
                    "label": 1
                },
                {
                    "sent": "And talk about kind of the state of the art in computer vision now.",
                    "label": 0
                },
                {
                    "sent": "What sort of applications there are?",
                    "label": 0
                },
                {
                    "sent": "What we can do and then start talking about open issues and places where we're stuck.",
                    "label": 0
                },
                {
                    "sent": "So it starts out.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Kind of as a travel log, here's.",
                    "label": 0
                },
                {
                    "sent": "I live for a year in China with my wife.",
                    "label": 0
                },
                {
                    "sent": "Before I start having kids and to have experience in another country and there I am at the computer center of the tire and typing at Ashley and see if you can spot me.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I'm right there.",
                    "label": 0
                },
                {
                    "sent": "And so during.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Time, you know we would drive the family car to the foreigners cafeteria.",
                    "label": 0
                },
                {
                    "sent": "This was before.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Really opened up and they were really good to me.",
                    "label": 1
                },
                {
                    "sent": "This is my office.",
                    "label": 1
                },
                {
                    "sent": "In you know, I was anyway I was just a someone with a Masters degree from Polaroid.",
                    "label": 0
                },
                {
                    "sent": "They set me up in this nice office so anyway.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "While I was there I read this great book that got me totally excited about computer vision.",
                    "label": 1
                },
                {
                    "sent": "An MIT press has recently reissued it an It's called Vision by David Marr.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So David Marr said the goal of vision is to tell what is where by looking and so examples of the sorts of things you want to do with vision is to estimate the shapes and properties of things that like material characteristics, recognize objects, find and recognize people.",
                    "label": 1
                },
                {
                    "sent": "Find Rd lanes and cars help a robot walk and inspect for manufacturing.",
                    "label": 0
                },
                {
                    "sent": "And so within.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "As you know, space of possible things are a number of very kind of concrete goals you might set, so you might want to weigh the camera around some object and get out of 3D model of it.",
                    "label": 0
                },
                {
                    "sent": "That would be a useful thing you want to have a video camera looking at an actor or dancer moving around and pull out the three depots overtime of that person moving.",
                    "label": 0
                },
                {
                    "sent": "Detect and recognize faces.",
                    "label": 0
                },
                {
                    "sent": "Recognize objects, track people or objects.",
                    "label": 1
                },
                {
                    "sent": "This is useful for surveillance, for safety, for all sorts of things, and also at a kind of lower level you might want to enhance images.",
                    "label": 0
                },
                {
                    "sent": "So how well can we do it these things?",
                    "label": 0
                },
                {
                    "sent": "Well, one piece of evidence that we're actually doing pretty wealthy.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Things is there a whole lot of companies that are sprung up over the years and also more recently which have made computer vision applications.",
                    "label": 0
                },
                {
                    "sent": "So I just wanted some of them just to give a.",
                    "label": 0
                },
                {
                    "sent": "Pick.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We have kind of where we are, so the leader in.",
                    "label": 0
                },
                {
                    "sent": "Sort of manufacturing kind of old style computer vision, sort of controlled environment.",
                    "label": 0
                },
                {
                    "sent": "Manufacturing is Cognex, so they do a lot of inspection for semiconductors.",
                    "label": 0
                },
                {
                    "sent": "I think that every diaper disposable diaper manufactured is inspected with computer vision.",
                    "label": 0
                },
                {
                    "sent": "And so that's useful and ubiquitous.",
                    "label": 0
                },
                {
                    "sent": "It's not really a research problem in the sense that it's so so well controlled that that it's solved in any way.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is.",
                    "label": 0
                },
                {
                    "sent": "Here's an application that's you just can't argue with how useful it is.",
                    "label": 0
                },
                {
                    "sent": "There's a company that puts cameras under swimming pools and looks for people who have drowned.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "They've installed them in a lot of pools.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And they save lives with them.",
                    "label": 0
                },
                {
                    "sent": "So that's somewhat controlled but not completely control a lot of lighting conditions and so forth, but stationary camera.",
                    "label": 0
                },
                {
                    "sent": "So that's great application of computer vision.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here's one an Israeli company started by unknown Joshua, which is up and coming.",
                    "label": 0
                },
                {
                    "sent": "I think these products are in Mercedes-Benz cars now and.",
                    "label": 0
                },
                {
                    "sent": "They it's a little camera that sits behind the rearview mirror and looks out of the world, and it tells you when you're shifting lanes when you shouldn't be, and things like that, and it's expected that more and more overtime, more and more controls will be handed over to this camera systems.",
                    "label": 0
                },
                {
                    "sent": "Right now, it's just a warning system, but it could also do, I think in some cases it is breaking if you're about to collide with something it breaks for you.",
                    "label": 0
                },
                {
                    "sent": "So again, that's a certain application.",
                    "label": 0
                },
                {
                    "sent": "It will save a lot of lives.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here's the progression of other applications.",
                    "label": 0
                },
                {
                    "sent": "This is a research project from my lab in the late 1990s.",
                    "label": 0
                },
                {
                    "sent": "Computer vision for computer games.",
                    "label": 0
                },
                {
                    "sent": "There's a little camera.",
                    "label": 0
                },
                {
                    "sent": "There's person playing game.",
                    "label": 0
                },
                {
                    "sent": "This is in a trade show.",
                    "label": 0
                },
                {
                    "sent": "Note the controlled conditions.",
                    "label": 0
                },
                {
                    "sent": "There's a black screen behind the person that was late 1990s then are.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "2003 Sony came out with the Eyetoy, which was in peoples living rooms, although you still had to be careful with the lighting conditions.",
                    "label": 0
                },
                {
                    "sent": "So they sold 10,000,000 / 8 years.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Good and then Microsoft.",
                    "label": 0
                },
                {
                    "sent": "Just recently came out with the Connect product and that just went haywire.",
                    "label": 0
                },
                {
                    "sent": "As far as people accepting it, it holds the Guinness Book of World Records for being the fastest selling consumer electronics device.",
                    "label": 1
                },
                {
                    "sent": "They sold 8 million in the first 60 days and they've sold 10,000,000 up to March 9th.",
                    "label": 0
                },
                {
                    "sent": "And this, by the way, is a great success story for research in general for industrial research, because within Microsoft it's viewed as this great success of the research labs who kind of stepped in.",
                    "label": 0
                },
                {
                    "sent": "Relatively at the last minute and applied a lot of sort of straightforward really machine learning methods to get this thing to work as reliably as it does.",
                    "label": 0
                },
                {
                    "sent": "It's an active sensing system, so they project out infrared light at the world to help them recover these depth Maps that are used in these games.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We also use computer vision for face recognition and for for detecting frontal faces.",
                    "label": 0
                },
                {
                    "sent": "We can do pretty much as well or better than humans do, but when you get unknown lighting conditions and get people moving their heads, then it the performance falls off quite a bit.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Of course Google is in everything and they're also in computer vision as well.",
                    "label": 0
                },
                {
                    "sent": "And of course you have search that can look for things that look similar to what you're looking for.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And also there's this wonderful new product, relatively new called Google Goggles that.",
                    "label": 1
                },
                {
                    "sent": "Lets you take a PDA or a cell phone and take a photo of something and then goes and looks up.",
                    "label": 0
                },
                {
                    "sent": "What it is and tells you something about it, and these are the sorts of things that it works well for.",
                    "label": 0
                },
                {
                    "sent": "Basically kind of richly textured things which aren't too.",
                    "label": 0
                },
                {
                    "sent": "Movable, which kind of fairly rigid can do well at those, and we'll see why these are basically feature based, and we're doing pretty well with features, and I'll talk about that in a little bit.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So there's a nice summary of what the state of computer vision industry is on David Lowe's web page and you can just read out some of the headlines, automotive assistance, digital photography.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Be tracking.",
                    "label": 0
                },
                {
                    "sent": "Games and gesture recognition.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "General purpose.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This industrial automation people tracking object recognition also say in terms of where the field is excited about the field is kind of maniacally focused on the object recognition problem.",
                    "label": 0
                },
                {
                    "sent": "I think a little too much I think, but that's where there's a whole lot of effort in trying to.",
                    "label": 0
                },
                {
                    "sent": "We can recognize a few categories pretty well.",
                    "label": 0
                },
                {
                    "sent": "We want to get that up to somewhere recognized thousands of objects, or it's not that people can recognize like 30,000 different objects.",
                    "label": 0
                },
                {
                    "sent": "Well, we're nowhere near that.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Old performance.",
                    "label": 0
                },
                {
                    "sent": "Traffic and Rd management web applications 3D.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Only so, so with all that industrial interest and work you know what?",
                    "label": 0
                },
                {
                    "sent": "How are we on what, the status report and where we are with with those particular tasks that I mentioned before, can you wave around the camera and get a 3D model out?",
                    "label": 1
                },
                {
                    "sent": "Well, almost certainly you can use the so called active lighting user Connect or some other system and get a 3D model out.",
                    "label": 0
                },
                {
                    "sent": "Doing it was simply a camera you can almost do that.",
                    "label": 0
                },
                {
                    "sent": "Or many times it can do it, but have some holes or problems in it.",
                    "label": 1
                },
                {
                    "sent": "Capture opposing an actor dancing.",
                    "label": 1
                },
                {
                    "sent": "Well if you use multiple cameras, we can nail that problem and people signed it to their computer vision glasses with just a single camera.",
                    "label": 0
                },
                {
                    "sent": "It's much harder, and we're not quite there yet, but we're getting close.",
                    "label": 0
                },
                {
                    "sent": "Detect and recognize faces.",
                    "label": 0
                },
                {
                    "sent": "If it's a frontal view, yes.",
                    "label": 0
                },
                {
                    "sent": "If it's not funnel as much harder.",
                    "label": 0
                },
                {
                    "sent": "Recognize object.",
                    "label": 1
                },
                {
                    "sent": "Again, there's a lot of people working on it, and a lot of progress, but it's still.",
                    "label": 0
                },
                {
                    "sent": "It's a tough problem and we have a long way to go.",
                    "label": 0
                },
                {
                    "sent": "Track people and objects well if it's over a short period of time, yes, over a long period of time, meaning more than just a second or two, it's hard to do it reliably.",
                    "label": 0
                },
                {
                    "sent": "And enhance images.",
                    "label": 0
                },
                {
                    "sent": "Well, we can enlarge images and make up details for those enlargements.",
                    "label": 0
                },
                {
                    "sent": "If we zoom just by a factor of four in each dimension.",
                    "label": 0
                },
                {
                    "sent": "But we go larger than that, then we start breaking down.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So that's kind of where things are.",
                    "label": 0
                },
                {
                    "sent": "So what I want to do now is kind of a little bit more detail talk about how these problems are really machine learning problems and talk about where some of the places are.",
                    "label": 0
                },
                {
                    "sent": "They were stuck.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So high level vision.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "So why?",
                    "label": 0
                },
                {
                    "sent": "Why is this hard?",
                    "label": 0
                },
                {
                    "sent": "Why can't we just solve this?",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Problems well, the thing that really makes it hard is variability.",
                    "label": 0
                },
                {
                    "sent": "So here I'm going to show you a lot of pictures of one person.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And just look at how different these pictures are of that one person.",
                    "label": 0
                },
                {
                    "sent": "Of course, this is celebrity.",
                    "label": 0
                },
                {
                    "sent": "We all know him, but these are all Paul McCartney pictures.",
                    "label": 0
                },
                {
                    "sent": "Over different times under different lighting conditions.",
                    "label": 0
                },
                {
                    "sent": "Normalized so they're all facing forward and same size, but you can see how much that image changes overtime.",
                    "label": 0
                },
                {
                    "sent": "That's just one object, one not even.",
                    "label": 0
                },
                {
                    "sent": "You know it's a sub category of an object if you start.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Branching out to different instances in different types of within one category, you can get huge visual variability, so all these things are chairs or things you can sit on and yet you can see that they.",
                    "label": 0
                },
                {
                    "sent": "Look very different visually, so we want to get a classifier which will look at any one of those and say, oh, that's a chair.",
                    "label": 0
                },
                {
                    "sent": "So that's a hard problem.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So that's really in my mind, the top level thing that makes vision difficult.",
                    "label": 0
                },
                {
                    "sent": "Or do you want to become invariant?",
                    "label": 0
                },
                {
                    "sent": "Two different viewpoints, different illumination conditions, invariant to occlusions, different scales to deformations to clutter?",
                    "label": 0
                },
                {
                    "sent": "Those are the things that really make it difficult.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "One approach to get around these problems is to find so-called features.",
                    "label": 0
                },
                {
                    "sent": "A little regions of the image and some representation of that image.",
                    "label": 0
                },
                {
                    "sent": "Which is invariant as much as possible to all these little changes.",
                    "label": 0
                },
                {
                    "sent": "They're going to happen to it, and now you can't expect the whole image to be invariant to these things, but maybe you can come up with some representation which will make this small region descriptive yet invariant, and that's actually where we've recently made progress.",
                    "label": 0
                },
                {
                    "sent": "So to talk about that.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So I'm going to go back in time first, so let's take a little time machine and see what things were like like in the mid 80s, OK, in computer vision.",
                    "label": 0
                },
                {
                    "sent": "So bad.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Then everybody looked like this.",
                    "label": 0
                },
                {
                    "sent": "OK, nice geometrical things connected by lines bounded by points.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And so those are the kind of features that people used.",
                    "label": 0
                },
                {
                    "sent": "Back then.",
                    "label": 0
                },
                {
                    "sent": "Points, lines, conics, sometimes fitted curve.",
                    "label": 1
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we could do pretty well with kind of computer generated images of things that look kind of like this sort of blocksworld.",
                    "label": 0
                },
                {
                    "sent": "We could handle it pretty well.",
                    "label": 0
                },
                {
                    "sent": "And so.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here's a picture from a research paper around 1986, so this is like the.",
                    "label": 0
                },
                {
                    "sent": "You know the good output of a paper at the top conference in 1986 and so.",
                    "label": 0
                },
                {
                    "sent": "Well, if you'll pardon the image quality from back then digitized from a paper proceedings, here's a model they're looking for.",
                    "label": 0
                },
                {
                    "sent": "Here's the input image.",
                    "label": 0
                },
                {
                    "sent": "Find this in that model.",
                    "label": 0
                },
                {
                    "sent": "So first of all, it's all 2D's that makes it much easier, and it's all geometrical shapes that also makes it easier and hear the spectacular result of this paper at the top conference in 1986 was OK. We found the two different instances of that thing.",
                    "label": 0
                },
                {
                    "sent": "That shape within that clutter.",
                    "label": 0
                },
                {
                    "sent": "OK, now let's go.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Forward to six years later, still at the top conference.",
                    "label": 0
                },
                {
                    "sent": "Well, we were looking at it from a slightly different viewpoint.",
                    "label": 0
                },
                {
                    "sent": "Now it's got slightly more lighting variation, but still things that are kind of mostly flat sitting on table geometric anile look.",
                    "label": 0
                },
                {
                    "sent": "We found them again, you know, so progress was slow.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "But now let's go back with The Time Machine back to the present.",
                    "label": 1
                },
                {
                    "sent": "Well nowadays we handle images like this and.",
                    "label": 0
                },
                {
                    "sent": "And we you know, real world images of how these companies we have things looking out from cars.",
                    "label": 0
                },
                {
                    "sent": "How is it that we?",
                    "label": 0
                },
                {
                    "sent": "Have made that progress from what we could do in the.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "80s and 90s.",
                    "label": 0
                },
                {
                    "sent": "Well so.",
                    "label": 0
                },
                {
                    "sent": "This is all my view of things.",
                    "label": 0
                },
                {
                    "sent": "I think they're kind of four reasons.",
                    "label": 0
                },
                {
                    "sent": "Arguably, this progress, the first one are these modern features, and these are getting little descriptions of local image areas that are primarily robust against many of those changes that we're going to be worried about, and I want to tell you about the ones that had the one that is had by far the most impact, but other things I should mention have been discriminative classifiers.",
                    "label": 0
                },
                {
                    "sent": "Again, these are not things that we borrowed from your community.",
                    "label": 0
                },
                {
                    "sent": "I think from the NIPS type community discriminative classifiers such as boosting support vector machines had a huge impact in computer vision.",
                    "label": 0
                },
                {
                    "sent": "Bayesian methods, graphical models, nonparametric Bayes have also had a big impact.",
                    "label": 1
                },
                {
                    "sent": "And of course another thing that I think is really brought about.",
                    "label": 0
                },
                {
                    "sent": "A lot of this change is just computers advancing and having very large databases.",
                    "label": 0
                },
                {
                    "sent": "So you should note, by the way, that these four things that have really caused these improvements in my area.",
                    "label": 0
                },
                {
                    "sent": "Only one of them is really vision specific and the others are things that we borrowed from other communities or just as a result of computers getting faster.",
                    "label": 0
                },
                {
                    "sent": "But this would be encouraging for you to jump in and help us.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "More.",
                    "label": 0
                },
                {
                    "sent": "But let me talk about the SIFT features that have really had a big impact.",
                    "label": 1
                },
                {
                    "sent": "In the vision field so.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is.",
                    "label": 0
                },
                {
                    "sent": "The paper that had the huge impact.",
                    "label": 0
                },
                {
                    "sent": "It's not the only kind of feature there is, but it just is by far the most influential is by David Lowe at UBC.",
                    "label": 0
                },
                {
                    "sent": "And this paper that he published in Journal Form in 04.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Received 9000 citations and it was like single handedly responsible for having the impact factor of that Journal be as high as it is and they were.",
                    "label": 0
                },
                {
                    "sent": "They were worried that when when the.",
                    "label": 0
                },
                {
                    "sent": "Time that they track the impact factor for an individual paper passed over this paper, they're going to fall in their impact factor because this one paper has been so.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Influential, So what does the paper do?",
                    "label": 0
                },
                {
                    "sent": "So the game is again you want to find some local description of a local region which will be as much as possible robust against all these changes that happen to things in the world.",
                    "label": 0
                },
                {
                    "sent": "And so the story is, if you can find that magical descriptor, then you would take an object you want to recognize and apply this featured detector and descriptor all over the image and get a little set of features.",
                    "label": 0
                },
                {
                    "sent": "These are the rich textural features that are.",
                    "label": 1
                },
                {
                    "sent": "That are present on this object, and then you would go with some image that you want to recognize that object in you go apply your feature detector and descriptor all over this image.",
                    "label": 0
                },
                {
                    "sent": "And go compare it against your dictionary database saying all the features that you have in which database object that feature corresponds to.",
                    "label": 0
                },
                {
                    "sent": "So then in this case you would look and say oh here's that feature outlook.",
                    "label": 0
                },
                {
                    "sent": "I've seen that feature before.",
                    "label": 0
                },
                {
                    "sent": "That's from this database objects and so here's a candidate pose.",
                    "label": 0
                },
                {
                    "sent": "An object that might be in this image and you find other features and they all confirm that same object and pose and say hi detected this object at this pose in this image is kind of.",
                    "label": 0
                },
                {
                    "sent": "The way things work now, how are we going to describe those local image regions?",
                    "label": 0
                },
                {
                    "sent": "Well, again, we want it to be robust against all these lights.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Changes and stuff.",
                    "label": 0
                },
                {
                    "sent": "So the first thing let's not use pixels, let's use.",
                    "label": 0
                },
                {
                    "sent": "Image gradients, image image, directional derivatives.",
                    "label": 0
                },
                {
                    "sent": "So why is that going to be helpful?",
                    "label": 0
                },
                {
                    "sent": "Well, here's a picture of my hand under two different lighting conditions, and the pixel based image.",
                    "label": 0
                },
                {
                    "sent": "You can see it's quite different from one lighting condition to another, but if you instead represent it as image gradient orientations.",
                    "label": 0
                },
                {
                    "sent": "And normalize it to local contrast.",
                    "label": 0
                },
                {
                    "sent": "You can see it's actually much more similar to each other than in the original pixel based representation.",
                    "label": 0
                },
                {
                    "sent": "So that's step one.",
                    "label": 0
                },
                {
                    "sent": "Let's let's work with image gradients.",
                    "label": 0
                },
                {
                    "sent": "To get some.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Independence and then Step 2 is we want to.",
                    "label": 0
                },
                {
                    "sent": "We don't really care whether some contour goes exactly here or some slight difference away from it.",
                    "label": 0
                },
                {
                    "sent": "And again, if we use the pixel representation and then you try to subtract the two and compare, you're going to be very sensitive to everything lining up just perfectly.",
                    "label": 0
                },
                {
                    "sent": "So we want to be insensitive to that.",
                    "label": 0
                },
                {
                    "sent": "So let's first take the image, find the image gradients.",
                    "label": 0
                },
                {
                    "sent": "Then let's do some spatial pooling so that we don't have to worry about exactly.",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Everything landed, so let's look not at the histograms themselves, but rather.",
                    "label": 0
                },
                {
                    "sent": "Sorry, not at the gradients themselves, but rather at histogram of the gradients.",
                    "label": 0
                },
                {
                    "sent": "Cooling over some spatial region, so that's going to be our representation of that local image region will take the gradients.",
                    "label": 0
                },
                {
                    "sent": "Pull them over space an but we don't forget entirely where things happened over space will make little regions of pooling and stack them together in a configuration.",
                    "label": 0
                },
                {
                    "sent": "This is 2 by two in practice which you used as a four by four region of these little local pooled accumulation regions where we calculate the histogram of the gradients history orientations.",
                    "label": 0
                },
                {
                    "sent": "And that's pretty much it.",
                    "label": 0
                },
                {
                    "sent": "Then we take all those things and stack them up into big vector.",
                    "label": 0
                },
                {
                    "sent": "And that's a turns out 128 dimensional representation of the image stuff in each little region.",
                    "label": 0
                },
                {
                    "sent": "Then there's other steps about where you find those specific regions that you.",
                    "label": 0
                },
                {
                    "sent": "Refinable way.",
                    "label": 0
                },
                {
                    "sent": "That will and then set up a coordinate system that's invariant to the local orientation, invariant to scale.",
                    "label": 0
                },
                {
                    "sent": "And if you follow all those steps then you get this so called sift feature for scale invariant feature transform which takes these features, put them into 120 mention vector which is by and large robust against orientation scale, exact positioning, an lighting and these things are the sliced bread of computer vision.",
                    "label": 0
                },
                {
                    "sent": "It's kind of annoying actually how many papers.",
                    "label": 0
                },
                {
                    "sent": "Use this just as the initial first step, but anyway.",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Very successful.",
                    "label": 0
                },
                {
                    "sent": "And why are they successful?",
                    "label": 0
                },
                {
                    "sent": "'cause they work pretty well.",
                    "label": 0
                },
                {
                    "sent": "So here's a couple of slides showing how they work pretty well.",
                    "label": 0
                },
                {
                    "sent": "Here we're going to add different amounts of image noise on the bottom 0246, eight, 10%.",
                    "label": 1
                },
                {
                    "sent": "Pixel noise and then look at how well this feature will match against the data set of features.",
                    "label": 0
                },
                {
                    "sent": "Finding it's it's match within that data set.",
                    "label": 0
                },
                {
                    "sent": "It's fairly robust against noise, so what's nice about it is a relatively high dimensional feature 120 dimensional so it can be you can push it around a little bit and you'll still find its nearest proper nearest neighbor.",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You can change the viewpoint of the image, so this is modeled by an afine change, and if we change the viewpoint angle by on the bottom scale 0 ten 2040, thirty 4050 degrees and again the correct matching falls off somewhat, but not dramatically.",
                    "label": 0
                },
                {
                    "sent": "As you make these changes in viewpoint, so that's.",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So good and then how distinctive are they?",
                    "label": 0
                },
                {
                    "sent": "Well, you can take this 120th national feature and then just add lots more features to the data set that you're trying to look for the best match within.",
                    "label": 0
                },
                {
                    "sent": "And even as you add many, many more sort of distractors if you will for finding the nearest neighbour match it will still do a very good job of finding their stable match again because it's a fairly relatively high dimensional thing.",
                    "label": 0
                },
                {
                    "sent": "120 mentioned that you're looking for so there the number of other distracting key points in the database can be 1010 thousand or 100,000 and performance drops very little.",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And so the result is you can get results like these, so this is from this 2004 paper.",
                    "label": 0
                },
                {
                    "sent": "Here's a here's your little.",
                    "label": 0
                },
                {
                    "sent": "Toy data set of objects you're looking for.",
                    "label": 0
                },
                {
                    "sent": "Again, you go and find the search features in there and then.",
                    "label": 0
                },
                {
                    "sent": "Here's the image you want to find those in.",
                    "label": 0
                },
                {
                    "sent": "So now you take your SIFT feature detector and look for all the places where you find those features and then look to see when did I see this thing anywhere.",
                    "label": 0
                },
                {
                    "sent": "There rather did I see the features that were found here anywhere else in this image.",
                    "label": 0
                },
                {
                    "sent": "Anna how you did and you can localize where those objects are even if they are included so you don't.",
                    "label": 0
                },
                {
                    "sent": "The features are localized so you don't find all of them, you just have to find some.",
                    "label": 0
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And here's another example, and again, this kind of shows where it works really well when you have richly textured things, it just nails it.",
                    "label": 0
                },
                {
                    "sent": "Harder with things that don't have the same kind of richness of the orientation distribution, but here's some totem poles.",
                    "label": 0
                },
                {
                    "sent": "And you can find the those in some other photo quite easily.",
                    "label": 0
                },
                {
                    "sent": "So what can you do with this?",
                    "label": 0
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Sort of thing.",
                    "label": 0
                },
                {
                    "sent": "Well, again, there pervasive.",
                    "label": 0
                },
                {
                    "sent": "So you can use them in.",
                    "label": 0
                }
            ]
        },
        "clip_55": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Computational photography, so here you're making a mosaic taking many different shots of this region and then matching one picture with another.",
                    "label": 0
                },
                {
                    "sent": "By matching those sift features.",
                    "label": 0
                }
            ]
        },
        "clip_56": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And it turns out these things are useful for all sorts of computer vision and image processing applications, so here's a partial list of where they used image alignment, 3D reconstruction, motion tracking, indexing, database retrieval mode, robot navigation, and then it's also used in places where they wouldn't think of work well.",
                    "label": 1
                },
                {
                    "sent": "So when I first saw these that OK, these are good, for instance recognition for really for magazine cover detection.",
                    "label": 0
                },
                {
                    "sent": "If you have a magazine cover and you want to find that somewhere else you look, you match those exact textured regions.",
                    "label": 0
                },
                {
                    "sent": "And the other thing.",
                    "label": 0
                },
                {
                    "sent": "But to my surprise, and other people surprise.",
                    "label": 0
                }
            ]
        },
        "clip_57": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "They're also really good for category object category recognition.",
                    "label": 0
                },
                {
                    "sent": "In other words, you have a database of chairs.",
                    "label": 0
                },
                {
                    "sent": "Go find a new chair that you've never seen before in your database.",
                    "label": 0
                },
                {
                    "sent": "Not an exact match.",
                    "label": 0
                },
                {
                    "sent": "It still does a good job to 1st represent these things.",
                    "label": 0
                },
                {
                    "sent": "These features, and of course you want to maybe vector quantized them as little space around them, But then match up those features that works really quite well for object category recognition.",
                    "label": 0
                }
            ]
        },
        "clip_58": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here's an example of that.",
                    "label": 0
                },
                {
                    "sent": "You might want to take an image and.",
                    "label": 0
                },
                {
                    "sent": "Detect those, detect those points where you're going to describe the local image region.",
                    "label": 0
                },
                {
                    "sent": "These are called key points for finding your features.",
                    "label": 0
                },
                {
                    "sent": "Then describe the local.",
                    "label": 0
                },
                {
                    "sent": "Image region with the SIFT feature at those points and then typically these are vector quantized into a little vocabulary of maybe 2000 or so.",
                    "label": 0
                }
            ]
        },
        "clip_59": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "You would call them visual words.",
                    "label": 1
                },
                {
                    "sent": "This is your visual vocabulary.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                }
            ]
        },
        "clip_60": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You can use these to categorize, so here's the image.",
                    "label": 0
                },
                {
                    "sent": "Find the features and then you say OK, how many times did each of my two or three each of my different of the 3000 vocabulary elements that I have for all images, how many times each?",
                    "label": 0
                },
                {
                    "sent": "Did each image occur?",
                    "label": 0
                },
                {
                    "sent": "Sorry.",
                    "label": 0
                },
                {
                    "sent": "Did each feature vector word occur?",
                    "label": 0
                },
                {
                    "sent": "Let me get back to where I was.",
                    "label": 0
                },
                {
                    "sent": "So then you can make a almost like a with a text document.",
                    "label": 0
                },
                {
                    "sent": "You make a word frequency occurrence that describes this image and then puzzlingly enough.",
                    "label": 0
                },
                {
                    "sent": "This is actually quite good at.",
                    "label": 0
                },
                {
                    "sent": "At detecting what kind of objects are in this image, just looking at the frequency, how many times did each different feature word class occur?",
                    "label": 0
                },
                {
                    "sent": "So my point is.",
                    "label": 0
                }
            ]
        },
        "clip_61": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now this starts to look like a learning problem.",
                    "label": 1
                },
                {
                    "sent": "We have M possible.",
                    "label": 1
                },
                {
                    "sent": "And feature words that were found in some test region and then end possible matching features from some each of each different K possible training classes.",
                    "label": 0
                },
                {
                    "sent": "Which of those training classes most likely to have a curd in that image and?",
                    "label": 0
                },
                {
                    "sent": "So this is this type of approaches is among the leaders in object recognition approaches currently.",
                    "label": 0
                }
            ]
        },
        "clip_62": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "These features have been very useful.",
                    "label": 0
                },
                {
                    "sent": "We've also adopted many machine learning methods.",
                    "label": 0
                },
                {
                    "sent": "What else do we want?",
                    "label": 1
                },
                {
                    "sent": "You know?",
                    "label": 0
                },
                {
                    "sent": "What do we need to help make progress?",
                    "label": 0
                }
            ]
        },
        "clip_63": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So I actually went around to the last several computer vision conferences and asked my colleagues this question.",
                    "label": 0
                },
                {
                    "sent": "It would be sort of my lunchtime conversation with them.",
                    "label": 0
                },
                {
                    "sent": "I say so suppose.",
                    "label": 0
                },
                {
                    "sent": "You were talking with a good group of machine learning theorists.",
                    "label": 0
                },
                {
                    "sent": "You know what would you ask them for?",
                    "label": 0
                },
                {
                    "sent": "So here's a.",
                    "label": 0
                },
                {
                    "sent": "Picture representing my community.",
                    "label": 0
                },
                {
                    "sent": "This was at a particular workshop.",
                    "label": 0
                }
            ]
        },
        "clip_64": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And so I would ask them.",
                    "label": 0
                },
                {
                    "sent": "How do you think computer science can best help computer vision?",
                    "label": 0
                }
            ]
        },
        "clip_65": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the most common response for what they wanted was.",
                    "label": 0
                },
                {
                    "sent": "Any guesses, by the way?",
                    "label": 0
                },
                {
                    "sent": "The most common.",
                    "label": 0
                }
            ]
        },
        "clip_66": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Once was fast.",
                    "label": 0
                },
                {
                    "sent": "Approximate nearest neighbor search in high dimensions.",
                    "label": 1
                },
                {
                    "sent": "Now you may be thinking, but look we gave them that already.",
                    "label": 0
                },
                {
                    "sent": "You know, gave them locality sensitive hashing.",
                    "label": 0
                },
                {
                    "sent": "You know they've already got this, but no.",
                    "label": 0
                }
            ]
        },
        "clip_67": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "It's not good enough.",
                    "label": 0
                },
                {
                    "sent": "So here's some quotes from people what they said OK. Let's see nearest neighbor search, but taking into account our particular type of data, you know these are images are not just random vectors and also what maybe have them tell us what questions we should be asking about our data in order to do nearest neighbor search.",
                    "label": 1
                },
                {
                    "sent": "Well, how can we explore parallelism?",
                    "label": 0
                },
                {
                    "sent": "Why doesn't LSH work as advertised for our datasets?",
                    "label": 0
                },
                {
                    "sent": "Let's see.",
                    "label": 0
                },
                {
                    "sent": "Right, so let me.",
                    "label": 0
                }
            ]
        },
        "clip_68": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Show some of this, so there's a nice paper also actually by Co.",
                    "label": 0
                },
                {
                    "sent": "Authored by David Lowe on fast approximate nearest neighbors for.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                }
            ]
        },
        "clip_69": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Algorithms and how to configure these rolling, so here's a plot showing.",
                    "label": 0
                },
                {
                    "sent": "See for the number of.",
                    "label": 0
                },
                {
                    "sent": "If you want to key nearest neighbors and have some fraction of those indeed be within the K nearest neighbors, set, here's the fraction of the nearest neighbors that are correctly retrieved.",
                    "label": 0
                },
                {
                    "sent": "The nearest fraction of the nearest neighbors that you retrieve that are correct.",
                    "label": 0
                },
                {
                    "sent": "Going from 50 sixty 7900.",
                    "label": 0
                },
                {
                    "sent": "And then here is the speedup over linear search plotted this way.",
                    "label": 0
                },
                {
                    "sent": "So the best curve would be high here.",
                    "label": 0
                },
                {
                    "sent": "And how does LSH perform well?",
                    "label": 0
                },
                {
                    "sent": "It's way down here for our particular datasets, and so the point of this paper was introducing these other way to automatically tune these other two algorithms.",
                    "label": 0
                },
                {
                    "sent": "K means tryan random KD trees which do much better than other methods.",
                    "label": 0
                },
                {
                    "sent": "Again for finding nearest neighbors of image patches or of local descriptors of image patches.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "We need.",
                    "label": 0
                }
            ]
        },
        "clip_70": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Help here and also oftentimes in our nearest neighbor searches, there's extra structure that we'd like to be able to exploit or have an algorithm take advantage of.",
                    "label": 0
                },
                {
                    "sent": "So for example.",
                    "label": 0
                },
                {
                    "sent": "Here's a panda and then overlaid.",
                    "label": 0
                },
                {
                    "sent": "There are all these little features that are detected and each one has a little word that's associated with it.",
                    "label": 0
                },
                {
                    "sent": "To saying what image, what's the image?",
                    "label": 0
                },
                {
                    "sent": "Appearances in this local region that spanned A and here's panda be that you want to match it to.",
                    "label": 0
                },
                {
                    "sent": "It doesn't have all the same features detected.",
                    "label": 0
                },
                {
                    "sent": "It has some of the same ones detected and there's different scales involved an so you want to do an optimal partial matching of the features found in here to the features found there.",
                    "label": 0
                },
                {
                    "sent": "And so here's a.",
                    "label": 0
                },
                {
                    "sent": "An attempt at that are optimal partial matching of the features, and you've got scale variations and distance variations.",
                    "label": 0
                },
                {
                    "sent": "So how can we quickly find the most probable object categories from these sets of partial matches of features?",
                    "label": 1
                },
                {
                    "sent": "How do we, in a principled way, handle these features?",
                    "label": 0
                },
                {
                    "sent": "Variations that are inevitably?",
                    "label": 0
                }
            ]
        },
        "clip_71": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Going to show up.",
                    "label": 0
                },
                {
                    "sent": "Another nearest nearest neighbor search problem.",
                    "label": 1
                },
                {
                    "sent": "With kind of the structure of images, is so called nonlocal means denoising, so this is.",
                    "label": 1
                },
                {
                    "sent": "This is actually the world's best denoising algorithm right now.",
                    "label": 0
                },
                {
                    "sent": "Or tide with the best and it's this crazy simple Al.",
                    "label": 0
                }
            ]
        },
        "clip_72": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Rhythm here it is.",
                    "label": 0
                },
                {
                    "sent": "It's easy, it's so easy.",
                    "label": 0
                },
                {
                    "sent": "You can explain it with the picture.",
                    "label": 0
                },
                {
                    "sent": "The idea is that there aren't that many different image patches in the world, or even in any single image, an if you.",
                    "label": 0
                },
                {
                    "sent": "So in any given image, if you take any Patch, you'll be able to find.",
                    "label": 0
                },
                {
                    "sent": "Within that image, other matches of that Patch which are pretty much the same Patch, just with some noise added to it.",
                    "label": 0
                },
                {
                    "sent": "So this is sort of a sparsity assumption about image data.",
                    "label": 0
                },
                {
                    "sent": "And so one way to denoise an image is to go grab each Patch, look for its nearest neighbors within that image and average them together.",
                    "label": 0
                },
                {
                    "sent": "Say that well, these are just versions of the exact same Patch and the only differences between these are caused by noise.",
                    "label": 0
                },
                {
                    "sent": "So I'll just average them together and take the average value as my new denoise value for the center pixel, and do that for all the pixels of your image and you get the world's best in terms of signal noise ratio denoising algorithm.",
                    "label": 0
                },
                {
                    "sent": "But so this brings up the question, how do you quickly and efficiently find those?",
                    "label": 0
                },
                {
                    "sent": "Nearest neighbor matches key nearest neighbor matches within the image and you've got the again.",
                    "label": 0
                },
                {
                    "sent": "This extra structure that you've got.",
                    "label": 0
                },
                {
                    "sent": "It's an image is not just random sets of data.",
                    "label": 0
                }
            ]
        },
        "clip_73": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here's one.",
                    "label": 0
                },
                {
                    "sent": "Here's one algorithm which actually works well to take that into account, and so this is.",
                    "label": 0
                },
                {
                    "sent": "Perhaps not where we need help, but it's an example of the sort of algorithm that we need.",
                    "label": 0
                },
                {
                    "sent": "Apply in other situations.",
                    "label": 0
                },
                {
                    "sent": "This is called Patch match.",
                    "label": 0
                },
                {
                    "sent": "It was.",
                    "label": 0
                },
                {
                    "sent": "It's a randomized.",
                    "label": 0
                }
            ]
        },
        "clip_74": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Algorithm.",
                    "label": 0
                },
                {
                    "sent": "So here's the story you take here.",
                    "label": 0
                }
            ]
        },
        "clip_75": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Pixel user Patch.",
                    "label": 0
                },
                {
                    "sent": "Step one is you throw down your Patch marker at random different positions within the image.",
                    "label": 0
                },
                {
                    "sent": "These are candidate matches for it.",
                    "label": 0
                }
            ]
        },
        "clip_76": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then Step 2 is you look at the previous pixel, which by now you from the previous iteration of the algorithm you found the best matches for that thing and you.",
                    "label": 0
                }
            ]
        },
        "clip_77": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Say OK, what?",
                    "label": 0
                },
                {
                    "sent": "So the previous pixel to the left had these best nearest neighbor Patch patches for matching, so I'm going to.",
                    "label": 0
                }
            ]
        },
        "clip_78": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Look at what's just one to the right of those patches.",
                    "label": 0
                },
                {
                    "sent": "That's like a Reese.",
                    "label": 0
                }
            ]
        },
        "clip_79": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "More good guess for what might be a good match to where you are and so now.",
                    "label": 0
                },
                {
                    "sent": "You got this set of candidate patches.",
                    "label": 0
                },
                {
                    "sent": "You've got the ones that matched that were just to the right of the ones that matched your pixel to the left from the previous time, and you've got these ones from throwing down your.",
                    "label": 0
                },
                {
                    "sent": "Candidate position that it's just random locations.",
                    "label": 0
                },
                {
                    "sent": "Let's take this set of candidates and now exhaustively look and see how close each one of them is to the current Patch and pick.",
                    "label": 0
                }
            ]
        },
        "clip_80": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The best ones there and use that as my set of K nearest neighbors to match this particular Patch and then move on.",
                    "label": 0
                },
                {
                    "sent": "So you introduce a little bit of randomness in the search by by throwing down the marker at random positions in the image.",
                    "label": 0
                }
            ]
        },
        "clip_81": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And OK, this is a kind of crazy algorithm, kind of simple, not that hard to come up with.",
                    "label": 0
                },
                {
                    "sent": "You can come up with other things like this for us, but this one, for example, works spectacularly well, and it's in the latest version of Photoshop, so I want to show you show it to you working.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Let's see, let's go to photo shop.",
                    "label": 0
                },
                {
                    "sent": "OK, here's a picture of my daughter.",
                    "label": 0
                },
                {
                    "sent": "You can say I want to take away.",
                    "label": 0
                },
                {
                    "sent": "That white plate.",
                    "label": 0
                },
                {
                    "sent": "OK, so I'm going to hit the delete key.",
                    "label": 0
                },
                {
                    "sent": "On the computer and it asked me OK, when I fill in what you're deleting, do you want me to fill it in with a content where a content aware fill?",
                    "label": 0
                },
                {
                    "sent": "And I'll say yes.",
                    "label": 0
                },
                {
                    "sent": "And there it does it, so it it did this past match algorithm to fill in that stuff.",
                    "label": 0
                },
                {
                    "sent": "But look for things that would fit in well from other parts.",
                    "label": 0
                },
                {
                    "sent": "But you can do bigger things here.",
                    "label": 0
                },
                {
                    "sent": "Let's take this the whole thing away.",
                    "label": 0
                },
                {
                    "sent": "Let's delete that content aware sure.",
                    "label": 0
                },
                {
                    "sent": "And so there is hard to see.",
                    "label": 0
                },
                {
                    "sent": "Where was let's do something harder just to finish up.",
                    "label": 0
                },
                {
                    "sent": "I think this so I'm not sure if this will fail or work, but let's go try this thing at a boundary.",
                    "label": 0
                },
                {
                    "sent": "Delete that.",
                    "label": 0
                },
                {
                    "sent": "And as you know, that's a pretty good guess.",
                    "label": 0
                },
                {
                    "sent": "So anyway, that's that's one of the benefits of randomized algorithms in computer vision applications.",
                    "label": 0
                },
                {
                    "sent": "Let's go back to the show.",
                    "label": 0
                }
            ]
        },
        "clip_82": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And so, by the way, this this is another example of research working well.",
                    "label": 0
                },
                {
                    "sent": "the Adobe group that the Adobe Research Group introduced this to the into the product and they just it led to the first billion dollars sales of Photoshop than they had in a year before.",
                    "label": 0
                },
                {
                    "sent": "I mean, for the first year after this was introduced, they had the sales dramatically increased and they thought it was marketing, particularly thought that was caused by this feature.",
                    "label": 0
                },
                {
                    "sent": "I mean, there's in the blogs and all the reviews just raved over that feature.",
                    "label": 0
                },
                {
                    "sent": "New feature for Adobe Photo shop.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "OK, let me go back.",
                    "label": 0
                }
            ]
        },
        "clip_83": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK so anyway, just to recap, we need help with nearest neighbor search in high dimensions for images and it will have application in texture synthesis and super resolution image filling in object recognition scene recognition.",
                    "label": 0
                }
            ]
        },
        "clip_84": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "All sorts of applications and what else did people ask for?",
                    "label": 0
                },
                {
                    "sent": "In general, people ask for help scaling things up that.",
                    "label": 0
                },
                {
                    "sent": "Many computer vision algorithms really boil down to solving some integer program or some linear program, or some quadratic program, or some semidefinite programs, and with large amounts of high dimensional data, and the standard solvers typically don't work under the conditions that we're asking them to work, and we need help in exploiting the sparsity or the structure of the problem, or developing online versions.",
                    "label": 1
                },
                {
                    "sent": "You know with maybe thousands of other categories.",
                    "label": 0
                },
                {
                    "sent": "These are some of the things that people ask for.",
                    "label": 0
                }
            ]
        },
        "clip_85": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So that summarizes this slide.",
                    "label": 0
                }
            ]
        },
        "clip_86": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So those are kind of high level things, although I guess the Patch matches low level as well.",
                    "label": 0
                },
                {
                    "sent": "Let's talk about some other low level problems so I'm distinguishing high level from low level.",
                    "label": 0
                },
                {
                    "sent": "I think high level vision as image in words out like descriptions of it low level vision as image in image out, maybe an enhanced image.",
                    "label": 0
                }
            ]
        },
        "clip_87": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "One thing we really need help with is having statistical priors on images.",
                    "label": 0
                },
                {
                    "sent": "How are prices can be useful?",
                    "label": 0
                },
                {
                    "sent": "Well, so here's an image.",
                    "label": 0
                },
                {
                    "sent": "Here's a noisy version of that image.",
                    "label": 0
                },
                {
                    "sent": "We want to denoise it.",
                    "label": 0
                },
                {
                    "sent": "You have to have make prior assumptions about what the images look like in order to do anything with a noisy image.",
                    "label": 0
                },
                {
                    "sent": "Suppose you didn't know anything about images.",
                    "label": 0
                },
                {
                    "sent": "How do you know that that isn't a perfectly good image and you should just stop right there?",
                    "label": 0
                },
                {
                    "sent": "Because there you got it?",
                    "label": 0
                },
                {
                    "sent": "You know you've got to make some assumptions about images to move away from this one.",
                    "label": 0
                },
                {
                    "sent": "Well, it turns out it really matters what assumptions you make as far as how well you can denoise, for example, or many things as well.",
                    "label": 0
                },
                {
                    "sent": "So if you just make a Gaussian assumption about images you and make some assumption about with the spectral falloff is you'll get a an optimal reconstruction of this noisy image.",
                    "label": 0
                },
                {
                    "sent": "That might look something like this.",
                    "label": 0
                },
                {
                    "sent": "Which would be optimally supersense under some assumptions about the spectrum of the image, but it doesn't literally look like an image.",
                    "label": 0
                },
                {
                    "sent": "If you instead use.",
                    "label": 0
                },
                {
                    "sent": "More sophisticated Gaussian scale mixture model.",
                    "label": 0
                },
                {
                    "sent": "In a wave representation, you can get a denoising result that looks like this.",
                    "label": 0
                },
                {
                    "sent": "It's still obviously has flaws, but it's much better.",
                    "label": 0
                }
            ]
        },
        "clip_88": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Another problem that image priors are essential to is removing blur from images.",
                    "label": 0
                },
                {
                    "sent": "So if you imagine you shake your camera, so here's kind of a picture of the shows.",
                    "label": 0
                },
                {
                    "sent": "Both the output and the problem.",
                    "label": 0
                },
                {
                    "sent": "Here's a picture of someone in the mirror.",
                    "label": 0
                },
                {
                    "sent": "She shook the camera when she took the picture and you get a blurred picture of her.",
                    "label": 0
                }
            ]
        },
        "clip_89": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We've developed an algorithm which uses Bayesian methods to infer the and prior assumption about images to make a best guess at what the sharp image was before it was blurred.",
                    "label": 0
                }
            ]
        },
        "clip_90": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So he was showing.",
                    "label": 0
                }
            ]
        },
        "clip_91": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "With the algorithms, here's original, here's kind.",
                    "label": 0
                }
            ]
        },
        "clip_92": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Naive sharpening is not just simply sharpening that you need to do.",
                    "label": 1
                },
                {
                    "sent": "You need to also basically estimate how was blurred and remove that.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                }
            ]
        },
        "clip_93": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So here's for this problem.",
                    "label": 0
                },
                {
                    "sent": "Here's the the model for how we get the data blurry.",
                    "label": 0
                },
                {
                    "sent": "Image results from some latent sharp image convolved with this blur kernel.",
                    "label": 1
                },
                {
                    "sent": "So here's a picture of how I'm going to blur kernels.",
                    "label": 0
                },
                {
                    "sent": "It's a photograph of what a point of light would have looked like if you move the camera in the same way as you're photographing this point of light, so that's how one pixel was blurred, and we assume that the whole.",
                    "label": 0
                },
                {
                    "sent": "Every point in the image is blurred in the same way, so then you are instructed to convolve this with that to get this thing.",
                    "label": 0
                },
                {
                    "sent": "What's really cool about this problem is there's just delightfulee under detur.",
                    "label": 0
                }
            ]
        },
        "clip_94": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And again, so here's your data.",
                    "label": 0
                },
                {
                    "sent": "There are many possible solutions which fit this data.",
                    "label": 0
                }
            ]
        },
        "clip_95": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Number one.",
                    "label": 0
                },
                {
                    "sent": "How do you know this was blurred at all?",
                    "label": 0
                },
                {
                    "sent": "It could be that's what was out there.",
                    "label": 0
                },
                {
                    "sent": "That was the image, and that's the blur kernel, you know, just the Delta function, no blur.",
                    "label": 1
                },
                {
                    "sent": "How do you know that's not there?",
                    "label": 0
                },
                {
                    "sent": "You haven't seen this thing before.",
                    "label": 0
                }
            ]
        },
        "clip_96": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "If you're pathological, you can also come up with crazy combinations of image and blur kernel, which will get you what you.",
                    "label": 0
                }
            ]
        },
        "clip_97": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Saw and then of course, this is what you're really looking for.",
                    "label": 0
                },
                {
                    "sent": "This kind of sharp image and implausible kernel, and so to distinguish between these choices, especially this one, is.",
                    "label": 1
                },
                {
                    "sent": "This is really hard to beat because it gets the noise exactly correctly.",
                    "label": 0
                },
                {
                    "sent": "You know everything is just the likelihood is very high on this one.",
                    "label": 0
                }
            ]
        },
        "clip_98": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So how do we favor this one well?",
                    "label": 0
                }
            ]
        },
        "clip_99": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It turns out that you all are really quite good at looking at images you've never seen before and telling us whether it's blurred or not.",
                    "label": 0
                },
                {
                    "sent": "Let's just.",
                    "label": 0
                }
            ]
        },
        "clip_100": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Some just to show me that you can do it blurred or not blurred.",
                    "label": 0
                }
            ]
        },
        "clip_101": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK this one.",
                    "label": 0
                }
            ]
        },
        "clip_102": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Blurred, but this one blurred.",
                    "label": 0
                },
                {
                    "sent": "Yes, right?",
                    "label": 0
                },
                {
                    "sent": "So you could imagine it's kind of high level process that you know about people in swing sets are supposed to look like, but you'd really like to have a low level process that looks at it and tells you whether this is valid image data or whether it's.",
                    "label": 0
                }
            ]
        },
        "clip_103": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Unblurred in some way.",
                    "label": 0
                },
                {
                    "sent": "So it turns out one.",
                    "label": 0
                },
                {
                    "sent": "I mean we're not done with this problem, but we need a little bit of progress on it.",
                    "label": 0
                },
                {
                    "sent": "Some of the progress is just looking at image gradients again, is just really useful.",
                    "label": 1
                },
                {
                    "sent": "Here's a simple statistical model for images saying that if you look at the difference between adjacent pixels, it should have this shape.",
                    "label": 0
                },
                {
                    "sent": "So here is zero difference.",
                    "label": 0
                },
                {
                    "sent": "Here's an scale zero 255 here is going minus 50 -- 100 + 50 + 100 and the vertical axis is log frequency of occurrence of that difference between adjacent pixels.",
                    "label": 0
                },
                {
                    "sent": "In this image.",
                    "label": 0
                },
                {
                    "sent": "So what does it tell you?",
                    "label": 0
                },
                {
                    "sent": "Right away?",
                    "label": 0
                },
                {
                    "sent": "We're not dealing with Gaussians, right?",
                    "label": 0
                },
                {
                    "sent": "Because the log frequency of occurrence for Gaussian noise, it would be an inverted parabola, but it's just really spiky thing, so it's much sparse.",
                    "label": 0
                }
            ]
        },
        "clip_104": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Within Gaussians, and then if you blur the image and look at those gradients, distribution of differences, you get a different curve an.",
                    "label": 0
                },
                {
                    "sent": "So that's what we use for our for the work that I showed you the results up here.",
                    "label": 0
                },
                {
                    "sent": "That's what we worked uses are.",
                    "label": 0
                }
            ]
        },
        "clip_105": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Which prior we we actually did this particular image, we fit a parametrically this.",
                    "label": 0
                },
                {
                    "sent": "Histogram of adjacent.",
                    "label": 0
                }
            ]
        },
        "clip_106": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So differences and then put it into a.",
                    "label": 0
                }
            ]
        },
        "clip_107": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Bayesian framework, so we had a reconstruction constraint that our latent image convolved with our estimated blur kernel, had to give us our data.",
                    "label": 0
                }
            ]
        },
        "clip_108": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We had a prior on the latent image that the gradient distributions had to look like that.",
                    "label": 0
                }
            ]
        },
        "clip_109": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we had a little prior on the Blur kernel that had to be sparse and positive.",
                    "label": 0
                }
            ]
        },
        "clip_110": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And put it on a Bayesian framework.",
                    "label": 0
                },
                {
                    "sent": "It turns out.",
                    "label": 0
                },
                {
                    "sent": "We couldn't use Nmap solution to this.",
                    "label": 0
                },
                {
                    "sent": "And we thought a lot about the reasons for why that we've written papers on this, but variational Bayes worked much better, and I think that's because there are many local Maxima in this problem and you want to.",
                    "label": 0
                },
                {
                    "sent": "It's over 200 constrained to just use Nmap approach an but marginalizing.",
                    "label": 0
                },
                {
                    "sent": "Basically.",
                    "label": 0
                },
                {
                    "sent": "Marginalizing over all possible the images was very good for estimating the unknown blur kernel.",
                    "label": 0
                }
            ]
        },
        "clip_111": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then once you have the blue kernel, would freeze that an estimate the latent image.",
                    "label": 0
                },
                {
                    "sent": "So here's an example image.",
                    "label": 0
                },
                {
                    "sent": "This was taken into museum.",
                    "label": 0
                },
                {
                    "sent": "We couldn't use flash, and it's blurred.",
                    "label": 0
                }
            ]
        },
        "clip_112": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here's are the results of this variational Bayesian method I just sketched to you, and here's the D blurred image.",
                    "label": 0
                },
                {
                    "sent": "And here's the estimated blur kernel Ann, just to show you that it's.",
                    "label": 0
                }
            ]
        },
        "clip_113": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Hard problem, here's the output of matlab's decons blind.",
                    "label": 0
                },
                {
                    "sent": "Nothing gets Matlab, but it's there.",
                    "label": 0
                }
            ]
        },
        "clip_114": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Problem, and here's a close up of our output and the original bird image in Matlab, secom blind.",
                    "label": 1
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "This paper generated a lot of interest in the computer vision and graphics community on on revisiting this so called blind deconvolution problem and we've made it.",
                    "label": 0
                }
            ]
        },
        "clip_115": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Progress, but there's still images that we can't at all handle.",
                    "label": 0
                },
                {
                    "sent": "Basically, we can, if the blur is pretty much uniform over the whole image, well, we have enough data.",
                    "label": 0
                },
                {
                    "sent": "We can kind of solve that, but if different things are moving different ways, we just can't deal with that well now, and so there's a lot of room for.",
                    "label": 0
                }
            ]
        },
        "clip_116": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "A good statistical characterization of images that could be used in noise removal and super resolution and filling in and texture synthesis.",
                    "label": 0
                },
                {
                    "sent": "Lots of things.",
                    "label": 0
                }
            ]
        },
        "clip_117": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Let's see.",
                    "label": 0
                },
                {
                    "sent": "Now that's a repair metric type prior, but we could also use.",
                    "label": 0
                },
                {
                    "sent": "There's a lot of benefits to non parametric synthesis in nonparametric techniques in texture synthesis, and you could use these as priors as well.",
                    "label": 0
                },
                {
                    "sent": "Turns out, the world's best texture synthesis algorithm is basically something that.",
                    "label": 0
                },
                {
                    "sent": "Looks at a local image region, looks in a source texture for where have I seen that same local neighborhood before?",
                    "label": 0
                },
                {
                    "sent": "Looks at the corresponding pixel that you're trying to synthesize in those previous regions and.",
                    "label": 0
                },
                {
                    "sent": "Select one to put there that's.",
                    "label": 0
                },
                {
                    "sent": "One of the.",
                    "label": 0
                }
            ]
        },
        "clip_118": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Simplest and best texture synthesis methods is basically a non parametric image prior and works great and what we would like is for ways to make this more controllable.",
                    "label": 0
                },
                {
                    "sent": "Maybe let me just first show.",
                    "label": 0
                }
            ]
        },
        "clip_119": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The outputs of this texture synthesis method.",
                    "label": 0
                },
                {
                    "sent": "Here's the input texture, and here's more of that same stuff and.",
                    "label": 0
                }
            ]
        },
        "clip_120": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It just works great to use these very simple non parametric.",
                    "label": 0
                }
            ]
        },
        "clip_121": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Methods.",
                    "label": 0
                },
                {
                    "sent": "I would call it the corrupt professors algorithm 'cause it basically says plagiarize as much as you possibly can from the image and try to cover up your tracks.",
                    "label": 0
                },
                {
                    "sent": "And anyway, that works really well for this texture synthesis.",
                    "label": 0
                }
            ]
        },
        "clip_122": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "But we want to use it for other things, for again, for image priors.",
                    "label": 1
                },
                {
                    "sent": "For these other problems, and so I guess another problem is how to construct and manage nonparametric signal prior as well.",
                    "label": 1
                },
                {
                    "sent": "And you could use these in many different places, and here are some references for papers that address this problem.",
                    "label": 0
                }
            ]
        },
        "clip_123": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So then still on the subject of image priors and image prior, that's very often used as a marker and a field.",
                    "label": 0
                },
                {
                    "sent": "This is quite a bit in computer vision and image processing applications, so we have a graphical model.",
                    "label": 0
                },
                {
                    "sent": "These might represent pixels.",
                    "label": 0
                },
                {
                    "sent": "These might represent patches neighboring each other, and.",
                    "label": 0
                },
                {
                    "sent": "Our image is too big to have to make to make this thing be attractable prior over and something that large is an image we want to modular eyes it so will say, well, we say we know what this compatibility function is between neighboring patches or between neighboring pixels and we just use that same function over and over again.",
                    "label": 0
                },
                {
                    "sent": "And then we say what the maybe the likelihood term is between some observation and some underlying label or pixel value.",
                    "label": 0
                },
                {
                    "sent": "We're trying to estimate and again we keep that same one and use it in spatially invariant pattern.",
                    "label": 0
                },
                {
                    "sent": "So then this is our prior over the entire image, if you.",
                    "label": 0
                },
                {
                    "sent": "Give some data in for your wise.",
                    "label": 0
                },
                {
                    "sent": "You want to try to estimate some underlying label or some underlying modified pixel and Marco Random Field will tell you analytically what that relationship is.",
                    "label": 0
                },
                {
                    "sent": "We can use these things and saw we typically want to then solve for the optimal labeling or set of pixels act.",
                    "label": 0
                }
            ]
        },
        "clip_124": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So what are some approximate methods we have to solve this?",
                    "label": 0
                },
                {
                    "sent": "It's an NP hard problem.",
                    "label": 0
                },
                {
                    "sent": "Well, you can use loopy belief propagation and get.",
                    "label": 1
                },
                {
                    "sent": "You know an approximate answer for for any desired.",
                    "label": 0
                },
                {
                    "sent": "Compatibility function between neighboring patches or pixels.",
                    "label": 0
                },
                {
                    "sent": "Or you can use graph cuts, but then you have this restriction of things being submodular for.",
                    "label": 0
                },
                {
                    "sent": "In order to use the min cut Max flow algorithms and get guarantees on perfor.",
                    "label": 0
                }
            ]
        },
        "clip_125": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And so one thing we like is efficient algorithms for minimizing non submodular functions which give at the same time bounds on the quality of the solution.",
                    "label": 1
                },
                {
                    "sent": "Because we don't have that now.",
                    "label": 0
                },
                {
                    "sent": "Another thing I proposed, Marco Brandon Fields that we would like help with.",
                    "label": 0
                }
            ]
        },
        "clip_126": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is people have recently pointed out?",
                    "label": 0
                },
                {
                    "sent": "That if you use more than just these pairwise compatibility between neighboring labels but use maybe trios or higher order click compatibility's, you get much better results in the image processing.",
                    "label": 0
                },
                {
                    "sent": "So here's an example showing the better results that they're trying to labeling of this image.",
                    "label": 0
                },
                {
                    "sent": "And they have different features they use and then try to optimize the label.",
                    "label": 0
                },
                {
                    "sent": "Makes makes any given segmentation most likely, and if you use pairwise potentials you get this labeling of tree, grass, building and Sky.",
                    "label": 0
                },
                {
                    "sent": "But if you use higher order clique potentials and others higher than just second order, then you get a much richer labeling really showing the benefit of these higher order cliques in the market and fields, and these are the things that we can't.",
                    "label": 0
                }
            ]
        },
        "clip_127": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Work with as well.",
                    "label": 0
                },
                {
                    "sent": "So again, we'd like to find better ways to solve these markers.",
                    "label": 0
                },
                {
                    "sent": "Random fields with these higher order cliques and give us performance bounds.",
                    "label": 0
                },
                {
                    "sent": "Let's see, another thing was asked for.",
                    "label": 0
                },
                {
                    "sent": "Is.",
                    "label": 0
                },
                {
                    "sent": "That we often work with one of two different kinds of constraints in the market, brownfields, structural constraints, like say planarity or treewidth.",
                    "label": 1
                },
                {
                    "sent": "And also you might call them language constraints like submodularity or convexity and it be useful to have something that combines the two.",
                    "label": 0
                }
            ]
        },
        "clip_128": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here's an example of a constraint if you're.",
                    "label": 0
                },
                {
                    "sent": "Oftentimes, in image editing applications you want to put some box around something and have the algorithm automatically figure out what what you really mean when you put that box around it.",
                    "label": 0
                },
                {
                    "sent": "And so what's the constraint that gives a good hint for that?",
                    "label": 0
                },
                {
                    "sent": "Well, you didn't waste area when you put your box around the box is going to be every side is going to be close to some pixels of the thing you want pulled out within that region, so this is a.",
                    "label": 0
                },
                {
                    "sent": "A constraint on the as you call it a bounding box prior on this segmentation that you want to pull out something which has a certain consistent set of characteristics in here and you have this added constraint that that thing you're going to pull out has to be close to the bounding box edge for every one of the sides.",
                    "label": 0
                },
                {
                    "sent": "So that's an additional constraint that will help you in your image editing application, so here it doesn't meet that constraint, and you've missed the head of the baby, and here it does meet that constraint when you use that hint that actually constraint you can pull out the head.",
                    "label": 0
                }
            ]
        },
        "clip_129": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So these topological constraints are useful for mark random fields.",
                    "label": 0
                }
            ]
        },
        "clip_130": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "So then, summarizing this little section, we need help with inference in marker and fields.",
                    "label": 1
                },
                {
                    "sent": "How to handle higher order quick potentials, high dimensional safe aerials and these various constraints.",
                    "label": 1
                },
                {
                    "sent": "OK, so then.",
                    "label": 0
                },
                {
                    "sent": "Let me.",
                    "label": 0
                }
            ]
        },
        "clip_131": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Pop up with some miscellaneous problems that people ask me for.",
                    "label": 0
                }
            ]
        },
        "clip_132": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "One is compressed sensing, so compressed everyones wildbach compressed sensing.",
                    "label": 1
                },
                {
                    "sent": "Does it apply to images?",
                    "label": 0
                },
                {
                    "sent": "I'm not sure it does.",
                    "label": 0
                }
            ]
        },
        "clip_133": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This current sparsity assumptions are actually unrealistic for natural images, and is there perhaps a relaxed set of sparsity assumptions where these assumptions of compressed sensing could be?",
                    "label": 0
                },
                {
                    "sent": "Where these relaxed set of assumptions could apply, and then it could be useful for sensing images.",
                    "label": 0
                }
            ]
        },
        "clip_134": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So there could be potential photographic applications for a relaxed set of sparsely assumptions, which would actually be met by by natural images as opposed to these sort of unrealistic ones which.",
                    "label": 0
                }
            ]
        },
        "clip_135": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Natural images don't meet.",
                    "label": 0
                },
                {
                    "sent": "One thing is I talked with an issue and he said he's like our successful businessman in our field and he said, well, you know, Bill, what really matters more than anything else are datasets just having huge data set.",
                    "label": 0
                },
                {
                    "sent": "That's what wins in computer vision.",
                    "label": 0
                },
                {
                    "sent": "And so he ranked what matters for our field as one datasets 2 features matter to an three is algorithms.",
                    "label": 0
                },
                {
                    "sent": "You know, once you have a good feature in your data set, it almost doesn't matter what you use anyway.",
                    "label": 0
                },
                {
                    "sent": "We.",
                    "label": 0
                },
                {
                    "sent": "So let's look at number one.",
                    "label": 0
                },
                {
                    "sent": "We still need help handling our large noisy datasets, so we always assume that our training and test distributions are the same, but they're often not.",
                    "label": 0
                },
                {
                    "sent": "So how can we, under what circumstances can you break the assumption that the two distributions are the same?",
                    "label": 1
                },
                {
                    "sent": "What is the effect on algorithms when the IID assumption which we so often make doesn't hold and then because we have these huge datasets, you know lots and lots of images.",
                    "label": 0
                },
                {
                    "sent": "Online learning is really important, so online algorithms are critical.",
                    "label": 0
                }
            ]
        },
        "clip_136": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For us",
                    "label": 0
                }
            ]
        },
        "clip_137": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Let's see Cheyenne.",
                    "label": 0
                }
            ]
        },
        "clip_138": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "John had a really funny one.",
                    "label": 0
                }
            ]
        },
        "clip_139": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Which is he wanted to develop something called blind vision which is multi party techniques for vision algorithms.",
                    "label": 1
                },
                {
                    "sent": "So you've got person A who has just this super hot face recognition algorithm that he doesn't want to let out at all.",
                    "label": 0
                },
                {
                    "sent": "It doesn't want anyone to know about it and then person B who wants to have some great face recognition algorithm applied to.",
                    "label": 0
                },
                {
                    "sent": "This data set but doesn't want to let out any of these images 'cause they're sensitive.",
                    "label": 0
                },
                {
                    "sent": "So can these two people.",
                    "label": 0
                },
                {
                    "sent": "These two players somehow and let?",
                    "label": 0
                },
                {
                    "sent": "Alice is algorithm be run on Bobs images without either of them knowing anything about the other parties sensitive information.",
                    "label": 0
                },
                {
                    "sent": "So you could think of that as blind vision is set of protocols that would let somehow information about the faces be passed through the face detector, but yet no party know anything about the face detector or about the sensitive images.",
                    "label": 1
                }
            ]
        },
        "clip_140": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Something I want is.",
                    "label": 0
                }
            ]
        },
        "clip_141": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is.",
                    "label": 0
                },
                {
                    "sent": "In signal processing, it's just totally clear how to deal with continuous and discrete representations.",
                    "label": 0
                },
                {
                    "sent": "We have this sort of the Shannon sampling theorem if you want to do something, tells you precisely how many samples you should take.",
                    "label": 0
                },
                {
                    "sent": "And how to interpolate between them to get the exact same result you would have gotten if you played it into continuous domain.",
                    "label": 0
                },
                {
                    "sent": "We don't have that same thing with sort of these probabilistic belief propagation type algorithms.",
                    "label": 0
                },
                {
                    "sent": "How many layers should we discretize?",
                    "label": 0
                },
                {
                    "sent": "The possible set of candidate depths in a stereo image?",
                    "label": 0
                },
                {
                    "sent": "How many discrete levels should we use and how should we interpret between them to get to get the same result in a way that's independent of our digitization of scale of depth?",
                    "label": 0
                },
                {
                    "sent": "So I haven't yet seen a nice clean prescription for how to handle that discretization and how to go back and forth between continuous and discrete domains.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                }
            ]
        },
        "clip_142": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "I'd like a theory for how to optimally quantize manipulate probabilities over continuous domain.",
                    "label": 0
                }
            ]
        },
        "clip_143": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Let me skip some of these.",
                    "label": 0
                }
            ]
        },
        "clip_144": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Another person, Devil wanted an easy way to evaluate a function over power set of all possible segmentations.",
                    "label": 1
                },
                {
                    "sent": "It turns out if someone gives you a segmentation of the image everything is easy.",
                    "label": 0
                },
                {
                    "sent": "You can just interpret things really simply.",
                    "label": 0
                },
                {
                    "sent": "And if someone on the other hand, let's interpret things for you, it's easy to find the segmentation, but it's just often hard to do both and so you like some way that would evaluate all over all possible segmentation.",
                    "label": 0
                }
            ]
        },
        "clip_145": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And that you pick out the best thing.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                }
            ]
        },
        "clip_146": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And my friend.",
                    "label": 0
                }
            ]
        },
        "clip_147": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Efros said he wants some language that will help you understand, helping not confuse a having something.",
                    "label": 0
                },
                {
                    "sent": "Having a 10% similarity to a dog versus a 10% probability that it's a dog.",
                    "label": 0
                },
                {
                    "sent": "We often confound those two things in our language, and he wanted to kind of richer description of probabilistic relationships too.",
                    "label": 0
                },
                {
                    "sent": "To not confound having weak relationship with something or having an uncertain relationship about something.",
                    "label": 0
                }
            ]
        },
        "clip_148": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And then just to summarize, actually, really, we want is another breakthrough.",
                    "label": 1
                },
                {
                    "sent": "You know, we've just eaten up support vector machines, boosting, belief propagation, graph cuts.",
                    "label": 1
                },
                {
                    "sent": "We just embrace them and use them all over the place, and we're kind of ready for the next big thing.",
                    "label": 0
                }
            ]
        },
        "clip_149": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then finally, David Lowery, the person who invented features, I asked him what he thought we needed.",
                    "label": 0
                }
            ]
        },
        "clip_150": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "He said, well, you know, we could use better features.",
                    "label": 0
                },
                {
                    "sent": "That an artist can like draw the end of an elephants trunk and you know immediately what it is you know.",
                    "label": 1
                },
                {
                    "sent": "Such a rich description of just something that you can do.",
                    "label": 0
                },
                {
                    "sent": "So that's an elephants trunk.",
                    "label": 0
                },
                {
                    "sent": "We don't.",
                    "label": 1
                },
                {
                    "sent": "But none of our features capture that.",
                    "label": 0
                },
                {
                    "sent": "That richness.",
                    "label": 0
                }
            ]
        },
        "clip_151": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Let's see.",
                    "label": 0
                },
                {
                    "sent": "So I have a manuscript that kind of describes some of this and all the references.",
                    "label": 1
                },
                {
                    "sent": "Many of the references to talk about or in that manuscript is on my web page.",
                    "label": 0
                },
                {
                    "sent": "And also, I guess this talk will be available on the web.",
                    "label": 0
                }
            ]
        },
        "clip_152": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So if you are interested and want to join us, please do let me tell you a little bit about the computer vision, academic culture, computer vision got burned lots of times by people.",
                    "label": 0
                },
                {
                    "sent": "Promising results that take you from point A to point B and it turns out that you never really needed to go to point A and couldn't do anything.",
                    "label": 0
                },
                {
                    "sent": "Once you got to point B and so really we're interested in end to end systems, and it's your papers.",
                    "label": 0
                },
                {
                    "sent": "If they don't have it, offer end to end.",
                    "label": 0
                },
                {
                    "sent": "Solutions are often rejected, so it's hard to publish many if only papers, and you need to sort of end.",
                    "label": 0
                },
                {
                    "sent": "An empirical evaluation is often what it takes to get a paper into these selective conferences.",
                    "label": 0
                },
                {
                    "sent": "There's a certain overhead and coming up to speed with all the filters and representations that you want to work with.",
                    "label": 1
                },
                {
                    "sent": "The competitive conferences of 20 to 25% acceptance rate.",
                    "label": 0
                },
                {
                    "sent": "And if you don't publish in these conferences, people don't really aren't really aware of what you're doing, so you have to publish these conferences.",
                    "label": 0
                },
                {
                    "sent": "These are the competitive ones where you want to publish.",
                    "label": 0
                },
                {
                    "sent": "So the point of all this is, it's really best if you actually collaborate with someone.",
                    "label": 0
                },
                {
                    "sent": "But we know that you can help us and we're looking for help in our doors are open.",
                    "label": 1
                },
                {
                    "sent": "Let me just close with.",
                    "label": 0
                }
            ]
        },
        "clip_153": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "A mildly entertaining application of nearest neighbor finding.",
                    "label": 0
                }
            ]
        },
        "clip_154": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In high dimensions, and that's something that came out of our lab.",
                    "label": 1
                },
                {
                    "sent": "We call near infinite images.",
                    "label": 0
                },
                {
                    "sent": "So here we start with this video.",
                    "label": 0
                },
                {
                    "sent": "Now it turns out this video was all made up.",
                    "label": 0
                },
                {
                    "sent": "We just started from a single image an used Flickr Ann made it look as if we had a much bigger image.",
                    "label": 0
                },
                {
                    "sent": "I had a video that was.",
                    "label": 0
                }
            ]
        },
        "clip_155": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Around some scenes, so you start from the collection of like 6 million images from Flickr.",
                    "label": 0
                }
            ]
        },
        "clip_156": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And to get this to work without jumping from one situation to a crazy one that didn't fit with it, we first applied a preprocessing to those images from Flickr to put them into different themes.",
                    "label": 0
                },
                {
                    "sent": "So we had several 100,000 images in a Skyline theme or in landscapes theme or in a street theme, and to put them into themes we used trained in SVM based classifier from a set of labeled training examples.",
                    "label": 1
                },
                {
                    "sent": "OK, once they're in a theme we want to.",
                    "label": 0
                }
            ]
        },
        "clip_157": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Find a representation to match images in or match parts of images in an.",
                    "label": 0
                },
                {
                    "sent": "We use something very similar to the SIFT feature representation, but a different one.",
                    "label": 0
                },
                {
                    "sent": "It's called just an.",
                    "label": 0
                },
                {
                    "sent": "It's basically looks at the different orientations and different spatial scales in different regions of the image.",
                    "label": 0
                },
                {
                    "sent": "Again pooling over local spatial regions.",
                    "label": 0
                },
                {
                    "sent": "We also looked at a very low resolution, pixelated version of the image.",
                    "label": 0
                }
            ]
        },
        "clip_158": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And.",
                    "label": 0
                }
            ]
        },
        "clip_159": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here's what you want to do.",
                    "label": 0
                },
                {
                    "sent": "If you have an input image and you say OK, I want to pan my camera to the right and make up.",
                    "label": 0
                }
            ]
        },
        "clip_160": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "What would be there so, which is to say you take the right hand part of your image, put it off in the left and say I'm looking for an image in my database which has this on the left side and I don't care what's in the right side.",
                    "label": 0
                },
                {
                    "sent": "And so that would let you basically pan around and put in the appropriate images.",
                    "label": 0
                }
            ]
        },
        "clip_161": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And so here's what we found in our database, which in this representation I just told you about was the best match to this left side of the image.",
                    "label": 0
                },
                {
                    "sent": "Now we're going to work to make it fit in without.",
                    "label": 0
                }
            ]
        },
        "clip_162": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Too much of visual artifacts, so we take those two images, wiggle around over each other to find the best.",
                    "label": 0
                }
            ]
        },
        "clip_163": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Matching translation then we do dynamic programming to find the best cut between these two that would cut across the fewest image gradients too.",
                    "label": 0
                }
            ]
        },
        "clip_164": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We are the fewest cut artifacts and we use it basically integrate up from the observed gradients to come up with a so-called plus on representation, but it's.",
                    "label": 0
                },
                {
                    "sent": "This computer graphics technique designed to hide cuts between images.",
                    "label": 0
                },
                {
                    "sent": "And here's our synthesized new image starting from here, and we've made up all this extra stuff which fits.",
                    "label": 0
                },
                {
                    "sent": "You know, without too many visual artifacts for.",
                    "label": 0
                }
            ]
        },
        "clip_165": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I would go there and you can do the same thing with that was for translation.",
                    "label": 0
                },
                {
                    "sent": "You can do the same thing for rotation, so if we want to rotate from here then we're looking for an.",
                    "label": 0
                }
            ]
        },
        "clip_166": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Image which looks like that on his left side.",
                    "label": 0
                }
            ]
        },
        "clip_167": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we don't care what's on there.",
                    "label": 0
                }
            ]
        },
        "clip_168": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I hate you.",
                    "label": 0
                }
            ]
        },
        "clip_169": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Do the same trick and find out something here so you can.",
                    "label": 0
                }
            ]
        },
        "clip_170": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "These synthetic panoramas that didn't really exist anywhere but there from your Flickr data set.",
                    "label": 0
                }
            ]
        },
        "clip_171": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And so let me just close with some of these videos.",
                    "label": 0
                },
                {
                    "sent": "So here's.",
                    "label": 0
                },
                {
                    "sent": "Let's see, right?",
                    "label": 0
                },
                {
                    "sent": "You can start from famous scenes and see where you get too.",
                    "label": 0
                },
                {
                    "sent": "So here's starting from the Hollywood image.",
                    "label": 0
                }
            ]
        },
        "clip_172": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And we also made an image taxi, so you can start from one image.",
                    "label": 1
                },
                {
                    "sent": "They take start from one image.",
                    "label": 0
                },
                {
                    "sent": "Take me to another image on some path.",
                    "label": 0
                },
                {
                    "sent": "So here's we're going to end up with the desired well known image.",
                    "label": 0
                },
                {
                    "sent": "Enter image taxi.",
                    "label": 0
                },
                {
                    "sent": "Takes us back to there.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                }
            ]
        },
        "clip_173": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And you can if you want to know what's off to the right of the Windows XP screensaver.",
                    "label": 0
                },
                {
                    "sent": "You can find that out.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "And so again, this is all.",
                    "label": 0
                },
                {
                    "sent": "The result of fast nearest neighbor search through his large data set of images.",
                    "label": 0
                },
                {
                    "sent": "OK, so thank you very much.",
                    "label": 0
                }
            ]
        }
    }
}