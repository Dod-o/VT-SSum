{
    "id": "6kpy4wbivp25b3ty6bqodgtzcvwu3p7g",
    "title": "Adaptive procedures for FDR control in multiple testing",
    "info": {
        "author": [
            "Gilles Blanchard, Institut f\u00fcr Mathematik, University of Potsdam"
        ],
        "published": "Dec. 17, 2007",
        "recorded": "September 2007",
        "category": [
            "Top->Computer Science->Machine Learning->Statistical Learning"
        ]
    },
    "url": "http://videolectures.net/acs07_blanchard_apc/",
    "segmentation": [
        [
            "What I will tell you about this do with multiple testing this is.",
            "Joint work with the phosphorylate within Switzerland, in Lausanne.",
            "Oh actually now he's in a change, his filiation.",
            "He's now in India, and I Tenner account, who is in high in France?",
            "So."
        ],
        [
            "Well.",
            "The.",
            "I intend that also is a kind of overview.",
            "Talks of sorts, so I assume all of you here more or less familiar with testing in statistics.",
            "Nevertheless, I will go over the introductory part and motivator introduce the usual notation and motivate, approve multiple testing, and in particular the false discovery rate.",
            "So this notion, which has been introduced about 10 years ago, 12 years ago, and which is now becoming a kind of standard for multiple testing procedures and is widely used.",
            "In the second part I will present the sum of the.",
            "Well, someone known testing multiple testing procedures with FDR control an.",
            "Maybe present them in a kind of little unusual way that I think is a little simpler and allows two to see clearly more.",
            "Clear the results and allow some generalizations.",
            "On and so this will also motivate well in general.",
            "These so called step procedures for multiple testing, which now widely used.",
            "And finally, I will discuss about adaptive procedures, an Wellness, certain sensor.",
            "We explained that and.",
            "This would be my last spot."
        ],
        [
            "So."
        ],
        [
            "OK, so first the notation setting for statistical classical testing.",
            "So again, what is testing?",
            "I have a. I have a sample of data explained to extend.",
            "Usually they are ID, but here it's not really the point.",
            "An in in hypothesis testing we want to decide about whether hypothesis we make about the generating distribution is true or not so.",
            "This is for the moment is single testing, so I have a single hypothesis about generating distribution an from the data I must decide."
        ],
        [
            "Whether it's true or false, so the examples, classical examples of hypothesis testing, whether the mean zero weather.",
            "If I have couples of variables, whether the X&Y are independent.",
            "Weather distribution of X has a certain shape like Goshen.",
            "OK, so there are of course very many well known examples."
        ],
        [
            "And OK, the testing procedure is I take my data and then I take a decision about the hypothesis that belongs to 010 is no, I don't reject it and one is I rejected.",
            "So reject means that I think it's not true.",
            "So here maybe it's just.",
            "The first point, because maybe sometimes people are confused about the dragon of testing so.",
            "When you reject a null hypothesis, you can also call this a positive detection because it means when the new hypothesis is rejected.",
            "Basically you detected something interesting because your new hypothesis by default.",
            "What you think is by default and when it's not the case, then something interesting happens.",
            "We call this a positive detection or a discovery.",
            "So rejecting and hypothesis makes making a discovery."
        ],
        [
            "OK. And obstacles, Jeff.",
            "These two types of errors, also very classical ones, so I can make an error in both directions.",
            "Whether I declare that this is true is false so that it's rejected.",
            "So I think I made a discovery, but it's not.",
            "I tried, it's true.",
            "This is the false positive rate of type 1 error and the type where is the opposite of the dual.",
            "When I say it's true and it's, I do not reject it and it's actually false and classically statistiques you have this.",
            "Of course this introduces asymmetry so you don't control the two errors at the same at the same time, or rather than your first focus in a Type 1 error traditionally used to say I want to type 1 error, so for one single test you look at the property of type 1 error for a given test, and you want it to be less than Alpha and Alpha.",
            "Fixed so this is the classic alignment person setting.",
            "And given that the type owner is less than Alpha property of type pointer is less than Alpha, then you want to have the Type 2 error as low as possible, which is.",
            "Which is to say that you want to have your test to have a high power OK."
        ],
        [
            "So OK, some word about P values also, because that's a.",
            "That's also said that something that is very useful in multiple testing.",
            "So what are typically?",
            "What kind of decision do I take when I make a test?",
            "Well, most of the time I computed test statistic, some real function based on my data is your fix and then my decision based on zero weeks is just to say, well, I will declare that my purpose is rejected when my statistic is larger than a certain threshold.",
            "Ann is not rejected otherwise.",
            "So every time I go over the threshold for this statistic, I would say oh, I think I have.",
            "Which it's unusual.",
            "I have made a discovery.",
            "I have rejected.",
            "The output is.",
            "And the threshold T of Alpha.",
            "So here the trace will depend on the parameter Alpha, and it's precisely tuned so that if the null hypothesis is true, then the probability of this happening is less than Alpha.",
            "So it means that in that case my type 1 error will be less than Alpha OK.",
            "So this ensure the control of type 1 error rate."
        ],
        [
            "Alpha, so now what is the P value in that setting?",
            "Oh well, so it can be basically easy konbini statistiques.",
            "I'm usually you build statistic that are relevant to the hypothesis you want to test, but 4:30 called purposes.",
            "It's interesting once you have an interesting statistic so it can be, for example the empirical mean.",
            "If you want to test for the mean being greater than zero or the Z score in classical testing, when you divide the mean by the empirical variance.",
            "OK, so once you have done that, it's useful to normalize the statistics to have a unified framework.",
            "So let's consider this setting.",
            "So T is a decreasing function and let's let's consider T -- 1 of 0X.",
            "And of course, if I just apply T -- 1 here.",
            "And because it's a decreasing function, I have the property that P of X.",
            "This function is less than Alpha property that this being less than Alpha is less than Alpha.",
            "Of course, this is valid under the new hypothesis, so if HO is true, this is true and P is called the P value.",
            "P value function associated to the test.",
            "So what this means is that.",
            "If the hypothesis a zero is true, my function function pure weeks, which is also a particular statistics.",
            "It's just a normalized one.",
            "Is took a sickly lower bounded by uniform random variable and this is the important property.",
            "And so any test based on any test can be basically reduced to do a test of its P value.",
            "So this is, this is just a normalizing device.",
            "And, uh, OK."
        ],
        [
            "So most of the time we talk about tests will assume that they are based on the P values of certain P value.",
            "OK, So what now multiple testing so multiple testing is very important in for the treatment of large dimensional data and for lot of recent applications so traditional statistics I had to test one hypothesis and then maybe I want to test some many hypothesis at the same time so.",
            "This can be a procedure, large number of hypothesis that we want to test simultaneously."
        ],
        [
            "So here are some example applications so.",
            "I have a solution I want to detect the presence of some chemical compounds and I have a lot of them to test 4.",
            "So for each of them there is a test and then when I test all of them then I can make.",
            "I can make many errors possibly.",
            "So I want to test that all together and have an idea of the."
        ],
        [
            "Or I make another situation words well.",
            "Typical situation where we're testing is used is affordable in F, MRI, F, MRI, image and.",
            "So here you want to detect zones of activity and basically for each pixel of the image you can perform a test.",
            "To test whether it's significantly higher, the activation level is significantly higher than normal.",
            "And of course you have in principle to have to perform a hypothesis for each separate pixel, so that's a lot."
        ],
        [
            "In a. Microarray data.",
            "It's the same similar problem you can.",
            "You can have a microwave with a lot of jeans that are tested for several individuals in two different experimental conditions.",
            "You want to know which genes are differentially expressed in two experimental conditions and you have the choice when you have to test a lot of genes, possibly 10s of thousands to at the same time.",
            "So these are numerous applications where multiple testing is routinely used."
        ],
        [
            "And then also another example is when you have a regression problem and I want to test which regressors are have a dependent so significant dependence relationship with the output I want to predict.",
            "OK so these are all the classical examples and there are of course many other."
        ],
        [
            "It's just too imprecise itself.",
            "It's an important problem, especially in bioinformatic, San 4.",
            "For large large datasets.",
            "OK, so here's the setting for multiple testing.",
            "I assume that I have now a set of of null hypothesis.",
            "It's H, so it's a whole set of possible hypothesis.",
            "So maybe just to fix ideas.",
            "If you think of a set of hypothesis, you can think of a very large vector.",
            "And I want each hypothesis whether the one coordinates has mean different from zero and for each coordinate I have a separate hypothesis.",
            "So this is a typical setting, for example 5 MRI an.",
            "And microarray so you can keep that in mind.",
            "So there is a subset H zero, which are the set of truly hypothesis that are really satisfied by my data generating distribution.",
            "And of course a Geo is unknown.",
            "Of course I would not have to do anything, so I would like to have obtain as much information I can about a zero and in general and the people testing procedures takes the data.",
            "An output the set a subset of H which is the set of rejected hypothesis.",
            "So for each separate hypothesis I take a decision and I can sum up this by saying I'm just rejecting a subset.",
            "So this is a random subset."
        ],
        [
            "Depending on the data.",
            "OK, now what?",
            "What is the problem in multiple testing?",
            "Well usually it's about error control.",
            "So how do I control the error when I repeatedly do many tests and each of them is likely to make a small probability of making an error?",
            "So usually to concentrate on this problem, I assume we assume that for each separate hypothesis, we already have a test available.",
            "Maybe from some previous work, or maybe it's a classical test like AZ score test or something like this.",
            "So for each separate hypothesis.",
            "HI assume that I have a certain testing procedure TH with a P value function pH and OK that's known.",
            "I know the problem is that now that I have all these family of tests or P value.",
            "These people family.",
            "How do I construct?",
            "Meaningfully are multiple testing procedures based on that.",
            "And so, since I want generally want that to be based on the P values, I mean the the functional relationship will between the data and rejected set will be that my rejected set will actually depend just on the P values.",
            "So from the data as compute the P values there is 1 value for each hypothesis and from the set of P values somehow I compute my set of rejected hypothesis.",
            "So it will be."
        ],
        [
            "A function of P. Now the question is how do I measure the error I make?",
            "So of course there is a risk of error for each separate hypothesis and.",
            "So I mean I want to sum up the error.",
            "I'm making one single number to assist the quality, so there are of course many ways to sum up all these errors in one single number, and maybe the most traditional one and.",
            "Well, original, sorry.",
            "All the other one is the familywise error rate.",
            "Which is the probability that my rejected set contains at least a true null hypothesis.",
            "So if I make every time I make any error anywhere, any type 1 error, then here I say OK I made an error.",
            "So this is a very strict procedure, especially criterion, especially if I have a lot of hypothesis to test, it means I won't allow any Type 1 error anywhere.",
            "So this this can be useful sometimes.",
            "I mean sometimes I don't want to perform to have any error, but people have been complaining that maybe it's too strict because it's it will reduce the power a lot because it's."
        ],
        [
            "Strict, so this is where.",
            "Minion, minion hard work introduced these celebrated false discovery rate in 95.",
            "Which is another measure of type 1 error, which is more.",
            "Lenient and it's just the expected, so it's expected expectation over the drawer of the data.",
            "Of the proportion of errors I make in the in the hypothesis, I have rejected so it is the ratio of the intersection.",
            "Well, this is the cardinality of the intersection of rejected and new hypothesis.",
            "Divided by the quantity of rejected hypothesis.",
            "So why does it make sense?"
        ],
        [
            "So for this we are it makes sense in particular for screening processes so.",
            "Typically the examples I gave for chemical compounds or maybe microarrays, data microarray data, types of screening processes.",
            "So I have a lot of candidate objects.",
            "We can be this chemical compounds or jeans an and then I want to find among the subjects, some candidates that are interesting and I have a whole huge choice and I want to narrow my choice significantly and then maybe I will.",
            "Devote some more resource to studying the ones I deem interesting candidates.",
            "So this is, this is what I have here.",
            "So it means that if I if I in the screening process, if I use a testing procedure to detect.",
            "So to make these discoveries to detect which genes, for example, are interesting, if I make a few errors in my set of objectives, jeans.",
            "So I have a small proportion of jeans that are actually not significantly differentially expressed.",
            "Among my rejected one I'm it's not too bad because then I will devote my resource to my my set of candidates and OK, so some of them will turn out not to be interesting after all, but not such a big proportion.",
            "So in this case it's really relevant to look at this FDR criterion to assess the quality of my testing procedure.",
            "And OK, there's all these situations where we can defend the FDR as a meaningful measure, and so here in this talk I will really concentrate on this on controlling this measure of error.",
            "And again their situation where it's not appropriate.",
            "But there are many situations where these are now, as I explained earlier, it's really becoming like a standard way of controlling the error in many scientific papers you have people.",
            "Researchers precise that they are statistical errors are FDR corrected, and so it's it's really become."
        ],
        [
            "Standard.",
            "OK, so now I will.",
            "Talk about this.",
            "How you build procedures with FDR control?"
        ],
        [
            "OK, so we start with the kind of motivation.",
            "Heuristic motivation.",
            "So let's assume touristically that we would know a priori that the set of rejected hypothesis is more than certain K fix.",
            "OK, let's assume that for a moment.",
            "So what can we say about the FDR being less than Alpha?",
            "Well, if I reject a hypothesis, I would say well, giving the DVR is the proportion of errors I can afford up to Alpha errors on average.",
            "If I make up to Alpha cat errors on average and my FDR is less than Alpha, OK?",
            "So what's the number of at all?",
            "So here I consider.",
            "How do I use the P values to define to define a rejected set while the.",
            "Based on what I said earlier that you reject a single test when the statistic is higher than a certain threshold.",
            "Usually we consider also multiple rejection where we reject procedures where R is made of all the hypothesis such that the P value is less than a certain threshold T. OK, so let's consider a procedure of this form for certainty, which is the number of errors I commit.",
            "Well, I make an error for every age that is true.",
            "And for which this is, this happens nevertheless.",
            "So for any edge which is true, I have this probability.",
            "I know this is bounded.",
            "This probability is bounded by T by definition, because for true hypothesis this this is stochastically lower bounded by a uniform variable.",
            "So this is less than the quality of H0T, and for now I say, well agency, I don't know, but I know at least that it's less than the Canadian H * T. OK, very simple.",
            "And so if I want this to be less than Alpha.",
            "Sorry, then Alpha K. Then they can just choose T equals Alpha K over the cardinality of H, and then I'm done.",
            "I have FDR control.",
            "OK, so."
        ],
        [
            "Of course.",
            "This is based on this assumption which I don't know why you would know that priore.",
            "But OK, still still being juristic I can say.",
            "Well now assume that I have some rejection procedure and I observed after the fact after a post hoc that my.",
            "My my size, my size of rejection has a certain well observed the size of rejected hypothesis.",
            "So I can say well, if I had known that that in advance I could have plug that in here and have this control here.",
            "So of course this doesn't make much sense for logical point of view, but this is against it's just a motivation.",
            "So I could say post hoc.",
            "Well I would like I would like to say that my procedure will be kind of reasonable if after the fact I notice that my set of rejected hypothesis is included in this set, I would have rejected if I had known in advance the cardinality.",
            "And so I generalized this condition.",
            "How to say I call this self consistency condition to say my set of rejected hypothesis is included in the set of hypothesis such that the P value is less than Alpha times beta of the cardinality of our.",
            "So here the only difference that introduced a function beta which I don't precise for now.",
            "And I call this the self consistency condition for the function beta.",
            "I called beta shape function.",
            "OK, so this is just a motivation for this condition and now we show that if this condition is satisfied.",
            "Then actually my wealth and certain assumptions.",
            "Then my FDR will be actual."
        ],
        [
            "Controlled.",
            "And it's really very simple, so here here it is basically.",
            "So this is my FDR.",
            "It's the ratio of rejected errors.",
            "Divided by rejected.",
            "So this I can decompose by summing over all all hypothesis that are true for each hypothesis is true.",
            "I count 1 if it's in the it's rejected set which means one error and 0 otherwise.",
            "So for some overage zero of the expected value of the indicator of age belongs to R / R. This is an equality.",
            "And then here use myself consistency condition saying well if H is in R. Well, I know that R is contained in the set of hypothesis satisfying this, so it means that H will satisfy this condition.",
            "H will be such that pH is less than Alpha beta var.",
            "Using the my condition, my previous condition OK. Now what I'm saying is that if I can prove that this quantity here this term.",
            "Is less than.",
            "Is less than Alpha.",
            "So let's say.",
            "Lisa, yeah it's less than Alpha divided by H then by summing will just have H. Well actually H 0 times Alpha divided by H and this will be less than Alpha.",
            "So now with this very simple observation, I'm just reduced in a sense, if I want sufficient condition to controlling this quantity for any fixed H. And this can be, well, abstractly put, under the simple form that now I have two random variables, so one is pH.",
            "So I call you it's you here, it's bounded, it's it's stochastically lower bounded by a uniform variable.",
            "Because I mean it's in edge 0.",
            "And then another variable V which is here the cardinality of the rejected set.",
            "And so if I can prove something like.",
            "This probability can equality on 2 random variables U and V2 real random variables.",
            "So it's kind of very simple relation.",
            "And basically I'm done, I control.",
            "OK, so when is this satisfied?",
            "For you and me so."
        ],
        [
            "Here are three classical cases, so the first case is when we have independent aesthetics, which is a commonly considered case in multiple testing.",
            "So here assume that all my P values are independent.",
            "So in that case.",
            "Remember, I'm interested in a.",
            "This expectation.",
            "So here I say I'm saying that it will be.",
            "I can use beta of X is just a linear function.",
            "And divided by R. So this is sorry this is R. No, what can I do to use the hypothesis that I have independent aesthetics where I can condition with respect to all the other pH?",
            "So here it's concerns just pH are depends on all the other P values of course, but I can say well this condition with respect to all others and see what happens.",
            "So this P -- H is all P values except the one I'm interested in.",
            "So what's happening now?",
            "Well, if the orders are fixed, though, because they are independent, pH is still lower bounded by a stochastically stochastically, sarcastically bound lower bound by uniform random variable.",
            "Because conditioning doesn't change that.",
            "But then what is our well now conditionally to these ones?",
            "Are is just a function R of PRPH, so it's not really random variable because it just depends on the last remaining valuable.",
            "And then if I assume that R is a nondecreasing function.",
            "Now they just reduced to proving that indicator of U less than G or V. Sorry.",
            "This then geoview.",
            "So CCGFUC is a constant.",
            "Divided by geoview.",
            "Is less than C. Well, GG here it's a decreasing function.",
            "So I can leave that to you as an exercise.",
            "It's very simple, so this is true when G is a decreasing function.",
            "So why it is decreasing function thing?",
            "Well, this is actually another hypothesis, but it's a very natural hypothesis because I just assume that if I if my P values become lower, I will reject more an appeal with our lower means that really I have more evidence against one given hypothesis.",
            "So it's really natural to assume that my rejection.",
            "Procedure is an increasing sorry decreasing function as a function of the P values.",
            "So this is really not restrictive.",
            "So in the case of independency it's very simple so used to that claim and then it's true and then my idea is controlled with this linear function."
        ],
        [
            "So here's another case.",
            "So I would relate these two known results later, but when the when the peers are pretty positively dependent in a certain sense introduced by Benjamini and equity in 2001?",
            "It's also satisfied with the same beta function and so basically what these changes here.",
            "Is that?",
            "I cannot condition, but I can say that instead of being a function of you now.",
            "Are witches takes the role of V is a function which is stochastically decreasing in you.",
            "So basically it's a generalization of that which.",
            "Is also a stochastic probability lemma, but just two to two variables with a certain type of dependent, so it's also relatively simple."
        ],
        [
            "And then here is 1/3 case.",
            "It's when I want.",
            "I don't want to assume anything, so I don't want to assume any kind of knowledge about the dependence on the P values.",
            "And then it turns out that the relation is also satisfied if I take a beta of this form, so it's so this is normally normalizing factor 1 / H and its integral from zero to X or feuding.",
            "You a fewer new is any arbitrary property measure, so I can choose my any any new I have to choose it before I do my experiment of course.",
            "And I will comment on that a little later.",
            "And in all of these cases, because I have this control.",
            "Very simple privacy control.",
            "It implies that provided I satisfy the self consistency condition with function beta and the time decreasing the P values.",
            "Then it's true that any any are satisfying these two conditions will have this FDR control.",
            "Oh yeah.",
            "It seems that you have less assumptions.",
            "Yes, I have less assumptions.",
            "Well.",
            "Yeah, yes.",
            "Yes.",
            "Then you get.",
            "Well no, I get to keratic function.",
            "Yeah, yeah, I get something different.",
            "I will I will.",
            "I will give a little more details about this data functioning."
        ],
        [
            "You know in a moment.",
            "So first I introduce separate procedures, so OK, so here's my self consistency condition.",
            "So now we can do with that.",
            "Well, I can say, well, I know that given this condition my my my FDR is control and now I want to have high power to have high power.",
            "I want to reject as much as I can, given that I'm still satisfying this condition.",
            "So we can ask which is the largest set that I can reject.",
            "Given this is satisfied, and if you look at at what what you so you can take the maximum rejection set that satisfy this hypothesis.",
            "And then it's not difficult to see that this is equivalent to this to a so called step procedure.",
            "So what is a separate procedure?",
            "So here's the recipe for it an so I have my P values.",
            "For each hypothesis, I order them in increasing order.",
            "Then I take the largest K such that the P value of rank I the largest.",
            "I such at the pier Frank I is less than Alpha beta of I.",
            "So the maximum number and then so that you know these K hat and then I reject all hypothesis from H. Well, the order hypothesis for H128K Hut OK and you can check it's also not difficult to check that this is equivalent to saying that I take the largest set satisfying this."
        ],
        [
            "So what does this correspond to?",
            "So this is the.",
            "Kind of cartoon of P values, so of course there are general discrete, but let's say that, so this is my sorted P values and increasing function and then I have my shade shape function beta VIX.",
            "And as soon as well if I'm below I reject, reject, reject and then the last crossing point here is the maximum such that I'm still below and then I reject all hypothesis from here to here.",
            "So you see here I'm still above, but it doesn't matter because then I am below and here I can reject that.",
            "So this is called a step procedure.",
            "So for any beta function satisfying well under the different hypothesis I've told about before.",
            "This step procedure is maximizing the the size of the redacted.",
            "I posted this and I still have my FDR control at level Alpha."
        ],
        [
            "OK, so in the case of a linear function.",
            "These two first cases.",
            "This reduces to the well known procedure of Benjamin Hodge.",
            "Begin producing in 95."
        ],
        [
            "Paper, which is the.",
            "The linear step procedure and this is.",
            "Maybe the most standard procedure, so he merely I just retrieved this classical classical result, but I think this is a well.",
            "Usually this is not presented this way, so I really think this way is is.",
            "Is really simple than the original 1 to present things so anyway, so we achieve the classical step procedure and in the case of unspecified dependencies.",
            "So again, I have to choose beta of this form and I have to choose new and actually we can see that new kind of plays a role of a prior prior prior in a Bayesian sense about the size of the rejected hypothesis.",
            "So I will present some graphs in the next slides tournament.",
            "This means by the way, it's can be proved that it's.",
            "If you don't want to specify the dependencies, then it's necessary to lose a little so this bit of X, whatever new.",
            "It's always lower than the linear one, then X / H. So you lose something because your beta function is a.",
            "Here, if it's lower, of course you reject less.",
            "So what you lose the price to pay for and specify dependencies reside in that you have a lower beta function, But then you can still at least choose your new.",
            "And if you have a precise idea of approximately how, what is the percentage of hypothesis you will reject, you expect to be rejected and you can use that in this prior.",
            "To still have a reasonable power."
        ],
        [
            "In the case of special case of New Avize is proportional to the inverse of I.",
            "So this particular prior then beta is linear because it cancels out here, so it's again a linear step up, except the slope is lower than the slope for the standard LSU.",
            "So because I'm in the case of an specify dependencies, I lose a little in the slope, and again this recovers a result of Benjamin acquitted in 2001.",
            "But with this presentation, of course I can say I can.",
            "I can choose any arbitrary new, and this gives me more more."
        ],
        [
            "She.",
            "So here are some examples.",
            "Of the shape function you obtained by choosing different news so.",
            "Here we have Delta Direct functions, which means that I hope I know exactly that my rejected set will have a certain size, so this is compatible with my my you Ristic approach, where newer priority that.",
            "I would I would have rejected Kaopua thesis, so in this case I see that well, the shape function is a step function.",
            "Precise, yet the value in question.",
            "And so if I don't reject, so if I'm if I'm wrong, if I if the set of rejected hypothesis would be below, then I'm losing completely the power because I won't reject anything.",
            "But if I'm if I'm right and in that region then well here I see that I in this point I coincide with this linear step procedure, so this is the line for the independent case.",
            "The linear step procedure.",
            "So this is the one I obtained under the.",
            "The strong hypo assumption that my P values are independent.",
            "OK, so there are variations on this.",
            "I can look at the shape functions obtained for Goshen priors with some spread about the certain value.",
            "These are power priors for different powers, so.",
            "Here for power minus one, retrieve the other step up newspaper procedure.",
            "So we see that here this is the one without correction and this is the one with the beta correction.",
            "So the slope is lower.",
            "I lose a function.",
            "Logarithm of the cardinality, which is Southern here.",
            "And these are exponential priors, so I think the exponential priors may be interesting because so here in purple I have the corrected linear one, so the one which the correction for the fact that I don't assume anything on the dependence.",
            "And I can see that if for example for some settings in in this red or green curve here I'm mostly above the linear one.",
            "So I'm of course I cannot be above everywhere, so it means here I will lose in the initial section, but then I will be significantly above in after that.",
            "Which means if I expect, for example in this case to reject at least 50 hypothesis, which is like which is just 5% here.",
            "Then I I should better choose an exponential prior because then I will have a higher beta function which will result in larger number of rejected hypothesis so.",
            "If I'm really concerned about this dependent thing, then I choosing the priority in a good way is a is an interesting way of what can lead to improved power."
        ],
        [
            "OK, so now we'll talk about."
        ],
        [
            "Adaptive procedures, So what does it mean?",
            "Adaptive?",
            "So it's adaptive in a very specific sensor that default to this parameter by zero, which is the proportion of.",
            "True new hypothesis.",
            "So if you look back at the proof of the FDR in all of these cases, what we have proved actually is that the FDR of all these step procedures.",
            "Was bounded by, not by Alphabet by \u03c0 Zero Times Alpha.",
            "\u03a0 Zero is the proportion of new hypothesis, so of course I don't know this proportion is bounded by one, so in the worst case it's just Alpha.",
            "But if it turns out that I don't have, I don't have such a large number of null hypothesis, then maybe I can gain a little more.",
            "And this this way has also be explored by Benjamini, so the.",
            "I always quoting said citing Menomini because since he has started this field he's made a lot of papers on different areas related to that sort.",
            "Of course I'm always referring to.",
            "To him between others.",
            "So if I knew \u03c0 zero, my ideal beta will be just to correct and introduce a factor.",
            "Paso minus one.",
            "Then I would exactly.",
            "Control."
        ],
        [
            "Aviat level Alpha.",
            "In general, of course, Pacer is unknown, and then how can I address this?",
            "Well, here I can have two two ways.",
            "I can try to estimate by zero, or rather to submit by 0 -- 1 because that's why I'm interested.",
            "What I'm interested in here and then use this estimator, plug it in here instead of the true \u03c0 zero and expect.",
            "Hope it works.",
            "All I can use so this is called kind of two step procedure because I first estimate by zero and then I plug it into my function.",
            "My shape function beta or I tried to try to find a function beta.",
            "So that in some sense, so it's just a regular step procedure with a different function beta.",
            "Which is some sense already.",
            "Adaptive two by zero?",
            "And.",
            "So of course, what they expect in some intuitive sense is the more reject hypothesis.",
            "The more I think that actually pay 0 is little because if I reject a lot of hypothesis, I assume that most of them are actually really not true.",
            "So the set of of candidate, new libraries, strings, and so the more I reject once again, the more I reject, the more I expect to be able to reject so.",
            "This should be a."
        ],
        [
            "This should be.",
            "This is the general idea.",
            "So here are two previously known procedures.",
            "The first one is called so that.",
            "The two of them of the first type.",
            "So two state procedures, two stage.",
            "The first one is called story stories.",
            "Procedure is based on rejecting without correction.",
            "And so we reject the hypothesis without correction on that based on the stressful Lambda.",
            "And based on that you estimate natural way the proportion of new hypothesis.",
            "And the procedure of Benjamin Equigen equally, that in an article of 2006 is a two stage procedure, also with an estimation of \u03c0 zero, where with this estimator.",
            "So if you look at that, what this is is that the 1st.",
            "Perform the regular linear step procedure.",
            "So the classical one they look at the number of rejected algorithms and they say, oh, let's estimate by zero.",
            "So the inverse of that.",
            "By H -- R Zero over H2, N minus zero is the remaining number of hypothesis, so that I assume are actually true.",
            "And divided by H and then there is a correction factor to take into account that in my set of rejected hypothesis.",
            "Actually I have some of them that I expect to be to be actually true.",
            "So here it's kind of makes reasonable sense to estimate by 0 -- 1 by this quantity.",
            "And then again, I plug these all that into again into my my linear stepper procedure.",
            "What is shown where they showed in 2006 that both of these procedures actually correct in the sense that FDR is still controlled at level Alpha when I plug in this scimitar?",
            "Under the independence of.",
            "Under the hypothesis of independence of the test."
        ],
        [
            "Hi this statistiques so here we present.",
            "And you are one stage and two stage adaptive procedures, so this is a procedure of the second type.",
            "Or directly we have a function beta.",
            "So here we just.",
            "Have a regular step step up procedure whether the shape function beta takes this form.",
            "And basically it's it's a little like you have directly integrated in the function.",
            "The the estimation of the current rejection.",
            "So for fixed X, we retrieve these eight or up to this plus one.",
            "Here we retrieve this H -- X.",
            "Uh.",
            "OK somehow OK, I'm trying to justify intuitively, but it's maybe it's not completely intuitive, but at least I see that once again the more reject and the more I my beta function is a.",
            "Is different from the linear one I will draw it in the next slide.",
            "And again, and the the hypothesis of the assumption of independent statistics test statistics, it is true that the stepper procedure 1 one stage procedures based on R has FDR control."
        ],
        [
            "Alpha, so here.",
            "Here's what it looks like this function.",
            "So this is the regular one.",
            "The one you use when you assume that the test seeker independent is linear stable procedure, and this is the the other one.",
            "So you see them or reject the more it's above an OK.",
            "So here there is a cap.",
            "For technical reasons, but this proof is.",
            "It's almost always better than the regular linear one because you have a higher threshold.",
            "I say almost always, because here is below because of this technical thing.",
            "And here at the beginning is also slightly below.",
            "So apart from this, marginal cases is first of all, it's always better than the regular, you know, step up."
        ],
        [
            "And then there is more we can use actually transform that into a two or two stage procedure by saying, well, let's use that to estimate by zero again and then now put it in a two stage procedure.",
            "So here we do exactly what was proposing benyamini.",
            "Who go on you quit early?",
            "So they were estimating this this by zero using the regular linear step procedure that we do the same, except here we use instead our procedure the previous one."
        ],
        [
            "The one with this so they were using.",
            "This procedure and now we're using this."
        ],
        [
            "So will gain more, hopefully.",
            "Because it's so sharp?",
            "Or is it underestimates less by 0 -- 1?",
            "And then again, under the hypothesis of independence on the 36, and it's still valid at this two stage procedure.",
            "Now is bounded by Alpha OK. And then up to this, this marginal things like the plus one and this is 2 dimensional cases where it was less good and then it's all actually.",
            "From a theoretical point of view, it will always be more powerful that this this procedure of benyamini chronically."
        ],
        [
            "So here are some simulations to demonstrate what happens, so these are sense very limited.",
            "This is a framework that they used in their paper 2006, so you have just normal variables which have 00 mean or mean M, so that just two means.",
            "And the covariance of two variables is constant is sumrow, so you have all your.",
            "All your valuables share common two different, any two different rivals.",
            "So common covariance so far equals zero is independent, and then for roll greater than zero is a positive dependent case.",
            "Only perform 1 sided tests for.",
            "The mean being less than 0.",
            "And they are.",
            "I think it should be 1000 hypothesis.",
            "I forgot zero and M equals OK."
        ],
        [
            "OK, so here what do we have?",
            "So this is the power compared to the Oracle procedures or the Oracle procedures.",
            "Is the LSU when you know already exactly the value of P0, so you can really plug in the true value of \u03c0 zero.",
            "So, and this is the power compared to that so.",
            "Here we have story 1/2.",
            "Here we have.",
            "This is our one stage procedure.",
            "This is our two stage procedure involved.",
            "And procedure of Benjamin equally is here in dashed.",
            "So we see that here we see that we are always better.",
            "We have a higher power than the procedure of Mini Cooper Nuccetelli 06.",
            "The one the other T one stages is doing worse in the first part, and so the fact that you were using that the two stages correcting for that and then we are better.",
            "But of course here we notice there nevertheless than that story 1/2 is still better.",
            "So we can say, what's the point?",
            "So they argued in this paper of 2000 or 6, then stories.",
            "1/2 story.",
            "1/2 is a very good when you actually have independent hypothesis.",
            "But what you use it in a situation more reasonable situation where you have dependent."
        ],
        [
            "If it is this, then it's starts not behaving at all like you want, so it's here.",
            "And this is the FDR.",
            "And unfortunately, story 1/2.",
            "Is really totally never when you start to have positive correlations, so totally so the FBI is not controlled at all, so it's it's really not not you want, not at all what you want to happen.",
            "These are all still our methods, so once again we are our two stage method is is in bold.",
            "And we are here.",
            "Well so slightly above in terms of Eddy are closer to the nominal expected the nominal level you would like to have, which is .05.",
            "So of course, in this setting the theoretical guarantees we have do not apply because it's not independent, so we're just observing what happens if we are outside of our theoretical setting.",
            "And it seems our procedure is still reasonably close to two point.",
            "Two 0.05 and we are still doing better than the Big Y 06.",
            "In passing to be completely honest, I must say that if I.",
            "If I use story with another parameter, so sorry, 1/2 seems to be some kind of standard that people use a lot, but here we try also.",
            "Sorry Alpha divided by 1 minus Alpha because it's somehow compareable theoretically to the other settings and then it performed much better than so in half so it's here so it's still slightly.",
            "It goes above the nominal level, but it seems like something like that was notice before.",
            "So maybe after all maybe stories.",
            "OK, if you choose the right level.",
            "So this is of course all simulations and.",
            "Some more spec."
        ],
        [
            "Even of course, it would be interesting to have a more theoretical results to support these these observations.",
            "I know we go shortly about this, so this is also an effort we make made to try to have an adaptive procedures in the case where you don't want to assume anything on the.",
            "On independence.",
            "So you have to understand that in the dependent case, one key argument in the proof is just to say that because you're independent, the estimation of \u03c0 zero cannot be too much wrong, because it's based on independent trials.",
            "So if you test each hypothesis independently, you will in average your estimation by looking at how much are rejected will not be too far away from my zero.",
            "There is a kind of concentration effect because of independence.",
            "So now if you don't assume anything, well, we've seen all."
        ],
        [
            "That 4 three 1/2.",
            "It can completely go wrong."
        ],
        [
            "So more formally, surgical point of view we try to nevertheless have a device to treat that case, and it's based on.",
            "Much more.",
            "Rough arguments, namely net case markups inequality, so it's obviously we have a less of an improvement, but nevertheless we can prove that if you estimate so once again here we first perform the regular step procedure R0 and we take.",
            "This estimation of \u03c0 zero, which is rather an underestimation of another estimate and underestimation of by 0 -- 1.",
            "I'm sorry it should be a minimum of this and one.",
            "Sorry, a maximum of this, and one because it's the inverse.",
            "And here, because we do it on a 2 step procedure and we want to control each step separately, we also have to introduce to cut the level by four in the first step and between the second step.",
            "So it means.",
            "I don't think this procedure is really practically advisable, although we can show that in some specific cases you can have an improvement in particular, so this will give that significant improvement.",
            "If you can reject in the first step already a significant amount of hypothesis.",
            "So if \u03c0 zero is really small and you can a lot of hypothesis are easy to reject, so typically more than 6060%.",
            "Then you will we end.",
            "We will gain in the level.",
            "OK, so maybe this is a little marginal, but our point here was just to say that in principle, even the.",
            "Unspecified dependence case, we can also at least.",
            "Try to have something that is adaptive, two by zero and can, at least in principle improve the improve the power.",
            "On a 2 all knowledge, this is the first try in this direction, so there's no no result at all.",
            "No other result under unspecified dependencies."
        ],
        [
            "For adaptive procedures.",
            "OK, so to conclude, well, OK, so the first part of my talk was presenting these classical FDR step procedures with this kind of set output point of view using these self consistency condition, which I think is a kind of novel POV which gives very simple proofs and also allow us to introduce this added flexibility with this beta function in the case of unspecified dependencies and anything that was notice before.",
            "And then presented a new one stage and two stage adaptive procedure.",
            "Which one stage improves over the standard linear step up the two stages that improves over the procedure.",
            "Benyamini Crogan acquitted in the Tostada no 6 paper.",
            "An then specify dependency case.",
            "While we demonstrated at least 30 three the 1st first procedure that that can for which you can prove that the FBI is still control at level Alpha and is somehow adaptive.",
            "Two by zero.",
            "And of course, well, it's just a burgeoning field.",
            "I mean they are.",
            "If you look at the literature on this area just a lot of papers in the last few years in all direction, practical, theoretical and there are a lot of open issues so.",
            "They are difficult to list them all.",
            "Here is a few one I'm interested in respect to.",
            "This talk is have a better adaptive procedures, and in particular the case of unspecified dependency case.",
            "I'm particularly interested in the unspecified dependency case because they come from learning theory and.",
            "You can show that in this case it's it's related to some some results in learning theory, where typically you want to control an error of a large number of objects, and you don't assume any.",
            "And you knowledge about the kind of dependence they have a query.",
            "Then maybe exploring some of the role of this new shape prior on the and see if we can gain really significantly with respect to the default setting using the fact that we have some flexibility in this shape prior.",
            "And also related that this may be related to the first point is robustness or non robustness properties of these symmetries when you.",
            "You you go a little away from the independence assumption.",
            "So maybe it's just a different point of view on the first point.",
            "OK, thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "What I will tell you about this do with multiple testing this is.",
                    "label": 0
                },
                {
                    "sent": "Joint work with the phosphorylate within Switzerland, in Lausanne.",
                    "label": 0
                },
                {
                    "sent": "Oh actually now he's in a change, his filiation.",
                    "label": 0
                },
                {
                    "sent": "He's now in India, and I Tenner account, who is in high in France?",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Well.",
                    "label": 0
                },
                {
                    "sent": "The.",
                    "label": 0
                },
                {
                    "sent": "I intend that also is a kind of overview.",
                    "label": 0
                },
                {
                    "sent": "Talks of sorts, so I assume all of you here more or less familiar with testing in statistics.",
                    "label": 0
                },
                {
                    "sent": "Nevertheless, I will go over the introductory part and motivator introduce the usual notation and motivate, approve multiple testing, and in particular the false discovery rate.",
                    "label": 1
                },
                {
                    "sent": "So this notion, which has been introduced about 10 years ago, 12 years ago, and which is now becoming a kind of standard for multiple testing procedures and is widely used.",
                    "label": 0
                },
                {
                    "sent": "In the second part I will present the sum of the.",
                    "label": 1
                },
                {
                    "sent": "Well, someone known testing multiple testing procedures with FDR control an.",
                    "label": 0
                },
                {
                    "sent": "Maybe present them in a kind of little unusual way that I think is a little simpler and allows two to see clearly more.",
                    "label": 0
                },
                {
                    "sent": "Clear the results and allow some generalizations.",
                    "label": 0
                },
                {
                    "sent": "On and so this will also motivate well in general.",
                    "label": 0
                },
                {
                    "sent": "These so called step procedures for multiple testing, which now widely used.",
                    "label": 0
                },
                {
                    "sent": "And finally, I will discuss about adaptive procedures, an Wellness, certain sensor.",
                    "label": 0
                },
                {
                    "sent": "We explained that and.",
                    "label": 0
                },
                {
                    "sent": "This would be my last spot.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so first the notation setting for statistical classical testing.",
                    "label": 0
                },
                {
                    "sent": "So again, what is testing?",
                    "label": 0
                },
                {
                    "sent": "I have a. I have a sample of data explained to extend.",
                    "label": 0
                },
                {
                    "sent": "Usually they are ID, but here it's not really the point.",
                    "label": 0
                },
                {
                    "sent": "An in in hypothesis testing we want to decide about whether hypothesis we make about the generating distribution is true or not so.",
                    "label": 1
                },
                {
                    "sent": "This is for the moment is single testing, so I have a single hypothesis about generating distribution an from the data I must decide.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Whether it's true or false, so the examples, classical examples of hypothesis testing, whether the mean zero weather.",
                    "label": 1
                },
                {
                    "sent": "If I have couples of variables, whether the X&Y are independent.",
                    "label": 0
                },
                {
                    "sent": "Weather distribution of X has a certain shape like Goshen.",
                    "label": 1
                },
                {
                    "sent": "OK, so there are of course very many well known examples.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And OK, the testing procedure is I take my data and then I take a decision about the hypothesis that belongs to 010 is no, I don't reject it and one is I rejected.",
                    "label": 0
                },
                {
                    "sent": "So reject means that I think it's not true.",
                    "label": 0
                },
                {
                    "sent": "So here maybe it's just.",
                    "label": 0
                },
                {
                    "sent": "The first point, because maybe sometimes people are confused about the dragon of testing so.",
                    "label": 0
                },
                {
                    "sent": "When you reject a null hypothesis, you can also call this a positive detection because it means when the new hypothesis is rejected.",
                    "label": 1
                },
                {
                    "sent": "Basically you detected something interesting because your new hypothesis by default.",
                    "label": 0
                },
                {
                    "sent": "What you think is by default and when it's not the case, then something interesting happens.",
                    "label": 1
                },
                {
                    "sent": "We call this a positive detection or a discovery.",
                    "label": 0
                },
                {
                    "sent": "So rejecting and hypothesis makes making a discovery.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK. And obstacles, Jeff.",
                    "label": 0
                },
                {
                    "sent": "These two types of errors, also very classical ones, so I can make an error in both directions.",
                    "label": 0
                },
                {
                    "sent": "Whether I declare that this is true is false so that it's rejected.",
                    "label": 0
                },
                {
                    "sent": "So I think I made a discovery, but it's not.",
                    "label": 0
                },
                {
                    "sent": "I tried, it's true.",
                    "label": 0
                },
                {
                    "sent": "This is the false positive rate of type 1 error and the type where is the opposite of the dual.",
                    "label": 0
                },
                {
                    "sent": "When I say it's true and it's, I do not reject it and it's actually false and classically statistiques you have this.",
                    "label": 0
                },
                {
                    "sent": "Of course this introduces asymmetry so you don't control the two errors at the same at the same time, or rather than your first focus in a Type 1 error traditionally used to say I want to type 1 error, so for one single test you look at the property of type 1 error for a given test, and you want it to be less than Alpha and Alpha.",
                    "label": 0
                },
                {
                    "sent": "Fixed so this is the classic alignment person setting.",
                    "label": 0
                },
                {
                    "sent": "And given that the type owner is less than Alpha property of type pointer is less than Alpha, then you want to have the Type 2 error as low as possible, which is.",
                    "label": 0
                },
                {
                    "sent": "Which is to say that you want to have your test to have a high power OK.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So OK, some word about P values also, because that's a.",
                    "label": 0
                },
                {
                    "sent": "That's also said that something that is very useful in multiple testing.",
                    "label": 1
                },
                {
                    "sent": "So what are typically?",
                    "label": 1
                },
                {
                    "sent": "What kind of decision do I take when I make a test?",
                    "label": 0
                },
                {
                    "sent": "Well, most of the time I computed test statistic, some real function based on my data is your fix and then my decision based on zero weeks is just to say, well, I will declare that my purpose is rejected when my statistic is larger than a certain threshold.",
                    "label": 0
                },
                {
                    "sent": "Ann is not rejected otherwise.",
                    "label": 0
                },
                {
                    "sent": "So every time I go over the threshold for this statistic, I would say oh, I think I have.",
                    "label": 0
                },
                {
                    "sent": "Which it's unusual.",
                    "label": 0
                },
                {
                    "sent": "I have made a discovery.",
                    "label": 0
                },
                {
                    "sent": "I have rejected.",
                    "label": 0
                },
                {
                    "sent": "The output is.",
                    "label": 0
                },
                {
                    "sent": "And the threshold T of Alpha.",
                    "label": 0
                },
                {
                    "sent": "So here the trace will depend on the parameter Alpha, and it's precisely tuned so that if the null hypothesis is true, then the probability of this happening is less than Alpha.",
                    "label": 1
                },
                {
                    "sent": "So it means that in that case my type 1 error will be less than Alpha OK.",
                    "label": 0
                },
                {
                    "sent": "So this ensure the control of type 1 error rate.",
                    "label": 1
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Alpha, so now what is the P value in that setting?",
                    "label": 0
                },
                {
                    "sent": "Oh well, so it can be basically easy konbini statistiques.",
                    "label": 0
                },
                {
                    "sent": "I'm usually you build statistic that are relevant to the hypothesis you want to test, but 4:30 called purposes.",
                    "label": 0
                },
                {
                    "sent": "It's interesting once you have an interesting statistic so it can be, for example the empirical mean.",
                    "label": 0
                },
                {
                    "sent": "If you want to test for the mean being greater than zero or the Z score in classical testing, when you divide the mean by the empirical variance.",
                    "label": 0
                },
                {
                    "sent": "OK, so once you have done that, it's useful to normalize the statistics to have a unified framework.",
                    "label": 0
                },
                {
                    "sent": "So let's consider this setting.",
                    "label": 0
                },
                {
                    "sent": "So T is a decreasing function and let's let's consider T -- 1 of 0X.",
                    "label": 0
                },
                {
                    "sent": "And of course, if I just apply T -- 1 here.",
                    "label": 0
                },
                {
                    "sent": "And because it's a decreasing function, I have the property that P of X.",
                    "label": 0
                },
                {
                    "sent": "This function is less than Alpha property that this being less than Alpha is less than Alpha.",
                    "label": 0
                },
                {
                    "sent": "Of course, this is valid under the new hypothesis, so if HO is true, this is true and P is called the P value.",
                    "label": 1
                },
                {
                    "sent": "P value function associated to the test.",
                    "label": 0
                },
                {
                    "sent": "So what this means is that.",
                    "label": 0
                },
                {
                    "sent": "If the hypothesis a zero is true, my function function pure weeks, which is also a particular statistics.",
                    "label": 1
                },
                {
                    "sent": "It's just a normalized one.",
                    "label": 0
                },
                {
                    "sent": "Is took a sickly lower bounded by uniform random variable and this is the important property.",
                    "label": 1
                },
                {
                    "sent": "And so any test based on any test can be basically reduced to do a test of its P value.",
                    "label": 0
                },
                {
                    "sent": "So this is, this is just a normalizing device.",
                    "label": 0
                },
                {
                    "sent": "And, uh, OK.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So most of the time we talk about tests will assume that they are based on the P values of certain P value.",
                    "label": 0
                },
                {
                    "sent": "OK, So what now multiple testing so multiple testing is very important in for the treatment of large dimensional data and for lot of recent applications so traditional statistics I had to test one hypothesis and then maybe I want to test some many hypothesis at the same time so.",
                    "label": 1
                },
                {
                    "sent": "This can be a procedure, large number of hypothesis that we want to test simultaneously.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So here are some example applications so.",
                    "label": 0
                },
                {
                    "sent": "I have a solution I want to detect the presence of some chemical compounds and I have a lot of them to test 4.",
                    "label": 1
                },
                {
                    "sent": "So for each of them there is a test and then when I test all of them then I can make.",
                    "label": 0
                },
                {
                    "sent": "I can make many errors possibly.",
                    "label": 0
                },
                {
                    "sent": "So I want to test that all together and have an idea of the.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Or I make another situation words well.",
                    "label": 0
                },
                {
                    "sent": "Typical situation where we're testing is used is affordable in F, MRI, F, MRI, image and.",
                    "label": 0
                },
                {
                    "sent": "So here you want to detect zones of activity and basically for each pixel of the image you can perform a test.",
                    "label": 0
                },
                {
                    "sent": "To test whether it's significantly higher, the activation level is significantly higher than normal.",
                    "label": 0
                },
                {
                    "sent": "And of course you have in principle to have to perform a hypothesis for each separate pixel, so that's a lot.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In a. Microarray data.",
                    "label": 0
                },
                {
                    "sent": "It's the same similar problem you can.",
                    "label": 0
                },
                {
                    "sent": "You can have a microwave with a lot of jeans that are tested for several individuals in two different experimental conditions.",
                    "label": 0
                },
                {
                    "sent": "You want to know which genes are differentially expressed in two experimental conditions and you have the choice when you have to test a lot of genes, possibly 10s of thousands to at the same time.",
                    "label": 0
                },
                {
                    "sent": "So these are numerous applications where multiple testing is routinely used.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then also another example is when you have a regression problem and I want to test which regressors are have a dependent so significant dependence relationship with the output I want to predict.",
                    "label": 0
                },
                {
                    "sent": "OK so these are all the classical examples and there are of course many other.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "It's just too imprecise itself.",
                    "label": 0
                },
                {
                    "sent": "It's an important problem, especially in bioinformatic, San 4.",
                    "label": 0
                },
                {
                    "sent": "For large large datasets.",
                    "label": 0
                },
                {
                    "sent": "OK, so here's the setting for multiple testing.",
                    "label": 1
                },
                {
                    "sent": "I assume that I have now a set of of null hypothesis.",
                    "label": 1
                },
                {
                    "sent": "It's H, so it's a whole set of possible hypothesis.",
                    "label": 0
                },
                {
                    "sent": "So maybe just to fix ideas.",
                    "label": 0
                },
                {
                    "sent": "If you think of a set of hypothesis, you can think of a very large vector.",
                    "label": 0
                },
                {
                    "sent": "And I want each hypothesis whether the one coordinates has mean different from zero and for each coordinate I have a separate hypothesis.",
                    "label": 0
                },
                {
                    "sent": "So this is a typical setting, for example 5 MRI an.",
                    "label": 0
                },
                {
                    "sent": "And microarray so you can keep that in mind.",
                    "label": 1
                },
                {
                    "sent": "So there is a subset H zero, which are the set of truly hypothesis that are really satisfied by my data generating distribution.",
                    "label": 0
                },
                {
                    "sent": "And of course a Geo is unknown.",
                    "label": 1
                },
                {
                    "sent": "Of course I would not have to do anything, so I would like to have obtain as much information I can about a zero and in general and the people testing procedures takes the data.",
                    "label": 0
                },
                {
                    "sent": "An output the set a subset of H which is the set of rejected hypothesis.",
                    "label": 0
                },
                {
                    "sent": "So for each separate hypothesis I take a decision and I can sum up this by saying I'm just rejecting a subset.",
                    "label": 0
                },
                {
                    "sent": "So this is a random subset.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Depending on the data.",
                    "label": 0
                },
                {
                    "sent": "OK, now what?",
                    "label": 0
                },
                {
                    "sent": "What is the problem in multiple testing?",
                    "label": 1
                },
                {
                    "sent": "Well usually it's about error control.",
                    "label": 0
                },
                {
                    "sent": "So how do I control the error when I repeatedly do many tests and each of them is likely to make a small probability of making an error?",
                    "label": 0
                },
                {
                    "sent": "So usually to concentrate on this problem, I assume we assume that for each separate hypothesis, we already have a test available.",
                    "label": 1
                },
                {
                    "sent": "Maybe from some previous work, or maybe it's a classical test like AZ score test or something like this.",
                    "label": 0
                },
                {
                    "sent": "So for each separate hypothesis.",
                    "label": 0
                },
                {
                    "sent": "HI assume that I have a certain testing procedure TH with a P value function pH and OK that's known.",
                    "label": 1
                },
                {
                    "sent": "I know the problem is that now that I have all these family of tests or P value.",
                    "label": 1
                },
                {
                    "sent": "These people family.",
                    "label": 0
                },
                {
                    "sent": "How do I construct?",
                    "label": 1
                },
                {
                    "sent": "Meaningfully are multiple testing procedures based on that.",
                    "label": 0
                },
                {
                    "sent": "And so, since I want generally want that to be based on the P values, I mean the the functional relationship will between the data and rejected set will be that my rejected set will actually depend just on the P values.",
                    "label": 0
                },
                {
                    "sent": "So from the data as compute the P values there is 1 value for each hypothesis and from the set of P values somehow I compute my set of rejected hypothesis.",
                    "label": 0
                },
                {
                    "sent": "So it will be.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "A function of P. Now the question is how do I measure the error I make?",
                    "label": 0
                },
                {
                    "sent": "So of course there is a risk of error for each separate hypothesis and.",
                    "label": 1
                },
                {
                    "sent": "So I mean I want to sum up the error.",
                    "label": 0
                },
                {
                    "sent": "I'm making one single number to assist the quality, so there are of course many ways to sum up all these errors in one single number, and maybe the most traditional one and.",
                    "label": 0
                },
                {
                    "sent": "Well, original, sorry.",
                    "label": 1
                },
                {
                    "sent": "All the other one is the familywise error rate.",
                    "label": 1
                },
                {
                    "sent": "Which is the probability that my rejected set contains at least a true null hypothesis.",
                    "label": 0
                },
                {
                    "sent": "So if I make every time I make any error anywhere, any type 1 error, then here I say OK I made an error.",
                    "label": 0
                },
                {
                    "sent": "So this is a very strict procedure, especially criterion, especially if I have a lot of hypothesis to test, it means I won't allow any Type 1 error anywhere.",
                    "label": 0
                },
                {
                    "sent": "So this this can be useful sometimes.",
                    "label": 0
                },
                {
                    "sent": "I mean sometimes I don't want to perform to have any error, but people have been complaining that maybe it's too strict because it's it will reduce the power a lot because it's.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Strict, so this is where.",
                    "label": 0
                },
                {
                    "sent": "Minion, minion hard work introduced these celebrated false discovery rate in 95.",
                    "label": 1
                },
                {
                    "sent": "Which is another measure of type 1 error, which is more.",
                    "label": 0
                },
                {
                    "sent": "Lenient and it's just the expected, so it's expected expectation over the drawer of the data.",
                    "label": 0
                },
                {
                    "sent": "Of the proportion of errors I make in the in the hypothesis, I have rejected so it is the ratio of the intersection.",
                    "label": 0
                },
                {
                    "sent": "Well, this is the cardinality of the intersection of rejected and new hypothesis.",
                    "label": 0
                },
                {
                    "sent": "Divided by the quantity of rejected hypothesis.",
                    "label": 0
                },
                {
                    "sent": "So why does it make sense?",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So for this we are it makes sense in particular for screening processes so.",
                    "label": 1
                },
                {
                    "sent": "Typically the examples I gave for chemical compounds or maybe microarrays, data microarray data, types of screening processes.",
                    "label": 0
                },
                {
                    "sent": "So I have a lot of candidate objects.",
                    "label": 0
                },
                {
                    "sent": "We can be this chemical compounds or jeans an and then I want to find among the subjects, some candidates that are interesting and I have a whole huge choice and I want to narrow my choice significantly and then maybe I will.",
                    "label": 0
                },
                {
                    "sent": "Devote some more resource to studying the ones I deem interesting candidates.",
                    "label": 0
                },
                {
                    "sent": "So this is, this is what I have here.",
                    "label": 0
                },
                {
                    "sent": "So it means that if I if I in the screening process, if I use a testing procedure to detect.",
                    "label": 0
                },
                {
                    "sent": "So to make these discoveries to detect which genes, for example, are interesting, if I make a few errors in my set of objectives, jeans.",
                    "label": 0
                },
                {
                    "sent": "So I have a small proportion of jeans that are actually not significantly differentially expressed.",
                    "label": 0
                },
                {
                    "sent": "Among my rejected one I'm it's not too bad because then I will devote my resource to my my set of candidates and OK, so some of them will turn out not to be interesting after all, but not such a big proportion.",
                    "label": 1
                },
                {
                    "sent": "So in this case it's really relevant to look at this FDR criterion to assess the quality of my testing procedure.",
                    "label": 0
                },
                {
                    "sent": "And OK, there's all these situations where we can defend the FDR as a meaningful measure, and so here in this talk I will really concentrate on this on controlling this measure of error.",
                    "label": 0
                },
                {
                    "sent": "And again their situation where it's not appropriate.",
                    "label": 0
                },
                {
                    "sent": "But there are many situations where these are now, as I explained earlier, it's really becoming like a standard way of controlling the error in many scientific papers you have people.",
                    "label": 0
                },
                {
                    "sent": "Researchers precise that they are statistical errors are FDR corrected, and so it's it's really become.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Standard.",
                    "label": 0
                },
                {
                    "sent": "OK, so now I will.",
                    "label": 0
                },
                {
                    "sent": "Talk about this.",
                    "label": 0
                },
                {
                    "sent": "How you build procedures with FDR control?",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so we start with the kind of motivation.",
                    "label": 0
                },
                {
                    "sent": "Heuristic motivation.",
                    "label": 0
                },
                {
                    "sent": "So let's assume touristically that we would know a priori that the set of rejected hypothesis is more than certain K fix.",
                    "label": 1
                },
                {
                    "sent": "OK, let's assume that for a moment.",
                    "label": 0
                },
                {
                    "sent": "So what can we say about the FDR being less than Alpha?",
                    "label": 0
                },
                {
                    "sent": "Well, if I reject a hypothesis, I would say well, giving the DVR is the proportion of errors I can afford up to Alpha errors on average.",
                    "label": 1
                },
                {
                    "sent": "If I make up to Alpha cat errors on average and my FDR is less than Alpha, OK?",
                    "label": 0
                },
                {
                    "sent": "So what's the number of at all?",
                    "label": 0
                },
                {
                    "sent": "So here I consider.",
                    "label": 0
                },
                {
                    "sent": "How do I use the P values to define to define a rejected set while the.",
                    "label": 0
                },
                {
                    "sent": "Based on what I said earlier that you reject a single test when the statistic is higher than a certain threshold.",
                    "label": 0
                },
                {
                    "sent": "Usually we consider also multiple rejection where we reject procedures where R is made of all the hypothesis such that the P value is less than a certain threshold T. OK, so let's consider a procedure of this form for certainty, which is the number of errors I commit.",
                    "label": 0
                },
                {
                    "sent": "Well, I make an error for every age that is true.",
                    "label": 0
                },
                {
                    "sent": "And for which this is, this happens nevertheless.",
                    "label": 0
                },
                {
                    "sent": "So for any edge which is true, I have this probability.",
                    "label": 0
                },
                {
                    "sent": "I know this is bounded.",
                    "label": 0
                },
                {
                    "sent": "This probability is bounded by T by definition, because for true hypothesis this this is stochastically lower bounded by a uniform variable.",
                    "label": 0
                },
                {
                    "sent": "So this is less than the quality of H0T, and for now I say, well agency, I don't know, but I know at least that it's less than the Canadian H * T. OK, very simple.",
                    "label": 0
                },
                {
                    "sent": "And so if I want this to be less than Alpha.",
                    "label": 0
                },
                {
                    "sent": "Sorry, then Alpha K. Then they can just choose T equals Alpha K over the cardinality of H, and then I'm done.",
                    "label": 0
                },
                {
                    "sent": "I have FDR control.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Of course.",
                    "label": 0
                },
                {
                    "sent": "This is based on this assumption which I don't know why you would know that priore.",
                    "label": 0
                },
                {
                    "sent": "But OK, still still being juristic I can say.",
                    "label": 0
                },
                {
                    "sent": "Well now assume that I have some rejection procedure and I observed after the fact after a post hoc that my.",
                    "label": 0
                },
                {
                    "sent": "My my size, my size of rejection has a certain well observed the size of rejected hypothesis.",
                    "label": 0
                },
                {
                    "sent": "So I can say well, if I had known that that in advance I could have plug that in here and have this control here.",
                    "label": 0
                },
                {
                    "sent": "So of course this doesn't make much sense for logical point of view, but this is against it's just a motivation.",
                    "label": 0
                },
                {
                    "sent": "So I could say post hoc.",
                    "label": 0
                },
                {
                    "sent": "Well I would like I would like to say that my procedure will be kind of reasonable if after the fact I notice that my set of rejected hypothesis is included in this set, I would have rejected if I had known in advance the cardinality.",
                    "label": 1
                },
                {
                    "sent": "And so I generalized this condition.",
                    "label": 0
                },
                {
                    "sent": "How to say I call this self consistency condition to say my set of rejected hypothesis is included in the set of hypothesis such that the P value is less than Alpha times beta of the cardinality of our.",
                    "label": 0
                },
                {
                    "sent": "So here the only difference that introduced a function beta which I don't precise for now.",
                    "label": 0
                },
                {
                    "sent": "And I call this the self consistency condition for the function beta.",
                    "label": 1
                },
                {
                    "sent": "I called beta shape function.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is just a motivation for this condition and now we show that if this condition is satisfied.",
                    "label": 0
                },
                {
                    "sent": "Then actually my wealth and certain assumptions.",
                    "label": 0
                },
                {
                    "sent": "Then my FDR will be actual.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Controlled.",
                    "label": 0
                },
                {
                    "sent": "And it's really very simple, so here here it is basically.",
                    "label": 0
                },
                {
                    "sent": "So this is my FDR.",
                    "label": 0
                },
                {
                    "sent": "It's the ratio of rejected errors.",
                    "label": 0
                },
                {
                    "sent": "Divided by rejected.",
                    "label": 0
                },
                {
                    "sent": "So this I can decompose by summing over all all hypothesis that are true for each hypothesis is true.",
                    "label": 0
                },
                {
                    "sent": "I count 1 if it's in the it's rejected set which means one error and 0 otherwise.",
                    "label": 0
                },
                {
                    "sent": "So for some overage zero of the expected value of the indicator of age belongs to R / R. This is an equality.",
                    "label": 1
                },
                {
                    "sent": "And then here use myself consistency condition saying well if H is in R. Well, I know that R is contained in the set of hypothesis satisfying this, so it means that H will satisfy this condition.",
                    "label": 0
                },
                {
                    "sent": "H will be such that pH is less than Alpha beta var.",
                    "label": 0
                },
                {
                    "sent": "Using the my condition, my previous condition OK. Now what I'm saying is that if I can prove that this quantity here this term.",
                    "label": 0
                },
                {
                    "sent": "Is less than.",
                    "label": 0
                },
                {
                    "sent": "Is less than Alpha.",
                    "label": 0
                },
                {
                    "sent": "So let's say.",
                    "label": 0
                },
                {
                    "sent": "Lisa, yeah it's less than Alpha divided by H then by summing will just have H. Well actually H 0 times Alpha divided by H and this will be less than Alpha.",
                    "label": 0
                },
                {
                    "sent": "So now with this very simple observation, I'm just reduced in a sense, if I want sufficient condition to controlling this quantity for any fixed H. And this can be, well, abstractly put, under the simple form that now I have two random variables, so one is pH.",
                    "label": 0
                },
                {
                    "sent": "So I call you it's you here, it's bounded, it's it's stochastically lower bounded by a uniform variable.",
                    "label": 1
                },
                {
                    "sent": "Because I mean it's in edge 0.",
                    "label": 0
                },
                {
                    "sent": "And then another variable V which is here the cardinality of the rejected set.",
                    "label": 0
                },
                {
                    "sent": "And so if I can prove something like.",
                    "label": 0
                },
                {
                    "sent": "This probability can equality on 2 random variables U and V2 real random variables.",
                    "label": 0
                },
                {
                    "sent": "So it's kind of very simple relation.",
                    "label": 0
                },
                {
                    "sent": "And basically I'm done, I control.",
                    "label": 0
                },
                {
                    "sent": "OK, so when is this satisfied?",
                    "label": 0
                },
                {
                    "sent": "For you and me so.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Here are three classical cases, so the first case is when we have independent aesthetics, which is a commonly considered case in multiple testing.",
                    "label": 0
                },
                {
                    "sent": "So here assume that all my P values are independent.",
                    "label": 0
                },
                {
                    "sent": "So in that case.",
                    "label": 0
                },
                {
                    "sent": "Remember, I'm interested in a.",
                    "label": 0
                },
                {
                    "sent": "This expectation.",
                    "label": 0
                },
                {
                    "sent": "So here I say I'm saying that it will be.",
                    "label": 0
                },
                {
                    "sent": "I can use beta of X is just a linear function.",
                    "label": 0
                },
                {
                    "sent": "And divided by R. So this is sorry this is R. No, what can I do to use the hypothesis that I have independent aesthetics where I can condition with respect to all the other pH?",
                    "label": 0
                },
                {
                    "sent": "So here it's concerns just pH are depends on all the other P values of course, but I can say well this condition with respect to all others and see what happens.",
                    "label": 0
                },
                {
                    "sent": "So this P -- H is all P values except the one I'm interested in.",
                    "label": 0
                },
                {
                    "sent": "So what's happening now?",
                    "label": 0
                },
                {
                    "sent": "Well, if the orders are fixed, though, because they are independent, pH is still lower bounded by a stochastically stochastically, sarcastically bound lower bound by uniform random variable.",
                    "label": 0
                },
                {
                    "sent": "Because conditioning doesn't change that.",
                    "label": 0
                },
                {
                    "sent": "But then what is our well now conditionally to these ones?",
                    "label": 0
                },
                {
                    "sent": "Are is just a function R of PRPH, so it's not really random variable because it just depends on the last remaining valuable.",
                    "label": 0
                },
                {
                    "sent": "And then if I assume that R is a nondecreasing function.",
                    "label": 1
                },
                {
                    "sent": "Now they just reduced to proving that indicator of U less than G or V. Sorry.",
                    "label": 0
                },
                {
                    "sent": "This then geoview.",
                    "label": 0
                },
                {
                    "sent": "So CCGFUC is a constant.",
                    "label": 0
                },
                {
                    "sent": "Divided by geoview.",
                    "label": 0
                },
                {
                    "sent": "Is less than C. Well, GG here it's a decreasing function.",
                    "label": 0
                },
                {
                    "sent": "So I can leave that to you as an exercise.",
                    "label": 0
                },
                {
                    "sent": "It's very simple, so this is true when G is a decreasing function.",
                    "label": 0
                },
                {
                    "sent": "So why it is decreasing function thing?",
                    "label": 0
                },
                {
                    "sent": "Well, this is actually another hypothesis, but it's a very natural hypothesis because I just assume that if I if my P values become lower, I will reject more an appeal with our lower means that really I have more evidence against one given hypothesis.",
                    "label": 0
                },
                {
                    "sent": "So it's really natural to assume that my rejection.",
                    "label": 0
                },
                {
                    "sent": "Procedure is an increasing sorry decreasing function as a function of the P values.",
                    "label": 0
                },
                {
                    "sent": "So this is really not restrictive.",
                    "label": 0
                },
                {
                    "sent": "So in the case of independency it's very simple so used to that claim and then it's true and then my idea is controlled with this linear function.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here's another case.",
                    "label": 0
                },
                {
                    "sent": "So I would relate these two known results later, but when the when the peers are pretty positively dependent in a certain sense introduced by Benjamini and equity in 2001?",
                    "label": 0
                },
                {
                    "sent": "It's also satisfied with the same beta function and so basically what these changes here.",
                    "label": 0
                },
                {
                    "sent": "Is that?",
                    "label": 0
                },
                {
                    "sent": "I cannot condition, but I can say that instead of being a function of you now.",
                    "label": 0
                },
                {
                    "sent": "Are witches takes the role of V is a function which is stochastically decreasing in you.",
                    "label": 0
                },
                {
                    "sent": "So basically it's a generalization of that which.",
                    "label": 0
                },
                {
                    "sent": "Is also a stochastic probability lemma, but just two to two variables with a certain type of dependent, so it's also relatively simple.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And then here is 1/3 case.",
                    "label": 0
                },
                {
                    "sent": "It's when I want.",
                    "label": 0
                },
                {
                    "sent": "I don't want to assume anything, so I don't want to assume any kind of knowledge about the dependence on the P values.",
                    "label": 0
                },
                {
                    "sent": "And then it turns out that the relation is also satisfied if I take a beta of this form, so it's so this is normally normalizing factor 1 / H and its integral from zero to X or feuding.",
                    "label": 0
                },
                {
                    "sent": "You a fewer new is any arbitrary property measure, so I can choose my any any new I have to choose it before I do my experiment of course.",
                    "label": 0
                },
                {
                    "sent": "And I will comment on that a little later.",
                    "label": 0
                },
                {
                    "sent": "And in all of these cases, because I have this control.",
                    "label": 1
                },
                {
                    "sent": "Very simple privacy control.",
                    "label": 0
                },
                {
                    "sent": "It implies that provided I satisfy the self consistency condition with function beta and the time decreasing the P values.",
                    "label": 1
                },
                {
                    "sent": "Then it's true that any any are satisfying these two conditions will have this FDR control.",
                    "label": 0
                },
                {
                    "sent": "Oh yeah.",
                    "label": 0
                },
                {
                    "sent": "It seems that you have less assumptions.",
                    "label": 0
                },
                {
                    "sent": "Yes, I have less assumptions.",
                    "label": 0
                },
                {
                    "sent": "Well.",
                    "label": 0
                },
                {
                    "sent": "Yeah, yes.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "Then you get.",
                    "label": 0
                },
                {
                    "sent": "Well no, I get to keratic function.",
                    "label": 0
                },
                {
                    "sent": "Yeah, yeah, I get something different.",
                    "label": 0
                },
                {
                    "sent": "I will I will.",
                    "label": 0
                },
                {
                    "sent": "I will give a little more details about this data functioning.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You know in a moment.",
                    "label": 0
                },
                {
                    "sent": "So first I introduce separate procedures, so OK, so here's my self consistency condition.",
                    "label": 0
                },
                {
                    "sent": "So now we can do with that.",
                    "label": 0
                },
                {
                    "sent": "Well, I can say, well, I know that given this condition my my my FDR is control and now I want to have high power to have high power.",
                    "label": 0
                },
                {
                    "sent": "I want to reject as much as I can, given that I'm still satisfying this condition.",
                    "label": 0
                },
                {
                    "sent": "So we can ask which is the largest set that I can reject.",
                    "label": 0
                },
                {
                    "sent": "Given this is satisfied, and if you look at at what what you so you can take the maximum rejection set that satisfy this hypothesis.",
                    "label": 0
                },
                {
                    "sent": "And then it's not difficult to see that this is equivalent to this to a so called step procedure.",
                    "label": 0
                },
                {
                    "sent": "So what is a separate procedure?",
                    "label": 0
                },
                {
                    "sent": "So here's the recipe for it an so I have my P values.",
                    "label": 0
                },
                {
                    "sent": "For each hypothesis, I order them in increasing order.",
                    "label": 0
                },
                {
                    "sent": "Then I take the largest K such that the P value of rank I the largest.",
                    "label": 0
                },
                {
                    "sent": "I such at the pier Frank I is less than Alpha beta of I.",
                    "label": 0
                },
                {
                    "sent": "So the maximum number and then so that you know these K hat and then I reject all hypothesis from H. Well, the order hypothesis for H128K Hut OK and you can check it's also not difficult to check that this is equivalent to saying that I take the largest set satisfying this.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So what does this correspond to?",
                    "label": 0
                },
                {
                    "sent": "So this is the.",
                    "label": 0
                },
                {
                    "sent": "Kind of cartoon of P values, so of course there are general discrete, but let's say that, so this is my sorted P values and increasing function and then I have my shade shape function beta VIX.",
                    "label": 0
                },
                {
                    "sent": "And as soon as well if I'm below I reject, reject, reject and then the last crossing point here is the maximum such that I'm still below and then I reject all hypothesis from here to here.",
                    "label": 0
                },
                {
                    "sent": "So you see here I'm still above, but it doesn't matter because then I am below and here I can reject that.",
                    "label": 0
                },
                {
                    "sent": "So this is called a step procedure.",
                    "label": 0
                },
                {
                    "sent": "So for any beta function satisfying well under the different hypothesis I've told about before.",
                    "label": 0
                },
                {
                    "sent": "This step procedure is maximizing the the size of the redacted.",
                    "label": 0
                },
                {
                    "sent": "I posted this and I still have my FDR control at level Alpha.",
                    "label": 1
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so in the case of a linear function.",
                    "label": 0
                },
                {
                    "sent": "These two first cases.",
                    "label": 0
                },
                {
                    "sent": "This reduces to the well known procedure of Benjamin Hodge.",
                    "label": 0
                },
                {
                    "sent": "Begin producing in 95.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Paper, which is the.",
                    "label": 0
                },
                {
                    "sent": "The linear step procedure and this is.",
                    "label": 0
                },
                {
                    "sent": "Maybe the most standard procedure, so he merely I just retrieved this classical classical result, but I think this is a well.",
                    "label": 0
                },
                {
                    "sent": "Usually this is not presented this way, so I really think this way is is.",
                    "label": 0
                },
                {
                    "sent": "Is really simple than the original 1 to present things so anyway, so we achieve the classical step procedure and in the case of unspecified dependencies.",
                    "label": 0
                },
                {
                    "sent": "So again, I have to choose beta of this form and I have to choose new and actually we can see that new kind of plays a role of a prior prior prior in a Bayesian sense about the size of the rejected hypothesis.",
                    "label": 0
                },
                {
                    "sent": "So I will present some graphs in the next slides tournament.",
                    "label": 0
                },
                {
                    "sent": "This means by the way, it's can be proved that it's.",
                    "label": 0
                },
                {
                    "sent": "If you don't want to specify the dependencies, then it's necessary to lose a little so this bit of X, whatever new.",
                    "label": 0
                },
                {
                    "sent": "It's always lower than the linear one, then X / H. So you lose something because your beta function is a.",
                    "label": 0
                },
                {
                    "sent": "Here, if it's lower, of course you reject less.",
                    "label": 0
                },
                {
                    "sent": "So what you lose the price to pay for and specify dependencies reside in that you have a lower beta function, But then you can still at least choose your new.",
                    "label": 0
                },
                {
                    "sent": "And if you have a precise idea of approximately how, what is the percentage of hypothesis you will reject, you expect to be rejected and you can use that in this prior.",
                    "label": 0
                },
                {
                    "sent": "To still have a reasonable power.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In the case of special case of New Avize is proportional to the inverse of I.",
                    "label": 0
                },
                {
                    "sent": "So this particular prior then beta is linear because it cancels out here, so it's again a linear step up, except the slope is lower than the slope for the standard LSU.",
                    "label": 0
                },
                {
                    "sent": "So because I'm in the case of an specify dependencies, I lose a little in the slope, and again this recovers a result of Benjamin acquitted in 2001.",
                    "label": 0
                },
                {
                    "sent": "But with this presentation, of course I can say I can.",
                    "label": 0
                },
                {
                    "sent": "I can choose any arbitrary new, and this gives me more more.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "She.",
                    "label": 0
                },
                {
                    "sent": "So here are some examples.",
                    "label": 0
                },
                {
                    "sent": "Of the shape function you obtained by choosing different news so.",
                    "label": 0
                },
                {
                    "sent": "Here we have Delta Direct functions, which means that I hope I know exactly that my rejected set will have a certain size, so this is compatible with my my you Ristic approach, where newer priority that.",
                    "label": 0
                },
                {
                    "sent": "I would I would have rejected Kaopua thesis, so in this case I see that well, the shape function is a step function.",
                    "label": 0
                },
                {
                    "sent": "Precise, yet the value in question.",
                    "label": 0
                },
                {
                    "sent": "And so if I don't reject, so if I'm if I'm wrong, if I if the set of rejected hypothesis would be below, then I'm losing completely the power because I won't reject anything.",
                    "label": 0
                },
                {
                    "sent": "But if I'm if I'm right and in that region then well here I see that I in this point I coincide with this linear step procedure, so this is the line for the independent case.",
                    "label": 0
                },
                {
                    "sent": "The linear step procedure.",
                    "label": 0
                },
                {
                    "sent": "So this is the one I obtained under the.",
                    "label": 0
                },
                {
                    "sent": "The strong hypo assumption that my P values are independent.",
                    "label": 0
                },
                {
                    "sent": "OK, so there are variations on this.",
                    "label": 0
                },
                {
                    "sent": "I can look at the shape functions obtained for Goshen priors with some spread about the certain value.",
                    "label": 0
                },
                {
                    "sent": "These are power priors for different powers, so.",
                    "label": 0
                },
                {
                    "sent": "Here for power minus one, retrieve the other step up newspaper procedure.",
                    "label": 0
                },
                {
                    "sent": "So we see that here this is the one without correction and this is the one with the beta correction.",
                    "label": 0
                },
                {
                    "sent": "So the slope is lower.",
                    "label": 0
                },
                {
                    "sent": "I lose a function.",
                    "label": 0
                },
                {
                    "sent": "Logarithm of the cardinality, which is Southern here.",
                    "label": 0
                },
                {
                    "sent": "And these are exponential priors, so I think the exponential priors may be interesting because so here in purple I have the corrected linear one, so the one which the correction for the fact that I don't assume anything on the dependence.",
                    "label": 0
                },
                {
                    "sent": "And I can see that if for example for some settings in in this red or green curve here I'm mostly above the linear one.",
                    "label": 0
                },
                {
                    "sent": "So I'm of course I cannot be above everywhere, so it means here I will lose in the initial section, but then I will be significantly above in after that.",
                    "label": 0
                },
                {
                    "sent": "Which means if I expect, for example in this case to reject at least 50 hypothesis, which is like which is just 5% here.",
                    "label": 0
                },
                {
                    "sent": "Then I I should better choose an exponential prior because then I will have a higher beta function which will result in larger number of rejected hypothesis so.",
                    "label": 0
                },
                {
                    "sent": "If I'm really concerned about this dependent thing, then I choosing the priority in a good way is a is an interesting way of what can lead to improved power.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so now we'll talk about.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Adaptive procedures, So what does it mean?",
                    "label": 1
                },
                {
                    "sent": "Adaptive?",
                    "label": 0
                },
                {
                    "sent": "So it's adaptive in a very specific sensor that default to this parameter by zero, which is the proportion of.",
                    "label": 0
                },
                {
                    "sent": "True new hypothesis.",
                    "label": 0
                },
                {
                    "sent": "So if you look back at the proof of the FDR in all of these cases, what we have proved actually is that the FDR of all these step procedures.",
                    "label": 1
                },
                {
                    "sent": "Was bounded by, not by Alphabet by \u03c0 Zero Times Alpha.",
                    "label": 0
                },
                {
                    "sent": "\u03a0 Zero is the proportion of new hypothesis, so of course I don't know this proportion is bounded by one, so in the worst case it's just Alpha.",
                    "label": 0
                },
                {
                    "sent": "But if it turns out that I don't have, I don't have such a large number of null hypothesis, then maybe I can gain a little more.",
                    "label": 0
                },
                {
                    "sent": "And this this way has also be explored by Benjamini, so the.",
                    "label": 0
                },
                {
                    "sent": "I always quoting said citing Menomini because since he has started this field he's made a lot of papers on different areas related to that sort.",
                    "label": 0
                },
                {
                    "sent": "Of course I'm always referring to.",
                    "label": 0
                },
                {
                    "sent": "To him between others.",
                    "label": 0
                },
                {
                    "sent": "So if I knew \u03c0 zero, my ideal beta will be just to correct and introduce a factor.",
                    "label": 0
                },
                {
                    "sent": "Paso minus one.",
                    "label": 0
                },
                {
                    "sent": "Then I would exactly.",
                    "label": 0
                },
                {
                    "sent": "Control.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Aviat level Alpha.",
                    "label": 0
                },
                {
                    "sent": "In general, of course, Pacer is unknown, and then how can I address this?",
                    "label": 1
                },
                {
                    "sent": "Well, here I can have two two ways.",
                    "label": 0
                },
                {
                    "sent": "I can try to estimate by zero, or rather to submit by 0 -- 1 because that's why I'm interested.",
                    "label": 0
                },
                {
                    "sent": "What I'm interested in here and then use this estimator, plug it in here instead of the true \u03c0 zero and expect.",
                    "label": 0
                },
                {
                    "sent": "Hope it works.",
                    "label": 1
                },
                {
                    "sent": "All I can use so this is called kind of two step procedure because I first estimate by zero and then I plug it into my function.",
                    "label": 0
                },
                {
                    "sent": "My shape function beta or I tried to try to find a function beta.",
                    "label": 1
                },
                {
                    "sent": "So that in some sense, so it's just a regular step procedure with a different function beta.",
                    "label": 0
                },
                {
                    "sent": "Which is some sense already.",
                    "label": 0
                },
                {
                    "sent": "Adaptive two by zero?",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "So of course, what they expect in some intuitive sense is the more reject hypothesis.",
                    "label": 0
                },
                {
                    "sent": "The more I think that actually pay 0 is little because if I reject a lot of hypothesis, I assume that most of them are actually really not true.",
                    "label": 0
                },
                {
                    "sent": "So the set of of candidate, new libraries, strings, and so the more I reject once again, the more I reject, the more I expect to be able to reject so.",
                    "label": 0
                },
                {
                    "sent": "This should be a.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This should be.",
                    "label": 0
                },
                {
                    "sent": "This is the general idea.",
                    "label": 1
                },
                {
                    "sent": "So here are two previously known procedures.",
                    "label": 0
                },
                {
                    "sent": "The first one is called so that.",
                    "label": 0
                },
                {
                    "sent": "The two of them of the first type.",
                    "label": 0
                },
                {
                    "sent": "So two state procedures, two stage.",
                    "label": 0
                },
                {
                    "sent": "The first one is called story stories.",
                    "label": 0
                },
                {
                    "sent": "Procedure is based on rejecting without correction.",
                    "label": 0
                },
                {
                    "sent": "And so we reject the hypothesis without correction on that based on the stressful Lambda.",
                    "label": 0
                },
                {
                    "sent": "And based on that you estimate natural way the proportion of new hypothesis.",
                    "label": 0
                },
                {
                    "sent": "And the procedure of Benjamin Equigen equally, that in an article of 2006 is a two stage procedure, also with an estimation of \u03c0 zero, where with this estimator.",
                    "label": 1
                },
                {
                    "sent": "So if you look at that, what this is is that the 1st.",
                    "label": 0
                },
                {
                    "sent": "Perform the regular linear step procedure.",
                    "label": 0
                },
                {
                    "sent": "So the classical one they look at the number of rejected algorithms and they say, oh, let's estimate by zero.",
                    "label": 0
                },
                {
                    "sent": "So the inverse of that.",
                    "label": 0
                },
                {
                    "sent": "By H -- R Zero over H2, N minus zero is the remaining number of hypothesis, so that I assume are actually true.",
                    "label": 0
                },
                {
                    "sent": "And divided by H and then there is a correction factor to take into account that in my set of rejected hypothesis.",
                    "label": 1
                },
                {
                    "sent": "Actually I have some of them that I expect to be to be actually true.",
                    "label": 0
                },
                {
                    "sent": "So here it's kind of makes reasonable sense to estimate by 0 -- 1 by this quantity.",
                    "label": 0
                },
                {
                    "sent": "And then again, I plug these all that into again into my my linear stepper procedure.",
                    "label": 0
                },
                {
                    "sent": "What is shown where they showed in 2006 that both of these procedures actually correct in the sense that FDR is still controlled at level Alpha when I plug in this scimitar?",
                    "label": 0
                },
                {
                    "sent": "Under the independence of.",
                    "label": 0
                },
                {
                    "sent": "Under the hypothesis of independence of the test.",
                    "label": 1
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Hi this statistiques so here we present.",
                    "label": 0
                },
                {
                    "sent": "And you are one stage and two stage adaptive procedures, so this is a procedure of the second type.",
                    "label": 1
                },
                {
                    "sent": "Or directly we have a function beta.",
                    "label": 0
                },
                {
                    "sent": "So here we just.",
                    "label": 0
                },
                {
                    "sent": "Have a regular step step up procedure whether the shape function beta takes this form.",
                    "label": 1
                },
                {
                    "sent": "And basically it's it's a little like you have directly integrated in the function.",
                    "label": 0
                },
                {
                    "sent": "The the estimation of the current rejection.",
                    "label": 0
                },
                {
                    "sent": "So for fixed X, we retrieve these eight or up to this plus one.",
                    "label": 0
                },
                {
                    "sent": "Here we retrieve this H -- X.",
                    "label": 0
                },
                {
                    "sent": "Uh.",
                    "label": 0
                },
                {
                    "sent": "OK somehow OK, I'm trying to justify intuitively, but it's maybe it's not completely intuitive, but at least I see that once again the more reject and the more I my beta function is a.",
                    "label": 0
                },
                {
                    "sent": "Is different from the linear one I will draw it in the next slide.",
                    "label": 0
                },
                {
                    "sent": "And again, and the the hypothesis of the assumption of independent statistics test statistics, it is true that the stepper procedure 1 one stage procedures based on R has FDR control.",
                    "label": 1
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Alpha, so here.",
                    "label": 0
                },
                {
                    "sent": "Here's what it looks like this function.",
                    "label": 0
                },
                {
                    "sent": "So this is the regular one.",
                    "label": 0
                },
                {
                    "sent": "The one you use when you assume that the test seeker independent is linear stable procedure, and this is the the other one.",
                    "label": 0
                },
                {
                    "sent": "So you see them or reject the more it's above an OK.",
                    "label": 0
                },
                {
                    "sent": "So here there is a cap.",
                    "label": 0
                },
                {
                    "sent": "For technical reasons, but this proof is.",
                    "label": 0
                },
                {
                    "sent": "It's almost always better than the regular linear one because you have a higher threshold.",
                    "label": 0
                },
                {
                    "sent": "I say almost always, because here is below because of this technical thing.",
                    "label": 0
                },
                {
                    "sent": "And here at the beginning is also slightly below.",
                    "label": 0
                },
                {
                    "sent": "So apart from this, marginal cases is first of all, it's always better than the regular, you know, step up.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then there is more we can use actually transform that into a two or two stage procedure by saying, well, let's use that to estimate by zero again and then now put it in a two stage procedure.",
                    "label": 0
                },
                {
                    "sent": "So here we do exactly what was proposing benyamini.",
                    "label": 0
                },
                {
                    "sent": "Who go on you quit early?",
                    "label": 0
                },
                {
                    "sent": "So they were estimating this this by zero using the regular linear step procedure that we do the same, except here we use instead our procedure the previous one.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The one with this so they were using.",
                    "label": 0
                },
                {
                    "sent": "This procedure and now we're using this.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So will gain more, hopefully.",
                    "label": 0
                },
                {
                    "sent": "Because it's so sharp?",
                    "label": 0
                },
                {
                    "sent": "Or is it underestimates less by 0 -- 1?",
                    "label": 0
                },
                {
                    "sent": "And then again, under the hypothesis of independence on the 36, and it's still valid at this two stage procedure.",
                    "label": 0
                },
                {
                    "sent": "Now is bounded by Alpha OK. And then up to this, this marginal things like the plus one and this is 2 dimensional cases where it was less good and then it's all actually.",
                    "label": 0
                },
                {
                    "sent": "From a theoretical point of view, it will always be more powerful that this this procedure of benyamini chronically.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here are some simulations to demonstrate what happens, so these are sense very limited.",
                    "label": 0
                },
                {
                    "sent": "This is a framework that they used in their paper 2006, so you have just normal variables which have 00 mean or mean M, so that just two means.",
                    "label": 0
                },
                {
                    "sent": "And the covariance of two variables is constant is sumrow, so you have all your.",
                    "label": 0
                },
                {
                    "sent": "All your valuables share common two different, any two different rivals.",
                    "label": 0
                },
                {
                    "sent": "So common covariance so far equals zero is independent, and then for roll greater than zero is a positive dependent case.",
                    "label": 0
                },
                {
                    "sent": "Only perform 1 sided tests for.",
                    "label": 0
                },
                {
                    "sent": "The mean being less than 0.",
                    "label": 0
                },
                {
                    "sent": "And they are.",
                    "label": 0
                },
                {
                    "sent": "I think it should be 1000 hypothesis.",
                    "label": 0
                },
                {
                    "sent": "I forgot zero and M equals OK.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so here what do we have?",
                    "label": 0
                },
                {
                    "sent": "So this is the power compared to the Oracle procedures or the Oracle procedures.",
                    "label": 0
                },
                {
                    "sent": "Is the LSU when you know already exactly the value of P0, so you can really plug in the true value of \u03c0 zero.",
                    "label": 0
                },
                {
                    "sent": "So, and this is the power compared to that so.",
                    "label": 0
                },
                {
                    "sent": "Here we have story 1/2.",
                    "label": 0
                },
                {
                    "sent": "Here we have.",
                    "label": 0
                },
                {
                    "sent": "This is our one stage procedure.",
                    "label": 0
                },
                {
                    "sent": "This is our two stage procedure involved.",
                    "label": 0
                },
                {
                    "sent": "And procedure of Benjamin equally is here in dashed.",
                    "label": 0
                },
                {
                    "sent": "So we see that here we see that we are always better.",
                    "label": 0
                },
                {
                    "sent": "We have a higher power than the procedure of Mini Cooper Nuccetelli 06.",
                    "label": 0
                },
                {
                    "sent": "The one the other T one stages is doing worse in the first part, and so the fact that you were using that the two stages correcting for that and then we are better.",
                    "label": 0
                },
                {
                    "sent": "But of course here we notice there nevertheless than that story 1/2 is still better.",
                    "label": 0
                },
                {
                    "sent": "So we can say, what's the point?",
                    "label": 0
                },
                {
                    "sent": "So they argued in this paper of 2000 or 6, then stories.",
                    "label": 0
                },
                {
                    "sent": "1/2 story.",
                    "label": 0
                },
                {
                    "sent": "1/2 is a very good when you actually have independent hypothesis.",
                    "label": 0
                },
                {
                    "sent": "But what you use it in a situation more reasonable situation where you have dependent.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "If it is this, then it's starts not behaving at all like you want, so it's here.",
                    "label": 0
                },
                {
                    "sent": "And this is the FDR.",
                    "label": 0
                },
                {
                    "sent": "And unfortunately, story 1/2.",
                    "label": 0
                },
                {
                    "sent": "Is really totally never when you start to have positive correlations, so totally so the FBI is not controlled at all, so it's it's really not not you want, not at all what you want to happen.",
                    "label": 0
                },
                {
                    "sent": "These are all still our methods, so once again we are our two stage method is is in bold.",
                    "label": 0
                },
                {
                    "sent": "And we are here.",
                    "label": 0
                },
                {
                    "sent": "Well so slightly above in terms of Eddy are closer to the nominal expected the nominal level you would like to have, which is .05.",
                    "label": 0
                },
                {
                    "sent": "So of course, in this setting the theoretical guarantees we have do not apply because it's not independent, so we're just observing what happens if we are outside of our theoretical setting.",
                    "label": 0
                },
                {
                    "sent": "And it seems our procedure is still reasonably close to two point.",
                    "label": 0
                },
                {
                    "sent": "Two 0.05 and we are still doing better than the Big Y 06.",
                    "label": 0
                },
                {
                    "sent": "In passing to be completely honest, I must say that if I.",
                    "label": 0
                },
                {
                    "sent": "If I use story with another parameter, so sorry, 1/2 seems to be some kind of standard that people use a lot, but here we try also.",
                    "label": 0
                },
                {
                    "sent": "Sorry Alpha divided by 1 minus Alpha because it's somehow compareable theoretically to the other settings and then it performed much better than so in half so it's here so it's still slightly.",
                    "label": 0
                },
                {
                    "sent": "It goes above the nominal level, but it seems like something like that was notice before.",
                    "label": 0
                },
                {
                    "sent": "So maybe after all maybe stories.",
                    "label": 0
                },
                {
                    "sent": "OK, if you choose the right level.",
                    "label": 0
                },
                {
                    "sent": "So this is of course all simulations and.",
                    "label": 0
                },
                {
                    "sent": "Some more spec.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Even of course, it would be interesting to have a more theoretical results to support these these observations.",
                    "label": 0
                },
                {
                    "sent": "I know we go shortly about this, so this is also an effort we make made to try to have an adaptive procedures in the case where you don't want to assume anything on the.",
                    "label": 0
                },
                {
                    "sent": "On independence.",
                    "label": 0
                },
                {
                    "sent": "So you have to understand that in the dependent case, one key argument in the proof is just to say that because you're independent, the estimation of \u03c0 zero cannot be too much wrong, because it's based on independent trials.",
                    "label": 0
                },
                {
                    "sent": "So if you test each hypothesis independently, you will in average your estimation by looking at how much are rejected will not be too far away from my zero.",
                    "label": 0
                },
                {
                    "sent": "There is a kind of concentration effect because of independence.",
                    "label": 0
                },
                {
                    "sent": "So now if you don't assume anything, well, we've seen all.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That 4 three 1/2.",
                    "label": 0
                },
                {
                    "sent": "It can completely go wrong.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So more formally, surgical point of view we try to nevertheless have a device to treat that case, and it's based on.",
                    "label": 0
                },
                {
                    "sent": "Much more.",
                    "label": 0
                },
                {
                    "sent": "Rough arguments, namely net case markups inequality, so it's obviously we have a less of an improvement, but nevertheless we can prove that if you estimate so once again here we first perform the regular step procedure R0 and we take.",
                    "label": 0
                },
                {
                    "sent": "This estimation of \u03c0 zero, which is rather an underestimation of another estimate and underestimation of by 0 -- 1.",
                    "label": 1
                },
                {
                    "sent": "I'm sorry it should be a minimum of this and one.",
                    "label": 0
                },
                {
                    "sent": "Sorry, a maximum of this, and one because it's the inverse.",
                    "label": 0
                },
                {
                    "sent": "And here, because we do it on a 2 step procedure and we want to control each step separately, we also have to introduce to cut the level by four in the first step and between the second step.",
                    "label": 0
                },
                {
                    "sent": "So it means.",
                    "label": 0
                },
                {
                    "sent": "I don't think this procedure is really practically advisable, although we can show that in some specific cases you can have an improvement in particular, so this will give that significant improvement.",
                    "label": 0
                },
                {
                    "sent": "If you can reject in the first step already a significant amount of hypothesis.",
                    "label": 1
                },
                {
                    "sent": "So if \u03c0 zero is really small and you can a lot of hypothesis are easy to reject, so typically more than 6060%.",
                    "label": 1
                },
                {
                    "sent": "Then you will we end.",
                    "label": 0
                },
                {
                    "sent": "We will gain in the level.",
                    "label": 1
                },
                {
                    "sent": "OK, so maybe this is a little marginal, but our point here was just to say that in principle, even the.",
                    "label": 0
                },
                {
                    "sent": "Unspecified dependence case, we can also at least.",
                    "label": 1
                },
                {
                    "sent": "Try to have something that is adaptive, two by zero and can, at least in principle improve the improve the power.",
                    "label": 0
                },
                {
                    "sent": "On a 2 all knowledge, this is the first try in this direction, so there's no no result at all.",
                    "label": 0
                },
                {
                    "sent": "No other result under unspecified dependencies.",
                    "label": 1
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "For adaptive procedures.",
                    "label": 0
                },
                {
                    "sent": "OK, so to conclude, well, OK, so the first part of my talk was presenting these classical FDR step procedures with this kind of set output point of view using these self consistency condition, which I think is a kind of novel POV which gives very simple proofs and also allow us to introduce this added flexibility with this beta function in the case of unspecified dependencies and anything that was notice before.",
                    "label": 0
                },
                {
                    "sent": "And then presented a new one stage and two stage adaptive procedure.",
                    "label": 1
                },
                {
                    "sent": "Which one stage improves over the standard linear step up the two stages that improves over the procedure.",
                    "label": 1
                },
                {
                    "sent": "Benyamini Crogan acquitted in the Tostada no 6 paper.",
                    "label": 0
                },
                {
                    "sent": "An then specify dependency case.",
                    "label": 0
                },
                {
                    "sent": "While we demonstrated at least 30 three the 1st first procedure that that can for which you can prove that the FBI is still control at level Alpha and is somehow adaptive.",
                    "label": 0
                },
                {
                    "sent": "Two by zero.",
                    "label": 0
                },
                {
                    "sent": "And of course, well, it's just a burgeoning field.",
                    "label": 0
                },
                {
                    "sent": "I mean they are.",
                    "label": 0
                },
                {
                    "sent": "If you look at the literature on this area just a lot of papers in the last few years in all direction, practical, theoretical and there are a lot of open issues so.",
                    "label": 0
                },
                {
                    "sent": "They are difficult to list them all.",
                    "label": 0
                },
                {
                    "sent": "Here is a few one I'm interested in respect to.",
                    "label": 1
                },
                {
                    "sent": "This talk is have a better adaptive procedures, and in particular the case of unspecified dependency case.",
                    "label": 1
                },
                {
                    "sent": "I'm particularly interested in the unspecified dependency case because they come from learning theory and.",
                    "label": 1
                },
                {
                    "sent": "You can show that in this case it's it's related to some some results in learning theory, where typically you want to control an error of a large number of objects, and you don't assume any.",
                    "label": 0
                },
                {
                    "sent": "And you knowledge about the kind of dependence they have a query.",
                    "label": 0
                },
                {
                    "sent": "Then maybe exploring some of the role of this new shape prior on the and see if we can gain really significantly with respect to the default setting using the fact that we have some flexibility in this shape prior.",
                    "label": 0
                },
                {
                    "sent": "And also related that this may be related to the first point is robustness or non robustness properties of these symmetries when you.",
                    "label": 0
                },
                {
                    "sent": "You you go a little away from the independence assumption.",
                    "label": 0
                },
                {
                    "sent": "So maybe it's just a different point of view on the first point.",
                    "label": 0
                },
                {
                    "sent": "OK, thank you.",
                    "label": 0
                }
            ]
        }
    }
}