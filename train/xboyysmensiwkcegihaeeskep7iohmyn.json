{
    "id": "xboyysmensiwkcegihaeeskep7iohmyn",
    "title": "Stationary Features and Folded Hierarchies for Efficient Object Detection",
    "info": {
        "author": [
            "Donald Geman, John Hopkins University"
        ],
        "published": "Dec. 29, 2007",
        "recorded": "December 2007",
        "category": [
            "Top->Computer Science->Computer Vision->Object Recognition"
        ]
    },
    "url": "http://videolectures.net/eml07_geman_sff/",
    "segmentation": [
        [
            "Thanks for inviting me.",
            "Going to take a different point of view.",
            "It's interesting to me that there's this session.",
            "About learning and there's another.",
            "Workshop going on.",
            "About grammars provision and the points of view are so different.",
            "Here there's a buzz this year.",
            "I've never been an IFS, but there's always a buzz about something.",
            "There's a buzz this year about.",
            "Deep, deep architectures.",
            "Jeff's 2006 paper.",
            "Deep learning, I'm not sure what to call it.",
            "There's no corresponding buzz at the moment in the grammar thing, although everybody is converging back to grammars from the generative point of view.",
            "But the difference that I see in a nutshell is the belief here is in learning.",
            "Deep architectures, hierarchical architectures, learning about the world.",
            "And over in the other room, the feeling is that learning is hopeless.",
            "It will never happen.",
            "It's not going to happen this year, and it's not going to happen 10 years from now.",
            "It didn't happen 10 years ago when people thought it would have happened by this year, at least, learning to the point where you can do scene interpretation, semantics, interpretation.",
            "The view in the other room is that you're never going to learn everything.",
            "I don't care how many layers and how efficiently you learn and how clever the learning is, layer by layer.",
            "It's just never going to happen.",
            "And because there's just too much to learn, it doesn't matter how many examples you have.",
            "10 to the 100 doesn't matter.",
            "There's too much to learn.",
            "You have to hard wire things and you have to roll up your sleeves and deal with invariants.",
            "The fact that this is the same thing, not just translated that simple but scaled included.",
            "In infinite variations on this very device etc.",
            "An until you deal with invariants.",
            "Some things are in front of others next to others, including others, and make the system invariant to all the photometric and geometric transformations that we know.",
            "Preserve the names of things.",
            "Until you hardwire that invariants.",
            "You're never going to come close to solving the vision problem.",
            "You might.",
            "Detect isolated faces in our frontal view.",
            "You might get up to 99, six or something on M NIST, but you're not going to go to 99.9.",
            "You're not going to.",
            "You know, detect somebody who's sitting in front of you on a.",
            "Bus at night and you detect them from the back of their head.",
            "It's not going to happen with your deep architectures until Invariances brought into the picture.",
            "So that would be the point of view.",
            "Not everybody.",
            "But I feel that way and I want to present a somewhat different point of view today.",
            "There are some shared themes I've been interested in efficient learning for years and I used to summarize our whole research program by saying that.",
            "Efficiency is a very powerful organizing principle for vision.",
            "I believe it is and.",
            "But I inefficiency from the point of view of both training and online computation.",
            "Most of the work that I've done over the last 10 or 15 years was concentrated on the online part through course define search course defined processing of.",
            "Data.",
            "And more recently, with Francois sort of round two with Francois around one was his dissertation in the 90s and it was about course define face detection."
        ],
        [
            "And round two has been to overcome the principle liability of that research which was there was too much learning going on too many classifiers to train in our hierarchy of classifiers, one per node and for a deep architecture.",
            "That's a lot of classifiers to train.",
            "And so in the last few, the work I'm going to mainly report on today is in the last few years we've addressed the efficiency from the learning side.",
            "So his thesis was efficiency from the on line computational side and more recently we joined up again to attack efficiency from the learning side so.",
            "In this problem you want to detect the faces frontal views but arbitrarily cluttered image."
        ],
        [
            "And the approach we took was course defined processing of the space of poses.",
            "So just basically I don't want to spend much time on this and want to spend the time on the other things I alluded to.",
            "But basically the idea is that here are all the poses.",
            "They're not all there.",
            "All the poses, let's say for faces with the position between the eyes, let's say fluctuate ING at a 16 by 16 window, the distance between the eyes and some scale range 8 to 16 and some range of tilts so but it's a big post.",
            "It's a big chunk of the post space.",
            "And basically, you're just going to vision successfully.",
            "Visit different 16 by 16 regions in the scene or non overlapping process the data in the surrounding area looking for faces that are centered in that 16 by 16 with a scale that some range roughly 2 to one you'll downsample to get bigger faces, downsample again to get faces you know whatever, 32 to 64, etc.",
            "And so.",
            "Here is if you're looking at the position of the two eyes and the mouth or whatever it is you see there are many, many representations here and then successively finer by the time you get down to these least pose cells, training data available to train that one is in principle is limited to faces which satisfy this constraint.",
            "So first you might have a split.",
            "For example, you might take the 16 by 16 and split into four 8 by 8.",
            "So there might be a binary split next which divides into big scale small scale 8 to 1212 to 16 but.",
            "In the eyes, then there might be a tilt scale left, tilt, right tilt, split left till right till you recursively successively decompose the space of poses.",
            "The space of hypothesis.",
            "So it's a representation of the space of a recursive partitioning of the space of hypothesis, and you build a classifier by whatever method you want by any method for each set."
        ],
        [
            "Well.",
            "So the advantages are that it's incredibly efficient scene parsing because.",
            "It's when you build the classifier, it's built with a very, very small false negative rate.",
            "A very, very high true detection rate at the expense of false positive which are going to be weaned out as you go down.",
            "So when you reject, you really reject, you can just quit.",
            "You exit the search for that 16 by 16 Patch and move to another one.",
            "So.",
            "Once you once a classifier responds, know all the classifiers that are blow it in the hierarchy or you don't care.",
            "Because none of them represent faces anymore that are, I mean, the probability that there's a face with that representation is exceedingly small, so you have early exit of the search.",
            "By the way, Cascades are a special case where you just have a linear chain and you can build cascades into a hierarchical fashion.",
            "And so it's very, very fast, extremely fast, and it what you have is organized successive focusing on the hard examples.",
            "Now let me since I mentioned the word cascade, let me say it cascades are hopeless tool.",
            "If they don't scale, the problem with the cascade is if you want to apply it to, let's say, frontal view of faces, you have to pick a reference pose cell like.",
            "Positions in a certain range scales in a certain range and then keep doing that over and over again.",
            "OK, if the pose if the pose space is enormous, like a represent much more complex representation than just a position in a scale like Cat, I'll come to that then.",
            "And you take some partition of the pose space.",
            "If the cells of the partition are course and you build a class Cade dedicated to that level of granularity of detecting the pose, then you will invariably have low selectivity.",
            "False positives.",
            "An if the cells are very fine, very precise, there'll be way too many to do for a rich post space, so you're stuck, you can't win, you're stuck on both ends.",
            "You have a you want to have something computationally efficient.",
            "You would have to have a course partitioning the post space with cascades, and if you want to have something that's efficient in an error POV with the selectivity.",
            "In variance tradeoff, you are forced into very fine cells.",
            "And hence successive computation, and there's no win.",
            "So you have to go to a hierarchy.",
            "You can't just have change anymore.",
            "You have to consider a hierarchy with successively."
        ],
        [
            "Fissioning's of the representation space.",
            "The disadvantages of this method is that there is a classifier to train for every cell.",
            "So if you have a rich hierarchy, you've got a lot of classifiers to train, and again, let me emphasize you can train those classifiers any way you wish.",
            "You can use boosting or neural net or decision tree or naive Bayes or anything.",
            "And the learning is very inefficient because of data fragmentation.",
            "Now just put aside the fact that of course we translate the data or reference pose.",
            "Just literally.",
            "Think of partitioning the pose space, whatever your sample set is, whatever your training set is, you're getting, it's getting partitioned.",
            "And so the number of samples available to train each classifier in the hierarchy is quickly diminishing.",
            "So the."
        ],
        [
            "Are the two."
        ],
        [
            "Those are the weaknesses.",
            "Now I'm going to skip over this, but just to say that the method that we propose is a kind of marriage of two things.",
            "It's a marriage of the parts based generative models, variation on which is what's going on in the other room.",
            "And of the holistic, pure learning technique."
        ],
        [
            "So let me be more precise now, so let Y be the space of poses.",
            "So just think of it as the space for faces of let's say position because I said between the eyes.",
            "That's two parameters, scale and.",
            "Tilt four parameters.",
            "And consider a recursive partition.",
            "I mean it just gives me a single partition of the post space.",
            "Ann let YK be a variable that indicates whether or not there is an object in the image with pose in the cell.",
            "So I have capital K Boolean variables signaling whether or not there's an object in the image.",
            "We're fixing an object type fixing an object category with pose in cell."
        ],
        [
            "K. So for example, here are two faces.",
            "Here's the position of these two face."
        ],
        [
            "Is if I superimpose on this?",
            "A decomposition just based on position.",
            "Of the post space, then you know this face is identified.",
            "The Boolean variable for this particular YY 11 should light up an Y.",
            "31 should light up, and the other should be 0.",
            "Ideally, if we correctly classify at that granularity."
        ],
        [
            "Looking for faces."
        ],
        [
            "Showing here the two.",
            "OK, so for typically for faces what most people consider is a representation of the kind of just articulated four parameters.",
            "Basically in our various.",
            "We could also think of it as the position of the two eyes equivalently."
        ],
        [
            "But what about cats?",
            "So the motivation for this was I was giving a talk and we differ on where it was.",
            "About course defined face detection.",
            "And Mumford.",
            "Said Don what about?",
            "Would this method extend to cats?",
            "Ann, I said I don't have any idea.",
            "I think this is about five years ago.",
            "And so that idea stuck with us.",
            "That would course define processing.",
            "Is it general enough?",
            "Flexible enough?",
            "Can it be made to work for a much higher dimensional representation?",
            "Like the pose of a cat."
        ],
        [
            "Never that maybe.",
            "So a still course description, I would argue even course description of a cat is a position of the head.",
            "Position for the belly.",
            "An maybe scale of the head.",
            "Let's just assume that, roughly speaking, the scale of the head takes care of the scale of the cat.",
            "So.",
            "Scale of the head just being the diameter of this circle around the position point of the head."
        ],
        [
            "So let's suppose we're given a training set now, so these are images with pictures of cats in them and some don't have pictures of cats.",
            "So this is the teeth training image, and this is the vector of Boolean variables relative to some partition of the post space.",
            "OK, so it's a standard training set.",
            "Cats are here, here, here, and here, but it's more than just here, it's scale and two positions, but."
        ],
        [
            "Same idea.",
            "And we're interested in building a classifier for each cell.",
            "Let's not worry about the hierarchy for a moment.",
            "Let's just worry about a flat, just single partition of the post space we want to build a classifier for each cell."
        ],
        [
            "Well, what's the training set?",
            "We have, it's exactly.",
            "The big training set restricted to that K. In other words, again without using knowledge of the world about, you know if this is a cat over here.",
            "It's also the same cat moved over without using that knowledge.",
            "Literally the training set you have is just the data that satisfy."
        ],
        [
            "Your constraint that have a cat with pose you know the positive samples here.",
            "When this is one in the teeth image, there's a cat whose poses in cell K. Yes, that's a one and 0 means, no, that's a negative example so."
        ],
        [
            "That's the training set you have.",
            "So you have fragmented the data in order to train one classifier for each partition, obviously right?",
            "You only have order 1 / K as much data available for training the classifier again without using knowledge about the world about transformations which preserve object idente."
        ],
        [
            "Deezen properties."
        ],
        [
            "Now to avoid fragmentation, samples are often normalized imposed, so let's just think about formally what people actually do when they build a cascade or any other.",
            "Device for, let's say face detection.",
            "What do people really do without maybe writing it down explicitly in articulating about what are they actually doing from an abstract?"
        ],
        [
            "Formal point of view.",
            "Well, they are considering a mapping."
        ],
        [
            "From images.",
            "And what they're doing is, for each cell of the post space and from each image they're producing another image, which is kind of a normalized version, so it's just a fancy way of saying, for example, in translation, you're just bringing all your cats to a reference pose and then training with all of them.",
            "Obviously for only you're going to, if you're just going to look for cats in different positions everywhere, forget scale.",
            "Obviously you're going to train with the whole training set right, just by bringing them all to a reference position for.",
            "Let's say it was just the center of the head, or in face detection, just a single point.",
            "But that's what you're doing actually.",
            "When you train, so you're aggregating the data for training by taking advantage of transformations that preserve that.",
            "Are you know?"
        ],
        [
            "Variant."
        ],
        [
            "OK, so let me go on.",
            "So what you do is you train a single classifier.",
            "You transform all the images you're going to have to do this offline and online offline for training and online.",
            "You're going to be doing these global image transforms.",
            "And you know?",
            "Well, OK, that's clear.",
            "And so you have this training set.",
            "You have aggregated all the data and now you just train a single classifier and then just apply it everywhere, right?",
            "OK, that's the basic idea, but that quickly."
        ],
        [
            "Breaks down.",
            "OK, I'm just continuing the definition of this, then train a class train one single classifier on the aggregated data set based on whole image transforms.",
            "And then just apply this mapping on line to get your classifier for cell K. So that is what all methods are doing."
        ],
        [
            "The samples are aggregated for training, but there's a big problem with a more complex full space.",
            "You've got to do this gazillions of times.",
            "Both during training, even if the mapping exists and will come to that in a minute and online, you've got to be doing these transformations."
        ],
        [
            "So.",
            "What about if you have a really complex pose space?",
            "Is there even such a mapping PSI at the image level?",
            "It's not obvious.",
            "Once you have a very complex post base this."
        ],
        [
            "Mapping may not even exist.",
            "So in practice, fragmentation is still the norm to deal with many deformations, but not it doesn't extend to complex deformations.",
            "I'm sorry in practice fragmentation is the norm.",
            "I mean if you have a complex pose, you have to fragment the data and train on the set on the data that you have.",
            "Because there is."
        ],
        [
            "Transformation alright.",
            "But what do you do if there's a complex?"
        ],
        [
            "So the standard method is to go in this direction and then in this direction transform the image to a reference pose and then just have a single base set of features that you enter into the classifier and you build a classifier at that.",
            "Normalized pose or reference pose."
        ],
        [
            "But we're going to suggest another approach, which is go directly.",
            "Through pose indexed features go directly to the.",
            "From the product space.",
            "From for each post cell and each image define a vector of features which have certain properties that will allow you to aggregate all the data for training.",
            "For training one single."
        ],
        [
            "Pacifier.",
            "So let's define throughout the talk.",
            "X is a posed, indexed.",
            "Feature that means its value is not just determined by the image, is not an image functional by itself.",
            "You have to tell me a K oppose cell or just think of it as oppose.",
            "Once you tell me a pose.",
            "And an image.",
            "Then I give you a number."
        ],
        [
            "And let's assume it has the following central property.",
            "Given there is a cat.",
            "Who's poses in cell K?",
            "Look at the probability distribution of this vector.",
            "That probability distribution is invariant.",
            "The probability is the same probability distribution.",
            "These are not the invariant features that.",
            "Never worked the true invariants that people were, you know, talk about a buzz.",
            "You can't imagine the buzz that was going on in the early 90s when people were interested in variant features.",
            "So the the feeling was we've solved the vision problem by finding features which are invariant.",
            "They'll always be one if there's an object independently of its Posen.",
            "And so people search like crazy for algebraic and geometric invariants.",
            "And it failed because there are no invariant features.",
            "But this is."
        ],
        [
            "Very different sense of invariants."
        ],
        [
            "Me.",
            "This is invariants in a stochastic or weak sense.",
            "So another way to put it is if I tell you.",
            "If there's an object at pose with the pose in cell K, and I give you the response of the feature I tell you start to tell you samples from the feature vector.",
            "Can you figure out the pose?",
            "No, you can't.",
            "Because they're identically distributed over the poses."
        ],
        [
            "So if you were parametrizing the scissors by the screw point and the two tips.",
            "You might imagine Pose index features of this nature.",
            "I'm looking for all the edges of a certain type in this window or."
        ],
        [
            "Something of this nature.",
            "Let me show you an artificial example to drive home what a stationary feature is.",
            "My signal is a 1D signal and my poses 2."
        ],
        [
            "Distinguished points.",
            "And basically I'm just saying the signal is going to go along at basically level zero with some noise bump up to level one and come back down to level 0.",
            "It goes up that data one comes back down at data two.",
            "That's my world."
        ],
        [
            "So there's two samples.",
            "Of this very, very simple problem with just a two dimension."
        ],
        [
            "No pose.",
            "Let me define oppose index feature as follows.",
            "I'm going to take the signal just before Theta one.",
            "I'm going to take the signal at Theta one and then just before just app data two and just after Theta two.",
            "I'm going to measure those four points expose index.",
            "So I have a conjecture they don't want they do."
        ],
        [
            "What's the distribution of that?",
            "Going to be?",
            "Well, the distribution is just going to be the this 4 dimensional product of Gaussians has, and there's no Theta in that.",
            "It's invariant, the distribution is invariant."
        ],
        [
            "Suppose.",
            "Alright, well now."
        ],
        [
            "Now I'm going to define.",
            "I'm going to build one single classifier.",
            "With this training set.",
            "An by the invariants property by the stationarity property plus a few other things you have to throw in.",
            "This is again IID.",
            "This has the independent, you know our training sets.",
            "We want them to be from the same distribution, our training samples.",
            "It has that property.",
            "If you think it through the stationarity property is just what you need to still have identical distribution in your training set.",
            "And so it makes sense."
        ],
        [
            "To aggregate all of these, oops.",
            "Makes sense to aggregate all the data and train one single classifier G, so you only train one classifier for the partition.",
            "This is going to allow us to only train one classifier per level of the hierarchy, not one per node.",
            "So the number of classifiers to train is linear in the depth of the hierarchy, not exponential in the depth of the hierarchy, and that's what I mean by efficient learning in this hierarchical context."
        ],
        [
            "Alright, so let's now put this into practice."
        ],
        [
            "So I'm just going to go quickly through this.",
            "The base features that we use at the most at the most elementary level.",
            "We use edge features.",
            "I'm going to skip this, you know, everybody has their version of Edge features for more than 10 years.",
            "We've been using features that are only based on comparisons of differences because they are invariant to grayscale many grayscale transformations.",
            "They have a lot of photometric invariants, so we only use features that, by the way, that's a perfect example of hardwiring invariants.",
            "If I just, well, I will say something about, since I said something about hardwiring invariants earlier, let me follow up appointment.",
            "With a very simple example.",
            "You detect an edge here in this direction.",
            "If this difference is greater than the other six.",
            "So you're comparing intensity differences.",
            "The comparison of intensity differences is invariant to linear transformations of the grayscale.",
            "Not all monotone transformations, but at least to linear, so it has a lot of nice photometric properties.",
            "Your hardwiring net.",
            "You want photometric invariants.",
            "And so you, hardwired in this very."
        ],
        [
            "The elementary way.",
            "OK, so we build edge detectors at different scale."
        ],
        [
            "I'm going to.",
            "I'm going to pass through this."
        ],
        [
            "One scale, second scale."
        ],
        [
            "Midscale this is pretty standard.",
            "And here is we use three types of purported stationary features.",
            "Let me say three types of base features they might to make them stationary.",
            "Features, of course, is another."
        ],
        [
            "Issue, but one is you take a window W an you look at the proportion of edges of a certain type at a certain scale.",
            "That's one of our base features.",
            "Just a window, so it's indexed by a window and edge orientation.",
            "Plus polarity Anna scale."
        ],
        [
            "OK, second type of base features.",
            "Take the histogram of orientations in two windows and take the distance between them, indexed by two windows.",
            "Um?",
            "And that's it.",
            "Oh, in a scale, take the difference of the orientations at a scale.",
            "Thanks for."
        ],
        [
            "And the third is just the L1 distance between the histograms and two windows.",
            "These are the candidate features and what we want to do is take this big world of candidate features and organize them into a vector.",
            "You can think of it as a permutation.",
            "Each for each K you can think of it as a permutation, putting them in a certain order for each cell K and a different order for a different cell.",
            "A different order for a different cell.",
            "Roughly speaking, you can think of it that way.",
            "You can think of pose index features as feature.",
            "The reordering of the base feature set adapted to the post cell."
        ],
        [
            "OK."
        ],
        [
            "So.",
            "We're going to consider 2 frames.",
            "One is just the head frame, so these are the edges of a certain type in this window and all that happens is I'm translating because the only in the head registration.",
            "There's only the center of the head and the scale of the head."
        ],
        [
            "And the second type of candidate features will be taking into account this coordinate system.",
            "So I want to use this distance so I have a little coordinate system here.",
            "I'm not going to normalize in this direction, so let's say this feature in this with this cat.",
            "If I tell you this position, this position and the scale.",
            "This feature is looking for edges of a certain type.",
            "Maybe it's trying to find edges around the body.",
            "Now if this were the pose, the feature is translated to this.",
            "I mean the box is moved and the orientation of the edges that you're looking for is moved.",
            "I don't want to go into details.",
            "We get the idea right, you adapt for the pose."
        ],
        [
            "We happen to use Adaboost to build the base classifier."
        ],
        [
            "You could use anything."
        ],
        [
            "Nelson, I'm going to go through this very quickly.",
            "I'm going to just go to the bottom here.",
            "There's two.",
            "We have 2327 scenes containing 16183 cats.",
            "We use 85% of them for training."
        ],
        [
            "So we've done a lot of experiments.",
            "Laugh OK, it's an inside joke.",
            "Those experiments might have been presented and then we did a lot of experiments.",
            "Just verifying some sort of common sense conclusions that you probably would have formed.",
            "You didn't need to see experiments to believe."
        ],
        [
            "Here are the two common sense conclusion.",
            "If you have a very complex post phase then frag mating the data.",
            "Member very, you have many, many cells.",
            "Let's say 'cause it's a complex post base.",
            "Fragmenting the data is a disaster.",
            "If you just train on the data that satisfies exactly, you know your pose constraint.",
            "You're not going to have an updated to build good classifiers, and you can show that the error rates are horrible."
        ],
        [
            "And the second thing that is also obvious is that a naive brute force, even if they were good these classifiers, if there is a gazillion of these.",
            "Cells if K is gigantic, then obviously it's very inefficient.",
            "Computationally.",
            "You've got just a lot of cells to visit billions.",
            "For like that, if you really start to chunk up the post space or the cap that I talked about in any reasonable way on those five or six or whatever it is."
        ],
        [
            "Alternatively stationary features avoid fragmentation because you're aggregating all the data to train one single classifier."
        ],
        [
            "And the hierarchy this the older stuff Francois's thesis.",
            "Gives you the, avoids the online computational problem.",
            "So in a nutshell, stationary features address efficient learning by building only a single classifier for a partition of the post space.",
            "An hierarchical course defined search addresses efficient on line computation.",
            "In a nutshell."
        ],
        [
            "And we call this a folded hierarchy of classifiers like a fan.",
            "You have this hierarchy, you know, pose in, and then you fold it for training and you unfolded for scene parsing.",
            "Like a fan, you see what I mean, so that you're only training one classifier and then just.",
            "Propagating that classifier appropriately to all the."
        ],
        [
            "Cells so that's course defined search.",
            "I don't know why I'm just reviewing the idea.",
            "You know that you do this test, then you go and do this one, then you go because this was yes you would do both of these.",
            "You only do a test if its parents are executed and positive you would never visit these tests because this was negative and you built these classifiers.",
            "They have a very high true detection rate.",
            "And you would never.",
            "You wouldn't visit these two because this was negative.",
            "This was positive.",
            "This both parents, both ancestors of these two were positive.",
            "And so you visit both of these.",
            "OK, when you're all done, you're conjecturing there's a cat.",
            "If this is a fine post, fairly fine cell.",
            "You're saying I have detected a cat who's poses in this cell."
        ],
        [
            "So how does it work?",
            "I've already said it you visit.",
            "The just the two layer let me just take a two layer example.",
            "So first we're just chunking up on the head position.",
            "Let's say head in the scale.",
            "Let's fix the scale.",
            "Take the scale out so just the head position.",
            "You're just just like I showed at the very beginning.",
            "You're just using a considering a partition of the post space based only on the.",
            "Excuse me, a partition of the pose space based only on the position of the head.",
            "OK at the first layer.",
            "So you do all these classifiers.",
            "You only made one.",
            "We only trained one classifier an using the pose indexed features.",
            "You apply it here, here, here, here, etc.",
            "And so you find these three.",
            "Detections.",
            "All the others are.",
            "Exited I mean were negative.",
            "There's only there's no exit anything, there's just a flat partition.",
            "So then you go around.",
            "You only have to look around the ones you've detected.",
            "And now let's say you have a partition of the belly position relative to those head positions.",
            "It really is a partition of the post space.",
            "You're only going to visit because of the course defined nature of the search and the low false positive false negative rate.",
            "You only have to visit certain cells of the second layer, but basically, in principle you're partitioning all the poses of the cats based on both the head and the belly position, and you visit some of them and you."
        ],
        [
            "Get a couple of detections.",
            "So I'm going to show you some results and just yes.",
            "Stan beside that different image belongs to particular wholesale."
        ],
        [
            "You don't.",
            "You apply the same to every of them.",
            "You just take an image this image and you just start running.",
            "The.",
            "Yeah.",
            "Which cell wait?",
            "No, you haven't labeled training set.",
            "You have a label training set labeled by puzzles by pose.",
            "Oh yeah, of course and I'll come back to that.",
            "And the downside is rich annotation Anwyl.",
            "If there's any time we'll talk about unsupervised versus supervised.",
            "You have a labeled training set, of course."
        ],
        [
            "So OK, so this green is a true positive because the estimated location of the head is reasonably near the true location and the estimated location of the tail of the belly is reasonably near the true one and the others are all examples of false positives because either both are wrong, one is wrong or the other is wrong.",
            "So OK, another thing.",
            "This is not just classification.",
            "This is not this bag of feature stuff.",
            "Saying just yes cat, no cat what we're just doing is parsing a cat, describing texting and describing a cat.",
            "That's what vision is all about.",
            "You know what what's in front of what?",
            "What are the pose wears the head?",
            "Where's the body?",
            "Where's the arms?",
            "Where's the tail?",
            "Where the pause?",
            "It's not just about cat or no cat.",
            "You're not going to get very far that way.",
            "So it's about parsing with people in language called parsing, decomposing the object into its parts and so forth."
        ],
        [
            "So when I show you error rates there at the level of nailing both of these.",
            "Which is a lot harder than just nailing the head."
        ],
        [
            "OK, so this represents a system that would not use stationary features, would just have a head detector and then go and have trained a separate belly detector not in the head belly.",
            "Reference frame would have just trained ahead detector and separately a belly detector and do the head detector and then the belly detective.",
            "OK, so it's the same strategy you visit with your head detector.",
            "Might be almost the same head detector as in the with the stationary features, but then you just go to those around those places you found ahead with your head detector and you run that independent belly detector that wasn't trained with the knowledge of where the conjectured head was.",
            "'cause it doesn't use pose index features that doesn't use stationery features, it's just trained like we always train classifiers."
        ],
        [
            "And it just does a lot better.",
            "So here's the two Roc curves that count, and it's an order of magnitude improvement if you take into.",
            "If you deal with the full pose, you get an order of magnitude improvement in the Roc curve.",
            "So some I don't know .6.",
            "If you're going to get 60% of the cats then you're going to have an average of 1 false positive per 640 by 480.",
            "If you use this.",
            "You know, if you use the program I've advocated, whereas if you just train in the usual way, you'll have ordered 10 false positives.",
            "At 60% detection rate.",
            "Same adjusting for everything, adjusting the same number of weak learners and the boosting everything being identical.",
            "Same size training set you know everything the same."
        ],
        [
            "So this is the thing working.",
            "On a random sample, I'm tell your cats we have 100 and 12,000 pictures of cats that we got from a data set the data site.",
            "Website called Rate My Kitten making acknowledgement in a minute and we used as I said, order 2000 of these 110,000.",
            "So that's a random sample.",
            "Some pretty wild.",
            "You know, cats get into some pretty amazing positions.",
            "It's not easy to detect cats.",
            "You know, specially if you're you know, the goal is to tell you where the head is and where the belly is.",
            "So that's a random sample."
        ],
        [
            "And you know, there's mistakes like crazy, of course.",
            "But you saw the Roc curve.",
            "And it doesn't light up everywhere in in backgrounds, as you can see."
        ],
        [
            "These are picked at random continued OK.",
            "These are just more cats picked at random and background scenes and you're just seeing all the detections.",
            "Open circle for head close circle for belly so.",
            "Well, you get the idea."
        ],
        [
            "Oops.",
            "These are selected false alarms."
        ],
        [
            "And.",
            "OK, I don't have time to go into this.",
            "These are examples of the features that boosting chooses of the stationary features that boosting chooses.",
            "And if you go through it and you, if I were to give you a little vocabulary of what the colors mean and what everything means, you'd say oh it's doing this.",
            "Oh, it's doing that, you know.",
            "I mean many, many of them, not most.",
            "Don't possibly, but many, many have.",
            "A very natural interpretation.",
            "You know it's comparing.",
            "I don't know.",
            "It's comparing the texture in the head area in the belly.",
            "It's comparing the texture in two boxes in the belly.",
            "It's saying that the texture in the belly is different than the texture in the outside.",
            "Once you know where once you have a conjecture for those, you know what's inside and outside you know what's the head in the belly so you can start to make very intelligent build very intelligent features that you would never find otherwise.",
            "And so each of these can."
        ],
        [
            "Can be interpreted."
        ],
        [
            "So in conclusion, folder hierarchy of classifiers is it's very efficient for online learning because of data aggregation, 'cause you're only building 1 classifier per."
        ],
        [
            "Level of the hierarchy and it's very efficient because it's a hierarchical."
        ],
        [
            "Course defined.",
            "Search for scene processing."
        ],
        [
            "It can."
        ],
        [
            "Finds the strength of.",
            "Template matching.",
            "Machine learning is what I mean by the second one, holistic machine learning and."
        ],
        [
            "Rockel search."
        ],
        [
            "How?"
        ],
        [
            "However, there's two drawbacks.",
            "One is, you need richly annotated data.",
            "Some of it I don't.",
            "We don't know how much.",
            "When she didn't investigating what happens if we start now decreasing the amount of annotated data that we use?",
            "What's the breakpoint?",
            "Nope, we trained with the thousands that are 2000.",
            "What's going to happen?",
            "We actually haven't done that.",
            "We just get one.",
            "11 training at one level and you have to design the stationary features and we're learning how to do that automatically.",
            "Automatically design stationary features."
        ],
        [
            "So that's the acknowledgment to the website.",
            "Alright, and so in summary, I can't help but believe that you know the route to success, at least in the vision problem is not in deep learning.",
            "It's in deep representations.",
            "It's in hard wiring and variance to the greatest extent possible, always keeping in mind both efficient learning and efficiency in parsing.",
            "Thank you.",
            "Correlation that may happen in the labor, neighborhoods or poses, no.",
            "I mean, you mean in the sense that.",
            "A joint distribution on the pose variables is not entering the story explicitly, it's only entering Internet.",
            "Really, the hierarchy is associated with the factory.",
            "You can think of it is associated with a decomposition of the pose distribution into probability of belly given head times probability of head.",
            "I'm being simple minded, it's more complex than that.",
            "And so that's driving the design of the hierarchy is a factorization of the pose distribution into conditional into products of conditional probabilities.",
            "And if you had, if you wanted to look for a tail, what's the right thing to do is to freeze the head, look at belly given ahead and look at tail.",
            "Given belly, head 'cause that'll tell you where to look for the tail.",
            "So if you were to go a level deeper with the tail you would to that extent that I just described, you would use that distribution and that would you know you know that if the head is here, where can the belly be if the head is here in the if the head is here in the bellies here you know about where the tail can be, so to that extent would use the.",
            "Dependency structure among the pose variables.",
            "Post labels or do you have any?",
            "Could potentially use learning to essentially cluster the data at each level.",
            "Discover.",
            "First off, right?",
            "You could use unsupervised learning.",
            "You're suggesting to annotate the data.",
            "Well that would be great.",
            "That would be great.",
            "In the representation right?",
            "And so if you try to consider corrupted YK?",
            "When when constructing the invariant features you mean add noise to the labels.",
            "I don't think we've ever done that, no.",
            "Having things which are preserving the distribution is my come up with something just as good but random.",
            "When I ran oh, you don't mean totally random.",
            "You mean you could tolerate some level.",
            "Some flip noise.",
            "Let's say I take every time like it, huh?",
            "Is there a question?",
            "But if it doesn't pop too much, then the extension would be well.",
            "I think if you just totally permuta labor just thing would fall apart."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Thanks for inviting me.",
                    "label": 0
                },
                {
                    "sent": "Going to take a different point of view.",
                    "label": 0
                },
                {
                    "sent": "It's interesting to me that there's this session.",
                    "label": 0
                },
                {
                    "sent": "About learning and there's another.",
                    "label": 0
                },
                {
                    "sent": "Workshop going on.",
                    "label": 0
                },
                {
                    "sent": "About grammars provision and the points of view are so different.",
                    "label": 0
                },
                {
                    "sent": "Here there's a buzz this year.",
                    "label": 0
                },
                {
                    "sent": "I've never been an IFS, but there's always a buzz about something.",
                    "label": 0
                },
                {
                    "sent": "There's a buzz this year about.",
                    "label": 0
                },
                {
                    "sent": "Deep, deep architectures.",
                    "label": 0
                },
                {
                    "sent": "Jeff's 2006 paper.",
                    "label": 0
                },
                {
                    "sent": "Deep learning, I'm not sure what to call it.",
                    "label": 0
                },
                {
                    "sent": "There's no corresponding buzz at the moment in the grammar thing, although everybody is converging back to grammars from the generative point of view.",
                    "label": 0
                },
                {
                    "sent": "But the difference that I see in a nutshell is the belief here is in learning.",
                    "label": 0
                },
                {
                    "sent": "Deep architectures, hierarchical architectures, learning about the world.",
                    "label": 0
                },
                {
                    "sent": "And over in the other room, the feeling is that learning is hopeless.",
                    "label": 0
                },
                {
                    "sent": "It will never happen.",
                    "label": 0
                },
                {
                    "sent": "It's not going to happen this year, and it's not going to happen 10 years from now.",
                    "label": 0
                },
                {
                    "sent": "It didn't happen 10 years ago when people thought it would have happened by this year, at least, learning to the point where you can do scene interpretation, semantics, interpretation.",
                    "label": 0
                },
                {
                    "sent": "The view in the other room is that you're never going to learn everything.",
                    "label": 0
                },
                {
                    "sent": "I don't care how many layers and how efficiently you learn and how clever the learning is, layer by layer.",
                    "label": 0
                },
                {
                    "sent": "It's just never going to happen.",
                    "label": 0
                },
                {
                    "sent": "And because there's just too much to learn, it doesn't matter how many examples you have.",
                    "label": 0
                },
                {
                    "sent": "10 to the 100 doesn't matter.",
                    "label": 0
                },
                {
                    "sent": "There's too much to learn.",
                    "label": 0
                },
                {
                    "sent": "You have to hard wire things and you have to roll up your sleeves and deal with invariants.",
                    "label": 0
                },
                {
                    "sent": "The fact that this is the same thing, not just translated that simple but scaled included.",
                    "label": 0
                },
                {
                    "sent": "In infinite variations on this very device etc.",
                    "label": 0
                },
                {
                    "sent": "An until you deal with invariants.",
                    "label": 0
                },
                {
                    "sent": "Some things are in front of others next to others, including others, and make the system invariant to all the photometric and geometric transformations that we know.",
                    "label": 0
                },
                {
                    "sent": "Preserve the names of things.",
                    "label": 0
                },
                {
                    "sent": "Until you hardwire that invariants.",
                    "label": 0
                },
                {
                    "sent": "You're never going to come close to solving the vision problem.",
                    "label": 0
                },
                {
                    "sent": "You might.",
                    "label": 0
                },
                {
                    "sent": "Detect isolated faces in our frontal view.",
                    "label": 0
                },
                {
                    "sent": "You might get up to 99, six or something on M NIST, but you're not going to go to 99.9.",
                    "label": 0
                },
                {
                    "sent": "You're not going to.",
                    "label": 0
                },
                {
                    "sent": "You know, detect somebody who's sitting in front of you on a.",
                    "label": 0
                },
                {
                    "sent": "Bus at night and you detect them from the back of their head.",
                    "label": 0
                },
                {
                    "sent": "It's not going to happen with your deep architectures until Invariances brought into the picture.",
                    "label": 0
                },
                {
                    "sent": "So that would be the point of view.",
                    "label": 0
                },
                {
                    "sent": "Not everybody.",
                    "label": 0
                },
                {
                    "sent": "But I feel that way and I want to present a somewhat different point of view today.",
                    "label": 0
                },
                {
                    "sent": "There are some shared themes I've been interested in efficient learning for years and I used to summarize our whole research program by saying that.",
                    "label": 0
                },
                {
                    "sent": "Efficiency is a very powerful organizing principle for vision.",
                    "label": 0
                },
                {
                    "sent": "I believe it is and.",
                    "label": 0
                },
                {
                    "sent": "But I inefficiency from the point of view of both training and online computation.",
                    "label": 0
                },
                {
                    "sent": "Most of the work that I've done over the last 10 or 15 years was concentrated on the online part through course define search course defined processing of.",
                    "label": 0
                },
                {
                    "sent": "Data.",
                    "label": 0
                },
                {
                    "sent": "And more recently, with Francois sort of round two with Francois around one was his dissertation in the 90s and it was about course define face detection.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And round two has been to overcome the principle liability of that research which was there was too much learning going on too many classifiers to train in our hierarchy of classifiers, one per node and for a deep architecture.",
                    "label": 0
                },
                {
                    "sent": "That's a lot of classifiers to train.",
                    "label": 0
                },
                {
                    "sent": "And so in the last few, the work I'm going to mainly report on today is in the last few years we've addressed the efficiency from the learning side.",
                    "label": 0
                },
                {
                    "sent": "So his thesis was efficiency from the on line computational side and more recently we joined up again to attack efficiency from the learning side so.",
                    "label": 0
                },
                {
                    "sent": "In this problem you want to detect the faces frontal views but arbitrarily cluttered image.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And the approach we took was course defined processing of the space of poses.",
                    "label": 0
                },
                {
                    "sent": "So just basically I don't want to spend much time on this and want to spend the time on the other things I alluded to.",
                    "label": 0
                },
                {
                    "sent": "But basically the idea is that here are all the poses.",
                    "label": 0
                },
                {
                    "sent": "They're not all there.",
                    "label": 0
                },
                {
                    "sent": "All the poses, let's say for faces with the position between the eyes, let's say fluctuate ING at a 16 by 16 window, the distance between the eyes and some scale range 8 to 16 and some range of tilts so but it's a big post.",
                    "label": 0
                },
                {
                    "sent": "It's a big chunk of the post space.",
                    "label": 0
                },
                {
                    "sent": "And basically, you're just going to vision successfully.",
                    "label": 0
                },
                {
                    "sent": "Visit different 16 by 16 regions in the scene or non overlapping process the data in the surrounding area looking for faces that are centered in that 16 by 16 with a scale that some range roughly 2 to one you'll downsample to get bigger faces, downsample again to get faces you know whatever, 32 to 64, etc.",
                    "label": 0
                },
                {
                    "sent": "And so.",
                    "label": 0
                },
                {
                    "sent": "Here is if you're looking at the position of the two eyes and the mouth or whatever it is you see there are many, many representations here and then successively finer by the time you get down to these least pose cells, training data available to train that one is in principle is limited to faces which satisfy this constraint.",
                    "label": 0
                },
                {
                    "sent": "So first you might have a split.",
                    "label": 0
                },
                {
                    "sent": "For example, you might take the 16 by 16 and split into four 8 by 8.",
                    "label": 0
                },
                {
                    "sent": "So there might be a binary split next which divides into big scale small scale 8 to 1212 to 16 but.",
                    "label": 0
                },
                {
                    "sent": "In the eyes, then there might be a tilt scale left, tilt, right tilt, split left till right till you recursively successively decompose the space of poses.",
                    "label": 0
                },
                {
                    "sent": "The space of hypothesis.",
                    "label": 0
                },
                {
                    "sent": "So it's a representation of the space of a recursive partitioning of the space of hypothesis, and you build a classifier by whatever method you want by any method for each set.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Well.",
                    "label": 0
                },
                {
                    "sent": "So the advantages are that it's incredibly efficient scene parsing because.",
                    "label": 1
                },
                {
                    "sent": "It's when you build the classifier, it's built with a very, very small false negative rate.",
                    "label": 0
                },
                {
                    "sent": "A very, very high true detection rate at the expense of false positive which are going to be weaned out as you go down.",
                    "label": 0
                },
                {
                    "sent": "So when you reject, you really reject, you can just quit.",
                    "label": 0
                },
                {
                    "sent": "You exit the search for that 16 by 16 Patch and move to another one.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Once you once a classifier responds, know all the classifiers that are blow it in the hierarchy or you don't care.",
                    "label": 0
                },
                {
                    "sent": "Because none of them represent faces anymore that are, I mean, the probability that there's a face with that representation is exceedingly small, so you have early exit of the search.",
                    "label": 0
                },
                {
                    "sent": "By the way, Cascades are a special case where you just have a linear chain and you can build cascades into a hierarchical fashion.",
                    "label": 1
                },
                {
                    "sent": "And so it's very, very fast, extremely fast, and it what you have is organized successive focusing on the hard examples.",
                    "label": 0
                },
                {
                    "sent": "Now let me since I mentioned the word cascade, let me say it cascades are hopeless tool.",
                    "label": 0
                },
                {
                    "sent": "If they don't scale, the problem with the cascade is if you want to apply it to, let's say, frontal view of faces, you have to pick a reference pose cell like.",
                    "label": 0
                },
                {
                    "sent": "Positions in a certain range scales in a certain range and then keep doing that over and over again.",
                    "label": 0
                },
                {
                    "sent": "OK, if the pose if the pose space is enormous, like a represent much more complex representation than just a position in a scale like Cat, I'll come to that then.",
                    "label": 0
                },
                {
                    "sent": "And you take some partition of the pose space.",
                    "label": 0
                },
                {
                    "sent": "If the cells of the partition are course and you build a class Cade dedicated to that level of granularity of detecting the pose, then you will invariably have low selectivity.",
                    "label": 0
                },
                {
                    "sent": "False positives.",
                    "label": 0
                },
                {
                    "sent": "An if the cells are very fine, very precise, there'll be way too many to do for a rich post space, so you're stuck, you can't win, you're stuck on both ends.",
                    "label": 0
                },
                {
                    "sent": "You have a you want to have something computationally efficient.",
                    "label": 0
                },
                {
                    "sent": "You would have to have a course partitioning the post space with cascades, and if you want to have something that's efficient in an error POV with the selectivity.",
                    "label": 0
                },
                {
                    "sent": "In variance tradeoff, you are forced into very fine cells.",
                    "label": 0
                },
                {
                    "sent": "And hence successive computation, and there's no win.",
                    "label": 0
                },
                {
                    "sent": "So you have to go to a hierarchy.",
                    "label": 0
                },
                {
                    "sent": "You can't just have change anymore.",
                    "label": 0
                },
                {
                    "sent": "You have to consider a hierarchy with successively.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Fissioning's of the representation space.",
                    "label": 0
                },
                {
                    "sent": "The disadvantages of this method is that there is a classifier to train for every cell.",
                    "label": 0
                },
                {
                    "sent": "So if you have a rich hierarchy, you've got a lot of classifiers to train, and again, let me emphasize you can train those classifiers any way you wish.",
                    "label": 1
                },
                {
                    "sent": "You can use boosting or neural net or decision tree or naive Bayes or anything.",
                    "label": 0
                },
                {
                    "sent": "And the learning is very inefficient because of data fragmentation.",
                    "label": 0
                },
                {
                    "sent": "Now just put aside the fact that of course we translate the data or reference pose.",
                    "label": 0
                },
                {
                    "sent": "Just literally.",
                    "label": 0
                },
                {
                    "sent": "Think of partitioning the pose space, whatever your sample set is, whatever your training set is, you're getting, it's getting partitioned.",
                    "label": 0
                },
                {
                    "sent": "And so the number of samples available to train each classifier in the hierarchy is quickly diminishing.",
                    "label": 0
                },
                {
                    "sent": "So the.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Are the two.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Those are the weaknesses.",
                    "label": 0
                },
                {
                    "sent": "Now I'm going to skip over this, but just to say that the method that we propose is a kind of marriage of two things.",
                    "label": 0
                },
                {
                    "sent": "It's a marriage of the parts based generative models, variation on which is what's going on in the other room.",
                    "label": 0
                },
                {
                    "sent": "And of the holistic, pure learning technique.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So let me be more precise now, so let Y be the space of poses.",
                    "label": 1
                },
                {
                    "sent": "So just think of it as the space for faces of let's say position because I said between the eyes.",
                    "label": 0
                },
                {
                    "sent": "That's two parameters, scale and.",
                    "label": 0
                },
                {
                    "sent": "Tilt four parameters.",
                    "label": 0
                },
                {
                    "sent": "And consider a recursive partition.",
                    "label": 0
                },
                {
                    "sent": "I mean it just gives me a single partition of the post space.",
                    "label": 1
                },
                {
                    "sent": "Ann let YK be a variable that indicates whether or not there is an object in the image with pose in the cell.",
                    "label": 0
                },
                {
                    "sent": "So I have capital K Boolean variables signaling whether or not there's an object in the image.",
                    "label": 0
                },
                {
                    "sent": "We're fixing an object type fixing an object category with pose in cell.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "K. So for example, here are two faces.",
                    "label": 0
                },
                {
                    "sent": "Here's the position of these two face.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is if I superimpose on this?",
                    "label": 0
                },
                {
                    "sent": "A decomposition just based on position.",
                    "label": 0
                },
                {
                    "sent": "Of the post space, then you know this face is identified.",
                    "label": 0
                },
                {
                    "sent": "The Boolean variable for this particular YY 11 should light up an Y.",
                    "label": 0
                },
                {
                    "sent": "31 should light up, and the other should be 0.",
                    "label": 0
                },
                {
                    "sent": "Ideally, if we correctly classify at that granularity.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Looking for faces.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Showing here the two.",
                    "label": 0
                },
                {
                    "sent": "OK, so for typically for faces what most people consider is a representation of the kind of just articulated four parameters.",
                    "label": 1
                },
                {
                    "sent": "Basically in our various.",
                    "label": 0
                },
                {
                    "sent": "We could also think of it as the position of the two eyes equivalently.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But what about cats?",
                    "label": 0
                },
                {
                    "sent": "So the motivation for this was I was giving a talk and we differ on where it was.",
                    "label": 0
                },
                {
                    "sent": "About course defined face detection.",
                    "label": 0
                },
                {
                    "sent": "And Mumford.",
                    "label": 0
                },
                {
                    "sent": "Said Don what about?",
                    "label": 0
                },
                {
                    "sent": "Would this method extend to cats?",
                    "label": 0
                },
                {
                    "sent": "Ann, I said I don't have any idea.",
                    "label": 0
                },
                {
                    "sent": "I think this is about five years ago.",
                    "label": 0
                },
                {
                    "sent": "And so that idea stuck with us.",
                    "label": 0
                },
                {
                    "sent": "That would course define processing.",
                    "label": 0
                },
                {
                    "sent": "Is it general enough?",
                    "label": 0
                },
                {
                    "sent": "Flexible enough?",
                    "label": 0
                },
                {
                    "sent": "Can it be made to work for a much higher dimensional representation?",
                    "label": 0
                },
                {
                    "sent": "Like the pose of a cat.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Never that maybe.",
                    "label": 0
                },
                {
                    "sent": "So a still course description, I would argue even course description of a cat is a position of the head.",
                    "label": 0
                },
                {
                    "sent": "Position for the belly.",
                    "label": 0
                },
                {
                    "sent": "An maybe scale of the head.",
                    "label": 0
                },
                {
                    "sent": "Let's just assume that, roughly speaking, the scale of the head takes care of the scale of the cat.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Scale of the head just being the diameter of this circle around the position point of the head.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So let's suppose we're given a training set now, so these are images with pictures of cats in them and some don't have pictures of cats.",
                    "label": 1
                },
                {
                    "sent": "So this is the teeth training image, and this is the vector of Boolean variables relative to some partition of the post space.",
                    "label": 0
                },
                {
                    "sent": "OK, so it's a standard training set.",
                    "label": 0
                },
                {
                    "sent": "Cats are here, here, here, and here, but it's more than just here, it's scale and two positions, but.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Same idea.",
                    "label": 0
                },
                {
                    "sent": "And we're interested in building a classifier for each cell.",
                    "label": 1
                },
                {
                    "sent": "Let's not worry about the hierarchy for a moment.",
                    "label": 0
                },
                {
                    "sent": "Let's just worry about a flat, just single partition of the post space we want to build a classifier for each cell.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Well, what's the training set?",
                    "label": 0
                },
                {
                    "sent": "We have, it's exactly.",
                    "label": 0
                },
                {
                    "sent": "The big training set restricted to that K. In other words, again without using knowledge of the world about, you know if this is a cat over here.",
                    "label": 0
                },
                {
                    "sent": "It's also the same cat moved over without using that knowledge.",
                    "label": 0
                },
                {
                    "sent": "Literally the training set you have is just the data that satisfy.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Your constraint that have a cat with pose you know the positive samples here.",
                    "label": 0
                },
                {
                    "sent": "When this is one in the teeth image, there's a cat whose poses in cell K. Yes, that's a one and 0 means, no, that's a negative example so.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "That's the training set you have.",
                    "label": 1
                },
                {
                    "sent": "So you have fragmented the data in order to train one classifier for each partition, obviously right?",
                    "label": 0
                },
                {
                    "sent": "You only have order 1 / K as much data available for training the classifier again without using knowledge about the world about transformations which preserve object idente.",
                    "label": 1
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Deezen properties.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now to avoid fragmentation, samples are often normalized imposed, so let's just think about formally what people actually do when they build a cascade or any other.",
                    "label": 1
                },
                {
                    "sent": "Device for, let's say face detection.",
                    "label": 0
                },
                {
                    "sent": "What do people really do without maybe writing it down explicitly in articulating about what are they actually doing from an abstract?",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Formal point of view.",
                    "label": 0
                },
                {
                    "sent": "Well, they are considering a mapping.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "From images.",
                    "label": 0
                },
                {
                    "sent": "And what they're doing is, for each cell of the post space and from each image they're producing another image, which is kind of a normalized version, so it's just a fancy way of saying, for example, in translation, you're just bringing all your cats to a reference pose and then training with all of them.",
                    "label": 0
                },
                {
                    "sent": "Obviously for only you're going to, if you're just going to look for cats in different positions everywhere, forget scale.",
                    "label": 0
                },
                {
                    "sent": "Obviously you're going to train with the whole training set right, just by bringing them all to a reference position for.",
                    "label": 0
                },
                {
                    "sent": "Let's say it was just the center of the head, or in face detection, just a single point.",
                    "label": 0
                },
                {
                    "sent": "But that's what you're doing actually.",
                    "label": 0
                },
                {
                    "sent": "When you train, so you're aggregating the data for training by taking advantage of transformations that preserve that.",
                    "label": 0
                },
                {
                    "sent": "Are you know?",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Variant.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so let me go on.",
                    "label": 0
                },
                {
                    "sent": "So what you do is you train a single classifier.",
                    "label": 1
                },
                {
                    "sent": "You transform all the images you're going to have to do this offline and online offline for training and online.",
                    "label": 0
                },
                {
                    "sent": "You're going to be doing these global image transforms.",
                    "label": 0
                },
                {
                    "sent": "And you know?",
                    "label": 0
                },
                {
                    "sent": "Well, OK, that's clear.",
                    "label": 1
                },
                {
                    "sent": "And so you have this training set.",
                    "label": 0
                },
                {
                    "sent": "You have aggregated all the data and now you just train a single classifier and then just apply it everywhere, right?",
                    "label": 0
                },
                {
                    "sent": "OK, that's the basic idea, but that quickly.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Breaks down.",
                    "label": 0
                },
                {
                    "sent": "OK, I'm just continuing the definition of this, then train a class train one single classifier on the aggregated data set based on whole image transforms.",
                    "label": 1
                },
                {
                    "sent": "And then just apply this mapping on line to get your classifier for cell K. So that is what all methods are doing.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The samples are aggregated for training, but there's a big problem with a more complex full space.",
                    "label": 0
                },
                {
                    "sent": "You've got to do this gazillions of times.",
                    "label": 0
                },
                {
                    "sent": "Both during training, even if the mapping exists and will come to that in a minute and online, you've got to be doing these transformations.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "What about if you have a really complex pose space?",
                    "label": 1
                },
                {
                    "sent": "Is there even such a mapping PSI at the image level?",
                    "label": 0
                },
                {
                    "sent": "It's not obvious.",
                    "label": 0
                },
                {
                    "sent": "Once you have a very complex post base this.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Mapping may not even exist.",
                    "label": 0
                },
                {
                    "sent": "So in practice, fragmentation is still the norm to deal with many deformations, but not it doesn't extend to complex deformations.",
                    "label": 1
                },
                {
                    "sent": "I'm sorry in practice fragmentation is the norm.",
                    "label": 0
                },
                {
                    "sent": "I mean if you have a complex pose, you have to fragment the data and train on the set on the data that you have.",
                    "label": 0
                },
                {
                    "sent": "Because there is.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Transformation alright.",
                    "label": 0
                },
                {
                    "sent": "But what do you do if there's a complex?",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the standard method is to go in this direction and then in this direction transform the image to a reference pose and then just have a single base set of features that you enter into the classifier and you build a classifier at that.",
                    "label": 0
                },
                {
                    "sent": "Normalized pose or reference pose.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But we're going to suggest another approach, which is go directly.",
                    "label": 0
                },
                {
                    "sent": "Through pose indexed features go directly to the.",
                    "label": 0
                },
                {
                    "sent": "From the product space.",
                    "label": 0
                },
                {
                    "sent": "From for each post cell and each image define a vector of features which have certain properties that will allow you to aggregate all the data for training.",
                    "label": 0
                },
                {
                    "sent": "For training one single.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Pacifier.",
                    "label": 0
                },
                {
                    "sent": "So let's define throughout the talk.",
                    "label": 0
                },
                {
                    "sent": "X is a posed, indexed.",
                    "label": 0
                },
                {
                    "sent": "Feature that means its value is not just determined by the image, is not an image functional by itself.",
                    "label": 0
                },
                {
                    "sent": "You have to tell me a K oppose cell or just think of it as oppose.",
                    "label": 0
                },
                {
                    "sent": "Once you tell me a pose.",
                    "label": 0
                },
                {
                    "sent": "And an image.",
                    "label": 0
                },
                {
                    "sent": "Then I give you a number.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And let's assume it has the following central property.",
                    "label": 0
                },
                {
                    "sent": "Given there is a cat.",
                    "label": 0
                },
                {
                    "sent": "Who's poses in cell K?",
                    "label": 0
                },
                {
                    "sent": "Look at the probability distribution of this vector.",
                    "label": 0
                },
                {
                    "sent": "That probability distribution is invariant.",
                    "label": 0
                },
                {
                    "sent": "The probability is the same probability distribution.",
                    "label": 1
                },
                {
                    "sent": "These are not the invariant features that.",
                    "label": 0
                },
                {
                    "sent": "Never worked the true invariants that people were, you know, talk about a buzz.",
                    "label": 0
                },
                {
                    "sent": "You can't imagine the buzz that was going on in the early 90s when people were interested in variant features.",
                    "label": 0
                },
                {
                    "sent": "So the the feeling was we've solved the vision problem by finding features which are invariant.",
                    "label": 0
                },
                {
                    "sent": "They'll always be one if there's an object independently of its Posen.",
                    "label": 0
                },
                {
                    "sent": "And so people search like crazy for algebraic and geometric invariants.",
                    "label": 0
                },
                {
                    "sent": "And it failed because there are no invariant features.",
                    "label": 0
                },
                {
                    "sent": "But this is.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Very different sense of invariants.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Me.",
                    "label": 0
                },
                {
                    "sent": "This is invariants in a stochastic or weak sense.",
                    "label": 0
                },
                {
                    "sent": "So another way to put it is if I tell you.",
                    "label": 0
                },
                {
                    "sent": "If there's an object at pose with the pose in cell K, and I give you the response of the feature I tell you start to tell you samples from the feature vector.",
                    "label": 0
                },
                {
                    "sent": "Can you figure out the pose?",
                    "label": 0
                },
                {
                    "sent": "No, you can't.",
                    "label": 0
                },
                {
                    "sent": "Because they're identically distributed over the poses.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So if you were parametrizing the scissors by the screw point and the two tips.",
                    "label": 0
                },
                {
                    "sent": "You might imagine Pose index features of this nature.",
                    "label": 0
                },
                {
                    "sent": "I'm looking for all the edges of a certain type in this window or.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Something of this nature.",
                    "label": 0
                },
                {
                    "sent": "Let me show you an artificial example to drive home what a stationary feature is.",
                    "label": 0
                },
                {
                    "sent": "My signal is a 1D signal and my poses 2.",
                    "label": 1
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Distinguished points.",
                    "label": 0
                },
                {
                    "sent": "And basically I'm just saying the signal is going to go along at basically level zero with some noise bump up to level one and come back down to level 0.",
                    "label": 0
                },
                {
                    "sent": "It goes up that data one comes back down at data two.",
                    "label": 0
                },
                {
                    "sent": "That's my world.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So there's two samples.",
                    "label": 0
                },
                {
                    "sent": "Of this very, very simple problem with just a two dimension.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "No pose.",
                    "label": 0
                },
                {
                    "sent": "Let me define oppose index feature as follows.",
                    "label": 0
                },
                {
                    "sent": "I'm going to take the signal just before Theta one.",
                    "label": 0
                },
                {
                    "sent": "I'm going to take the signal at Theta one and then just before just app data two and just after Theta two.",
                    "label": 0
                },
                {
                    "sent": "I'm going to measure those four points expose index.",
                    "label": 0
                },
                {
                    "sent": "So I have a conjecture they don't want they do.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "What's the distribution of that?",
                    "label": 0
                },
                {
                    "sent": "Going to be?",
                    "label": 0
                },
                {
                    "sent": "Well, the distribution is just going to be the this 4 dimensional product of Gaussians has, and there's no Theta in that.",
                    "label": 0
                },
                {
                    "sent": "It's invariant, the distribution is invariant.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Suppose.",
                    "label": 0
                },
                {
                    "sent": "Alright, well now.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now I'm going to define.",
                    "label": 0
                },
                {
                    "sent": "I'm going to build one single classifier.",
                    "label": 1
                },
                {
                    "sent": "With this training set.",
                    "label": 0
                },
                {
                    "sent": "An by the invariants property by the stationarity property plus a few other things you have to throw in.",
                    "label": 0
                },
                {
                    "sent": "This is again IID.",
                    "label": 0
                },
                {
                    "sent": "This has the independent, you know our training sets.",
                    "label": 0
                },
                {
                    "sent": "We want them to be from the same distribution, our training samples.",
                    "label": 0
                },
                {
                    "sent": "It has that property.",
                    "label": 0
                },
                {
                    "sent": "If you think it through the stationarity property is just what you need to still have identical distribution in your training set.",
                    "label": 0
                },
                {
                    "sent": "And so it makes sense.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "To aggregate all of these, oops.",
                    "label": 0
                },
                {
                    "sent": "Makes sense to aggregate all the data and train one single classifier G, so you only train one classifier for the partition.",
                    "label": 1
                },
                {
                    "sent": "This is going to allow us to only train one classifier per level of the hierarchy, not one per node.",
                    "label": 0
                },
                {
                    "sent": "So the number of classifiers to train is linear in the depth of the hierarchy, not exponential in the depth of the hierarchy, and that's what I mean by efficient learning in this hierarchical context.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Alright, so let's now put this into practice.",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So I'm just going to go quickly through this.",
                    "label": 0
                },
                {
                    "sent": "The base features that we use at the most at the most elementary level.",
                    "label": 0
                },
                {
                    "sent": "We use edge features.",
                    "label": 0
                },
                {
                    "sent": "I'm going to skip this, you know, everybody has their version of Edge features for more than 10 years.",
                    "label": 0
                },
                {
                    "sent": "We've been using features that are only based on comparisons of differences because they are invariant to grayscale many grayscale transformations.",
                    "label": 0
                },
                {
                    "sent": "They have a lot of photometric invariants, so we only use features that, by the way, that's a perfect example of hardwiring invariants.",
                    "label": 0
                },
                {
                    "sent": "If I just, well, I will say something about, since I said something about hardwiring invariants earlier, let me follow up appointment.",
                    "label": 0
                },
                {
                    "sent": "With a very simple example.",
                    "label": 0
                },
                {
                    "sent": "You detect an edge here in this direction.",
                    "label": 0
                },
                {
                    "sent": "If this difference is greater than the other six.",
                    "label": 0
                },
                {
                    "sent": "So you're comparing intensity differences.",
                    "label": 0
                },
                {
                    "sent": "The comparison of intensity differences is invariant to linear transformations of the grayscale.",
                    "label": 0
                },
                {
                    "sent": "Not all monotone transformations, but at least to linear, so it has a lot of nice photometric properties.",
                    "label": 0
                },
                {
                    "sent": "Your hardwiring net.",
                    "label": 0
                },
                {
                    "sent": "You want photometric invariants.",
                    "label": 0
                },
                {
                    "sent": "And so you, hardwired in this very.",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The elementary way.",
                    "label": 0
                },
                {
                    "sent": "OK, so we build edge detectors at different scale.",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I'm going to.",
                    "label": 0
                },
                {
                    "sent": "I'm going to pass through this.",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "One scale, second scale.",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Midscale this is pretty standard.",
                    "label": 0
                },
                {
                    "sent": "And here is we use three types of purported stationary features.",
                    "label": 0
                },
                {
                    "sent": "Let me say three types of base features they might to make them stationary.",
                    "label": 0
                },
                {
                    "sent": "Features, of course, is another.",
                    "label": 0
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Issue, but one is you take a window W an you look at the proportion of edges of a certain type at a certain scale.",
                    "label": 1
                },
                {
                    "sent": "That's one of our base features.",
                    "label": 0
                },
                {
                    "sent": "Just a window, so it's indexed by a window and edge orientation.",
                    "label": 0
                },
                {
                    "sent": "Plus polarity Anna scale.",
                    "label": 0
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, second type of base features.",
                    "label": 1
                },
                {
                    "sent": "Take the histogram of orientations in two windows and take the distance between them, indexed by two windows.",
                    "label": 1
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "And that's it.",
                    "label": 1
                },
                {
                    "sent": "Oh, in a scale, take the difference of the orientations at a scale.",
                    "label": 0
                },
                {
                    "sent": "Thanks for.",
                    "label": 0
                }
            ]
        },
        "clip_55": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And the third is just the L1 distance between the histograms and two windows.",
                    "label": 1
                },
                {
                    "sent": "These are the candidate features and what we want to do is take this big world of candidate features and organize them into a vector.",
                    "label": 0
                },
                {
                    "sent": "You can think of it as a permutation.",
                    "label": 0
                },
                {
                    "sent": "Each for each K you can think of it as a permutation, putting them in a certain order for each cell K and a different order for a different cell.",
                    "label": 0
                },
                {
                    "sent": "A different order for a different cell.",
                    "label": 0
                },
                {
                    "sent": "Roughly speaking, you can think of it that way.",
                    "label": 0
                },
                {
                    "sent": "You can think of pose index features as feature.",
                    "label": 0
                },
                {
                    "sent": "The reordering of the base feature set adapted to the post cell.",
                    "label": 0
                }
            ]
        },
        "clip_56": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_57": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "We're going to consider 2 frames.",
                    "label": 0
                },
                {
                    "sent": "One is just the head frame, so these are the edges of a certain type in this window and all that happens is I'm translating because the only in the head registration.",
                    "label": 1
                },
                {
                    "sent": "There's only the center of the head and the scale of the head.",
                    "label": 0
                }
            ]
        },
        "clip_58": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And the second type of candidate features will be taking into account this coordinate system.",
                    "label": 0
                },
                {
                    "sent": "So I want to use this distance so I have a little coordinate system here.",
                    "label": 0
                },
                {
                    "sent": "I'm not going to normalize in this direction, so let's say this feature in this with this cat.",
                    "label": 0
                },
                {
                    "sent": "If I tell you this position, this position and the scale.",
                    "label": 0
                },
                {
                    "sent": "This feature is looking for edges of a certain type.",
                    "label": 0
                },
                {
                    "sent": "Maybe it's trying to find edges around the body.",
                    "label": 0
                },
                {
                    "sent": "Now if this were the pose, the feature is translated to this.",
                    "label": 0
                },
                {
                    "sent": "I mean the box is moved and the orientation of the edges that you're looking for is moved.",
                    "label": 0
                },
                {
                    "sent": "I don't want to go into details.",
                    "label": 0
                },
                {
                    "sent": "We get the idea right, you adapt for the pose.",
                    "label": 0
                }
            ]
        },
        "clip_59": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We happen to use Adaboost to build the base classifier.",
                    "label": 0
                }
            ]
        },
        "clip_60": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You could use anything.",
                    "label": 0
                }
            ]
        },
        "clip_61": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Nelson, I'm going to go through this very quickly.",
                    "label": 0
                },
                {
                    "sent": "I'm going to just go to the bottom here.",
                    "label": 0
                },
                {
                    "sent": "There's two.",
                    "label": 0
                },
                {
                    "sent": "We have 2327 scenes containing 16183 cats.",
                    "label": 0
                },
                {
                    "sent": "We use 85% of them for training.",
                    "label": 0
                }
            ]
        },
        "clip_62": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we've done a lot of experiments.",
                    "label": 0
                },
                {
                    "sent": "Laugh OK, it's an inside joke.",
                    "label": 0
                },
                {
                    "sent": "Those experiments might have been presented and then we did a lot of experiments.",
                    "label": 0
                },
                {
                    "sent": "Just verifying some sort of common sense conclusions that you probably would have formed.",
                    "label": 0
                },
                {
                    "sent": "You didn't need to see experiments to believe.",
                    "label": 0
                }
            ]
        },
        "clip_63": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here are the two common sense conclusion.",
                    "label": 0
                },
                {
                    "sent": "If you have a very complex post phase then frag mating the data.",
                    "label": 0
                },
                {
                    "sent": "Member very, you have many, many cells.",
                    "label": 0
                },
                {
                    "sent": "Let's say 'cause it's a complex post base.",
                    "label": 0
                },
                {
                    "sent": "Fragmenting the data is a disaster.",
                    "label": 0
                },
                {
                    "sent": "If you just train on the data that satisfies exactly, you know your pose constraint.",
                    "label": 0
                },
                {
                    "sent": "You're not going to have an updated to build good classifiers, and you can show that the error rates are horrible.",
                    "label": 0
                }
            ]
        },
        "clip_64": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And the second thing that is also obvious is that a naive brute force, even if they were good these classifiers, if there is a gazillion of these.",
                    "label": 0
                },
                {
                    "sent": "Cells if K is gigantic, then obviously it's very inefficient.",
                    "label": 0
                },
                {
                    "sent": "Computationally.",
                    "label": 0
                },
                {
                    "sent": "You've got just a lot of cells to visit billions.",
                    "label": 0
                },
                {
                    "sent": "For like that, if you really start to chunk up the post space or the cap that I talked about in any reasonable way on those five or six or whatever it is.",
                    "label": 0
                }
            ]
        },
        "clip_65": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_66": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Alternatively stationary features avoid fragmentation because you're aggregating all the data to train one single classifier.",
                    "label": 0
                }
            ]
        },
        "clip_67": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And the hierarchy this the older stuff Francois's thesis.",
                    "label": 0
                },
                {
                    "sent": "Gives you the, avoids the online computational problem.",
                    "label": 0
                },
                {
                    "sent": "So in a nutshell, stationary features address efficient learning by building only a single classifier for a partition of the post space.",
                    "label": 0
                },
                {
                    "sent": "An hierarchical course defined search addresses efficient on line computation.",
                    "label": 0
                },
                {
                    "sent": "In a nutshell.",
                    "label": 0
                }
            ]
        },
        "clip_68": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we call this a folded hierarchy of classifiers like a fan.",
                    "label": 0
                },
                {
                    "sent": "You have this hierarchy, you know, pose in, and then you fold it for training and you unfolded for scene parsing.",
                    "label": 0
                },
                {
                    "sent": "Like a fan, you see what I mean, so that you're only training one classifier and then just.",
                    "label": 0
                },
                {
                    "sent": "Propagating that classifier appropriately to all the.",
                    "label": 0
                }
            ]
        },
        "clip_69": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Cells so that's course defined search.",
                    "label": 0
                },
                {
                    "sent": "I don't know why I'm just reviewing the idea.",
                    "label": 0
                },
                {
                    "sent": "You know that you do this test, then you go and do this one, then you go because this was yes you would do both of these.",
                    "label": 0
                },
                {
                    "sent": "You only do a test if its parents are executed and positive you would never visit these tests because this was negative and you built these classifiers.",
                    "label": 0
                },
                {
                    "sent": "They have a very high true detection rate.",
                    "label": 0
                },
                {
                    "sent": "And you would never.",
                    "label": 0
                },
                {
                    "sent": "You wouldn't visit these two because this was negative.",
                    "label": 0
                },
                {
                    "sent": "This was positive.",
                    "label": 0
                },
                {
                    "sent": "This both parents, both ancestors of these two were positive.",
                    "label": 0
                },
                {
                    "sent": "And so you visit both of these.",
                    "label": 0
                },
                {
                    "sent": "OK, when you're all done, you're conjecturing there's a cat.",
                    "label": 0
                },
                {
                    "sent": "If this is a fine post, fairly fine cell.",
                    "label": 0
                },
                {
                    "sent": "You're saying I have detected a cat who's poses in this cell.",
                    "label": 0
                }
            ]
        },
        "clip_70": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So how does it work?",
                    "label": 0
                },
                {
                    "sent": "I've already said it you visit.",
                    "label": 0
                },
                {
                    "sent": "The just the two layer let me just take a two layer example.",
                    "label": 0
                },
                {
                    "sent": "So first we're just chunking up on the head position.",
                    "label": 0
                },
                {
                    "sent": "Let's say head in the scale.",
                    "label": 0
                },
                {
                    "sent": "Let's fix the scale.",
                    "label": 0
                },
                {
                    "sent": "Take the scale out so just the head position.",
                    "label": 0
                },
                {
                    "sent": "You're just just like I showed at the very beginning.",
                    "label": 0
                },
                {
                    "sent": "You're just using a considering a partition of the post space based only on the.",
                    "label": 0
                },
                {
                    "sent": "Excuse me, a partition of the pose space based only on the position of the head.",
                    "label": 0
                },
                {
                    "sent": "OK at the first layer.",
                    "label": 0
                },
                {
                    "sent": "So you do all these classifiers.",
                    "label": 0
                },
                {
                    "sent": "You only made one.",
                    "label": 0
                },
                {
                    "sent": "We only trained one classifier an using the pose indexed features.",
                    "label": 0
                },
                {
                    "sent": "You apply it here, here, here, here, etc.",
                    "label": 0
                },
                {
                    "sent": "And so you find these three.",
                    "label": 0
                },
                {
                    "sent": "Detections.",
                    "label": 0
                },
                {
                    "sent": "All the others are.",
                    "label": 0
                },
                {
                    "sent": "Exited I mean were negative.",
                    "label": 0
                },
                {
                    "sent": "There's only there's no exit anything, there's just a flat partition.",
                    "label": 0
                },
                {
                    "sent": "So then you go around.",
                    "label": 0
                },
                {
                    "sent": "You only have to look around the ones you've detected.",
                    "label": 0
                },
                {
                    "sent": "And now let's say you have a partition of the belly position relative to those head positions.",
                    "label": 0
                },
                {
                    "sent": "It really is a partition of the post space.",
                    "label": 0
                },
                {
                    "sent": "You're only going to visit because of the course defined nature of the search and the low false positive false negative rate.",
                    "label": 0
                },
                {
                    "sent": "You only have to visit certain cells of the second layer, but basically, in principle you're partitioning all the poses of the cats based on both the head and the belly position, and you visit some of them and you.",
                    "label": 0
                }
            ]
        },
        "clip_71": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Get a couple of detections.",
                    "label": 0
                },
                {
                    "sent": "So I'm going to show you some results and just yes.",
                    "label": 0
                },
                {
                    "sent": "Stan beside that different image belongs to particular wholesale.",
                    "label": 0
                }
            ]
        },
        "clip_72": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You don't.",
                    "label": 0
                },
                {
                    "sent": "You apply the same to every of them.",
                    "label": 0
                },
                {
                    "sent": "You just take an image this image and you just start running.",
                    "label": 0
                },
                {
                    "sent": "The.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Which cell wait?",
                    "label": 0
                },
                {
                    "sent": "No, you haven't labeled training set.",
                    "label": 0
                },
                {
                    "sent": "You have a label training set labeled by puzzles by pose.",
                    "label": 0
                },
                {
                    "sent": "Oh yeah, of course and I'll come back to that.",
                    "label": 0
                },
                {
                    "sent": "And the downside is rich annotation Anwyl.",
                    "label": 0
                },
                {
                    "sent": "If there's any time we'll talk about unsupervised versus supervised.",
                    "label": 0
                },
                {
                    "sent": "You have a labeled training set, of course.",
                    "label": 0
                }
            ]
        },
        "clip_73": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So OK, so this green is a true positive because the estimated location of the head is reasonably near the true location and the estimated location of the tail of the belly is reasonably near the true one and the others are all examples of false positives because either both are wrong, one is wrong or the other is wrong.",
                    "label": 0
                },
                {
                    "sent": "So OK, another thing.",
                    "label": 0
                },
                {
                    "sent": "This is not just classification.",
                    "label": 0
                },
                {
                    "sent": "This is not this bag of feature stuff.",
                    "label": 0
                },
                {
                    "sent": "Saying just yes cat, no cat what we're just doing is parsing a cat, describing texting and describing a cat.",
                    "label": 0
                },
                {
                    "sent": "That's what vision is all about.",
                    "label": 0
                },
                {
                    "sent": "You know what what's in front of what?",
                    "label": 0
                },
                {
                    "sent": "What are the pose wears the head?",
                    "label": 0
                },
                {
                    "sent": "Where's the body?",
                    "label": 0
                },
                {
                    "sent": "Where's the arms?",
                    "label": 0
                },
                {
                    "sent": "Where's the tail?",
                    "label": 0
                },
                {
                    "sent": "Where the pause?",
                    "label": 0
                },
                {
                    "sent": "It's not just about cat or no cat.",
                    "label": 0
                },
                {
                    "sent": "You're not going to get very far that way.",
                    "label": 0
                },
                {
                    "sent": "So it's about parsing with people in language called parsing, decomposing the object into its parts and so forth.",
                    "label": 0
                }
            ]
        },
        "clip_74": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So when I show you error rates there at the level of nailing both of these.",
                    "label": 0
                },
                {
                    "sent": "Which is a lot harder than just nailing the head.",
                    "label": 0
                }
            ]
        },
        "clip_75": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so this represents a system that would not use stationary features, would just have a head detector and then go and have trained a separate belly detector not in the head belly.",
                    "label": 0
                },
                {
                    "sent": "Reference frame would have just trained ahead detector and separately a belly detector and do the head detector and then the belly detective.",
                    "label": 0
                },
                {
                    "sent": "OK, so it's the same strategy you visit with your head detector.",
                    "label": 0
                },
                {
                    "sent": "Might be almost the same head detector as in the with the stationary features, but then you just go to those around those places you found ahead with your head detector and you run that independent belly detector that wasn't trained with the knowledge of where the conjectured head was.",
                    "label": 0
                },
                {
                    "sent": "'cause it doesn't use pose index features that doesn't use stationery features, it's just trained like we always train classifiers.",
                    "label": 0
                }
            ]
        },
        "clip_76": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And it just does a lot better.",
                    "label": 0
                },
                {
                    "sent": "So here's the two Roc curves that count, and it's an order of magnitude improvement if you take into.",
                    "label": 0
                },
                {
                    "sent": "If you deal with the full pose, you get an order of magnitude improvement in the Roc curve.",
                    "label": 0
                },
                {
                    "sent": "So some I don't know .6.",
                    "label": 0
                },
                {
                    "sent": "If you're going to get 60% of the cats then you're going to have an average of 1 false positive per 640 by 480.",
                    "label": 0
                },
                {
                    "sent": "If you use this.",
                    "label": 0
                },
                {
                    "sent": "You know, if you use the program I've advocated, whereas if you just train in the usual way, you'll have ordered 10 false positives.",
                    "label": 0
                },
                {
                    "sent": "At 60% detection rate.",
                    "label": 0
                },
                {
                    "sent": "Same adjusting for everything, adjusting the same number of weak learners and the boosting everything being identical.",
                    "label": 0
                },
                {
                    "sent": "Same size training set you know everything the same.",
                    "label": 0
                }
            ]
        },
        "clip_77": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is the thing working.",
                    "label": 0
                },
                {
                    "sent": "On a random sample, I'm tell your cats we have 100 and 12,000 pictures of cats that we got from a data set the data site.",
                    "label": 0
                },
                {
                    "sent": "Website called Rate My Kitten making acknowledgement in a minute and we used as I said, order 2000 of these 110,000.",
                    "label": 0
                },
                {
                    "sent": "So that's a random sample.",
                    "label": 0
                },
                {
                    "sent": "Some pretty wild.",
                    "label": 0
                },
                {
                    "sent": "You know, cats get into some pretty amazing positions.",
                    "label": 0
                },
                {
                    "sent": "It's not easy to detect cats.",
                    "label": 0
                },
                {
                    "sent": "You know, specially if you're you know, the goal is to tell you where the head is and where the belly is.",
                    "label": 0
                },
                {
                    "sent": "So that's a random sample.",
                    "label": 0
                }
            ]
        },
        "clip_78": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And you know, there's mistakes like crazy, of course.",
                    "label": 0
                },
                {
                    "sent": "But you saw the Roc curve.",
                    "label": 0
                },
                {
                    "sent": "And it doesn't light up everywhere in in backgrounds, as you can see.",
                    "label": 0
                }
            ]
        },
        "clip_79": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "These are picked at random continued OK.",
                    "label": 0
                },
                {
                    "sent": "These are just more cats picked at random and background scenes and you're just seeing all the detections.",
                    "label": 0
                },
                {
                    "sent": "Open circle for head close circle for belly so.",
                    "label": 0
                },
                {
                    "sent": "Well, you get the idea.",
                    "label": 0
                }
            ]
        },
        "clip_80": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Oops.",
                    "label": 0
                },
                {
                    "sent": "These are selected false alarms.",
                    "label": 0
                }
            ]
        },
        "clip_81": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "OK, I don't have time to go into this.",
                    "label": 0
                },
                {
                    "sent": "These are examples of the features that boosting chooses of the stationary features that boosting chooses.",
                    "label": 0
                },
                {
                    "sent": "And if you go through it and you, if I were to give you a little vocabulary of what the colors mean and what everything means, you'd say oh it's doing this.",
                    "label": 0
                },
                {
                    "sent": "Oh, it's doing that, you know.",
                    "label": 0
                },
                {
                    "sent": "I mean many, many of them, not most.",
                    "label": 0
                },
                {
                    "sent": "Don't possibly, but many, many have.",
                    "label": 0
                },
                {
                    "sent": "A very natural interpretation.",
                    "label": 0
                },
                {
                    "sent": "You know it's comparing.",
                    "label": 0
                },
                {
                    "sent": "I don't know.",
                    "label": 0
                },
                {
                    "sent": "It's comparing the texture in the head area in the belly.",
                    "label": 0
                },
                {
                    "sent": "It's comparing the texture in two boxes in the belly.",
                    "label": 0
                },
                {
                    "sent": "It's saying that the texture in the belly is different than the texture in the outside.",
                    "label": 0
                },
                {
                    "sent": "Once you know where once you have a conjecture for those, you know what's inside and outside you know what's the head in the belly so you can start to make very intelligent build very intelligent features that you would never find otherwise.",
                    "label": 0
                },
                {
                    "sent": "And so each of these can.",
                    "label": 0
                }
            ]
        },
        "clip_82": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Can be interpreted.",
                    "label": 0
                }
            ]
        },
        "clip_83": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So in conclusion, folder hierarchy of classifiers is it's very efficient for online learning because of data aggregation, 'cause you're only building 1 classifier per.",
                    "label": 0
                }
            ]
        },
        "clip_84": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Level of the hierarchy and it's very efficient because it's a hierarchical.",
                    "label": 0
                }
            ]
        },
        "clip_85": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Course defined.",
                    "label": 0
                },
                {
                    "sent": "Search for scene processing.",
                    "label": 0
                }
            ]
        },
        "clip_86": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It can.",
                    "label": 0
                }
            ]
        },
        "clip_87": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Finds the strength of.",
                    "label": 0
                },
                {
                    "sent": "Template matching.",
                    "label": 0
                },
                {
                    "sent": "Machine learning is what I mean by the second one, holistic machine learning and.",
                    "label": 0
                }
            ]
        },
        "clip_88": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Rockel search.",
                    "label": 0
                }
            ]
        },
        "clip_89": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "How?",
                    "label": 0
                }
            ]
        },
        "clip_90": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "However, there's two drawbacks.",
                    "label": 0
                },
                {
                    "sent": "One is, you need richly annotated data.",
                    "label": 0
                },
                {
                    "sent": "Some of it I don't.",
                    "label": 0
                },
                {
                    "sent": "We don't know how much.",
                    "label": 0
                },
                {
                    "sent": "When she didn't investigating what happens if we start now decreasing the amount of annotated data that we use?",
                    "label": 0
                },
                {
                    "sent": "What's the breakpoint?",
                    "label": 0
                },
                {
                    "sent": "Nope, we trained with the thousands that are 2000.",
                    "label": 0
                },
                {
                    "sent": "What's going to happen?",
                    "label": 0
                },
                {
                    "sent": "We actually haven't done that.",
                    "label": 0
                },
                {
                    "sent": "We just get one.",
                    "label": 0
                },
                {
                    "sent": "11 training at one level and you have to design the stationary features and we're learning how to do that automatically.",
                    "label": 0
                },
                {
                    "sent": "Automatically design stationary features.",
                    "label": 0
                }
            ]
        },
        "clip_91": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So that's the acknowledgment to the website.",
                    "label": 0
                },
                {
                    "sent": "Alright, and so in summary, I can't help but believe that you know the route to success, at least in the vision problem is not in deep learning.",
                    "label": 0
                },
                {
                    "sent": "It's in deep representations.",
                    "label": 0
                },
                {
                    "sent": "It's in hard wiring and variance to the greatest extent possible, always keeping in mind both efficient learning and efficiency in parsing.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                },
                {
                    "sent": "Correlation that may happen in the labor, neighborhoods or poses, no.",
                    "label": 0
                },
                {
                    "sent": "I mean, you mean in the sense that.",
                    "label": 0
                },
                {
                    "sent": "A joint distribution on the pose variables is not entering the story explicitly, it's only entering Internet.",
                    "label": 0
                },
                {
                    "sent": "Really, the hierarchy is associated with the factory.",
                    "label": 0
                },
                {
                    "sent": "You can think of it is associated with a decomposition of the pose distribution into probability of belly given head times probability of head.",
                    "label": 0
                },
                {
                    "sent": "I'm being simple minded, it's more complex than that.",
                    "label": 0
                },
                {
                    "sent": "And so that's driving the design of the hierarchy is a factorization of the pose distribution into conditional into products of conditional probabilities.",
                    "label": 0
                },
                {
                    "sent": "And if you had, if you wanted to look for a tail, what's the right thing to do is to freeze the head, look at belly given ahead and look at tail.",
                    "label": 0
                },
                {
                    "sent": "Given belly, head 'cause that'll tell you where to look for the tail.",
                    "label": 0
                },
                {
                    "sent": "So if you were to go a level deeper with the tail you would to that extent that I just described, you would use that distribution and that would you know you know that if the head is here, where can the belly be if the head is here in the if the head is here in the bellies here you know about where the tail can be, so to that extent would use the.",
                    "label": 0
                },
                {
                    "sent": "Dependency structure among the pose variables.",
                    "label": 0
                },
                {
                    "sent": "Post labels or do you have any?",
                    "label": 0
                },
                {
                    "sent": "Could potentially use learning to essentially cluster the data at each level.",
                    "label": 0
                },
                {
                    "sent": "Discover.",
                    "label": 0
                },
                {
                    "sent": "First off, right?",
                    "label": 0
                },
                {
                    "sent": "You could use unsupervised learning.",
                    "label": 0
                },
                {
                    "sent": "You're suggesting to annotate the data.",
                    "label": 0
                },
                {
                    "sent": "Well that would be great.",
                    "label": 0
                },
                {
                    "sent": "That would be great.",
                    "label": 0
                },
                {
                    "sent": "In the representation right?",
                    "label": 0
                },
                {
                    "sent": "And so if you try to consider corrupted YK?",
                    "label": 0
                },
                {
                    "sent": "When when constructing the invariant features you mean add noise to the labels.",
                    "label": 0
                },
                {
                    "sent": "I don't think we've ever done that, no.",
                    "label": 0
                },
                {
                    "sent": "Having things which are preserving the distribution is my come up with something just as good but random.",
                    "label": 0
                },
                {
                    "sent": "When I ran oh, you don't mean totally random.",
                    "label": 0
                },
                {
                    "sent": "You mean you could tolerate some level.",
                    "label": 0
                },
                {
                    "sent": "Some flip noise.",
                    "label": 0
                },
                {
                    "sent": "Let's say I take every time like it, huh?",
                    "label": 0
                },
                {
                    "sent": "Is there a question?",
                    "label": 0
                },
                {
                    "sent": "But if it doesn't pop too much, then the extension would be well.",
                    "label": 0
                },
                {
                    "sent": "I think if you just totally permuta labor just thing would fall apart.",
                    "label": 0
                }
            ]
        }
    }
}