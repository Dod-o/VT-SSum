{
    "id": "llmolp7aeg3thjywe7s75rpi7rnv6cbo",
    "title": "Direct Mining of Discriminative Patterns for Classifying Uncertain Data",
    "info": {
        "author": [
            "Jianyong Wang, Department of Computer Science and Technology, Tsinghua University"
        ],
        "published": "Oct. 1, 2010",
        "recorded": "July 2010",
        "category": [
            "Top->Computer Science->Data Mining"
        ]
    },
    "url": "http://videolectures.net/kdd2010_wang_dmdp/",
    "segmentation": [
        [
            "Good afternoon, I will.",
            "I'll give a talk about direct manual, discriminative pattern, classifying auction data."
        ],
        [
            "Before going to uncertain data offered to show a little about classification on certain data, here is a toy example about certain categorical data set containing four classes.",
            "It's about, for example, PCPC, purchasing and."
        ],
        [
            "We can apply a lot of methods here, for example using this entry."
        ],
        [
            "I'll just rule based."
        ],
        [
            "After all, we could use associative classification, also known as paper pattern based classification, and there are a lot of evaluations in this part proving that this method could prove to provide better performance on most of the datasets on certain category codes."
        ],
        [
            "And also some other methods."
        ],
        [
            "Oh, and I also introduce little an associative classification.",
            "First, the two step framework.",
            "We first must settle frequent patterns."
        ],
        [
            "Unselect a subset of most discriminative patterns from them."
        ],
        [
            "And patterns all we could further further use one stamp just directly among the site of most discriminative, discriminative, frequent pattern."
        ],
        [
            "And then we use the mind patterns to convert each of the pattern into a binary feature.",
            "Weather by weather.",
            "The instance contains the pattern."
        ],
        [
            "And then we can train the trainer classifier likewise as well using the feature data converted from the original training data."
        ],
        [
            "Follow, follow, follow.",
            "Many of the associated class packing algorithms.",
            "There are some difference differences.",
            "First is different types of mind patterns in the two step framework.",
            "For example, we can use our frequent patterns are closed, frequent pattern or generator pattern like such."
        ],
        [
            "Also, there are some different discriminating measures like confidence value, information gain features are also some."
        ],
        [
            "Used as covering strategies like sequential carry, topic mining or search tree based data application."
        ],
        [
            "Um, awesome.",
            "How we can use different classification models like classname rule based of some base?"
        ],
        [
            "Also, here is the recently proposed mice the using different feature types, for example binary or numeric."
        ],
        [
            "No way, no way I can say the classification uncertain data here is example from also about uncertain categorical data set from the previous one, modified here.",
            "The uncertainty is called by the URL code by noisy or some measurement precisions.",
            "We could say that in the actual quality there is original certain value is replaced with probability vector."
        ],
        [
            "Come here for for classification of certain categorical data.",
            "There are very few methods.",
            "Why is why is uncertain?",
            "Dysentry it's based on say for PowerPoint file named DTO."
        ],
        [
            "And another algorithm is uncertain.",
            "Robust classifier named euro."
        ],
        [
            "So this time we want to we want to do the classification on certain categorical data by devising a new associative classification algorithm, working uncertain data."
        ],
        [
            "The data is the main differences to the certainty site is that Python And out.",
            "Pattern involving a certain attributes.",
            "They have probabilities to appear in instance soldiers so they don't have some certain spousal certain confidence value, but it's done some.",
            "This probability distribution."
        ],
        [
            "Here are some challenges.",
            "First, how to present the frequent needs of the frequently this information here some of the values.",
            "The expected value of the sport.",
            "Used in some previous studies and it's easy to calculate which would just seem some other probabilities appearing in different instances."
        ],
        [
            "But there are also some other challenges, like how to represent discriminative information."
        ],
        [
            "How to cover instances in uncertain data?",
            "In this paper I mean we focus on the letter two challenges."
        ],
        [
            "So far the discriminator will my rules are uncertain data.",
            "Here we choose to use the expected value of confidence.",
            "Unlike the expected such the expected confidence is difficult to."
        ],
        [
            "Great things, according to its definition.",
            "Expected value of confidence is equal to all of the all the confidence values.",
            "What price they are most present probability of the current world and some some of that together.",
            "However, there are a great many of possible words so that.",
            "So here's the here's the DM means the possible possible values in the in the.",
            "Built and we could say that there are."
        ],
        [
            "A great manual possible works, so we need the amount effect compute computation."
        ],
        [
            "Since this since our master contains a lot of details with just give the result here due to time limit."
        ],
        [
            "Here is here is our computation method.",
            "Mainly we use the dynamic program.",
            "My search here, each here, each each blue.",
            "It's blue cell is.",
            "As a function named, the EII and confidence value, it means the expected confidence.",
            "The, uh, the pattern X on Class C with the support of I on the 1st instances in the current database here.",
            "Way to calculate EIE function EIN, we just use some function some equation.",
            "On the on the bottom row of of its of the iron, and here here we have.",
            "We have the database size plus one steps and for example for each sample there are some calculations and we just sum them together and the whole result is the sum of the last column on the right side and we just sum.",
            "Doing during the computation, there are actually two dynamic programming.",
            "Nation there first is the first is spot value on over pattern Exxon classy and another is the probability of pattern.",
            "Exxon class.",
            "Say we mainly use those two combined together to get the.",
            "Expected confidence value."
        ],
        [
            "Here here the time complexity is.",
            "Pico of the square of the different size, because for each cell, the computation cost is bigger."
        ],
        [
            "Therefore, the space complexity the required the complexity is bigger the size of database things.",
            "Only two rows are needed to solve the needed to be saved file the computation."
        ],
        [
            "Also we tried to try to find some upper bounds for the expected confidence to try to further accelerate the computation here with different spots I we could further divide, divide the equation of the original expected confidence into two parts and get different bundle different upper bound bound by showing the showing.",
            "Awesome."
        ],
        [
            "And in total we could have the number of the different bound of the of the size of database."
        ],
        [
            "Here for different upper bound we have we have this relation with bundle 1 equal to the equal to the expected fault and the last bounding equal to the expected confidence.",
            "And also we could compute the next bound with current bond fund.",
            "Mental."
        ],
        [
            "And here is the computation for each step at the end of each step, we just try to check the check whether current boundaries is smaller than the maximal confidence in in current projected database every is true, we just stop it since it could not provide a better discriminating pattern."
        ],
        [
            "How is the is a running example the the upper left, upper left part is calculated bound where the red part is skipped bound."
        ],
        [
            "Here is the algorithm framework.",
            "We first calculate the confidence or expected confidence of Current Creek."
        ],
        [
            "Prefix pattern, then.",
            "If the confidence is larger than the previous maximum one, we just updated to the cover instances."
        ],
        [
            "And if I at least one is covered with, select the."
        ],
        [
            "Fix also will continue growing current prefix and go to sample one."
        ],
        [
            "We also need to sort out the certain attributes before the uncertains actually used to help shrink shrink current projected date."
        ],
        [
            "This here also using some different current straight edge than using."
        ],
        [
            "On certain certain data site, here we apply our thresholds of minimum covering probability.",
            "To control the flow, show the probability of not covered less than three."
        ],
        [
            "Another"
        ],
        [
            "I will ask them and some robust classifier from Harmony."
        ],
        [
            "Here is a good site we use.",
            "We use the 3030 publicly UCI certainty."
        ],
        [
            "And."
        ],
        [
            "Try to convert them into another one because of the unavailable uncertainties site."
        ],
        [
            "And here we have two parameters on certain attributes, number and uncertain degree, which means the probability of the taking values other than originally."
        ],
        [
            "Value and also here we use it to present the two parameters."
        ],
        [
            "And here is the accuracy.",
            "We just show the average accuracy on certain datasets and using different answers and parameters.",
            "And here is the result of SVM is a great improvement and also the robust we see also some good improvements compared to the two baselines and also."
        ],
        [
            "There is a sensitivity with respect to different minimums, part and with respect to different minimum covering probability.",
            "It proves the effectiveness of the minimum using minimum covering probabilities."
        ],
        [
            "There is a runtime efficiency, including all of the runtime.",
            "And here is the combination with using upper bound or not using from.",
            "So our conclusions very first to have a first associated classification algorithm on certain data and some if I can computationally expensive confidence and new current strategy and intensive evaluation and we probably its effectiveness.",
            "So thank you.",
            "I think we do not have more time for questions.",
            "Maybe questions can postpone to offline.",
            "So this single speaker."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Good afternoon, I will.",
                    "label": 0
                },
                {
                    "sent": "I'll give a talk about direct manual, discriminative pattern, classifying auction data.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Before going to uncertain data offered to show a little about classification on certain data, here is a toy example about certain categorical data set containing four classes.",
                    "label": 0
                },
                {
                    "sent": "It's about, for example, PCPC, purchasing and.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We can apply a lot of methods here, for example using this entry.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I'll just rule based.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "After all, we could use associative classification, also known as paper pattern based classification, and there are a lot of evaluations in this part proving that this method could prove to provide better performance on most of the datasets on certain category codes.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And also some other methods.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Oh, and I also introduce little an associative classification.",
                    "label": 0
                },
                {
                    "sent": "First, the two step framework.",
                    "label": 0
                },
                {
                    "sent": "We first must settle frequent patterns.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Unselect a subset of most discriminative patterns from them.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And patterns all we could further further use one stamp just directly among the site of most discriminative, discriminative, frequent pattern.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And then we use the mind patterns to convert each of the pattern into a binary feature.",
                    "label": 1
                },
                {
                    "sent": "Weather by weather.",
                    "label": 0
                },
                {
                    "sent": "The instance contains the pattern.",
                    "label": 1
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then we can train the trainer classifier likewise as well using the feature data converted from the original training data.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Follow, follow, follow.",
                    "label": 0
                },
                {
                    "sent": "Many of the associated class packing algorithms.",
                    "label": 0
                },
                {
                    "sent": "There are some difference differences.",
                    "label": 0
                },
                {
                    "sent": "First is different types of mind patterns in the two step framework.",
                    "label": 1
                },
                {
                    "sent": "For example, we can use our frequent patterns are closed, frequent pattern or generator pattern like such.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Also, there are some different discriminating measures like confidence value, information gain features are also some.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Used as covering strategies like sequential carry, topic mining or search tree based data application.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Um, awesome.",
                    "label": 0
                },
                {
                    "sent": "How we can use different classification models like classname rule based of some base?",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Also, here is the recently proposed mice the using different feature types, for example binary or numeric.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "No way, no way I can say the classification uncertain data here is example from also about uncertain categorical data set from the previous one, modified here.",
                    "label": 1
                },
                {
                    "sent": "The uncertainty is called by the URL code by noisy or some measurement precisions.",
                    "label": 0
                },
                {
                    "sent": "We could say that in the actual quality there is original certain value is replaced with probability vector.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Come here for for classification of certain categorical data.",
                    "label": 0
                },
                {
                    "sent": "There are very few methods.",
                    "label": 1
                },
                {
                    "sent": "Why is why is uncertain?",
                    "label": 0
                },
                {
                    "sent": "Dysentry it's based on say for PowerPoint file named DTO.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And another algorithm is uncertain.",
                    "label": 0
                },
                {
                    "sent": "Robust classifier named euro.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this time we want to we want to do the classification on certain categorical data by devising a new associative classification algorithm, working uncertain data.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The data is the main differences to the certainty site is that Python And out.",
                    "label": 0
                },
                {
                    "sent": "Pattern involving a certain attributes.",
                    "label": 0
                },
                {
                    "sent": "They have probabilities to appear in instance soldiers so they don't have some certain spousal certain confidence value, but it's done some.",
                    "label": 1
                },
                {
                    "sent": "This probability distribution.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Here are some challenges.",
                    "label": 0
                },
                {
                    "sent": "First, how to present the frequent needs of the frequently this information here some of the values.",
                    "label": 0
                },
                {
                    "sent": "The expected value of the sport.",
                    "label": 1
                },
                {
                    "sent": "Used in some previous studies and it's easy to calculate which would just seem some other probabilities appearing in different instances.",
                    "label": 1
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But there are also some other challenges, like how to represent discriminative information.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "How to cover instances in uncertain data?",
                    "label": 0
                },
                {
                    "sent": "In this paper I mean we focus on the letter two challenges.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So far the discriminator will my rules are uncertain data.",
                    "label": 0
                },
                {
                    "sent": "Here we choose to use the expected value of confidence.",
                    "label": 1
                },
                {
                    "sent": "Unlike the expected such the expected confidence is difficult to.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Great things, according to its definition.",
                    "label": 0
                },
                {
                    "sent": "Expected value of confidence is equal to all of the all the confidence values.",
                    "label": 1
                },
                {
                    "sent": "What price they are most present probability of the current world and some some of that together.",
                    "label": 0
                },
                {
                    "sent": "However, there are a great many of possible words so that.",
                    "label": 0
                },
                {
                    "sent": "So here's the here's the DM means the possible possible values in the in the.",
                    "label": 0
                },
                {
                    "sent": "Built and we could say that there are.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "A great manual possible works, so we need the amount effect compute computation.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Since this since our master contains a lot of details with just give the result here due to time limit.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here is here is our computation method.",
                    "label": 0
                },
                {
                    "sent": "Mainly we use the dynamic program.",
                    "label": 0
                },
                {
                    "sent": "My search here, each here, each each blue.",
                    "label": 0
                },
                {
                    "sent": "It's blue cell is.",
                    "label": 0
                },
                {
                    "sent": "As a function named, the EII and confidence value, it means the expected confidence.",
                    "label": 0
                },
                {
                    "sent": "The, uh, the pattern X on Class C with the support of I on the 1st instances in the current database here.",
                    "label": 0
                },
                {
                    "sent": "Way to calculate EIE function EIN, we just use some function some equation.",
                    "label": 0
                },
                {
                    "sent": "On the on the bottom row of of its of the iron, and here here we have.",
                    "label": 0
                },
                {
                    "sent": "We have the database size plus one steps and for example for each sample there are some calculations and we just sum them together and the whole result is the sum of the last column on the right side and we just sum.",
                    "label": 0
                },
                {
                    "sent": "Doing during the computation, there are actually two dynamic programming.",
                    "label": 0
                },
                {
                    "sent": "Nation there first is the first is spot value on over pattern Exxon classy and another is the probability of pattern.",
                    "label": 0
                },
                {
                    "sent": "Exxon class.",
                    "label": 0
                },
                {
                    "sent": "Say we mainly use those two combined together to get the.",
                    "label": 0
                },
                {
                    "sent": "Expected confidence value.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here here the time complexity is.",
                    "label": 0
                },
                {
                    "sent": "Pico of the square of the different size, because for each cell, the computation cost is bigger.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Therefore, the space complexity the required the complexity is bigger the size of database things.",
                    "label": 0
                },
                {
                    "sent": "Only two rows are needed to solve the needed to be saved file the computation.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Also we tried to try to find some upper bounds for the expected confidence to try to further accelerate the computation here with different spots I we could further divide, divide the equation of the original expected confidence into two parts and get different bundle different upper bound bound by showing the showing.",
                    "label": 0
                },
                {
                    "sent": "Awesome.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And in total we could have the number of the different bound of the of the size of database.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here for different upper bound we have we have this relation with bundle 1 equal to the equal to the expected fault and the last bounding equal to the expected confidence.",
                    "label": 0
                },
                {
                    "sent": "And also we could compute the next bound with current bond fund.",
                    "label": 0
                },
                {
                    "sent": "Mental.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And here is the computation for each step at the end of each step, we just try to check the check whether current boundaries is smaller than the maximal confidence in in current projected database every is true, we just stop it since it could not provide a better discriminating pattern.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "How is the is a running example the the upper left, upper left part is calculated bound where the red part is skipped bound.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here is the algorithm framework.",
                    "label": 0
                },
                {
                    "sent": "We first calculate the confidence or expected confidence of Current Creek.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Prefix pattern, then.",
                    "label": 0
                },
                {
                    "sent": "If the confidence is larger than the previous maximum one, we just updated to the cover instances.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And if I at least one is covered with, select the.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Fix also will continue growing current prefix and go to sample one.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We also need to sort out the certain attributes before the uncertains actually used to help shrink shrink current projected date.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This here also using some different current straight edge than using.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "On certain certain data site, here we apply our thresholds of minimum covering probability.",
                    "label": 0
                },
                {
                    "sent": "To control the flow, show the probability of not covered less than three.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Another",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I will ask them and some robust classifier from Harmony.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here is a good site we use.",
                    "label": 0
                },
                {
                    "sent": "We use the 3030 publicly UCI certainty.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Try to convert them into another one because of the unavailable uncertainties site.",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And here we have two parameters on certain attributes, number and uncertain degree, which means the probability of the taking values other than originally.",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Value and also here we use it to present the two parameters.",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And here is the accuracy.",
                    "label": 0
                },
                {
                    "sent": "We just show the average accuracy on certain datasets and using different answers and parameters.",
                    "label": 0
                },
                {
                    "sent": "And here is the result of SVM is a great improvement and also the robust we see also some good improvements compared to the two baselines and also.",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "There is a sensitivity with respect to different minimums, part and with respect to different minimum covering probability.",
                    "label": 0
                },
                {
                    "sent": "It proves the effectiveness of the minimum using minimum covering probabilities.",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "There is a runtime efficiency, including all of the runtime.",
                    "label": 0
                },
                {
                    "sent": "And here is the combination with using upper bound or not using from.",
                    "label": 0
                },
                {
                    "sent": "So our conclusions very first to have a first associated classification algorithm on certain data and some if I can computationally expensive confidence and new current strategy and intensive evaluation and we probably its effectiveness.",
                    "label": 0
                },
                {
                    "sent": "So thank you.",
                    "label": 0
                },
                {
                    "sent": "I think we do not have more time for questions.",
                    "label": 0
                },
                {
                    "sent": "Maybe questions can postpone to offline.",
                    "label": 0
                },
                {
                    "sent": "So this single speaker.",
                    "label": 0
                }
            ]
        }
    }
}