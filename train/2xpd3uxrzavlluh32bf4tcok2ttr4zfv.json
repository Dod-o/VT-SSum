{
    "id": "2xpd3uxrzavlluh32bf4tcok2ttr4zfv",
    "title": "Multilayer Corpus and Toolchain for Full-Stack NLU in Latvian",
    "info": {
        "author": [
            "Art\u016brs Znoti\u0146\u0161, Institute of Mathematics and Computer Science, University of Latvia"
        ],
        "published": "Jan. 14, 2019",
        "recorded": "October 2018",
        "category": [
            "Top->Humanities",
            "Top->Social Sciences"
        ]
    },
    "url": "http://videolectures.net/clarinannualconference2018_znotins_corpus/",
    "segmentation": [
        [
            "Hello everyone."
        ],
        [
            "I'm authors from Institute of Mathematics and Computer Science, University of Latvia.",
            "And today I am.",
            "Today I'm presenting working progress to create multilayer text corpus for Latvian final releases planned in 2019.",
            "The goal of this project is to advance research and innovation in natural language understanding and to strengthen the Latvian language technology support in support, especially in a cross lingual context.",
            "In parallel with creating with this corpus, we are developing data driven tools for automatic processing of Latvian text to demonstrate the potential benefits of such.",
            "That resource and with the support from Claire and Latvia, we are planning also to add add created datasets and tools to Claire in infrastructure as well."
        ],
        [
            "So current state of art systems for semantic parsing, parsing too large extent rely on supervised machine learning techniques, which requires substantial amount of training data in language resources.",
            "Appropriate text corpora with syntactic and semantic annotations an for Latvian.",
            "We don't have such resources or if we have, they are very limited in size.",
            "So with this project we are trying to address this issue and.",
            "With some old layer corpus is based on widely available knowledge.",
            "Multilingual representations, including universal universal dependencies, framing it Prop bank, an abstract meaning representation.",
            "This set of resources was chosen according to the state of Art practice is widely used for other other languages, so let me include the benefit from multi lingual tools.",
            "Yeah, requirements are mostly driven by abstract meaning representation.",
            "The base layer of Foundation contains three bank.",
            "Which is manually annotated next week.",
            "How manually annotated frament.",
            "The Pro Bank is automatically automatically derived from frament and you delayers, and we also have named entities and an indent in conference layers and their end goal is to generate draft AMR knowledge graphs.",
            "And derive them automatically from other layers.",
            "So we we have done some experiments with this is a feasible approach, but they are a margraf generation is still in the future work."
        ],
        [
            "So yeah, we're aiming at medium sized corpus, around 10 to 15,000 sentences.",
            "The texts are manually select selected in different proportions from a balance to text corpus of what 10,000,000 words?",
            "We made a decision to use paragraphs as the main text units.",
            "And yeah, paragraphs are selected based on verbs they contain, not randomly.",
            "And our goal is to cover around to cover 1000 most frequently occurring occurring verbs."
        ],
        [
            "So moving more specifically to three bank, yeah to capture the language language specific details on one hand and to meet cross lingual application on the other hand, the Tree Bank is annotated in two complementary formalisms.",
            "First, we have.",
            "No.",
            "Trees annotated today according to Hybrids Dependency constituency grammar model and 2nd.",
            "The hybrid annotation is automatically automatically converted to universal dependencies to achieve the cross lingual compatibility, we suffers also other benefits that this hybrid model already includes a lot of additional information, so we can even general generate large parts of enhanced universal dependencies."
        ],
        [
            "We don't annotate syntax trees from scratch, rather reuse available Morpho Tiger and parser to generate drop trees for text that are automatically exported to Git repository when we when they are selected in our corpus management tool, we.",
            "The trees are manually inspected and corrected in thread annotation tool.",
            "And it's proved to be beneficial to it.",
            "Iteratively retrain the parser on a larger debts at so we can minimize the needed correction steps."
        ],
        [
            "We keep track of statistics to provide balance of January's.",
            "This is taken into account when we are selecting new paragraphs.",
            "Yeah, here we can see that we are aiming to include text from newswire fiction, academic writings, legal documents and spoken language."
        ],
        [
            "Yeah, you know universal dependencies using commonly used date format.",
            "And for other tools and annotation layers we are using also account derived formats that basically adds some extra columns.",
            "For now it's working quite well for us and it works well with Git versioning as well.",
            "We keep track of document ID, paragraphs and sentence identifiers, and additional metadata can be extracted from balanced text corpus for wedding."
        ],
        [
            "Yeah, named entities and core fences are annotated in Vamp Anna annotation tool.",
            "We mostly follow MUC annotation guidelines which we have extended to for camp compatibility with top level AMR named entity entity categories.",
            "Additionally, we provide a hierarchical named entity annotations and links to Wikipedia, keeping in mind that we want to generate a margraf's.",
            "Conferences are annotated in paragraph level, so this of course has its downsides, but it allows much faster annotation process and it's less error prone.",
            "And for AMR it's enough to do it in paragraph level."
        ],
        [
            "Yeah, framing temptations are also annotated in web panel based on Berkeley frames frame inventory.",
            "The annotation of problem frames are is relatively more simple if compared to frame it, since problem frames are less abstract and their semantic roles directly follow from a syntactic verb argument structure.",
            "However, we saw that we can generate prop bank from frame it.",
            "So we are start, start and tighting frame it frames and derive prop bank annotations.",
            "Same automatically from frame net.",
            "And you know your day annotations."
        ],
        [
            "Frames are annotated in a conquered concordance view, so the language can focus on on the target verpan it's different senses or frames without constantly switching between different sets of frames, which also improves the annotation consistency.",
            "And in this example you can see occurrences of the target verb Z, what the live reside to exist."
        ],
        [
            "And here you can see the end frame.",
            "That same problem can dotations.",
            "I will maybe Jumpable."
        ],
        [
            "Little bit forward and here is some basic basic example how we try to map frame data problem frames and also how we map frame elements to problem semantic role roles considering frame and syntax."
        ],
        [
            "So.",
            "In parallel, to create the creation of this corpus, we also are developing and improving NLP tools for Latvian.",
            "We already had the pretty good documentation and morphological tag tagger.",
            "Um?",
            "These are written in Java dependency parsing.",
            "It was just developed recently and is continuously improved.",
            "This is a neural neural network architecture based LST model.",
            "Named entity recognition is based on.",
            "Bidirectional Stam, if additional CRF layer.",
            "It's also released just recently.",
            "Coreference resolution system is rule based system.",
            "Right now it it's.",
            "It will still be developed.",
            "And we also have some other tools that we are trying to integrate in in a single unified architecture, so all these components are dockerized, we use.",
            "Our created library NLP pipe.",
            "Basically in each language we provide some basic wrapping functionality so we can easily provide wrap these components language course in Docker containers and also provide additional functionality as chaining of the components.",
            "Also API and queuing golf works.",
            "So yeah, basically in general the architecture is based on task queues were very specifically user EBT MQ and components with our dockerized.",
            "And this type of architecture provides a lot of benefits.",
            "But we can scale this architecture on multiple machines and it also offers.",
            "Basically say fail over if something bad happens and all the tasks are.",
            "Still saved so they can be processed later on.",
            "Yeah, we have right now.",
            "This is mostly.",
            "We have focused on the internal use and with we are planning to move onto more standardized approach and right now we haven't that much considered different formats for.",
            "Full communication and if you want to look forward to integration with Claren architecture and even maybe web lift, we can try to think about a little bit further.",
            "So, um."
        ],
        [
            "Yeah, the first prototype is already available online.",
            "For DEMA purposes you can try it out and LP dot dot Salvi.",
            "Yeah, final release office Corpus is a plant in 2019.",
            "Corpus is gradually released under Creative Commons license for non commercial use and and under commercial license otherwise, actually they also dependency corpus is already available in Clarion architecture through Linda.",
            "Anna Toolchain Deema is publicly available and currently dockerized components.",
            "Together with NLP pipe libraries will be released in the next weeks.",
            "So yeah, as I already mentioned, the tools and data will be integrating currently in infrastructure.",
            "It still is in far future.",
            "Thank you.",
            "Alright, thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Hello everyone.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I'm authors from Institute of Mathematics and Computer Science, University of Latvia.",
                    "label": 0
                },
                {
                    "sent": "And today I am.",
                    "label": 0
                },
                {
                    "sent": "Today I'm presenting working progress to create multilayer text corpus for Latvian final releases planned in 2019.",
                    "label": 0
                },
                {
                    "sent": "The goal of this project is to advance research and innovation in natural language understanding and to strengthen the Latvian language technology support in support, especially in a cross lingual context.",
                    "label": 0
                },
                {
                    "sent": "In parallel with creating with this corpus, we are developing data driven tools for automatic processing of Latvian text to demonstrate the potential benefits of such.",
                    "label": 0
                },
                {
                    "sent": "That resource and with the support from Claire and Latvia, we are planning also to add add created datasets and tools to Claire in infrastructure as well.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So current state of art systems for semantic parsing, parsing too large extent rely on supervised machine learning techniques, which requires substantial amount of training data in language resources.",
                    "label": 0
                },
                {
                    "sent": "Appropriate text corpora with syntactic and semantic annotations an for Latvian.",
                    "label": 0
                },
                {
                    "sent": "We don't have such resources or if we have, they are very limited in size.",
                    "label": 0
                },
                {
                    "sent": "So with this project we are trying to address this issue and.",
                    "label": 0
                },
                {
                    "sent": "With some old layer corpus is based on widely available knowledge.",
                    "label": 0
                },
                {
                    "sent": "Multilingual representations, including universal universal dependencies, framing it Prop bank, an abstract meaning representation.",
                    "label": 0
                },
                {
                    "sent": "This set of resources was chosen according to the state of Art practice is widely used for other other languages, so let me include the benefit from multi lingual tools.",
                    "label": 0
                },
                {
                    "sent": "Yeah, requirements are mostly driven by abstract meaning representation.",
                    "label": 0
                },
                {
                    "sent": "The base layer of Foundation contains three bank.",
                    "label": 0
                },
                {
                    "sent": "Which is manually annotated next week.",
                    "label": 0
                },
                {
                    "sent": "How manually annotated frament.",
                    "label": 0
                },
                {
                    "sent": "The Pro Bank is automatically automatically derived from frament and you delayers, and we also have named entities and an indent in conference layers and their end goal is to generate draft AMR knowledge graphs.",
                    "label": 0
                },
                {
                    "sent": "And derive them automatically from other layers.",
                    "label": 0
                },
                {
                    "sent": "So we we have done some experiments with this is a feasible approach, but they are a margraf generation is still in the future work.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So yeah, we're aiming at medium sized corpus, around 10 to 15,000 sentences.",
                    "label": 0
                },
                {
                    "sent": "The texts are manually select selected in different proportions from a balance to text corpus of what 10,000,000 words?",
                    "label": 1
                },
                {
                    "sent": "We made a decision to use paragraphs as the main text units.",
                    "label": 1
                },
                {
                    "sent": "And yeah, paragraphs are selected based on verbs they contain, not randomly.",
                    "label": 1
                },
                {
                    "sent": "And our goal is to cover around to cover 1000 most frequently occurring occurring verbs.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So moving more specifically to three bank, yeah to capture the language language specific details on one hand and to meet cross lingual application on the other hand, the Tree Bank is annotated in two complementary formalisms.",
                    "label": 0
                },
                {
                    "sent": "First, we have.",
                    "label": 0
                },
                {
                    "sent": "No.",
                    "label": 0
                },
                {
                    "sent": "Trees annotated today according to Hybrids Dependency constituency grammar model and 2nd.",
                    "label": 0
                },
                {
                    "sent": "The hybrid annotation is automatically automatically converted to universal dependencies to achieve the cross lingual compatibility, we suffers also other benefits that this hybrid model already includes a lot of additional information, so we can even general generate large parts of enhanced universal dependencies.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We don't annotate syntax trees from scratch, rather reuse available Morpho Tiger and parser to generate drop trees for text that are automatically exported to Git repository when we when they are selected in our corpus management tool, we.",
                    "label": 0
                },
                {
                    "sent": "The trees are manually inspected and corrected in thread annotation tool.",
                    "label": 0
                },
                {
                    "sent": "And it's proved to be beneficial to it.",
                    "label": 0
                },
                {
                    "sent": "Iteratively retrain the parser on a larger debts at so we can minimize the needed correction steps.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We keep track of statistics to provide balance of January's.",
                    "label": 0
                },
                {
                    "sent": "This is taken into account when we are selecting new paragraphs.",
                    "label": 0
                },
                {
                    "sent": "Yeah, here we can see that we are aiming to include text from newswire fiction, academic writings, legal documents and spoken language.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Yeah, you know universal dependencies using commonly used date format.",
                    "label": 0
                },
                {
                    "sent": "And for other tools and annotation layers we are using also account derived formats that basically adds some extra columns.",
                    "label": 0
                },
                {
                    "sent": "For now it's working quite well for us and it works well with Git versioning as well.",
                    "label": 0
                },
                {
                    "sent": "We keep track of document ID, paragraphs and sentence identifiers, and additional metadata can be extracted from balanced text corpus for wedding.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Yeah, named entities and core fences are annotated in Vamp Anna annotation tool.",
                    "label": 0
                },
                {
                    "sent": "We mostly follow MUC annotation guidelines which we have extended to for camp compatibility with top level AMR named entity entity categories.",
                    "label": 0
                },
                {
                    "sent": "Additionally, we provide a hierarchical named entity annotations and links to Wikipedia, keeping in mind that we want to generate a margraf's.",
                    "label": 0
                },
                {
                    "sent": "Conferences are annotated in paragraph level, so this of course has its downsides, but it allows much faster annotation process and it's less error prone.",
                    "label": 0
                },
                {
                    "sent": "And for AMR it's enough to do it in paragraph level.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Yeah, framing temptations are also annotated in web panel based on Berkeley frames frame inventory.",
                    "label": 0
                },
                {
                    "sent": "The annotation of problem frames are is relatively more simple if compared to frame it, since problem frames are less abstract and their semantic roles directly follow from a syntactic verb argument structure.",
                    "label": 0
                },
                {
                    "sent": "However, we saw that we can generate prop bank from frame it.",
                    "label": 0
                },
                {
                    "sent": "So we are start, start and tighting frame it frames and derive prop bank annotations.",
                    "label": 0
                },
                {
                    "sent": "Same automatically from frame net.",
                    "label": 0
                },
                {
                    "sent": "And you know your day annotations.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Frames are annotated in a conquered concordance view, so the language can focus on on the target verpan it's different senses or frames without constantly switching between different sets of frames, which also improves the annotation consistency.",
                    "label": 0
                },
                {
                    "sent": "And in this example you can see occurrences of the target verb Z, what the live reside to exist.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And here you can see the end frame.",
                    "label": 0
                },
                {
                    "sent": "That same problem can dotations.",
                    "label": 0
                },
                {
                    "sent": "I will maybe Jumpable.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Little bit forward and here is some basic basic example how we try to map frame data problem frames and also how we map frame elements to problem semantic role roles considering frame and syntax.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "In parallel, to create the creation of this corpus, we also are developing and improving NLP tools for Latvian.",
                    "label": 0
                },
                {
                    "sent": "We already had the pretty good documentation and morphological tag tagger.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "These are written in Java dependency parsing.",
                    "label": 0
                },
                {
                    "sent": "It was just developed recently and is continuously improved.",
                    "label": 0
                },
                {
                    "sent": "This is a neural neural network architecture based LST model.",
                    "label": 0
                },
                {
                    "sent": "Named entity recognition is based on.",
                    "label": 0
                },
                {
                    "sent": "Bidirectional Stam, if additional CRF layer.",
                    "label": 0
                },
                {
                    "sent": "It's also released just recently.",
                    "label": 0
                },
                {
                    "sent": "Coreference resolution system is rule based system.",
                    "label": 1
                },
                {
                    "sent": "Right now it it's.",
                    "label": 0
                },
                {
                    "sent": "It will still be developed.",
                    "label": 0
                },
                {
                    "sent": "And we also have some other tools that we are trying to integrate in in a single unified architecture, so all these components are dockerized, we use.",
                    "label": 0
                },
                {
                    "sent": "Our created library NLP pipe.",
                    "label": 0
                },
                {
                    "sent": "Basically in each language we provide some basic wrapping functionality so we can easily provide wrap these components language course in Docker containers and also provide additional functionality as chaining of the components.",
                    "label": 0
                },
                {
                    "sent": "Also API and queuing golf works.",
                    "label": 0
                },
                {
                    "sent": "So yeah, basically in general the architecture is based on task queues were very specifically user EBT MQ and components with our dockerized.",
                    "label": 0
                },
                {
                    "sent": "And this type of architecture provides a lot of benefits.",
                    "label": 0
                },
                {
                    "sent": "But we can scale this architecture on multiple machines and it also offers.",
                    "label": 0
                },
                {
                    "sent": "Basically say fail over if something bad happens and all the tasks are.",
                    "label": 0
                },
                {
                    "sent": "Still saved so they can be processed later on.",
                    "label": 0
                },
                {
                    "sent": "Yeah, we have right now.",
                    "label": 0
                },
                {
                    "sent": "This is mostly.",
                    "label": 0
                },
                {
                    "sent": "We have focused on the internal use and with we are planning to move onto more standardized approach and right now we haven't that much considered different formats for.",
                    "label": 0
                },
                {
                    "sent": "Full communication and if you want to look forward to integration with Claren architecture and even maybe web lift, we can try to think about a little bit further.",
                    "label": 0
                },
                {
                    "sent": "So, um.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Yeah, the first prototype is already available online.",
                    "label": 0
                },
                {
                    "sent": "For DEMA purposes you can try it out and LP dot dot Salvi.",
                    "label": 0
                },
                {
                    "sent": "Yeah, final release office Corpus is a plant in 2019.",
                    "label": 0
                },
                {
                    "sent": "Corpus is gradually released under Creative Commons license for non commercial use and and under commercial license otherwise, actually they also dependency corpus is already available in Clarion architecture through Linda.",
                    "label": 0
                },
                {
                    "sent": "Anna Toolchain Deema is publicly available and currently dockerized components.",
                    "label": 0
                },
                {
                    "sent": "Together with NLP pipe libraries will be released in the next weeks.",
                    "label": 0
                },
                {
                    "sent": "So yeah, as I already mentioned, the tools and data will be integrating currently in infrastructure.",
                    "label": 0
                },
                {
                    "sent": "It still is in far future.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                },
                {
                    "sent": "Alright, thank you.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": []
        }
    }
}