{
    "id": "m5xsyscn3zigpd3wtvyhrkpxuomcaelv",
    "title": "Serving DBPedia with DOLCE - More than Just Adding a Cherry on Top",
    "info": {
        "author": [
            "Heiko Paulheim, Institut f\u00fcr Informatik, University of Mannheim"
        ],
        "published": "Nov. 10, 2015",
        "recorded": "October 2015",
        "category": [
            "Top->Computer Science->Semantic Web"
        ]
    },
    "url": "http://videolectures.net/iswc2015_paulheim_serving_dbpedia/",
    "segmentation": [
        [
            "Um, yeah, this work started out together with Ogunjimi last year in Ice WC in reverse, so we were sitting there towards the end of the conference by that beautiful Lake.",
            "Getting a town or freshly shaved heads and we thought, yeah, we've seen so many layer cakes during the past days and years, so maybe it's time for a paradigm shift and I'm happy to present the very first semantic web cupcake today.",
            "Alright."
        ],
        [
            "So so many of you who use DB pedia may have notice that since the 2014 releases they have these Dolce alignments in there so you have types for instances in indulging ontologies."
        ],
        [
            "You also have properties in map 2 properties and daughter.",
            "Have you notice those?",
            "But yeah.",
            "Who have you hasn't done anything meaningful with that?",
            "Oh, I want to talk to you over the coffee break and you too cool so but I think most people when they spot this, they think like you help.",
            "OK now I know that for example, Tim Berners Lee is also a physical entity.",
            "Nice, so."
        ],
        [
            "It's a cherry on top.",
            "Does that really give me any valuable input or valuable signals that are going to use in applications?",
            "So before I tell you what we do with that, actually I want to briefly tell you some some insights on what daughter is, what it gives us, So what it gives us is a set of very high level actions, so it tells us that certain things cannot be the same at the same time, so if something cannot be a social and physical object at the same time, for example, then we get some very high level domain and range restrictions and those fundamental disjointness is So what they give us is they give us a semantic enrichment of the DB pedia ontology and what we can use them.",
            "For, among other things is consistency checking."
        ],
        [
            "So when you see this example here, there is an example of statement from the pedia that says Tim Berners Lee got the award Royal Society, where Royal Society obviously is not an award right.",
            "It is an organization and once we add these top level actions from Doll show, we can see that descriptions and social agents, which is the top level classes.",
            "There are actually disjoint with each other, so this statement cannot be correct and this is what we can use it for."
        ],
        [
            "Just just a brief idea on what the pedia already gives us.",
            "So DB Pedia gives us an extraction from Wikipedia infoboxes into an ontology.",
            "So these infobox keys they are mapped to, ontology properties, infobox types are mapped to ontology classes and then we run an instruction extraction every once or twice a year.",
            "And from that we get what you know is DB pedia and the DPT ontology contains some disjointness actions but they are most of the time covering some exotic corner cases like.",
            "Moving walkways and persons being disjoint.",
            "This is without any doubt true, but I don't know if there are even any moving walkways in the pedia and so this touches just a few corner cases.",
            "This is not touching the majority of DPD instances actually."
        ],
        [
            "Daughter on the other hand is a very high level ontology, so you get very high level classes like physical and social objects and they are defined with a very high level of extra motivation, and they're very richly described semantically and you also have properties that are very detailed, Lee described, and they come in hierarchies with very precise domain and range restrictions and so on.",
            "So this is somewhat we get on top of the pedia ontology.",
            "Sync up."
        ],
        [
            "So what we saw but with Dulce is that the original document allergies that developed some years ago.",
            "They they have actually been shown to be a bit too heavyweight for actual usage in the semantic web, so they are quite picky and some distinctions, and they're very hard to use.",
            "So what people came up with was a simplified version called Dodge 0 and the sister one we use in those experiments.",
            "By the way, discern, actually adults has served in a nutshell, so it fits the title of the slide quite nicely."
        ],
        [
            "Um?",
            "Yeah, so we see that when we used to also become spot those errors there like Tim Berners Lee gets an award which is an organization an now.",
            "I mean, we could of course collect all those errors, but we actually after is finding systematic errors so we just we don't want to just delete all the nonsense out of DB pedia, but we want to try to understand where does it come from.",
            "So is there any systematics there?",
            "And for example, if we spot that that this is a recurring pattern that people get organizations as awards, we can see.",
            "OK, there is probably some common root cause.",
            "And we can try to identify it and then fix it once and for all instead of just throwing out all the erroneous statements.",
            "So this is the idea where we want to go."
        ],
        [
            "So what do we do?",
            "So for each statement that we find in DB pedia, we load the ontology of DB pedia plus the ontology of culture.",
            "Then we add the statement plus all the types of the subject and object and then we use it reasoner to check whether that is consistent and So what you could do now is you could you could present all those inconsistent statements and explanations to a user or an expert to make sounds of them and see what is the common pattern here.",
            "The first challenge here is that when you do that, then inspecting once in one statement and checking the consistency takes about 2.6 seconds.",
            "That's actually quite fast, but DB Pedia has roughly 50 million statements.",
            "So this whole thing would take you 450 days if we aim at two releases a year.",
            "This is a bit too long to be of any practical value."
        ],
        [
            "Luckily, you don't have to necessarily check each and every statement, because many of those patterns are actually the same.",
            "So once you see you have checked already, a person and an organization connected by an award predicate, you don't have to do that over again because you know you already know it's inconsistent and you already know the explanation will be exactly the same, so you can just cash that.",
            "And once you do that, you see that there is only a very small fraction, so there's only like 35,000 different settings of subject types, object tabs and predicates.",
            "And that's much more manageable than checking 50,000,000, so this actually runs in roughly 24 hours to check.",
            "So once we do that, we find about 3.6 million statements that are inconsistent with just bought a quarter of of the pedia.",
            "This is this does not mean that they are all wrong, it's just that they are inconsistent with the ontology for various reasons.",
            "And here you also see that adding this top level ontology really gives us a boost here because if you do this only with the disjointness actions that are contained in DB pedia as such, you only find roughly 100,000.",
            "So one order of magnitude less than when you use this top level ontology.",
            "But nevertheless, you don't want to check these 3.6 million by hand, right?",
            "So what we do is we we are after these systematic errors an to find or systematic errors.",
            "We cluster the explanations that the reason that gives us and then we hope that each of those clusters will represent one of those systematic."
        ],
        [
            "So in the end, the end user does not inspect all of those statements, but he only inspects like one representative for each cluster."
        ],
        [
            "To do this clustering, what we do is we look at the explanations that the reason that gives us so all the justifications, the actions and each of the actions of the justifications becomes a binary feature.",
            "This gives us these inconsistent statements in a binary feature space of roughly one point 5000 dimensions, and then we run that too through a clustering algorithm.",
            "Here we use DB scan with Manhattan Distance, so Manhattan distance means in how many actions do the explanations differ?",
            "We ran some preliminary experiments and then we.",
            "Came up with this parameter setting using 100.",
            "We assume that if one something appears 100 times and it's a systematic error below that it's not.",
            "It's an arbitrary threshold an this is the distribution of clusters you find and you see this is a log scale, so you see, there are some very large clusters which are almost 1 million statements in there, and then it slows down but it slows down quite quite quickly and these few large clusters they contribute to the majority of the inconsistencies you find."
        ],
        [
            "So next we inspect the Top 40 clusters that we found with DB scan and they represent roughly 96% of all the inconsistent statements, so this is really a huge portion of the inconsistencies.",
            "And then we looked at what's happening there, what's going wrong, and one thing that goes wrong is that properties are introduced at some point in time and then they are used for various other purposes.",
            "So people spot this property in the ontology.",
            "It looks like, yeah, this is roughly what I also want to use and then they just use it for a very different purpose.",
            "And you can.",
            "You can spot those.",
            "You can spot those issues and then you can think about whether you want to introduce a new property there, or whether you want to relax the domain and range constraints of the one you already have.",
            "Another thing you quite frequently find is those metonymies where you use terms in the ontology in an ambiguous way, so there are species and DB pedia.",
            "And they are all the way mixed with actual instances of those species.",
            "So you have the species horrors and then you have actual horses that are also of type species.",
            "This is pretty hard to refactor because.",
            "Most of the time the error already goes back to Wikipedia, where somebody uses a species info box for an actual animals, so this is hard, but we can at least find those issues."
        ],
        [
            "Yeah, and in some cases we also found that the alignment to daughter was simply wrong, but there was OK. We found that we fixed it and then we're done.",
            "And one thing we also found is that DPD ontology evolves an you have to tell the people that make alignments to other ontologies that you have evolved, something that you have changed the semantics and we could also automatically find those points where the versions had changed and where there was a divergent between what we saw before in what is now."
        ],
        [
            "Next to those clusters, we also took a short glance at the long tail, say what DB scan does, it finds those clusters and it finds things that do not fall into any clusters and it marks them as noise.",
            "So what we expect here is that these are not systematic errors related to a class, but you may find common patterns that are that are cross cutting across all sorts of classes and properties, and from those we looked at 100 instances and 64 of those are actually errors.",
            "30 are correct, and for six you just.",
            "Can't tell whether this is an error or not.",
            "They are so exotic that you have no clue."
        ],
        [
            "But these also gave us some interesting insights and what things can go wrong in DB pedia.",
            "So there is the statement that a person called Cosmo Kramer was by occupation.",
            "He was a bagel and you wonder how this gets into DB pedia.",
            "This is what happens so you have this info box over there and this info box contains as occupation detects in there, says, Bagel Shop worker an only.",
            "The text bagel is linked to an entity and then you extract that statement that says this guy was a bagel at some.",
            "Point in his career.",
            "I'll see what what causes us headaches sometimes, as some links with fragments or links that are just wrong in Wikipedia.",
            "This is something but you just can't help because people put wrong things in Wikipedia.",
            "Redirects are interesting, so you have this person whose company is Bing Crosby and Bing Crosby is obviously a person, not a company, and the original link target says Bing Crosby Productions, which is a re direct to the person being cross B which is then resolved to the actual entity.",
            "And this is how the arrow gets in there.",
            "But again we see that OK redirects are obviously a problem.",
            "We need to look at.",
            "And finally, this this this anchor thing.",
            "This is responsible for this Tim Berners Lee example I showed in the beginning so the actual object there in the Wikipedia Infoboxes Royal SoC Fragmente fellows, and these fragments are completely ignored and this often leads to nonsensical statements and Peters is also a very common source of errors."
        ],
        [
            "So for some conclusions we have seen that the Gulch Ontology actually helps us identify inconsistent statements that we find by an order of magnitude more inconsistencies than without using that former top level ontology.",
            "And if we use cluster analysis on the explanations that are reason that gives us, then we can also find the systematic errors, and this is pretty handy because you can.",
            "You can find issues that are responsible for lots of errors with very minimal user interaction.",
            "So we just looked at the Top 40 clusters, we inspect it no more than 40 statements, one from each cluster, and then we looked at how can we fit.",
            "So we will, by looking at 40 statements we can actually fix 3.5 million statements.",
            "So this is a pretty pretty cool minimal user interaction.",
            "So what we did with this is we changed some points in DPD ontologies.",
            "We changed some mappings when we found those errors.",
            "We also sometimes change the alignment adulterer and in cases where we didn't figure out what the hell the problem is.",
            "We just filed a bug report to the Pedia.",
            "But it's a very systematic way of finding those bugs that affect a huge number of statements."
        ],
        [
            "So in general in life there was a time for cupcakes and a time for questions, and I think now is the letter.",
            "Thank you.",
            "So we have indeed time for questions.",
            "Peter so did you actually make the changes to the TPD ontology?",
            "Some are actually carried out and we also carried out some mapping changes.",
            "We carried out some changes.",
            "Yet this is actually dumb.",
            "OK, so I mean DPD ontology is notorious for having incorrect superclasses.",
            "Would you pick those up?",
            "Um, if they need to such inconsistencies, we are able to pick them up, most of them.",
            "Most of the stuff we found, however, was domain and range restrictions, which were not.",
            "So which will not usable with the data account.",
            "Let's put it that way.",
            "I wouldn't say they were wrong.",
            "So you would say that the majority of the errors were obtained through violation of domain and range restrictions of the predicates as well as your class disjunction.",
            "So yeah, a domain and range violation without a class?",
            "Disjointness does not need lead to an inconsistency, yes, so you need the disjointness of some classes to detect the inconsistency.",
            "Otherwise, in RDF semantics, just keep putting another object in arrange.",
            "This does not harm anything right?",
            "So?",
            "But what was the contribution?",
            "Were there any additional axioms in Dolce that can sort of non obvious disjunction?",
            "So some kind of inference?",
            "That aside from those ones that that led to an inconsistency.",
            "We also have quite a variety there, so there was additional disjointness is that Bulger gives us.",
            "There is also that these predicate these properties they are linked to higher level properties which have something like actor or agent participates in event and then these domains and ranges were actually used to detect the inconsistency.",
            "There are also some things indulged like inverses of properties which were sometimes exploited by the reason.",
            "So when looking at these explanations the reason generated you found all sorts of different actions that were exploited there.",
            "Great, thank you.",
            "What was there any way in which Dulce could be used to enhance searching or browsing?",
            "Or is it too too high level?",
            "It's actually 2 high levels so I think I'll do and a few of his colleagues are the only person who actually understand what they see there.",
            "So for the rest it's really exotic stuff that I think for end users does not make much sense now.",
            "Have you thought about bringing this forward, so to speak, to Wikipedia itself so that people could get feedback in a visual way maybe?",
            "I realize there's some scaling issues that would be involved with that sort of thing, but are there any thought about that?",
            "So most of the stuff we find here is not errors in Wikipedia.",
            "Most of the stuff we find here is actually errors in how we process the inputs of Wikipedia, and sometimes you find there's there's incorrect things, but they are found in the long tail and we can't process the long tail automatically.",
            "We can just inspect statements from the long tail one by one, and.",
            "Decide whether it's an error in Wikipedia on error in the processing.",
            "So in that case it's hardly doable to feed that automatic back to Wikipedia automatically."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Um, yeah, this work started out together with Ogunjimi last year in Ice WC in reverse, so we were sitting there towards the end of the conference by that beautiful Lake.",
                    "label": 0
                },
                {
                    "sent": "Getting a town or freshly shaved heads and we thought, yeah, we've seen so many layer cakes during the past days and years, so maybe it's time for a paradigm shift and I'm happy to present the very first semantic web cupcake today.",
                    "label": 0
                },
                {
                    "sent": "Alright.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So so many of you who use DB pedia may have notice that since the 2014 releases they have these Dolce alignments in there so you have types for instances in indulging ontologies.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You also have properties in map 2 properties and daughter.",
                    "label": 0
                },
                {
                    "sent": "Have you notice those?",
                    "label": 0
                },
                {
                    "sent": "But yeah.",
                    "label": 0
                },
                {
                    "sent": "Who have you hasn't done anything meaningful with that?",
                    "label": 0
                },
                {
                    "sent": "Oh, I want to talk to you over the coffee break and you too cool so but I think most people when they spot this, they think like you help.",
                    "label": 0
                },
                {
                    "sent": "OK now I know that for example, Tim Berners Lee is also a physical entity.",
                    "label": 0
                },
                {
                    "sent": "Nice, so.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "It's a cherry on top.",
                    "label": 1
                },
                {
                    "sent": "Does that really give me any valuable input or valuable signals that are going to use in applications?",
                    "label": 0
                },
                {
                    "sent": "So before I tell you what we do with that, actually I want to briefly tell you some some insights on what daughter is, what it gives us, So what it gives us is a set of very high level actions, so it tells us that certain things cannot be the same at the same time, so if something cannot be a social and physical object at the same time, for example, then we get some very high level domain and range restrictions and those fundamental disjointness is So what they give us is they give us a semantic enrichment of the DB pedia ontology and what we can use them.",
                    "label": 1
                },
                {
                    "sent": "For, among other things is consistency checking.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So when you see this example here, there is an example of statement from the pedia that says Tim Berners Lee got the award Royal Society, where Royal Society obviously is not an award right.",
                    "label": 0
                },
                {
                    "sent": "It is an organization and once we add these top level actions from Doll show, we can see that descriptions and social agents, which is the top level classes.",
                    "label": 0
                },
                {
                    "sent": "There are actually disjoint with each other, so this statement cannot be correct and this is what we can use it for.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Just just a brief idea on what the pedia already gives us.",
                    "label": 0
                },
                {
                    "sent": "So DB Pedia gives us an extraction from Wikipedia infoboxes into an ontology.",
                    "label": 1
                },
                {
                    "sent": "So these infobox keys they are mapped to, ontology properties, infobox types are mapped to ontology classes and then we run an instruction extraction every once or twice a year.",
                    "label": 0
                },
                {
                    "sent": "And from that we get what you know is DB pedia and the DPT ontology contains some disjointness actions but they are most of the time covering some exotic corner cases like.",
                    "label": 0
                },
                {
                    "sent": "Moving walkways and persons being disjoint.",
                    "label": 0
                },
                {
                    "sent": "This is without any doubt true, but I don't know if there are even any moving walkways in the pedia and so this touches just a few corner cases.",
                    "label": 0
                },
                {
                    "sent": "This is not touching the majority of DPD instances actually.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Daughter on the other hand is a very high level ontology, so you get very high level classes like physical and social objects and they are defined with a very high level of extra motivation, and they're very richly described semantically and you also have properties that are very detailed, Lee described, and they come in hierarchies with very precise domain and range restrictions and so on.",
                    "label": 0
                },
                {
                    "sent": "So this is somewhat we get on top of the pedia ontology.",
                    "label": 0
                },
                {
                    "sent": "Sync up.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So what we saw but with Dulce is that the original document allergies that developed some years ago.",
                    "label": 0
                },
                {
                    "sent": "They they have actually been shown to be a bit too heavyweight for actual usage in the semantic web, so they are quite picky and some distinctions, and they're very hard to use.",
                    "label": 1
                },
                {
                    "sent": "So what people came up with was a simplified version called Dodge 0 and the sister one we use in those experiments.",
                    "label": 0
                },
                {
                    "sent": "By the way, discern, actually adults has served in a nutshell, so it fits the title of the slide quite nicely.",
                    "label": 1
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Yeah, so we see that when we used to also become spot those errors there like Tim Berners Lee gets an award which is an organization an now.",
                    "label": 0
                },
                {
                    "sent": "I mean, we could of course collect all those errors, but we actually after is finding systematic errors so we just we don't want to just delete all the nonsense out of DB pedia, but we want to try to understand where does it come from.",
                    "label": 0
                },
                {
                    "sent": "So is there any systematics there?",
                    "label": 0
                },
                {
                    "sent": "And for example, if we spot that that this is a recurring pattern that people get organizations as awards, we can see.",
                    "label": 0
                },
                {
                    "sent": "OK, there is probably some common root cause.",
                    "label": 1
                },
                {
                    "sent": "And we can try to identify it and then fix it once and for all instead of just throwing out all the erroneous statements.",
                    "label": 0
                },
                {
                    "sent": "So this is the idea where we want to go.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So what do we do?",
                    "label": 0
                },
                {
                    "sent": "So for each statement that we find in DB pedia, we load the ontology of DB pedia plus the ontology of culture.",
                    "label": 1
                },
                {
                    "sent": "Then we add the statement plus all the types of the subject and object and then we use it reasoner to check whether that is consistent and So what you could do now is you could you could present all those inconsistent statements and explanations to a user or an expert to make sounds of them and see what is the common pattern here.",
                    "label": 1
                },
                {
                    "sent": "The first challenge here is that when you do that, then inspecting once in one statement and checking the consistency takes about 2.6 seconds.",
                    "label": 0
                },
                {
                    "sent": "That's actually quite fast, but DB Pedia has roughly 50 million statements.",
                    "label": 0
                },
                {
                    "sent": "So this whole thing would take you 450 days if we aim at two releases a year.",
                    "label": 0
                },
                {
                    "sent": "This is a bit too long to be of any practical value.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Luckily, you don't have to necessarily check each and every statement, because many of those patterns are actually the same.",
                    "label": 0
                },
                {
                    "sent": "So once you see you have checked already, a person and an organization connected by an award predicate, you don't have to do that over again because you know you already know it's inconsistent and you already know the explanation will be exactly the same, so you can just cash that.",
                    "label": 0
                },
                {
                    "sent": "And once you do that, you see that there is only a very small fraction, so there's only like 35,000 different settings of subject types, object tabs and predicates.",
                    "label": 0
                },
                {
                    "sent": "And that's much more manageable than checking 50,000,000, so this actually runs in roughly 24 hours to check.",
                    "label": 0
                },
                {
                    "sent": "So once we do that, we find about 3.6 million statements that are inconsistent with just bought a quarter of of the pedia.",
                    "label": 0
                },
                {
                    "sent": "This is this does not mean that they are all wrong, it's just that they are inconsistent with the ontology for various reasons.",
                    "label": 0
                },
                {
                    "sent": "And here you also see that adding this top level ontology really gives us a boost here because if you do this only with the disjointness actions that are contained in DB pedia as such, you only find roughly 100,000.",
                    "label": 0
                },
                {
                    "sent": "So one order of magnitude less than when you use this top level ontology.",
                    "label": 0
                },
                {
                    "sent": "But nevertheless, you don't want to check these 3.6 million by hand, right?",
                    "label": 0
                },
                {
                    "sent": "So what we do is we we are after these systematic errors an to find or systematic errors.",
                    "label": 0
                },
                {
                    "sent": "We cluster the explanations that the reason that gives us and then we hope that each of those clusters will represent one of those systematic.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So in the end, the end user does not inspect all of those statements, but he only inspects like one representative for each cluster.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "To do this clustering, what we do is we look at the explanations that the reason that gives us so all the justifications, the actions and each of the actions of the justifications becomes a binary feature.",
                    "label": 0
                },
                {
                    "sent": "This gives us these inconsistent statements in a binary feature space of roughly one point 5000 dimensions, and then we run that too through a clustering algorithm.",
                    "label": 1
                },
                {
                    "sent": "Here we use DB scan with Manhattan Distance, so Manhattan distance means in how many actions do the explanations differ?",
                    "label": 0
                },
                {
                    "sent": "We ran some preliminary experiments and then we.",
                    "label": 0
                },
                {
                    "sent": "Came up with this parameter setting using 100.",
                    "label": 1
                },
                {
                    "sent": "We assume that if one something appears 100 times and it's a systematic error below that it's not.",
                    "label": 0
                },
                {
                    "sent": "It's an arbitrary threshold an this is the distribution of clusters you find and you see this is a log scale, so you see, there are some very large clusters which are almost 1 million statements in there, and then it slows down but it slows down quite quite quickly and these few large clusters they contribute to the majority of the inconsistencies you find.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So next we inspect the Top 40 clusters that we found with DB scan and they represent roughly 96% of all the inconsistent statements, so this is really a huge portion of the inconsistencies.",
                    "label": 1
                },
                {
                    "sent": "And then we looked at what's happening there, what's going wrong, and one thing that goes wrong is that properties are introduced at some point in time and then they are used for various other purposes.",
                    "label": 0
                },
                {
                    "sent": "So people spot this property in the ontology.",
                    "label": 0
                },
                {
                    "sent": "It looks like, yeah, this is roughly what I also want to use and then they just use it for a very different purpose.",
                    "label": 0
                },
                {
                    "sent": "And you can.",
                    "label": 0
                },
                {
                    "sent": "You can spot those.",
                    "label": 0
                },
                {
                    "sent": "You can spot those issues and then you can think about whether you want to introduce a new property there, or whether you want to relax the domain and range constraints of the one you already have.",
                    "label": 0
                },
                {
                    "sent": "Another thing you quite frequently find is those metonymies where you use terms in the ontology in an ambiguous way, so there are species and DB pedia.",
                    "label": 0
                },
                {
                    "sent": "And they are all the way mixed with actual instances of those species.",
                    "label": 0
                },
                {
                    "sent": "So you have the species horrors and then you have actual horses that are also of type species.",
                    "label": 0
                },
                {
                    "sent": "This is pretty hard to refactor because.",
                    "label": 0
                },
                {
                    "sent": "Most of the time the error already goes back to Wikipedia, where somebody uses a species info box for an actual animals, so this is hard, but we can at least find those issues.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Yeah, and in some cases we also found that the alignment to daughter was simply wrong, but there was OK. We found that we fixed it and then we're done.",
                    "label": 0
                },
                {
                    "sent": "And one thing we also found is that DPD ontology evolves an you have to tell the people that make alignments to other ontologies that you have evolved, something that you have changed the semantics and we could also automatically find those points where the versions had changed and where there was a divergent between what we saw before in what is now.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Next to those clusters, we also took a short glance at the long tail, say what DB scan does, it finds those clusters and it finds things that do not fall into any clusters and it marks them as noise.",
                    "label": 1
                },
                {
                    "sent": "So what we expect here is that these are not systematic errors related to a class, but you may find common patterns that are that are cross cutting across all sorts of classes and properties, and from those we looked at 100 instances and 64 of those are actually errors.",
                    "label": 1
                },
                {
                    "sent": "30 are correct, and for six you just.",
                    "label": 0
                },
                {
                    "sent": "Can't tell whether this is an error or not.",
                    "label": 0
                },
                {
                    "sent": "They are so exotic that you have no clue.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "But these also gave us some interesting insights and what things can go wrong in DB pedia.",
                    "label": 0
                },
                {
                    "sent": "So there is the statement that a person called Cosmo Kramer was by occupation.",
                    "label": 0
                },
                {
                    "sent": "He was a bagel and you wonder how this gets into DB pedia.",
                    "label": 0
                },
                {
                    "sent": "This is what happens so you have this info box over there and this info box contains as occupation detects in there, says, Bagel Shop worker an only.",
                    "label": 0
                },
                {
                    "sent": "The text bagel is linked to an entity and then you extract that statement that says this guy was a bagel at some.",
                    "label": 0
                },
                {
                    "sent": "Point in his career.",
                    "label": 0
                },
                {
                    "sent": "I'll see what what causes us headaches sometimes, as some links with fragments or links that are just wrong in Wikipedia.",
                    "label": 1
                },
                {
                    "sent": "This is something but you just can't help because people put wrong things in Wikipedia.",
                    "label": 0
                },
                {
                    "sent": "Redirects are interesting, so you have this person whose company is Bing Crosby and Bing Crosby is obviously a person, not a company, and the original link target says Bing Crosby Productions, which is a re direct to the person being cross B which is then resolved to the actual entity.",
                    "label": 1
                },
                {
                    "sent": "And this is how the arrow gets in there.",
                    "label": 0
                },
                {
                    "sent": "But again we see that OK redirects are obviously a problem.",
                    "label": 0
                },
                {
                    "sent": "We need to look at.",
                    "label": 0
                },
                {
                    "sent": "And finally, this this this anchor thing.",
                    "label": 0
                },
                {
                    "sent": "This is responsible for this Tim Berners Lee example I showed in the beginning so the actual object there in the Wikipedia Infoboxes Royal SoC Fragmente fellows, and these fragments are completely ignored and this often leads to nonsensical statements and Peters is also a very common source of errors.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So for some conclusions we have seen that the Gulch Ontology actually helps us identify inconsistent statements that we find by an order of magnitude more inconsistencies than without using that former top level ontology.",
                    "label": 1
                },
                {
                    "sent": "And if we use cluster analysis on the explanations that are reason that gives us, then we can also find the systematic errors, and this is pretty handy because you can.",
                    "label": 0
                },
                {
                    "sent": "You can find issues that are responsible for lots of errors with very minimal user interaction.",
                    "label": 0
                },
                {
                    "sent": "So we just looked at the Top 40 clusters, we inspect it no more than 40 statements, one from each cluster, and then we looked at how can we fit.",
                    "label": 1
                },
                {
                    "sent": "So we will, by looking at 40 statements we can actually fix 3.5 million statements.",
                    "label": 0
                },
                {
                    "sent": "So this is a pretty pretty cool minimal user interaction.",
                    "label": 0
                },
                {
                    "sent": "So what we did with this is we changed some points in DPD ontologies.",
                    "label": 0
                },
                {
                    "sent": "We changed some mappings when we found those errors.",
                    "label": 0
                },
                {
                    "sent": "We also sometimes change the alignment adulterer and in cases where we didn't figure out what the hell the problem is.",
                    "label": 0
                },
                {
                    "sent": "We just filed a bug report to the Pedia.",
                    "label": 0
                },
                {
                    "sent": "But it's a very systematic way of finding those bugs that affect a huge number of statements.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So in general in life there was a time for cupcakes and a time for questions, and I think now is the letter.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                },
                {
                    "sent": "So we have indeed time for questions.",
                    "label": 0
                },
                {
                    "sent": "Peter so did you actually make the changes to the TPD ontology?",
                    "label": 0
                },
                {
                    "sent": "Some are actually carried out and we also carried out some mapping changes.",
                    "label": 0
                },
                {
                    "sent": "We carried out some changes.",
                    "label": 0
                },
                {
                    "sent": "Yet this is actually dumb.",
                    "label": 0
                },
                {
                    "sent": "OK, so I mean DPD ontology is notorious for having incorrect superclasses.",
                    "label": 0
                },
                {
                    "sent": "Would you pick those up?",
                    "label": 0
                },
                {
                    "sent": "Um, if they need to such inconsistencies, we are able to pick them up, most of them.",
                    "label": 0
                },
                {
                    "sent": "Most of the stuff we found, however, was domain and range restrictions, which were not.",
                    "label": 0
                },
                {
                    "sent": "So which will not usable with the data account.",
                    "label": 0
                },
                {
                    "sent": "Let's put it that way.",
                    "label": 0
                },
                {
                    "sent": "I wouldn't say they were wrong.",
                    "label": 0
                },
                {
                    "sent": "So you would say that the majority of the errors were obtained through violation of domain and range restrictions of the predicates as well as your class disjunction.",
                    "label": 0
                },
                {
                    "sent": "So yeah, a domain and range violation without a class?",
                    "label": 0
                },
                {
                    "sent": "Disjointness does not need lead to an inconsistency, yes, so you need the disjointness of some classes to detect the inconsistency.",
                    "label": 0
                },
                {
                    "sent": "Otherwise, in RDF semantics, just keep putting another object in arrange.",
                    "label": 0
                },
                {
                    "sent": "This does not harm anything right?",
                    "label": 0
                },
                {
                    "sent": "So?",
                    "label": 0
                },
                {
                    "sent": "But what was the contribution?",
                    "label": 0
                },
                {
                    "sent": "Were there any additional axioms in Dolce that can sort of non obvious disjunction?",
                    "label": 0
                },
                {
                    "sent": "So some kind of inference?",
                    "label": 0
                },
                {
                    "sent": "That aside from those ones that that led to an inconsistency.",
                    "label": 0
                },
                {
                    "sent": "We also have quite a variety there, so there was additional disjointness is that Bulger gives us.",
                    "label": 0
                },
                {
                    "sent": "There is also that these predicate these properties they are linked to higher level properties which have something like actor or agent participates in event and then these domains and ranges were actually used to detect the inconsistency.",
                    "label": 0
                },
                {
                    "sent": "There are also some things indulged like inverses of properties which were sometimes exploited by the reason.",
                    "label": 0
                },
                {
                    "sent": "So when looking at these explanations the reason generated you found all sorts of different actions that were exploited there.",
                    "label": 0
                },
                {
                    "sent": "Great, thank you.",
                    "label": 0
                },
                {
                    "sent": "What was there any way in which Dulce could be used to enhance searching or browsing?",
                    "label": 0
                },
                {
                    "sent": "Or is it too too high level?",
                    "label": 0
                },
                {
                    "sent": "It's actually 2 high levels so I think I'll do and a few of his colleagues are the only person who actually understand what they see there.",
                    "label": 0
                },
                {
                    "sent": "So for the rest it's really exotic stuff that I think for end users does not make much sense now.",
                    "label": 0
                },
                {
                    "sent": "Have you thought about bringing this forward, so to speak, to Wikipedia itself so that people could get feedback in a visual way maybe?",
                    "label": 0
                },
                {
                    "sent": "I realize there's some scaling issues that would be involved with that sort of thing, but are there any thought about that?",
                    "label": 0
                },
                {
                    "sent": "So most of the stuff we find here is not errors in Wikipedia.",
                    "label": 0
                },
                {
                    "sent": "Most of the stuff we find here is actually errors in how we process the inputs of Wikipedia, and sometimes you find there's there's incorrect things, but they are found in the long tail and we can't process the long tail automatically.",
                    "label": 0
                },
                {
                    "sent": "We can just inspect statements from the long tail one by one, and.",
                    "label": 0
                },
                {
                    "sent": "Decide whether it's an error in Wikipedia on error in the processing.",
                    "label": 0
                },
                {
                    "sent": "So in that case it's hardly doable to feed that automatic back to Wikipedia automatically.",
                    "label": 0
                }
            ]
        }
    }
}