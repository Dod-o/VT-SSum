{
    "id": "ex5wudkapkpg3yowe5w5mq6txdshzxuc",
    "title": "Object Recognition and Segmentation by Association",
    "info": {
        "author": [
            "Tomasz Malisiewicz, Robotics Institute, School of Computer Science, Carnegie Mellon University"
        ],
        "published": "Jan. 15, 2009",
        "recorded": "October 2008",
        "category": [
            "Top->Computer Science->Computer Vision->Object Recognition"
        ]
    },
    "url": "http://videolectures.net/cmulls08_malisiewicz_orsa/",
    "segmentation": [
        [
            "Alright so I am the second speaker for today and I'm going to try not to spill too much over the time and everybody's dying to get back to their own research.",
            "So my name is Tomasz and this is going to talk about joint work with my advisor Alyosha Efros from the Robotics Institute.",
            "This is also a CPR 2008 paper.",
            "Title is a recognition by Association and what I'm going to be talking about today is object recognition.",
            "This is something that is one of the biggest problems in computer vision.",
            "It's also a big interest to learning community and basic idea is that when you look at the word recognition or re cognition, etymologically, it means that we're cognizing something again.",
            "So when looking at objects, instead of asking the question.",
            "What is this object will be asking the question?",
            "What is it like?",
            "How is it compared to something we've seen before in the past?"
        ],
        [
            "So the basic problem that I'll be looking at is recognizing many different types of objects inside an image.",
            "So rather than looking at just cars or just faces, the goal will be given an image to try to reason about all the different types of objects that we could find inside the image.",
            "The key observation of this research is that recognition becomes significantly easier once we have the correct segmentation for an object.",
            "So once we already know what region we should be looking at in the image, and then we have to figure out what it is, the problem becomes easier.",
            "And the basic approach is using a segment centric object representation and an exemplar based nonparametric recognition model.",
            "And that's what I'll be talking about."
        ],
        [
            "It's worthwhile first taking a look at what generally is meant by understanding an image in the computer vision community, so here's the zoomed in version of this input image and what we're interested in in understanding this image."
        ],
        [
            "Is naming all the different objects that are displayed inside this image so reasonable object names or things like building face streetlamp walls or bust and we take actually close?",
            "Look at these object names.",
            "What we find out is that they're not refering so much to these particular instances.",
            "In this image there actually object categories, so usually image understanding means categorizing all the different objects inside this image.",
            "But if we were to represent this image by all the different object categories that it contains, what would happen is we were going to."
        ],
        [
            "Picture that looks like."
        ],
        [
            "This and it wouldn't really tell us much about the actual image.",
            "While it's still very important to tell what's in the image, just saying that this is the layout of these different categories, there is an infinite amount of images that could easily map the scenario and tells you very little about what the image looks like."
        ],
        [
            "So what we did in this paper is we propose a different way of looking at recognition.",
            "So given input image shown on the left rather than directly trying to categorize different regions and just trying to represent the image by saying it contains building here cars here in a Rd there."
        ],
        [
            "Let's try to associate things that we have seen before in the past on the right here or previously seen objects and associate each one of those objects with some chunk of the visual input.",
            "And when we've done recognition this way, what happens is we have regions.",
            "We have things that they previously looked like.",
            "It gives us a much more colorful picture of what an image could actually look like.",
            "And once we've associated pieces of the visual input with things that we have seen before, we can then look at the labels or the categories so."
        ],
        [
            "You see it with those objects we've seen before, and we can propagate them back into the image.",
            "But what's different in this view is that rather than directly trying to categorise what we're trying to do now is, we're trying to associate things we've seen before in the past, and once we have these associations, we can look at what other metadata is stored with these objects.",
            "Things like labels.",
            "Imagine a robot stores.",
            "Whether this is something that's going to harm it or not, or anything else you can kind of propagate that information back into the image."
        ],
        [
            "So just to quickly summarize what I'll be talking about throughout the rest of the talk is.",
            "The basic contributions of this paper are first posing object recognition as Association in order to have this Association framework actually work.",
            "When you use a large number of object exemplars, we need to capture all the different appearances of lots of different objects.",
            "And in order to actually create this associations to see if something we've seen in the past associated with something new, we needed a way to.",
            "To kind of compare these new things with old things to do that we."
        ],
        [
            "Learn a different object similarity measure per exemplar.",
            "So rather than heuristically defining some sort of similarity measure, that's going to magically work for things like buildings and skies as well as cars and people we have each object that we've seen in the past learn its own similarity function.",
            "That will let us create associations."
        ],
        [
            "And finally, since we're interested in real images and the real images have the problem where we're not going to be given any segmentations.",
            "Objects occur in many different configurations.",
            "Only we want to reason about where the objects are in the image and in order to do this, we use a recognition based object segmentation strategy where we use multiple image segmentations to generate lots of potential regions where objects could be in, and then we use the object similarity functions too.",
            "Create these associations."
        ],
        [
            "So in order to have this Association framework work.",
            "We need to have object exemplars.",
            "We need to have lots of them, because objects will occur in many different configurations, and we're going to have this nonparametric approach.",
            "We need to kind of capture all the different visual appearances that as much as we can, so we use the label me tool and label need data set.",
            "This is constantly growing datasets put together by researchers at MIT and you log onto a website and you click certain points around the object, and you're then.",
            "Allowed to label this object so you might type artillery or cannon, or almost anything you want for this particular object, and.",
            "There's now thousands and thousands of images that are labeled.",
            "Some images are very densely labeled, some aren't.",
            "But the key thing to note here is that we will then have our training set or these object exemplars.",
            "We will have segments obtained from what people clicked around the object as well as a certain label.",
            "And the particular subset of label me that we use contains about 13,000 object exemplars that span 171 unique labels.",
            "We don't try to directly treat these as object categories, because a person is allowed to type in any label they want, so we have the problem where sometimes somebody could put in vehicle, sometimes car, and these are actually different labels in the tool doesn't know anything about this directly, so we're going to just work with these as.",
            "Different labels.",
            "Now an interesting question."
        ],
        [
            "And to ask ourselves before I continue is.",
            "How can I?"
        ],
        [
            "Objects be similar, like what does it mean for two different objects to be similar?",
            "So here have displayed two different cars and if I were to ask anybody how are these two objects similar?",
            "Could you devise some sort of features that let you say that these objects are similar to each other?",
            "Many people could come up with those so well this shape is pretty similar.",
            "There's some sort of alignment between the wheels, so some sort of rough feature correspondence works in this case, but color in this case isn't so much useful.",
            "I mean, cars can vary in color.",
            "Now when we look at."
        ],
        [
            "Other objects that are in these rigid objects like cars, grass regions, so we can see that the polygons that people clicked in the image have significantly different shape.",
            "And if we relied too much on just a shape based representation, it would say that these two objects are very dissimilar.",
            "But because these are examples of graphs, we know that the green is very very informative and if two regions are basically green and have similar texture, that's reasonable said that they're both, grass is."
        ],
        [
            "Other cases of objects just stop signs might really have similar shape, color, texture, almost everything you can think of.",
            "Happens in the world stop signs.",
            "There isn't that much variation in stop signs and we need somehow to be able to cope with all these different types of ways that objects can be similar."
        ],
        [
            "So in order to kind of capture these different shape color texture attributes.",
            "About the different features that we compute for each object exemplar, and then exactly how they're used.",
            "So on the left.",
            "Here we see this is a picture of a car.",
            "This is an object exemplar.",
            "This is something that comes out of label knee.",
            "And compute different types of features that roughly capture the shape, texture, color as well as absolute location properties of this object.",
            "So it's capture things like shape.",
            "We just compute the centered masks.",
            "So this is translation invariant, not so much scale invariant which kind of captures roughly the shape of this object as well as the bounding box extent and pixel area.",
            "These are very simple features for texture, we have a pixelize text.",
            "Computation and we look at the histogram of taxons over the interior of the object as well as along the boundaries for color.",
            "Just average color standard deviation in each of the color channels as well as a simple histogram.",
            "Now for the absolute location, we also look at these absolute position mask, which in this case maybe isn't that informative.",
            "But for things like skies and roads we would then have this absolute position.",
            "Mask would pretty much say all skies are just some things at the top and Rd something at the bottom and these kind of absolute position features help us distinguish between things like skies and roads, which from the local appearance POV might just be.",
            "These kind of grayish blueish things but once we factor in this absolute position then it's very easy to.",
            "To discriminate between them.",
            "So now though."
        ],
        [
            "I've defined is this 14 different features that capture shape, location and texture?",
            "Rather than just manually setting for the weights for how to combine these different features, the game now is going to be learn a different combination of weights.",
            "Learn how to combine these different features differently for each object in our training database for each object exemplar, and there's different set of weights.",
            "Basically, the 14 numbers plus some bias is a distance function.",
            "This is going to be learned differently for each exemplar, and this is motivated by earlier work coming out of Berkeley.",
            "That did something very similar, except they were working with kind of the SIFT local patches and in here the features are defined over segments that are much more holistic representations of each object.",
            "So."
        ],
        [
            "I'll have a quick little walkthrough for what it means to learn a distance function.",
            "This is 1 example for what we're learning.",
            "The distance function for the car on the bottom left I'll refer to as the focal exemplar.",
            "This is the one who's learning problem we're solving and will be solving as many of these, or about 13,000 of these different problems.",
            "And this is just to make things easy.",
            "This is just a 2D representation of what's going on.",
            "Meaning every other object.",
            "We can compute the distance along these 14 different features.",
            "We can compute the distance to this focal exemplar, and in this visualization this is the two D demonstration of what's going on.",
            "So along the X axis there's distance in shape and along the Y axis is the distance in color.",
            "And we want to learn a distance function which is a combination of these weights and in this case in this distance space what happens?"
        ],
        [
            "Is that?",
            "A decision boundary in this distant space we can reveal interpreted as just this combination of weights that will be learning for this example are the idea is that the decision boundary will split up all the other exemplars into the similar side, and the dissimilar side.",
            "We'll also have some other objects in this case for other cars that we won't necessarily care about.",
            "Meaning that it's going to be very difficult to find one distance function that somehow magically puts all the cars on the similar side and all the non cars on the dissimilar side.",
            "The idea is that there's only some subset of other cars that we should say are actually similar to this.",
            "Other cars that appear in different configurations.",
            "We should say that, well, we don't really know, but they are similar or not.",
            "I mean, there's probably as much variation in some other cars.",
            "There's for a window or a building region.",
            "So we'll be trying to actually learn the decision boundary as well as this subset of other objects with the same label that should fall on the similar side."
        ],
        [
            "Basic.",
            "Learning problem has its own optimism optimization problem.",
            "The objective function, which in this particular case, if you imagine we just neglect Alpha.",
            "And we just have some over all the different objects that fall and have the same class label, as well as all the objects that don't have the same class label.",
            "This is just.",
            "There's a loss function that's associated with each object.",
            "This is a very simple convex optimization problem.",
            "If we don't have the Alpha involved in here.",
            "The idea now is that for all the objects that have the same label will associate a binary variable Alpha that can only be one or zero, which will.",
            "Act is just kind of an activation for whether that object is in the.",
            "Actually weather work."
        ],
        [
            "The idea with the Alpha is whether it actually is a similar exemplar, or it's one that we shouldn't care about.",
            "So Alpha here is binary vector and the idea is that.",
            "The number of non zero entries in Alpha will be small in this particular case it's fixed to K which is equal to 10.",
            "This basically says that for each exemplar we will.",
            "Have only ten other examples fall on this similar side and on the dissimilar side will just place all the other objects that have a different label which will always say should be dissimilar and now we will be trying to learn this real valued weight vector W as well as Alpha this binary vector which will indicate which subset of the examples of the same label are actually similar."
        ],
        [
            "On and as I said earlier, if we already Alpha wasn't in the problem, or if we already had the alphas, which are binary, it would mean that some of the.",
            "Other examples of the same class which drop out they would have an Alpha of zero, and once we had fixed an Alpha we could just solve this optimization problem.",
            "This could be logistic regression or SVM optimization problem depending on the form of the loss function.",
            "And how we solve this is very simple.",
            "We just we iterate between solving these two terms.",
            "Given the other term.",
            "So we start with some initial distance function, so we now have initial way to measure these exemplars, and given that we can then sort all the other exemplars with the same label.",
            "Given this initial distance function.",
            "And then find this best configuration of the Alphas.",
            "And once we have the alphas then that defines which of the terms drop out of this optimization problem and then we can just solve the convex optimization problem and in this case L is a hinge loss function squared which allows us to use a second order technique in the primal software very efficiently.",
            "But we could use the regular hinge loss or any or mean.",
            "A logistic regression type loss function.",
            "Anything else could work too.",
            "And in order to initialize this whole procedure, we use a text on histogram distance, meaning that we basically put zeros on all the weights except just to text on histogram and we found that.",
            "Empirically, this tends to work very well for lots of different objects.",
            "Actually works better than weighing all the different distances uniformly, setting, giving them all ones.",
            "Now another way to kind of visual."
        ],
        [
            "What's actually happening here?",
            "But if you have a lot of data and you tried to learn the web."
        ],
        [
            "For example, are and.",
            "Then you quite a lot of a duplicate entry for that one.",
            "What is that?",
            "So you find a lot of plays at the segments are exactly the same like the one that you tried to learn.",
            "If OK and then it doesn't say it doesn't learn anything, right?",
            "Because any anything could distinguish between any feature to do good enough to distinguish between the positive send you have and the negative side.",
            "If the actual data is actually redundant and it's exactly the same segment, meaning it will have a distance of 0 to itself.",
            "Along all these different attributes then this will breakdown if that actually does happen.",
            "So in this case, because K is equal to 10, as long as that happens only once or twice, that's OK.",
            "But if it does actually happen where you just repeat almost training it 10 times, then this is actually going to break it down.",
            "Yeah.",
            "So another way to kind of visualize what's actually happening is seeing how this is similar to nonparametric density estimation.",
            "You can imagine these are now three different types of classes, kind of embedded."
        ],
        [
            "In this high dimension, there's a color axis Anna shape axis.",
            "And in nonparametric parametric density estimation, people usually."
        ],
        [
            "Up some sort of kernel and they just plop this around each of the data points and then they have a nonparametric density estimator for each of the different classes.",
            "And learning distance function."
        ],
        [
            "And can be thought of as these learning the shape of this kind of similarity, kernel centered around each data point.",
            "One of the ways you can think about this now, since it's very actually very difficult to display in the real high dimensional space.",
            "Any kind of figure like this from real data.",
            "Alternatively, because.",
            "We learned a bias for the different weight vector, which means that we actually have now.",
            "The region isn't just arbitrarily drawn, there isn't actually significance to this to the extent of each of these kernels.",
            "Rather than displaying this as a bunch of our regions.",
            "You could just imagine connecting all the different exemplars that are active."
        ],
        [
            "Be similar to each other, So what happens is if."
        ],
        [
            "If this object falls within kind of similarity region of this object and vice versa, we could imagine just drawing an edge in between them and kind of single the output."
        ],
        [
            "Learning is not only these distance function, but also kind of a similarity type graph."
        ],
        [
            "So to see what actually happens now in real example, because in this case I can't draw regions and some 2000 dimensional space.",
            "I can only display one of these graphs here.",
            "Now cars are very popular object that occurs in these outdoor images, so there's actually a couple of 1000 of car, couple thousand car instances and this is kind of a zoomed version for what happens after we learn these car distance functions.",
            "And even tho K was equal to 10, meaning we are forcing a car to be similar to 10 other cars.",
            "There was this kind of do not care.",
            "There were still lots of other cars that had Alpha is equal to 0, meaning they fell out of the optimization problem so they could appear on the similar or dissimilar side, and we actually often see cars that have actually lots of different connections a lot more than 10.",
            "In this case there are a lot of cars and this kind of very simple.",
            "Back view of a car appears so often it's no surprise that connections are much denser."
        ],
        [
            "So in the next couple of slides, I'm going to kind of quickly visualize what actually happens during this distance function learning.",
            "More on some other examples so.",
            "On the top there will be this kind of initial car that we're considering.",
            "This is what happens if we use the initial distance and we sort all the other exemplars to the focal example using a kind of initial heuristically defined distance, which is this text on histogram distance and after learning these are then the four most similar object exemplars.",
            "So in this case, we see that when you look at the distance function as kind of this bar plot overweights, we see there's a lot of emphasis on the centered mask as well as the color, so it's no surprise.",
            "Now the most similar objects actually.",
            "I have similar shape and color."
        ],
        [
            "Here's another example where before learning just looking at a kind of this histogram bag of words, type representation.",
            "Lots of other exemplars, just, you know, mean couple of them are reasonable, but for example, the most similar one is just some kind of clutter associated with cars.",
            "And after learning, we see that actually all the similar objects.",
            "The labels in the interim propagating the labels right?",
            "Add to the example from the ones you found similar.",
            "So in this case they both perform the same right.",
            "They both get the same labels.",
            "Yeah images you can see it is different, but the labels and they're going to be the same.",
            "Do you have any examples where you know the label will be different?",
            "Because your your training method will be better.",
            "Sure, sure sure.",
            "So I think here maybe is 1 example of exactly what you're referring."
        ],
        [
            "Yeah, So what happens if you use this kind of texture histogram type techniques measure and you don't use any shape or anything else?",
            "You might have this piece of sidewalk, or better yet a car with a fence in front of it, who's texture happens to match with the building.",
            "But then after you do the training procedure, you find that now the most similar object.",
            "Actually, not only do they have the correct label, but they actually visually look more reasonable."
        ],
        [
            "So so far I've talked about what happens during training and those other images were actually the result of what happens during training, and I didn't talk about actually what happens at Test time at recognition time.",
            "So what happens at recognition time is that now this is the configuration of learning.",
            "We have all these distance functions.",
            "And we'll have some new input, some new region."
        ],
        [
            "And we want to say OK, is this region anything we've seen before?",
            "So this region lands somewhere in this.",
            "High dimensional descriptor space and then we compute all the distances between this input and all the other."
        ],
        [
            "Exemplars using their distance functions.",
            "And then we only retain."
        ],
        [
            "The exemplars that say they're actually similar to it, so we can see that from all of these different ones here to this particular exemplar, whose region is kind of this large region.",
            "This particular input.",
            "Only falls inside the similar region of this, so we would say that this new input associated with this particular exemplar.",
            "And when we have, that is."
        ],
        [
            "Confidence measure that basically says the more objects we associate with, the more confident should be in the recognition and if those returned objects associating objects all returns smaller distances, we should also be more confident in their recognition.",
            "So this is kind of 1 simple way to just kind of combine these different numbers.",
            "There are lots of different ways of doing this, but the two intuitively things that make sense is that if some new input we say wow, this has been very similar to many things we've seen, we should be more confident in it.",
            "And if all those previously seen examples return smaller distances, we should also be more confident."
        ],
        [
            "So what actually happens is at the real scenario of looking at a new image.",
            "So far I only talked about given an input, how can you apply these distance functions to recognition?",
            "But the reality is in an image we don't know what region corresponds to what object.",
            "We have this chicken and egg problem saying well, if we already had recognition, maybe we could do segmentation or if we had segmentation then I really show you how you can do recognition and the problems that we have neither and we need somehow to initialize this procedure.",
            "So what we do is we generate multiple image segmentations for an image.",
            "The idea is that it's going to be very, very difficult to somehow have a magical algorithm that can segment an image once and magically give us regions that correspond to objects.",
            "But if we run many of these algorithms many different times, there's a.",
            "There's a Good Hope that each of the objects of interest will pop out as at least one segment in this whole collection of segments.",
            "So we use mean shift and normalized cuts and use.",
            "Those segments produced by those algorithms as well as pairs and triplets of adjacent segments.",
            "And since we run mean shift and normalized cuts many different times at the end of the day, we have about 10,000 different segments per image.",
            "For now, that will be 10,000 different inputs to all the different distance functions.",
            "Now, in order to actually make this procedure work, meaning that we don't want very bad segments that we've never seen before to kind of start associating with random cars and random clutter.",
            "We also generate lots of bad segments and during the learning procedure we can always put onto this similar side.",
            "Lots of these kind of garbage.",
            "Bad segments that are actually often generated by a segmentation engine.",
            "So once we have images and we know where objects land, we can just kind of.",
            "Gotta go crazy and start generating very bad segments and always throw those into the learning procedure as kind of negative negative examples.",
            "In this case, that actually helps.",
            "So now once we have this collection of segments, we just apply these distance functions to all these segments.",
            "So if we have 13,000 exemplars and 10,000 segments per image, we have to compute all of those distances, and then we can reason about which segments."
        ],
        [
            "We're good.",
            "Which ones weren't.",
            "So looking at a test set which is now, this is some other held out set of labeled me.",
            "We can then create all these different associations and Harry test settings, and there's a test set of about 150 images or so and these are that the best recognitions now out of the 150 different images.",
            "So the top only the best and these actually are just the best ones.",
            "I mean the list is actually very long.",
            "But what we see here is that on the left these are actually bottom up segments, so these are the output of some segmentation algorithm, and they're not perfect.",
            "Sometimes you will miss a wheel, and these are the different examples we've seen before.",
            "These are kind of training data that was associated that associates with each of these.",
            "Inputs.",
            "And we can see that this appears to work fairly well each time we see some object in some configuration that's seen before, we have many examples.",
            "That basically means we're often very confident in recognizing it."
        ],
        [
            "And one thing we can do now that we have an image and we generate lots of these object associations is we can try to see how we can use all those associations."
        ],
        [
            "Is 2.",
            "To parse an image so this is the image I showed earlier in the talk and once we generate different associations between different regions and different exemplars, we can just sort that entire list.",
            "And then we can vary in a greedy fashion, take the best Association, keep that one, and then we throw away all the other segments that were too similar to this building segment and then go to the next best segment, which happens to be then this car.",
            "Then throw away all the other segments.",
            "That kind of overlap too much already.",
            "This large region and this one and kind of go to the next best one, and.",
            "What happens is this very simple approach and some images happens to work very well in this kind of is a kind of vision for the thing to do next, as in coming up the more principled way kind of combine all these associations and then for an image tried to then reason about all the different objects at the same time.",
            "So a greedy type algorithm might work well for a couple of images, but realistically just applying this ingredient doesn't work for all the images."
        ],
        [
            "So this is for example another.",
            "Image another one showing for doing the same kind of greedy stacking of the best associations and what we see again as previously seen is that the bottom up segments aren't perfect, meaning sometimes they just spill into the background.",
            "Sometimes they miss certain parts of the object, but what happens is kind of enough of the object is visible.",
            "Then these associations are still reasonable."
        ],
        [
            "So to just kind of quickly conclude an talk about some of the different things I discussed are so exemplar based model and segments and segment centric features work well for both freeform things like grass as well as fixed extent things like cars.",
            "So generally people have different approaches that work for things like cars and people and segmentation approach.",
            "Approaches, then they apply.",
            "Think skies and buildings and here we have kind of the same type representation that works well for both types of object.",
            "Once we have observed many instances of an object, then these distance functions are pretty good at actually localising these objects.",
            "Now the success of this entire approach relies on having ground truth segmentations during learning, which is kind of like the biggest bottleneck in the sense that can't just use Flickr images, which we might have labels for those images, but we don't have ground truth segmentations, and this kind of approach relies on having those segmentations.",
            "And for future work, need a clever way to integrate these objects, hypothesised apart to parse images?",
            "Alright, well that's it.",
            "Any questions?",
            "Have you thought about including semantic features into the work you're doing?",
            "Like, for example, you mentioned initially that the labels, sometimes they have cars.",
            "Sometimes if you call, you know that even though they're in the same, you don't know.",
            "They're saying would be beneficial to have something like word net worth.",
            "The labels are similar, So what actually happens is.",
            "I'm sure to repeat the question is, is it useful in using some tool like word, net, something that can already help with some of the problems such that certain segments are labeled vehicle certain reliable car using something?"
        ],
        [
            "Word net you can figure out that both are instances of kind of some sort of high level class.",
            "That is a very reasonable thing to do, and in this particular case, that's something that would probably help a good amount.",
            "What I didn't show in just 30 minutes is that.",
            "There are actually cases of where the types of confusions that are learned by this method actually correspond to what word net would tell you, meaning that often it ends up that if some object is labeled vehicle, but there are a lot more that looked like it labeled car, it will happen when we're learning a distance function for that vehicle.",
            "Still, lots of cars will land on that similar side.",
            "So there's a little bit of robustness to some of these problems, but I agree that kind of word net is maybe better long term solution to also in terms of semantic features like you showed an example you had the road and the sidewalk and label both his roads think you're less example.",
            "Yeah, so the 3rd Rd sidewalk there right?",
            "Yeah, I mean what?"
        ],
        [
            "Happens is, you know this is all stuff that came from label me.",
            "So people actually label these things as Rd.",
            "But not, but not that right?",
            "I mean that that that image you have there you just because it sounds similar to it looks similar to the segment to the label thing Rd.",
            "You're going to label it road, right?",
            "Yeah, so some sort of semantic relation that says, you know that the sidewalk is next to a road, or you know, like how things how objects relate to each other.",
            "Yeah, so at this point, each segment that was generated, I kind of cheated independently.",
            "And then once I sorted this list an I applied a very simple kind of greedy ordering.",
            "Then this works really well.",
            "But this whole kind of idea of reasoning about these relationships that's really, I think, where.",
            "It's really needed to kind of make all this really, really work kind of as a long term, you know.",
            "Picture of Time square right?",
            "What is the sort of the desired label in that situation?",
            "And you could have you know, buildings, people, roads, whatever.",
            "But would it be more meaningful if you set time square?",
            "I mean like if you have if you tell someone else I'm going to show a picture of Times Square versus where show picture of buildings and so on so forth.",
            "Isn't there more information finding a specific label to a location rather than?",
            "Yeah, it really ends up that you know.",
            "Kind of computer vision.",
            "People usually think of all you know break up the image into object is the ultimate goal.",
            "But I agree with you that often just saying this is Times Square and being done with the image is probably better than spending all this work on.",
            "Trying to decipher anything else, and I think without any particular real application in mind, it's hard to say what should the goal be.",
            "So if you have a robot that's navigating the world and then it's reasoning about objects, or maybe this would be better, but if you're trying to sort images for human using their collection, maybe just saying time squares.",
            "Can be an order of magnitude more informative than seeing where the road is in that image.",
            "So Can you imagine a way to generalize this so that it wouldn't require detailed segmentation and training?",
            "I mean, I can imagine putting an X on a point on the car have it sort of jointly learn both the segment the car and find the features about what it has segmented.",
            "Yeah, so I have done some work over the summer.",
            "That this is kind of more recent work on saying if you just have an image that you know contains an instance of an object, could you Start learning off that?",
            "And, well, I'm not going to talk too much about it, just the basic idea was that.",
            "You can imagine that you're not only trying to learn a distance function for this object, but you're also trying to learn its segmentation.",
            "So you could imagine trying to segment these images using your best algorithm, your first pass, trying your best shot, and if 10% of the objects you segmented out nicely, that might be enough to kind of bootstrap the learning so that you can improve these other segments.",
            "Um?",
            "So there's a car somewhere in this image, versus this is a point on the car you take it from there, but what's nice is if you get images from the Internet where maybe a lot of the objects of white background simple backgrounds, you might be able to segment, you know 5000 cars, and then when you look at 5000 other cars embedded inside of images.",
            "Once you've already learned in this kind of segmentation recognition model, you might be able to use these kind of Internet images to help bootstrap yourself.",
            "Searching on eBay or something for car taking the image and trying to segment just searching for the object specifically.",
            "Trying to find more data before.",
            "Yeah, but it seems like using API and just query.",
            "Yeah, I mean we actually we use a Google image search we found I mean lots of images.",
            "Just have an object of interest with this very fake blue background or white or whatever that even though it's not really segmented, it kind of is segmented, meaning you can use a lot of these heuristic techniques just going to subtract the white background and then you basically have training data for any kind of approach.",
            "Facebook people can sort of segment images according to I think most of the time these people, but I don't use it for other objects.",
            "Is there any value in that data?",
            "I mean, I don't even if it's assessable, but if it's something, yeah, I know that.",
            "I mean, we actually when you look at kind of the images that people captures, people are in there.",
            "So Facebook is no surprise that people in faces, that's really the number one thing I haven't heard of anybody using that for non people non faces I imagine with the kind of social networking tool it really is faces and recognizing people that.",
            "The most important thing maybe Time Square would also be valuable like a scene scene level label.",
            "But anything like this people would just say I'm not going to click on cars, you know.",
            "Alright thanks."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Alright so I am the second speaker for today and I'm going to try not to spill too much over the time and everybody's dying to get back to their own research.",
                    "label": 0
                },
                {
                    "sent": "So my name is Tomasz and this is going to talk about joint work with my advisor Alyosha Efros from the Robotics Institute.",
                    "label": 1
                },
                {
                    "sent": "This is also a CPR 2008 paper.",
                    "label": 0
                },
                {
                    "sent": "Title is a recognition by Association and what I'm going to be talking about today is object recognition.",
                    "label": 0
                },
                {
                    "sent": "This is something that is one of the biggest problems in computer vision.",
                    "label": 0
                },
                {
                    "sent": "It's also a big interest to learning community and basic idea is that when you look at the word recognition or re cognition, etymologically, it means that we're cognizing something again.",
                    "label": 0
                },
                {
                    "sent": "So when looking at objects, instead of asking the question.",
                    "label": 1
                },
                {
                    "sent": "What is this object will be asking the question?",
                    "label": 0
                },
                {
                    "sent": "What is it like?",
                    "label": 0
                },
                {
                    "sent": "How is it compared to something we've seen before in the past?",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the basic problem that I'll be looking at is recognizing many different types of objects inside an image.",
                    "label": 1
                },
                {
                    "sent": "So rather than looking at just cars or just faces, the goal will be given an image to try to reason about all the different types of objects that we could find inside the image.",
                    "label": 1
                },
                {
                    "sent": "The key observation of this research is that recognition becomes significantly easier once we have the correct segmentation for an object.",
                    "label": 1
                },
                {
                    "sent": "So once we already know what region we should be looking at in the image, and then we have to figure out what it is, the problem becomes easier.",
                    "label": 0
                },
                {
                    "sent": "And the basic approach is using a segment centric object representation and an exemplar based nonparametric recognition model.",
                    "label": 0
                },
                {
                    "sent": "And that's what I'll be talking about.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It's worthwhile first taking a look at what generally is meant by understanding an image in the computer vision community, so here's the zoomed in version of this input image and what we're interested in in understanding this image.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is naming all the different objects that are displayed inside this image so reasonable object names or things like building face streetlamp walls or bust and we take actually close?",
                    "label": 0
                },
                {
                    "sent": "Look at these object names.",
                    "label": 0
                },
                {
                    "sent": "What we find out is that they're not refering so much to these particular instances.",
                    "label": 0
                },
                {
                    "sent": "In this image there actually object categories, so usually image understanding means categorizing all the different objects inside this image.",
                    "label": 0
                },
                {
                    "sent": "But if we were to represent this image by all the different object categories that it contains, what would happen is we were going to.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Picture that looks like.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This and it wouldn't really tell us much about the actual image.",
                    "label": 0
                },
                {
                    "sent": "While it's still very important to tell what's in the image, just saying that this is the layout of these different categories, there is an infinite amount of images that could easily map the scenario and tells you very little about what the image looks like.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So what we did in this paper is we propose a different way of looking at recognition.",
                    "label": 0
                },
                {
                    "sent": "So given input image shown on the left rather than directly trying to categorize different regions and just trying to represent the image by saying it contains building here cars here in a Rd there.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Let's try to associate things that we have seen before in the past on the right here or previously seen objects and associate each one of those objects with some chunk of the visual input.",
                    "label": 0
                },
                {
                    "sent": "And when we've done recognition this way, what happens is we have regions.",
                    "label": 0
                },
                {
                    "sent": "We have things that they previously looked like.",
                    "label": 0
                },
                {
                    "sent": "It gives us a much more colorful picture of what an image could actually look like.",
                    "label": 0
                },
                {
                    "sent": "And once we've associated pieces of the visual input with things that we have seen before, we can then look at the labels or the categories so.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You see it with those objects we've seen before, and we can propagate them back into the image.",
                    "label": 0
                },
                {
                    "sent": "But what's different in this view is that rather than directly trying to categorise what we're trying to do now is, we're trying to associate things we've seen before in the past, and once we have these associations, we can look at what other metadata is stored with these objects.",
                    "label": 0
                },
                {
                    "sent": "Things like labels.",
                    "label": 0
                },
                {
                    "sent": "Imagine a robot stores.",
                    "label": 0
                },
                {
                    "sent": "Whether this is something that's going to harm it or not, or anything else you can kind of propagate that information back into the image.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So just to quickly summarize what I'll be talking about throughout the rest of the talk is.",
                    "label": 0
                },
                {
                    "sent": "The basic contributions of this paper are first posing object recognition as Association in order to have this Association framework actually work.",
                    "label": 0
                },
                {
                    "sent": "When you use a large number of object exemplars, we need to capture all the different appearances of lots of different objects.",
                    "label": 1
                },
                {
                    "sent": "And in order to actually create this associations to see if something we've seen in the past associated with something new, we needed a way to.",
                    "label": 0
                },
                {
                    "sent": "To kind of compare these new things with old things to do that we.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Learn a different object similarity measure per exemplar.",
                    "label": 1
                },
                {
                    "sent": "So rather than heuristically defining some sort of similarity measure, that's going to magically work for things like buildings and skies as well as cars and people we have each object that we've seen in the past learn its own similarity function.",
                    "label": 0
                },
                {
                    "sent": "That will let us create associations.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And finally, since we're interested in real images and the real images have the problem where we're not going to be given any segmentations.",
                    "label": 0
                },
                {
                    "sent": "Objects occur in many different configurations.",
                    "label": 0
                },
                {
                    "sent": "Only we want to reason about where the objects are in the image and in order to do this, we use a recognition based object segmentation strategy where we use multiple image segmentations to generate lots of potential regions where objects could be in, and then we use the object similarity functions too.",
                    "label": 1
                },
                {
                    "sent": "Create these associations.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So in order to have this Association framework work.",
                    "label": 0
                },
                {
                    "sent": "We need to have object exemplars.",
                    "label": 1
                },
                {
                    "sent": "We need to have lots of them, because objects will occur in many different configurations, and we're going to have this nonparametric approach.",
                    "label": 0
                },
                {
                    "sent": "We need to kind of capture all the different visual appearances that as much as we can, so we use the label me tool and label need data set.",
                    "label": 0
                },
                {
                    "sent": "This is constantly growing datasets put together by researchers at MIT and you log onto a website and you click certain points around the object, and you're then.",
                    "label": 0
                },
                {
                    "sent": "Allowed to label this object so you might type artillery or cannon, or almost anything you want for this particular object, and.",
                    "label": 0
                },
                {
                    "sent": "There's now thousands and thousands of images that are labeled.",
                    "label": 0
                },
                {
                    "sent": "Some images are very densely labeled, some aren't.",
                    "label": 0
                },
                {
                    "sent": "But the key thing to note here is that we will then have our training set or these object exemplars.",
                    "label": 0
                },
                {
                    "sent": "We will have segments obtained from what people clicked around the object as well as a certain label.",
                    "label": 0
                },
                {
                    "sent": "And the particular subset of label me that we use contains about 13,000 object exemplars that span 171 unique labels.",
                    "label": 1
                },
                {
                    "sent": "We don't try to directly treat these as object categories, because a person is allowed to type in any label they want, so we have the problem where sometimes somebody could put in vehicle, sometimes car, and these are actually different labels in the tool doesn't know anything about this directly, so we're going to just work with these as.",
                    "label": 0
                },
                {
                    "sent": "Different labels.",
                    "label": 0
                },
                {
                    "sent": "Now an interesting question.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And to ask ourselves before I continue is.",
                    "label": 0
                },
                {
                    "sent": "How can I?",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Objects be similar, like what does it mean for two different objects to be similar?",
                    "label": 0
                },
                {
                    "sent": "So here have displayed two different cars and if I were to ask anybody how are these two objects similar?",
                    "label": 1
                },
                {
                    "sent": "Could you devise some sort of features that let you say that these objects are similar to each other?",
                    "label": 0
                },
                {
                    "sent": "Many people could come up with those so well this shape is pretty similar.",
                    "label": 0
                },
                {
                    "sent": "There's some sort of alignment between the wheels, so some sort of rough feature correspondence works in this case, but color in this case isn't so much useful.",
                    "label": 0
                },
                {
                    "sent": "I mean, cars can vary in color.",
                    "label": 0
                },
                {
                    "sent": "Now when we look at.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Other objects that are in these rigid objects like cars, grass regions, so we can see that the polygons that people clicked in the image have significantly different shape.",
                    "label": 0
                },
                {
                    "sent": "And if we relied too much on just a shape based representation, it would say that these two objects are very dissimilar.",
                    "label": 0
                },
                {
                    "sent": "But because these are examples of graphs, we know that the green is very very informative and if two regions are basically green and have similar texture, that's reasonable said that they're both, grass is.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Other cases of objects just stop signs might really have similar shape, color, texture, almost everything you can think of.",
                    "label": 0
                },
                {
                    "sent": "Happens in the world stop signs.",
                    "label": 0
                },
                {
                    "sent": "There isn't that much variation in stop signs and we need somehow to be able to cope with all these different types of ways that objects can be similar.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So in order to kind of capture these different shape color texture attributes.",
                    "label": 0
                },
                {
                    "sent": "About the different features that we compute for each object exemplar, and then exactly how they're used.",
                    "label": 0
                },
                {
                    "sent": "So on the left.",
                    "label": 0
                },
                {
                    "sent": "Here we see this is a picture of a car.",
                    "label": 0
                },
                {
                    "sent": "This is an object exemplar.",
                    "label": 0
                },
                {
                    "sent": "This is something that comes out of label knee.",
                    "label": 0
                },
                {
                    "sent": "And compute different types of features that roughly capture the shape, texture, color as well as absolute location properties of this object.",
                    "label": 0
                },
                {
                    "sent": "So it's capture things like shape.",
                    "label": 0
                },
                {
                    "sent": "We just compute the centered masks.",
                    "label": 0
                },
                {
                    "sent": "So this is translation invariant, not so much scale invariant which kind of captures roughly the shape of this object as well as the bounding box extent and pixel area.",
                    "label": 0
                },
                {
                    "sent": "These are very simple features for texture, we have a pixelize text.",
                    "label": 0
                },
                {
                    "sent": "Computation and we look at the histogram of taxons over the interior of the object as well as along the boundaries for color.",
                    "label": 0
                },
                {
                    "sent": "Just average color standard deviation in each of the color channels as well as a simple histogram.",
                    "label": 0
                },
                {
                    "sent": "Now for the absolute location, we also look at these absolute position mask, which in this case maybe isn't that informative.",
                    "label": 1
                },
                {
                    "sent": "But for things like skies and roads we would then have this absolute position.",
                    "label": 0
                },
                {
                    "sent": "Mask would pretty much say all skies are just some things at the top and Rd something at the bottom and these kind of absolute position features help us distinguish between things like skies and roads, which from the local appearance POV might just be.",
                    "label": 0
                },
                {
                    "sent": "These kind of grayish blueish things but once we factor in this absolute position then it's very easy to.",
                    "label": 0
                },
                {
                    "sent": "To discriminate between them.",
                    "label": 0
                },
                {
                    "sent": "So now though.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I've defined is this 14 different features that capture shape, location and texture?",
                    "label": 0
                },
                {
                    "sent": "Rather than just manually setting for the weights for how to combine these different features, the game now is going to be learn a different combination of weights.",
                    "label": 0
                },
                {
                    "sent": "Learn how to combine these different features differently for each object in our training database for each object exemplar, and there's different set of weights.",
                    "label": 1
                },
                {
                    "sent": "Basically, the 14 numbers plus some bias is a distance function.",
                    "label": 0
                },
                {
                    "sent": "This is going to be learned differently for each exemplar, and this is motivated by earlier work coming out of Berkeley.",
                    "label": 0
                },
                {
                    "sent": "That did something very similar, except they were working with kind of the SIFT local patches and in here the features are defined over segments that are much more holistic representations of each object.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I'll have a quick little walkthrough for what it means to learn a distance function.",
                    "label": 0
                },
                {
                    "sent": "This is 1 example for what we're learning.",
                    "label": 0
                },
                {
                    "sent": "The distance function for the car on the bottom left I'll refer to as the focal exemplar.",
                    "label": 1
                },
                {
                    "sent": "This is the one who's learning problem we're solving and will be solving as many of these, or about 13,000 of these different problems.",
                    "label": 0
                },
                {
                    "sent": "And this is just to make things easy.",
                    "label": 0
                },
                {
                    "sent": "This is just a 2D representation of what's going on.",
                    "label": 0
                },
                {
                    "sent": "Meaning every other object.",
                    "label": 0
                },
                {
                    "sent": "We can compute the distance along these 14 different features.",
                    "label": 0
                },
                {
                    "sent": "We can compute the distance to this focal exemplar, and in this visualization this is the two D demonstration of what's going on.",
                    "label": 0
                },
                {
                    "sent": "So along the X axis there's distance in shape and along the Y axis is the distance in color.",
                    "label": 0
                },
                {
                    "sent": "And we want to learn a distance function which is a combination of these weights and in this case in this distance space what happens?",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Is that?",
                    "label": 0
                },
                {
                    "sent": "A decision boundary in this distant space we can reveal interpreted as just this combination of weights that will be learning for this example are the idea is that the decision boundary will split up all the other exemplars into the similar side, and the dissimilar side.",
                    "label": 1
                },
                {
                    "sent": "We'll also have some other objects in this case for other cars that we won't necessarily care about.",
                    "label": 0
                },
                {
                    "sent": "Meaning that it's going to be very difficult to find one distance function that somehow magically puts all the cars on the similar side and all the non cars on the dissimilar side.",
                    "label": 0
                },
                {
                    "sent": "The idea is that there's only some subset of other cars that we should say are actually similar to this.",
                    "label": 0
                },
                {
                    "sent": "Other cars that appear in different configurations.",
                    "label": 0
                },
                {
                    "sent": "We should say that, well, we don't really know, but they are similar or not.",
                    "label": 0
                },
                {
                    "sent": "I mean, there's probably as much variation in some other cars.",
                    "label": 0
                },
                {
                    "sent": "There's for a window or a building region.",
                    "label": 0
                },
                {
                    "sent": "So we'll be trying to actually learn the decision boundary as well as this subset of other objects with the same label that should fall on the similar side.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Basic.",
                    "label": 0
                },
                {
                    "sent": "Learning problem has its own optimism optimization problem.",
                    "label": 0
                },
                {
                    "sent": "The objective function, which in this particular case, if you imagine we just neglect Alpha.",
                    "label": 0
                },
                {
                    "sent": "And we just have some over all the different objects that fall and have the same class label, as well as all the objects that don't have the same class label.",
                    "label": 0
                },
                {
                    "sent": "This is just.",
                    "label": 0
                },
                {
                    "sent": "There's a loss function that's associated with each object.",
                    "label": 0
                },
                {
                    "sent": "This is a very simple convex optimization problem.",
                    "label": 0
                },
                {
                    "sent": "If we don't have the Alpha involved in here.",
                    "label": 0
                },
                {
                    "sent": "The idea now is that for all the objects that have the same label will associate a binary variable Alpha that can only be one or zero, which will.",
                    "label": 0
                },
                {
                    "sent": "Act is just kind of an activation for whether that object is in the.",
                    "label": 0
                },
                {
                    "sent": "Actually weather work.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The idea with the Alpha is whether it actually is a similar exemplar, or it's one that we shouldn't care about.",
                    "label": 0
                },
                {
                    "sent": "So Alpha here is binary vector and the idea is that.",
                    "label": 0
                },
                {
                    "sent": "The number of non zero entries in Alpha will be small in this particular case it's fixed to K which is equal to 10.",
                    "label": 0
                },
                {
                    "sent": "This basically says that for each exemplar we will.",
                    "label": 0
                },
                {
                    "sent": "Have only ten other examples fall on this similar side and on the dissimilar side will just place all the other objects that have a different label which will always say should be dissimilar and now we will be trying to learn this real valued weight vector W as well as Alpha this binary vector which will indicate which subset of the examples of the same label are actually similar.",
                    "label": 1
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "On and as I said earlier, if we already Alpha wasn't in the problem, or if we already had the alphas, which are binary, it would mean that some of the.",
                    "label": 0
                },
                {
                    "sent": "Other examples of the same class which drop out they would have an Alpha of zero, and once we had fixed an Alpha we could just solve this optimization problem.",
                    "label": 0
                },
                {
                    "sent": "This could be logistic regression or SVM optimization problem depending on the form of the loss function.",
                    "label": 0
                },
                {
                    "sent": "And how we solve this is very simple.",
                    "label": 0
                },
                {
                    "sent": "We just we iterate between solving these two terms.",
                    "label": 0
                },
                {
                    "sent": "Given the other term.",
                    "label": 0
                },
                {
                    "sent": "So we start with some initial distance function, so we now have initial way to measure these exemplars, and given that we can then sort all the other exemplars with the same label.",
                    "label": 0
                },
                {
                    "sent": "Given this initial distance function.",
                    "label": 0
                },
                {
                    "sent": "And then find this best configuration of the Alphas.",
                    "label": 0
                },
                {
                    "sent": "And once we have the alphas then that defines which of the terms drop out of this optimization problem and then we can just solve the convex optimization problem and in this case L is a hinge loss function squared which allows us to use a second order technique in the primal software very efficiently.",
                    "label": 0
                },
                {
                    "sent": "But we could use the regular hinge loss or any or mean.",
                    "label": 0
                },
                {
                    "sent": "A logistic regression type loss function.",
                    "label": 0
                },
                {
                    "sent": "Anything else could work too.",
                    "label": 0
                },
                {
                    "sent": "And in order to initialize this whole procedure, we use a text on histogram distance, meaning that we basically put zeros on all the weights except just to text on histogram and we found that.",
                    "label": 0
                },
                {
                    "sent": "Empirically, this tends to work very well for lots of different objects.",
                    "label": 0
                },
                {
                    "sent": "Actually works better than weighing all the different distances uniformly, setting, giving them all ones.",
                    "label": 0
                },
                {
                    "sent": "Now another way to kind of visual.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "What's actually happening here?",
                    "label": 0
                },
                {
                    "sent": "But if you have a lot of data and you tried to learn the web.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For example, are and.",
                    "label": 0
                },
                {
                    "sent": "Then you quite a lot of a duplicate entry for that one.",
                    "label": 0
                },
                {
                    "sent": "What is that?",
                    "label": 0
                },
                {
                    "sent": "So you find a lot of plays at the segments are exactly the same like the one that you tried to learn.",
                    "label": 0
                },
                {
                    "sent": "If OK and then it doesn't say it doesn't learn anything, right?",
                    "label": 0
                },
                {
                    "sent": "Because any anything could distinguish between any feature to do good enough to distinguish between the positive send you have and the negative side.",
                    "label": 0
                },
                {
                    "sent": "If the actual data is actually redundant and it's exactly the same segment, meaning it will have a distance of 0 to itself.",
                    "label": 0
                },
                {
                    "sent": "Along all these different attributes then this will breakdown if that actually does happen.",
                    "label": 0
                },
                {
                    "sent": "So in this case, because K is equal to 10, as long as that happens only once or twice, that's OK.",
                    "label": 0
                },
                {
                    "sent": "But if it does actually happen where you just repeat almost training it 10 times, then this is actually going to break it down.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "So another way to kind of visualize what's actually happening is seeing how this is similar to nonparametric density estimation.",
                    "label": 0
                },
                {
                    "sent": "You can imagine these are now three different types of classes, kind of embedded.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In this high dimension, there's a color axis Anna shape axis.",
                    "label": 0
                },
                {
                    "sent": "And in nonparametric parametric density estimation, people usually.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Up some sort of kernel and they just plop this around each of the data points and then they have a nonparametric density estimator for each of the different classes.",
                    "label": 0
                },
                {
                    "sent": "And learning distance function.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And can be thought of as these learning the shape of this kind of similarity, kernel centered around each data point.",
                    "label": 0
                },
                {
                    "sent": "One of the ways you can think about this now, since it's very actually very difficult to display in the real high dimensional space.",
                    "label": 0
                },
                {
                    "sent": "Any kind of figure like this from real data.",
                    "label": 0
                },
                {
                    "sent": "Alternatively, because.",
                    "label": 0
                },
                {
                    "sent": "We learned a bias for the different weight vector, which means that we actually have now.",
                    "label": 0
                },
                {
                    "sent": "The region isn't just arbitrarily drawn, there isn't actually significance to this to the extent of each of these kernels.",
                    "label": 0
                },
                {
                    "sent": "Rather than displaying this as a bunch of our regions.",
                    "label": 0
                },
                {
                    "sent": "You could just imagine connecting all the different exemplars that are active.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Be similar to each other, So what happens is if.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "If this object falls within kind of similarity region of this object and vice versa, we could imagine just drawing an edge in between them and kind of single the output.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Learning is not only these distance function, but also kind of a similarity type graph.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So to see what actually happens now in real example, because in this case I can't draw regions and some 2000 dimensional space.",
                    "label": 0
                },
                {
                    "sent": "I can only display one of these graphs here.",
                    "label": 0
                },
                {
                    "sent": "Now cars are very popular object that occurs in these outdoor images, so there's actually a couple of 1000 of car, couple thousand car instances and this is kind of a zoomed version for what happens after we learn these car distance functions.",
                    "label": 0
                },
                {
                    "sent": "And even tho K was equal to 10, meaning we are forcing a car to be similar to 10 other cars.",
                    "label": 0
                },
                {
                    "sent": "There was this kind of do not care.",
                    "label": 0
                },
                {
                    "sent": "There were still lots of other cars that had Alpha is equal to 0, meaning they fell out of the optimization problem so they could appear on the similar or dissimilar side, and we actually often see cars that have actually lots of different connections a lot more than 10.",
                    "label": 0
                },
                {
                    "sent": "In this case there are a lot of cars and this kind of very simple.",
                    "label": 0
                },
                {
                    "sent": "Back view of a car appears so often it's no surprise that connections are much denser.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So in the next couple of slides, I'm going to kind of quickly visualize what actually happens during this distance function learning.",
                    "label": 0
                },
                {
                    "sent": "More on some other examples so.",
                    "label": 0
                },
                {
                    "sent": "On the top there will be this kind of initial car that we're considering.",
                    "label": 0
                },
                {
                    "sent": "This is what happens if we use the initial distance and we sort all the other exemplars to the focal example using a kind of initial heuristically defined distance, which is this text on histogram distance and after learning these are then the four most similar object exemplars.",
                    "label": 0
                },
                {
                    "sent": "So in this case, we see that when you look at the distance function as kind of this bar plot overweights, we see there's a lot of emphasis on the centered mask as well as the color, so it's no surprise.",
                    "label": 0
                },
                {
                    "sent": "Now the most similar objects actually.",
                    "label": 0
                },
                {
                    "sent": "I have similar shape and color.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here's another example where before learning just looking at a kind of this histogram bag of words, type representation.",
                    "label": 0
                },
                {
                    "sent": "Lots of other exemplars, just, you know, mean couple of them are reasonable, but for example, the most similar one is just some kind of clutter associated with cars.",
                    "label": 0
                },
                {
                    "sent": "And after learning, we see that actually all the similar objects.",
                    "label": 0
                },
                {
                    "sent": "The labels in the interim propagating the labels right?",
                    "label": 0
                },
                {
                    "sent": "Add to the example from the ones you found similar.",
                    "label": 0
                },
                {
                    "sent": "So in this case they both perform the same right.",
                    "label": 0
                },
                {
                    "sent": "They both get the same labels.",
                    "label": 0
                },
                {
                    "sent": "Yeah images you can see it is different, but the labels and they're going to be the same.",
                    "label": 0
                },
                {
                    "sent": "Do you have any examples where you know the label will be different?",
                    "label": 0
                },
                {
                    "sent": "Because your your training method will be better.",
                    "label": 0
                },
                {
                    "sent": "Sure, sure sure.",
                    "label": 0
                },
                {
                    "sent": "So I think here maybe is 1 example of exactly what you're referring.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Yeah, So what happens if you use this kind of texture histogram type techniques measure and you don't use any shape or anything else?",
                    "label": 0
                },
                {
                    "sent": "You might have this piece of sidewalk, or better yet a car with a fence in front of it, who's texture happens to match with the building.",
                    "label": 0
                },
                {
                    "sent": "But then after you do the training procedure, you find that now the most similar object.",
                    "label": 0
                },
                {
                    "sent": "Actually, not only do they have the correct label, but they actually visually look more reasonable.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So so far I've talked about what happens during training and those other images were actually the result of what happens during training, and I didn't talk about actually what happens at Test time at recognition time.",
                    "label": 0
                },
                {
                    "sent": "So what happens at recognition time is that now this is the configuration of learning.",
                    "label": 1
                },
                {
                    "sent": "We have all these distance functions.",
                    "label": 0
                },
                {
                    "sent": "And we'll have some new input, some new region.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we want to say OK, is this region anything we've seen before?",
                    "label": 0
                },
                {
                    "sent": "So this region lands somewhere in this.",
                    "label": 0
                },
                {
                    "sent": "High dimensional descriptor space and then we compute all the distances between this input and all the other.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Exemplars using their distance functions.",
                    "label": 0
                },
                {
                    "sent": "And then we only retain.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The exemplars that say they're actually similar to it, so we can see that from all of these different ones here to this particular exemplar, whose region is kind of this large region.",
                    "label": 0
                },
                {
                    "sent": "This particular input.",
                    "label": 0
                },
                {
                    "sent": "Only falls inside the similar region of this, so we would say that this new input associated with this particular exemplar.",
                    "label": 0
                },
                {
                    "sent": "And when we have, that is.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Confidence measure that basically says the more objects we associate with, the more confident should be in the recognition and if those returned objects associating objects all returns smaller distances, we should also be more confident in their recognition.",
                    "label": 0
                },
                {
                    "sent": "So this is kind of 1 simple way to just kind of combine these different numbers.",
                    "label": 0
                },
                {
                    "sent": "There are lots of different ways of doing this, but the two intuitively things that make sense is that if some new input we say wow, this has been very similar to many things we've seen, we should be more confident in it.",
                    "label": 0
                },
                {
                    "sent": "And if all those previously seen examples return smaller distances, we should also be more confident.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So what actually happens is at the real scenario of looking at a new image.",
                    "label": 0
                },
                {
                    "sent": "So far I only talked about given an input, how can you apply these distance functions to recognition?",
                    "label": 0
                },
                {
                    "sent": "But the reality is in an image we don't know what region corresponds to what object.",
                    "label": 0
                },
                {
                    "sent": "We have this chicken and egg problem saying well, if we already had recognition, maybe we could do segmentation or if we had segmentation then I really show you how you can do recognition and the problems that we have neither and we need somehow to initialize this procedure.",
                    "label": 0
                },
                {
                    "sent": "So what we do is we generate multiple image segmentations for an image.",
                    "label": 0
                },
                {
                    "sent": "The idea is that it's going to be very, very difficult to somehow have a magical algorithm that can segment an image once and magically give us regions that correspond to objects.",
                    "label": 0
                },
                {
                    "sent": "But if we run many of these algorithms many different times, there's a.",
                    "label": 0
                },
                {
                    "sent": "There's a Good Hope that each of the objects of interest will pop out as at least one segment in this whole collection of segments.",
                    "label": 0
                },
                {
                    "sent": "So we use mean shift and normalized cuts and use.",
                    "label": 0
                },
                {
                    "sent": "Those segments produced by those algorithms as well as pairs and triplets of adjacent segments.",
                    "label": 0
                },
                {
                    "sent": "And since we run mean shift and normalized cuts many different times at the end of the day, we have about 10,000 different segments per image.",
                    "label": 0
                },
                {
                    "sent": "For now, that will be 10,000 different inputs to all the different distance functions.",
                    "label": 0
                },
                {
                    "sent": "Now, in order to actually make this procedure work, meaning that we don't want very bad segments that we've never seen before to kind of start associating with random cars and random clutter.",
                    "label": 0
                },
                {
                    "sent": "We also generate lots of bad segments and during the learning procedure we can always put onto this similar side.",
                    "label": 0
                },
                {
                    "sent": "Lots of these kind of garbage.",
                    "label": 0
                },
                {
                    "sent": "Bad segments that are actually often generated by a segmentation engine.",
                    "label": 0
                },
                {
                    "sent": "So once we have images and we know where objects land, we can just kind of.",
                    "label": 0
                },
                {
                    "sent": "Gotta go crazy and start generating very bad segments and always throw those into the learning procedure as kind of negative negative examples.",
                    "label": 0
                },
                {
                    "sent": "In this case, that actually helps.",
                    "label": 0
                },
                {
                    "sent": "So now once we have this collection of segments, we just apply these distance functions to all these segments.",
                    "label": 0
                },
                {
                    "sent": "So if we have 13,000 exemplars and 10,000 segments per image, we have to compute all of those distances, and then we can reason about which segments.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We're good.",
                    "label": 0
                },
                {
                    "sent": "Which ones weren't.",
                    "label": 0
                },
                {
                    "sent": "So looking at a test set which is now, this is some other held out set of labeled me.",
                    "label": 1
                },
                {
                    "sent": "We can then create all these different associations and Harry test settings, and there's a test set of about 150 images or so and these are that the best recognitions now out of the 150 different images.",
                    "label": 0
                },
                {
                    "sent": "So the top only the best and these actually are just the best ones.",
                    "label": 0
                },
                {
                    "sent": "I mean the list is actually very long.",
                    "label": 0
                },
                {
                    "sent": "But what we see here is that on the left these are actually bottom up segments, so these are the output of some segmentation algorithm, and they're not perfect.",
                    "label": 0
                },
                {
                    "sent": "Sometimes you will miss a wheel, and these are the different examples we've seen before.",
                    "label": 0
                },
                {
                    "sent": "These are kind of training data that was associated that associates with each of these.",
                    "label": 0
                },
                {
                    "sent": "Inputs.",
                    "label": 0
                },
                {
                    "sent": "And we can see that this appears to work fairly well each time we see some object in some configuration that's seen before, we have many examples.",
                    "label": 0
                },
                {
                    "sent": "That basically means we're often very confident in recognizing it.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And one thing we can do now that we have an image and we generate lots of these object associations is we can try to see how we can use all those associations.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is 2.",
                    "label": 0
                },
                {
                    "sent": "To parse an image so this is the image I showed earlier in the talk and once we generate different associations between different regions and different exemplars, we can just sort that entire list.",
                    "label": 0
                },
                {
                    "sent": "And then we can vary in a greedy fashion, take the best Association, keep that one, and then we throw away all the other segments that were too similar to this building segment and then go to the next best segment, which happens to be then this car.",
                    "label": 0
                },
                {
                    "sent": "Then throw away all the other segments.",
                    "label": 0
                },
                {
                    "sent": "That kind of overlap too much already.",
                    "label": 0
                },
                {
                    "sent": "This large region and this one and kind of go to the next best one, and.",
                    "label": 0
                },
                {
                    "sent": "What happens is this very simple approach and some images happens to work very well in this kind of is a kind of vision for the thing to do next, as in coming up the more principled way kind of combine all these associations and then for an image tried to then reason about all the different objects at the same time.",
                    "label": 0
                },
                {
                    "sent": "So a greedy type algorithm might work well for a couple of images, but realistically just applying this ingredient doesn't work for all the images.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is for example another.",
                    "label": 0
                },
                {
                    "sent": "Image another one showing for doing the same kind of greedy stacking of the best associations and what we see again as previously seen is that the bottom up segments aren't perfect, meaning sometimes they just spill into the background.",
                    "label": 0
                },
                {
                    "sent": "Sometimes they miss certain parts of the object, but what happens is kind of enough of the object is visible.",
                    "label": 0
                },
                {
                    "sent": "Then these associations are still reasonable.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So to just kind of quickly conclude an talk about some of the different things I discussed are so exemplar based model and segments and segment centric features work well for both freeform things like grass as well as fixed extent things like cars.",
                    "label": 1
                },
                {
                    "sent": "So generally people have different approaches that work for things like cars and people and segmentation approach.",
                    "label": 0
                },
                {
                    "sent": "Approaches, then they apply.",
                    "label": 0
                },
                {
                    "sent": "Think skies and buildings and here we have kind of the same type representation that works well for both types of object.",
                    "label": 0
                },
                {
                    "sent": "Once we have observed many instances of an object, then these distance functions are pretty good at actually localising these objects.",
                    "label": 1
                },
                {
                    "sent": "Now the success of this entire approach relies on having ground truth segmentations during learning, which is kind of like the biggest bottleneck in the sense that can't just use Flickr images, which we might have labels for those images, but we don't have ground truth segmentations, and this kind of approach relies on having those segmentations.",
                    "label": 0
                },
                {
                    "sent": "And for future work, need a clever way to integrate these objects, hypothesised apart to parse images?",
                    "label": 1
                },
                {
                    "sent": "Alright, well that's it.",
                    "label": 0
                },
                {
                    "sent": "Any questions?",
                    "label": 0
                },
                {
                    "sent": "Have you thought about including semantic features into the work you're doing?",
                    "label": 0
                },
                {
                    "sent": "Like, for example, you mentioned initially that the labels, sometimes they have cars.",
                    "label": 0
                },
                {
                    "sent": "Sometimes if you call, you know that even though they're in the same, you don't know.",
                    "label": 0
                },
                {
                    "sent": "They're saying would be beneficial to have something like word net worth.",
                    "label": 0
                },
                {
                    "sent": "The labels are similar, So what actually happens is.",
                    "label": 0
                },
                {
                    "sent": "I'm sure to repeat the question is, is it useful in using some tool like word, net, something that can already help with some of the problems such that certain segments are labeled vehicle certain reliable car using something?",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Word net you can figure out that both are instances of kind of some sort of high level class.",
                    "label": 0
                },
                {
                    "sent": "That is a very reasonable thing to do, and in this particular case, that's something that would probably help a good amount.",
                    "label": 0
                },
                {
                    "sent": "What I didn't show in just 30 minutes is that.",
                    "label": 0
                },
                {
                    "sent": "There are actually cases of where the types of confusions that are learned by this method actually correspond to what word net would tell you, meaning that often it ends up that if some object is labeled vehicle, but there are a lot more that looked like it labeled car, it will happen when we're learning a distance function for that vehicle.",
                    "label": 0
                },
                {
                    "sent": "Still, lots of cars will land on that similar side.",
                    "label": 0
                },
                {
                    "sent": "So there's a little bit of robustness to some of these problems, but I agree that kind of word net is maybe better long term solution to also in terms of semantic features like you showed an example you had the road and the sidewalk and label both his roads think you're less example.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so the 3rd Rd sidewalk there right?",
                    "label": 0
                },
                {
                    "sent": "Yeah, I mean what?",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Happens is, you know this is all stuff that came from label me.",
                    "label": 0
                },
                {
                    "sent": "So people actually label these things as Rd.",
                    "label": 0
                },
                {
                    "sent": "But not, but not that right?",
                    "label": 0
                },
                {
                    "sent": "I mean that that that image you have there you just because it sounds similar to it looks similar to the segment to the label thing Rd.",
                    "label": 0
                },
                {
                    "sent": "You're going to label it road, right?",
                    "label": 0
                },
                {
                    "sent": "Yeah, so some sort of semantic relation that says, you know that the sidewalk is next to a road, or you know, like how things how objects relate to each other.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so at this point, each segment that was generated, I kind of cheated independently.",
                    "label": 0
                },
                {
                    "sent": "And then once I sorted this list an I applied a very simple kind of greedy ordering.",
                    "label": 0
                },
                {
                    "sent": "Then this works really well.",
                    "label": 0
                },
                {
                    "sent": "But this whole kind of idea of reasoning about these relationships that's really, I think, where.",
                    "label": 0
                },
                {
                    "sent": "It's really needed to kind of make all this really, really work kind of as a long term, you know.",
                    "label": 0
                },
                {
                    "sent": "Picture of Time square right?",
                    "label": 0
                },
                {
                    "sent": "What is the sort of the desired label in that situation?",
                    "label": 0
                },
                {
                    "sent": "And you could have you know, buildings, people, roads, whatever.",
                    "label": 0
                },
                {
                    "sent": "But would it be more meaningful if you set time square?",
                    "label": 0
                },
                {
                    "sent": "I mean like if you have if you tell someone else I'm going to show a picture of Times Square versus where show picture of buildings and so on so forth.",
                    "label": 0
                },
                {
                    "sent": "Isn't there more information finding a specific label to a location rather than?",
                    "label": 0
                },
                {
                    "sent": "Yeah, it really ends up that you know.",
                    "label": 0
                },
                {
                    "sent": "Kind of computer vision.",
                    "label": 0
                },
                {
                    "sent": "People usually think of all you know break up the image into object is the ultimate goal.",
                    "label": 0
                },
                {
                    "sent": "But I agree with you that often just saying this is Times Square and being done with the image is probably better than spending all this work on.",
                    "label": 0
                },
                {
                    "sent": "Trying to decipher anything else, and I think without any particular real application in mind, it's hard to say what should the goal be.",
                    "label": 0
                },
                {
                    "sent": "So if you have a robot that's navigating the world and then it's reasoning about objects, or maybe this would be better, but if you're trying to sort images for human using their collection, maybe just saying time squares.",
                    "label": 0
                },
                {
                    "sent": "Can be an order of magnitude more informative than seeing where the road is in that image.",
                    "label": 0
                },
                {
                    "sent": "So Can you imagine a way to generalize this so that it wouldn't require detailed segmentation and training?",
                    "label": 0
                },
                {
                    "sent": "I mean, I can imagine putting an X on a point on the car have it sort of jointly learn both the segment the car and find the features about what it has segmented.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so I have done some work over the summer.",
                    "label": 0
                },
                {
                    "sent": "That this is kind of more recent work on saying if you just have an image that you know contains an instance of an object, could you Start learning off that?",
                    "label": 0
                },
                {
                    "sent": "And, well, I'm not going to talk too much about it, just the basic idea was that.",
                    "label": 0
                },
                {
                    "sent": "You can imagine that you're not only trying to learn a distance function for this object, but you're also trying to learn its segmentation.",
                    "label": 0
                },
                {
                    "sent": "So you could imagine trying to segment these images using your best algorithm, your first pass, trying your best shot, and if 10% of the objects you segmented out nicely, that might be enough to kind of bootstrap the learning so that you can improve these other segments.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "So there's a car somewhere in this image, versus this is a point on the car you take it from there, but what's nice is if you get images from the Internet where maybe a lot of the objects of white background simple backgrounds, you might be able to segment, you know 5000 cars, and then when you look at 5000 other cars embedded inside of images.",
                    "label": 0
                },
                {
                    "sent": "Once you've already learned in this kind of segmentation recognition model, you might be able to use these kind of Internet images to help bootstrap yourself.",
                    "label": 0
                },
                {
                    "sent": "Searching on eBay or something for car taking the image and trying to segment just searching for the object specifically.",
                    "label": 0
                },
                {
                    "sent": "Trying to find more data before.",
                    "label": 0
                },
                {
                    "sent": "Yeah, but it seems like using API and just query.",
                    "label": 0
                },
                {
                    "sent": "Yeah, I mean we actually we use a Google image search we found I mean lots of images.",
                    "label": 0
                },
                {
                    "sent": "Just have an object of interest with this very fake blue background or white or whatever that even though it's not really segmented, it kind of is segmented, meaning you can use a lot of these heuristic techniques just going to subtract the white background and then you basically have training data for any kind of approach.",
                    "label": 0
                },
                {
                    "sent": "Facebook people can sort of segment images according to I think most of the time these people, but I don't use it for other objects.",
                    "label": 0
                },
                {
                    "sent": "Is there any value in that data?",
                    "label": 0
                },
                {
                    "sent": "I mean, I don't even if it's assessable, but if it's something, yeah, I know that.",
                    "label": 0
                },
                {
                    "sent": "I mean, we actually when you look at kind of the images that people captures, people are in there.",
                    "label": 0
                },
                {
                    "sent": "So Facebook is no surprise that people in faces, that's really the number one thing I haven't heard of anybody using that for non people non faces I imagine with the kind of social networking tool it really is faces and recognizing people that.",
                    "label": 0
                },
                {
                    "sent": "The most important thing maybe Time Square would also be valuable like a scene scene level label.",
                    "label": 0
                },
                {
                    "sent": "But anything like this people would just say I'm not going to click on cars, you know.",
                    "label": 0
                },
                {
                    "sent": "Alright thanks.",
                    "label": 0
                }
            ]
        }
    }
}