{
    "id": "j4sboxprncraezlqhinrgzsynmahioix",
    "title": "Data Mining for Anomaly Detection",
    "info": {
        "author": [
            "Jaideep Srivastava, University of Minnesota",
            "Varun Chandola, University of Minnesota",
            "Vipin Kumar, Department of Computer Science and Engineering, University of Minnesota",
            "Aleksandar Lazarevic, United Technologies Research Center",
            "Arindam Banerjee, Department of Computer Science and Engineering, University of Minnesota"
        ],
        "published": "Oct. 10, 2008",
        "recorded": "September 2008",
        "category": [
            "Top->Computer Science->Data Mining"
        ]
    },
    "url": "http://videolectures.net/ecmlpkdd08_lazarevic_dmfa/",
    "segmentation": [
        [
            "My name is Alexander Lazarevich and I am from United Technologies Research Center.",
            "This is tutorial on using different data mining techniques for anomaly detection and this is a joint work with people from University of Minnesota rivals.",
            "There earlier so.",
            "Start how many of you are working in the field of anomaly detection right now.",
            "OK few people and by some other interested to get involved in this area because probably it's one of the hot fields."
        ],
        [
            "So this would be like a outline editorial first will give some brief introduction.",
            "We will cover different aspects of anomaly detection and different applications.",
            "We will present some taxonomy how anomaly detection techniques can be.",
            "Classified and present some of these techniques and finally will present some case study.",
            "I made some changes from the.",
            "Slides that you have probably on your proceedings so you can download the new version of flights on my website.",
            "You can copy from here.",
            "There are not many changes, but still there are some I need to do.",
            "Some new slides which you don't have.",
            "Or you can just send me email and you know I'll send you the link or send you the presentation, whatever, it's easier for you.",
            "OK, so I assume I can continue.",
            "OK."
        ],
        [
            "So as you know, we all are doing work in data mining and we're trying via.",
            "Drowning in the data, but at the same time we are starving for the knowledge.",
            "This is the famous sentence basically from 82 whole field of data mining.",
            "It begins and however, in spite of this large amounts of data, particular instances are still quite rare and this instances may may have a dramatic influence.",
            "An often in a negative."
        ],
        [
            "Data sense, So what?",
            "What are actually anomalies?",
            "Do you have any?",
            "OK, let's network.",
            "So what is actually anomaly anomaly is better in data that does not belong to like regular behavior does not belong to expected behavior from your data.",
            "And normally it's also referred as outliers.",
            "Some people called.",
            "It's a peculiarity some people call a surprises.",
            "It's alright and so on.",
            "Typical instances where anomaly detection can be useful.",
            "Cyber intrusions.",
            "For example, when you try to catch the hackers in your computer network or on your computer, credit card fraud detection when out of millions of credit card transactions that people do all over the world.",
            "Some people steal credit card and use in fraudulent purposes.",
            "Also, different faults in mechanical systems.",
            "For example, if you collect the data.",
            "On your plane, on your car, and you suddenly have to figure out where certain faults can be coming, or if you want to detect certain faults in advance before they happen.",
            "So all of these applications basically where."
        ],
        [
            "Oh anomaly detection can be important as I said.",
            "These are real world anomalies.",
            "I'd mention the credit card for detection and cyber intrusions."
        ],
        [
            "So these are simple examples.",
            "What anomalies can be so.",
            "So let's assume that we have this.",
            "This big groups of data N1 and N2 that correspond to normal behavior points that do not conform to this normal behavior.",
            "For example, let's say oh one or two maybe typical outliers or anomalies.",
            "Also, the small groups of data that are far from anything else may also be considered as anomalies.",
            "This is really up to application.",
            "Sometimes this may correspond to normal behavior, or sometimes this may correspond to to some anomalies group for example.",
            "If you're dealing with the network intrusion detection in the network intrusion detection, there are computer techs called denial of service attacks and analysis of service attacks.",
            "There is no single network connection involved in that attack.",
            "There is usually hundreds of natural connections that are involved in that tag, but they look quite normal and when you want to make the difference between them, you want to see how many network connections appear in the last few few seconds coming from specific source IP.",
            "That's probably the best way to detect these kind of attacks.",
            "So basically you have to construct additional features and then to make this data points move somewhere else, but they will form the cluster which is far from everything else, so it's not necessarily the normally, so only the single instances."
        ],
        [
            "So already a dimension that people from different communities called the problem of anomaly detection with different names.",
            "Some of them are using the rare class mining summarize using chance discovery.",
            "People use novelty detection, exception mining, noise removal and recently there is a book but nothing solid.",
            "The Black Swan is basically very interested book and he's explaining why there is a huge impact of this highly improbable events like the 9/11 or predicting the stock market which we may cause these days or not.",
            "And so on."
        ],
        [
            "So what are the key challenges when you're doing a anomaly detection?",
            "So first the bigger challenge is to define a representative at the normal region usually.",
            "It's hard to get a clear understanding what is normal, especially when you don't have the labels so big that it's another challenge that labeled data for training is not usually available.",
            "For example, in many real life applications you don't have any labels.",
            "You don't know what is normal, you know knows what is anomaly.",
            "If you're lucky, you may know what is normal.",
            "Sometimes you know several types of faults, and that may help you in your analysis.",
            "Also, the boundary between the normal and outlying or anomalous behavior is not clear sometimes, so you have to figure it out and also the exact notion of anomaly or outlier is different for different applications.",
            "For example, if you have the same kind of data set.",
            "OK, we have more people.",
            "Hello.",
            "If you have, uh, same datasets that correspond to, for example, network intrusion detection, or correspond to fault diagnostics.",
            "If you take certain.",
            "Anomalies in that data set one normally from one application may be perfect.",
            "Normal behavior while anomaly in another data set may correspond to something anomalous.",
            "Also, data may contain a huge amount of noise and if you want to detect anomalies in the noisy data, this is quite different and difficult cause.",
            "Sometimes regular.",
            "The values may happen in the in the noisy environment.",
            "This is especially true for time series data and temporal data.",
            "When you're trying to detect anomalous subsequences.",
            "So, for example, if a normal normal subsequence is.",
            "For any reason, the different than anything else.",
            "If you have the noisy data, single individual instances may not be maybe in the perfect age.",
            "Also few examples.",
            "It will be clear to you what I mean, so also in temporal data normal behavior keeps evolving.",
            "So for example, if you create the model.",
            "When you want to detect anomalies, this normal behavior is changing overtime, so your model should be updated as well.",
            "So the question is how frequently you need to update this model, and you know how your data is model because the computational efficiency is very important because if you have the data streams data is coming at a normal speed, so we have to figure out how fast you need to do this and of course.",
            "If you have thousands of features in your application.",
            "Are all these thousand features important?",
            "Which features are important for anomaly detection?",
            "This is not the classical feature selection.",
            "The problem like in every data money problem when you have the class label.",
            "Here we usually do not have the class label and trying to identify.",
            "Relevant features is not that is not easy, so different people are doing different."
        ],
        [
            "End of future projections and so on.",
            "In order to detect the anomalies in different dimensions.",
            "So there are several aspects of anomaly detection that we will try to cover here.",
            "First, what kind of the data we have, the nature of input data, what kind of labels do you have?",
            "Type of anomalies.",
            "But I'll explain what this means, output what kind of output general election algorithm is providing to you and also how you do evaluation of anomaly detection techniques."
        ],
        [
            "So, so let's assume that you have some data.",
            "Most of the data is is coming into the form of either univariate or multivariate data is we have the univariate data usually have just one one variable, which is not very often the case, and if you have multivariate."
        ],
        [
            "You have maybe 10s, hundreds or sometimes thousands of variables and you have to find anomalies in this multi dimensional space.",
            "So the question is, if you have a normal is that appear in only one feature, that's easy to find.",
            "But for example, if a normally it's not obvious in any of the individual features how to find these anomalies and was the right size of the attribute.",
            "You need to take a look at."
        ],
        [
            "So also you may deal with different kind of the type of attributes, but you also familiar with all of these from the data money perspective you may have the binary attributes.",
            "You may have categorical attributes, continuous and hybrid for example if you're dealing with.",
            "Network intrusion detection.",
            "You may end up with using Source IP and Destination IP addresses, and sometimes it's not clear how to convert this IP and IP addresses into the future that you can use in your calculation."
        ],
        [
            "OK, so you also have different data types you may dealing with sequential data.",
            "For example stock market data collecting from some engines, your car plane.",
            "Also you may have the economics data like this is James data.",
            "You may have the data from the traffic, you know how certain cars are moving, so you want to detect certain accidents.",
            "Also, if you have earth science data you want.",
            "You have basically spatial interpolator because you have two dimensions.",
            "Also this is some data from the ports all across the US, and sometimes it's important to understand the location as well as other attributes.",
            "So you see that sometimes you have the mixture of all these attributes plus spatial and temporal."
        ],
        [
            "And you have to deal with all these issues in order to attack otherwise, according to the data labels that are available to you, you may have situations when we're talking about supervised anomaly detection in this case.",
            "The labels for both normal and anomalous are available to you, so in this case you're just applying some classification techniques in order to detect both normal and anomalous, however.",
            "Since this is usually imbalanced, kind of datasets usually have to tweak your classification algorithms to work on this kind of the other problems to different people were doing different things and I'll have a small section on these techniques.",
            "Also, if you have labels available only from the normal data we're talking about, semi supervised anomaly detection techniques.",
            "In this case we usually build some data mining the model to represent this normal behavior, and then you're trying to detect deviations from the normal behavior.",
            "As potential anomalies.",
            "And finally, when you don't have any labels, which is probably the most typical situation in real life problems you were talking about unsupervised anomaly detection.",
            "And in this case you usually basing your decision, your algorithms on the assumption that the normal is a very rare compared to the normal data, and they are different from the majority of other data here.",
            "So you're basically making assumption that majority of data have correspond to normal behavior and everything that is not belong to that majority behavior can be anomalous.",
            "So obviously in this case you are prone to have the highest false alarm rate because you don't have any labels and you're treating everything.",
            "New or everything unusual is anomalous."
        ],
        [
            "Also, we're talking about three different types of anomalies, point anomalies, contextual and collective.",
            "These are some terms that introduced in the survey that is published by our group at University, Minnesota recently.",
            "You can download this survey.",
            "It's available on version dollar website.",
            "Here's the page student at University Minnesota, so you can get some extra information about anomaly detection comparing to this tutorial."
        ],
        [
            "So what actually point anomalies?",
            "The only words is saying that usually the data record only considering only the instances.",
            "For example in this case this and always can be like single instances or some small group of instances when we're talking about the."
        ],
        [
            "Contextual information I mentioned your earlier that when we considering temporal domain.",
            "Sometimes.",
            "You have some pattern in behavior, so in this case you have seasonal seasonal, the temperature and you can see that value T2.",
            "If you look only the value of the temperature.",
            "Value Tito is perfectly fine because it's it's in the range of all the temperatures here.",
            "So if you just considering the values you cannot detect this pointing to as anomaly.",
            "So from that reason you have to put this point into the context of observing the temperature and then it's obvious that you know you have a drop here, which is not expected at that specific time.",
            "So that's why this is a normal listen.",
            "This anomaly is usually detected.",
            "You have to put the data occurs in the context.",
            "This is also applicable.",
            "For special at domain, for example if you have.",
            "It desert and you are trying to monitor the temperature there.",
            "You don't expect the snow in the desert, so you have to put this in the context for example.",
            "But if you go to Minnesota, it's quite normal to expect the snow, so the spatial location is also very important."
        ],
        [
            "OK.",
            "So another term that we introduced this collective anomalies.",
            "So usually in this case you have to look at collection of related data instances and to consider them as a normal is for example in this case this is ECG data from the beating of your heart.",
            "So there is a regular at the pattern that appears here.",
            "So every.",
            "Some time interval you expecting this kind of behavior here.",
            "However, if after a while you don't have any kind of data, this is anomalous.",
            "However, if you look just in the data itself, you know this is quite normal, so we have again to put in the context of what is expected at this specific time.",
            "So again, this is also applicable to sequential data spatial data and graph data."
        ],
        [
            "Gay.",
            "And finally, different anomaly detection algorithms can provide different outputs.",
            "The simplest possible way is.",
            "To just provide the label if the point is normal anomaly, but this is usually the case if you have classification techniques that are applied to the problem.",
            "If you have both normal and anomaly labels available.",
            "Of course, most of anomaly detection algorithms provide the score and usually the higher the score, the more more probable the data record is anomalous one, and you can always convert this score into into the label by specifying some kind of threshold and saying all the points about the threshold can be anomalous and everything else should be.",
            "The normal behavior."
        ],
        [
            "And finally, how you get how you evaluate these anomaly detection techniques.",
            "Of course, if you use just accuracy, you know that this is not true.",
            "For example, if you have a network intrusion.",
            "The problem, and let's assume you have 99 Percent 99.9% of your data is is normal and 0.1 correspond to certain computer intrusions or computer attacks.",
            "And if you're just using the trivial classifiers saying that everything is the normal, you will achieve 99.9% accuracy.",
            "But obviously that's wrong, so that's why people constructing this confusion matrix.",
            "I'm pretty sure that you're familiar with this, so in this case you basically.",
            "He have the normal class and the normal class.",
            "This is what is actually kind of the label and this is what you predict.",
            "So you're making correct predictions here through negative and through positive.",
            "And of course, you're making false positive if you're saying this is anomaly, but it's actually the normal class.",
            "And of course you making the force the negative if you're saying this is the normal class, but it's actually anomaly or attack.",
            "So obviously the first the negative is the.",
            "Is one that have the high cost?",
            "For example, it's highly.",
            "It's very costly if you miss computer attack or if you miss the fault in your system.",
            "If you Mr Attack certain disease from the medical at the data and this is false positive.",
            "This is basically how much you're annoying your analyst, how much you're saying them.",
            "It's something normal, but it's not.",
            "And people are discussing different kind of measures from this data.",
            "People construct recall, which is like the ratio of true positive over the true positive plus false negative.",
            "This is similar to partial accuracy for their specific class, and of course a precision.",
            "How many times we are.",
            "Put the out of everything that we predicted.",
            "How many times we made a correct prediction.",
            "This is TP over 3 plus FP so.",
            "In order to get the good tradeoff between these two values, people use F measure.",
            "Most typical way is to use this formula here.",
            "However, the more general formula is using the factor at beta, and in this case if you if you have beta equal to 1, you will get this formula.",
            "However, if you want to and this is equal weight between recall and precision where we want to put more weight into recall or precision, you can change this parameter."
        ],
        [
            "Also, you're so familiar that.",
            "People also use terms and metrics like detection rate and false alarm rate, so detection rate is defined in the same way as recall.",
            "Its rate is basically how many times I predicted something incorrectly.",
            "False alarm rate is basically trying to say how many times I think I'm saying that something is anomalous, but it's not.",
            "It's actually the normal behavior and as a tradeoff between these two values, people usually construct our seeker in RC curve you are.",
            "On the X axis using false alarm rate.",
            "And Y axis using detection rate and ideal RC curve should be something like that for the fazira false alarm you have to achieve 100% detection rate but this is usually cards achieving your life as you as you imagine in most real life RC curves look something like this.",
            "So these are the typical curves for RC.",
            "And of course, the people also trying to measure the area under the curve as as a metric to evaluate different either classification techniques or anomaly detection techniques.",
            "In recent years people were also trying to improve the measure of area under the curve by proposing.",
            "To compute how big error the classifiers are making and so basically instead of.",
            "Providing the measure for the test data that you're dealing with is basically giving you impression how good generalizability the model has, so I think there are paper last year and paper this year that proposing different variations of area under the curve."
        ],
        [
            "OK, and I mentioned earlier that there are different applications of anomaly detection.",
            "I like to mention at network intrusion detection, their applications of different fraud detection like credit card fraud, insurance fraud.",
            "In healthcare informatics and the medical diagnostics, we also have this problem.",
            "I'll have one slide for each of them.",
            "In industrials detection you may have different engineering systems that may experience some faults in image processing and video surveillance.",
            "Anomalisa extremely important to detect some events like the life package at the airport and something suspicious.",
            "And finally there is a topic of novel detection in text mining."
        ],
        [
            "So intrusion detection as I said.",
            "You're trying to monitor the computer network in order or computer system.",
            "In order to analyze.",
            "The network for certain interactions and interactions are usually defined as attempts to bypass the security of a computer or the network, and there are typical challenges in network intrusion, texture world, some of them that most of interest rebate.",
            "Actually the current state of the art and currently interested state of the art intelligent action.",
            "We did.",
            "Most of the people using signature based intrusion detection systems.",
            "Most of you have either the virus scan or the Norton that is checking for the virus in your computer.",
            "And you know that you often have to go to the.",
            "Actually, it's it's done automatically, but the software is going to the website trying to download all definitions of viruses and then it uses these definitions to detect all the viruses in our computers.",
            "And these systems work in a similar way.",
            "They have the signatures, full computer tags that are known so far, but obvious disadvantage of this.",
            "The system says every time when you have a new attack there is a delay in detecting this attack.",
            "So you have to go to the.",
            "Website and download this the signature to take this computer intrusion and then you can attack this.",
            "So basically these systems are incapable of detecting new and emerging computer threats and anomaly detection can be extremely important here because they can do this."
        ],
        [
            "OK, I didn't.",
            "Mention briefly about fraud detection.",
            "So you may deal with different kind of fruits.",
            "As I mentioned, credit card frauds when people trying to steal your credit card and using music to buy something on eBay.",
            "That's difficult one.",
            "Insurance claim you may claim that you lossed other people stole something for you, but that's not actually the case or mobile cell phone fraud.",
            "If you lose the cell phone and someone else is trying to use that instead of you.",
            "And in this case, most of the time you have temporal data and you have to deal with fast and accurate real time detection.",
            "So basically you have the data streams they're not occurring at regular uniform intervals, so they occur every time when you have transaction or something bad happen.",
            "Especially in credit card transaction and then we have to react fast because you have to stop this.",
            "Fraudulent transactions and misclassification cost is very high if you don't say something is intrusion, you may actually the, for example, credit card company may lose a lot of money."
        ],
        [
            "In the healthcare informatics you may deal with different problems.",
            "For example if you analyzing certain disease anomalies may represent disease outbreaks.",
            "For example, that's certain.",
            "Disease can happen in certain area.",
            "If you're dealing with, for example, people who have certain type of cancer.",
            "Using anomaly detection, you may detect this cancer in advance or at early stage, so and then you can save the lives and usually in this case only normal data is available.",
            "Very few instances of.",
            "Rare class or anomalies can be available and in this case misclassification cost is very high.",
            "So for example, if you missed the text that there is a cancer, you will lose the personal life, so that's that's really expensive and the data can be quite complex depending on the problem.",
            "For example, in the case of disease outbreak data, maybe both spatial and temporal."
        ],
        [
            "I mentioned earlier that there are extremely important problems in industrial damage detection and decisional involving engineering health applications.",
            "So many companies are starting to apply different data mining techniques to help their physical based model techniques to detect certain failures in advance.",
            "So they figure out that physical based models are not sufficient to explain and describe the complex.",
            "Sharing systems and then the data driven techniques may help them.",
            "So typical example is aircraft.",
            "The safety and there is a recent effort from Vanessa they basically they try to use different data driven techniques to detect anomalies from the flight record data.",
            "So the idea is to analyze the data from the flights during the flight and then if anything unusual that happened you may give the signal either to the pilot or to the center and say there is probably probably fault or something like that.",
            "So this is also very important for aviation safety.",
            "And it can also save many many lives.",
            "However, there are many challenges in this gate data.",
            "Since you're getting the data from different types of sensor data, may be extremely extremely huge can be extremely noisy because you're mixing, you know all different types of sensors, some of some of them more reliable, someone or not, and most of the time the data is not labeled at all, so you don't know what is normal.",
            "You don't know what is anomaly.",
            "Most of the applications because you're collecting this online, have temporal behavior, so you have to consider different sequential temporal anomaly detection techniques.",
            "And detecting anomalous events require usually immediate intervention, and again, the cost here is extremely high, because if you missed this certain anomaly and this really correspond to failure in this case of aviation safety, you may use the hundreds of lives."
        ],
        [
            "I mentioned that people tried to use recently different anomaly detection techniques in image processing and video surveillance, so.",
            "As you know, we have more and more cameras everywhere, so they record us if you go to the airport, record us.",
            "If you go Tom store they record us.",
            "So people used to analyze this videos and images to detect some suspicious events and to detect different things.",
            "For example, if an airport people try to detect this kind of that someone left the package.",
            "That's also very important for the train stations and so on.",
            "So using anomaly detection techniques can be here very, very important.",
            "And again there are some key challenges you have to detect this.",
            "A collective anomalies from the previous case because you have to put into context all different pieces.",
            "What can be normal?",
            "What can be anomaly in specific situation and datasets can be extremely huge and you have to convert the raw.",
            "Image and video data into the data format.",
            "It is appropriate to use by anomaly detection."
        ],
        [
            "OK, so this is a taxonomy of anomaly detection techniques that is also published in a survey by our group.",
            "So we try to.",
            "Categorise different anomaly detection techniques according to different criteria.",
            "So.",
            "Let's start from left.",
            "So we have this point anomaly detection when you're trying to basically find individual data records as anomalies.",
            "And basically most of the problems into dealing with here.",
            "Also you try to convert them into this problem because it's much easier to deal with this.",
            "So you have these classification based techniques when you basically have.",
            "Both normal and abnormal data available.",
            "You have certain nearest neighbor based techniques.",
            "Then you try to detect anomalies based on computing the distances between data records.",
            "A clustering basic things are quite similar to this.",
            "You have different statistical techniques which are based either on parametric or nonparametric well known statistical.",
            "So physical approaches and you have some other techniques which include information theory based spectral composition.",
            "Some people try different visualization techniques and so on.",
            "And of course we already mentioned all of this.",
            "Collect contextual and collective action.",
            "If you have real time system you have to have an online anomaly detection and sometimes.",
            "I mean the date meant the data is dispersed among several physical occasions.",
            "You have to deal with distributed anomaly detection.",
            "Sometimes you cannot merge data and you have to deal, you know how's it like.",
            "This global anomalies?",
            "We don't.",
            "We don't modulate, but we'll talk briefly about this at the end.",
            "Any questions so far?",
            "OK, good."
        ],
        [
            "OK, so I'll start with explaining briefly the classification based techniques.",
            "As I mentioned earlier.",
            "The main idea is to build classification model for both normal and anomalous behavior.",
            "So basically you assuming here that you have little labels from both normal and anomalous behavior available.",
            "So.",
            "Classification models that use here must be able to handle this kind of skewed data distributions.",
            "For example, if you have 99% of data that correspond to normal and only 1%, it corresponds to anomalies using simple decision tree may not give you very good results because usually these techniques are.",
            "Hello.",
            "Designed for Val balance datasets.",
            "So in this case we are dealing with two types of approaches, supervised and semi supervised classification techniques.",
            "In supervised you basically solving both labels available both from normal and.",
            "Anomaly and you have to.",
            "Low.",
            "Construct different type of classifiers to classify between normal and anomalous and finally in the semi supervised you're assuming there is only label from the normal behavior.",
            "Available and then using some kind of one class model to define what is normal and then to detect deviations from this normal behavior.",
            "For for anomaly, so basically you have the data from the normal only you're trying to construct the model that will describe this normal behavior and then you're using this at the model to go to the new data.",
            "Everything that fits this.",
            "The model would correspond to normal here.",
            "Everything else should be anomaly."
        ],
        [
            "Um?",
            "So obvious advantages of these techniques are that.",
            "It models can be easy to understand because you exactly know what is normal, what is anomaly?",
            "Also, since you have both normal and normally, you can achieve pretty high accuracy in detecting these events.",
            "Um?",
            "In summer supervised techniques also the normal behavior, since you know what is normal normally can be actually very well learned and you can use this description of our behavior to detect future anomalies.",
            "Obvious kind of disadvantages include that in both cases you require.",
            "The labels in supervised techniques you require both labels from normal anomaly and summer supervisor required.",
            "The labels from the remotest and in real life application.",
            "This is sometimes not feasible because in order to label this data, let's say you have millions of data records.",
            "You need some time.",
            "The drawback of supervised classification techniques they can usually.",
            "They cannot detect this emerging and new anomalous because they know what is normal and normal and everything outside the range.",
            "They will just be longer than normal anomaly depending on the closeness.",
            "And in summer, supervised since we have the information only about the normal, you may have relatively high false alarm rate because everything new which does not correspond to normal may be categorized."
        ],
        [
            "Normally.",
            "There are some typical techniques for supervised classification, so people.",
            "First try to use different kind of manipulation of data records.",
            "So the simplest thing is to do.",
            "Either oversampling undersampling I'll talk briefly about this.",
            "People also did different kind of rule based techniques.",
            "And people also try different kind of the neural network support vector machines, Bayesian networks approaches.",
            "People also tried cost sensitive classification techniques.",
            "When for example when you're learning your classifier.",
            "In criteria that you use to construct classifier, you introducing the cost.",
            "So basically if you trying to measure the cost of making the force at the negative is much higher than making the false positive error, so that's how you tweak your classifier to do different things and also different researchers were trying to use an sample based learning to combine.",
            "Some of oversampling undersampling techniques with the boosting, for example, we have a smooth boost variables and a meter cost."
        ],
        [
            "So let's first briefly talk about the data manipulation techniques.",
            "So there are three basic approaches here.",
            "You can do either oversampling.",
            "Undersampling or try to generate some artificial anomalies so in the oversampling is the word saying.",
            "You're basically trying to make the duplicates of the rare events or basically of minority class until the data sets contain as many examples as majority class.",
            "So basically trying to make the datasets.",
            "Equally balanced, so obviously you're not introducing any new information here, you're just trying to duplicate to duplicate records, and this usually does not increase information, but it basically creates only misclassification costs, so that's usually does not give you good result.",
            "Another approach is to do downsizing, basically undersampling the majority class.",
            "So in this case, undersampling the normal class.",
            "And.",
            "Examples.",
            "From from minority class are selected using several techniques.",
            "Either you do randomly.",
            "Either you're trying to, when you selecting the data from the normal class you are trying to do the near Miss examples.",
            "For example, when you make the most mistakes you're trying to select this data point.",
            "When you make classification because they are most useful also.",
            "You can when you are trying to select the data from normal, you're trying to exempt to select examples that are far from minority class examples or basically far from decision boundaries so different people will try different techniques when selecting this.",
            "And of course they got different styles depending on the data set that they're trying to apply their results on.",
            "And usually this results in a general loss of information and.",
            "Basically two general.",
            "Rules because if you have less data, euros will be to add general and then we have relatively poor prediction performance.",
            "And finally, there are a few approaches that are trying to generate some artificial anomalies.",
            "So basically official example from minority class from your.",
            "A real class.",
            "There is a smooth technique where basically new examples from minority class are generated inside the regions of existing rare class examples.",
            "But again since this is within the well defined at boundary, this again may not increase the performance as well because you're you're generating the class within the well defined region.",
            "However, if you have normal data records that are within this region, this may try to alleviate some noise effects.",
            "Because you will get more robust classifiers in this case.",
            "Also another approach by fan that artificial normal is generated around the edges of the sparsely populated later.",
            "This is a little bit different in this one, driven by different.",
            "Idea and also there is a recent approach by Nokia.",
            "Ben Biancas draws me from IBM to classify synthetic outlets versus the real normal data using some type of active learning."
        ],
        [
            "For all of these references you have at the end of tutorial so you can find this paper.",
            "Most of this paper can find online.",
            "So another type of classification based technique that I prefer normal function are called role based techniques.",
            "So some people design new techniques to deal with rare class problems.",
            "Some of these are coming from University, Minnesota.",
            "PN role and create this algorithm.",
            "Some people try to adapt existing rule based techniques like C 4.5 and adapting some multi classification.",
            "Is the method to single classification problem.",
            "In this case we have only a normal class and that's where we use to describe the normal behavior.",
            "In the.",
            "Association rules people were trying to do different basically things to describe what can correspond to normal behavior, for example.",
            "Rules are certain rules that have high support, which then actually have higher support in some pre specified threshold.",
            "May characterize the normal behavior.",
            "That's the most obvious way to apply Association rules.",
            "Also some people try to associate anomalous data records that occur in fewer frequent itemsets compared to the normal data record.",
            "And finally, if you're dealing with temporal data, frequent episodes also used to describe the normal behavior this is.",
            "One of the first techniques trying data mining for network intrusion detection by Van Cleef from Columbia University Hills.",
            "Frequent episodes to define the normal temporal behavior and then he used the Reaper.",
            "On top of that to detect normal versus intrusions.",
            "And, uh, some people also used.",
            "K specific feature and rule and waiting, which basically.",
            "Tells you that you have to give different weights, different feature in order to achieve good performance.",
            "For example, in Decision tree learning, in this case specific feature waiting for each rare class test example you have to replace global late vector with dynamically generated rate vector depends on the path taken by that example and also in this another approach case specific role rating is.",
            "Basically a little bit at a different you.",
            "Basically the algorithm increases the roles trend for all the rules that describe the rare class.",
            "So basically we have some rule based algorithms that define the both classes.",
            "You're basically first focusing on defining the rare class and then you will define the normal price.",
            "Is the similar idea is."
        ],
        [
            "Also for the PM role in the panel you have two steps.",
            "You have the P phase and you have the end phase in the P phase you basically trying to construct all the rules that cover basically all the rare class examples.",
            "So basically if this is your kind of data set and this is your.",
            "Or Eric listen normally class and this is the normal class.",
            "Your first trying to construct the rules.",
            "That will cover most of examples in this region in this region.",
            "So so basically when constructing the rules, some of those may cover examples from the normal class as well.",
            "So basically that's why you have this end phase.",
            "When you try basically to eliminate these errors that introduce in this phase.",
            "So basically all of this point in all of this data records that are detected by this rules here will be eliminated in this phase.",
            "So basically that's why you're so.",
            "This enrolls gives high accuracy and significant support, and piano can give really good results when you're dealing with this kind of imbalance datasets."
        ],
        [
            "There is another approach called Crados, also by Market Yoshi from University Minnesota.",
            "He used the ripple down rules which is some form of decision tree in basically in which every node has a protective role associated with this.",
            "So this ripple down rules specialized genetic specialist genetic form.",
            "Of multiphase PN role at model so.",
            "So basically in panel at the model you have two phases here basically for every of these.",
            "Rules you have the path associated this so there again two phases, growth and pruning in growth.",
            "You're basically using this ripple down rules to cover most of the positive examples and basically by doing this you will overfit the training data and as a result you will get a binary tree where each node is.",
            "Characterized by the rule.",
            "A default class and the links that to child subtrees.",
            "This is just the implementation and you have to grow this ripple down structure in recursive admin.",
            "And finally, in the second phase.",
            "Prone phase, you have to prune this structure in order, basically to improve generalization.",
            "It's something similar how you prune the decision tree in order to improve the generalization."
        ],
        [
            "OK.",
            "Different people were using different forms of world at the networks to apply them on intrusion detection or self engineering health applications and so on.",
            "So these are all different types of techniques that people are using when both of the labels were available and I mean I'll not go through most of this because there's just modification of regular neural networks.",
            "You have all these kind of references.",
            "You can go there and and track because there is nothing significantly introduced here.",
            "People just supply neural networks for different rare class problems.",
            "And what is the typical and common for most of them that they assume that both labels from normal and abnormal is available to them?"
        ],
        [
            "People also use different forms of support vector classifiers to detect intrusions.",
            "The main idea here is basically that.",
            "This approach bystanders that normal data records can belong to high density data regions, while the data from the data basically that correspond to normalize correspond to low density data regions and then he used unsupervised approach to learn high density and low density data regions and then he used the standard support vector machines to classify this data density level.",
            "Another approach.",
            "Is by mukkamala.",
            "He assumed that he has both labels available, normal and abnormal.",
            "And he used the support vector machines for the problem of network intrusion detection.",
            "So I mean this is up Europe."
        ],
        [
            "Nation paper and you know, not significant research skills in three hours here.",
            "Um?",
            "Other type of.",
            "Classification techniques for normalization.",
            "Semi supervised.",
            "When we talked about this.",
            "So basically they use modify classification at the model to represent normal behavior only an older version from this normal behavior may correspond to anomalies.",
            "So people use different approaches.",
            "People use neural networks, support vector machines, so Markov model based approaches, which can be extremely good if you have temporal data and you're trying to capture the transitions between the sequences.",
            "And finally you have different kind of rule based approaches."
        ],
        [
            "So, uh, this is.",
            "Form of neural network which is called replicator neural network.",
            "Or some people called Diablo neural network.",
            "So the basic idea here is to use this type of network to learn the normal behavior.",
            "So you put your input data here this input layer.",
            "And you're trying to reconstruct your input data here at the output layer.",
            "So so some form of this neural network is also used for dimensionality reduction.",
            "So basically we're trying to reduce the dimension of this, let's say 100 space 100 dimensional space into something smaller here.",
            "And if you're able to reconstruct your input data from this reduce space.",
            "So basically, if you are able to get.",
            "The same data is the data on the input.",
            "You are good and basically this layer may may be used as the reduced the majority space.",
            "So the idea here is to measure the difference between.",
            "Output and the input.",
            "This is called reconstruction error.",
            "And to use this reconstruction error as the measure for out learners.",
            "So basically the smaller reconstruction error.",
            "That means that data should correspond to normal behavior.",
            "The large reconstruction error, the data make respond to novels.",
            "So basically in the training phase you have only normal, you have only normal data records, you passing all normal data records with this kind of neural network.",
            "Your training this network, and then when you're done, you know network represent this normal here pretty well.",
            "So now when you go to the testing phase, every data record that you pass through this neural network.",
            "Will behave in two different ways.",
            "If this is the normal data record, it will have small reconstruction error.",
            "If this is anomalous data record, it will have huge reconstruction error.",
            "So that's the basic idea."
        ],
        [
            "People also use different forms of one class support vector machines to detect anomalies, so outliers.",
            "So people use different techniques and but the most common approach is basically to separate the entire set of training data from the origin here and to find a small region where the most of the data allocated.",
            "So I mean, these are all the different approaches.",
            "Usually you're dealing with two parameters you care to specify number of authors.",
            "So basically specify how many outlets we expect and also you are specifying the variance of our RBF kernel, radial basis function, the criminal if you're.",
            "If the variance of the radial basis function getting smaller, that means you need the larger number of support vectors to cover the area and separating surface get more complex.",
            "And that's usually why you don't get that such good generalizability vice versa.",
            "If your variance is getting bigger, you don't need that many support vectors, but again, your model can be two general.",
            "So another approach here can be in.",
            "Using support vector applied by shortcut is to separate regions that contain data from the regions that have only very few data records.",
            "And in the end, basic ideas to push the hyperplane away from these regions."
        ],
        [
            "OK, so we came to the second type of anomaly detection techniques, which are called the nearest neighbor based techniques, and in this approach is usually you have.",
            "The distance computation is the key.",
            "How to measure what is the normal and what is that?",
            "Two major approaches.",
            "There are distance based on density based."
        ],
        [
            "Roaches so as I said, the key assumption is that the normal points have.",
            "At the neighbors, very close at neighbors, so normal points are located in a very.",
            "Dense region they have a lot of points around them while anomalies allocated in some areas that are kind of isolated.",
            "So that's the main idea.",
            "Actually behind this approach, and usually it contains 2 steps in the first step you compute the neighborhood for every data record.",
            "And then you're trying to analyze the neighborhood in order to determine whether the data record correspond to normally or not.",
            "And there's a mention earlier.",
            "There are two major approaches, distance based then.",
            "Basically, you're trying to compute the anomalies.",
            "Is the point that are too far from everything else and density based methods.",
            "When basically you are treating anomalous data points that are located in the low density regions.",
            "I'll talk about both of them."
        ],
        [
            "In the later slides, so obviously advantages of these approaches.",
            "Are that they can be used in unsupervised or semi supervised setting so they do not require any information about the labels.",
            "Obvious drawback.",
            "That if normal points do not have sufficient number of the neighbors, this technique may fail.",
            "Also very important drawback that they're computationally expensive 'cause you know trying to compute the neighbors for every day to record.",
            "It's usually often square and for many real life application this is not.",
            "This is not practical, so people are trying to use different kind of techniques like KD trees are trees to improve the search for nearest neighbors and to reduce the complexity 2 N log N. Also, in high dimensional spaces.",
            "Data is quite sparse and concept of similarity is not do meaningful anymore because due to sparseness the date actually the distance between any two data records can be quite similar and then each data record may be considered as potential outlet or potential anomaly.",
            "So that's that's why selecting important features and in selecting relevant features may be quite important here because if you have let's say 200 dimensions.",
            "For trying to compute the distances using these two dimensional space, all the distances may be quite large and you know your notion of anomaly may not be good, so that's why it's important to select only few relevant features that you may use in this kind of approach, and then you can achieve much better results.",
            "Of course this depends on application and you have to work probably closely with."
        ],
        [
            "People who have domain knowledge.",
            "So the 1st.",
            "Type of techniques that belong to the city to distance based techniques and nearest neighbor based techniques.",
            "And in this case, this is a classical definition by the paper by North.",
            "And the point is, in data set is considered as outlier if at least some fraction P. That especially here of the points in datasets lights greater than distance D. Also specify here from certain .0.",
            "So there's a classical definition of outlier.",
            "Using this approach intensity based approach.",
            "Local densities of particular regions.",
            "Are computed and then you define all the instances that lie in this low density regions as potential anomalies.",
            "Typical approaches.",
            "In this.",
            "In this density based techniques, a local outlier, factor connectivity, outlier factor, multi granularity division factor people, some researchers also use kernel estimation to estimate the density around at points.",
            "I'll present all of these three papers so I can see how they do this."
        ],
        [
            "So in the nearest.",
            "Neighbor approach is this the most similar and actually the simplest possible technique to detect anomalies.",
            "So basically for each data point, first step is to compute the distance from the Kate closes point.",
            "So this distance is called decay is called K distance, and then you sort all this data records according to this distance that you computed in the previous step.",
            "Obviously the data records that have very large distance.",
            "That means they are far from everything else.",
            "And they can be on the top of the list.",
            "So basically you take the top one or two percent from that list and you treat them as anomalies.",
            "So usually you have the parameter.",
            "How many top data I could you want to consider is enormous.",
            "And also this you have also the parameter for K was the how many clauses point you want to consider.",
            "However, this technique is not suitable for datasets that have mode switch wearing at the density.",
            "For example, I'll show this example in the next slide."
        ],
        [
            "So let's assume we have two clusters here, one very dense cluster.",
            "Here another one very sparse here, and we have three points P1P2 and P3 for which we want to consider.",
            "Oops.",
            "For which we want to consider actually for which we want to determine if there are outliers or not.",
            "Obviously, point P1 is a normal because it's far from everything else.",
            "That's very simple.",
            "However, if you want to consider points P2 and P3.",
            "And if you want to compute the distance only, the distance from point P2 to the closest point is this line here something like this?",
            "The distance from Point P3 to the closest point is something like that.",
            "So this distance is quite similar.",
            "And if you want to say which of these two points are anomalous, what we would say is P2 or P3.",
            "P2 OK, because its distance from this local region.",
            "Here P through kind of belongs to this sparse region, so you can see that computing only the distance may not be sufficient to detect what is anomaly.",
            "So that's why people are trying to use kind of density based approaches to detect what is the normal.",
            "So basically in this case they would compute the densities in this region.",
            "Computer desk is here and then they'll they'll determine what is outlier so.",
            "The main idea behind this density based approaches is.",
            "You compute the density local density around the point.",
            "So basically this point consider these points around as the closest point.",
            "However, this point considered this point is the closest point, so they do not share the same notion of the neighborhood.",
            "So points do not share the same notion of the neighborhood.",
            "That means something is wrong, so that basically that's how you detect this.",
            "Another point is anomaly, and this is."
        ],
        [
            "LF approach this is one of the first approaches that employ this kind of idea, so it has four steps.",
            "First step is to compute the distance to the Kate Clauses point is the same as the distance based approach.",
            "In the second step.",
            "In the second step, you're basically computing something they called reachability distance, and this is basically defined for two points.",
            "For if you have one point and you define the Kate at the distance you are constructing the hyper sphere with radius of Cade distance for all the points that are inside of this hypersphere.",
            "Reachability distance is equal to the radius.",
            "For all the points at the outside of that hypersphere, reachability distance is actually equal to actual distance between these two points.",
            "This is done just for some to make this algorithm robust, cause sometimes if you have two or three same data records, the algorithm may not be robust and may give you some results.",
            "The third step is to compute local reachability density, and this is defined as the inverse of the.",
            "Reachability at distances from the points around you.",
            "So basically you're considering the points around you.",
            "You computing the distances to them an inverse of that sum should be should be notion of the density.",
            "If you have closed points around you, that means the density is higher.",
            "If you have the points around you that you consider is the neighbored far from you, that means you are living in the sparse kind of neighborhood.",
            "So for example, if you live in New York City, you have a lot of clothes at neighborhood and then you're dense this guy.",
            "If you live in Texas or somewhere else, your neighborhood sparse.",
            "So because you have your neighbors are not that close.",
            "And final step is basically to compute local outlier factor.",
            "Is the ratio for.",
            "A local ability densities for all the points around you and your and your density.",
            "For example, if the points around me that I consider is the closest point, he have different.",
            "Density, then I do, then this will be an anomaly because this will give higher normal score."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "My name is Alexander Lazarevich and I am from United Technologies Research Center.",
                    "label": 0
                },
                {
                    "sent": "This is tutorial on using different data mining techniques for anomaly detection and this is a joint work with people from University of Minnesota rivals.",
                    "label": 1
                },
                {
                    "sent": "There earlier so.",
                    "label": 0
                },
                {
                    "sent": "Start how many of you are working in the field of anomaly detection right now.",
                    "label": 0
                },
                {
                    "sent": "OK few people and by some other interested to get involved in this area because probably it's one of the hot fields.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this would be like a outline editorial first will give some brief introduction.",
                    "label": 0
                },
                {
                    "sent": "We will cover different aspects of anomaly detection and different applications.",
                    "label": 1
                },
                {
                    "sent": "We will present some taxonomy how anomaly detection techniques can be.",
                    "label": 0
                },
                {
                    "sent": "Classified and present some of these techniques and finally will present some case study.",
                    "label": 0
                },
                {
                    "sent": "I made some changes from the.",
                    "label": 0
                },
                {
                    "sent": "Slides that you have probably on your proceedings so you can download the new version of flights on my website.",
                    "label": 0
                },
                {
                    "sent": "You can copy from here.",
                    "label": 0
                },
                {
                    "sent": "There are not many changes, but still there are some I need to do.",
                    "label": 0
                },
                {
                    "sent": "Some new slides which you don't have.",
                    "label": 0
                },
                {
                    "sent": "Or you can just send me email and you know I'll send you the link or send you the presentation, whatever, it's easier for you.",
                    "label": 0
                },
                {
                    "sent": "OK, so I assume I can continue.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So as you know, we all are doing work in data mining and we're trying via.",
                    "label": 0
                },
                {
                    "sent": "Drowning in the data, but at the same time we are starving for the knowledge.",
                    "label": 1
                },
                {
                    "sent": "This is the famous sentence basically from 82 whole field of data mining.",
                    "label": 0
                },
                {
                    "sent": "It begins and however, in spite of this large amounts of data, particular instances are still quite rare and this instances may may have a dramatic influence.",
                    "label": 1
                },
                {
                    "sent": "An often in a negative.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Data sense, So what?",
                    "label": 0
                },
                {
                    "sent": "What are actually anomalies?",
                    "label": 0
                },
                {
                    "sent": "Do you have any?",
                    "label": 0
                },
                {
                    "sent": "OK, let's network.",
                    "label": 0
                },
                {
                    "sent": "So what is actually anomaly anomaly is better in data that does not belong to like regular behavior does not belong to expected behavior from your data.",
                    "label": 1
                },
                {
                    "sent": "And normally it's also referred as outliers.",
                    "label": 0
                },
                {
                    "sent": "Some people called.",
                    "label": 0
                },
                {
                    "sent": "It's a peculiarity some people call a surprises.",
                    "label": 0
                },
                {
                    "sent": "It's alright and so on.",
                    "label": 0
                },
                {
                    "sent": "Typical instances where anomaly detection can be useful.",
                    "label": 0
                },
                {
                    "sent": "Cyber intrusions.",
                    "label": 0
                },
                {
                    "sent": "For example, when you try to catch the hackers in your computer network or on your computer, credit card fraud detection when out of millions of credit card transactions that people do all over the world.",
                    "label": 1
                },
                {
                    "sent": "Some people steal credit card and use in fraudulent purposes.",
                    "label": 1
                },
                {
                    "sent": "Also, different faults in mechanical systems.",
                    "label": 0
                },
                {
                    "sent": "For example, if you collect the data.",
                    "label": 0
                },
                {
                    "sent": "On your plane, on your car, and you suddenly have to figure out where certain faults can be coming, or if you want to detect certain faults in advance before they happen.",
                    "label": 0
                },
                {
                    "sent": "So all of these applications basically where.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Oh anomaly detection can be important as I said.",
                    "label": 0
                },
                {
                    "sent": "These are real world anomalies.",
                    "label": 1
                },
                {
                    "sent": "I'd mention the credit card for detection and cyber intrusions.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So these are simple examples.",
                    "label": 0
                },
                {
                    "sent": "What anomalies can be so.",
                    "label": 0
                },
                {
                    "sent": "So let's assume that we have this.",
                    "label": 0
                },
                {
                    "sent": "This big groups of data N1 and N2 that correspond to normal behavior points that do not conform to this normal behavior.",
                    "label": 1
                },
                {
                    "sent": "For example, let's say oh one or two maybe typical outliers or anomalies.",
                    "label": 0
                },
                {
                    "sent": "Also, the small groups of data that are far from anything else may also be considered as anomalies.",
                    "label": 0
                },
                {
                    "sent": "This is really up to application.",
                    "label": 0
                },
                {
                    "sent": "Sometimes this may correspond to normal behavior, or sometimes this may correspond to to some anomalies group for example.",
                    "label": 0
                },
                {
                    "sent": "If you're dealing with the network intrusion detection in the network intrusion detection, there are computer techs called denial of service attacks and analysis of service attacks.",
                    "label": 0
                },
                {
                    "sent": "There is no single network connection involved in that attack.",
                    "label": 0
                },
                {
                    "sent": "There is usually hundreds of natural connections that are involved in that tag, but they look quite normal and when you want to make the difference between them, you want to see how many network connections appear in the last few few seconds coming from specific source IP.",
                    "label": 0
                },
                {
                    "sent": "That's probably the best way to detect these kind of attacks.",
                    "label": 0
                },
                {
                    "sent": "So basically you have to construct additional features and then to make this data points move somewhere else, but they will form the cluster which is far from everything else, so it's not necessarily the normally, so only the single instances.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So already a dimension that people from different communities called the problem of anomaly detection with different names.",
                    "label": 0
                },
                {
                    "sent": "Some of them are using the rare class mining summarize using chance discovery.",
                    "label": 1
                },
                {
                    "sent": "People use novelty detection, exception mining, noise removal and recently there is a book but nothing solid.",
                    "label": 1
                },
                {
                    "sent": "The Black Swan is basically very interested book and he's explaining why there is a huge impact of this highly improbable events like the 9/11 or predicting the stock market which we may cause these days or not.",
                    "label": 0
                },
                {
                    "sent": "And so on.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So what are the key challenges when you're doing a anomaly detection?",
                    "label": 1
                },
                {
                    "sent": "So first the bigger challenge is to define a representative at the normal region usually.",
                    "label": 0
                },
                {
                    "sent": "It's hard to get a clear understanding what is normal, especially when you don't have the labels so big that it's another challenge that labeled data for training is not usually available.",
                    "label": 0
                },
                {
                    "sent": "For example, in many real life applications you don't have any labels.",
                    "label": 0
                },
                {
                    "sent": "You don't know what is normal, you know knows what is anomaly.",
                    "label": 0
                },
                {
                    "sent": "If you're lucky, you may know what is normal.",
                    "label": 0
                },
                {
                    "sent": "Sometimes you know several types of faults, and that may help you in your analysis.",
                    "label": 0
                },
                {
                    "sent": "Also, the boundary between the normal and outlying or anomalous behavior is not clear sometimes, so you have to figure it out and also the exact notion of anomaly or outlier is different for different applications.",
                    "label": 0
                },
                {
                    "sent": "For example, if you have the same kind of data set.",
                    "label": 0
                },
                {
                    "sent": "OK, we have more people.",
                    "label": 0
                },
                {
                    "sent": "Hello.",
                    "label": 0
                },
                {
                    "sent": "If you have, uh, same datasets that correspond to, for example, network intrusion detection, or correspond to fault diagnostics.",
                    "label": 0
                },
                {
                    "sent": "If you take certain.",
                    "label": 0
                },
                {
                    "sent": "Anomalies in that data set one normally from one application may be perfect.",
                    "label": 0
                },
                {
                    "sent": "Normal behavior while anomaly in another data set may correspond to something anomalous.",
                    "label": 0
                },
                {
                    "sent": "Also, data may contain a huge amount of noise and if you want to detect anomalies in the noisy data, this is quite different and difficult cause.",
                    "label": 0
                },
                {
                    "sent": "Sometimes regular.",
                    "label": 0
                },
                {
                    "sent": "The values may happen in the in the noisy environment.",
                    "label": 0
                },
                {
                    "sent": "This is especially true for time series data and temporal data.",
                    "label": 0
                },
                {
                    "sent": "When you're trying to detect anomalous subsequences.",
                    "label": 1
                },
                {
                    "sent": "So, for example, if a normal normal subsequence is.",
                    "label": 0
                },
                {
                    "sent": "For any reason, the different than anything else.",
                    "label": 0
                },
                {
                    "sent": "If you have the noisy data, single individual instances may not be maybe in the perfect age.",
                    "label": 0
                },
                {
                    "sent": "Also few examples.",
                    "label": 0
                },
                {
                    "sent": "It will be clear to you what I mean, so also in temporal data normal behavior keeps evolving.",
                    "label": 0
                },
                {
                    "sent": "So for example, if you create the model.",
                    "label": 0
                },
                {
                    "sent": "When you want to detect anomalies, this normal behavior is changing overtime, so your model should be updated as well.",
                    "label": 0
                },
                {
                    "sent": "So the question is how frequently you need to update this model, and you know how your data is model because the computational efficiency is very important because if you have the data streams data is coming at a normal speed, so we have to figure out how fast you need to do this and of course.",
                    "label": 0
                },
                {
                    "sent": "If you have thousands of features in your application.",
                    "label": 0
                },
                {
                    "sent": "Are all these thousand features important?",
                    "label": 0
                },
                {
                    "sent": "Which features are important for anomaly detection?",
                    "label": 0
                },
                {
                    "sent": "This is not the classical feature selection.",
                    "label": 0
                },
                {
                    "sent": "The problem like in every data money problem when you have the class label.",
                    "label": 0
                },
                {
                    "sent": "Here we usually do not have the class label and trying to identify.",
                    "label": 0
                },
                {
                    "sent": "Relevant features is not that is not easy, so different people are doing different.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "End of future projections and so on.",
                    "label": 0
                },
                {
                    "sent": "In order to detect the anomalies in different dimensions.",
                    "label": 0
                },
                {
                    "sent": "So there are several aspects of anomaly detection that we will try to cover here.",
                    "label": 1
                },
                {
                    "sent": "First, what kind of the data we have, the nature of input data, what kind of labels do you have?",
                    "label": 0
                },
                {
                    "sent": "Type of anomalies.",
                    "label": 0
                },
                {
                    "sent": "But I'll explain what this means, output what kind of output general election algorithm is providing to you and also how you do evaluation of anomaly detection techniques.",
                    "label": 1
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So, so let's assume that you have some data.",
                    "label": 0
                },
                {
                    "sent": "Most of the data is is coming into the form of either univariate or multivariate data is we have the univariate data usually have just one one variable, which is not very often the case, and if you have multivariate.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You have maybe 10s, hundreds or sometimes thousands of variables and you have to find anomalies in this multi dimensional space.",
                    "label": 0
                },
                {
                    "sent": "So the question is, if you have a normal is that appear in only one feature, that's easy to find.",
                    "label": 0
                },
                {
                    "sent": "But for example, if a normally it's not obvious in any of the individual features how to find these anomalies and was the right size of the attribute.",
                    "label": 0
                },
                {
                    "sent": "You need to take a look at.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So also you may deal with different kind of the type of attributes, but you also familiar with all of these from the data money perspective you may have the binary attributes.",
                    "label": 0
                },
                {
                    "sent": "You may have categorical attributes, continuous and hybrid for example if you're dealing with.",
                    "label": 0
                },
                {
                    "sent": "Network intrusion detection.",
                    "label": 0
                },
                {
                    "sent": "You may end up with using Source IP and Destination IP addresses, and sometimes it's not clear how to convert this IP and IP addresses into the future that you can use in your calculation.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so you also have different data types you may dealing with sequential data.",
                    "label": 0
                },
                {
                    "sent": "For example stock market data collecting from some engines, your car plane.",
                    "label": 0
                },
                {
                    "sent": "Also you may have the economics data like this is James data.",
                    "label": 0
                },
                {
                    "sent": "You may have the data from the traffic, you know how certain cars are moving, so you want to detect certain accidents.",
                    "label": 0
                },
                {
                    "sent": "Also, if you have earth science data you want.",
                    "label": 0
                },
                {
                    "sent": "You have basically spatial interpolator because you have two dimensions.",
                    "label": 0
                },
                {
                    "sent": "Also this is some data from the ports all across the US, and sometimes it's important to understand the location as well as other attributes.",
                    "label": 0
                },
                {
                    "sent": "So you see that sometimes you have the mixture of all these attributes plus spatial and temporal.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And you have to deal with all these issues in order to attack otherwise, according to the data labels that are available to you, you may have situations when we're talking about supervised anomaly detection in this case.",
                    "label": 0
                },
                {
                    "sent": "The labels for both normal and anomalous are available to you, so in this case you're just applying some classification techniques in order to detect both normal and anomalous, however.",
                    "label": 0
                },
                {
                    "sent": "Since this is usually imbalanced, kind of datasets usually have to tweak your classification algorithms to work on this kind of the other problems to different people were doing different things and I'll have a small section on these techniques.",
                    "label": 0
                },
                {
                    "sent": "Also, if you have labels available only from the normal data we're talking about, semi supervised anomaly detection techniques.",
                    "label": 1
                },
                {
                    "sent": "In this case we usually build some data mining the model to represent this normal behavior, and then you're trying to detect deviations from the normal behavior.",
                    "label": 0
                },
                {
                    "sent": "As potential anomalies.",
                    "label": 0
                },
                {
                    "sent": "And finally, when you don't have any labels, which is probably the most typical situation in real life problems you were talking about unsupervised anomaly detection.",
                    "label": 0
                },
                {
                    "sent": "And in this case you usually basing your decision, your algorithms on the assumption that the normal is a very rare compared to the normal data, and they are different from the majority of other data here.",
                    "label": 1
                },
                {
                    "sent": "So you're basically making assumption that majority of data have correspond to normal behavior and everything that is not belong to that majority behavior can be anomalous.",
                    "label": 0
                },
                {
                    "sent": "So obviously in this case you are prone to have the highest false alarm rate because you don't have any labels and you're treating everything.",
                    "label": 0
                },
                {
                    "sent": "New or everything unusual is anomalous.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Also, we're talking about three different types of anomalies, point anomalies, contextual and collective.",
                    "label": 1
                },
                {
                    "sent": "These are some terms that introduced in the survey that is published by our group at University, Minnesota recently.",
                    "label": 0
                },
                {
                    "sent": "You can download this survey.",
                    "label": 0
                },
                {
                    "sent": "It's available on version dollar website.",
                    "label": 0
                },
                {
                    "sent": "Here's the page student at University Minnesota, so you can get some extra information about anomaly detection comparing to this tutorial.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So what actually point anomalies?",
                    "label": 1
                },
                {
                    "sent": "The only words is saying that usually the data record only considering only the instances.",
                    "label": 0
                },
                {
                    "sent": "For example in this case this and always can be like single instances or some small group of instances when we're talking about the.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Contextual information I mentioned your earlier that when we considering temporal domain.",
                    "label": 0
                },
                {
                    "sent": "Sometimes.",
                    "label": 0
                },
                {
                    "sent": "You have some pattern in behavior, so in this case you have seasonal seasonal, the temperature and you can see that value T2.",
                    "label": 0
                },
                {
                    "sent": "If you look only the value of the temperature.",
                    "label": 0
                },
                {
                    "sent": "Value Tito is perfectly fine because it's it's in the range of all the temperatures here.",
                    "label": 0
                },
                {
                    "sent": "So if you just considering the values you cannot detect this pointing to as anomaly.",
                    "label": 0
                },
                {
                    "sent": "So from that reason you have to put this point into the context of observing the temperature and then it's obvious that you know you have a drop here, which is not expected at that specific time.",
                    "label": 0
                },
                {
                    "sent": "So that's why this is a normal listen.",
                    "label": 0
                },
                {
                    "sent": "This anomaly is usually detected.",
                    "label": 0
                },
                {
                    "sent": "You have to put the data occurs in the context.",
                    "label": 0
                },
                {
                    "sent": "This is also applicable.",
                    "label": 0
                },
                {
                    "sent": "For special at domain, for example if you have.",
                    "label": 0
                },
                {
                    "sent": "It desert and you are trying to monitor the temperature there.",
                    "label": 0
                },
                {
                    "sent": "You don't expect the snow in the desert, so you have to put this in the context for example.",
                    "label": 0
                },
                {
                    "sent": "But if you go to Minnesota, it's quite normal to expect the snow, so the spatial location is also very important.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So another term that we introduced this collective anomalies.",
                    "label": 1
                },
                {
                    "sent": "So usually in this case you have to look at collection of related data instances and to consider them as a normal is for example in this case this is ECG data from the beating of your heart.",
                    "label": 1
                },
                {
                    "sent": "So there is a regular at the pattern that appears here.",
                    "label": 0
                },
                {
                    "sent": "So every.",
                    "label": 0
                },
                {
                    "sent": "Some time interval you expecting this kind of behavior here.",
                    "label": 0
                },
                {
                    "sent": "However, if after a while you don't have any kind of data, this is anomalous.",
                    "label": 0
                },
                {
                    "sent": "However, if you look just in the data itself, you know this is quite normal, so we have again to put in the context of what is expected at this specific time.",
                    "label": 0
                },
                {
                    "sent": "So again, this is also applicable to sequential data spatial data and graph data.",
                    "label": 1
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Gay.",
                    "label": 0
                },
                {
                    "sent": "And finally, different anomaly detection algorithms can provide different outputs.",
                    "label": 0
                },
                {
                    "sent": "The simplest possible way is.",
                    "label": 0
                },
                {
                    "sent": "To just provide the label if the point is normal anomaly, but this is usually the case if you have classification techniques that are applied to the problem.",
                    "label": 0
                },
                {
                    "sent": "If you have both normal and anomaly labels available.",
                    "label": 0
                },
                {
                    "sent": "Of course, most of anomaly detection algorithms provide the score and usually the higher the score, the more more probable the data record is anomalous one, and you can always convert this score into into the label by specifying some kind of threshold and saying all the points about the threshold can be anomalous and everything else should be.",
                    "label": 0
                },
                {
                    "sent": "The normal behavior.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And finally, how you get how you evaluate these anomaly detection techniques.",
                    "label": 1
                },
                {
                    "sent": "Of course, if you use just accuracy, you know that this is not true.",
                    "label": 0
                },
                {
                    "sent": "For example, if you have a network intrusion.",
                    "label": 1
                },
                {
                    "sent": "The problem, and let's assume you have 99 Percent 99.9% of your data is is normal and 0.1 correspond to certain computer intrusions or computer attacks.",
                    "label": 1
                },
                {
                    "sent": "And if you're just using the trivial classifiers saying that everything is the normal, you will achieve 99.9% accuracy.",
                    "label": 1
                },
                {
                    "sent": "But obviously that's wrong, so that's why people constructing this confusion matrix.",
                    "label": 1
                },
                {
                    "sent": "I'm pretty sure that you're familiar with this, so in this case you basically.",
                    "label": 0
                },
                {
                    "sent": "He have the normal class and the normal class.",
                    "label": 0
                },
                {
                    "sent": "This is what is actually kind of the label and this is what you predict.",
                    "label": 0
                },
                {
                    "sent": "So you're making correct predictions here through negative and through positive.",
                    "label": 0
                },
                {
                    "sent": "And of course, you're making false positive if you're saying this is anomaly, but it's actually the normal class.",
                    "label": 0
                },
                {
                    "sent": "And of course you making the force the negative if you're saying this is the normal class, but it's actually anomaly or attack.",
                    "label": 0
                },
                {
                    "sent": "So obviously the first the negative is the.",
                    "label": 0
                },
                {
                    "sent": "Is one that have the high cost?",
                    "label": 0
                },
                {
                    "sent": "For example, it's highly.",
                    "label": 0
                },
                {
                    "sent": "It's very costly if you miss computer attack or if you miss the fault in your system.",
                    "label": 0
                },
                {
                    "sent": "If you Mr Attack certain disease from the medical at the data and this is false positive.",
                    "label": 0
                },
                {
                    "sent": "This is basically how much you're annoying your analyst, how much you're saying them.",
                    "label": 0
                },
                {
                    "sent": "It's something normal, but it's not.",
                    "label": 0
                },
                {
                    "sent": "And people are discussing different kind of measures from this data.",
                    "label": 0
                },
                {
                    "sent": "People construct recall, which is like the ratio of true positive over the true positive plus false negative.",
                    "label": 1
                },
                {
                    "sent": "This is similar to partial accuracy for their specific class, and of course a precision.",
                    "label": 0
                },
                {
                    "sent": "How many times we are.",
                    "label": 0
                },
                {
                    "sent": "Put the out of everything that we predicted.",
                    "label": 0
                },
                {
                    "sent": "How many times we made a correct prediction.",
                    "label": 0
                },
                {
                    "sent": "This is TP over 3 plus FP so.",
                    "label": 0
                },
                {
                    "sent": "In order to get the good tradeoff between these two values, people use F measure.",
                    "label": 0
                },
                {
                    "sent": "Most typical way is to use this formula here.",
                    "label": 1
                },
                {
                    "sent": "However, the more general formula is using the factor at beta, and in this case if you if you have beta equal to 1, you will get this formula.",
                    "label": 0
                },
                {
                    "sent": "However, if you want to and this is equal weight between recall and precision where we want to put more weight into recall or precision, you can change this parameter.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Also, you're so familiar that.",
                    "label": 0
                },
                {
                    "sent": "People also use terms and metrics like detection rate and false alarm rate, so detection rate is defined in the same way as recall.",
                    "label": 1
                },
                {
                    "sent": "Its rate is basically how many times I predicted something incorrectly.",
                    "label": 1
                },
                {
                    "sent": "False alarm rate is basically trying to say how many times I think I'm saying that something is anomalous, but it's not.",
                    "label": 0
                },
                {
                    "sent": "It's actually the normal behavior and as a tradeoff between these two values, people usually construct our seeker in RC curve you are.",
                    "label": 0
                },
                {
                    "sent": "On the X axis using false alarm rate.",
                    "label": 0
                },
                {
                    "sent": "And Y axis using detection rate and ideal RC curve should be something like that for the fazira false alarm you have to achieve 100% detection rate but this is usually cards achieving your life as you as you imagine in most real life RC curves look something like this.",
                    "label": 0
                },
                {
                    "sent": "So these are the typical curves for RC.",
                    "label": 1
                },
                {
                    "sent": "And of course, the people also trying to measure the area under the curve as as a metric to evaluate different either classification techniques or anomaly detection techniques.",
                    "label": 0
                },
                {
                    "sent": "In recent years people were also trying to improve the measure of area under the curve by proposing.",
                    "label": 0
                },
                {
                    "sent": "To compute how big error the classifiers are making and so basically instead of.",
                    "label": 0
                },
                {
                    "sent": "Providing the measure for the test data that you're dealing with is basically giving you impression how good generalizability the model has, so I think there are paper last year and paper this year that proposing different variations of area under the curve.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, and I mentioned earlier that there are different applications of anomaly detection.",
                    "label": 0
                },
                {
                    "sent": "I like to mention at network intrusion detection, their applications of different fraud detection like credit card fraud, insurance fraud.",
                    "label": 1
                },
                {
                    "sent": "In healthcare informatics and the medical diagnostics, we also have this problem.",
                    "label": 0
                },
                {
                    "sent": "I'll have one slide for each of them.",
                    "label": 0
                },
                {
                    "sent": "In industrials detection you may have different engineering systems that may experience some faults in image processing and video surveillance.",
                    "label": 0
                },
                {
                    "sent": "Anomalisa extremely important to detect some events like the life package at the airport and something suspicious.",
                    "label": 1
                },
                {
                    "sent": "And finally there is a topic of novel detection in text mining.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So intrusion detection as I said.",
                    "label": 1
                },
                {
                    "sent": "You're trying to monitor the computer network in order or computer system.",
                    "label": 1
                },
                {
                    "sent": "In order to analyze.",
                    "label": 0
                },
                {
                    "sent": "The network for certain interactions and interactions are usually defined as attempts to bypass the security of a computer or the network, and there are typical challenges in network intrusion, texture world, some of them that most of interest rebate.",
                    "label": 1
                },
                {
                    "sent": "Actually the current state of the art and currently interested state of the art intelligent action.",
                    "label": 0
                },
                {
                    "sent": "We did.",
                    "label": 1
                },
                {
                    "sent": "Most of the people using signature based intrusion detection systems.",
                    "label": 1
                },
                {
                    "sent": "Most of you have either the virus scan or the Norton that is checking for the virus in your computer.",
                    "label": 0
                },
                {
                    "sent": "And you know that you often have to go to the.",
                    "label": 0
                },
                {
                    "sent": "Actually, it's it's done automatically, but the software is going to the website trying to download all definitions of viruses and then it uses these definitions to detect all the viruses in our computers.",
                    "label": 0
                },
                {
                    "sent": "And these systems work in a similar way.",
                    "label": 0
                },
                {
                    "sent": "They have the signatures, full computer tags that are known so far, but obvious disadvantage of this.",
                    "label": 1
                },
                {
                    "sent": "The system says every time when you have a new attack there is a delay in detecting this attack.",
                    "label": 0
                },
                {
                    "sent": "So you have to go to the.",
                    "label": 0
                },
                {
                    "sent": "Website and download this the signature to take this computer intrusion and then you can attack this.",
                    "label": 0
                },
                {
                    "sent": "So basically these systems are incapable of detecting new and emerging computer threats and anomaly detection can be extremely important here because they can do this.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, I didn't.",
                    "label": 0
                },
                {
                    "sent": "Mention briefly about fraud detection.",
                    "label": 1
                },
                {
                    "sent": "So you may deal with different kind of fruits.",
                    "label": 0
                },
                {
                    "sent": "As I mentioned, credit card frauds when people trying to steal your credit card and using music to buy something on eBay.",
                    "label": 0
                },
                {
                    "sent": "That's difficult one.",
                    "label": 0
                },
                {
                    "sent": "Insurance claim you may claim that you lossed other people stole something for you, but that's not actually the case or mobile cell phone fraud.",
                    "label": 1
                },
                {
                    "sent": "If you lose the cell phone and someone else is trying to use that instead of you.",
                    "label": 1
                },
                {
                    "sent": "And in this case, most of the time you have temporal data and you have to deal with fast and accurate real time detection.",
                    "label": 0
                },
                {
                    "sent": "So basically you have the data streams they're not occurring at regular uniform intervals, so they occur every time when you have transaction or something bad happen.",
                    "label": 0
                },
                {
                    "sent": "Especially in credit card transaction and then we have to react fast because you have to stop this.",
                    "label": 0
                },
                {
                    "sent": "Fraudulent transactions and misclassification cost is very high if you don't say something is intrusion, you may actually the, for example, credit card company may lose a lot of money.",
                    "label": 1
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In the healthcare informatics you may deal with different problems.",
                    "label": 0
                },
                {
                    "sent": "For example if you analyzing certain disease anomalies may represent disease outbreaks.",
                    "label": 0
                },
                {
                    "sent": "For example, that's certain.",
                    "label": 0
                },
                {
                    "sent": "Disease can happen in certain area.",
                    "label": 0
                },
                {
                    "sent": "If you're dealing with, for example, people who have certain type of cancer.",
                    "label": 0
                },
                {
                    "sent": "Using anomaly detection, you may detect this cancer in advance or at early stage, so and then you can save the lives and usually in this case only normal data is available.",
                    "label": 0
                },
                {
                    "sent": "Very few instances of.",
                    "label": 0
                },
                {
                    "sent": "Rare class or anomalies can be available and in this case misclassification cost is very high.",
                    "label": 1
                },
                {
                    "sent": "So for example, if you missed the text that there is a cancer, you will lose the personal life, so that's that's really expensive and the data can be quite complex depending on the problem.",
                    "label": 0
                },
                {
                    "sent": "For example, in the case of disease outbreak data, maybe both spatial and temporal.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I mentioned earlier that there are extremely important problems in industrial damage detection and decisional involving engineering health applications.",
                    "label": 1
                },
                {
                    "sent": "So many companies are starting to apply different data mining techniques to help their physical based model techniques to detect certain failures in advance.",
                    "label": 0
                },
                {
                    "sent": "So they figure out that physical based models are not sufficient to explain and describe the complex.",
                    "label": 0
                },
                {
                    "sent": "Sharing systems and then the data driven techniques may help them.",
                    "label": 0
                },
                {
                    "sent": "So typical example is aircraft.",
                    "label": 0
                },
                {
                    "sent": "The safety and there is a recent effort from Vanessa they basically they try to use different data driven techniques to detect anomalies from the flight record data.",
                    "label": 0
                },
                {
                    "sent": "So the idea is to analyze the data from the flights during the flight and then if anything unusual that happened you may give the signal either to the pilot or to the center and say there is probably probably fault or something like that.",
                    "label": 0
                },
                {
                    "sent": "So this is also very important for aviation safety.",
                    "label": 0
                },
                {
                    "sent": "And it can also save many many lives.",
                    "label": 0
                },
                {
                    "sent": "However, there are many challenges in this gate data.",
                    "label": 0
                },
                {
                    "sent": "Since you're getting the data from different types of sensor data, may be extremely extremely huge can be extremely noisy because you're mixing, you know all different types of sensors, some of some of them more reliable, someone or not, and most of the time the data is not labeled at all, so you don't know what is normal.",
                    "label": 0
                },
                {
                    "sent": "You don't know what is anomaly.",
                    "label": 1
                },
                {
                    "sent": "Most of the applications because you're collecting this online, have temporal behavior, so you have to consider different sequential temporal anomaly detection techniques.",
                    "label": 0
                },
                {
                    "sent": "And detecting anomalous events require usually immediate intervention, and again, the cost here is extremely high, because if you missed this certain anomaly and this really correspond to failure in this case of aviation safety, you may use the hundreds of lives.",
                    "label": 1
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I mentioned that people tried to use recently different anomaly detection techniques in image processing and video surveillance, so.",
                    "label": 1
                },
                {
                    "sent": "As you know, we have more and more cameras everywhere, so they record us if you go to the airport, record us.",
                    "label": 0
                },
                {
                    "sent": "If you go Tom store they record us.",
                    "label": 0
                },
                {
                    "sent": "So people used to analyze this videos and images to detect some suspicious events and to detect different things.",
                    "label": 0
                },
                {
                    "sent": "For example, if an airport people try to detect this kind of that someone left the package.",
                    "label": 0
                },
                {
                    "sent": "That's also very important for the train stations and so on.",
                    "label": 0
                },
                {
                    "sent": "So using anomaly detection techniques can be here very, very important.",
                    "label": 1
                },
                {
                    "sent": "And again there are some key challenges you have to detect this.",
                    "label": 0
                },
                {
                    "sent": "A collective anomalies from the previous case because you have to put into context all different pieces.",
                    "label": 0
                },
                {
                    "sent": "What can be normal?",
                    "label": 0
                },
                {
                    "sent": "What can be anomaly in specific situation and datasets can be extremely huge and you have to convert the raw.",
                    "label": 0
                },
                {
                    "sent": "Image and video data into the data format.",
                    "label": 0
                },
                {
                    "sent": "It is appropriate to use by anomaly detection.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so this is a taxonomy of anomaly detection techniques that is also published in a survey by our group.",
                    "label": 1
                },
                {
                    "sent": "So we try to.",
                    "label": 1
                },
                {
                    "sent": "Categorise different anomaly detection techniques according to different criteria.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Let's start from left.",
                    "label": 0
                },
                {
                    "sent": "So we have this point anomaly detection when you're trying to basically find individual data records as anomalies.",
                    "label": 1
                },
                {
                    "sent": "And basically most of the problems into dealing with here.",
                    "label": 0
                },
                {
                    "sent": "Also you try to convert them into this problem because it's much easier to deal with this.",
                    "label": 0
                },
                {
                    "sent": "So you have these classification based techniques when you basically have.",
                    "label": 0
                },
                {
                    "sent": "Both normal and abnormal data available.",
                    "label": 0
                },
                {
                    "sent": "You have certain nearest neighbor based techniques.",
                    "label": 1
                },
                {
                    "sent": "Then you try to detect anomalies based on computing the distances between data records.",
                    "label": 0
                },
                {
                    "sent": "A clustering basic things are quite similar to this.",
                    "label": 0
                },
                {
                    "sent": "You have different statistical techniques which are based either on parametric or nonparametric well known statistical.",
                    "label": 0
                },
                {
                    "sent": "So physical approaches and you have some other techniques which include information theory based spectral composition.",
                    "label": 1
                },
                {
                    "sent": "Some people try different visualization techniques and so on.",
                    "label": 0
                },
                {
                    "sent": "And of course we already mentioned all of this.",
                    "label": 1
                },
                {
                    "sent": "Collect contextual and collective action.",
                    "label": 0
                },
                {
                    "sent": "If you have real time system you have to have an online anomaly detection and sometimes.",
                    "label": 1
                },
                {
                    "sent": "I mean the date meant the data is dispersed among several physical occasions.",
                    "label": 0
                },
                {
                    "sent": "You have to deal with distributed anomaly detection.",
                    "label": 0
                },
                {
                    "sent": "Sometimes you cannot merge data and you have to deal, you know how's it like.",
                    "label": 0
                },
                {
                    "sent": "This global anomalies?",
                    "label": 0
                },
                {
                    "sent": "We don't.",
                    "label": 0
                },
                {
                    "sent": "We don't modulate, but we'll talk briefly about this at the end.",
                    "label": 0
                },
                {
                    "sent": "Any questions so far?",
                    "label": 0
                },
                {
                    "sent": "OK, good.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so I'll start with explaining briefly the classification based techniques.",
                    "label": 1
                },
                {
                    "sent": "As I mentioned earlier.",
                    "label": 0
                },
                {
                    "sent": "The main idea is to build classification model for both normal and anomalous behavior.",
                    "label": 1
                },
                {
                    "sent": "So basically you assuming here that you have little labels from both normal and anomalous behavior available.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 1
                },
                {
                    "sent": "Classification models that use here must be able to handle this kind of skewed data distributions.",
                    "label": 0
                },
                {
                    "sent": "For example, if you have 99% of data that correspond to normal and only 1%, it corresponds to anomalies using simple decision tree may not give you very good results because usually these techniques are.",
                    "label": 0
                },
                {
                    "sent": "Hello.",
                    "label": 0
                },
                {
                    "sent": "Designed for Val balance datasets.",
                    "label": 0
                },
                {
                    "sent": "So in this case we are dealing with two types of approaches, supervised and semi supervised classification techniques.",
                    "label": 0
                },
                {
                    "sent": "In supervised you basically solving both labels available both from normal and.",
                    "label": 0
                },
                {
                    "sent": "Anomaly and you have to.",
                    "label": 1
                },
                {
                    "sent": "Low.",
                    "label": 1
                },
                {
                    "sent": "Construct different type of classifiers to classify between normal and anomalous and finally in the semi supervised you're assuming there is only label from the normal behavior.",
                    "label": 0
                },
                {
                    "sent": "Available and then using some kind of one class model to define what is normal and then to detect deviations from this normal behavior.",
                    "label": 0
                },
                {
                    "sent": "For for anomaly, so basically you have the data from the normal only you're trying to construct the model that will describe this normal behavior and then you're using this at the model to go to the new data.",
                    "label": 0
                },
                {
                    "sent": "Everything that fits this.",
                    "label": 0
                },
                {
                    "sent": "The model would correspond to normal here.",
                    "label": 0
                },
                {
                    "sent": "Everything else should be anomaly.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "So obvious advantages of these techniques are that.",
                    "label": 0
                },
                {
                    "sent": "It models can be easy to understand because you exactly know what is normal, what is anomaly?",
                    "label": 0
                },
                {
                    "sent": "Also, since you have both normal and normally, you can achieve pretty high accuracy in detecting these events.",
                    "label": 1
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "In summer supervised techniques also the normal behavior, since you know what is normal normally can be actually very well learned and you can use this description of our behavior to detect future anomalies.",
                    "label": 0
                },
                {
                    "sent": "Obvious kind of disadvantages include that in both cases you require.",
                    "label": 1
                },
                {
                    "sent": "The labels in supervised techniques you require both labels from normal anomaly and summer supervisor required.",
                    "label": 0
                },
                {
                    "sent": "The labels from the remotest and in real life application.",
                    "label": 0
                },
                {
                    "sent": "This is sometimes not feasible because in order to label this data, let's say you have millions of data records.",
                    "label": 1
                },
                {
                    "sent": "You need some time.",
                    "label": 0
                },
                {
                    "sent": "The drawback of supervised classification techniques they can usually.",
                    "label": 1
                },
                {
                    "sent": "They cannot detect this emerging and new anomalous because they know what is normal and normal and everything outside the range.",
                    "label": 0
                },
                {
                    "sent": "They will just be longer than normal anomaly depending on the closeness.",
                    "label": 0
                },
                {
                    "sent": "And in summer, supervised since we have the information only about the normal, you may have relatively high false alarm rate because everything new which does not correspond to normal may be categorized.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Normally.",
                    "label": 0
                },
                {
                    "sent": "There are some typical techniques for supervised classification, so people.",
                    "label": 1
                },
                {
                    "sent": "First try to use different kind of manipulation of data records.",
                    "label": 0
                },
                {
                    "sent": "So the simplest thing is to do.",
                    "label": 0
                },
                {
                    "sent": "Either oversampling undersampling I'll talk briefly about this.",
                    "label": 1
                },
                {
                    "sent": "People also did different kind of rule based techniques.",
                    "label": 1
                },
                {
                    "sent": "And people also try different kind of the neural network support vector machines, Bayesian networks approaches.",
                    "label": 1
                },
                {
                    "sent": "People also tried cost sensitive classification techniques.",
                    "label": 0
                },
                {
                    "sent": "When for example when you're learning your classifier.",
                    "label": 0
                },
                {
                    "sent": "In criteria that you use to construct classifier, you introducing the cost.",
                    "label": 0
                },
                {
                    "sent": "So basically if you trying to measure the cost of making the force at the negative is much higher than making the false positive error, so that's how you tweak your classifier to do different things and also different researchers were trying to use an sample based learning to combine.",
                    "label": 0
                },
                {
                    "sent": "Some of oversampling undersampling techniques with the boosting, for example, we have a smooth boost variables and a meter cost.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So let's first briefly talk about the data manipulation techniques.",
                    "label": 0
                },
                {
                    "sent": "So there are three basic approaches here.",
                    "label": 0
                },
                {
                    "sent": "You can do either oversampling.",
                    "label": 0
                },
                {
                    "sent": "Undersampling or try to generate some artificial anomalies so in the oversampling is the word saying.",
                    "label": 0
                },
                {
                    "sent": "You're basically trying to make the duplicates of the rare events or basically of minority class until the data sets contain as many examples as majority class.",
                    "label": 0
                },
                {
                    "sent": "So basically trying to make the datasets.",
                    "label": 0
                },
                {
                    "sent": "Equally balanced, so obviously you're not introducing any new information here, you're just trying to duplicate to duplicate records, and this usually does not increase information, but it basically creates only misclassification costs, so that's usually does not give you good result.",
                    "label": 0
                },
                {
                    "sent": "Another approach is to do downsizing, basically undersampling the majority class.",
                    "label": 0
                },
                {
                    "sent": "So in this case, undersampling the normal class.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "Examples.",
                    "label": 0
                },
                {
                    "sent": "From from minority class are selected using several techniques.",
                    "label": 0
                },
                {
                    "sent": "Either you do randomly.",
                    "label": 0
                },
                {
                    "sent": "Either you're trying to, when you selecting the data from the normal class you are trying to do the near Miss examples.",
                    "label": 1
                },
                {
                    "sent": "For example, when you make the most mistakes you're trying to select this data point.",
                    "label": 0
                },
                {
                    "sent": "When you make classification because they are most useful also.",
                    "label": 0
                },
                {
                    "sent": "You can when you are trying to select the data from normal, you're trying to exempt to select examples that are far from minority class examples or basically far from decision boundaries so different people will try different techniques when selecting this.",
                    "label": 0
                },
                {
                    "sent": "And of course they got different styles depending on the data set that they're trying to apply their results on.",
                    "label": 0
                },
                {
                    "sent": "And usually this results in a general loss of information and.",
                    "label": 0
                },
                {
                    "sent": "Basically two general.",
                    "label": 0
                },
                {
                    "sent": "Rules because if you have less data, euros will be to add general and then we have relatively poor prediction performance.",
                    "label": 0
                },
                {
                    "sent": "And finally, there are a few approaches that are trying to generate some artificial anomalies.",
                    "label": 0
                },
                {
                    "sent": "So basically official example from minority class from your.",
                    "label": 0
                },
                {
                    "sent": "A real class.",
                    "label": 0
                },
                {
                    "sent": "There is a smooth technique where basically new examples from minority class are generated inside the regions of existing rare class examples.",
                    "label": 0
                },
                {
                    "sent": "But again since this is within the well defined at boundary, this again may not increase the performance as well because you're you're generating the class within the well defined region.",
                    "label": 0
                },
                {
                    "sent": "However, if you have normal data records that are within this region, this may try to alleviate some noise effects.",
                    "label": 0
                },
                {
                    "sent": "Because you will get more robust classifiers in this case.",
                    "label": 0
                },
                {
                    "sent": "Also another approach by fan that artificial normal is generated around the edges of the sparsely populated later.",
                    "label": 0
                },
                {
                    "sent": "This is a little bit different in this one, driven by different.",
                    "label": 0
                },
                {
                    "sent": "Idea and also there is a recent approach by Nokia.",
                    "label": 1
                },
                {
                    "sent": "Ben Biancas draws me from IBM to classify synthetic outlets versus the real normal data using some type of active learning.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "For all of these references you have at the end of tutorial so you can find this paper.",
                    "label": 0
                },
                {
                    "sent": "Most of this paper can find online.",
                    "label": 0
                },
                {
                    "sent": "So another type of classification based technique that I prefer normal function are called role based techniques.",
                    "label": 0
                },
                {
                    "sent": "So some people design new techniques to deal with rare class problems.",
                    "label": 0
                },
                {
                    "sent": "Some of these are coming from University, Minnesota.",
                    "label": 0
                },
                {
                    "sent": "PN role and create this algorithm.",
                    "label": 0
                },
                {
                    "sent": "Some people try to adapt existing rule based techniques like C 4.5 and adapting some multi classification.",
                    "label": 0
                },
                {
                    "sent": "Is the method to single classification problem.",
                    "label": 0
                },
                {
                    "sent": "In this case we have only a normal class and that's where we use to describe the normal behavior.",
                    "label": 0
                },
                {
                    "sent": "In the.",
                    "label": 0
                },
                {
                    "sent": "Association rules people were trying to do different basically things to describe what can correspond to normal behavior, for example.",
                    "label": 0
                },
                {
                    "sent": "Rules are certain rules that have high support, which then actually have higher support in some pre specified threshold.",
                    "label": 0
                },
                {
                    "sent": "May characterize the normal behavior.",
                    "label": 1
                },
                {
                    "sent": "That's the most obvious way to apply Association rules.",
                    "label": 0
                },
                {
                    "sent": "Also some people try to associate anomalous data records that occur in fewer frequent itemsets compared to the normal data record.",
                    "label": 1
                },
                {
                    "sent": "And finally, if you're dealing with temporal data, frequent episodes also used to describe the normal behavior this is.",
                    "label": 0
                },
                {
                    "sent": "One of the first techniques trying data mining for network intrusion detection by Van Cleef from Columbia University Hills.",
                    "label": 0
                },
                {
                    "sent": "Frequent episodes to define the normal temporal behavior and then he used the Reaper.",
                    "label": 0
                },
                {
                    "sent": "On top of that to detect normal versus intrusions.",
                    "label": 0
                },
                {
                    "sent": "And, uh, some people also used.",
                    "label": 0
                },
                {
                    "sent": "K specific feature and rule and waiting, which basically.",
                    "label": 0
                },
                {
                    "sent": "Tells you that you have to give different weights, different feature in order to achieve good performance.",
                    "label": 0
                },
                {
                    "sent": "For example, in Decision tree learning, in this case specific feature waiting for each rare class test example you have to replace global late vector with dynamically generated rate vector depends on the path taken by that example and also in this another approach case specific role rating is.",
                    "label": 1
                },
                {
                    "sent": "Basically a little bit at a different you.",
                    "label": 0
                },
                {
                    "sent": "Basically the algorithm increases the roles trend for all the rules that describe the rare class.",
                    "label": 0
                },
                {
                    "sent": "So basically we have some rule based algorithms that define the both classes.",
                    "label": 0
                },
                {
                    "sent": "You're basically first focusing on defining the rare class and then you will define the normal price.",
                    "label": 0
                },
                {
                    "sent": "Is the similar idea is.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Also for the PM role in the panel you have two steps.",
                    "label": 0
                },
                {
                    "sent": "You have the P phase and you have the end phase in the P phase you basically trying to construct all the rules that cover basically all the rare class examples.",
                    "label": 0
                },
                {
                    "sent": "So basically if this is your kind of data set and this is your.",
                    "label": 0
                },
                {
                    "sent": "Or Eric listen normally class and this is the normal class.",
                    "label": 0
                },
                {
                    "sent": "Your first trying to construct the rules.",
                    "label": 0
                },
                {
                    "sent": "That will cover most of examples in this region in this region.",
                    "label": 1
                },
                {
                    "sent": "So so basically when constructing the rules, some of those may cover examples from the normal class as well.",
                    "label": 0
                },
                {
                    "sent": "So basically that's why you have this end phase.",
                    "label": 0
                },
                {
                    "sent": "When you try basically to eliminate these errors that introduce in this phase.",
                    "label": 0
                },
                {
                    "sent": "So basically all of this point in all of this data records that are detected by this rules here will be eliminated in this phase.",
                    "label": 0
                },
                {
                    "sent": "So basically that's why you're so.",
                    "label": 0
                },
                {
                    "sent": "This enrolls gives high accuracy and significant support, and piano can give really good results when you're dealing with this kind of imbalance datasets.",
                    "label": 1
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "There is another approach called Crados, also by Market Yoshi from University Minnesota.",
                    "label": 0
                },
                {
                    "sent": "He used the ripple down rules which is some form of decision tree in basically in which every node has a protective role associated with this.",
                    "label": 1
                },
                {
                    "sent": "So this ripple down rules specialized genetic specialist genetic form.",
                    "label": 1
                },
                {
                    "sent": "Of multiphase PN role at model so.",
                    "label": 0
                },
                {
                    "sent": "So basically in panel at the model you have two phases here basically for every of these.",
                    "label": 1
                },
                {
                    "sent": "Rules you have the path associated this so there again two phases, growth and pruning in growth.",
                    "label": 0
                },
                {
                    "sent": "You're basically using this ripple down rules to cover most of the positive examples and basically by doing this you will overfit the training data and as a result you will get a binary tree where each node is.",
                    "label": 1
                },
                {
                    "sent": "Characterized by the rule.",
                    "label": 1
                },
                {
                    "sent": "A default class and the links that to child subtrees.",
                    "label": 0
                },
                {
                    "sent": "This is just the implementation and you have to grow this ripple down structure in recursive admin.",
                    "label": 0
                },
                {
                    "sent": "And finally, in the second phase.",
                    "label": 0
                },
                {
                    "sent": "Prone phase, you have to prune this structure in order, basically to improve generalization.",
                    "label": 0
                },
                {
                    "sent": "It's something similar how you prune the decision tree in order to improve the generalization.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "Different people were using different forms of world at the networks to apply them on intrusion detection or self engineering health applications and so on.",
                    "label": 0
                },
                {
                    "sent": "So these are all different types of techniques that people are using when both of the labels were available and I mean I'll not go through most of this because there's just modification of regular neural networks.",
                    "label": 0
                },
                {
                    "sent": "You have all these kind of references.",
                    "label": 0
                },
                {
                    "sent": "You can go there and and track because there is nothing significantly introduced here.",
                    "label": 0
                },
                {
                    "sent": "People just supply neural networks for different rare class problems.",
                    "label": 0
                },
                {
                    "sent": "And what is the typical and common for most of them that they assume that both labels from normal and abnormal is available to them?",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "People also use different forms of support vector classifiers to detect intrusions.",
                    "label": 1
                },
                {
                    "sent": "The main idea here is basically that.",
                    "label": 0
                },
                {
                    "sent": "This approach bystanders that normal data records can belong to high density data regions, while the data from the data basically that correspond to normalize correspond to low density data regions and then he used unsupervised approach to learn high density and low density data regions and then he used the standard support vector machines to classify this data density level.",
                    "label": 1
                },
                {
                    "sent": "Another approach.",
                    "label": 0
                },
                {
                    "sent": "Is by mukkamala.",
                    "label": 0
                },
                {
                    "sent": "He assumed that he has both labels available, normal and abnormal.",
                    "label": 0
                },
                {
                    "sent": "And he used the support vector machines for the problem of network intrusion detection.",
                    "label": 0
                },
                {
                    "sent": "So I mean this is up Europe.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Nation paper and you know, not significant research skills in three hours here.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Other type of.",
                    "label": 0
                },
                {
                    "sent": "Classification techniques for normalization.",
                    "label": 0
                },
                {
                    "sent": "Semi supervised.",
                    "label": 0
                },
                {
                    "sent": "When we talked about this.",
                    "label": 0
                },
                {
                    "sent": "So basically they use modify classification at the model to represent normal behavior only an older version from this normal behavior may correspond to anomalies.",
                    "label": 1
                },
                {
                    "sent": "So people use different approaches.",
                    "label": 1
                },
                {
                    "sent": "People use neural networks, support vector machines, so Markov model based approaches, which can be extremely good if you have temporal data and you're trying to capture the transitions between the sequences.",
                    "label": 1
                },
                {
                    "sent": "And finally you have different kind of rule based approaches.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So, uh, this is.",
                    "label": 0
                },
                {
                    "sent": "Form of neural network which is called replicator neural network.",
                    "label": 1
                },
                {
                    "sent": "Or some people called Diablo neural network.",
                    "label": 0
                },
                {
                    "sent": "So the basic idea here is to use this type of network to learn the normal behavior.",
                    "label": 0
                },
                {
                    "sent": "So you put your input data here this input layer.",
                    "label": 1
                },
                {
                    "sent": "And you're trying to reconstruct your input data here at the output layer.",
                    "label": 0
                },
                {
                    "sent": "So so some form of this neural network is also used for dimensionality reduction.",
                    "label": 0
                },
                {
                    "sent": "So basically we're trying to reduce the dimension of this, let's say 100 space 100 dimensional space into something smaller here.",
                    "label": 0
                },
                {
                    "sent": "And if you're able to reconstruct your input data from this reduce space.",
                    "label": 0
                },
                {
                    "sent": "So basically, if you are able to get.",
                    "label": 0
                },
                {
                    "sent": "The same data is the data on the input.",
                    "label": 1
                },
                {
                    "sent": "You are good and basically this layer may may be used as the reduced the majority space.",
                    "label": 0
                },
                {
                    "sent": "So the idea here is to measure the difference between.",
                    "label": 1
                },
                {
                    "sent": "Output and the input.",
                    "label": 0
                },
                {
                    "sent": "This is called reconstruction error.",
                    "label": 0
                },
                {
                    "sent": "And to use this reconstruction error as the measure for out learners.",
                    "label": 0
                },
                {
                    "sent": "So basically the smaller reconstruction error.",
                    "label": 0
                },
                {
                    "sent": "That means that data should correspond to normal behavior.",
                    "label": 0
                },
                {
                    "sent": "The large reconstruction error, the data make respond to novels.",
                    "label": 0
                },
                {
                    "sent": "So basically in the training phase you have only normal, you have only normal data records, you passing all normal data records with this kind of neural network.",
                    "label": 0
                },
                {
                    "sent": "Your training this network, and then when you're done, you know network represent this normal here pretty well.",
                    "label": 0
                },
                {
                    "sent": "So now when you go to the testing phase, every data record that you pass through this neural network.",
                    "label": 0
                },
                {
                    "sent": "Will behave in two different ways.",
                    "label": 0
                },
                {
                    "sent": "If this is the normal data record, it will have small reconstruction error.",
                    "label": 0
                },
                {
                    "sent": "If this is anomalous data record, it will have huge reconstruction error.",
                    "label": 0
                },
                {
                    "sent": "So that's the basic idea.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "People also use different forms of one class support vector machines to detect anomalies, so outliers.",
                    "label": 0
                },
                {
                    "sent": "So people use different techniques and but the most common approach is basically to separate the entire set of training data from the origin here and to find a small region where the most of the data allocated.",
                    "label": 1
                },
                {
                    "sent": "So I mean, these are all the different approaches.",
                    "label": 0
                },
                {
                    "sent": "Usually you're dealing with two parameters you care to specify number of authors.",
                    "label": 0
                },
                {
                    "sent": "So basically specify how many outlets we expect and also you are specifying the variance of our RBF kernel, radial basis function, the criminal if you're.",
                    "label": 1
                },
                {
                    "sent": "If the variance of the radial basis function getting smaller, that means you need the larger number of support vectors to cover the area and separating surface get more complex.",
                    "label": 0
                },
                {
                    "sent": "And that's usually why you don't get that such good generalizability vice versa.",
                    "label": 0
                },
                {
                    "sent": "If your variance is getting bigger, you don't need that many support vectors, but again, your model can be two general.",
                    "label": 1
                },
                {
                    "sent": "So another approach here can be in.",
                    "label": 0
                },
                {
                    "sent": "Using support vector applied by shortcut is to separate regions that contain data from the regions that have only very few data records.",
                    "label": 0
                },
                {
                    "sent": "And in the end, basic ideas to push the hyperplane away from these regions.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so we came to the second type of anomaly detection techniques, which are called the nearest neighbor based techniques, and in this approach is usually you have.",
                    "label": 1
                },
                {
                    "sent": "The distance computation is the key.",
                    "label": 0
                },
                {
                    "sent": "How to measure what is the normal and what is that?",
                    "label": 0
                },
                {
                    "sent": "Two major approaches.",
                    "label": 1
                },
                {
                    "sent": "There are distance based on density based.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Roaches so as I said, the key assumption is that the normal points have.",
                    "label": 1
                },
                {
                    "sent": "At the neighbors, very close at neighbors, so normal points are located in a very.",
                    "label": 0
                },
                {
                    "sent": "Dense region they have a lot of points around them while anomalies allocated in some areas that are kind of isolated.",
                    "label": 0
                },
                {
                    "sent": "So that's the main idea.",
                    "label": 0
                },
                {
                    "sent": "Actually behind this approach, and usually it contains 2 steps in the first step you compute the neighborhood for every data record.",
                    "label": 0
                },
                {
                    "sent": "And then you're trying to analyze the neighborhood in order to determine whether the data record correspond to normally or not.",
                    "label": 1
                },
                {
                    "sent": "And there's a mention earlier.",
                    "label": 0
                },
                {
                    "sent": "There are two major approaches, distance based then.",
                    "label": 1
                },
                {
                    "sent": "Basically, you're trying to compute the anomalies.",
                    "label": 0
                },
                {
                    "sent": "Is the point that are too far from everything else and density based methods.",
                    "label": 1
                },
                {
                    "sent": "When basically you are treating anomalous data points that are located in the low density regions.",
                    "label": 0
                },
                {
                    "sent": "I'll talk about both of them.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In the later slides, so obviously advantages of these approaches.",
                    "label": 0
                },
                {
                    "sent": "Are that they can be used in unsupervised or semi supervised setting so they do not require any information about the labels.",
                    "label": 0
                },
                {
                    "sent": "Obvious drawback.",
                    "label": 0
                },
                {
                    "sent": "That if normal points do not have sufficient number of the neighbors, this technique may fail.",
                    "label": 0
                },
                {
                    "sent": "Also very important drawback that they're computationally expensive 'cause you know trying to compute the neighbors for every day to record.",
                    "label": 0
                },
                {
                    "sent": "It's usually often square and for many real life application this is not.",
                    "label": 0
                },
                {
                    "sent": "This is not practical, so people are trying to use different kind of techniques like KD trees are trees to improve the search for nearest neighbors and to reduce the complexity 2 N log N. Also, in high dimensional spaces.",
                    "label": 0
                },
                {
                    "sent": "Data is quite sparse and concept of similarity is not do meaningful anymore because due to sparseness the date actually the distance between any two data records can be quite similar and then each data record may be considered as potential outlet or potential anomaly.",
                    "label": 0
                },
                {
                    "sent": "So that's that's why selecting important features and in selecting relevant features may be quite important here because if you have let's say 200 dimensions.",
                    "label": 0
                },
                {
                    "sent": "For trying to compute the distances using these two dimensional space, all the distances may be quite large and you know your notion of anomaly may not be good, so that's why it's important to select only few relevant features that you may use in this kind of approach, and then you can achieve much better results.",
                    "label": 0
                },
                {
                    "sent": "Of course this depends on application and you have to work probably closely with.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "People who have domain knowledge.",
                    "label": 0
                },
                {
                    "sent": "So the 1st.",
                    "label": 0
                },
                {
                    "sent": "Type of techniques that belong to the city to distance based techniques and nearest neighbor based techniques.",
                    "label": 1
                },
                {
                    "sent": "And in this case, this is a classical definition by the paper by North.",
                    "label": 0
                },
                {
                    "sent": "And the point is, in data set is considered as outlier if at least some fraction P. That especially here of the points in datasets lights greater than distance D. Also specify here from certain .0.",
                    "label": 1
                },
                {
                    "sent": "So there's a classical definition of outlier.",
                    "label": 0
                },
                {
                    "sent": "Using this approach intensity based approach.",
                    "label": 1
                },
                {
                    "sent": "Local densities of particular regions.",
                    "label": 0
                },
                {
                    "sent": "Are computed and then you define all the instances that lie in this low density regions as potential anomalies.",
                    "label": 1
                },
                {
                    "sent": "Typical approaches.",
                    "label": 0
                },
                {
                    "sent": "In this.",
                    "label": 0
                },
                {
                    "sent": "In this density based techniques, a local outlier, factor connectivity, outlier factor, multi granularity division factor people, some researchers also use kernel estimation to estimate the density around at points.",
                    "label": 0
                },
                {
                    "sent": "I'll present all of these three papers so I can see how they do this.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So in the nearest.",
                    "label": 0
                },
                {
                    "sent": "Neighbor approach is this the most similar and actually the simplest possible technique to detect anomalies.",
                    "label": 0
                },
                {
                    "sent": "So basically for each data point, first step is to compute the distance from the Kate closes point.",
                    "label": 1
                },
                {
                    "sent": "So this distance is called decay is called K distance, and then you sort all this data records according to this distance that you computed in the previous step.",
                    "label": 0
                },
                {
                    "sent": "Obviously the data records that have very large distance.",
                    "label": 0
                },
                {
                    "sent": "That means they are far from everything else.",
                    "label": 0
                },
                {
                    "sent": "And they can be on the top of the list.",
                    "label": 1
                },
                {
                    "sent": "So basically you take the top one or two percent from that list and you treat them as anomalies.",
                    "label": 0
                },
                {
                    "sent": "So usually you have the parameter.",
                    "label": 0
                },
                {
                    "sent": "How many top data I could you want to consider is enormous.",
                    "label": 0
                },
                {
                    "sent": "And also this you have also the parameter for K was the how many clauses point you want to consider.",
                    "label": 0
                },
                {
                    "sent": "However, this technique is not suitable for datasets that have mode switch wearing at the density.",
                    "label": 1
                },
                {
                    "sent": "For example, I'll show this example in the next slide.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So let's assume we have two clusters here, one very dense cluster.",
                    "label": 0
                },
                {
                    "sent": "Here another one very sparse here, and we have three points P1P2 and P3 for which we want to consider.",
                    "label": 0
                },
                {
                    "sent": "Oops.",
                    "label": 0
                },
                {
                    "sent": "For which we want to consider actually for which we want to determine if there are outliers or not.",
                    "label": 0
                },
                {
                    "sent": "Obviously, point P1 is a normal because it's far from everything else.",
                    "label": 0
                },
                {
                    "sent": "That's very simple.",
                    "label": 0
                },
                {
                    "sent": "However, if you want to consider points P2 and P3.",
                    "label": 0
                },
                {
                    "sent": "And if you want to compute the distance only, the distance from point P2 to the closest point is this line here something like this?",
                    "label": 1
                },
                {
                    "sent": "The distance from Point P3 to the closest point is something like that.",
                    "label": 1
                },
                {
                    "sent": "So this distance is quite similar.",
                    "label": 0
                },
                {
                    "sent": "And if you want to say which of these two points are anomalous, what we would say is P2 or P3.",
                    "label": 0
                },
                {
                    "sent": "P2 OK, because its distance from this local region.",
                    "label": 0
                },
                {
                    "sent": "Here P through kind of belongs to this sparse region, so you can see that computing only the distance may not be sufficient to detect what is anomaly.",
                    "label": 1
                },
                {
                    "sent": "So that's why people are trying to use kind of density based approaches to detect what is the normal.",
                    "label": 0
                },
                {
                    "sent": "So basically in this case they would compute the densities in this region.",
                    "label": 0
                },
                {
                    "sent": "Computer desk is here and then they'll they'll determine what is outlier so.",
                    "label": 0
                },
                {
                    "sent": "The main idea behind this density based approaches is.",
                    "label": 0
                },
                {
                    "sent": "You compute the density local density around the point.",
                    "label": 0
                },
                {
                    "sent": "So basically this point consider these points around as the closest point.",
                    "label": 0
                },
                {
                    "sent": "However, this point considered this point is the closest point, so they do not share the same notion of the neighborhood.",
                    "label": 0
                },
                {
                    "sent": "So points do not share the same notion of the neighborhood.",
                    "label": 0
                },
                {
                    "sent": "That means something is wrong, so that basically that's how you detect this.",
                    "label": 0
                },
                {
                    "sent": "Another point is anomaly, and this is.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "LF approach this is one of the first approaches that employ this kind of idea, so it has four steps.",
                    "label": 0
                },
                {
                    "sent": "First step is to compute the distance to the Kate Clauses point is the same as the distance based approach.",
                    "label": 1
                },
                {
                    "sent": "In the second step.",
                    "label": 0
                },
                {
                    "sent": "In the second step, you're basically computing something they called reachability distance, and this is basically defined for two points.",
                    "label": 0
                },
                {
                    "sent": "For if you have one point and you define the Kate at the distance you are constructing the hyper sphere with radius of Cade distance for all the points that are inside of this hypersphere.",
                    "label": 1
                },
                {
                    "sent": "Reachability distance is equal to the radius.",
                    "label": 0
                },
                {
                    "sent": "For all the points at the outside of that hypersphere, reachability distance is actually equal to actual distance between these two points.",
                    "label": 0
                },
                {
                    "sent": "This is done just for some to make this algorithm robust, cause sometimes if you have two or three same data records, the algorithm may not be robust and may give you some results.",
                    "label": 0
                },
                {
                    "sent": "The third step is to compute local reachability density, and this is defined as the inverse of the.",
                    "label": 1
                },
                {
                    "sent": "Reachability at distances from the points around you.",
                    "label": 0
                },
                {
                    "sent": "So basically you're considering the points around you.",
                    "label": 0
                },
                {
                    "sent": "You computing the distances to them an inverse of that sum should be should be notion of the density.",
                    "label": 0
                },
                {
                    "sent": "If you have closed points around you, that means the density is higher.",
                    "label": 0
                },
                {
                    "sent": "If you have the points around you that you consider is the neighbored far from you, that means you are living in the sparse kind of neighborhood.",
                    "label": 0
                },
                {
                    "sent": "So for example, if you live in New York City, you have a lot of clothes at neighborhood and then you're dense this guy.",
                    "label": 0
                },
                {
                    "sent": "If you live in Texas or somewhere else, your neighborhood sparse.",
                    "label": 1
                },
                {
                    "sent": "So because you have your neighbors are not that close.",
                    "label": 0
                },
                {
                    "sent": "And final step is basically to compute local outlier factor.",
                    "label": 0
                },
                {
                    "sent": "Is the ratio for.",
                    "label": 0
                },
                {
                    "sent": "A local ability densities for all the points around you and your and your density.",
                    "label": 0
                },
                {
                    "sent": "For example, if the points around me that I consider is the closest point, he have different.",
                    "label": 0
                },
                {
                    "sent": "Density, then I do, then this will be an anomaly because this will give higher normal score.",
                    "label": 0
                }
            ]
        }
    }
}