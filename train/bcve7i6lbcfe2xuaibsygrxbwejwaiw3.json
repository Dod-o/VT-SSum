{
    "id": "bcve7i6lbcfe2xuaibsygrxbwejwaiw3",
    "title": "COALA \u2013 Correlation Aware Active Learning of Link Specifications",
    "info": {
        "author": [
            "Axel-Cyrille Ngonga Ngomo, University of Leipzig"
        ],
        "introducer": [
            "Marko Grobelnik, Artificial Intelligence Laboratory, Jo\u017eef Stefan Institute"
        ],
        "published": "July 8, 2013",
        "recorded": "May 2013",
        "category": [
            "Top->Computer Science->Semantic Web",
            "Top->Computer Science->Big Data"
        ]
    },
    "url": "http://videolectures.net/eswc2013_ngonga_ngomo_link/",
    "segmentation": [
        [
            "For those who don't know me, my name is Axel.",
            "I'm from the University of Leipzig in Germany.",
            "And what I'm going to talk about.",
            "OK, that you work the 2nd and it didn't work then.",
            "Well, I'm going to talk about is the correlation our active learning of link specifications."
        ],
        [
            "The question."
        ],
        [
            "Oscar cells object list.",
            "What do we need links for?",
            "And as I said, they are central for implementing.",
            "Basically the link data web.",
            "This actually does work because most of the leader with applications, the large scale once obviously rely on links.",
            "Now if you look at the current apology after linked open Data Cloud, we basically see that we have plenty of triples and not that many links less than 2% of the triples are links on top of it.",
            "We only have you mostly have a certain type of links that are.",
            "There are same as links.",
            "So we can now ask ourselves why?"
        ],
        [
            "Why is it difficult to create links and technically?",
            "Most link discovery systems rely on an approach that goes as follows that try to approximate the set M of pairs from the Cartesian product of a set of source instances and target instances that are related via relation R by computing a similarity function, a complex similarity function on the threshold.",
            "And they basically say if I have approximate M with M prime by saying that if Sigma Fest EST belonging to S * T is larger than equal to Terra, then St is a so called link candidate for for the linking task at hand.",
            "And obviously you can do the same with distances.",
            "They would have the distance between S&T must be less or equal to a certain threshold, so that's the first problem.",
            "If you want implement that, that's obviously quadratic an it's very difficult to do that on large datasets."
        ],
        [
            "But that's not what we're going to focus on today.",
            "The second problem is what we're going to focus on, and he's basically the complexity of specifications.",
            "So basically you have two datasets and you want to create links between them.",
            "You need to find a link specification that is accurate, that is, that has a high precision and high recall, and doing this manually is usually very, very tricky.",
            "So the question that we had and the question behind our work is obviously, how can we help users where creating link specifications?"
        ],
        [
            "Now there's been some work done on that in the past.",
            "People have used both supervised and unsupervised approaches, supervised approaches.",
            "They obviously have batch learning that the idea is that you give a bunch of positive and negative examples to a classifier or train machine learning approach.",
            "Their machine learning approach learns a classifier out of the examples, and you basically use that as your function.",
            "That is busy class the Sigma.",
            "That I talked about before.",
            "The main problem here is obviously that you need a lot of links to train such a batch learner.",
            "So what many approaches do is rely on active learning, and here the idea is that you only start with a few examples and your classifier is a so-called curious classifier.",
            "So given a classifier, the classifier can actually ask questions to the user and ask the user how would you classify this particular link candidates and based on the classification you can actually update the classifier and you do that until you have a solution that.",
            "Satisfactory.",
            "Now approaches for Link discovery so far have relied on the following approach there.",
            "They have a classifier boundary which is basically this black line over there and they take the so called most informative, positive and negative examples.",
            "Those are those that are usually closes simply to the boundary and have not been classified so far.",
            "So in this case."
        ],
        [
            "Should get these points, the blue points and four examples of a link that actually links that are correct positive examples and the red ones are stand for things that are not supposed to Billings.",
            "So if you take the ones that are close to the boundary, you basically get these four points and these four points will obviously be classified by the user as being correct.",
            "So basically what you."
        ],
        [
            "Learn is something like that.",
            "If you then look at the recall that you achieve in this particular example, you actually see that your record drops while precision remains one.",
            "And."
        ],
        [
            "Our question was do we have to rely exclusively on the informativeness function that is on the distance from the boundary actually?"
        ],
        [
            "We want to be able to do is say these.",
            "This point might actually be more.",
            "I hope you can see the laser beam here that this point might actually be more informative or actually should be selected as an example and shown to the user."
        ],
        [
            "And then we learn a better classifier, where the recall actually improves with time.",
            "That was basically the intuition."
        ],
        [
            "So what we know Tist doing research on this topic is simply that the choice of the right examples is key for learning.",
            "I think that's pretty straightforward and then so far approaches.",
            "I've only relied on the informativeness functions that is on the distance to the boundary."
        ],
        [
            "So we wanted to know can we do better by using more information?"
        ],
        [
            "And the answer I'm just going to follow the tradition of giving the conclusion before the end of the talk is that yes, we can actually do that.",
            "We actually higher F measures, but obviously we're slower because we have to process more information and I'm not going to give you details on how we did it."
        ],
        [
            "Alright, so the basic insight that we had was if we use the similarity between the link candidates, we can actually figure out which link candidates should be used as example in a more accurate manner, an."
        ],
        [
            "I'm just gonna give you 2 insights that we had on how to do that.",
            "So basically how to use the similarity between the link candidates and then show the similarity function that we used and algorithms that we used to then actually exploit this similarity function.",
            "The first idea that we can use the so called intraclass similarity.",
            "So if you look at this example and you just have to choose two positive examples of this class or out of this bunch of examples you will actually see that these two are.",
            "Clustered and this one is alone.",
            "So these two are kind of representative for the same portion of space.",
            "You would want to only pick one from this group and then this B so you would cover more space and the idea is that if you do that that way you might even you might converge faster."
        ],
        [
            "The the second idea that we had was we can also use the interclass similarity, so if you assume that this Gray area is the area of the negative.",
            "So basically the things that the classifier things are negative and the white area, the things that are classified things are positive that these that should belong to the result set.",
            "We see that a is actually closer to DNC, which are negative.",
            "So basically the intraclass energy here is higher the entire classroom right here is hidden there.",
            "Then obviously if you were forced to choose only one of these examples, although they have the same distance to the boundary you aren't, you might want to choose A and not B and by using that you can actually find a classifier that can really separate these entities in more efficiently.",
            "That's a basic idea, so you have intra class similarity and interclass similarity."
        ],
        [
            "Now to be able to exploit that, we first need to define a similarity measure between link candidates, and we did it very simply.",
            "What we did is.",
            "We defined we simply use the Euclidean distance between the candidates by saying that each candidate.",
            "So basically, if you look at the similarity function, Sigma is actually made up of several atomic similarity functions.",
            "So we set that it calculate has to coordinate.",
            "Sigma one Sigma.",
            "Two Sigma N of the candidate itself accounted obviously being a pair of elements from S&T.",
            "So we basically said Sigma, one of St Sigma Travesti, Two Sigma N of St are the coordinates of the point.",
            "Then we can put actually these candidates within a space and all we need to do is measure distances, which is what is given here.",
            "That's basically Euclidean distance between two candidates and we typically take 1 / 1.",
            "Plus the distance which gives us a similarity function which is bound between zero and one.",
            "That's exactly what we wanted to have.",
            "So now we can actually measure distances between candidates, not can do that.",
            "We can actually use the Inter and intra class similarity."
        ],
        [
            "So we present it to approach used in the paper.",
            "The first approach relies on graph clustering and irrational here is that we want to reduce the intraclass similarity.",
            "So basically we want to say we only look at elements and competent with elements within this same class to pick the right positive and negative most informative, positive and negative examples.",
            "So if we assume that the set S plus and S minus are respectively the elements that are classified as being positive or negative, but classifier and for which we do not have a direct classification from the.",
            "Oracle that is from user what we do is that we simply create a similarity graph.",
            "The creation of this similarity graph simply goes by computing the similarity between the set of objects that is closer to the boundary.",
            "So basically a subset of S minus an S plus that is closest to the boundary.",
            "We compute all the similarities in here and generate a graph out of that.",
            "Then we can apply graph clustering to the graph that we've generated and what comes out of there are clusters.",
            "Now we see for each cluster.",
            "So basically is cluster gives us.",
            "A portion of space, another of each cluster.",
            "We pick the most informative example, and that's basically what we use.",
            "Then as most as positive and negative examples for the next iteration of the active learning.",
            "Um today."
        ],
        [
            "For more details on the clustering algorithm that we used, we relied on the border flow algorithm.",
            "And the idea behind the Board of Logarithm is simply to regard graph clustering as a flow problem.",
            "So if you assume that we have a certain set of nodes, we first define the so-called border flow ratio, which characterizes how many edges within the.",
            "Within the set actually belong to the set and compares that to the edges from the set to the outside of the set.",
            "So we have three types of notes here.",
            "We have so-called border notes.",
            "Those are not set up part of the set, but I have edges to the outside.",
            "We have inner nodes that part of the set, but have no edges to the outside, so the blue notes here and we have neighbor or neighboring nodes.",
            "Those are notes that are connected to border notes and to connect to compute the border flow ratio or we need to do is simply compute the sum of the edges from the border to the inside and divided by the sum of the width of the edges from the border to the outside.",
            "So in this case we will have a border for ratio of 123456 divided by three and give us a border for ratio of two and the main idea of the algorithm or behind the algorithm is simply to maximize the border flow ratio.",
            "That is, we start with each node of the graph, a seed.",
            "We run an iterative procedure that tries to maximize the border flow ratio, and once we've done so, basically what we find for each seed, a set that maximizes the border for ratio, we put all the sets equivalent together, and those are clusters."
        ],
        [
            "Alright, so how do we do that?",
            "We assume that we for each seed we basically firstly."
        ],
        [
            "At the neighbors of the seat.",
            "And we see what will happen if I were to put this neighbor with the seat together and would that improve my border flow ratio.",
            "So here we have a bottle flow ratio of zero, obviously an here if we were to add this node, which is a neighbor of X2 X and say this is my new cluster would have a board of a ratio of 2 / 4 which is half, and that is actually the same for all the other neighbors."
        ],
        [
            "So we basically say these are our candidates, so these are the candidates for augmenting or cluster.",
            "Now what we then try to do is to look at the candidates themselves and say how are they interrelated?",
            "We obviously want to only add candidates which promise to further augment the border floor issue in the future.",
            "So we only take candidates that are interrelated, that is, that have a maximal weight between them.",
            "In this case it will be these two candidates so."
        ],
        [
            "We would actually end up with these three nodes being selected for augmenting this eat eggs and we do that iteratively until we cannot improve the border floor issue anymore.",
            "And sorry if we run that, we actually get these four clusters that a cluster there there there and there, and that's basically how we terminate."
        ],
        [
            "Alright, so basically that was that was the first idea.",
            "We take the examples.",
            "So basically we take everything that's very close to the boundary.",
            "We compute the similarities, we cluster those and only take 11 example per cluster.",
            "The most informative example pro cluster, and that's actually what we showed to the user.",
            "The second idea was to actually combine into an interclass similarity and what we did there is similar in the sense of we defined a similarity matrix.",
            "The Axis Zeiser next JS cannot can be both from S plus and S minus.",
            "So basically we did not differentiate between them like we did in the clustering.",
            "And we basically said we have an activation vector and that activation vector is given to us by the informativeness function that is used anyway.",
            "So we have an activation score AI."
        ],
        [
            "What we then do is that refer spread activation across the matrix and all we need to do is basically to say the new activation is to all activation plus M + M T minus one.",
            "That is the similarity matrix times the activation vector that basically spreads the activation from the one node to all its neighbors.",
            "Then we normalize activation vector because we want to activation vector or the values in the activation vector to be one maximally or else will have an explosion obviously and the last step was basically weight decay.",
            "He added idea.",
            "The reason why I have this circle around R is that it's not the.",
            "Normal power function here what we do is we take each element of the matrix and actually raise it to the power R and we iterate this process until the activation vector actually converges.",
            "The."
        ],
        [
            "Basically shows an example of that.",
            "So what we do here is here is as plus iasis minus and these nodes both have an initial activation of 0.8, while these nodes have an activation of 0.9 and if we run this iteration thrice, if you look at this, these values is obviously 0.5 raised to the power of three, and this is basically the activations that you get at the end.",
            "So basically because these two nodes are connected, they get the high activation.",
            "And decided no such actually select for presenting to the user."
        ],
        [
            "Alright."
        ],
        [
            "Now, how did we evaluate that?",
            "There we used the Eagle algorithm, the eager at garden is an active learning algorithm that has been defined in the past was presented one or two years ago, and basically it relies on genetic programming.",
            "So what we had was an algorithm we had is actually or its informativeness function.",
            "Or we could combine it with the with the true values.",
            "This basically describes justice settings that we used and that come from the Old Eagle Paper.",
            "We used a mutation and crossover rate of 0.6 selection rate of 0.74.",
            "Basically, for merging different trees for the crossover, that's what I'm looking for, and because the algorithm is not nondeterministic, rerun each experiment five times.",
            "For each iteration, we asked 5 questions to the Oracle, and we had 10 iterations.",
            "Overall, we use two different population sizes, 2100, and we had 50 learning generations between iterations.",
            "As datasets we used to real world and three synthetic datasets and we run.",
            "We run everything on a single thread of his server."
        ],
        [
            "The first thing that we had to do was actually to find the right R for the spreading activation as well as the right number of edge counts for the graph creation for the clustering.",
            "For our recently used five different values used, the one of the datasets which WPDBLPACM and a population of 20.",
            "We run the experiments and basically took the value that maximizes the F score and that was two and we did so."
        ],
        [
            "Things similar for finding the parameters for the clustering.",
            "I'm not just not going to bore you with the details here."
        ],
        [
            "What we basically figure out and this is just a portion of the results of the results, are reported in the paper is that we can actually improve the F measure that the approach is the approach that is eagleget simply by combining it.",
            "The one result that was very interesting is that actually we were not able to really see which of both approaches is the best.",
            "It might be just because those are two instantiations of the basic principle of using intraclass and interclass similarity.",
            "But so far we're not able to say please use weight decane always work or pleasurable, and clustering we need to do more experiments in that respect to figure that out."
        ],
        [
            "OK, so.",
            "I presented the correlational learning of link specifications and we were able to show that we improve the F measures for both approaches both by using the weight decay and the clustering.",
            "The one thing that is obviously a problem here is that we have longer runtimes.",
            "That is where up to two times slower, but in real use cases the user rarely has to wait more than five seconds, which basically means that even if we use these approaches in a real setting, the user will really have to wait more than 10 seconds to be asked the next.",
            "Things.",
            "Future work we need to evaluate the whole thing or more datasets to actually figure out what in on rich datasets we can use with detail on which data sets we can use.",
            "The clustering based approach.",
            "And obviously we are actually independent of the cluster algorithm that is used or Windsor clusters.",
            "So we are going to combine their approach or actually try out different clustering algorithms to figure out which one works best with the different datasets that we have."
        ],
        [
            "Thank you very much for listing and please ask her.",
            "Let me let me start by checking that I understood what you did, yeah?",
            "Previously you presented lines, which is a tool for finding out which resources in different datasets represent the same real world things, right?",
            "No lines is a link discovery tool, which basically means that it can learn all kinds of predicates.",
            "So you can link resources from two different datasets with all kinds of predicates.",
            "You just have to learn the right specification for that purpose, and Eagle is the tool that learns specifications to Eagle is actually an algorithm, and it is integrated in lives.",
            "So Alliance is a framework and contains different algorithms, and Eagle is one of them.",
            "And what you did in this tool, yes, was to find a way to select the best examples to ask the user from the active learning algorithm exactly.",
            "OK, if you switch to slide number 9."
        ],
        [
            "The sigmas here and the first bullet point, yeah, where do they come from?",
            "Are they the same for all link specifications?",
            "Well, this is the basic idea.",
            "You want to learn, just give me a sick."
        ],
        [
            "I'll be there if I can that so you never described feature vectors, so that's just, yeah, actually.",
            "I mean, this would be the first step to go to Slide 9 to describe this part.",
            "Actually describe the feature vectors by saying that each of these specifications can be complex and compound consist of different, basically of smaller atomic similarity functions.",
            "So for example, if you."
        ],
        [
            "Look at this example.",
            "You have different similarity functions here, like the trigram similarity 11 Stein and leverage trying again that compare different predicates.",
            "Now you combine them into one big one big similarity function.",
            "The sigmas are these atomic similarity functions, the Sigma one Sigma, two Sigma three.",
            "Now you use exactly these values to place your examples, that is, the St pairs into a vector space and there you can measure the distance.",
            "What confuses me is yes.",
            "The sickness presumably are specific to each link specification.",
            "Well, each member of the population in your genetic population, right?",
            "Or are they independent?",
            "Are they always the same?",
            "There are where do they come from?",
            "I get what you mean.",
            "So basically you learn a link specification.",
            "And you have.",
            "If you're using genetic programming, you obviously have different links specifications that I suppose what you mean yes, but there you have any informativeness function that basically tells you what the distances from the boundary, and you can still buy taking for for at one of the specifications.",
            "So basically our best candidate so far.",
            "You can still figure out what you still have sickness and those sigmas are the ones that you use.",
            "OK, I'll try asking the question a different way if you if you go to slide #9 again, yes the let me see.",
            "The."
        ],
        [
            "That one yeah, the the.",
            "The SIM function.",
            "Yes, it's the same function always the same.",
            "Or is it?",
            "Is there a different SIM function for each member of your population?",
            "Technically there is, but you only take the best member of the population and use his SIM function.",
            "I see OK, thank you sure.",
            "Some other question.",
            "Otherwise, I would have a couple of comments please.",
            "So OK, you were using active learning, so your approach as I would understand, is one way how you could sample examples for active learning.",
            "Yes, this is this.",
            "Through clustering it's actually a little bit complicated to be honest compared to the old fashion.",
            "Active learning from 90s, so I would expect let's say to use some of these traditional active learning expectation maximization uncertainly and so on.",
            "So couple of these traditional techniques as a baseline so to evaluate really whether this works well or not because you have some schema, which is OK. Good work actually works, obviously it's just.",
            "It's hard to say.",
            "Whether it's contribution or not compared to, let's say, uncertainty sampling is something which people used to use like 15 years ago.",
            "So do you have any feeling how this old fashion active learning could be compared with what most what most people do is basically that define some form of an informativeness function.",
            "They basically say you have you have for example a boundary and you basically said the distance to the boundary is the informativeness.",
            "If you're using genetic programming, you said the entropy is that your informativeness function actually approach that we developed is independent of that.",
            "We just assumed that we have one and we used one that has been used in the past.",
            "And shown, at least in link discovery to prop to produce good results.",
            "And that's the one that is implemented in the Eagle algorithm.",
            "So basically respect to the state of the art we were able to show that we do make, we do produce better results, and we actually compared it as well with other functions.",
            "People have used the entropy function.",
            "People have used MCC, and we've also compare that with those values and we were able to show.",
            "I mean, it's not mentioned in the paper, but we know that we get better results indeed as well.",
            "OK yeah, this feature vector is.",
            "I mean now I understood that there were features in this picture on slide five I think Slide 5.",
            "This would be better to show it a little bit more expensive.",
            "This is."
        ],
        [
            "Start to read even from the first line.",
            "OK, sure.",
            "OK, any other comments questions?",
            "One thing I didn't see in your evaluation at the end was."
        ],
        [
            "Yeah there.",
            "How many questions did you have to ask the user?",
            "We actually run 10 iterations, which basically means that for all algorithms, independently of whether they said they were done or not, we run 10 iterations.",
            "That was actually stated."
        ],
        [
            "In the slide before that will run 10 iterations overall, so 100 questions to the users exactly."
        ],
        [
            "OK, but another thing I don't understand is that you're doing linking, right?",
            "Yes, an if you.",
            "But you only have one data set, no, we have two.",
            "So basic app stand for ABT by and DBL P stands for DBA.",
            "PCM is all mentioned in the paper.",
            "Person one and person two as well as restaurants are God.",
            "Benchmark datasets Goldstone, Albita Gold standard data provided by the ontology Alignment and Evaluation Initiative.",
            "So what is the runtime on Sadie BLP then?",
            "I can show it to you here with a second."
        ],
        [
            "And so.",
            "If you run 100 questions here, you have a runtime of 500, like 800 seconds to basically means that the user has to wait 8 seconds between the different questions.",
            "Yes, you you.",
            "Not counting the users the time the user spent.",
            "It's just there.",
            "Oh yeah, we just got to run over on time that we need there.",
            "Well, a lot of questions, yes sure, can you go back to the slide about show clustering algorithm?",
            "Border flow yes sure.",
            "Yeah, basically you are."
        ],
        [
            "Train to find cluster of the most representative example in your data sets basis algorithm.",
            "Well what we do is we look at the examples that are closest to the boundary and that have not been classified yet.",
            "So we take that.",
            "We take an examples.",
            "I can't remember the exact number that are closest to the boundary and then we compute the similarity between them.",
            "You create the graph similarity.",
            "Basically symmetric graph and based on that that is the craftable cluster.",
            "So if you try to compare your algorithm but the flow is.",
            "So the clustering algorithm based on similarity.",
            "We've implemented all these are."
        ],
        [
            "Gardens in the Cougar framework and we are currently running the experiments, so that's basically what I mentioned here that we want to measure the effect of the combination of CL, reorder graph clustering approaches such as affinity propagation, Markov clustering and so on.",
            "OK, another question is your classifier is eagle as you try and basically simple classifier as most common classifiers SVM or less or or elastic net or other most common algorithm in machine learning world.",
            "Yes, we have actually presented in.",
            "I think that was two years ago, the riven algorithm that relies on linear and Boolean classifiers, and obviously it is very clear that we're going to try to combine linear classifiers SVM under like with this approach.",
            "And also if you look at the paper from last year, we've also done some work on using SVM's falling discovery.",
            "OK, thanks sure.",
            "Thanks, thank you very much."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "For those who don't know me, my name is Axel.",
                    "label": 0
                },
                {
                    "sent": "I'm from the University of Leipzig in Germany.",
                    "label": 0
                },
                {
                    "sent": "And what I'm going to talk about.",
                    "label": 0
                },
                {
                    "sent": "OK, that you work the 2nd and it didn't work then.",
                    "label": 0
                },
                {
                    "sent": "Well, I'm going to talk about is the correlation our active learning of link specifications.",
                    "label": 1
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The question.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Oscar cells object list.",
                    "label": 0
                },
                {
                    "sent": "What do we need links for?",
                    "label": 0
                },
                {
                    "sent": "And as I said, they are central for implementing.",
                    "label": 1
                },
                {
                    "sent": "Basically the link data web.",
                    "label": 1
                },
                {
                    "sent": "This actually does work because most of the leader with applications, the large scale once obviously rely on links.",
                    "label": 0
                },
                {
                    "sent": "Now if you look at the current apology after linked open Data Cloud, we basically see that we have plenty of triples and not that many links less than 2% of the triples are links on top of it.",
                    "label": 0
                },
                {
                    "sent": "We only have you mostly have a certain type of links that are.",
                    "label": 0
                },
                {
                    "sent": "There are same as links.",
                    "label": 0
                },
                {
                    "sent": "So we can now ask ourselves why?",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Why is it difficult to create links and technically?",
                    "label": 1
                },
                {
                    "sent": "Most link discovery systems rely on an approach that goes as follows that try to approximate the set M of pairs from the Cartesian product of a set of source instances and target instances that are related via relation R by computing a similarity function, a complex similarity function on the threshold.",
                    "label": 0
                },
                {
                    "sent": "And they basically say if I have approximate M with M prime by saying that if Sigma Fest EST belonging to S * T is larger than equal to Terra, then St is a so called link candidate for for the linking task at hand.",
                    "label": 0
                },
                {
                    "sent": "And obviously you can do the same with distances.",
                    "label": 0
                },
                {
                    "sent": "They would have the distance between S&T must be less or equal to a certain threshold, so that's the first problem.",
                    "label": 0
                },
                {
                    "sent": "If you want implement that, that's obviously quadratic an it's very difficult to do that on large datasets.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "But that's not what we're going to focus on today.",
                    "label": 0
                },
                {
                    "sent": "The second problem is what we're going to focus on, and he's basically the complexity of specifications.",
                    "label": 1
                },
                {
                    "sent": "So basically you have two datasets and you want to create links between them.",
                    "label": 0
                },
                {
                    "sent": "You need to find a link specification that is accurate, that is, that has a high precision and high recall, and doing this manually is usually very, very tricky.",
                    "label": 0
                },
                {
                    "sent": "So the question that we had and the question behind our work is obviously, how can we help users where creating link specifications?",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now there's been some work done on that in the past.",
                    "label": 0
                },
                {
                    "sent": "People have used both supervised and unsupervised approaches, supervised approaches.",
                    "label": 0
                },
                {
                    "sent": "They obviously have batch learning that the idea is that you give a bunch of positive and negative examples to a classifier or train machine learning approach.",
                    "label": 0
                },
                {
                    "sent": "Their machine learning approach learns a classifier out of the examples, and you basically use that as your function.",
                    "label": 0
                },
                {
                    "sent": "That is busy class the Sigma.",
                    "label": 0
                },
                {
                    "sent": "That I talked about before.",
                    "label": 0
                },
                {
                    "sent": "The main problem here is obviously that you need a lot of links to train such a batch learner.",
                    "label": 0
                },
                {
                    "sent": "So what many approaches do is rely on active learning, and here the idea is that you only start with a few examples and your classifier is a so-called curious classifier.",
                    "label": 0
                },
                {
                    "sent": "So given a classifier, the classifier can actually ask questions to the user and ask the user how would you classify this particular link candidates and based on the classification you can actually update the classifier and you do that until you have a solution that.",
                    "label": 0
                },
                {
                    "sent": "Satisfactory.",
                    "label": 0
                },
                {
                    "sent": "Now approaches for Link discovery so far have relied on the following approach there.",
                    "label": 0
                },
                {
                    "sent": "They have a classifier boundary which is basically this black line over there and they take the so called most informative, positive and negative examples.",
                    "label": 0
                },
                {
                    "sent": "Those are those that are usually closes simply to the boundary and have not been classified so far.",
                    "label": 0
                },
                {
                    "sent": "So in this case.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Should get these points, the blue points and four examples of a link that actually links that are correct positive examples and the red ones are stand for things that are not supposed to Billings.",
                    "label": 0
                },
                {
                    "sent": "So if you take the ones that are close to the boundary, you basically get these four points and these four points will obviously be classified by the user as being correct.",
                    "label": 0
                },
                {
                    "sent": "So basically what you.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Learn is something like that.",
                    "label": 0
                },
                {
                    "sent": "If you then look at the recall that you achieve in this particular example, you actually see that your record drops while precision remains one.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Our question was do we have to rely exclusively on the informativeness function that is on the distance from the boundary actually?",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We want to be able to do is say these.",
                    "label": 0
                },
                {
                    "sent": "This point might actually be more.",
                    "label": 0
                },
                {
                    "sent": "I hope you can see the laser beam here that this point might actually be more informative or actually should be selected as an example and shown to the user.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then we learn a better classifier, where the recall actually improves with time.",
                    "label": 0
                },
                {
                    "sent": "That was basically the intuition.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So what we know Tist doing research on this topic is simply that the choice of the right examples is key for learning.",
                    "label": 1
                },
                {
                    "sent": "I think that's pretty straightforward and then so far approaches.",
                    "label": 0
                },
                {
                    "sent": "I've only relied on the informativeness functions that is on the distance to the boundary.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we wanted to know can we do better by using more information?",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And the answer I'm just going to follow the tradition of giving the conclusion before the end of the talk is that yes, we can actually do that.",
                    "label": 0
                },
                {
                    "sent": "We actually higher F measures, but obviously we're slower because we have to process more information and I'm not going to give you details on how we did it.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Alright, so the basic insight that we had was if we use the similarity between the link candidates, we can actually figure out which link candidates should be used as example in a more accurate manner, an.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I'm just gonna give you 2 insights that we had on how to do that.",
                    "label": 0
                },
                {
                    "sent": "So basically how to use the similarity between the link candidates and then show the similarity function that we used and algorithms that we used to then actually exploit this similarity function.",
                    "label": 0
                },
                {
                    "sent": "The first idea that we can use the so called intraclass similarity.",
                    "label": 0
                },
                {
                    "sent": "So if you look at this example and you just have to choose two positive examples of this class or out of this bunch of examples you will actually see that these two are.",
                    "label": 0
                },
                {
                    "sent": "Clustered and this one is alone.",
                    "label": 0
                },
                {
                    "sent": "So these two are kind of representative for the same portion of space.",
                    "label": 0
                },
                {
                    "sent": "You would want to only pick one from this group and then this B so you would cover more space and the idea is that if you do that that way you might even you might converge faster.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The the second idea that we had was we can also use the interclass similarity, so if you assume that this Gray area is the area of the negative.",
                    "label": 0
                },
                {
                    "sent": "So basically the things that the classifier things are negative and the white area, the things that are classified things are positive that these that should belong to the result set.",
                    "label": 0
                },
                {
                    "sent": "We see that a is actually closer to DNC, which are negative.",
                    "label": 0
                },
                {
                    "sent": "So basically the intraclass energy here is higher the entire classroom right here is hidden there.",
                    "label": 0
                },
                {
                    "sent": "Then obviously if you were forced to choose only one of these examples, although they have the same distance to the boundary you aren't, you might want to choose A and not B and by using that you can actually find a classifier that can really separate these entities in more efficiently.",
                    "label": 0
                },
                {
                    "sent": "That's a basic idea, so you have intra class similarity and interclass similarity.",
                    "label": 1
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now to be able to exploit that, we first need to define a similarity measure between link candidates, and we did it very simply.",
                    "label": 0
                },
                {
                    "sent": "What we did is.",
                    "label": 0
                },
                {
                    "sent": "We defined we simply use the Euclidean distance between the candidates by saying that each candidate.",
                    "label": 0
                },
                {
                    "sent": "So basically, if you look at the similarity function, Sigma is actually made up of several atomic similarity functions.",
                    "label": 0
                },
                {
                    "sent": "So we set that it calculate has to coordinate.",
                    "label": 0
                },
                {
                    "sent": "Sigma one Sigma.",
                    "label": 0
                },
                {
                    "sent": "Two Sigma N of the candidate itself accounted obviously being a pair of elements from S&T.",
                    "label": 0
                },
                {
                    "sent": "So we basically said Sigma, one of St Sigma Travesti, Two Sigma N of St are the coordinates of the point.",
                    "label": 0
                },
                {
                    "sent": "Then we can put actually these candidates within a space and all we need to do is measure distances, which is what is given here.",
                    "label": 0
                },
                {
                    "sent": "That's basically Euclidean distance between two candidates and we typically take 1 / 1.",
                    "label": 0
                },
                {
                    "sent": "Plus the distance which gives us a similarity function which is bound between zero and one.",
                    "label": 0
                },
                {
                    "sent": "That's exactly what we wanted to have.",
                    "label": 0
                },
                {
                    "sent": "So now we can actually measure distances between candidates, not can do that.",
                    "label": 0
                },
                {
                    "sent": "We can actually use the Inter and intra class similarity.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we present it to approach used in the paper.",
                    "label": 0
                },
                {
                    "sent": "The first approach relies on graph clustering and irrational here is that we want to reduce the intraclass similarity.",
                    "label": 1
                },
                {
                    "sent": "So basically we want to say we only look at elements and competent with elements within this same class to pick the right positive and negative most informative, positive and negative examples.",
                    "label": 0
                },
                {
                    "sent": "So if we assume that the set S plus and S minus are respectively the elements that are classified as being positive or negative, but classifier and for which we do not have a direct classification from the.",
                    "label": 0
                },
                {
                    "sent": "Oracle that is from user what we do is that we simply create a similarity graph.",
                    "label": 0
                },
                {
                    "sent": "The creation of this similarity graph simply goes by computing the similarity between the set of objects that is closer to the boundary.",
                    "label": 1
                },
                {
                    "sent": "So basically a subset of S minus an S plus that is closest to the boundary.",
                    "label": 0
                },
                {
                    "sent": "We compute all the similarities in here and generate a graph out of that.",
                    "label": 0
                },
                {
                    "sent": "Then we can apply graph clustering to the graph that we've generated and what comes out of there are clusters.",
                    "label": 0
                },
                {
                    "sent": "Now we see for each cluster.",
                    "label": 0
                },
                {
                    "sent": "So basically is cluster gives us.",
                    "label": 0
                },
                {
                    "sent": "A portion of space, another of each cluster.",
                    "label": 1
                },
                {
                    "sent": "We pick the most informative example, and that's basically what we use.",
                    "label": 0
                },
                {
                    "sent": "Then as most as positive and negative examples for the next iteration of the active learning.",
                    "label": 0
                },
                {
                    "sent": "Um today.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For more details on the clustering algorithm that we used, we relied on the border flow algorithm.",
                    "label": 0
                },
                {
                    "sent": "And the idea behind the Board of Logarithm is simply to regard graph clustering as a flow problem.",
                    "label": 0
                },
                {
                    "sent": "So if you assume that we have a certain set of nodes, we first define the so-called border flow ratio, which characterizes how many edges within the.",
                    "label": 0
                },
                {
                    "sent": "Within the set actually belong to the set and compares that to the edges from the set to the outside of the set.",
                    "label": 0
                },
                {
                    "sent": "So we have three types of notes here.",
                    "label": 0
                },
                {
                    "sent": "We have so-called border notes.",
                    "label": 0
                },
                {
                    "sent": "Those are not set up part of the set, but I have edges to the outside.",
                    "label": 0
                },
                {
                    "sent": "We have inner nodes that part of the set, but have no edges to the outside, so the blue notes here and we have neighbor or neighboring nodes.",
                    "label": 0
                },
                {
                    "sent": "Those are notes that are connected to border notes and to connect to compute the border flow ratio or we need to do is simply compute the sum of the edges from the border to the inside and divided by the sum of the width of the edges from the border to the outside.",
                    "label": 0
                },
                {
                    "sent": "So in this case we will have a border for ratio of 123456 divided by three and give us a border for ratio of two and the main idea of the algorithm or behind the algorithm is simply to maximize the border flow ratio.",
                    "label": 0
                },
                {
                    "sent": "That is, we start with each node of the graph, a seed.",
                    "label": 0
                },
                {
                    "sent": "We run an iterative procedure that tries to maximize the border flow ratio, and once we've done so, basically what we find for each seed, a set that maximizes the border for ratio, we put all the sets equivalent together, and those are clusters.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Alright, so how do we do that?",
                    "label": 0
                },
                {
                    "sent": "We assume that we for each seed we basically firstly.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "At the neighbors of the seat.",
                    "label": 0
                },
                {
                    "sent": "And we see what will happen if I were to put this neighbor with the seat together and would that improve my border flow ratio.",
                    "label": 0
                },
                {
                    "sent": "So here we have a bottle flow ratio of zero, obviously an here if we were to add this node, which is a neighbor of X2 X and say this is my new cluster would have a board of a ratio of 2 / 4 which is half, and that is actually the same for all the other neighbors.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we basically say these are our candidates, so these are the candidates for augmenting or cluster.",
                    "label": 0
                },
                {
                    "sent": "Now what we then try to do is to look at the candidates themselves and say how are they interrelated?",
                    "label": 0
                },
                {
                    "sent": "We obviously want to only add candidates which promise to further augment the border floor issue in the future.",
                    "label": 0
                },
                {
                    "sent": "So we only take candidates that are interrelated, that is, that have a maximal weight between them.",
                    "label": 0
                },
                {
                    "sent": "In this case it will be these two candidates so.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We would actually end up with these three nodes being selected for augmenting this eat eggs and we do that iteratively until we cannot improve the border floor issue anymore.",
                    "label": 0
                },
                {
                    "sent": "And sorry if we run that, we actually get these four clusters that a cluster there there there and there, and that's basically how we terminate.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Alright, so basically that was that was the first idea.",
                    "label": 0
                },
                {
                    "sent": "We take the examples.",
                    "label": 0
                },
                {
                    "sent": "So basically we take everything that's very close to the boundary.",
                    "label": 0
                },
                {
                    "sent": "We compute the similarities, we cluster those and only take 11 example per cluster.",
                    "label": 0
                },
                {
                    "sent": "The most informative example pro cluster, and that's actually what we showed to the user.",
                    "label": 0
                },
                {
                    "sent": "The second idea was to actually combine into an interclass similarity and what we did there is similar in the sense of we defined a similarity matrix.",
                    "label": 0
                },
                {
                    "sent": "The Axis Zeiser next JS cannot can be both from S plus and S minus.",
                    "label": 0
                },
                {
                    "sent": "So basically we did not differentiate between them like we did in the clustering.",
                    "label": 0
                },
                {
                    "sent": "And we basically said we have an activation vector and that activation vector is given to us by the informativeness function that is used anyway.",
                    "label": 0
                },
                {
                    "sent": "So we have an activation score AI.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "What we then do is that refer spread activation across the matrix and all we need to do is basically to say the new activation is to all activation plus M + M T minus one.",
                    "label": 0
                },
                {
                    "sent": "That is the similarity matrix times the activation vector that basically spreads the activation from the one node to all its neighbors.",
                    "label": 0
                },
                {
                    "sent": "Then we normalize activation vector because we want to activation vector or the values in the activation vector to be one maximally or else will have an explosion obviously and the last step was basically weight decay.",
                    "label": 0
                },
                {
                    "sent": "He added idea.",
                    "label": 0
                },
                {
                    "sent": "The reason why I have this circle around R is that it's not the.",
                    "label": 0
                },
                {
                    "sent": "Normal power function here what we do is we take each element of the matrix and actually raise it to the power R and we iterate this process until the activation vector actually converges.",
                    "label": 0
                },
                {
                    "sent": "The.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Basically shows an example of that.",
                    "label": 0
                },
                {
                    "sent": "So what we do here is here is as plus iasis minus and these nodes both have an initial activation of 0.8, while these nodes have an activation of 0.9 and if we run this iteration thrice, if you look at this, these values is obviously 0.5 raised to the power of three, and this is basically the activations that you get at the end.",
                    "label": 0
                },
                {
                    "sent": "So basically because these two nodes are connected, they get the high activation.",
                    "label": 0
                },
                {
                    "sent": "And decided no such actually select for presenting to the user.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Alright.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now, how did we evaluate that?",
                    "label": 0
                },
                {
                    "sent": "There we used the Eagle algorithm, the eager at garden is an active learning algorithm that has been defined in the past was presented one or two years ago, and basically it relies on genetic programming.",
                    "label": 0
                },
                {
                    "sent": "So what we had was an algorithm we had is actually or its informativeness function.",
                    "label": 0
                },
                {
                    "sent": "Or we could combine it with the with the true values.",
                    "label": 0
                },
                {
                    "sent": "This basically describes justice settings that we used and that come from the Old Eagle Paper.",
                    "label": 0
                },
                {
                    "sent": "We used a mutation and crossover rate of 0.6 selection rate of 0.74.",
                    "label": 1
                },
                {
                    "sent": "Basically, for merging different trees for the crossover, that's what I'm looking for, and because the algorithm is not nondeterministic, rerun each experiment five times.",
                    "label": 0
                },
                {
                    "sent": "For each iteration, we asked 5 questions to the Oracle, and we had 10 iterations.",
                    "label": 1
                },
                {
                    "sent": "Overall, we use two different population sizes, 2100, and we had 50 learning generations between iterations.",
                    "label": 1
                },
                {
                    "sent": "As datasets we used to real world and three synthetic datasets and we run.",
                    "label": 0
                },
                {
                    "sent": "We run everything on a single thread of his server.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The first thing that we had to do was actually to find the right R for the spreading activation as well as the right number of edge counts for the graph creation for the clustering.",
                    "label": 0
                },
                {
                    "sent": "For our recently used five different values used, the one of the datasets which WPDBLPACM and a population of 20.",
                    "label": 0
                },
                {
                    "sent": "We run the experiments and basically took the value that maximizes the F score and that was two and we did so.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Things similar for finding the parameters for the clustering.",
                    "label": 0
                },
                {
                    "sent": "I'm not just not going to bore you with the details here.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "What we basically figure out and this is just a portion of the results of the results, are reported in the paper is that we can actually improve the F measure that the approach is the approach that is eagleget simply by combining it.",
                    "label": 0
                },
                {
                    "sent": "The one result that was very interesting is that actually we were not able to really see which of both approaches is the best.",
                    "label": 0
                },
                {
                    "sent": "It might be just because those are two instantiations of the basic principle of using intraclass and interclass similarity.",
                    "label": 0
                },
                {
                    "sent": "But so far we're not able to say please use weight decane always work or pleasurable, and clustering we need to do more experiments in that respect to figure that out.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_35": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "I presented the correlational learning of link specifications and we were able to show that we improve the F measures for both approaches both by using the weight decay and the clustering.",
                    "label": 1
                },
                {
                    "sent": "The one thing that is obviously a problem here is that we have longer runtimes.",
                    "label": 0
                },
                {
                    "sent": "That is where up to two times slower, but in real use cases the user rarely has to wait more than five seconds, which basically means that even if we use these approaches in a real setting, the user will really have to wait more than 10 seconds to be asked the next.",
                    "label": 0
                },
                {
                    "sent": "Things.",
                    "label": 0
                },
                {
                    "sent": "Future work we need to evaluate the whole thing or more datasets to actually figure out what in on rich datasets we can use with detail on which data sets we can use.",
                    "label": 0
                },
                {
                    "sent": "The clustering based approach.",
                    "label": 0
                },
                {
                    "sent": "And obviously we are actually independent of the cluster algorithm that is used or Windsor clusters.",
                    "label": 0
                },
                {
                    "sent": "So we are going to combine their approach or actually try out different clustering algorithms to figure out which one works best with the different datasets that we have.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Thank you very much for listing and please ask her.",
                    "label": 1
                },
                {
                    "sent": "Let me let me start by checking that I understood what you did, yeah?",
                    "label": 0
                },
                {
                    "sent": "Previously you presented lines, which is a tool for finding out which resources in different datasets represent the same real world things, right?",
                    "label": 0
                },
                {
                    "sent": "No lines is a link discovery tool, which basically means that it can learn all kinds of predicates.",
                    "label": 0
                },
                {
                    "sent": "So you can link resources from two different datasets with all kinds of predicates.",
                    "label": 0
                },
                {
                    "sent": "You just have to learn the right specification for that purpose, and Eagle is the tool that learns specifications to Eagle is actually an algorithm, and it is integrated in lives.",
                    "label": 0
                },
                {
                    "sent": "So Alliance is a framework and contains different algorithms, and Eagle is one of them.",
                    "label": 0
                },
                {
                    "sent": "And what you did in this tool, yes, was to find a way to select the best examples to ask the user from the active learning algorithm exactly.",
                    "label": 0
                },
                {
                    "sent": "OK, if you switch to slide number 9.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The sigmas here and the first bullet point, yeah, where do they come from?",
                    "label": 0
                },
                {
                    "sent": "Are they the same for all link specifications?",
                    "label": 0
                },
                {
                    "sent": "Well, this is the basic idea.",
                    "label": 0
                },
                {
                    "sent": "You want to learn, just give me a sick.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I'll be there if I can that so you never described feature vectors, so that's just, yeah, actually.",
                    "label": 0
                },
                {
                    "sent": "I mean, this would be the first step to go to Slide 9 to describe this part.",
                    "label": 0
                },
                {
                    "sent": "Actually describe the feature vectors by saying that each of these specifications can be complex and compound consist of different, basically of smaller atomic similarity functions.",
                    "label": 0
                },
                {
                    "sent": "So for example, if you.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Look at this example.",
                    "label": 0
                },
                {
                    "sent": "You have different similarity functions here, like the trigram similarity 11 Stein and leverage trying again that compare different predicates.",
                    "label": 0
                },
                {
                    "sent": "Now you combine them into one big one big similarity function.",
                    "label": 0
                },
                {
                    "sent": "The sigmas are these atomic similarity functions, the Sigma one Sigma, two Sigma three.",
                    "label": 0
                },
                {
                    "sent": "Now you use exactly these values to place your examples, that is, the St pairs into a vector space and there you can measure the distance.",
                    "label": 0
                },
                {
                    "sent": "What confuses me is yes.",
                    "label": 0
                },
                {
                    "sent": "The sickness presumably are specific to each link specification.",
                    "label": 0
                },
                {
                    "sent": "Well, each member of the population in your genetic population, right?",
                    "label": 0
                },
                {
                    "sent": "Or are they independent?",
                    "label": 0
                },
                {
                    "sent": "Are they always the same?",
                    "label": 0
                },
                {
                    "sent": "There are where do they come from?",
                    "label": 0
                },
                {
                    "sent": "I get what you mean.",
                    "label": 0
                },
                {
                    "sent": "So basically you learn a link specification.",
                    "label": 0
                },
                {
                    "sent": "And you have.",
                    "label": 0
                },
                {
                    "sent": "If you're using genetic programming, you obviously have different links specifications that I suppose what you mean yes, but there you have any informativeness function that basically tells you what the distances from the boundary, and you can still buy taking for for at one of the specifications.",
                    "label": 0
                },
                {
                    "sent": "So basically our best candidate so far.",
                    "label": 0
                },
                {
                    "sent": "You can still figure out what you still have sickness and those sigmas are the ones that you use.",
                    "label": 0
                },
                {
                    "sent": "OK, I'll try asking the question a different way if you if you go to slide #9 again, yes the let me see.",
                    "label": 0
                },
                {
                    "sent": "The.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That one yeah, the the.",
                    "label": 0
                },
                {
                    "sent": "The SIM function.",
                    "label": 0
                },
                {
                    "sent": "Yes, it's the same function always the same.",
                    "label": 0
                },
                {
                    "sent": "Or is it?",
                    "label": 0
                },
                {
                    "sent": "Is there a different SIM function for each member of your population?",
                    "label": 0
                },
                {
                    "sent": "Technically there is, but you only take the best member of the population and use his SIM function.",
                    "label": 0
                },
                {
                    "sent": "I see OK, thank you sure.",
                    "label": 0
                },
                {
                    "sent": "Some other question.",
                    "label": 0
                },
                {
                    "sent": "Otherwise, I would have a couple of comments please.",
                    "label": 0
                },
                {
                    "sent": "So OK, you were using active learning, so your approach as I would understand, is one way how you could sample examples for active learning.",
                    "label": 0
                },
                {
                    "sent": "Yes, this is this.",
                    "label": 0
                },
                {
                    "sent": "Through clustering it's actually a little bit complicated to be honest compared to the old fashion.",
                    "label": 0
                },
                {
                    "sent": "Active learning from 90s, so I would expect let's say to use some of these traditional active learning expectation maximization uncertainly and so on.",
                    "label": 0
                },
                {
                    "sent": "So couple of these traditional techniques as a baseline so to evaluate really whether this works well or not because you have some schema, which is OK. Good work actually works, obviously it's just.",
                    "label": 0
                },
                {
                    "sent": "It's hard to say.",
                    "label": 0
                },
                {
                    "sent": "Whether it's contribution or not compared to, let's say, uncertainty sampling is something which people used to use like 15 years ago.",
                    "label": 0
                },
                {
                    "sent": "So do you have any feeling how this old fashion active learning could be compared with what most what most people do is basically that define some form of an informativeness function.",
                    "label": 0
                },
                {
                    "sent": "They basically say you have you have for example a boundary and you basically said the distance to the boundary is the informativeness.",
                    "label": 0
                },
                {
                    "sent": "If you're using genetic programming, you said the entropy is that your informativeness function actually approach that we developed is independent of that.",
                    "label": 0
                },
                {
                    "sent": "We just assumed that we have one and we used one that has been used in the past.",
                    "label": 0
                },
                {
                    "sent": "And shown, at least in link discovery to prop to produce good results.",
                    "label": 0
                },
                {
                    "sent": "And that's the one that is implemented in the Eagle algorithm.",
                    "label": 0
                },
                {
                    "sent": "So basically respect to the state of the art we were able to show that we do make, we do produce better results, and we actually compared it as well with other functions.",
                    "label": 0
                },
                {
                    "sent": "People have used the entropy function.",
                    "label": 0
                },
                {
                    "sent": "People have used MCC, and we've also compare that with those values and we were able to show.",
                    "label": 0
                },
                {
                    "sent": "I mean, it's not mentioned in the paper, but we know that we get better results indeed as well.",
                    "label": 0
                },
                {
                    "sent": "OK yeah, this feature vector is.",
                    "label": 0
                },
                {
                    "sent": "I mean now I understood that there were features in this picture on slide five I think Slide 5.",
                    "label": 0
                },
                {
                    "sent": "This would be better to show it a little bit more expensive.",
                    "label": 0
                },
                {
                    "sent": "This is.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Start to read even from the first line.",
                    "label": 0
                },
                {
                    "sent": "OK, sure.",
                    "label": 0
                },
                {
                    "sent": "OK, any other comments questions?",
                    "label": 0
                },
                {
                    "sent": "One thing I didn't see in your evaluation at the end was.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Yeah there.",
                    "label": 0
                },
                {
                    "sent": "How many questions did you have to ask the user?",
                    "label": 0
                },
                {
                    "sent": "We actually run 10 iterations, which basically means that for all algorithms, independently of whether they said they were done or not, we run 10 iterations.",
                    "label": 0
                },
                {
                    "sent": "That was actually stated.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In the slide before that will run 10 iterations overall, so 100 questions to the users exactly.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, but another thing I don't understand is that you're doing linking, right?",
                    "label": 0
                },
                {
                    "sent": "Yes, an if you.",
                    "label": 0
                },
                {
                    "sent": "But you only have one data set, no, we have two.",
                    "label": 0
                },
                {
                    "sent": "So basic app stand for ABT by and DBL P stands for DBA.",
                    "label": 0
                },
                {
                    "sent": "PCM is all mentioned in the paper.",
                    "label": 0
                },
                {
                    "sent": "Person one and person two as well as restaurants are God.",
                    "label": 0
                },
                {
                    "sent": "Benchmark datasets Goldstone, Albita Gold standard data provided by the ontology Alignment and Evaluation Initiative.",
                    "label": 0
                },
                {
                    "sent": "So what is the runtime on Sadie BLP then?",
                    "label": 0
                },
                {
                    "sent": "I can show it to you here with a second.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And so.",
                    "label": 0
                },
                {
                    "sent": "If you run 100 questions here, you have a runtime of 500, like 800 seconds to basically means that the user has to wait 8 seconds between the different questions.",
                    "label": 0
                },
                {
                    "sent": "Yes, you you.",
                    "label": 0
                },
                {
                    "sent": "Not counting the users the time the user spent.",
                    "label": 0
                },
                {
                    "sent": "It's just there.",
                    "label": 0
                },
                {
                    "sent": "Oh yeah, we just got to run over on time that we need there.",
                    "label": 0
                },
                {
                    "sent": "Well, a lot of questions, yes sure, can you go back to the slide about show clustering algorithm?",
                    "label": 0
                },
                {
                    "sent": "Border flow yes sure.",
                    "label": 0
                },
                {
                    "sent": "Yeah, basically you are.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Train to find cluster of the most representative example in your data sets basis algorithm.",
                    "label": 0
                },
                {
                    "sent": "Well what we do is we look at the examples that are closest to the boundary and that have not been classified yet.",
                    "label": 0
                },
                {
                    "sent": "So we take that.",
                    "label": 0
                },
                {
                    "sent": "We take an examples.",
                    "label": 0
                },
                {
                    "sent": "I can't remember the exact number that are closest to the boundary and then we compute the similarity between them.",
                    "label": 0
                },
                {
                    "sent": "You create the graph similarity.",
                    "label": 0
                },
                {
                    "sent": "Basically symmetric graph and based on that that is the craftable cluster.",
                    "label": 0
                },
                {
                    "sent": "So if you try to compare your algorithm but the flow is.",
                    "label": 0
                },
                {
                    "sent": "So the clustering algorithm based on similarity.",
                    "label": 0
                },
                {
                    "sent": "We've implemented all these are.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Gardens in the Cougar framework and we are currently running the experiments, so that's basically what I mentioned here that we want to measure the effect of the combination of CL, reorder graph clustering approaches such as affinity propagation, Markov clustering and so on.",
                    "label": 1
                },
                {
                    "sent": "OK, another question is your classifier is eagle as you try and basically simple classifier as most common classifiers SVM or less or or elastic net or other most common algorithm in machine learning world.",
                    "label": 0
                },
                {
                    "sent": "Yes, we have actually presented in.",
                    "label": 0
                },
                {
                    "sent": "I think that was two years ago, the riven algorithm that relies on linear and Boolean classifiers, and obviously it is very clear that we're going to try to combine linear classifiers SVM under like with this approach.",
                    "label": 0
                },
                {
                    "sent": "And also if you look at the paper from last year, we've also done some work on using SVM's falling discovery.",
                    "label": 0
                },
                {
                    "sent": "OK, thanks sure.",
                    "label": 0
                },
                {
                    "sent": "Thanks, thank you very much.",
                    "label": 0
                }
            ]
        }
    }
}